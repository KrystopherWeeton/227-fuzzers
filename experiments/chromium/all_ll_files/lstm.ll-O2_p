; ModuleID = '../../third_party/tflite/src/tensorflow/lite/kernels/lstm.cc'
source_filename = "../../third_party/tflite/src/tensorflow/lite/kernels/lstm.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.TfLiteContext = type { i64, i32 (%struct.TfLiteContext*, %struct.TfLiteIntArray**)*, %struct.TfLiteTensor*, i8*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, void (%struct.TfLiteContext*, i8*, ...)*, i32 (%struct.TfLiteContext*, i32, i32*)*, i32 (%struct.TfLiteContext*, i32, %struct.TfLiteNode**, %struct.TfLiteRegistration**)*, i32 (%struct.TfLiteContext*, %struct.TfLiteRegistration*, %struct.TfLiteIntArray*, %struct.TfLiteDelegate*)*, i32, %struct.TfLiteExternalContext* (%struct.TfLiteContext*, i32)*, void (%struct.TfLiteContext*, i32, %struct.TfLiteExternalContext*)*, i8, i8*, i32 (%struct.TfLiteContext*, i64, i8**)*, i32 (%struct.TfLiteContext*, i64, i8**)*, i32 (%struct.TfLiteContext*, i64, i32*)*, i8* (%struct.TfLiteContext*, i32)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, i32, i32*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteIntArray*, %struct.TfLiteDelegateParams**, i32*)* }
%struct.TfLiteIntArray = type { i32, [0 x i32] }
%struct.TfLiteTensor = type { i32, %union.TfLitePtrUnion, %struct.TfLiteIntArray*, %struct.TfLiteQuantizationParams, i32, i64, i8*, i8*, %struct.TfLiteDelegate*, i32, i8, i8, %struct.TfLiteQuantization, %struct.TfLiteSparsity*, %struct.TfLiteIntArray* }
%union.TfLitePtrUnion = type { i32* }
%struct.TfLiteQuantizationParams = type { float, i32 }
%struct.TfLiteDelegate = type { i8*, i32 (%struct.TfLiteContext*, %struct.TfLiteDelegate*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteDelegate*, i32, %struct.TfLiteTensor*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteDelegate*, i32, %struct.TfLiteTensor*)*, void (%struct.TfLiteContext*, %struct.TfLiteDelegate*, i32*)*, i64 }
%struct.TfLiteQuantization = type { i32, i8* }
%struct.TfLiteSparsity = type { %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, %struct.TfLiteDimensionMetadata*, i32 }
%struct.TfLiteDimensionMetadata = type { i32, i32, %struct.TfLiteIntArray*, %struct.TfLiteIntArray* }
%struct.TfLiteNode = type { %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, i8*, i8*, i8*, i32, %struct.TfLiteDelegate* }
%struct.TfLiteRegistration = type { {}*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 }
%struct.TfLiteExternalContext = type { i32, i32 (%struct.TfLiteContext*)* }
%struct.TfLiteDelegateParams = type { %struct.TfLiteDelegate*, %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, %struct.TfLiteIntArray* }
%"struct.ruy::KernelParamsFloat" = type <{ float*, float*, float*, float*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, float, float, i8, [3 x i8], [16 x float], [256 x float], [4 x i8] }>
%"struct.ruy::KernelParamsFloat.134" = type <{ float*, float*, float*, float*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, float, float, i8, [3 x i8], [8 x float], [64 x float], [4 x i8] }>
%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%struct.TfLiteLSTMParams = type { i32, float, float, i32, i8 }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i32* }
%"class.tflite::RuntimeShape" = type { i32, %union.anon }
%union.anon = type { i32*, [16 x i8] }
%"struct.tflite::ops::builtin::lstm::OpData" = type <{ i32, i8, [3 x i8], i32, [4 x i8], %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", i8, [7 x i8] }>
%"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter" = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i16, i8, i32, i32, i32, i32, i32, i32, %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr", [8 x i32], [8 x i32], [12 x i32] }
%struct.TfLiteAffineQuantization = type { %struct.TfLiteFloatArray*, %struct.TfLiteIntArray*, i32 }
%struct.TfLiteFloatArray = type { i32, [0 x float] }
%"class.std::__1::vector.25" = type { %"class.std::__1::__vector_base.26" }
%"class.std::__1::__vector_base.26" = type { float*, float*, %"class.std::__1::__compressed_pair.27" }
%"class.std::__1::__compressed_pair.27" = type { %"struct.std::__1::__compressed_pair_elem.28" }
%"struct.std::__1::__compressed_pair_elem.28" = type { float* }
%"class.std::__1::vector.32" = type { %"class.std::__1::__vector_base.33" }
%"class.std::__1::__vector_base.33" = type { i32*, i32*, %"class.std::__1::__compressed_pair.34" }
%"class.std::__1::__compressed_pair.34" = type { %"struct.std::__1::__compressed_pair_elem" }
%"class.std::__1::__vector_base_common" = type { i8 }
%"class.tflite::CpuBackendContext" = type <{ %"class.tflite::TfLiteInternalBackendContext", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.8", i32, i8, [3 x i8] }>
%"class.tflite::TfLiteInternalBackendContext" = type { i32 (...)** }
%"class.std::__1::unique_ptr.2" = type { %"class.std::__1::__compressed_pair.3" }
%"class.std::__1::__compressed_pair.3" = type { %"struct.std::__1::__compressed_pair_elem.4" }
%"struct.std::__1::__compressed_pair_elem.4" = type { %"class.ruy::Context"* }
%"class.ruy::Context" = type { %"class.ruy::CtxImpl"* }
%"class.ruy::CtxImpl" = type opaque
%"class.std::__1::unique_ptr.8" = type { %"class.std::__1::__compressed_pair.9" }
%"class.std::__1::__compressed_pair.9" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"struct.std::__1::__compressed_pair_elem.10" = type { %"class.gemmlowp::GemmContext"* }
%"class.gemmlowp::GemmContext" = type { %"class.gemmlowp::MultiThreadGemmContext" }
%"class.gemmlowp::MultiThreadGemmContext" = type { %"class.gemmlowp::MultiThreadGemmContextBase", %"class.gemmlowp::WorkersPool" }
%"class.gemmlowp::MultiThreadGemmContextBase" = type { %"class.gemmlowp::SingleThreadGemmContext.base", i32 }
%"class.gemmlowp::SingleThreadGemmContext.base" = type <{ %"class.gemmlowp::Allocator", i32, i32, float }>
%"class.gemmlowp::Allocator" = type { i8, i64, i8*, i64, i64, [5 x i64], i64 }
%"class.gemmlowp::WorkersPool" = type { %"class.std::__1::vector", %"class.gemmlowp::BlockingCounter", %"class.gemmlowp::Allocator" }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"**, %"class.std::__1::__compressed_pair.19" }
%"class.gemmlowp::Worker" = type { i64, %"struct.gemmlowp::Task"*, %union.pthread_cond_t, %union.pthread_mutex_t, %"struct.std::__1::atomic", %"class.gemmlowp::Allocator", %"class.gemmlowp::BlockingCounter"* }
%"struct.gemmlowp::Task" = type { i32 (...)**, %"class.gemmlowp::Allocator"* }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon.11, %union.anon.12, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon.11 = type { i64 }
%union.anon.12 = type { i64 }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"class.std::__1::__compressed_pair.19" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"struct.std::__1::__compressed_pair_elem.20" = type { %"class.gemmlowp::Worker"** }
%"class.gemmlowp::BlockingCounter" = type { %"struct.std::__1::atomic.14" }
%"struct.std::__1::atomic.14" = type { %"struct.std::__1::__atomic_base.15" }
%"struct.std::__1::__atomic_base.15" = type { %"struct.std::__1::__atomic_base.16" }
%"struct.std::__1::__atomic_base.16" = type { %"struct.std::__1::__cxx_atomic_impl.17" }
%"struct.std::__1::__cxx_atomic_impl.17" = type { %"struct.std::__1::__cxx_atomic_base_impl.18" }
%"struct.std::__1::__cxx_atomic_base_impl.18" = type { i64 }
%"struct.tflite::LstmCellParams" = type { i32, i32, i32, i32 }
%"struct.Eigen::internal::evaluator" = type { %"struct.Eigen::internal::binary_evaluator" }
%"struct.Eigen::internal::binary_evaluator" = type { %"struct.Eigen::internal::binary_evaluator<Eigen::CwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, const Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> > >, const Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::Map<const Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> > > >, Eigen::internal::IndexBased, Eigen::internal::IndexBased, float, float>::Data" }
%"struct.Eigen::internal::binary_evaluator<Eigen::CwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, const Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> > >, const Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::Map<const Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> > > >, Eigen::internal::IndexBased, Eigen::internal::IndexBased, float, float>::Data" = type { [8 x i8], %"struct.Eigen::internal::evaluator.176", %"struct.Eigen::internal::evaluator.196" }
%"struct.Eigen::internal::evaluator.176" = type { %"struct.Eigen::internal::evaluator.177" }
%"struct.Eigen::internal::evaluator.177" = type { %"struct.Eigen::internal::binary_evaluator.178" }
%"struct.Eigen::internal::binary_evaluator.178" = type { %"struct.Eigen::internal::binary_evaluator<Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> > >, Eigen::internal::IndexBased, Eigen::internal::IndexBased, float, float>::Data" }
%"struct.Eigen::internal::binary_evaluator<Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> > >, Eigen::internal::IndexBased, Eigen::internal::IndexBased, float, float>::Data" = type { %"struct.Eigen::internal::evaluator.181", %"struct.Eigen::internal::evaluator.191" }
%"struct.Eigen::internal::evaluator.181" = type { %"struct.Eigen::internal::evaluator.182" }
%"struct.Eigen::internal::evaluator.182" = type { %"struct.Eigen::internal::unary_evaluator" }
%"struct.Eigen::internal::unary_evaluator" = type { %"class.Eigen::internal::unary_evaluator<Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, Eigen::internal::IndexBased, float>::Data" }
%"class.Eigen::internal::unary_evaluator<Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, Eigen::internal::IndexBased, float>::Data" = type { %"struct.Eigen::internal::evaluator.185" }
%"struct.Eigen::internal::evaluator.185" = type { %"struct.Eigen::internal::evaluator.186" }
%"struct.Eigen::internal::evaluator.186" = type { %"struct.Eigen::internal::block_evaluator" }
%"struct.Eigen::internal::block_evaluator" = type { %"struct.Eigen::internal::mapbase_evaluator" }
%"struct.Eigen::internal::mapbase_evaluator" = type { float*, %"class.Eigen::internal::variable_if_dynamic.189", %"class.Eigen::internal::variable_if_dynamic" }
%"class.Eigen::internal::variable_if_dynamic.189" = type { i8 }
%"class.Eigen::internal::variable_if_dynamic" = type { i64 }
%"struct.Eigen::internal::evaluator.191" = type { %"struct.Eigen::internal::evaluator.192" }
%"struct.Eigen::internal::evaluator.192" = type { %"struct.Eigen::internal::unary_evaluator.193" }
%"struct.Eigen::internal::unary_evaluator.193" = type { %"class.Eigen::internal::unary_evaluator<Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, Eigen::internal::IndexBased, float>::Data" }
%"class.Eigen::internal::unary_evaluator<Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, Eigen::internal::IndexBased, float>::Data" = type { %"struct.Eigen::internal::evaluator.185" }
%"struct.Eigen::internal::evaluator.196" = type { %"struct.Eigen::internal::evaluator.197" }
%"struct.Eigen::internal::evaluator.197" = type { %"struct.Eigen::internal::binary_evaluator.198" }
%"struct.Eigen::internal::binary_evaluator.198" = type { %"struct.Eigen::internal::binary_evaluator<Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::Map<const Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> > >, Eigen::internal::IndexBased, Eigen::internal::IndexBased, float, float>::Data" }
%"struct.Eigen::internal::binary_evaluator<Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::Map<const Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> > >, Eigen::internal::IndexBased, Eigen::internal::IndexBased, float, float>::Data" = type { %"struct.Eigen::internal::evaluator.181", %"struct.Eigen::internal::evaluator.201" }
%"struct.Eigen::internal::evaluator.201" = type { %"struct.Eigen::internal::evaluator.202" }
%"struct.Eigen::internal::evaluator.202" = type { %"struct.Eigen::internal::mapbase_evaluator.203" }
%"struct.Eigen::internal::mapbase_evaluator.203" = type { float*, %"class.Eigen::internal::variable_if_dynamic.189", %"class.Eigen::internal::variable_if_dynamic" }
%"struct.Eigen::internal::evaluator.206" = type { %"struct.Eigen::internal::mapbase_evaluator.207" }
%"struct.Eigen::internal::mapbase_evaluator.207" = type { float*, %"class.Eigen::internal::variable_if_dynamic.189", %"class.Eigen::internal::variable_if_dynamic" }
%"class.Eigen::internal::generic_dense_assignment_kernel" = type { %"struct.Eigen::internal::evaluator.206"*, %"struct.Eigen::internal::evaluator"*, %"struct.Eigen::internal::assign_op"*, %"class.Eigen::Map"* }
%"struct.Eigen::internal::assign_op" = type { i8 }
%"class.Eigen::Map" = type <{ %"class.Eigen::MapBase", %"class.Eigen::Stride", [6 x i8] }>
%"class.Eigen::MapBase" = type { %"class.Eigen::MapBase.59" }
%"class.Eigen::MapBase.59" = type { float*, %"class.Eigen::internal::variable_if_dynamic", %"class.Eigen::internal::variable_if_dynamic" }
%"class.Eigen::Stride" = type { %"class.Eigen::internal::variable_if_dynamic.62", %"class.Eigen::internal::variable_if_dynamic.62" }
%"class.Eigen::internal::variable_if_dynamic.62" = type { i8 }
%"struct.Eigen::internal::evaluator.213" = type { %"struct.Eigen::internal::binary_evaluator.214" }
%"struct.Eigen::internal::binary_evaluator.214" = type { %"struct.Eigen::internal::binary_evaluator<Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> > > >, Eigen::internal::IndexBased, Eigen::internal::IndexBased, float, float>::Data" }
%"struct.Eigen::internal::binary_evaluator<Eigen::CwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<float>, const Eigen::Block<Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false> >, const Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> > > >, Eigen::internal::IndexBased, Eigen::internal::IndexBased, float, float>::Data" = type { %"struct.Eigen::internal::evaluator.181", %"struct.Eigen::internal::evaluator.217" }
%"struct.Eigen::internal::evaluator.217" = type { %"struct.Eigen::internal::evaluator.218" }
%"struct.Eigen::internal::evaluator.218" = type { %"struct.Eigen::internal::unary_evaluator.219" }
%"struct.Eigen::internal::unary_evaluator.219" = type { %"class.Eigen::internal::unary_evaluator<Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> > >, Eigen::internal::IndexBased, float>::Data" }
%"class.Eigen::internal::unary_evaluator<Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::Map<Eigen::Array<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> > >, Eigen::internal::IndexBased, float>::Data" = type { %"struct.Eigen::internal::evaluator.222" }
%"struct.Eigen::internal::evaluator.222" = type { %"struct.Eigen::internal::evaluator.206" }
%"class.Eigen::internal::generic_dense_assignment_kernel.223" = type { %"struct.Eigen::internal::evaluator.206"*, %"struct.Eigen::internal::evaluator.213"*, %"struct.Eigen::internal::assign_op"*, %"class.Eigen::Map"* }
%"class.std::__1::vector.45" = type { %"class.std::__1::__vector_base.46" }
%"class.std::__1::__vector_base.46" = type { float**, float**, %"class.std::__1::__compressed_pair.47" }
%"class.std::__1::__compressed_pair.47" = type { %"struct.std::__1::__compressed_pair_elem.48" }
%"struct.std::__1::__compressed_pair_elem.48" = type { float** }
%"class.std::__1::vector.52" = type { %"class.std::__1::__vector_base.53" }
%"class.std::__1::__vector_base.53" = type { %"class.tflite::RuntimeShape"**, %"class.tflite::RuntimeShape"**, %"class.std::__1::__compressed_pair.54" }
%"class.std::__1::__compressed_pair.54" = type { %"struct.std::__1::__compressed_pair_elem.55" }
%"struct.std::__1::__compressed_pair_elem.55" = type { %"class.tflite::RuntimeShape"** }
%"struct.tflite::FullyConnectedParams" = type { i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8 }
%"struct.tflite::cpu_backend_gemm::MatrixParams.224" = type <{ i32, i32, i32, i8, i8, [2 x i8] }>
%"struct.tflite::cpu_backend_gemm::MatrixParams.226" = type <{ i32, i32, i32, i16, i8, i8 }>
%"struct.tflite::cpu_backend_gemm::GemmParams.228" = type <{ i32, i32, i32*, i32*, i32*, i16, i16, [4 x i8] }>
%"struct.tflite::cpu_backend_gemm::MatrixParams" = type <{ i32, i32, i32, float, i8, [3 x i8] }>
%"struct.tflite::cpu_backend_gemm::GemmParams" = type { float, i32, float*, i32*, float*, float, float }
%"struct.ruy::Mat" = type <{ %"class.ruy::detail::ConstCheckingPtr", %"struct.ruy::MatLayout", float, i8, [3 x i8] }>
%"class.ruy::detail::ConstCheckingPtr" = type { float* }
%"struct.ruy::MatLayout" = type <{ i32, i32, i32, i8, [3 x i8] }>
%"class.ruy::MulParams" = type { float*, float, i32, float*, i32*, float, float }
%"class.ruy::Ctx" = type { i8 }
%"struct.ruy::TrMulParams" = type { i8, %"class.ruy::SidePair", void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)*, %"class.ruy::SidePair.130", %"struct.ruy::EMat", %"class.ruy::SidePair.128", %"class.ruy::SidePair.131", i8* }
%"class.ruy::SidePair" = type { [2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*] }
%"struct.ruy::PEMat" = type <{ %"struct.ruy::Type", [5 x i8], i8*, %"struct.ruy::Type", [5 x i8], i8*, %"struct.ruy::PMatLayout", i32, [4 x i8] }>
%"struct.ruy::Type" = type { i8, i8, i8 }
%"struct.ruy::PMatLayout" = type { i32, i32, i32, i8, %"struct.ruy::KernelLayout" }
%"struct.ruy::KernelLayout" = type { i8, i8, i8 }
%"class.ruy::SidePair.129" = type { [2 x i32] }
%"class.ruy::SidePair.130" = type { [2 x %"struct.ruy::EMat"] }
%"struct.ruy::EMat" = type <{ %"struct.ruy::Type", [5 x i8], i8*, %"struct.ruy::MatLayout", i32, i8, [3 x i8] }>
%"class.ruy::SidePair.128" = type { [2 x %"struct.ruy::PEMat"] }
%"class.ruy::SidePair.131" = type { [2 x i8] }
%"class.ruy::PrepackedCache" = type { %"class.std::__1::unordered_map", i32, i32, i64 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.137", %"class.std::__1::__compressed_pair.146", %"class.std::__1::__compressed_pair.151", %"class.std::__1::__compressed_pair.153", [4 x i8] }>
%"class.std::__1::unique_ptr.137" = type { %"class.std::__1::__compressed_pair.138" }
%"class.std::__1::__compressed_pair.138" = type { %"struct.std::__1::__compressed_pair_elem.139", %"struct.std::__1::__compressed_pair_elem.140" }
%"struct.std::__1::__compressed_pair_elem.139" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.140" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.141" }
%"class.std::__1::__compressed_pair.141" = type { %"struct.std::__1::__compressed_pair_elem.142" }
%"struct.std::__1::__compressed_pair_elem.142" = type { i64 }
%"class.std::__1::__compressed_pair.146" = type { %"struct.std::__1::__compressed_pair_elem.147" }
%"struct.std::__1::__compressed_pair_elem.147" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.151" = type { %"struct.std::__1::__compressed_pair_elem.142" }
%"class.std::__1::__compressed_pair.153" = type { %"struct.std::__1::__compressed_pair_elem.154" }
%"struct.std::__1::__compressed_pair_elem.154" = type { float }
%"struct.ruy::PMat" = type <{ float*, float*, %"struct.ruy::PMatLayout", i32, [4 x i8] }>
%"struct.ruy::Kernel" = type { i8 }
%"class.std::__1::chrono::duration.170" = type { i64 }
%union.pthread_condattr_t = type { i32 }
%union.pthread_mutexattr_t = type { i32 }
%union.pthread_attr_t = type { i64, [48 x i8] }
%"class.Eigen::DenseBase" = type { i8 }
%"struct.ruy::Mat.237" = type <{ %"class.ruy::detail::ConstCheckingPtr.233", %"struct.ruy::MatLayout", i8, i8, [6 x i8] }>
%"class.ruy::detail::ConstCheckingPtr.233" = type { i8* }
%"struct.ruy::Mat.238" = type <{ %"class.ruy::detail::ConstCheckingPtr.235", %"struct.ruy::MatLayout", i16, i8, [5 x i8] }>
%"class.ruy::detail::ConstCheckingPtr.235" = type { i16* }
%"class.ruy::MulParams.236" = type <{ i32*, i32, i32, i32*, i32*, i16, i16, [4 x i8] }>
%"class.gemmlowp::VectorDup" = type { i32, i32 }
%"class.gemmlowp::VectorDup.272" = type { i32, i32 }
%"class.gemmlowp::MatrixMap" = type <{ i8*, i32, i32, i32, [4 x i8] }>
%"class.gemmlowp::MatrixMap.258" = type <{ i8*, i32, i32, i32, [4 x i8] }>
%"class.gemmlowp::MatrixMap.260" = type <{ i16*, i32, i32, i32, [4 x i8] }>
%"class.std::__1::tuple" = type { %"struct.std::__1::__tuple_impl" }
%"struct.std::__1::__tuple_impl" = type { %"class.std::__1::__tuple_leaf", %"class.std::__1::__tuple_leaf.262", %"class.std::__1::__tuple_leaf.263", [4 x i8] }
%"class.std::__1::__tuple_leaf" = type { %"struct.gemmlowp::OutputStageBiasAddition" }
%"struct.gemmlowp::OutputStageBiasAddition" = type { %"class.gemmlowp::VectorMap" }
%"class.gemmlowp::VectorMap" = type <{ i32*, i32, [4 x i8] }>
%"class.std::__1::__tuple_leaf.262" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent" }
%"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent" = type { i32, i32, i32 }
%"class.std::__1::__tuple_leaf.263" = type { %"struct.gemmlowp::OutputStageClamp" }
%"struct.gemmlowp::OutputStageClamp" = type { i32, i32 }
%"class.std::__1::tuple.265" = type { %"struct.std::__1::__tuple_impl.266" }
%"struct.std::__1::__tuple_impl.266" = type { %"class.std::__1::__tuple_leaf.267", %"class.std::__1::__tuple_leaf.268" }
%"class.std::__1::__tuple_leaf.267" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent" }
%"class.std::__1::__tuple_leaf.268" = type { %"struct.gemmlowp::OutputStageClamp" }
%"struct.ruy::KernelParams8bit" = type <{ i32*, i32*, i32*, i8*, i32*, i32*, i8*, i8*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i8, i8, [2 x i8], [16 x i32], [1024 x i8], [16 x i32], [16 x i32], [4 x i8] }>
%"struct.ruy::PMat.239" = type <{ i8*, i32*, %"struct.ruy::PMatLayout", i32, [4 x i8] }>
%"struct.ruy::Kernel.240" = type { i8 }
%"struct.ruy::KernelParams8bit.245" = type <{ i32*, i32*, i32*, i8*, i32*, i32*, i8*, i8*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i8, i8, [2 x i8], [8 x i32], [256 x i8], [8 x i32], [8 x i32], [4 x i8] }>
%"class.gemmlowp::MatrixMap.273" = type <{ i16*, i32, i32, i32, [4 x i8] }>
%"class.std::__1::tuple.275" = type { %"struct.std::__1::__tuple_impl.276" }
%"struct.std::__1::__tuple_impl.276" = type { %"class.std::__1::__tuple_leaf.277", %"class.std::__1::__tuple_leaf.262", %"class.std::__1::__tuple_leaf.263", [4 x i8] }
%"class.std::__1::__tuple_leaf.277" = type { %"struct.gemmlowp::OutputStageBiasAddition.278" }
%"struct.gemmlowp::OutputStageBiasAddition.278" = type { %"class.gemmlowp::VectorMap.279" }
%"class.gemmlowp::VectorMap.279" = type <{ i32*, i32, [4 x i8] }>
%"struct.gemmlowp::DefaultKernel" = type { %"struct.gemmlowp::DefaultKernelImpl" }
%"struct.gemmlowp::DefaultKernelImpl" = type { %"struct.gemmlowp::DefaultKernelImpl.282" }
%"struct.gemmlowp::DefaultKernelImpl.282" = type { %"struct.gemmlowp::ReferenceKernel" }
%"struct.gemmlowp::ReferenceKernel" = type { %"struct.gemmlowp::KernelBase" }
%"struct.gemmlowp::KernelBase" = type { i32 (...)** }
%"class.gemmlowp::SideMap" = type <{ i8*, i32, i32, i32, [4 x i8] }>
%"class.gemmlowp::PackSideBlockImpl" = type { %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::SideMap"* }
%"class.gemmlowp::PackedSideBlock" = type <{ %"struct.gemmlowp::SideBlockParams", %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator::Handle", %"class.gemmlowp::Allocator::Handle", i32, [4 x i8] }>
%"struct.gemmlowp::SideBlockParams" = type { i32, i32, i32, i32 }
%"class.gemmlowp::Allocator::Handle" = type <{ i8, [7 x i8], i64, i8, [7 x i8] }>
%"struct.gemmlowp::BlockParams" = type { i32, i32, i32, i32, i32, i32 }
%"class.std::__1::vector.283" = type { %"class.std::__1::__vector_base.284" }
%"class.std::__1::__vector_base.284" = type { %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"**, %"class.std::__1::__compressed_pair.285" }
%"class.std::__1::__compressed_pair.285" = type { %"struct.std::__1::__compressed_pair_elem.286" }
%"struct.std::__1::__compressed_pair_elem.286" = type { %"struct.gemmlowp::Task"** }
%"class.gemmlowp::SingleThreadGemmContext" = type <{ %"class.gemmlowp::Allocator", i32, i32, float, [4 x i8] }>
%"class.gemmlowp::ComputeImpl" = type { %"struct.gemmlowp::KernelBase"*, %"struct.gemmlowp::BlockParams"*, %"class.gemmlowp::PackedResult"*, %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"* }
%"class.gemmlowp::PackedResult" = type { %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator::Handle", %"struct.gemmlowp::BlockParams"* }
%"struct.gemmlowp::MatrixBlockBounds" = type { i32, i32, i32, i32 }
%"struct.gemmlowp::RegisterBlock" = type { %"struct.gemmlowp::RegisterBuffer" }
%"struct.gemmlowp::RegisterBuffer" = type { [64 x i16] }
%"class.gemmlowp::MatrixMap.292" = type <{ i32*, i32, i32, i32, [4 x i8] }>
%"struct.gemmlowp::OutputPipelineExecutor" = type { %"struct.gemmlowp::OutputPipelineEvalImpl" }
%"struct.gemmlowp::OutputPipelineEvalImpl" = type { %"struct.gemmlowp::OutputStageEvalImpl", %"struct.gemmlowp::OutputPipelineEvalImpl.294" }
%"struct.gemmlowp::OutputStageEvalImpl" = type { %"struct.gemmlowp::OutputStageBiasAddition.278"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.294" = type { %"struct.gemmlowp::OutputStageEvalImpl.295", %"struct.gemmlowp::OutputPipelineEvalImpl.296" }
%"struct.gemmlowp::OutputStageEvalImpl.295" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl" }
%"struct.gemmlowp::OutputStageEvalBufferImpl" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.296" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.297", %"struct.gemmlowp::OutputPipelineEvalImpl.299", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.297" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.298" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.298" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.299" = type { %"struct.gemmlowp::OutputStageEvalImpl.300", %"struct.gemmlowp::OutputPipelineEvalImpl.302" }
%"struct.gemmlowp::OutputStageEvalImpl.300" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.301" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.301" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.302" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.304" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.305" }
%"struct.gemmlowp::OutputPipelineEvalImpl.305" = type { %"struct.gemmlowp::OutputStageEvalImpl.306", %"struct.gemmlowp::OutputPipelineEvalImpl.307" }
%"struct.gemmlowp::OutputStageEvalImpl.306" = type { %"struct.gemmlowp::OutputStageBiasAddition.278"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.307" = type { %"struct.gemmlowp::OutputStageEvalImpl.308", %"struct.gemmlowp::OutputPipelineEvalImpl.310" }
%"struct.gemmlowp::OutputStageEvalImpl.308" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.309" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.309" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.310" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.311", %"struct.gemmlowp::OutputPipelineEvalImpl.313", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.311" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.312" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.312" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.313" = type { %"struct.gemmlowp::OutputStageEvalImpl.314", %"struct.gemmlowp::OutputPipelineEvalImpl.317" }
%"struct.gemmlowp::OutputStageEvalImpl.314" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.315" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.315" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.317" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.320" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.321" }
%"struct.gemmlowp::OutputPipelineEvalImpl.321" = type { %"struct.gemmlowp::OutputStageEvalImpl.322", %"struct.gemmlowp::OutputPipelineEvalImpl.323" }
%"struct.gemmlowp::OutputStageEvalImpl.322" = type { %"struct.gemmlowp::OutputStageBiasAddition.278"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.323" = type { %"struct.gemmlowp::OutputStageEvalImpl.324", %"struct.gemmlowp::OutputPipelineEvalImpl.326" }
%"struct.gemmlowp::OutputStageEvalImpl.324" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.325" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.325" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.326" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.327", %"struct.gemmlowp::OutputPipelineEvalImpl.329", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.327" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.328" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.328" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.329" = type { %"struct.gemmlowp::OutputStageEvalImpl.330", %"struct.gemmlowp::OutputPipelineEvalImpl.333" }
%"struct.gemmlowp::OutputStageEvalImpl.330" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.331" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.331" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.333" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.336" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.337" }
%"struct.gemmlowp::OutputPipelineEvalImpl.337" = type { %"struct.gemmlowp::OutputStageEvalImpl.338", %"struct.gemmlowp::OutputPipelineEvalImpl.339" }
%"struct.gemmlowp::OutputStageEvalImpl.338" = type { %"struct.gemmlowp::OutputStageBiasAddition.278"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.339" = type { %"struct.gemmlowp::OutputStageEvalImpl.340", %"struct.gemmlowp::OutputPipelineEvalImpl.341" }
%"struct.gemmlowp::OutputStageEvalImpl.340" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.309" }
%"struct.gemmlowp::OutputPipelineEvalImpl.341" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.342", %"struct.gemmlowp::OutputPipelineEvalImpl.343", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.342" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.312" }
%"struct.gemmlowp::OutputPipelineEvalImpl.343" = type { %"struct.gemmlowp::OutputStageEvalImpl.344", %"struct.gemmlowp::OutputPipelineEvalImpl.345" }
%"struct.gemmlowp::OutputStageEvalImpl.344" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.315" }
%"struct.gemmlowp::OutputPipelineEvalImpl.345" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.348" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.349" }
%"struct.gemmlowp::OutputPipelineEvalImpl.349" = type { %"struct.gemmlowp::OutputStageEvalImpl.350", %"struct.gemmlowp::OutputPipelineEvalImpl.351" }
%"struct.gemmlowp::OutputStageEvalImpl.350" = type { %"struct.gemmlowp::OutputStageBiasAddition.278"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.351" = type { %"struct.gemmlowp::OutputStageEvalImpl.352", %"struct.gemmlowp::OutputPipelineEvalImpl.354" }
%"struct.gemmlowp::OutputStageEvalImpl.352" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.353" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.353" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.354" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.355", %"struct.gemmlowp::OutputPipelineEvalImpl.357", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.355" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.356" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.356" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.357" = type { %"struct.gemmlowp::OutputStageEvalImpl.358", %"struct.gemmlowp::OutputPipelineEvalImpl.361" }
%"struct.gemmlowp::OutputStageEvalImpl.358" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.359" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.359" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.361" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.364" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.365" }
%"struct.gemmlowp::OutputPipelineEvalImpl.365" = type { %"struct.gemmlowp::OutputStageEvalImpl.366", %"struct.gemmlowp::OutputPipelineEvalImpl.367" }
%"struct.gemmlowp::OutputStageEvalImpl.366" = type { %"struct.gemmlowp::OutputStageBiasAddition.278"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.367" = type { %"struct.gemmlowp::OutputStageEvalImpl.368", %"struct.gemmlowp::OutputPipelineEvalImpl.370" }
%"struct.gemmlowp::OutputStageEvalImpl.368" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.369" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.369" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.370" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.371", %"struct.gemmlowp::OutputPipelineEvalImpl.373", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.371" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.372" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.372" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.373" = type { %"struct.gemmlowp::OutputStageEvalImpl.374", %"struct.gemmlowp::OutputPipelineEvalImpl.377" }
%"struct.gemmlowp::OutputStageEvalImpl.374" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.375" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.375" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.377" = type { i8 }
%"class.gemmlowp::PackingRegisterBlock" = type { %"class.gemmlowp::PackingRegisterBlockBase" }
%"class.gemmlowp::PackingRegisterBlockBase" = type { %"class.gemmlowp::SideMap", [64 x i8] }
%"struct.gemmlowp::RegisterBlock.380" = type { %"struct.gemmlowp::RegisterBuffer.381" }
%"struct.gemmlowp::RegisterBuffer.381" = type { [32 x i32] }
%"struct.gemmlowp::RegisterBlock.393" = type { %"struct.gemmlowp::RegisterBuffer.394" }
%"struct.gemmlowp::RegisterBuffer.394" = type { [16 x i16] }
%"struct.gemmlowp::RegisterBlock.390" = type { %"struct.gemmlowp::RegisterBuffer.391" }
%"struct.gemmlowp::RegisterBuffer.391" = type { [16 x i32] }
%"struct.gemmlowp::RegisterBlock.382" = type { %"struct.gemmlowp::RegisterBuffer.383" }
%"struct.gemmlowp::RegisterBuffer.383" = type { [8 x i32] }
%"struct.gemmlowp::RegisterBlock.388" = type { %"struct.gemmlowp::RegisterBuffer.389" }
%"struct.gemmlowp::RegisterBuffer.389" = type { [32 x i16] }
%"struct.gemmlowp::GemmWithPackedRhsTask" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.273", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup.272"*, %"class.gemmlowp::VectorDup"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.275"* }
%"struct.gemmlowp::OutputPipelineExecutor.407" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.408" }
%"struct.gemmlowp::OutputPipelineEvalImpl.408" = type { %"struct.gemmlowp::OutputStageEvalImpl.409", %"struct.gemmlowp::OutputPipelineEvalImpl.410" }
%"struct.gemmlowp::OutputStageEvalImpl.409" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.410" = type { %"struct.gemmlowp::OutputStageEvalImpl.295", %"struct.gemmlowp::OutputPipelineEvalImpl.411" }
%"struct.gemmlowp::OutputPipelineEvalImpl.411" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.297", %"struct.gemmlowp::OutputPipelineEvalImpl.412", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.412" = type { %"struct.gemmlowp::OutputStageEvalImpl.300", %"struct.gemmlowp::OutputPipelineEvalImpl.413" }
%"struct.gemmlowp::OutputPipelineEvalImpl.413" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.416" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.417" }
%"struct.gemmlowp::OutputPipelineEvalImpl.417" = type { %"struct.gemmlowp::OutputStageEvalImpl.418", %"struct.gemmlowp::OutputPipelineEvalImpl.419" }
%"struct.gemmlowp::OutputStageEvalImpl.418" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.419" = type { %"struct.gemmlowp::OutputStageEvalImpl.308", %"struct.gemmlowp::OutputPipelineEvalImpl.420" }
%"struct.gemmlowp::OutputPipelineEvalImpl.420" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.311", %"struct.gemmlowp::OutputPipelineEvalImpl.421", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.421" = type { %"struct.gemmlowp::OutputStageEvalImpl.314", %"struct.gemmlowp::OutputPipelineEvalImpl.422" }
%"struct.gemmlowp::OutputPipelineEvalImpl.422" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.425" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.426" }
%"struct.gemmlowp::OutputPipelineEvalImpl.426" = type { %"struct.gemmlowp::OutputStageEvalImpl.427", %"struct.gemmlowp::OutputPipelineEvalImpl.428" }
%"struct.gemmlowp::OutputStageEvalImpl.427" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.428" = type { %"struct.gemmlowp::OutputStageEvalImpl.324", %"struct.gemmlowp::OutputPipelineEvalImpl.429" }
%"struct.gemmlowp::OutputPipelineEvalImpl.429" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.327", %"struct.gemmlowp::OutputPipelineEvalImpl.430", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.430" = type { %"struct.gemmlowp::OutputStageEvalImpl.330", %"struct.gemmlowp::OutputPipelineEvalImpl.431" }
%"struct.gemmlowp::OutputPipelineEvalImpl.431" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.434" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.435" }
%"struct.gemmlowp::OutputPipelineEvalImpl.435" = type { %"struct.gemmlowp::OutputStageEvalImpl.436", %"struct.gemmlowp::OutputPipelineEvalImpl.437" }
%"struct.gemmlowp::OutputStageEvalImpl.436" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.437" = type { %"struct.gemmlowp::OutputStageEvalImpl.340", %"struct.gemmlowp::OutputPipelineEvalImpl.438" }
%"struct.gemmlowp::OutputPipelineEvalImpl.438" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.342", %"struct.gemmlowp::OutputPipelineEvalImpl.439", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.439" = type { %"struct.gemmlowp::OutputStageEvalImpl.344", %"struct.gemmlowp::OutputPipelineEvalImpl.440" }
%"struct.gemmlowp::OutputPipelineEvalImpl.440" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.443" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.444" }
%"struct.gemmlowp::OutputPipelineEvalImpl.444" = type { %"struct.gemmlowp::OutputStageEvalImpl.445", %"struct.gemmlowp::OutputPipelineEvalImpl.446" }
%"struct.gemmlowp::OutputStageEvalImpl.445" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.446" = type { %"struct.gemmlowp::OutputStageEvalImpl.352", %"struct.gemmlowp::OutputPipelineEvalImpl.447" }
%"struct.gemmlowp::OutputPipelineEvalImpl.447" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.355", %"struct.gemmlowp::OutputPipelineEvalImpl.448", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.448" = type { %"struct.gemmlowp::OutputStageEvalImpl.358", %"struct.gemmlowp::OutputPipelineEvalImpl.449" }
%"struct.gemmlowp::OutputPipelineEvalImpl.449" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.452" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.453" }
%"struct.gemmlowp::OutputPipelineEvalImpl.453" = type { %"struct.gemmlowp::OutputStageEvalImpl.454", %"struct.gemmlowp::OutputPipelineEvalImpl.455" }
%"struct.gemmlowp::OutputStageEvalImpl.454" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.455" = type { %"struct.gemmlowp::OutputStageEvalImpl.368", %"struct.gemmlowp::OutputPipelineEvalImpl.456" }
%"struct.gemmlowp::OutputPipelineEvalImpl.456" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.371", %"struct.gemmlowp::OutputPipelineEvalImpl.457", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.457" = type { %"struct.gemmlowp::OutputStageEvalImpl.374", %"struct.gemmlowp::OutputPipelineEvalImpl.458" }
%"struct.gemmlowp::OutputPipelineEvalImpl.458" = type { i8 }
%"struct.gemmlowp::GemmWithPackedRhsTask.406" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.260", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup.272"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple"* }
%"struct.gemmlowp::OutputPipelineExecutor.471" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.472" }
%"struct.gemmlowp::OutputPipelineEvalImpl.472" = type { %"struct.gemmlowp::OutputStageEvalImpl.308", %"struct.gemmlowp::OutputPipelineEvalImpl.473" }
%"struct.gemmlowp::OutputPipelineEvalImpl.473" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.311", %"struct.gemmlowp::OutputPipelineEvalImpl.474", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.474" = type { %"struct.gemmlowp::OutputStageEvalImpl.314", %"struct.gemmlowp::OutputPipelineEvalImpl.475" }
%"struct.gemmlowp::OutputPipelineEvalImpl.475" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.478" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.479" }
%"struct.gemmlowp::OutputPipelineEvalImpl.479" = type { %"struct.gemmlowp::OutputStageEvalImpl.324", %"struct.gemmlowp::OutputPipelineEvalImpl.480" }
%"struct.gemmlowp::OutputPipelineEvalImpl.480" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.327", %"struct.gemmlowp::OutputPipelineEvalImpl.481", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.481" = type { %"struct.gemmlowp::OutputStageEvalImpl.330", %"struct.gemmlowp::OutputPipelineEvalImpl.482" }
%"struct.gemmlowp::OutputPipelineEvalImpl.482" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.485" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.486" }
%"struct.gemmlowp::OutputPipelineEvalImpl.486" = type { %"struct.gemmlowp::OutputStageEvalImpl.340", %"struct.gemmlowp::OutputPipelineEvalImpl.487" }
%"struct.gemmlowp::OutputPipelineEvalImpl.487" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.342", %"struct.gemmlowp::OutputPipelineEvalImpl.488", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.488" = type { %"struct.gemmlowp::OutputStageEvalImpl.344", %"struct.gemmlowp::OutputPipelineEvalImpl.489" }
%"struct.gemmlowp::OutputPipelineEvalImpl.489" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.492" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.493" }
%"struct.gemmlowp::OutputPipelineEvalImpl.493" = type { %"struct.gemmlowp::OutputStageEvalImpl.352", %"struct.gemmlowp::OutputPipelineEvalImpl.494" }
%"struct.gemmlowp::OutputPipelineEvalImpl.494" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.355", %"struct.gemmlowp::OutputPipelineEvalImpl.495", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.495" = type { %"struct.gemmlowp::OutputStageEvalImpl.358", %"struct.gemmlowp::OutputPipelineEvalImpl.496" }
%"struct.gemmlowp::OutputPipelineEvalImpl.496" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.499" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.500" }
%"struct.gemmlowp::OutputPipelineEvalImpl.500" = type { %"struct.gemmlowp::OutputStageEvalImpl.368", %"struct.gemmlowp::OutputPipelineEvalImpl.501" }
%"struct.gemmlowp::OutputPipelineEvalImpl.501" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.371", %"struct.gemmlowp::OutputPipelineEvalImpl.502", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.502" = type { %"struct.gemmlowp::OutputStageEvalImpl.374", %"struct.gemmlowp::OutputPipelineEvalImpl.503" }
%"struct.gemmlowp::OutputPipelineEvalImpl.503" = type { i8 }
%"struct.gemmlowp::GemmWithPackedRhsTask.463" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.273", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup.272"*, %"class.gemmlowp::VectorDup"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.265"* }
%"struct.gemmlowp::GemmWithPackedRhsTask.506" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.260", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup.272"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.265"* }

$_ZN6tflite13optimized_ops8LstmCellERKNS_14LstmCellParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_S8_S6_S8_S6_PfS6_S9_S6_S9_S6_S9_PNS_17CpuBackendContextE = comdat any

$_ZN6tflite13optimized_ops8LstmCellILi4EEEvRKNS_14LstmCellParamsERKNS_12RuntimeShapeEPKhS7_S9_S7_S9_S7_PKiS7_PKsS7_PsS7_PhS7_SF_S7_SE_PNS_17CpuBackendContextE = comdat any

$_ZN6tflite11MatchingDimIJNS_12RuntimeShapeEiS1_iS1_iEEEiRKS1_iS3_iDpT_ = comdat any

$_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfPNS_17CpuBackendContextE = comdat any

$_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIffffLNS0_18QuantizationFlavorE0EE3RunERKNS0_12MatrixParamsIfEEPKfS8_SA_S8_PfRKNS0_10GemmParamsIffLS3_0EEEPNS_17CpuBackendContextE = comdat any

$_ZN3ruy11DispatchMulILNS_4PathE26EfffNS_9MulParamsIffEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE = comdat any

$_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE = comdat any

$_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE16EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEii = comdat any

$_ZNK3ruy6KernelILNS_4PathE2EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE = comdat any

$_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EfffNS_9MulParamsIffEEE6SearchES1_PNS_11TrMulParamsE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EfffNS_9MulParamsIffEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE8EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN8gemmlowp11WorkersPool13CreateWorkersEm = comdat any

$_ZN8gemmlowp6Worker10ThreadFuncEPv = comdat any

$_ZN8gemmlowp6Worker10ThreadFuncEv = comdat any

$_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS3_INS_13CwiseBinaryOpINS0_13scalar_sum_opIffEEKNSB_INS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS9_Lin1ELin1ELb0EEEEEKNSG_INS0_14scalar_tanh_opIfEESL_EEEEKNSB_ISF_SN_KNS4_IKS6_Li0ES8_EEEEEEEENS0_9assign_opIffEELi0EEELi4ELi0EE3runERS13_ = comdat any

$_ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opIffEEKNS2_INS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEELin1ELin1ELb0EEEEEKNS7_INS0_14scalar_tanh_opIfEESI_EEEEKNS2_IS6_SK_KNSB_IKSD_Li0ESF_EEEEEENS0_10IndexBasedESX_ffE5coeffEll = comdat any

$_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS3_INS_13CwiseBinaryOpINS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS9_Lin1ELin1ELb0EEEEEKNSE_INS0_14scalar_tanh_opIfEEKS9_EEEEEENS0_9assign_opIffEELi0EEELi4ELi0EE3runERSV_ = comdat any

$_ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS8_Lin1ELin1ELb0EEEEEKNSD_INS0_14scalar_tanh_opIfEEKS8_EEEEEENS0_9assign_opIffEELi0EE23assignCoeffByOuterInnerEll = comdat any

$_ZN6tflite3ops7builtin9lstm_eval20IntegerLstmParameterD2Ev = comdat any

$_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE = comdat any

$_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE = comdat any

$_ZN3ruy11DispatchMulILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE = comdat any

$_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE16EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhiE3RunENS_6TuningERKNS_3MatIhEEPNS_4PMatIhEEii = comdat any

$_ZNK3ruy6KernelILNS_4PathE2EhhsNS_9MulParamsIisEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIsEE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE8EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif = comdat any

$_ZN8gemmlowp9Allocator6CommitEv = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev = comdat any

$_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE7PackRunEiiii = comdat any

$_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i = comdat any

$_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIsLi8ELi8EEENS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_ = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv = comdat any

$_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEv = comdat any

$_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE3RunEPimmPKhSB_mm = comdat any

$_ZN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEED0Ev = comdat any

$_ZN8gemmlowp10KernelBaseD2Ev = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvS8_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvS8_PT_iiii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_ = comdat any

$_ZN8gemmlowp22exp_on_negative_valuesIsLi3EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE = comdat any

$_ZN8gemmlowp40one_minus_x_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_ = comdat any

$_ZN8gemmlowp22exp_on_negative_valuesIsLi4EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE = comdat any

$_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count = comdat any

$_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE = comdat any

$_ZZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEvE3buf = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = comdat any

@.str = private unnamed_addr constant [23 x i8] c"%s:%d %s was not true.\00", align 1
@.str.3 = private unnamed_addr constant [61 x i8] c"../../third_party/tflite/src/tensorflow/lite/kernels/lstm.cc\00", align 1
@.str.4 = private unnamed_addr constant [23 x i8] c"params->cell_clip >= 0\00", align 1
@.str.5 = private unnamed_addr constant [23 x i8] c"params->proj_clip >= 0\00", align 1
@.str.6 = private unnamed_addr constant [26 x i8] c"%s:%d %s != %s (%d != %d)\00", align 1
@.str.7 = private unnamed_addr constant [36 x i8] c"input_to_forget_weights->dims->size\00", align 1
@.str.8 = private unnamed_addr constant [2 x i8] c"2\00", align 1
@.str.9 = private unnamed_addr constant [39 x i8] c"input_to_forget_weights->dims->data[0]\00", align 1
@.str.10 = private unnamed_addr constant [7 x i8] c"n_cell\00", align 1
@.str.11 = private unnamed_addr constant [39 x i8] c"input_to_forget_weights->dims->data[1]\00", align 1
@.str.12 = private unnamed_addr constant [8 x i8] c"n_input\00", align 1
@.str.13 = private unnamed_addr constant [151 x i8] c"(input_to_forget_weights->type == kTfLiteFloat32) || (input_to_forget_weights->type == kTfLiteUInt8) || (input_to_forget_weights->type == kTfLiteInt8)\00", align 1
@.str.14 = private unnamed_addr constant [35 x i8] c"input_to_input_weights->dims->size\00", align 1
@.str.15 = private unnamed_addr constant [38 x i8] c"input_to_input_weights->dims->data[0]\00", align 1
@.str.16 = private unnamed_addr constant [38 x i8] c"input_to_input_weights->dims->data[1]\00", align 1
@.str.17 = private unnamed_addr constant [26 x i8] c"%s:%d %s != %s (%s != %s)\00", align 1
@.str.18 = private unnamed_addr constant [29 x i8] c"input_to_input_weights->type\00", align 1
@.str.19 = private unnamed_addr constant [30 x i8] c"input_to_forget_weights->type\00", align 1
@.str.20 = private unnamed_addr constant [34 x i8] c"input_to_cell_weights->dims->size\00", align 1
@.str.21 = private unnamed_addr constant [37 x i8] c"input_to_cell_weights->dims->data[0]\00", align 1
@.str.22 = private unnamed_addr constant [37 x i8] c"input_to_cell_weights->dims->data[1]\00", align 1
@.str.23 = private unnamed_addr constant [28 x i8] c"input_to_cell_weights->type\00", align 1
@.str.24 = private unnamed_addr constant [39 x i8] c"recurrent_to_input_weights->dims->size\00", align 1
@.str.25 = private unnamed_addr constant [42 x i8] c"recurrent_to_input_weights->dims->data[0]\00", align 1
@.str.26 = private unnamed_addr constant [42 x i8] c"recurrent_to_input_weights->dims->data[1]\00", align 1
@.str.27 = private unnamed_addr constant [9 x i8] c"n_output\00", align 1
@.str.28 = private unnamed_addr constant [33 x i8] c"recurrent_to_input_weights->type\00", align 1
@.str.29 = private unnamed_addr constant [40 x i8] c"recurrent_to_forget_weights->dims->size\00", align 1
@.str.30 = private unnamed_addr constant [43 x i8] c"recurrent_to_forget_weights->dims->data[0]\00", align 1
@.str.31 = private unnamed_addr constant [43 x i8] c"recurrent_to_forget_weights->dims->data[1]\00", align 1
@.str.32 = private unnamed_addr constant [34 x i8] c"recurrent_to_forget_weights->type\00", align 1
@.str.33 = private unnamed_addr constant [38 x i8] c"recurrent_to_cell_weights->dims->size\00", align 1
@.str.34 = private unnamed_addr constant [41 x i8] c"recurrent_to_cell_weights->dims->data[0]\00", align 1
@.str.35 = private unnamed_addr constant [41 x i8] c"recurrent_to_cell_weights->dims->data[1]\00", align 1
@.str.36 = private unnamed_addr constant [32 x i8] c"recurrent_to_cell_weights->type\00", align 1
@.str.37 = private unnamed_addr constant [33 x i8] c"cifg_weights_all_or_none == true\00", align 1
@.str.38 = private unnamed_addr constant [34 x i8] c"cell_to_input_weights->dims->size\00", align 1
@.str.39 = private unnamed_addr constant [2 x i8] c"1\00", align 1
@.str.40 = private unnamed_addr constant [37 x i8] c"cell_to_input_weights->dims->data[0]\00", align 1
@.str.41 = private unnamed_addr constant [28 x i8] c"cell_to_input_weights->type\00", align 1
@.str.42 = private unnamed_addr constant [58 x i8] c"is_integer ? kTfLiteInt16 : input_to_forget_weights->type\00", align 1
@.str.43 = private unnamed_addr constant [35 x i8] c"cell_to_forget_weights->dims->size\00", align 1
@.str.44 = private unnamed_addr constant [38 x i8] c"cell_to_forget_weights->dims->data[0]\00", align 1
@.str.45 = private unnamed_addr constant [29 x i8] c"cell_to_forget_weights->type\00", align 1
@.str.46 = private unnamed_addr constant [35 x i8] c"cell_to_output_weights->dims->size\00", align 1
@.str.47 = private unnamed_addr constant [38 x i8] c"cell_to_output_weights->dims->data[0]\00", align 1
@.str.48 = private unnamed_addr constant [29 x i8] c"cell_to_output_weights->type\00", align 1
@.str.49 = private unnamed_addr constant [37 x i8] c"peephole_weights_all_or_none == true\00", align 1
@.str.50 = private unnamed_addr constant [16 x i8] c"input_gate_bias\00", align 1
@.str.51 = private unnamed_addr constant [8 x i8] c"nullptr\00", align 1
@.str.52 = private unnamed_addr constant [28 x i8] c"input_gate_bias->dims->size\00", align 1
@.str.53 = private unnamed_addr constant [31 x i8] c"input_gate_bias->dims->data[0]\00", align 1
@.str.54 = private unnamed_addr constant [22 x i8] c"input_gate_bias->type\00", align 1
@.str.55 = private unnamed_addr constant [13 x i8] c"kTfLiteInt32\00", align 1
@.str.56 = private unnamed_addr constant [15 x i8] c"kTfLiteFloat32\00", align 1
@.str.57 = private unnamed_addr constant [29 x i8] c"forget_gate_bias->dims->size\00", align 1
@.str.58 = private unnamed_addr constant [32 x i8] c"forget_gate_bias->dims->data[0]\00", align 1
@.str.59 = private unnamed_addr constant [23 x i8] c"forget_gate_bias->type\00", align 1
@.str.60 = private unnamed_addr constant [27 x i8] c"cell_gate_bias->dims->size\00", align 1
@.str.61 = private unnamed_addr constant [30 x i8] c"cell_gate_bias->dims->data[0]\00", align 1
@.str.62 = private unnamed_addr constant [21 x i8] c"cell_gate_bias->type\00", align 1
@.str.63 = private unnamed_addr constant [29 x i8] c"output_gate_bias->dims->size\00", align 1
@.str.64 = private unnamed_addr constant [32 x i8] c"output_gate_bias->dims->data[0]\00", align 1
@.str.65 = private unnamed_addr constant [23 x i8] c"output_gate_bias->type\00", align 1
@.str.66 = private unnamed_addr constant [31 x i8] c"projection_weights->dims->size\00", align 1
@.str.67 = private unnamed_addr constant [34 x i8] c"projection_weights->dims->data[0]\00", align 1
@.str.68 = private unnamed_addr constant [34 x i8] c"projection_weights->dims->data[1]\00", align 1
@.str.69 = private unnamed_addr constant [25 x i8] c"projection_weights->type\00", align 1
@.str.70 = private unnamed_addr constant [28 x i8] c"projection_bias->dims->size\00", align 1
@.str.71 = private unnamed_addr constant [31 x i8] c"projection_bias->dims->data[0]\00", align 1
@.str.72 = private unnamed_addr constant [22 x i8] c"projection_bias->type\00", align 1
@.str.73 = private unnamed_addr constant [38 x i8] c"projection_tensors_consistent == true\00", align 1
@.str.74 = private unnamed_addr constant [30 x i8] c"input_layer_norm_coefficients\00", align 1
@.str.75 = private unnamed_addr constant [41 x i8] c"input_layer_norm_coefficients != nullptr\00", align 1
@.str.76 = private unnamed_addr constant [42 x i8] c"input_layer_norm_coefficients->dims->size\00", align 1
@.str.77 = private unnamed_addr constant [45 x i8] c"input_layer_norm_coefficients->dims->data[0]\00", align 1
@.str.78 = private unnamed_addr constant [36 x i8] c"input_layer_norm_coefficients->type\00", align 1
@.str.79 = private unnamed_addr constant [13 x i8] c"kTfLiteInt16\00", align 1
@.str.80 = private unnamed_addr constant [42 x i8] c"forget_layer_norm_coefficients != nullptr\00", align 1
@.str.81 = private unnamed_addr constant [43 x i8] c"forget_layer_norm_coefficients->dims->size\00", align 1
@.str.82 = private unnamed_addr constant [46 x i8] c"forget_layer_norm_coefficients->dims->data[0]\00", align 1
@.str.83 = private unnamed_addr constant [37 x i8] c"forget_layer_norm_coefficients->type\00", align 1
@.str.84 = private unnamed_addr constant [40 x i8] c"cell_layer_norm_coefficients != nullptr\00", align 1
@.str.85 = private unnamed_addr constant [41 x i8] c"cell_layer_norm_coefficients->dims->size\00", align 1
@.str.86 = private unnamed_addr constant [44 x i8] c"cell_layer_norm_coefficients->dims->data[0]\00", align 1
@.str.87 = private unnamed_addr constant [35 x i8] c"cell_layer_norm_coefficients->type\00", align 1
@.str.88 = private unnamed_addr constant [42 x i8] c"output_layer_norm_coefficients != nullptr\00", align 1
@.str.89 = private unnamed_addr constant [43 x i8] c"output_layer_norm_coefficients->dims->size\00", align 1
@.str.90 = private unnamed_addr constant [46 x i8] c"output_layer_norm_coefficients->dims->data[0]\00", align 1
@.str.91 = private unnamed_addr constant [37 x i8] c"output_layer_norm_coefficients->type\00", align 1
@.str.92 = private unnamed_addr constant [31 x i8] c"weight_shape.DimensionsCount()\00", align 1
@.str.93 = private unnamed_addr constant [24 x i8] c"output_state != nullptr\00", align 1
@.str.94 = private unnamed_addr constant [20 x i8] c"node->outputs->size\00", align 1
@.str.95 = private unnamed_addr constant [60 x i8] c"The LSTM Full kernel expects 20 or 24 inputs. Got %d inputs\00", align 1
@.str.96 = private unnamed_addr constant [22 x i8] c"input->dims->size > 1\00", align 1
@.str.97 = private unnamed_addr constant [36 x i8] c"input_to_output_weights->dims->size\00", align 1
@.str.98 = private unnamed_addr constant [39 x i8] c"input_to_output_weights->dims->data[1]\00", align 1
@.str.99 = private unnamed_addr constant [40 x i8] c"recurrent_to_output_weights->dims->size\00", align 1
@.str.100 = private unnamed_addr constant [43 x i8] c"recurrent_to_output_weights->dims->data[0]\00", align 1
@.str.101 = private unnamed_addr constant [22 x i8] c"cell_state != nullptr\00", align 1
@.str.102 = private unnamed_addr constant [26 x i8] c"NumElements(output_state)\00", align 1
@.str.103 = private unnamed_addr constant [19 x i8] c"n_batch * n_output\00", align 1
@.str.104 = private unnamed_addr constant [24 x i8] c"NumElements(cell_state)\00", align 1
@.str.105 = private unnamed_addr constant [17 x i8] c"n_batch * n_cell\00", align 1
@.str.106 = private unnamed_addr constant [64 x i8] c"num_intermediate_tensors == 5 || num_intermediate_tensors == 12\00", align 1
@.str.107 = private unnamed_addr constant [36 x i8] c"Type %d is not currently supported.\00", align 1
@.str.108 = private unnamed_addr constant [32 x i8] c"node->inputs->size == kInputNum\00", align 1
@.str.109 = private unnamed_addr constant [34 x i8] c"node->outputs->size == kOutputNum\00", align 1
@.str.110 = private unnamed_addr constant [18 x i8] c"input->dims->size\00", align 1
@.str.111 = private unnamed_addr constant [28 x i8] c"prev_activation->dims->size\00", align 1
@.str.112 = private unnamed_addr constant [31 x i8] c"prev_activation->dims->data[0]\00", align 1
@.str.113 = private unnamed_addr constant [12 x i8] c"num_batches\00", align 1
@.str.114 = private unnamed_addr constant [20 x i8] c"weights->dims->size\00", align 1
@.str.115 = private unnamed_addr constant [23 x i8] c"weights->dims->data[0]\00", align 1
@.str.116 = private unnamed_addr constant [21 x i8] c"4 * activation_depth\00", align 1
@.str.117 = private unnamed_addr constant [23 x i8] c"weights->dims->data[1]\00", align 1
@.str.118 = private unnamed_addr constant [12 x i8] c"total_depth\00", align 1
@.str.119 = private unnamed_addr constant [17 x i8] c"bias->dims->size\00", align 1
@.str.120 = private unnamed_addr constant [20 x i8] c"bias->dims->data[0]\00", align 1
@.str.121 = private unnamed_addr constant [23 x i8] c"prev_state->dims->size\00", align 1
@.str.122 = private unnamed_addr constant [26 x i8] c"prev_state->dims->data[0]\00", align 1
@.str.123 = private unnamed_addr constant [26 x i8] c"prev_state->dims->data[1]\00", align 1
@.str.124 = private unnamed_addr constant [17 x i8] c"activation_depth\00", align 1
@.str.125 = private unnamed_addr constant [66 x i8] c"The internal state of a LSTM cell must have a power-of-two scale.\00", align 1
@.str.126 = private unnamed_addr constant [84 x i8] c"The only case of quantized LstmCell currently supported is with StateIntegerBits==4\00", align 1
@.str.127 = private unnamed_addr constant [51 x i8] c"Unsupported combination of data types for LstmCell\00", align 1
@_ZZN6tflite3ops7builtin13Register_LSTMEvE1r = internal global { i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 } { i8* (%struct.TfLiteContext*, i8*, i64)* @_ZN6tflite3ops7builtin4lstm4InitEP13TfLiteContextPKcm, void (%struct.TfLiteContext*, i8*)* @_ZN6tflite3ops7builtin4lstm4FreeEP13TfLiteContextPv, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)* @_ZN6tflite3ops7builtin4lstm7PrepareEP13TfLiteContextP10TfLiteNode, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)* @_ZN6tflite3ops7builtin4lstm4EvalEP13TfLiteContextP10TfLiteNode, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)* null, i32 0, i8* null, i32 0 }, align 8
@.str.129 = private unnamed_addr constant [51 x i8] c"CheckedLog2(cell_state->params.scale, &cell_scale)\00", align 1
@.str.130 = private unnamed_addr constant [17 x i8] c"cell_scale <= -9\00", align 1
@.str.132 = private unnamed_addr constant [34 x i8] c"cell_state_params->scale->data[0]\00", align 1
@.str.133 = private unnamed_addr constant [12 x i8] c"1.0 / 32768\00", align 1
@__const._ZN6tflite13optimized_ops8LstmCellERKNS_14LstmCellParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_S8_S6_S8_S6_PfS6_S9_S6_S9_S6_S9_PNS_17CpuBackendContextE.fc_params = private unnamed_addr constant { i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] } { i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, i8 -86, i8 -86, i8 -86, [1 x i8] c"\AA" }, align 4
@_ZZN3ruy8PackImplILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEiiE7zerobuf = internal constant [16 x float] zeroinitializer, align 16
@__const._ZNK3ruy6KernelILNS_4PathE16EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE.params = private unnamed_addr constant %"struct.ruy::KernelParamsFloat" <{ float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, i8 -86, [3 x i8] c"\AA\AA\AA", [16 x float] [float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000], [256 x float] [float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000], [4 x i8] c"\AA\AA\AA\AA" }>, align 8
@_ZZN3ruy8PackImplILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEiiE7zerobuf = internal constant [8 x float] zeroinitializer, align 16
@__const._ZNK3ruy6KernelILNS_4PathE8EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE.params = private unnamed_addr constant %"struct.ruy::KernelParamsFloat.134" <{ float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, i8 -86, [3 x i8] c"\AA\AA\AA", [8 x float] [float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000], [64 x float] [float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000], [4 x i8] c"\AA\AA\AA\AA" }>, align 8
@_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count = linkonce_odr hidden global i32 0, comdat, align 4
@_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count = linkonce_odr hidden global i64 0, comdat, align 8
@.str.158 = private unnamed_addr constant [19 x i8] c"allocation failure\00", align 1
@stderr = external local_unnamed_addr global %struct._IO_FILE*, align 8
@.str.159 = private unnamed_addr constant [20 x i8] c"gemmlowp error: %s\0A\00", align 1
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.406"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.406"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.406"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE = linkonce_odr hidden unnamed_addr constant { [6 x i8*] } { [6 x i8*] [i8* null, i8* null, i8* bitcast (i8* (%"struct.gemmlowp::ReferenceKernel"*)* @_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEv to i8*), i8* bitcast (void (%"struct.gemmlowp::ReferenceKernel"*, i32*, i64, i64, i8*, i8*, i64, i64)* @_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE3RunEPimmPKhSB_mm to i8*), i8* bitcast (void (%"struct.gemmlowp::KernelBase"*)* @_ZN8gemmlowp10KernelBaseD2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::DefaultKernel"*)* @_ZN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEED0Ev to i8*)] }, comdat, align 8
@_ZZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEvE3buf = linkonce_odr hidden global [256 x i8] zeroinitializer, comdat, align 16
@.str.163 = private unnamed_addr constant [58 x i8] c"reference(Lhs: %d cells %dx%d %s, Rhs: %d cells %dx%d %s)\00", align 1
@.str.165 = private unnamed_addr constant [11 x i8] c"WidthMajor\00", align 1
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.463"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.463"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.463"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.506"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.506"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.506"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@llvm.global_ctors = appending global [0 x { i32, void ()*, i8* }] zeroinitializer

; Function Attrs: argmemonly nounwind
declare {}* @llvm.invariant.start.p0i8(i64 immarg, i8* nocapture) #0

; Function Attrs: nounwind ssp uwtable
define hidden nonnull i8* @_ZN6tflite3ops7builtin4lstm4full4InitEP13TfLiteContextPKcm(%struct.TfLiteContext*, i8* nocapture readnone, i64) local_unnamed_addr #1 {
  %4 = tail call i8* @_Znwm(i64 376) #17
  %5 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %4, i8 0, i64 376, i1 false)
  %6 = load i32 (%struct.TfLiteContext*, i32, i32*)*, i32 (%struct.TfLiteContext*, i32, i32*)** %5, align 8
  %7 = getelementptr inbounds i8, i8* %4, i64 8
  %8 = bitcast i8* %7 to i32*
  %9 = tail call i32 %6(%struct.TfLiteContext* %0, i32 10, i32* %8) #18
  ret i8* %4
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #0

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #0

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #0

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm4full26CheckInputTensorDimensionsEP13TfLiteContextP10TfLiteNodeiiibb(%struct.TfLiteContext*, %struct.TfLiteNode* nocapture readonly, i32, i32, i32, i1 zeroext, i1 zeroext) local_unnamed_addr #1 {
  %8 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %9 = bitcast i8** %8 to %struct.TfLiteLSTMParams**
  %10 = load %struct.TfLiteLSTMParams*, %struct.TfLiteLSTMParams** %9, align 8
  %11 = getelementptr inbounds %struct.TfLiteLSTMParams, %struct.TfLiteLSTMParams* %10, i64 0, i32 1
  %12 = load float, float* %11, align 4
  %13 = fcmp ult float %12, 0.000000e+00
  br i1 %13, label %14, label %17

14:                                               ; preds = %7
  %15 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %16 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %15, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %16(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 743, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.4, i64 0, i64 0)) #18
  br label %884

17:                                               ; preds = %7
  %18 = getelementptr inbounds %struct.TfLiteLSTMParams, %struct.TfLiteLSTMParams* %10, i64 0, i32 2
  %19 = load float, float* %18, align 4
  %20 = fcmp ult float %19, 0.000000e+00
  br i1 %20, label %21, label %24

21:                                               ; preds = %17
  %22 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %23 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %22, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %23(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 744, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.5, i64 0, i64 0)) #18
  br label %884

24:                                               ; preds = %17
  %25 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %26 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %25, align 8
  %27 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 2
  %28 = load i32, i32* %27, align 4
  %29 = icmp slt i32 %28, 0
  br i1 %29, label %35, label %30

30:                                               ; preds = %24
  %31 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %32 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %31, align 8
  %33 = sext i32 %28 to i64
  %34 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %32, i64 %33
  br label %35

35:                                               ; preds = %24, %30
  %36 = phi %struct.TfLiteTensor* [ %34, %30 ], [ null, %24 ]
  %37 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %36, i64 0, i32 2
  %38 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %37, align 8
  %39 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %38, i64 0, i32 0
  %40 = load i32, i32* %39, align 4
  %41 = icmp eq i32 %40, 2
  br i1 %41, label %45, label %42

42:                                               ; preds = %35
  %43 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %44 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %43, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %44(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 748, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.7, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %40, i32 2) #18
  br label %884

45:                                               ; preds = %35
  %46 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %38, i64 0, i32 1, i64 0
  %47 = load i32, i32* %46, align 4
  %48 = icmp eq i32 %47, %4
  br i1 %48, label %52, label %49

49:                                               ; preds = %45
  %50 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %51 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %50, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %51(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 749, i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.9, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %47, i32 %4) #18
  br label %884

52:                                               ; preds = %45
  %53 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %38, i64 0, i32 1, i64 1
  %54 = load i32, i32* %53, align 4
  %55 = icmp eq i32 %54, %2
  br i1 %55, label %59, label %56

56:                                               ; preds = %52
  %57 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %58 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %57, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %58(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 750, i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.11, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.12, i64 0, i64 0), i32 %54, i32 %2) #18
  br label %884

59:                                               ; preds = %52
  %60 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %36, i64 0, i32 0
  %61 = load i32, i32* %60, align 8
  switch i32 %61, label %62 [
    i32 1, label %65
    i32 3, label %65
    i32 9, label %65
  ]

62:                                               ; preds = %59
  %63 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %64 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %63, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %64(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 753, i8* getelementptr inbounds ([151 x i8], [151 x i8]* @.str.13, i64 0, i64 0)) #18
  br label %884

65:                                               ; preds = %59, %59, %59
  %66 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 1
  %67 = load i32, i32* %66, align 4
  %68 = icmp slt i32 %67, 0
  br i1 %68, label %108, label %69

69:                                               ; preds = %65
  %70 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %71 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %70, align 8
  %72 = sext i32 %67 to i64
  %73 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %71, i64 %72
  %74 = icmp eq %struct.TfLiteTensor* %73, null
  br i1 %74, label %108, label %75

75:                                               ; preds = %69
  %76 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %71, i64 %72, i32 2
  %77 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %76, align 8
  %78 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4
  %80 = icmp eq i32 %79, 2
  br i1 %80, label %84, label %81

81:                                               ; preds = %75
  %82 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %83 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %82, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %83(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 759, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.14, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %79, i32 2) #18
  br label %884

84:                                               ; preds = %75
  %85 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 1, i64 0
  %86 = load i32, i32* %85, align 4
  %87 = icmp eq i32 %86, %4
  br i1 %87, label %91, label %88

88:                                               ; preds = %84
  %89 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %90 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %89, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %90(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 760, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.15, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %86, i32 %4) #18
  br label %884

91:                                               ; preds = %84
  %92 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 1, i64 1
  %93 = load i32, i32* %92, align 4
  %94 = icmp eq i32 %93, %2
  br i1 %94, label %98, label %95

95:                                               ; preds = %91
  %96 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %97 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %96, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %97(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 761, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.16, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.12, i64 0, i64 0), i32 %93, i32 %2) #18
  br label %884

98:                                               ; preds = %91
  %99 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %73, i64 0, i32 0
  %100 = load i32, i32* %99, align 8
  %101 = icmp eq i32 %100, %61
  br i1 %101, label %108, label %102

102:                                              ; preds = %98
  %103 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %104 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %103, align 8
  %105 = tail call i8* @TfLiteTypeGetName(i32 %100) #18
  %106 = load i32, i32* %60, align 8
  %107 = tail call i8* @TfLiteTypeGetName(i32 %106) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %104(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 763, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.19, i64 0, i64 0), i8* %105, i8* %107) #18
  br label %884

108:                                              ; preds = %65, %98, %69
  %109 = phi i1 [ false, %98 ], [ true, %69 ], [ true, %65 ]
  %110 = phi %struct.TfLiteTensor* [ %73, %98 ], [ null, %69 ], [ null, %65 ]
  %111 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 3
  %112 = load i32, i32* %111, align 4
  %113 = icmp slt i32 %112, 0
  br i1 %113, label %119, label %114

114:                                              ; preds = %108
  %115 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %116 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %115, align 8
  %117 = sext i32 %112 to i64
  %118 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %116, i64 %117
  br label %119

119:                                              ; preds = %108, %114
  %120 = phi %struct.TfLiteTensor* [ %118, %114 ], [ null, %108 ]
  %121 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %120, i64 0, i32 2
  %122 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %121, align 8
  %123 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %122, i64 0, i32 0
  %124 = load i32, i32* %123, align 4
  %125 = icmp eq i32 %124, 2
  br i1 %125, label %129, label %126

126:                                              ; preds = %119
  %127 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %128 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %127, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %128(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 768, i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.20, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %124, i32 2) #18
  br label %884

129:                                              ; preds = %119
  %130 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %122, i64 0, i32 1, i64 0
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, %4
  br i1 %132, label %136, label %133

133:                                              ; preds = %129
  %134 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %135 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %134, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %135(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 769, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.21, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %131, i32 %4) #18
  br label %884

136:                                              ; preds = %129
  %137 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %122, i64 0, i32 1, i64 1
  %138 = load i32, i32* %137, align 4
  %139 = icmp eq i32 %138, %2
  br i1 %139, label %143, label %140

140:                                              ; preds = %136
  %141 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %142 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %141, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %142(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 770, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.22, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.12, i64 0, i64 0), i32 %138, i32 %2) #18
  br label %884

143:                                              ; preds = %136
  %144 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %120, i64 0, i32 0
  %145 = load i32, i32* %144, align 8
  %146 = icmp eq i32 %145, %61
  br i1 %146, label %153, label %147

147:                                              ; preds = %143
  %148 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %149 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %148, align 8
  %150 = tail call i8* @TfLiteTypeGetName(i32 %145) #18
  %151 = load i32, i32* %60, align 8
  %152 = tail call i8* @TfLiteTypeGetName(i32 %151) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %149(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 772, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.23, i64 0, i64 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.19, i64 0, i64 0), i8* %150, i8* %152) #18
  br label %884

153:                                              ; preds = %143
  %154 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 5
  %155 = load i32, i32* %154, align 4
  %156 = icmp slt i32 %155, 0
  br i1 %156, label %196, label %157

157:                                              ; preds = %153
  %158 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %159 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %158, align 8
  %160 = sext i32 %155 to i64
  %161 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %159, i64 %160
  %162 = icmp eq %struct.TfLiteTensor* %161, null
  br i1 %162, label %196, label %163

163:                                              ; preds = %157
  %164 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %159, i64 %160, i32 2
  %165 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %164, align 8
  %166 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %165, i64 0, i32 0
  %167 = load i32, i32* %166, align 4
  %168 = icmp eq i32 %167, 2
  br i1 %168, label %172, label %169

169:                                              ; preds = %163
  %170 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %171 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %170, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %171(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 777, i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.24, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %167, i32 2) #18
  br label %884

172:                                              ; preds = %163
  %173 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %165, i64 0, i32 1, i64 0
  %174 = load i32, i32* %173, align 4
  %175 = icmp eq i32 %174, %4
  br i1 %175, label %179, label %176

176:                                              ; preds = %172
  %177 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %178 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %177, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %178(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 779, i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.25, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %174, i32 %4) #18
  br label %884

179:                                              ; preds = %172
  %180 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %165, i64 0, i32 1, i64 1
  %181 = load i32, i32* %180, align 4
  %182 = icmp eq i32 %181, %3
  br i1 %182, label %186, label %183

183:                                              ; preds = %179
  %184 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %185 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %184, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %185(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 781, i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.26, i64 0, i64 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.27, i64 0, i64 0), i32 %181, i32 %3) #18
  br label %884

186:                                              ; preds = %179
  %187 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %161, i64 0, i32 0
  %188 = load i32, i32* %187, align 8
  %189 = icmp eq i32 %188, %61
  br i1 %189, label %196, label %190

190:                                              ; preds = %186
  %191 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %192 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %191, align 8
  %193 = tail call i8* @TfLiteTypeGetName(i32 %188) #18
  %194 = load i32, i32* %60, align 8
  %195 = tail call i8* @TfLiteTypeGetName(i32 %194) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %192(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 783, i8* getelementptr inbounds ([33 x i8], [33 x i8]* @.str.28, i64 0, i64 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.19, i64 0, i64 0), i8* %193, i8* %195) #18
  br label %884

196:                                              ; preds = %157, %153, %186
  %197 = phi i1 [ true, %186 ], [ false, %157 ], [ false, %153 ]
  %198 = phi %struct.TfLiteTensor* [ %161, %186 ], [ null, %157 ], [ null, %153 ]
  %199 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 6
  %200 = load i32, i32* %199, align 4
  %201 = icmp slt i32 %200, 0
  br i1 %201, label %207, label %202

202:                                              ; preds = %196
  %203 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %204 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %203, align 8
  %205 = sext i32 %200 to i64
  %206 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %204, i64 %205
  br label %207

207:                                              ; preds = %196, %202
  %208 = phi %struct.TfLiteTensor* [ %206, %202 ], [ null, %196 ]
  %209 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %208, i64 0, i32 2
  %210 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %209, align 8
  %211 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %210, i64 0, i32 0
  %212 = load i32, i32* %211, align 4
  %213 = icmp eq i32 %212, 2
  br i1 %213, label %217, label %214

214:                                              ; preds = %207
  %215 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %216 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %215, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %216(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 788, i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.29, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %212, i32 2) #18
  br label %884

217:                                              ; preds = %207
  %218 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %210, i64 0, i32 1, i64 0
  %219 = load i32, i32* %218, align 4
  %220 = icmp eq i32 %219, %4
  br i1 %220, label %224, label %221

221:                                              ; preds = %217
  %222 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %223 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %222, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %223(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 790, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.30, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %219, i32 %4) #18
  br label %884

224:                                              ; preds = %217
  %225 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %210, i64 0, i32 1, i64 1
  %226 = load i32, i32* %225, align 4
  %227 = icmp eq i32 %226, %3
  br i1 %227, label %231, label %228

228:                                              ; preds = %224
  %229 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %230 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %229, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %230(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 792, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.31, i64 0, i64 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.27, i64 0, i64 0), i32 %226, i32 %3) #18
  br label %884

231:                                              ; preds = %224
  %232 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %208, i64 0, i32 0
  %233 = load i32, i32* %232, align 8
  %234 = icmp eq i32 %233, %61
  br i1 %234, label %241, label %235

235:                                              ; preds = %231
  %236 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %237 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %236, align 8
  %238 = tail call i8* @TfLiteTypeGetName(i32 %233) #18
  %239 = load i32, i32* %60, align 8
  %240 = tail call i8* @TfLiteTypeGetName(i32 %239) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %237(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 794, i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.32, i64 0, i64 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.19, i64 0, i64 0), i8* %238, i8* %240) #18
  br label %884

241:                                              ; preds = %231
  %242 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 7
  %243 = load i32, i32* %242, align 4
  %244 = icmp slt i32 %243, 0
  br i1 %244, label %250, label %245

245:                                              ; preds = %241
  %246 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %247 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %246, align 8
  %248 = sext i32 %243 to i64
  %249 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %247, i64 %248
  br label %250

250:                                              ; preds = %241, %245
  %251 = phi %struct.TfLiteTensor* [ %249, %245 ], [ null, %241 ]
  %252 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %251, i64 0, i32 2
  %253 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %252, align 8
  %254 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %253, i64 0, i32 0
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %255, 2
  br i1 %256, label %260, label %257

257:                                              ; preds = %250
  %258 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %259 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %258, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %259(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 798, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.33, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %255, i32 2) #18
  br label %884

260:                                              ; preds = %250
  %261 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %253, i64 0, i32 1, i64 0
  %262 = load i32, i32* %261, align 4
  %263 = icmp eq i32 %262, %4
  br i1 %263, label %267, label %264

264:                                              ; preds = %260
  %265 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %266 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %265, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %266(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 799, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.34, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %262, i32 %4) #18
  br label %884

267:                                              ; preds = %260
  %268 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %253, i64 0, i32 1, i64 1
  %269 = load i32, i32* %268, align 4
  %270 = icmp eq i32 %269, %3
  br i1 %270, label %274, label %271

271:                                              ; preds = %267
  %272 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %273 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %272, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %273(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 801, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.35, i64 0, i64 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.27, i64 0, i64 0), i32 %269, i32 %3) #18
  br label %884

274:                                              ; preds = %267
  %275 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %251, i64 0, i32 0
  %276 = load i32, i32* %275, align 8
  %277 = icmp eq i32 %276, %61
  br i1 %277, label %284, label %278

278:                                              ; preds = %274
  %279 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %280 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %279, align 8
  %281 = tail call i8* @TfLiteTypeGetName(i32 %276) #18
  %282 = load i32, i32* %60, align 8
  %283 = tail call i8* @TfLiteTypeGetName(i32 %282) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %280(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 803, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.36, i64 0, i64 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.19, i64 0, i64 0), i8* %281, i8* %283) #18
  br label %884

284:                                              ; preds = %274
  %285 = icmp ne %struct.TfLiteTensor* %110, null
  %286 = and i1 %285, %197
  %287 = icmp eq %struct.TfLiteTensor* %198, null
  %288 = and i1 %109, %287
  %289 = or i1 %286, %288
  br i1 %289, label %293, label %290

290:                                              ; preds = %284
  %291 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %292 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %291, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %292(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 812, i8* getelementptr inbounds ([33 x i8], [33 x i8]* @.str.37, i64 0, i64 0)) #18
  br label %884

293:                                              ; preds = %284
  %294 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 9
  %295 = load i32, i32* %294, align 4
  %296 = icmp slt i32 %295, 0
  br i1 %296, label %333, label %297

297:                                              ; preds = %293
  %298 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %299 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %298, align 8
  %300 = sext i32 %295 to i64
  %301 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %299, i64 %300
  %302 = icmp eq %struct.TfLiteTensor* %301, null
  br i1 %302, label %333, label %303

303:                                              ; preds = %297
  %304 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %299, i64 %300, i32 2
  %305 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %304, align 8
  %306 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %305, i64 0, i32 0
  %307 = load i32, i32* %306, align 4
  %308 = icmp eq i32 %307, 1
  br i1 %308, label %312, label %309

309:                                              ; preds = %303
  %310 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %311 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %310, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %311(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 817, i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.38, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %307, i32 1) #18
  br label %884

312:                                              ; preds = %303
  %313 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %305, i64 0, i32 1, i64 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, %4
  br i1 %315, label %319, label %316

316:                                              ; preds = %312
  %317 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %318 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %317, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %318(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 818, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.40, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %314, i32 %4) #18
  br label %884

319:                                              ; preds = %312
  %320 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %301, i64 0, i32 0
  %321 = load i32, i32* %320, align 8
  %322 = select i1 %6, i32 7, i32 %61
  %323 = icmp eq i32 %321, %322
  br i1 %323, label %333, label %324

324:                                              ; preds = %319
  %325 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %326 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %325, align 8
  %327 = tail call i8* @TfLiteTypeGetName(i32 %321) #18
  br i1 %6, label %330, label %328

328:                                              ; preds = %324
  %329 = load i32, i32* %60, align 8
  br label %330

330:                                              ; preds = %324, %328
  %331 = phi i32 [ %329, %328 ], [ 7, %324 ]
  %332 = tail call i8* @TfLiteTypeGetName(i32 %331) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %326(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 821, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.41, i64 0, i64 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.42, i64 0, i64 0), i8* %327, i8* %332) #18
  br label %884

333:                                              ; preds = %297, %293, %319
  %334 = phi i1 [ true, %319 ], [ false, %297 ], [ false, %293 ]
  %335 = phi %struct.TfLiteTensor* [ %301, %319 ], [ null, %297 ], [ null, %293 ]
  %336 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 10
  %337 = load i32, i32* %336, align 4
  %338 = icmp slt i32 %337, 0
  br i1 %338, label %375, label %339

339:                                              ; preds = %333
  %340 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %341 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %340, align 8
  %342 = sext i32 %337 to i64
  %343 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %341, i64 %342
  %344 = icmp eq %struct.TfLiteTensor* %343, null
  br i1 %344, label %375, label %345

345:                                              ; preds = %339
  %346 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %341, i64 %342, i32 2
  %347 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %346, align 8
  %348 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %347, i64 0, i32 0
  %349 = load i32, i32* %348, align 4
  %350 = icmp eq i32 %349, 1
  br i1 %350, label %354, label %351

351:                                              ; preds = %345
  %352 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %353 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %352, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %353(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 827, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.43, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %349, i32 1) #18
  br label %884

354:                                              ; preds = %345
  %355 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %347, i64 0, i32 1, i64 0
  %356 = load i32, i32* %355, align 4
  %357 = icmp eq i32 %356, %4
  br i1 %357, label %361, label %358

358:                                              ; preds = %354
  %359 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %360 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %359, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %360(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 828, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.44, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %356, i32 %4) #18
  br label %884

361:                                              ; preds = %354
  %362 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %343, i64 0, i32 0
  %363 = load i32, i32* %362, align 8
  %364 = select i1 %6, i32 7, i32 %61
  %365 = icmp eq i32 %363, %364
  br i1 %365, label %375, label %366

366:                                              ; preds = %361
  %367 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %368 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %367, align 8
  %369 = tail call i8* @TfLiteTypeGetName(i32 %363) #18
  br i1 %6, label %372, label %370

370:                                              ; preds = %366
  %371 = load i32, i32* %60, align 8
  br label %372

372:                                              ; preds = %366, %370
  %373 = phi i32 [ %371, %370 ], [ 7, %366 ]
  %374 = tail call i8* @TfLiteTypeGetName(i32 %373) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %368(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 831, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.45, i64 0, i64 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.42, i64 0, i64 0), i8* %369, i8* %374) #18
  br label %884

375:                                              ; preds = %339, %333, %361
  %376 = phi i1 [ true, %361 ], [ false, %339 ], [ false, %333 ]
  %377 = phi %struct.TfLiteTensor* [ %343, %361 ], [ null, %339 ], [ null, %333 ]
  %378 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 11
  %379 = load i32, i32* %378, align 4
  %380 = icmp slt i32 %379, 0
  br i1 %380, label %420, label %381

381:                                              ; preds = %375
  %382 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %383 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %382, align 8
  %384 = sext i32 %379 to i64
  %385 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %383, i64 %384
  %386 = icmp eq %struct.TfLiteTensor* %385, null
  br i1 %386, label %420, label %387

387:                                              ; preds = %381
  %388 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %383, i64 %384, i32 2
  %389 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %388, align 8
  %390 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %389, i64 0, i32 0
  %391 = load i32, i32* %390, align 4
  %392 = icmp eq i32 %391, 1
  br i1 %392, label %396, label %393

393:                                              ; preds = %387
  %394 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %395 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %394, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %395(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 837, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.46, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %391, i32 1) #18
  br label %884

396:                                              ; preds = %387
  %397 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %389, i64 0, i32 1, i64 0
  %398 = load i32, i32* %397, align 4
  %399 = icmp eq i32 %398, %4
  br i1 %399, label %403, label %400

400:                                              ; preds = %396
  %401 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %402 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %401, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %402(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 838, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.47, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %398, i32 %4) #18
  br label %884

403:                                              ; preds = %396
  %404 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %385, i64 0, i32 0
  %405 = load i32, i32* %404, align 8
  %406 = select i1 %6, i32 7, i32 %61
  %407 = icmp eq i32 %405, %406
  br i1 %407, label %417, label %408

408:                                              ; preds = %403
  %409 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %410 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %409, align 8
  %411 = tail call i8* @TfLiteTypeGetName(i32 %405) #18
  br i1 %6, label %414, label %412

412:                                              ; preds = %408
  %413 = load i32, i32* %60, align 8
  br label %414

414:                                              ; preds = %408, %412
  %415 = phi i32 [ %413, %412 ], [ 7, %408 ]
  %416 = tail call i8* @TfLiteTypeGetName(i32 %415) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %410(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 841, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.48, i64 0, i64 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.42, i64 0, i64 0), i8* %411, i8* %416) #18
  br label %884

417:                                              ; preds = %403
  %418 = or i1 %109, %334
  %419 = and i1 %418, %376
  br i1 %419, label %427, label %424

420:                                              ; preds = %381, %375
  %421 = icmp eq %struct.TfLiteTensor* %335, null
  %422 = icmp eq %struct.TfLiteTensor* %377, null
  %423 = and i1 %421, %422
  br i1 %423, label %427, label %424

424:                                              ; preds = %417, %420
  %425 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %426 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %425, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %426(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 852, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.49, i64 0, i64 0)) #18
  br label %884

427:                                              ; preds = %417, %420
  %428 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 12
  %429 = load i32, i32* %428, align 4
  %430 = icmp slt i32 %429, 0
  br i1 %430, label %436, label %431

431:                                              ; preds = %427
  %432 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %433 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %432, align 8
  %434 = sext i32 %429 to i64
  %435 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %433, i64 %434
  br label %436

436:                                              ; preds = %427, %431
  %437 = phi %struct.TfLiteTensor* [ %435, %431 ], [ null, %427 ]
  br i1 %109, label %438, label %443

438:                                              ; preds = %436
  %439 = icmp eq %struct.TfLiteTensor* %437, null
  br i1 %439, label %476, label %440

440:                                              ; preds = %438
  %441 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %442 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %441, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %442(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 858, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.50, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.51, i64 0, i64 0), %struct.TfLiteTensor* nonnull %437, i8* null) #18
  br label %884

443:                                              ; preds = %436
  %444 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %437, i64 0, i32 2
  %445 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %444, align 8
  %446 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %445, i64 0, i32 0
  %447 = load i32, i32* %446, align 4
  %448 = icmp eq i32 %447, 1
  br i1 %448, label %452, label %449

449:                                              ; preds = %443
  %450 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %451 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %450, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %451(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 860, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.52, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %447, i32 1) #18
  br label %884

452:                                              ; preds = %443
  %453 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %445, i64 0, i32 1, i64 0
  %454 = load i32, i32* %453, align 4
  %455 = icmp eq i32 %454, %4
  br i1 %455, label %459, label %456

456:                                              ; preds = %452
  %457 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %458 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %457, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %458(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 861, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.53, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %454, i32 %4) #18
  br label %884

459:                                              ; preds = %452
  %460 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %437, i64 0, i32 0
  %461 = load i32, i32* %460, align 8
  br i1 %6, label %462, label %469

462:                                              ; preds = %459
  %463 = icmp eq i32 %461, 2
  br i1 %463, label %476, label %464

464:                                              ; preds = %462
  %465 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %466 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %465, align 8
  %467 = tail call i8* @TfLiteTypeGetName(i32 %461) #18
  %468 = tail call i8* @TfLiteTypeGetName(i32 2) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %466(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 863, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.54, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.55, i64 0, i64 0), i8* %467, i8* %468) #18
  br label %884

469:                                              ; preds = %459
  %470 = icmp eq i32 %461, 1
  br i1 %470, label %476, label %471

471:                                              ; preds = %469
  %472 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %473 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %472, align 8
  %474 = tail call i8* @TfLiteTypeGetName(i32 %461) #18
  %475 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %473(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 865, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.54, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %474, i8* %475) #18
  br label %884

476:                                              ; preds = %438, %462, %469
  %477 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 13
  %478 = load i32, i32* %477, align 4
  %479 = icmp slt i32 %478, 0
  br i1 %479, label %485, label %480

480:                                              ; preds = %476
  %481 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %482 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %481, align 8
  %483 = sext i32 %478 to i64
  %484 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %482, i64 %483
  br label %485

485:                                              ; preds = %476, %480
  %486 = phi %struct.TfLiteTensor* [ %484, %480 ], [ null, %476 ]
  %487 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %486, i64 0, i32 2
  %488 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %487, align 8
  %489 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %488, i64 0, i32 0
  %490 = load i32, i32* %489, align 4
  %491 = icmp eq i32 %490, 1
  br i1 %491, label %495, label %492

492:                                              ; preds = %485
  %493 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %494 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %493, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %494(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 871, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.57, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %490, i32 1) #18
  br label %884

495:                                              ; preds = %485
  %496 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %488, i64 0, i32 1, i64 0
  %497 = load i32, i32* %496, align 4
  %498 = icmp eq i32 %497, %4
  br i1 %498, label %502, label %499

499:                                              ; preds = %495
  %500 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %501 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %500, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %501(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 872, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.58, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %497, i32 %4) #18
  br label %884

502:                                              ; preds = %495
  %503 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %486, i64 0, i32 0
  %504 = load i32, i32* %503, align 8
  br i1 %6, label %505, label %512

505:                                              ; preds = %502
  %506 = icmp eq i32 %504, 2
  br i1 %506, label %519, label %507

507:                                              ; preds = %505
  %508 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %509 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %508, align 8
  %510 = tail call i8* @TfLiteTypeGetName(i32 %504) #18
  %511 = tail call i8* @TfLiteTypeGetName(i32 2) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %509(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 874, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.59, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.55, i64 0, i64 0), i8* %510, i8* %511) #18
  br label %884

512:                                              ; preds = %502
  %513 = icmp eq i32 %504, 1
  br i1 %513, label %519, label %514

514:                                              ; preds = %512
  %515 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %516 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %515, align 8
  %517 = tail call i8* @TfLiteTypeGetName(i32 %504) #18
  %518 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %516(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 876, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.59, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %517, i8* %518) #18
  br label %884

519:                                              ; preds = %505, %512
  %520 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 14
  %521 = load i32, i32* %520, align 4
  %522 = icmp slt i32 %521, 0
  br i1 %522, label %528, label %523

523:                                              ; preds = %519
  %524 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %525 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %524, align 8
  %526 = sext i32 %521 to i64
  %527 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %525, i64 %526
  br label %528

528:                                              ; preds = %519, %523
  %529 = phi %struct.TfLiteTensor* [ %527, %523 ], [ null, %519 ]
  %530 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %529, i64 0, i32 2
  %531 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %530, align 8
  %532 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %531, i64 0, i32 0
  %533 = load i32, i32* %532, align 4
  %534 = icmp eq i32 %533, 1
  br i1 %534, label %538, label %535

535:                                              ; preds = %528
  %536 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %537 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %536, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %537(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 881, i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.60, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %533, i32 1) #18
  br label %884

538:                                              ; preds = %528
  %539 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %531, i64 0, i32 1, i64 0
  %540 = load i32, i32* %539, align 4
  %541 = icmp eq i32 %540, %4
  br i1 %541, label %545, label %542

542:                                              ; preds = %538
  %543 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %544 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %543, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %544(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 882, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.61, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %540, i32 %4) #18
  br label %884

545:                                              ; preds = %538
  %546 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %529, i64 0, i32 0
  %547 = load i32, i32* %546, align 8
  br i1 %6, label %548, label %555

548:                                              ; preds = %545
  %549 = icmp eq i32 %547, 2
  br i1 %549, label %562, label %550

550:                                              ; preds = %548
  %551 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %552 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %551, align 8
  %553 = tail call i8* @TfLiteTypeGetName(i32 %547) #18
  %554 = tail call i8* @TfLiteTypeGetName(i32 2) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %552(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 884, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.62, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.55, i64 0, i64 0), i8* %553, i8* %554) #18
  br label %884

555:                                              ; preds = %545
  %556 = icmp eq i32 %547, 1
  br i1 %556, label %562, label %557

557:                                              ; preds = %555
  %558 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %559 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %558, align 8
  %560 = tail call i8* @TfLiteTypeGetName(i32 %547) #18
  %561 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %559(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 886, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.62, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %560, i8* %561) #18
  br label %884

562:                                              ; preds = %548, %555
  %563 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 15
  %564 = load i32, i32* %563, align 4
  %565 = icmp slt i32 %564, 0
  br i1 %565, label %571, label %566

566:                                              ; preds = %562
  %567 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %568 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %567, align 8
  %569 = sext i32 %564 to i64
  %570 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %568, i64 %569
  br label %571

571:                                              ; preds = %562, %566
  %572 = phi %struct.TfLiteTensor* [ %570, %566 ], [ null, %562 ]
  %573 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %572, i64 0, i32 2
  %574 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %573, align 8
  %575 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %574, i64 0, i32 0
  %576 = load i32, i32* %575, align 4
  %577 = icmp eq i32 %576, 1
  br i1 %577, label %581, label %578

578:                                              ; preds = %571
  %579 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %580 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %579, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %580(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 891, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.63, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %576, i32 1) #18
  br label %884

581:                                              ; preds = %571
  %582 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %574, i64 0, i32 1, i64 0
  %583 = load i32, i32* %582, align 4
  %584 = icmp eq i32 %583, %4
  br i1 %584, label %588, label %585

585:                                              ; preds = %581
  %586 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %587 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %586, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %587(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 892, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.64, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %583, i32 %4) #18
  br label %884

588:                                              ; preds = %581
  %589 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %572, i64 0, i32 0
  %590 = load i32, i32* %589, align 8
  br i1 %6, label %591, label %598

591:                                              ; preds = %588
  %592 = icmp eq i32 %590, 2
  br i1 %592, label %605, label %593

593:                                              ; preds = %591
  %594 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %595 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %594, align 8
  %596 = tail call i8* @TfLiteTypeGetName(i32 %590) #18
  %597 = tail call i8* @TfLiteTypeGetName(i32 2) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %595(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 894, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.65, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.55, i64 0, i64 0), i8* %596, i8* %597) #18
  br label %884

598:                                              ; preds = %588
  %599 = icmp eq i32 %590, 1
  br i1 %599, label %605, label %600

600:                                              ; preds = %598
  %601 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %602 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %601, align 8
  %603 = tail call i8* @TfLiteTypeGetName(i32 %590) #18
  %604 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %602(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 896, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.65, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %603, i8* %604) #18
  br label %884

605:                                              ; preds = %591, %598
  %606 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 16
  %607 = load i32, i32* %606, align 4
  %608 = icmp slt i32 %607, 0
  br i1 %608, label %648, label %609

609:                                              ; preds = %605
  %610 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %611 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %610, align 8
  %612 = sext i32 %607 to i64
  %613 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %611, i64 %612
  %614 = icmp eq %struct.TfLiteTensor* %613, null
  br i1 %614, label %648, label %615

615:                                              ; preds = %609
  %616 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %611, i64 %612, i32 2
  %617 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %616, align 8
  %618 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %617, i64 0, i32 0
  %619 = load i32, i32* %618, align 4
  %620 = icmp eq i32 %619, 2
  br i1 %620, label %624, label %621

621:                                              ; preds = %615
  %622 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %623 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %622, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %623(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 902, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.66, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %619, i32 2) #18
  br label %884

624:                                              ; preds = %615
  %625 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %617, i64 0, i32 1, i64 0
  %626 = load i32, i32* %625, align 4
  %627 = icmp eq i32 %626, %3
  br i1 %627, label %631, label %628

628:                                              ; preds = %624
  %629 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %630 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %629, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %630(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 903, i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.67, i64 0, i64 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.27, i64 0, i64 0), i32 %626, i32 %3) #18
  br label %884

631:                                              ; preds = %624
  %632 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %617, i64 0, i32 1, i64 1
  %633 = load i32, i32* %632, align 4
  %634 = icmp eq i32 %633, %4
  br i1 %634, label %638, label %635

635:                                              ; preds = %631
  %636 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %637 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %636, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %637(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 904, i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.68, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %633, i32 %4) #18
  br label %884

638:                                              ; preds = %631
  %639 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %613, i64 0, i32 0
  %640 = load i32, i32* %639, align 8
  %641 = icmp eq i32 %640, %61
  br i1 %641, label %648, label %642

642:                                              ; preds = %638
  %643 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %644 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %643, align 8
  %645 = tail call i8* @TfLiteTypeGetName(i32 %640) #18
  %646 = load i32, i32* %60, align 8
  %647 = tail call i8* @TfLiteTypeGetName(i32 %646) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %644(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 906, i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.69, i64 0, i64 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.19, i64 0, i64 0), i8* %645, i8* %647) #18
  br label %884

648:                                              ; preds = %609, %605, %638
  %649 = phi i1 [ true, %638 ], [ false, %609 ], [ false, %605 ]
  %650 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 17
  %651 = load i32, i32* %650, align 4
  %652 = icmp slt i32 %651, 0
  br i1 %652, label %696, label %653

653:                                              ; preds = %648
  %654 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %655 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %654, align 8
  %656 = sext i32 %651 to i64
  %657 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %655, i64 %656
  %658 = icmp eq %struct.TfLiteTensor* %657, null
  br i1 %658, label %696, label %659

659:                                              ; preds = %653
  %660 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %655, i64 %656, i32 2
  %661 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %660, align 8
  %662 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %661, i64 0, i32 0
  %663 = load i32, i32* %662, align 4
  %664 = icmp eq i32 %663, 1
  br i1 %664, label %668, label %665

665:                                              ; preds = %659
  %666 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %667 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %666, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %667(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 912, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.70, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %663, i32 1) #18
  br label %884

668:                                              ; preds = %659
  %669 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %661, i64 0, i32 1, i64 0
  %670 = load i32, i32* %669, align 4
  %671 = icmp eq i32 %670, %3
  br i1 %671, label %675, label %672

672:                                              ; preds = %668
  %673 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %674 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %673, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %674(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 913, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.71, i64 0, i64 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.27, i64 0, i64 0), i32 %670, i32 %3) #18
  br label %884

675:                                              ; preds = %668
  %676 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %657, i64 0, i32 0
  %677 = load i32, i32* %676, align 8
  br i1 %6, label %678, label %685

678:                                              ; preds = %675
  %679 = icmp eq i32 %677, 2
  br i1 %679, label %692, label %680

680:                                              ; preds = %678
  %681 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %682 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %681, align 8
  %683 = tail call i8* @TfLiteTypeGetName(i32 %677) #18
  %684 = tail call i8* @TfLiteTypeGetName(i32 2) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %682(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 915, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.72, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.55, i64 0, i64 0), i8* %683, i8* %684) #18
  br label %884

685:                                              ; preds = %675
  %686 = icmp eq i32 %677, 1
  br i1 %686, label %692, label %687

687:                                              ; preds = %685
  %688 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %689 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %688, align 8
  %690 = tail call i8* @TfLiteTypeGetName(i32 %677) #18
  %691 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %689(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 917, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.72, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %690, i8* %691) #18
  br label %884

692:                                              ; preds = %678, %685
  br i1 %649, label %696, label %693

693:                                              ; preds = %692
  %694 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %695 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %694, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %695(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 928, i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.73, i64 0, i64 0)) #18
  br label %884

696:                                              ; preds = %648, %653, %692
  br i1 %5, label %697, label %884

697:                                              ; preds = %696
  %698 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 20
  %699 = load i32, i32* %698, align 4
  %700 = icmp slt i32 %699, 0
  br i1 %700, label %706, label %701

701:                                              ; preds = %697
  %702 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %703 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %702, align 8
  %704 = sext i32 %699 to i64
  %705 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %703, i64 %704
  br label %706

706:                                              ; preds = %697, %701
  %707 = phi %struct.TfLiteTensor* [ %705, %701 ], [ null, %697 ]
  %708 = icmp ne %struct.TfLiteTensor* %707, null
  br i1 %109, label %709, label %713

709:                                              ; preds = %706
  br i1 %708, label %710, label %750

710:                                              ; preds = %709
  %711 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %712 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %711, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %712(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 934, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.74, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.51, i64 0, i64 0), %struct.TfLiteTensor* nonnull %707, i8* null) #18
  br label %884

713:                                              ; preds = %706
  br i1 %708, label %717, label %714

714:                                              ; preds = %713
  %715 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %716 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %715, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %716(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 936, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.75, i64 0, i64 0)) #18
  br label %884

717:                                              ; preds = %713
  %718 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %707, i64 0, i32 2
  %719 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %718, align 8
  %720 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %719, i64 0, i32 0
  %721 = load i32, i32* %720, align 4
  %722 = icmp eq i32 %721, 1
  br i1 %722, label %726, label %723

723:                                              ; preds = %717
  %724 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %725 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %724, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %725(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 937, i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.76, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %721, i32 1) #18
  br label %884

726:                                              ; preds = %717
  %727 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %719, i64 0, i32 1, i64 0
  %728 = load i32, i32* %727, align 4
  %729 = icmp eq i32 %728, %4
  br i1 %729, label %733, label %730

730:                                              ; preds = %726
  %731 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %732 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %731, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %732(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 939, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.77, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %728, i32 %4) #18
  br label %884

733:                                              ; preds = %726
  %734 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %707, i64 0, i32 0
  %735 = load i32, i32* %734, align 8
  br i1 %6, label %736, label %743

736:                                              ; preds = %733
  %737 = icmp eq i32 %735, 7
  br i1 %737, label %750, label %738

738:                                              ; preds = %736
  %739 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %740 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %739, align 8
  %741 = tail call i8* @TfLiteTypeGetName(i32 %735) #18
  %742 = tail call i8* @TfLiteTypeGetName(i32 7) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %740(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 942, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.78, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.79, i64 0, i64 0), i8* %741, i8* %742) #18
  br label %884

743:                                              ; preds = %733
  %744 = icmp eq i32 %735, 1
  br i1 %744, label %750, label %745

745:                                              ; preds = %743
  %746 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %747 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %746, align 8
  %748 = tail call i8* @TfLiteTypeGetName(i32 %735) #18
  %749 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %747(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 945, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.78, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %748, i8* %749) #18
  br label %884

750:                                              ; preds = %736, %743, %709
  %751 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 21
  %752 = load i32, i32* %751, align 4
  %753 = icmp slt i32 %752, 0
  br i1 %753, label %760, label %754

754:                                              ; preds = %750
  %755 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %756 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %755, align 8
  %757 = sext i32 %752 to i64
  %758 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %756, i64 %757
  %759 = icmp eq %struct.TfLiteTensor* %758, null
  br i1 %759, label %760, label %763

760:                                              ; preds = %750, %754
  %761 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %762 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %761, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %762(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 951, i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.80, i64 0, i64 0)) #18
  br label %884

763:                                              ; preds = %754
  %764 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %756, i64 %757, i32 2
  %765 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %764, align 8
  %766 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %765, i64 0, i32 0
  %767 = load i32, i32* %766, align 4
  %768 = icmp eq i32 %767, 1
  br i1 %768, label %772, label %769

769:                                              ; preds = %763
  %770 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %771 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %770, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %771(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 952, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.81, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %767, i32 1) #18
  br label %884

772:                                              ; preds = %763
  %773 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %765, i64 0, i32 1, i64 0
  %774 = load i32, i32* %773, align 4
  %775 = icmp eq i32 %774, %4
  br i1 %775, label %779, label %776

776:                                              ; preds = %772
  %777 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %778 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %777, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %778(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 954, i8* getelementptr inbounds ([46 x i8], [46 x i8]* @.str.82, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %774, i32 %4) #18
  br label %884

779:                                              ; preds = %772
  %780 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %758, i64 0, i32 0
  %781 = load i32, i32* %780, align 8
  br i1 %6, label %782, label %789

782:                                              ; preds = %779
  %783 = icmp eq i32 %781, 7
  br i1 %783, label %796, label %784

784:                                              ; preds = %782
  %785 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %786 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %785, align 8
  %787 = tail call i8* @TfLiteTypeGetName(i32 %781) #18
  %788 = tail call i8* @TfLiteTypeGetName(i32 7) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %786(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 957, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.83, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.79, i64 0, i64 0), i8* %787, i8* %788) #18
  br label %884

789:                                              ; preds = %779
  %790 = icmp eq i32 %781, 1
  br i1 %790, label %796, label %791

791:                                              ; preds = %789
  %792 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %793 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %792, align 8
  %794 = tail call i8* @TfLiteTypeGetName(i32 %781) #18
  %795 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %793(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 960, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.83, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %794, i8* %795) #18
  br label %884

796:                                              ; preds = %782, %789
  %797 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 22
  %798 = load i32, i32* %797, align 4
  %799 = icmp slt i32 %798, 0
  br i1 %799, label %804, label %800

800:                                              ; preds = %796
  %801 = sext i32 %798 to i64
  %802 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %756, i64 %801
  %803 = icmp eq %struct.TfLiteTensor* %802, null
  br i1 %803, label %804, label %807

804:                                              ; preds = %796, %800
  %805 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %806 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %805, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %806(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 965, i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.84, i64 0, i64 0)) #18
  br label %884

807:                                              ; preds = %800
  %808 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %756, i64 %801, i32 2
  %809 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %808, align 8
  %810 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %809, i64 0, i32 0
  %811 = load i32, i32* %810, align 4
  %812 = icmp eq i32 %811, 1
  br i1 %812, label %816, label %813

813:                                              ; preds = %807
  %814 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %815 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %814, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %815(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 966, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.85, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %811, i32 1) #18
  br label %884

816:                                              ; preds = %807
  %817 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %809, i64 0, i32 1, i64 0
  %818 = load i32, i32* %817, align 4
  %819 = icmp eq i32 %818, %4
  br i1 %819, label %823, label %820

820:                                              ; preds = %816
  %821 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %822 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %821, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %822(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 968, i8* getelementptr inbounds ([44 x i8], [44 x i8]* @.str.86, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %818, i32 %4) #18
  br label %884

823:                                              ; preds = %816
  %824 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %802, i64 0, i32 0
  %825 = load i32, i32* %824, align 8
  br i1 %6, label %826, label %833

826:                                              ; preds = %823
  %827 = icmp eq i32 %825, 7
  br i1 %827, label %840, label %828

828:                                              ; preds = %826
  %829 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %830 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %829, align 8
  %831 = tail call i8* @TfLiteTypeGetName(i32 %825) #18
  %832 = tail call i8* @TfLiteTypeGetName(i32 7) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %830(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 971, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.87, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.79, i64 0, i64 0), i8* %831, i8* %832) #18
  br label %884

833:                                              ; preds = %823
  %834 = icmp eq i32 %825, 1
  br i1 %834, label %840, label %835

835:                                              ; preds = %833
  %836 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %837 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %836, align 8
  %838 = tail call i8* @TfLiteTypeGetName(i32 %825) #18
  %839 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %837(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 974, i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.87, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %838, i8* %839) #18
  br label %884

840:                                              ; preds = %826, %833
  %841 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %26, i64 0, i32 1, i64 23
  %842 = load i32, i32* %841, align 4
  %843 = icmp slt i32 %842, 0
  br i1 %843, label %848, label %844

844:                                              ; preds = %840
  %845 = sext i32 %842 to i64
  %846 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %756, i64 %845
  %847 = icmp eq %struct.TfLiteTensor* %846, null
  br i1 %847, label %848, label %851

848:                                              ; preds = %840, %844
  %849 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %850 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %849, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %850(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 979, i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.88, i64 0, i64 0)) #18
  br label %884

851:                                              ; preds = %844
  %852 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %756, i64 %845, i32 2
  %853 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %852, align 8
  %854 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %853, i64 0, i32 0
  %855 = load i32, i32* %854, align 4
  %856 = icmp eq i32 %855, 1
  br i1 %856, label %860, label %857

857:                                              ; preds = %851
  %858 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %859 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %858, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %859(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 980, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.89, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %855, i32 1) #18
  br label %884

860:                                              ; preds = %851
  %861 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %853, i64 0, i32 1, i64 0
  %862 = load i32, i32* %861, align 4
  %863 = icmp eq i32 %862, %4
  br i1 %863, label %867, label %864

864:                                              ; preds = %860
  %865 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %866 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %865, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %866(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 982, i8* getelementptr inbounds ([46 x i8], [46 x i8]* @.str.90, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %862, i32 %4) #18
  br label %884

867:                                              ; preds = %860
  %868 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %846, i64 0, i32 0
  %869 = load i32, i32* %868, align 8
  br i1 %6, label %870, label %877

870:                                              ; preds = %867
  %871 = icmp eq i32 %869, 7
  br i1 %871, label %884, label %872

872:                                              ; preds = %870
  %873 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %874 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %873, align 8
  %875 = tail call i8* @TfLiteTypeGetName(i32 %869) #18
  %876 = tail call i8* @TfLiteTypeGetName(i32 7) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %874(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 985, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.91, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.79, i64 0, i64 0), i8* %875, i8* %876) #18
  br label %884

877:                                              ; preds = %867
  %878 = icmp eq i32 %869, 1
  br i1 %878, label %884, label %879

879:                                              ; preds = %877
  %880 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %881 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %880, align 8
  %882 = tail call i8* @TfLiteTypeGetName(i32 %869) #18
  %883 = tail call i8* @TfLiteTypeGetName(i32 1) #18
  tail call void (%struct.TfLiteContext*, i8*, ...) %881(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 988, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.91, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.56, i64 0, i64 0), i8* %882, i8* %883) #18
  br label %884

884:                                              ; preds = %848, %879, %872, %864, %857, %804, %835, %828, %820, %813, %760, %791, %784, %776, %769, %714, %745, %738, %730, %723, %710, %696, %870, %877, %42, %49, %56, %62, %126, %133, %140, %147, %214, %221, %228, %235, %290, %351, %358, %372, %424, %492, %499, %507, %514, %578, %585, %593, %600, %665, %672, %680, %687, %693, %642, %635, %628, %621, %557, %550, %542, %535, %471, %464, %456, %449, %440, %414, %400, %393, %330, %316, %309, %278, %271, %264, %257, %190, %183, %176, %169, %102, %95, %88, %81, %21, %14
  %885 = phi i32 [ 1, %21 ], [ 1, %14 ], [ 1, %42 ], [ 1, %49 ], [ 1, %56 ], [ 1, %62 ], [ 1, %81 ], [ 1, %88 ], [ 1, %95 ], [ 1, %102 ], [ 1, %126 ], [ 1, %133 ], [ 1, %140 ], [ 1, %147 ], [ 1, %169 ], [ 1, %176 ], [ 1, %183 ], [ 1, %190 ], [ 1, %214 ], [ 1, %221 ], [ 1, %228 ], [ 1, %235 ], [ 1, %257 ], [ 1, %264 ], [ 1, %271 ], [ 1, %278 ], [ 1, %290 ], [ 1, %309 ], [ 1, %316 ], [ 1, %330 ], [ 1, %351 ], [ 1, %358 ], [ 1, %372 ], [ 1, %393 ], [ 1, %400 ], [ 1, %414 ], [ 1, %424 ], [ 1, %440 ], [ 1, %449 ], [ 1, %456 ], [ 1, %464 ], [ 1, %471 ], [ 1, %492 ], [ 1, %499 ], [ 1, %507 ], [ 1, %514 ], [ 1, %535 ], [ 1, %542 ], [ 1, %550 ], [ 1, %557 ], [ 1, %578 ], [ 1, %585 ], [ 1, %593 ], [ 1, %600 ], [ 1, %621 ], [ 1, %628 ], [ 1, %635 ], [ 1, %642 ], [ 1, %665 ], [ 1, %672 ], [ 1, %680 ], [ 1, %687 ], [ 1, %693 ], [ 0, %877 ], [ 0, %870 ], [ 0, %696 ], [ 1, %710 ], [ 1, %723 ], [ 1, %730 ], [ 1, %738 ], [ 1, %745 ], [ 1, %714 ], [ 1, %769 ], [ 1, %776 ], [ 1, %784 ], [ 1, %791 ], [ 1, %760 ], [ 1, %813 ], [ 1, %820 ], [ 1, %828 ], [ 1, %835 ], [ 1, %804 ], [ 1, %857 ], [ 1, %864 ], [ 1, %872 ], [ 1, %879 ], [ 1, %848 ]
  ret i32 %885
}

declare i8* @TfLiteTypeGetName(i32) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext*, i32, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %"class.std::__1::unique_ptr"* nocapture) local_unnamed_addr #1 {
  %6 = alloca %"class.tflite::RuntimeShape", align 8
  %7 = icmp eq %struct.TfLiteTensor* %2, null
  br i1 %7, label %80, label %8

8:                                                ; preds = %5
  %9 = bitcast %"class.tflite::RuntimeShape"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #18
  %10 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2, i64 0, i32 2
  %11 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %10, align 8, !noalias !2
  %12 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %11, i64 0, i32 0
  %13 = load i32, i32* %12, align 4, !noalias !2
  %14 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %11, i64 0, i32 1, i64 0
  %15 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 0
  store i32 %13, i32* %15, align 8, !alias.scope !2
  %16 = icmp sgt i32 %13, 5
  br i1 %16, label %64, label %17

17:                                               ; preds = %8
  %18 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 1
  %19 = sext i32 %13 to i64
  %20 = shl nsw i64 %19, 2
  %21 = bitcast %union.anon* %18 to i8*
  %22 = bitcast i32* %14 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %21, i8* align 4 %22, i64 %20, i1 false) #18
  %23 = icmp eq i32 %13, 2
  br i1 %23, label %24, label %61

24:                                               ; preds = %17
  %25 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 1
  %26 = bitcast %union.anon* %25 to i32*
  %27 = load i32, i32* %26, align 8
  %28 = bitcast %union.anon* %25 to [5 x i32]*
  %29 = getelementptr inbounds [5 x i32], [5 x i32]* %28, i64 0, i64 1
  %30 = load i32, i32* %29, align 4
  %31 = sext i32 %27 to i64
  %32 = tail call { i64, i1 } @llvm.umul.with.overflow.i64(i64 %31, i64 4)
  %33 = extractvalue { i64, i1 } %32, 1
  %34 = extractvalue { i64, i1 } %32, 0
  %35 = select i1 %33, i64 -1, i64 %34
  %36 = tail call i8* @_Znam(i64 %35) #17
  %37 = getelementptr inbounds %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr"* %4, i64 0, i32 0, i32 0, i32 0
  %38 = load i32*, i32** %37, align 8
  %39 = bitcast %"class.std::__1::unique_ptr"* %4 to i8**
  store i8* %36, i8** %39, align 8
  %40 = icmp eq i32* %38, null
  br i1 %40, label %43, label %41

41:                                               ; preds = %24
  %42 = bitcast i32* %38 to i8*
  tail call void @_ZdaPv(i8* %42) #17
  br label %43

43:                                               ; preds = %24, %41
  %44 = icmp eq %struct.TfLiteTensor* %3, null
  br i1 %44, label %45, label %48

45:                                               ; preds = %43
  %46 = load i8*, i8** %39, align 8
  %47 = shl nsw i64 %31, 2
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %46, i8 0, i64 %47, i1 false)
  br label %54

48:                                               ; preds = %43
  %49 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %3, i64 0, i32 1, i32 0
  %50 = bitcast i32** %49 to i8**
  %51 = load i8*, i8** %50, align 8
  %52 = load i8*, i8** %39, align 8
  %53 = shl nsw i64 %31, 2
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %52, i8* align 4 %51, i64 %53, i1 false)
  br label %54

54:                                               ; preds = %48, %45
  %55 = icmp eq i32 %1, 0
  br i1 %55, label %78, label %56

56:                                               ; preds = %54
  %57 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2, i64 0, i32 1
  %58 = bitcast %union.TfLitePtrUnion* %57 to i8**
  %59 = load i8*, i8** %58, align 8
  %60 = load i32*, i32** %37, align 8
  tail call void @_ZN6tflite12tensor_utils30MatrixScalarMultiplyAccumulateEPKaiiiPi(i8* %59, i32 %1, i32 %27, i32 %30, i32* %60) #18
  br label %78

61:                                               ; preds = %17
  %62 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %63 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %62, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %63(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1005, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.92, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %13, i32 2) #18
  br label %78

64:                                               ; preds = %8
  %65 = sext i32 %13 to i64
  %66 = shl nsw i64 %65, 2
  %67 = tail call i8* @_Znam(i64 %66) #17, !noalias !2
  %68 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 1, i32 0
  %69 = bitcast i32** %68 to i8**
  store i8* %67, i8** %69, align 8, !alias.scope !2
  %70 = bitcast i32* %14 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %67, i8* align 4 %70, i64 %66, i1 false) #18
  %71 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %72 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %71, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %72(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1005, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.92, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %13, i32 2) #18
  %73 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 1, i32 0
  %74 = load i32*, i32** %73, align 8
  %75 = icmp eq i32* %74, null
  br i1 %75, label %78, label %76

76:                                               ; preds = %64
  %77 = bitcast i32* %74 to i8*
  tail call void @_ZdaPv(i8* %77) #17
  br label %78

78:                                               ; preds = %61, %54, %56, %64, %76
  %79 = phi i32 [ 1, %61 ], [ 1, %64 ], [ 1, %76 ], [ 0, %56 ], [ 0, %54 ]
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #18
  br label %80

80:                                               ; preds = %5, %78
  %81 = phi i32 [ %79, %78 ], [ 0, %5 ]
  ret i32 %81
}

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.umul.with.overflow.i64(i64, i64) #4

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znam(i64) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #0

declare void @_ZN6tflite12tensor_utils30MatrixScalarMultiplyAccumulateEPKaiiiPi(i8*, i32, i32, i32, i32*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm4full41PopulatePrecomputedZPTimesWeightsWithBiasEP13TfLiteContextPNS2_6OpDataEP10TfLiteNode(%struct.TfLiteContext*, %"struct.tflite::ops::builtin::lstm::OpData"* nocapture, %struct.TfLiteNode* nocapture readonly) local_unnamed_addr #1 {
  %4 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %2, i64 0, i32 0
  %5 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %4, align 8
  %6 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 0
  %7 = load i32, i32* %6, align 4
  %8 = icmp slt i32 %7, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %3
  %10 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %11 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %10, align 8
  %12 = sext i32 %7 to i64
  %13 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %11, i64 %12
  br label %14

14:                                               ; preds = %3, %9
  %15 = phi %struct.TfLiteTensor* [ %13, %9 ], [ null, %3 ]
  %16 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 18
  %17 = load i32, i32* %16, align 4
  %18 = icmp slt i32 %17, 0
  br i1 %18, label %29, label %19

19:                                               ; preds = %14
  %20 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %21 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %20, align 8
  %22 = sext i32 %17 to i64
  %23 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %22
  %24 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %22, i32 11
  %25 = load i8, i8* %24, align 1, !range !5
  %26 = icmp eq i8 %25, 0
  %27 = icmp eq %struct.TfLiteTensor* %23, null
  %28 = or i1 %26, %27
  br i1 %28, label %29, label %32

29:                                               ; preds = %19, %14
  %30 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %31 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %30, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %31(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1029, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.93, i64 0, i64 0)) #18
  br label %190

32:                                               ; preds = %19
  %33 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %15, i64 0, i32 3, i32 1
  %34 = load i32, i32* %33, align 4
  %35 = sub nsw i32 0, %34
  %36 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %22, i32 3, i32 1
  %37 = load i32, i32* %36, align 4
  %38 = sub nsw i32 0, %37
  %39 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 1
  %40 = load i32, i32* %39, align 4
  %41 = icmp slt i32 %40, 0
  %42 = sext i32 %40 to i64
  %43 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %42
  %44 = select i1 %41, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %43
  %45 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 2
  %46 = load i32, i32* %45, align 4
  %47 = icmp slt i32 %46, 0
  %48 = sext i32 %46 to i64
  %49 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %48
  %50 = select i1 %47, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %49
  %51 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 3
  %52 = load i32, i32* %51, align 4
  %53 = icmp slt i32 %52, 0
  %54 = sext i32 %52 to i64
  %55 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %54
  %56 = select i1 %53, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %55
  %57 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 4
  %58 = load i32, i32* %57, align 4
  %59 = icmp slt i32 %58, 0
  %60 = sext i32 %58 to i64
  %61 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %60
  %62 = select i1 %59, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %61
  %63 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 5
  %64 = load i32, i32* %63, align 4
  %65 = icmp slt i32 %64, 0
  %66 = sext i32 %64 to i64
  %67 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %66
  %68 = select i1 %65, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %67
  %69 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 6
  %70 = load i32, i32* %69, align 4
  %71 = icmp slt i32 %70, 0
  %72 = sext i32 %70 to i64
  %73 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %72
  %74 = select i1 %71, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %73
  %75 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 7
  %76 = load i32, i32* %75, align 4
  %77 = icmp slt i32 %76, 0
  %78 = sext i32 %76 to i64
  %79 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %78
  %80 = select i1 %77, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %79
  %81 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 8
  %82 = load i32, i32* %81, align 4
  %83 = icmp slt i32 %82, 0
  %84 = sext i32 %82 to i64
  %85 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %84
  %86 = select i1 %83, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %85
  %87 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 16
  %88 = load i32, i32* %87, align 4
  %89 = icmp slt i32 %88, 0
  %90 = sext i32 %88 to i64
  %91 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %90
  %92 = select i1 %89, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %91
  %93 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 17
  %94 = load i32, i32* %93, align 4
  %95 = icmp slt i32 %94, 0
  %96 = sext i32 %94 to i64
  %97 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %96
  %98 = select i1 %95, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %97
  %99 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %2, i64 0, i32 2
  %100 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %99, align 8
  %101 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %100, i64 0, i32 1, i64 4
  %102 = load i32, i32* %101, align 4
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %103, i32 12, i32 1
  %105 = bitcast i8** %104 to %struct.TfLiteAffineQuantization**
  %106 = load %struct.TfLiteAffineQuantization*, %struct.TfLiteAffineQuantization** %105, align 8
  %107 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %106, i64 0, i32 1
  %108 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %107, align 8
  %109 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %108, i64 0, i32 1, i64 0
  %110 = load i32, i32* %109, align 4
  %111 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 1
  %112 = load i8, i8* %111, align 4, !range !5
  %113 = icmp ne i8 %112, 0
  br i1 %113, label %121, label %114

114:                                              ; preds = %32
  %115 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %5, i64 0, i32 1, i64 13
  %116 = load i32, i32* %115, align 4
  %117 = icmp slt i32 %116, 0
  br i1 %117, label %121, label %118

118:                                              ; preds = %114
  %119 = sext i32 %116 to i64
  %120 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %21, i64 %119
  br label %121

121:                                              ; preds = %118, %114, %32
  %122 = phi %struct.TfLiteTensor* [ null, %32 ], [ %120, %118 ], [ null, %114 ]
  %123 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 42
  %124 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %35, %struct.TfLiteTensor* %50, %struct.TfLiteTensor* %122, %"class.std::__1::unique_ptr"* %123)
  %125 = icmp eq i32 %124, 0
  br i1 %125, label %126, label %190

126:                                              ; preds = %121
  %127 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 43
  %128 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %38, %struct.TfLiteTensor* %74, %struct.TfLiteTensor* null, %"class.std::__1::unique_ptr"* %127)
  %129 = icmp eq i32 %128, 0
  br i1 %129, label %130, label %190

130:                                              ; preds = %126
  br i1 %113, label %140, label %131

131:                                              ; preds = %130
  %132 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %4, align 8
  %133 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %132, i64 0, i32 1, i64 14
  %134 = load i32, i32* %133, align 4
  %135 = icmp slt i32 %134, 0
  br i1 %135, label %140, label %136

136:                                              ; preds = %131
  %137 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %20, align 8
  %138 = sext i32 %134 to i64
  %139 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %137, i64 %138
  br label %140

140:                                              ; preds = %136, %131, %130
  %141 = phi %struct.TfLiteTensor* [ null, %130 ], [ %139, %136 ], [ null, %131 ]
  %142 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 44
  %143 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %35, %struct.TfLiteTensor* %56, %struct.TfLiteTensor* %141, %"class.std::__1::unique_ptr"* %142)
  %144 = icmp eq i32 %143, 0
  br i1 %144, label %145, label %190

145:                                              ; preds = %140
  %146 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 45
  %147 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %38, %struct.TfLiteTensor* %80, %struct.TfLiteTensor* null, %"class.std::__1::unique_ptr"* %146)
  %148 = icmp eq i32 %147, 0
  br i1 %148, label %149, label %190

149:                                              ; preds = %145
  br i1 %113, label %159, label %150

150:                                              ; preds = %149
  %151 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %4, align 8
  %152 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %151, i64 0, i32 1, i64 15
  %153 = load i32, i32* %152, align 4
  %154 = icmp slt i32 %153, 0
  br i1 %154, label %159, label %155

155:                                              ; preds = %150
  %156 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %20, align 8
  %157 = sext i32 %153 to i64
  %158 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %156, i64 %157
  br label %159

159:                                              ; preds = %155, %150, %149
  %160 = phi %struct.TfLiteTensor* [ null, %149 ], [ %158, %155 ], [ null, %150 ]
  %161 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 46
  %162 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %35, %struct.TfLiteTensor* %62, %struct.TfLiteTensor* %160, %"class.std::__1::unique_ptr"* %161)
  %163 = icmp eq i32 %162, 0
  br i1 %163, label %164, label %190

164:                                              ; preds = %159
  %165 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 47
  %166 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %38, %struct.TfLiteTensor* %86, %struct.TfLiteTensor* null, %"class.std::__1::unique_ptr"* %165)
  %167 = icmp eq i32 %166, 0
  br i1 %167, label %168, label %190

168:                                              ; preds = %164
  br i1 %113, label %178, label %169

169:                                              ; preds = %168
  %170 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %4, align 8
  %171 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %170, i64 0, i32 1, i64 12
  %172 = load i32, i32* %171, align 4
  %173 = icmp slt i32 %172, 0
  br i1 %173, label %178, label %174

174:                                              ; preds = %169
  %175 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %20, align 8
  %176 = sext i32 %172 to i64
  %177 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %175, i64 %176
  br label %178

178:                                              ; preds = %174, %169, %168
  %179 = phi %struct.TfLiteTensor* [ null, %168 ], [ %177, %174 ], [ null, %169 ]
  %180 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 48
  %181 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %35, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %179, %"class.std::__1::unique_ptr"* %180)
  %182 = icmp eq i32 %181, 0
  br i1 %182, label %183, label %190

183:                                              ; preds = %178
  %184 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 49
  %185 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %38, %struct.TfLiteTensor* %68, %struct.TfLiteTensor* null, %"class.std::__1::unique_ptr"* %184)
  %186 = icmp eq i32 %185, 0
  br i1 %186, label %187, label %190

187:                                              ; preds = %183
  %188 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %1, i64 0, i32 5, i32 50
  %189 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full38PrecomputeZeroPointTimesWeightWithBiasEP13TfLiteContextiPK12TfLiteTensorS8_PNSt3__110unique_ptrIA_iNS9_14default_deleteISB_EEEE(%struct.TfLiteContext* %0, i32 %110, %struct.TfLiteTensor* %92, %struct.TfLiteTensor* %98, %"class.std::__1::unique_ptr"* %188)
  ret i32 %189

190:                                              ; preds = %121, %126, %159, %164, %183, %178, %145, %140, %29
  %191 = phi i32 [ 1, %29 ], [ %128, %126 ], [ %124, %121 ], [ %147, %145 ], [ %143, %140 ], [ %166, %164 ], [ %162, %159 ], [ %185, %183 ], [ %181, %178 ]
  ret i32 %191
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm4full7PrepareEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode*) local_unnamed_addr #1 {
  %3 = alloca %"class.std::__1::vector.25", align 8
  %4 = alloca %"class.std::__1::vector.32", align 8
  %5 = alloca i32, align 4
  %6 = alloca %"class.std::__1::vector.25", align 8
  %7 = alloca [1 x i32], align 4
  %8 = alloca [1 x i32], align 4
  %9 = alloca [2 x i32], align 4
  %10 = alloca [1 x i32], align 4
  %11 = alloca [2 x i32], align 4
  %12 = alloca [2 x i32], align 4
  %13 = alloca [2 x i32], align 4
  %14 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 4
  %15 = bitcast i8** %14 to %"struct.tflite::ops::builtin::lstm::OpData"**
  %16 = load %"struct.tflite::ops::builtin::lstm::OpData"*, %"struct.tflite::ops::builtin::lstm::OpData"** %15, align 8
  %17 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 1
  %18 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %17, align 8
  %19 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %18, i64 0, i32 0
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %20, 1
  br i1 %21, label %25, label %22

22:                                               ; preds = %2
  %23 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %24 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %23, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %24(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1145, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.94, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %20, i32 1) #18
  br label %2453

25:                                               ; preds = %2
  %26 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %27 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %28 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %27, i64 0, i32 0
  %29 = load i32, i32* %28, align 4
  switch i32 %29, label %46 [
    i32 24, label %30
    i32 20, label %44
  ]

30:                                               ; preds = %25
  %31 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %27, i64 0, i32 1, i64 21
  %32 = load i32, i32* %31, align 4
  %33 = icmp slt i32 %32, 0
  br i1 %33, label %39, label %34

34:                                               ; preds = %30
  %35 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %36 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %35, align 8
  %37 = sext i32 %32 to i64
  %38 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %36, i64 %37
  br label %39

39:                                               ; preds = %30, %34
  %40 = phi %struct.TfLiteTensor* [ %38, %34 ], [ null, %30 ]
  %41 = icmp ne %struct.TfLiteTensor* %40, null
  %42 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 1
  %43 = zext i1 %41 to i8
  store i8 %43, i8* %42, align 4
  br label %49

44:                                               ; preds = %25
  %45 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 1
  store i8 0, i8* %45, align 4
  br label %49

46:                                               ; preds = %25
  %47 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %48 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %47, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %48(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([60 x i8], [60 x i8]* @.str.95, i64 0, i64 0), i32 %29) #18
  br label %2453

49:                                               ; preds = %44, %39
  %50 = phi i8 [ 0, %44 ], [ %43, %39 ]
  %51 = icmp ne i8 %50, 0
  %52 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %53 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %52, i64 0, i32 1, i64 0
  %54 = load i32, i32* %53, align 4
  %55 = icmp slt i32 %54, 0
  br i1 %55, label %61, label %56

56:                                               ; preds = %49
  %57 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %58 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %57, align 8
  %59 = sext i32 %54 to i64
  %60 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %58, i64 %59
  br label %61

61:                                               ; preds = %49, %56
  %62 = phi %struct.TfLiteTensor* [ %60, %56 ], [ null, %49 ]
  %63 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %62, i64 0, i32 0
  %64 = load i32, i32* %63, align 8
  %65 = icmp eq i32 %64, 9
  %66 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %62, i64 0, i32 2
  %67 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %66, align 8
  %68 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %67, i64 0, i32 0
  %69 = load i32, i32* %68, align 4
  %70 = icmp sgt i32 %69, 1
  br i1 %70, label %74, label %71

71:                                               ; preds = %61
  %72 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %73 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %72, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %73(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1177, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.96, i64 0, i64 0)) #18
  br label %2453

74:                                               ; preds = %61
  %75 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %67, i64 0, i32 1, i64 0
  %76 = load i32, i32* %75, align 4
  %77 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %67, i64 0, i32 1, i64 1
  %78 = load i32, i32* %77, align 4
  %79 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %52, i64 0, i32 1, i64 4
  %80 = load i32, i32* %79, align 4
  %81 = icmp slt i32 %80, 0
  br i1 %81, label %87, label %82

82:                                               ; preds = %74
  %83 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %84 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %83, align 8
  %85 = sext i32 %80 to i64
  %86 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %84, i64 %85
  br label %87

87:                                               ; preds = %74, %82
  %88 = phi %struct.TfLiteTensor* [ %86, %82 ], [ null, %74 ]
  %89 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %88, i64 0, i32 2
  %90 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %89, align 8
  %91 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %90, i64 0, i32 1, i64 0
  %92 = load i32, i32* %91, align 4
  %93 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %90, i64 0, i32 0
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 2
  br i1 %95, label %99, label %96

96:                                               ; preds = %87
  %97 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %98 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %97, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %98(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1184, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.97, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %94, i32 2) #18
  br label %2453

99:                                               ; preds = %87
  %100 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %90, i64 0, i32 1, i64 1
  %101 = load i32, i32* %100, align 4
  %102 = icmp eq i32 %101, %78
  br i1 %102, label %106, label %103

103:                                              ; preds = %99
  %104 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %105 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %104, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %105(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1185, i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.98, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.12, i64 0, i64 0), i32 %101, i32 %78) #18
  br label %2453

106:                                              ; preds = %99
  %107 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %52, i64 0, i32 1, i64 8
  %108 = load i32, i32* %107, align 4
  %109 = icmp slt i32 %108, 0
  br i1 %109, label %115, label %110

110:                                              ; preds = %106
  %111 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %112 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %111, align 8
  %113 = sext i32 %108 to i64
  %114 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %112, i64 %113
  br label %115

115:                                              ; preds = %106, %110
  %116 = phi %struct.TfLiteTensor* [ %114, %110 ], [ null, %106 ]
  %117 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %116, i64 0, i32 2
  %118 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %117, align 8
  %119 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %118, i64 0, i32 0
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 2
  br i1 %121, label %125, label %122

122:                                              ; preds = %115
  %123 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %124 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %123, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %124(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1189, i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.99, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %120, i32 2) #18
  br label %2453

125:                                              ; preds = %115
  %126 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %118, i64 0, i32 1, i64 0
  %127 = load i32, i32* %126, align 4
  %128 = icmp eq i32 %127, %92
  br i1 %128, label %132, label %129

129:                                              ; preds = %125
  %130 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %131 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %130, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %131(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1191, i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.100, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.10, i64 0, i64 0), i32 %127, i32 %92) #18
  br label %2453

132:                                              ; preds = %125
  %133 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %118, i64 0, i32 1, i64 1
  %134 = load i32, i32* %133, align 4
  %135 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full26CheckInputTensorDimensionsEP13TfLiteContextP10TfLiteNodeiiibb(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, i32 %78, i32 %134, i32 %92, i1 zeroext %51, i1 zeroext %65)
  %136 = icmp eq i32 %135, 0
  br i1 %136, label %137, label %2453

137:                                              ; preds = %132
  %138 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %17, align 8
  %139 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %138, i64 0, i32 1, i64 0
  %140 = load i32, i32* %139, align 4
  %141 = icmp slt i32 %140, 0
  br i1 %141, label %147, label %142

142:                                              ; preds = %137
  %143 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %144 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %143, align 8
  %145 = sext i32 %140 to i64
  %146 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %144, i64 %145
  br label %147

147:                                              ; preds = %137, %142
  %148 = phi %struct.TfLiteTensor* [ %146, %142 ], [ null, %137 ]
  %149 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %150 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %149, i64 0, i32 1, i64 18
  %151 = load i32, i32* %150, align 4
  %152 = icmp slt i32 %151, 0
  br i1 %152, label %163, label %153

153:                                              ; preds = %147
  %154 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %155 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %156 = sext i32 %151 to i64
  %157 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %155, i64 %156
  %158 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %155, i64 %156, i32 11
  %159 = load i8, i8* %158, align 1, !range !5
  %160 = icmp eq i8 %159, 0
  %161 = icmp eq %struct.TfLiteTensor* %157, null
  %162 = or i1 %160, %161
  br i1 %162, label %163, label %166

163:                                              ; preds = %153, %147
  %164 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %165 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %164, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %165(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1204, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.93, i64 0, i64 0)) #18
  br label %2453

166:                                              ; preds = %153
  %167 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %149, i64 0, i32 1, i64 19
  %168 = load i32, i32* %167, align 4
  %169 = icmp slt i32 %168, 0
  br i1 %169, label %178, label %170

170:                                              ; preds = %166
  %171 = sext i32 %168 to i64
  %172 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %155, i64 %171
  %173 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %155, i64 %171, i32 11
  %174 = load i8, i8* %173, align 1, !range !5
  %175 = icmp eq i8 %174, 0
  %176 = icmp eq %struct.TfLiteTensor* %172, null
  %177 = or i1 %175, %176
  br i1 %177, label %178, label %181

178:                                              ; preds = %170, %166
  %179 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %180 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %179, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %180(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1206, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.101, i64 0, i64 0)) #18
  br label %2453

181:                                              ; preds = %170
  %182 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %155, i64 %156, i32 2
  %183 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %182, align 8
  %184 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 0
  %185 = load i32, i32* %184, align 4
  %186 = icmp sgt i32 %185, 0
  br i1 %186, label %187, label %256

187:                                              ; preds = %181
  %188 = sext i32 %185 to i64
  %189 = add nsw i64 %188, -1
  %190 = and i64 %188, 7
  %191 = icmp ult i64 %189, 7
  br i1 %191, label %240, label %192

192:                                              ; preds = %187
  %193 = sub nsw i64 %188, %190
  br label %194

194:                                              ; preds = %194, %192
  %195 = phi i64 [ 0, %192 ], [ %237, %194 ]
  %196 = phi i64 [ 1, %192 ], [ %236, %194 ]
  %197 = phi i64 [ %193, %192 ], [ %238, %194 ]
  %198 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %195
  %199 = load i32, i32* %198, align 4
  %200 = sext i32 %199 to i64
  %201 = mul nsw i64 %196, %200
  %202 = or i64 %195, 1
  %203 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %202
  %204 = load i32, i32* %203, align 4
  %205 = sext i32 %204 to i64
  %206 = mul nsw i64 %201, %205
  %207 = or i64 %195, 2
  %208 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %207
  %209 = load i32, i32* %208, align 4
  %210 = sext i32 %209 to i64
  %211 = mul nsw i64 %206, %210
  %212 = or i64 %195, 3
  %213 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %212
  %214 = load i32, i32* %213, align 4
  %215 = sext i32 %214 to i64
  %216 = mul nsw i64 %211, %215
  %217 = or i64 %195, 4
  %218 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %217
  %219 = load i32, i32* %218, align 4
  %220 = sext i32 %219 to i64
  %221 = mul nsw i64 %216, %220
  %222 = or i64 %195, 5
  %223 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %222
  %224 = load i32, i32* %223, align 4
  %225 = sext i32 %224 to i64
  %226 = mul nsw i64 %221, %225
  %227 = or i64 %195, 6
  %228 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %227
  %229 = load i32, i32* %228, align 4
  %230 = sext i32 %229 to i64
  %231 = mul nsw i64 %226, %230
  %232 = or i64 %195, 7
  %233 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %232
  %234 = load i32, i32* %233, align 4
  %235 = sext i32 %234 to i64
  %236 = mul nsw i64 %231, %235
  %237 = add nuw nsw i64 %195, 8
  %238 = add i64 %197, -8
  %239 = icmp eq i64 %238, 0
  br i1 %239, label %240, label %194

240:                                              ; preds = %194, %187
  %241 = phi i64 [ undef, %187 ], [ %236, %194 ]
  %242 = phi i64 [ 0, %187 ], [ %237, %194 ]
  %243 = phi i64 [ 1, %187 ], [ %236, %194 ]
  %244 = icmp eq i64 %190, 0
  br i1 %244, label %256, label %245

245:                                              ; preds = %240, %245
  %246 = phi i64 [ %253, %245 ], [ %242, %240 ]
  %247 = phi i64 [ %252, %245 ], [ %243, %240 ]
  %248 = phi i64 [ %254, %245 ], [ %190, %240 ]
  %249 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %246
  %250 = load i32, i32* %249, align 4
  %251 = sext i32 %250 to i64
  %252 = mul nsw i64 %247, %251
  %253 = add nuw nsw i64 %246, 1
  %254 = add i64 %248, -1
  %255 = icmp eq i64 %254, 0
  br i1 %255, label %256, label %245, !llvm.loop !6

256:                                              ; preds = %240, %245, %181
  %257 = phi i64 [ 1, %181 ], [ %241, %240 ], [ %252, %245 ]
  %258 = mul nsw i32 %134, %76
  %259 = sext i32 %258 to i64
  %260 = icmp eq i64 %257, %259
  br i1 %260, label %335, label %261

261:                                              ; preds = %256
  %262 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %263 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %262, align 8
  br i1 %186, label %264, label %333

264:                                              ; preds = %261
  %265 = sext i32 %185 to i64
  %266 = add nsw i64 %265, -1
  %267 = and i64 %265, 7
  %268 = icmp ult i64 %266, 7
  br i1 %268, label %317, label %269

269:                                              ; preds = %264
  %270 = sub nsw i64 %265, %267
  br label %271

271:                                              ; preds = %271, %269
  %272 = phi i64 [ 0, %269 ], [ %314, %271 ]
  %273 = phi i64 [ 1, %269 ], [ %313, %271 ]
  %274 = phi i64 [ %270, %269 ], [ %315, %271 ]
  %275 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %272
  %276 = load i32, i32* %275, align 4
  %277 = sext i32 %276 to i64
  %278 = mul nsw i64 %273, %277
  %279 = or i64 %272, 1
  %280 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %279
  %281 = load i32, i32* %280, align 4
  %282 = sext i32 %281 to i64
  %283 = mul nsw i64 %278, %282
  %284 = or i64 %272, 2
  %285 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %284
  %286 = load i32, i32* %285, align 4
  %287 = sext i32 %286 to i64
  %288 = mul nsw i64 %283, %287
  %289 = or i64 %272, 3
  %290 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %289
  %291 = load i32, i32* %290, align 4
  %292 = sext i32 %291 to i64
  %293 = mul nsw i64 %288, %292
  %294 = or i64 %272, 4
  %295 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %294
  %296 = load i32, i32* %295, align 4
  %297 = sext i32 %296 to i64
  %298 = mul nsw i64 %293, %297
  %299 = or i64 %272, 5
  %300 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %299
  %301 = load i32, i32* %300, align 4
  %302 = sext i32 %301 to i64
  %303 = mul nsw i64 %298, %302
  %304 = or i64 %272, 6
  %305 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %304
  %306 = load i32, i32* %305, align 4
  %307 = sext i32 %306 to i64
  %308 = mul nsw i64 %303, %307
  %309 = or i64 %272, 7
  %310 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %309
  %311 = load i32, i32* %310, align 4
  %312 = sext i32 %311 to i64
  %313 = mul nsw i64 %308, %312
  %314 = add nuw nsw i64 %272, 8
  %315 = add i64 %274, -8
  %316 = icmp eq i64 %315, 0
  br i1 %316, label %317, label %271

317:                                              ; preds = %271, %264
  %318 = phi i64 [ undef, %264 ], [ %313, %271 ]
  %319 = phi i64 [ 0, %264 ], [ %314, %271 ]
  %320 = phi i64 [ 1, %264 ], [ %313, %271 ]
  %321 = icmp eq i64 %267, 0
  br i1 %321, label %333, label %322

322:                                              ; preds = %317, %322
  %323 = phi i64 [ %330, %322 ], [ %319, %317 ]
  %324 = phi i64 [ %329, %322 ], [ %320, %317 ]
  %325 = phi i64 [ %331, %322 ], [ %267, %317 ]
  %326 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %183, i64 0, i32 1, i64 %323
  %327 = load i32, i32* %326, align 4
  %328 = sext i32 %327 to i64
  %329 = mul nsw i64 %324, %328
  %330 = add nuw nsw i64 %323, 1
  %331 = add i64 %325, -1
  %332 = icmp eq i64 %331, 0
  br i1 %332, label %333, label %322, !llvm.loop !8

333:                                              ; preds = %317, %322, %261
  %334 = phi i64 [ 1, %261 ], [ %318, %317 ], [ %329, %322 ]
  tail call void (%struct.TfLiteContext*, i8*, ...) %263(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1211, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.102, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.103, i64 0, i64 0), i64 %334, i32 %258) #18
  br label %2453

335:                                              ; preds = %256
  %336 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %155, i64 %171, i32 2
  %337 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %336, align 8
  %338 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 0
  %339 = load i32, i32* %338, align 4
  %340 = icmp sgt i32 %339, 0
  br i1 %340, label %341, label %410

341:                                              ; preds = %335
  %342 = sext i32 %339 to i64
  %343 = add nsw i64 %342, -1
  %344 = and i64 %342, 7
  %345 = icmp ult i64 %343, 7
  br i1 %345, label %394, label %346

346:                                              ; preds = %341
  %347 = sub nsw i64 %342, %344
  br label %348

348:                                              ; preds = %348, %346
  %349 = phi i64 [ 0, %346 ], [ %391, %348 ]
  %350 = phi i64 [ 1, %346 ], [ %390, %348 ]
  %351 = phi i64 [ %347, %346 ], [ %392, %348 ]
  %352 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %349
  %353 = load i32, i32* %352, align 4
  %354 = sext i32 %353 to i64
  %355 = mul nsw i64 %350, %354
  %356 = or i64 %349, 1
  %357 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %356
  %358 = load i32, i32* %357, align 4
  %359 = sext i32 %358 to i64
  %360 = mul nsw i64 %355, %359
  %361 = or i64 %349, 2
  %362 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %361
  %363 = load i32, i32* %362, align 4
  %364 = sext i32 %363 to i64
  %365 = mul nsw i64 %360, %364
  %366 = or i64 %349, 3
  %367 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %366
  %368 = load i32, i32* %367, align 4
  %369 = sext i32 %368 to i64
  %370 = mul nsw i64 %365, %369
  %371 = or i64 %349, 4
  %372 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %371
  %373 = load i32, i32* %372, align 4
  %374 = sext i32 %373 to i64
  %375 = mul nsw i64 %370, %374
  %376 = or i64 %349, 5
  %377 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %376
  %378 = load i32, i32* %377, align 4
  %379 = sext i32 %378 to i64
  %380 = mul nsw i64 %375, %379
  %381 = or i64 %349, 6
  %382 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %381
  %383 = load i32, i32* %382, align 4
  %384 = sext i32 %383 to i64
  %385 = mul nsw i64 %380, %384
  %386 = or i64 %349, 7
  %387 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %386
  %388 = load i32, i32* %387, align 4
  %389 = sext i32 %388 to i64
  %390 = mul nsw i64 %385, %389
  %391 = add nuw nsw i64 %349, 8
  %392 = add i64 %351, -8
  %393 = icmp eq i64 %392, 0
  br i1 %393, label %394, label %348

394:                                              ; preds = %348, %341
  %395 = phi i64 [ undef, %341 ], [ %390, %348 ]
  %396 = phi i64 [ 0, %341 ], [ %391, %348 ]
  %397 = phi i64 [ 1, %341 ], [ %390, %348 ]
  %398 = icmp eq i64 %344, 0
  br i1 %398, label %410, label %399

399:                                              ; preds = %394, %399
  %400 = phi i64 [ %407, %399 ], [ %396, %394 ]
  %401 = phi i64 [ %406, %399 ], [ %397, %394 ]
  %402 = phi i64 [ %408, %399 ], [ %344, %394 ]
  %403 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %400
  %404 = load i32, i32* %403, align 4
  %405 = sext i32 %404 to i64
  %406 = mul nsw i64 %401, %405
  %407 = add nuw nsw i64 %400, 1
  %408 = add i64 %402, -1
  %409 = icmp eq i64 %408, 0
  br i1 %409, label %410, label %399, !llvm.loop !9

410:                                              ; preds = %394, %399, %335
  %411 = phi i64 [ 1, %335 ], [ %395, %394 ], [ %406, %399 ]
  %412 = mul nsw i32 %92, %76
  %413 = sext i32 %412 to i64
  %414 = icmp eq i64 %411, %413
  br i1 %414, label %489, label %415

415:                                              ; preds = %410
  %416 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %417 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %416, align 8
  br i1 %340, label %418, label %487

418:                                              ; preds = %415
  %419 = sext i32 %339 to i64
  %420 = add nsw i64 %419, -1
  %421 = and i64 %419, 7
  %422 = icmp ult i64 %420, 7
  br i1 %422, label %471, label %423

423:                                              ; preds = %418
  %424 = sub nsw i64 %419, %421
  br label %425

425:                                              ; preds = %425, %423
  %426 = phi i64 [ 0, %423 ], [ %468, %425 ]
  %427 = phi i64 [ 1, %423 ], [ %467, %425 ]
  %428 = phi i64 [ %424, %423 ], [ %469, %425 ]
  %429 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %426
  %430 = load i32, i32* %429, align 4
  %431 = sext i32 %430 to i64
  %432 = mul nsw i64 %427, %431
  %433 = or i64 %426, 1
  %434 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %433
  %435 = load i32, i32* %434, align 4
  %436 = sext i32 %435 to i64
  %437 = mul nsw i64 %432, %436
  %438 = or i64 %426, 2
  %439 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %438
  %440 = load i32, i32* %439, align 4
  %441 = sext i32 %440 to i64
  %442 = mul nsw i64 %437, %441
  %443 = or i64 %426, 3
  %444 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %443
  %445 = load i32, i32* %444, align 4
  %446 = sext i32 %445 to i64
  %447 = mul nsw i64 %442, %446
  %448 = or i64 %426, 4
  %449 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %448
  %450 = load i32, i32* %449, align 4
  %451 = sext i32 %450 to i64
  %452 = mul nsw i64 %447, %451
  %453 = or i64 %426, 5
  %454 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %453
  %455 = load i32, i32* %454, align 4
  %456 = sext i32 %455 to i64
  %457 = mul nsw i64 %452, %456
  %458 = or i64 %426, 6
  %459 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %458
  %460 = load i32, i32* %459, align 4
  %461 = sext i32 %460 to i64
  %462 = mul nsw i64 %457, %461
  %463 = or i64 %426, 7
  %464 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %463
  %465 = load i32, i32* %464, align 4
  %466 = sext i32 %465 to i64
  %467 = mul nsw i64 %462, %466
  %468 = add nuw nsw i64 %426, 8
  %469 = add i64 %428, -8
  %470 = icmp eq i64 %469, 0
  br i1 %470, label %471, label %425

471:                                              ; preds = %425, %418
  %472 = phi i64 [ undef, %418 ], [ %467, %425 ]
  %473 = phi i64 [ 0, %418 ], [ %468, %425 ]
  %474 = phi i64 [ 1, %418 ], [ %467, %425 ]
  %475 = icmp eq i64 %421, 0
  br i1 %475, label %487, label %476

476:                                              ; preds = %471, %476
  %477 = phi i64 [ %484, %476 ], [ %473, %471 ]
  %478 = phi i64 [ %483, %476 ], [ %474, %471 ]
  %479 = phi i64 [ %485, %476 ], [ %421, %471 ]
  %480 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %337, i64 0, i32 1, i64 %477
  %481 = load i32, i32* %480, align 4
  %482 = sext i32 %481 to i64
  %483 = mul nsw i64 %478, %482
  %484 = add nuw nsw i64 %477, 1
  %485 = add i64 %479, -1
  %486 = icmp eq i64 %485, 0
  br i1 %486, label %487, label %476, !llvm.loop !10

487:                                              ; preds = %471, %476, %415
  %488 = phi i64 [ 1, %415 ], [ %472, %471 ], [ %483, %476 ]
  tail call void (%struct.TfLiteContext*, i8*, ...) %417(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1212, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.104, i64 0, i64 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.105, i64 0, i64 0), i64 %488, i32 %412) #18
  br label %2453

489:                                              ; preds = %410
  %490 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #18
  %491 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %490, i64 0, i32 1, i64 0
  store i32 %76, i32* %491, align 4
  %492 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %490, i64 0, i32 1, i64 1
  store i32 %134, i32* %492, align 4
  %493 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 4
  %494 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %495 = tail call i32 %494(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %148, %struct.TfLiteIntArray* %490) #18
  %496 = icmp eq i32 %495, 0
  br i1 %496, label %497, label %2453

497:                                              ; preds = %489
  %498 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %88, i64 0, i32 0
  %499 = load i32, i32* %498, align 8
  switch i32 %499, label %503 [
    i32 3, label %500
    i32 9, label %500
  ]

500:                                              ; preds = %497, %497
  %501 = load i32, i32* %63, align 8
  %502 = icmp eq i32 %501, 1
  br label %503

503:                                              ; preds = %497, %500
  %504 = phi i1 [ %502, %500 ], [ false, %497 ]
  %505 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 2
  %506 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %505, align 8
  %507 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %506, i64 0, i32 0
  %508 = load i32, i32* %507, align 4
  br i1 %65, label %509, label %513

509:                                              ; preds = %503
  switch i32 %508, label %510 [
    i32 12, label %513
    i32 5, label %513
  ]

510:                                              ; preds = %509
  %511 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %512 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %511, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %512(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1228, i8* getelementptr inbounds ([64 x i8], [64 x i8]* @.str.106, i64 0, i64 0)) #18
  br label %2453

513:                                              ; preds = %509, %509, %503
  %514 = icmp eq i32 %508, 5
  %515 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 3
  %516 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  tail call void @TfLiteIntArrayFree(%struct.TfLiteIntArray* %516) #18
  br i1 %504, label %525, label %517

517:                                              ; preds = %513
  br i1 %65, label %518, label %523

518:                                              ; preds = %517
  br i1 %514, label %519, label %521

519:                                              ; preds = %518
  %520 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 6) #18
  store %struct.TfLiteIntArray* %520, %struct.TfLiteIntArray** %515, align 8
  br label %903

521:                                              ; preds = %518
  %522 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 8) #18
  store %struct.TfLiteIntArray* %522, %struct.TfLiteIntArray** %515, align 8
  br label %1836

523:                                              ; preds = %517
  %524 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 1) #18
  store %struct.TfLiteIntArray* %524, %struct.TfLiteIntArray** %515, align 8
  br label %527

525:                                              ; preds = %513
  %526 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 10) #18
  store %struct.TfLiteIntArray* %526, %struct.TfLiteIntArray** %515, align 8
  br i1 %65, label %566, label %527

527:                                              ; preds = %523, %525
  %528 = phi %struct.TfLiteIntArray* [ %524, %523 ], [ %526, %525 ]
  %529 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 3
  %530 = load i32, i32* %529, align 8
  %531 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %528, i64 0, i32 1, i64 0
  store i32 %530, i32* %531, align 4
  %532 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %533 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %532, i64 0, i32 1, i64 0
  %534 = load i32, i32* %533, align 4
  %535 = icmp slt i32 %534, 0
  br i1 %535, label %540, label %536

536:                                              ; preds = %527
  %537 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %538 = sext i32 %534 to i64
  %539 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %537, i64 %538
  br label %540

540:                                              ; preds = %527, %536
  %541 = phi %struct.TfLiteTensor* [ %539, %536 ], [ null, %527 ]
  %542 = load i32, i32* %63, align 8
  %543 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %541, i64 0, i32 0
  store i32 %542, i32* %543, align 8
  %544 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %541, i64 0, i32 4
  store i32 2, i32* %544, align 8
  %545 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %546 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %545, i64 0, i32 1, i64 1
  %547 = load i32, i32* %546, align 4
  %548 = icmp slt i32 %547, 0
  br i1 %548, label %553, label %549

549:                                              ; preds = %540
  %550 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %551 = sext i32 %547 to i64
  %552 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %550, i64 %551
  br label %553

553:                                              ; preds = %540, %549
  %554 = phi %struct.TfLiteTensor* [ %552, %549 ], [ null, %540 ]
  %555 = icmp eq %struct.TfLiteTensor* %554, null
  %556 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #18
  %557 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %556, i64 0, i32 1, i64 0
  store i32 %76, i32* %557, align 4
  %558 = mul nsw i32 %92, 3
  %559 = shl nsw i32 %92, 2
  %560 = select i1 %555, i32 %558, i32 %559
  %561 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %556, i64 0, i32 1, i64 1
  store i32 %560, i32* %561, align 4
  %562 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %563 = tail call i32 %562(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %541, %struct.TfLiteIntArray* %556) #18
  %564 = icmp eq i32 %563, 0
  br i1 %564, label %565, label %2453

565:                                              ; preds = %553
  br i1 %504, label %566, label %2452

566:                                              ; preds = %525, %565
  %567 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 6
  store i8 1, i8* %567, align 8
  %568 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 3
  %569 = load i32, i32* %568, align 8
  %570 = add nsw i32 %569, 1
  %571 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %572 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %571, i64 0, i32 1, i64 1
  store i32 %570, i32* %572, align 4
  %573 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %574 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %573, i64 0, i32 1, i64 1
  %575 = load i32, i32* %574, align 4
  %576 = icmp slt i32 %575, 0
  br i1 %576, label %581, label %577

577:                                              ; preds = %566
  %578 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %579 = sext i32 %575 to i64
  %580 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %578, i64 %579
  br label %581

581:                                              ; preds = %566, %577
  %582 = phi %struct.TfLiteTensor* [ %580, %577 ], [ null, %566 ]
  %583 = load i32, i32* %498, align 8
  %584 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %582, i64 0, i32 0
  store i32 %583, i32* %584, align 8
  %585 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %582, i64 0, i32 4
  store i32 2, i32* %585, align 8
  %586 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %582, i64 0, i32 2
  %587 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %586, align 8
  %588 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %66, align 8
  %589 = tail call i32 @TfLiteIntArrayEqual(%struct.TfLiteIntArray* %587, %struct.TfLiteIntArray* %588) #18
  %590 = icmp eq i32 %589, 0
  br i1 %590, label %591, label %599

591:                                              ; preds = %581
  %592 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %66, align 8
  %593 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray* %592) #18
  %594 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %595 = tail call i32 %594(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %582, %struct.TfLiteIntArray* %593) #18
  %596 = icmp eq i32 %595, 0
  %597 = xor i1 %596, true
  %598 = zext i1 %597 to i32
  br i1 %596, label %599, label %897

599:                                              ; preds = %581, %591
  %600 = load i32, i32* %568, align 8
  %601 = add nsw i32 %600, 2
  %602 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %603 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %602, i64 0, i32 1, i64 2
  store i32 %601, i32* %603, align 4
  %604 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %605 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %604, i64 0, i32 1, i64 2
  %606 = load i32, i32* %605, align 4
  %607 = icmp slt i32 %606, 0
  br i1 %607, label %612, label %608

608:                                              ; preds = %599
  %609 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %610 = sext i32 %606 to i64
  %611 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %609, i64 %610
  br label %612

612:                                              ; preds = %599, %608
  %613 = phi %struct.TfLiteTensor* [ %611, %608 ], [ null, %599 ]
  %614 = load i32, i32* %498, align 8
  %615 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %613, i64 0, i32 0
  store i32 %614, i32* %615, align 8
  %616 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %613, i64 0, i32 4
  store i32 2, i32* %616, align 8
  %617 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %613, i64 0, i32 2
  %618 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %617, align 8
  %619 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %182, align 8
  %620 = tail call i32 @TfLiteIntArrayEqual(%struct.TfLiteIntArray* %618, %struct.TfLiteIntArray* %619) #18
  %621 = icmp eq i32 %620, 0
  br i1 %621, label %622, label %630

622:                                              ; preds = %612
  %623 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %182, align 8
  %624 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray* %623) #18
  %625 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %626 = tail call i32 %625(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %613, %struct.TfLiteIntArray* %624) #18
  %627 = icmp eq i32 %626, 0
  %628 = xor i1 %627, true
  %629 = zext i1 %628 to i32
  br i1 %627, label %630, label %897

630:                                              ; preds = %612, %622
  %631 = load i32, i32* %568, align 8
  %632 = add nsw i32 %631, 3
  %633 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %634 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %633, i64 0, i32 1, i64 3
  store i32 %632, i32* %634, align 4
  %635 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %636 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %635, i64 0, i32 1, i64 3
  %637 = load i32, i32* %636, align 4
  %638 = icmp slt i32 %637, 0
  br i1 %638, label %643, label %639

639:                                              ; preds = %630
  %640 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %641 = sext i32 %637 to i64
  %642 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %640, i64 %641
  br label %643

643:                                              ; preds = %630, %639
  %644 = phi %struct.TfLiteTensor* [ %642, %639 ], [ null, %630 ]
  %645 = load i32, i32* %498, align 8
  %646 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %644, i64 0, i32 0
  store i32 %645, i32* %646, align 8
  %647 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %644, i64 0, i32 4
  store i32 2, i32* %647, align 8
  %648 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %644, i64 0, i32 2
  %649 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %648, align 8
  %650 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %336, align 8
  %651 = tail call i32 @TfLiteIntArrayEqual(%struct.TfLiteIntArray* %649, %struct.TfLiteIntArray* %650) #18
  %652 = icmp eq i32 %651, 0
  br i1 %652, label %653, label %661

653:                                              ; preds = %643
  %654 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %336, align 8
  %655 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray* %654) #18
  %656 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %657 = tail call i32 %656(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %644, %struct.TfLiteIntArray* %655) #18
  %658 = icmp eq i32 %657, 0
  %659 = xor i1 %658, true
  %660 = zext i1 %659 to i32
  br i1 %658, label %661, label %897

661:                                              ; preds = %643, %653
  %662 = load i32, i32* %568, align 8
  %663 = add nsw i32 %662, 4
  %664 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %665 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %664, i64 0, i32 1, i64 4
  store i32 %663, i32* %665, align 4
  %666 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %667 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %666, i64 0, i32 1, i64 4
  %668 = load i32, i32* %667, align 4
  %669 = icmp slt i32 %668, 0
  br i1 %669, label %674, label %670

670:                                              ; preds = %661
  %671 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %672 = sext i32 %668 to i64
  %673 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %671, i64 %672
  br label %674

674:                                              ; preds = %661, %670
  %675 = phi %struct.TfLiteTensor* [ %673, %670 ], [ null, %661 ]
  %676 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %675, i64 0, i32 0
  store i32 1, i32* %676, align 8
  %677 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %675, i64 0, i32 4
  store i32 2, i32* %677, align 8
  %678 = bitcast [1 x i32]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %678) #18
  %679 = getelementptr inbounds [1 x i32], [1 x i32]* %7, i64 0, i64 0
  store i32 %76, i32* %679, align 4
  %680 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %675, i64 0, i32 2
  %681 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %680, align 8
  %682 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %681, i32 1, i32* nonnull %679) #18
  %683 = icmp eq i32 %682, 0
  br i1 %683, label %684, label %692

684:                                              ; preds = %674
  %685 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 1) #18
  %686 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %685, i64 0, i32 1, i64 0
  store i32 %76, i32* %686, align 4
  %687 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %688 = call i32 %687(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %675, %struct.TfLiteIntArray* %685) #18
  %689 = icmp eq i32 %688, 0
  %690 = xor i1 %689, true
  %691 = zext i1 %690 to i32
  br i1 %689, label %692, label %894

692:                                              ; preds = %674, %684
  %693 = load i32, i32* %568, align 8
  %694 = add nsw i32 %693, 5
  %695 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %696 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %695, i64 0, i32 1, i64 5
  store i32 %694, i32* %696, align 4
  %697 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %698 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %697, i64 0, i32 1, i64 5
  %699 = load i32, i32* %698, align 4
  %700 = icmp slt i32 %699, 0
  br i1 %700, label %705, label %701

701:                                              ; preds = %692
  %702 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %703 = sext i32 %699 to i64
  %704 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %702, i64 %703
  br label %705

705:                                              ; preds = %692, %701
  %706 = phi %struct.TfLiteTensor* [ %704, %701 ], [ null, %692 ]
  %707 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %706, i64 0, i32 0
  store i32 1, i32* %707, align 8
  %708 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %706, i64 0, i32 4
  store i32 2, i32* %708, align 8
  %709 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %706, i64 0, i32 2
  %710 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %709, align 8
  %711 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %710, i32 1, i32* nonnull %679) #18
  %712 = icmp eq i32 %711, 0
  br i1 %712, label %713, label %721

713:                                              ; preds = %705
  %714 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 1) #18
  %715 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %714, i64 0, i32 1, i64 0
  store i32 %76, i32* %715, align 4
  %716 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %717 = call i32 %716(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %706, %struct.TfLiteIntArray* %714) #18
  %718 = icmp eq i32 %717, 0
  %719 = xor i1 %718, true
  %720 = zext i1 %719 to i32
  br i1 %718, label %721, label %894

721:                                              ; preds = %705, %713
  %722 = load i32, i32* %568, align 8
  %723 = add nsw i32 %722, 6
  %724 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %725 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %724, i64 0, i32 1, i64 6
  store i32 %723, i32* %725, align 4
  %726 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %727 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %726, i64 0, i32 1, i64 6
  %728 = load i32, i32* %727, align 4
  %729 = icmp slt i32 %728, 0
  br i1 %729, label %734, label %730

730:                                              ; preds = %721
  %731 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %732 = sext i32 %728 to i64
  %733 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %731, i64 %732
  br label %734

734:                                              ; preds = %721, %730
  %735 = phi %struct.TfLiteTensor* [ %733, %730 ], [ null, %721 ]
  %736 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %735, i64 0, i32 0
  store i32 1, i32* %736, align 8
  %737 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %735, i64 0, i32 4
  store i32 2, i32* %737, align 8
  %738 = bitcast [1 x i32]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %738) #18
  %739 = getelementptr inbounds [1 x i32], [1 x i32]* %8, i64 0, i64 0
  store i32 %92, i32* %739, align 4
  %740 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %735, i64 0, i32 2
  %741 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %740, align 8
  %742 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %741, i32 1, i32* nonnull %739) #18
  %743 = icmp eq i32 %742, 0
  br i1 %743, label %744, label %752

744:                                              ; preds = %734
  %745 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 1) #18
  %746 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %745, i64 0, i32 1, i64 0
  store i32 %92, i32* %746, align 4
  %747 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %748 = call i32 %747(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %735, %struct.TfLiteIntArray* %745) #18
  %749 = icmp eq i32 %748, 0
  %750 = xor i1 %749, true
  %751 = zext i1 %750 to i32
  br i1 %749, label %752, label %891

752:                                              ; preds = %734, %744
  %753 = load i32, i32* %568, align 8
  %754 = add nsw i32 %753, 7
  %755 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %756 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %755, i64 0, i32 1, i64 7
  store i32 %754, i32* %756, align 4
  %757 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %758 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %757, i64 0, i32 1, i64 7
  %759 = load i32, i32* %758, align 4
  %760 = icmp slt i32 %759, 0
  br i1 %760, label %765, label %761

761:                                              ; preds = %752
  %762 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %763 = sext i32 %759 to i64
  %764 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %762, i64 %763
  br label %765

765:                                              ; preds = %752, %761
  %766 = phi %struct.TfLiteTensor* [ %764, %761 ], [ null, %752 ]
  %767 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %766, i64 0, i32 0
  store i32 2, i32* %767, align 8
  %768 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %766, i64 0, i32 4
  store i32 2, i32* %768, align 8
  %769 = bitcast [2 x i32]* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %769) #18
  %770 = getelementptr inbounds [2 x i32], [2 x i32]* %9, i64 0, i64 0
  %771 = getelementptr inbounds [2 x i32], [2 x i32]* %9, i64 0, i64 1
  store i32 %92, i32* %770, align 4
  store i32 %76, i32* %771, align 4
  %772 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %766, i64 0, i32 2
  %773 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %772, align 8
  %774 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %773, i32 2, i32* nonnull %770) #18
  %775 = icmp eq i32 %774, 0
  br i1 %775, label %776, label %785

776:                                              ; preds = %765
  %777 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #18
  %778 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %777, i64 0, i32 1, i64 0
  store i32 %92, i32* %778, align 4
  %779 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %777, i64 0, i32 1, i64 1
  store i32 %76, i32* %779, align 4
  %780 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %781 = call i32 %780(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %766, %struct.TfLiteIntArray* %777) #18
  %782 = icmp eq i32 %781, 0
  %783 = xor i1 %782, true
  %784 = zext i1 %783 to i32
  br i1 %782, label %785, label %888

785:                                              ; preds = %765, %776
  %786 = load i32, i32* %568, align 8
  %787 = add nsw i32 %786, 8
  %788 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %789 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %788, i64 0, i32 1, i64 8
  store i32 %787, i32* %789, align 4
  %790 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %791 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %790, i64 0, i32 1, i64 8
  %792 = load i32, i32* %791, align 4
  %793 = icmp slt i32 %792, 0
  br i1 %793, label %798, label %794

794:                                              ; preds = %785
  %795 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %796 = sext i32 %792 to i64
  %797 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %795, i64 %796
  br label %798

798:                                              ; preds = %785, %794
  %799 = phi %struct.TfLiteTensor* [ %797, %794 ], [ null, %785 ]
  %800 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %799, i64 0, i32 0
  store i32 1, i32* %800, align 8
  %801 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %799, i64 0, i32 4
  store i32 2, i32* %801, align 8
  %802 = bitcast [1 x i32]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %802) #18
  %803 = getelementptr inbounds [1 x i32], [1 x i32]* %10, i64 0, i64 0
  store i32 %76, i32* %803, align 4
  %804 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %799, i64 0, i32 2
  %805 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %804, align 8
  %806 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %805, i32 1, i32* nonnull %803) #18
  %807 = icmp eq i32 %806, 0
  br i1 %807, label %808, label %816

808:                                              ; preds = %798
  %809 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 1) #18
  %810 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %809, i64 0, i32 1, i64 0
  store i32 %76, i32* %810, align 4
  %811 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %812 = call i32 %811(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %799, %struct.TfLiteIntArray* %809) #18
  %813 = icmp eq i32 %812, 0
  %814 = xor i1 %813, true
  %815 = zext i1 %814 to i32
  br i1 %813, label %816, label %885

816:                                              ; preds = %798, %808
  %817 = load i32, i32* %568, align 8
  %818 = add nsw i32 %817, 9
  %819 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %820 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %819, i64 0, i32 1, i64 9
  store i32 %818, i32* %820, align 4
  %821 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %822 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %821, i64 0, i32 1, i64 1
  %823 = load i32, i32* %822, align 4
  %824 = icmp slt i32 %823, 0
  br i1 %824, label %829, label %825

825:                                              ; preds = %816
  %826 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %827 = sext i32 %823 to i64
  %828 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %826, i64 %827
  br label %829

829:                                              ; preds = %816, %825
  %830 = phi %struct.TfLiteTensor* [ %828, %825 ], [ null, %816 ]
  %831 = icmp eq %struct.TfLiteTensor* %830, null
  %832 = select i1 %831, i32 6, i32 8
  %833 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %821, i64 0, i32 1, i64 16
  %834 = load i32, i32* %833, align 4
  %835 = icmp slt i32 %834, 0
  br i1 %835, label %849, label %836

836:                                              ; preds = %829
  %837 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %838 = sext i32 %834 to i64
  %839 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %837, i64 %838
  %840 = icmp eq %struct.TfLiteTensor* %839, null
  br i1 %840, label %849, label %841

841:                                              ; preds = %836
  %842 = sitofp i32 %134 to float
  %843 = sitofp i32 %92 to float
  %844 = fdiv float %842, %843
  %845 = call float @llvm.ceil.f32(float %844) #18
  %846 = sitofp i32 %832 to float
  %847 = fadd float %845, %846
  %848 = fptosi float %847 to i32
  br label %849

849:                                              ; preds = %829, %836, %841
  %850 = phi i32 [ %848, %841 ], [ %832, %836 ], [ %832, %829 ]
  %851 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %852 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %851, i64 0, i32 1, i64 9
  %853 = load i32, i32* %852, align 4
  %854 = icmp slt i32 %853, 0
  br i1 %854, label %859, label %855

855:                                              ; preds = %849
  %856 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %857 = sext i32 %853 to i64
  %858 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %856, i64 %857
  br label %859

859:                                              ; preds = %849, %855
  %860 = phi %struct.TfLiteTensor* [ %858, %855 ], [ null, %849 ]
  %861 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %860, i64 0, i32 0
  store i32 2, i32* %861, align 8
  %862 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %860, i64 0, i32 4
  store i32 3, i32* %862, align 8
  %863 = bitcast [2 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %863) #18
  %864 = getelementptr inbounds [2 x i32], [2 x i32]* %11, i64 0, i64 0
  %865 = getelementptr inbounds [2 x i32], [2 x i32]* %11, i64 0, i64 1
  store i32 %850, i32* %864, align 4
  store i32 %92, i32* %865, align 4
  %866 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %860, i64 0, i32 2
  %867 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %866, align 8
  %868 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %867, i32 2, i32* nonnull %864) #18
  %869 = icmp eq i32 %868, 0
  br i1 %869, label %870, label %881

870:                                              ; preds = %859
  %871 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #18
  %872 = load i32, i32* %864, align 4
  %873 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %871, i64 0, i32 1, i64 0
  store i32 %872, i32* %873, align 4
  %874 = load i32, i32* %865, align 4
  %875 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %871, i64 0, i32 1, i64 1
  store i32 %874, i32* %875, align 4
  %876 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %877 = call i32 %876(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %860, %struct.TfLiteIntArray* %871) #18
  %878 = icmp eq i32 %877, 0
  %879 = xor i1 %878, true
  %880 = zext i1 %879 to i32
  br i1 %878, label %881, label %882

881:                                              ; preds = %859, %870
  br label %882

882:                                              ; preds = %870, %881
  %883 = phi i32 [ 0, %881 ], [ %880, %870 ]
  %884 = phi i32 [ 0, %881 ], [ %877, %870 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %863) #18
  br label %885

885:                                              ; preds = %808, %882
  %886 = phi i32 [ %883, %882 ], [ %815, %808 ]
  %887 = phi i32 [ %884, %882 ], [ %812, %808 ]
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %802) #18
  br label %888

888:                                              ; preds = %776, %885
  %889 = phi i32 [ %886, %885 ], [ %784, %776 ]
  %890 = phi i32 [ %887, %885 ], [ %781, %776 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %769) #18
  br label %891

891:                                              ; preds = %744, %888
  %892 = phi i32 [ %889, %888 ], [ %751, %744 ]
  %893 = phi i32 [ %890, %888 ], [ %748, %744 ]
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %738) #18
  br label %894

894:                                              ; preds = %891, %713, %684
  %895 = phi i32 [ %691, %684 ], [ %892, %891 ], [ %720, %713 ]
  %896 = phi i32 [ %688, %684 ], [ %893, %891 ], [ %717, %713 ]
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %678) #18
  br label %897

897:                                              ; preds = %622, %653, %894, %591
  %898 = phi i32 [ %598, %591 ], [ %629, %622 ], [ %895, %894 ], [ %660, %653 ]
  %899 = phi i32 [ %595, %591 ], [ %626, %622 ], [ %896, %894 ], [ %657, %653 ]
  %900 = icmp eq i32 %898, 0
  br i1 %900, label %901, label %2453

901:                                              ; preds = %897
  br i1 %65, label %902, label %2452

902:                                              ; preds = %901
  br i1 %514, label %903, label %1836

903:                                              ; preds = %519, %902
  %904 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %905 = bitcast i8** %904 to %struct.TfLiteLSTMParams**
  %906 = load %struct.TfLiteLSTMParams*, %struct.TfLiteLSTMParams** %905, align 8
  %907 = getelementptr inbounds %struct.TfLiteLSTMParams, %struct.TfLiteLSTMParams* %906, i64 0, i32 1
  %908 = load float, float* %907, align 4
  %909 = getelementptr inbounds %struct.TfLiteLSTMParams, %struct.TfLiteLSTMParams* %906, i64 0, i32 2
  %910 = load float, float* %909, align 4
  %911 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %912 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %911, i64 0, i32 1, i64 19
  %913 = load i32, i32* %912, align 4
  %914 = icmp slt i32 %913, 0
  br i1 %914, label %924, label %915

915:                                              ; preds = %903
  %916 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %917 = sext i32 %913 to i64
  %918 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %916, i64 %917
  %919 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %916, i64 %917, i32 11
  %920 = load i8, i8* %919, align 1, !range !5
  %921 = icmp eq i8 %920, 0
  %922 = icmp eq %struct.TfLiteTensor* %918, null
  %923 = or i1 %921, %922
  br i1 %923, label %924, label %927

924:                                              ; preds = %915, %903
  %925 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %926 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %925, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %926(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 73, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.101, i64 0, i64 0)) #18
  br label %1790

927:                                              ; preds = %915
  %928 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %17, align 8
  %929 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %928, i64 0, i32 1, i64 0
  %930 = load i32, i32* %929, align 4
  %931 = icmp slt i32 %930, 0
  %932 = sext i32 %930 to i64
  %933 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %916, i64 %932
  %934 = select i1 %931, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %933
  %935 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %934, i64 0, i32 12, i32 1
  %936 = bitcast i8** %935 to %struct.TfLiteAffineQuantization**
  %937 = load %struct.TfLiteAffineQuantization*, %struct.TfLiteAffineQuantization** %936, align 8
  %938 = fcmp ogt float %908, 0.000000e+00
  br i1 %938, label %939, label %953

939:                                              ; preds = %927
  %940 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %916, i64 %917, i32 12, i32 1
  %941 = bitcast i8** %940 to %struct.TfLiteAffineQuantization**
  %942 = load %struct.TfLiteAffineQuantization*, %struct.TfLiteAffineQuantization** %941, align 8
  %943 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %942, i64 0, i32 0
  %944 = load %struct.TfLiteFloatArray*, %struct.TfLiteFloatArray** %943, align 8
  %945 = getelementptr inbounds %struct.TfLiteFloatArray, %struct.TfLiteFloatArray* %944, i64 0, i32 1, i64 0
  %946 = load float, float* %945, align 4
  %947 = fdiv float %908, %946
  %948 = fcmp olt float %947, -3.276800e+04
  %949 = select i1 %948, float -3.276800e+04, float %947
  %950 = fcmp ogt float %949, 3.276700e+04
  %951 = select i1 %950, float 3.276700e+04, float %949
  %952 = fptosi float %951 to i16
  br label %953

953:                                              ; preds = %939, %927
  %954 = phi i16 [ %952, %939 ], [ 0, %927 ]
  %955 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 34
  store i16 %954, i16* %955, align 8
  %956 = fcmp ogt float %910, 0.000000e+00
  br i1 %956, label %957, label %968

957:                                              ; preds = %953
  %958 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %937, i64 0, i32 0
  %959 = load %struct.TfLiteFloatArray*, %struct.TfLiteFloatArray** %958, align 8
  %960 = getelementptr inbounds %struct.TfLiteFloatArray, %struct.TfLiteFloatArray* %959, i64 0, i32 1, i64 0
  %961 = load float, float* %960, align 4
  %962 = fdiv float %910, %961
  %963 = fcmp olt float %962, -1.280000e+02
  %964 = select i1 %963, float -1.280000e+02, float %962
  %965 = fcmp ogt float %964, 1.270000e+02
  %966 = select i1 %965, float 1.270000e+02, float %964
  %967 = fptosi float %966 to i8
  br label %968

968:                                              ; preds = %957, %953
  %969 = phi i8 [ %967, %957 ], [ 0, %953 ]
  %970 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 35
  store i8 %969, i8* %970, align 2
  %971 = load %"struct.tflite::ops::builtin::lstm::OpData"*, %"struct.tflite::ops::builtin::lstm::OpData"** %15, align 8
  %972 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %971, i64 0, i32 1
  %973 = load i8, i8* %972, align 4, !range !5
  %974 = icmp ne i8 %973, 0
  %975 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %976 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 0
  %977 = load i32, i32* %976, align 4
  %978 = icmp slt i32 %977, 0
  br i1 %978, label %983, label %979

979:                                              ; preds = %968
  %980 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %981 = sext i32 %977 to i64
  %982 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %980, i64 %981
  br label %983

983:                                              ; preds = %979, %968
  %984 = phi %struct.TfLiteTensor* [ %982, %979 ], [ null, %968 ]
  %985 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 1
  %986 = load i32, i32* %985, align 4
  %987 = icmp slt i32 %986, 0
  br i1 %987, label %992, label %988

988:                                              ; preds = %983
  %989 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %990 = sext i32 %986 to i64
  %991 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %989, i64 %990
  br label %992

992:                                              ; preds = %988, %983
  %993 = phi %struct.TfLiteTensor* [ %991, %988 ], [ null, %983 ]
  %994 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 2
  %995 = load i32, i32* %994, align 4
  %996 = icmp slt i32 %995, 0
  br i1 %996, label %1001, label %997

997:                                              ; preds = %992
  %998 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %999 = sext i32 %995 to i64
  %1000 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %998, i64 %999
  br label %1001

1001:                                             ; preds = %997, %992
  %1002 = phi %struct.TfLiteTensor* [ %1000, %997 ], [ null, %992 ]
  %1003 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 3
  %1004 = load i32, i32* %1003, align 4
  %1005 = icmp slt i32 %1004, 0
  br i1 %1005, label %1010, label %1006

1006:                                             ; preds = %1001
  %1007 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1008 = sext i32 %1004 to i64
  %1009 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1007, i64 %1008
  br label %1010

1010:                                             ; preds = %1006, %1001
  %1011 = phi %struct.TfLiteTensor* [ %1009, %1006 ], [ null, %1001 ]
  %1012 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 4
  %1013 = load i32, i32* %1012, align 4
  %1014 = icmp slt i32 %1013, 0
  br i1 %1014, label %1019, label %1015

1015:                                             ; preds = %1010
  %1016 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1017 = sext i32 %1013 to i64
  %1018 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1016, i64 %1017
  br label %1019

1019:                                             ; preds = %1015, %1010
  %1020 = phi %struct.TfLiteTensor* [ %1018, %1015 ], [ null, %1010 ]
  %1021 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 5
  %1022 = load i32, i32* %1021, align 4
  %1023 = icmp slt i32 %1022, 0
  br i1 %1023, label %1028, label %1024

1024:                                             ; preds = %1019
  %1025 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1026 = sext i32 %1022 to i64
  %1027 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1025, i64 %1026
  br label %1028

1028:                                             ; preds = %1024, %1019
  %1029 = phi %struct.TfLiteTensor* [ %1027, %1024 ], [ null, %1019 ]
  %1030 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 6
  %1031 = load i32, i32* %1030, align 4
  %1032 = icmp slt i32 %1031, 0
  br i1 %1032, label %1037, label %1033

1033:                                             ; preds = %1028
  %1034 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1035 = sext i32 %1031 to i64
  %1036 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1034, i64 %1035
  br label %1037

1037:                                             ; preds = %1033, %1028
  %1038 = phi %struct.TfLiteTensor* [ %1036, %1033 ], [ null, %1028 ]
  %1039 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 7
  %1040 = load i32, i32* %1039, align 4
  %1041 = icmp slt i32 %1040, 0
  br i1 %1041, label %1046, label %1042

1042:                                             ; preds = %1037
  %1043 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1044 = sext i32 %1040 to i64
  %1045 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1043, i64 %1044
  br label %1046

1046:                                             ; preds = %1042, %1037
  %1047 = phi %struct.TfLiteTensor* [ %1045, %1042 ], [ null, %1037 ]
  %1048 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 8
  %1049 = load i32, i32* %1048, align 4
  %1050 = icmp slt i32 %1049, 0
  br i1 %1050, label %1055, label %1051

1051:                                             ; preds = %1046
  %1052 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1053 = sext i32 %1049 to i64
  %1054 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1052, i64 %1053
  br label %1055

1055:                                             ; preds = %1051, %1046
  %1056 = phi %struct.TfLiteTensor* [ %1054, %1051 ], [ null, %1046 ]
  %1057 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 9
  %1058 = load i32, i32* %1057, align 4
  %1059 = icmp slt i32 %1058, 0
  br i1 %1059, label %1064, label %1060

1060:                                             ; preds = %1055
  %1061 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1062 = sext i32 %1058 to i64
  %1063 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1061, i64 %1062
  br label %1064

1064:                                             ; preds = %1060, %1055
  %1065 = phi %struct.TfLiteTensor* [ %1063, %1060 ], [ null, %1055 ]
  %1066 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 10
  %1067 = load i32, i32* %1066, align 4
  %1068 = icmp slt i32 %1067, 0
  br i1 %1068, label %1073, label %1069

1069:                                             ; preds = %1064
  %1070 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1071 = sext i32 %1067 to i64
  %1072 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1070, i64 %1071
  br label %1073

1073:                                             ; preds = %1069, %1064
  %1074 = phi %struct.TfLiteTensor* [ %1072, %1069 ], [ null, %1064 ]
  %1075 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 11
  %1076 = load i32, i32* %1075, align 4
  %1077 = icmp slt i32 %1076, 0
  br i1 %1077, label %1082, label %1078

1078:                                             ; preds = %1073
  %1079 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1080 = sext i32 %1076 to i64
  %1081 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1079, i64 %1080
  br label %1082

1082:                                             ; preds = %1078, %1073
  %1083 = phi %struct.TfLiteTensor* [ %1081, %1078 ], [ null, %1073 ]
  %1084 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 20
  %1085 = load i32, i32* %1084, align 4
  %1086 = icmp slt i32 %1085, 0
  br i1 %1086, label %1091, label %1087

1087:                                             ; preds = %1082
  %1088 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1089 = sext i32 %1085 to i64
  %1090 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1088, i64 %1089
  br label %1091

1091:                                             ; preds = %1087, %1082
  %1092 = phi %struct.TfLiteTensor* [ %1090, %1087 ], [ null, %1082 ]
  %1093 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 21
  %1094 = load i32, i32* %1093, align 4
  %1095 = icmp slt i32 %1094, 0
  br i1 %1095, label %1100, label %1096

1096:                                             ; preds = %1091
  %1097 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1098 = sext i32 %1094 to i64
  %1099 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1097, i64 %1098
  br label %1100

1100:                                             ; preds = %1096, %1091
  %1101 = phi %struct.TfLiteTensor* [ %1099, %1096 ], [ null, %1091 ]
  %1102 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 22
  %1103 = load i32, i32* %1102, align 4
  %1104 = icmp slt i32 %1103, 0
  br i1 %1104, label %1109, label %1105

1105:                                             ; preds = %1100
  %1106 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1107 = sext i32 %1103 to i64
  %1108 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1106, i64 %1107
  br label %1109

1109:                                             ; preds = %1105, %1100
  %1110 = phi %struct.TfLiteTensor* [ %1108, %1105 ], [ null, %1100 ]
  %1111 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 23
  %1112 = load i32, i32* %1111, align 4
  %1113 = icmp slt i32 %1112, 0
  br i1 %1113, label %1118, label %1114

1114:                                             ; preds = %1109
  %1115 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1116 = sext i32 %1112 to i64
  %1117 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1115, i64 %1116
  br label %1118

1118:                                             ; preds = %1114, %1109
  %1119 = phi %struct.TfLiteTensor* [ %1117, %1114 ], [ null, %1109 ]
  %1120 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 16
  %1121 = load i32, i32* %1120, align 4
  %1122 = icmp slt i32 %1121, 0
  br i1 %1122, label %1127, label %1123

1123:                                             ; preds = %1118
  %1124 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1125 = sext i32 %1121 to i64
  %1126 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1124, i64 %1125
  br label %1127

1127:                                             ; preds = %1123, %1118
  %1128 = phi %struct.TfLiteTensor* [ %1126, %1123 ], [ null, %1118 ]
  %1129 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %975, i64 0, i32 1, i64 18
  %1130 = load i32, i32* %1129, align 4
  %1131 = icmp slt i32 %1130, 0
  br i1 %1131, label %1141, label %1132

1132:                                             ; preds = %1127
  %1133 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1134 = sext i32 %1130 to i64
  %1135 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1133, i64 %1134
  %1136 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1133, i64 %1134, i32 11
  %1137 = load i8, i8* %1136, align 1, !range !5
  %1138 = icmp eq i8 %1137, 0
  %1139 = icmp eq %struct.TfLiteTensor* %1135, null
  %1140 = or i1 %1138, %1139
  br i1 %1140, label %1141, label %1144

1141:                                             ; preds = %1132, %1127
  %1142 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %1143 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %1142, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %1143(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 139, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.93, i64 0, i64 0)) #18
  br label %1790

1144:                                             ; preds = %1132
  %1145 = icmp eq %struct.TfLiteTensor* %993, null
  %1146 = icmp ne %struct.TfLiteTensor* %1083, null
  %1147 = icmp eq %struct.TfLiteTensor* %1128, null
  %1148 = bitcast %"class.std::__1::vector.25"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %1148) #18
  %1149 = getelementptr inbounds %"class.std::__1::vector.25", %"class.std::__1::vector.25"* %3, i64 0, i32 0, i32 0
  %1150 = getelementptr inbounds %"class.std::__1::vector.25", %"class.std::__1::vector.25"* %3, i64 0, i32 0, i32 1
  %1151 = getelementptr inbounds %"class.std::__1::vector.25", %"class.std::__1::vector.25"* %3, i64 0, i32 0, i32 2, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1148, i8 0, i64 24, i1 false) #18
  %1152 = bitcast %"class.std::__1::vector.32"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %1152) #18
  %1153 = getelementptr inbounds %"class.std::__1::vector.32", %"class.std::__1::vector.32"* %4, i64 0, i32 0, i32 0
  %1154 = getelementptr inbounds %"class.std::__1::vector.32", %"class.std::__1::vector.32"* %4, i64 0, i32 0, i32 1
  %1155 = getelementptr inbounds %"class.std::__1::vector.32", %"class.std::__1::vector.32"* %4, i64 0, i32 0, i32 2, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1152, i8 0, i64 24, i1 false) #18
  %1156 = bitcast float** %1150 to i64*
  %1157 = bitcast %"class.std::__1::vector.25"* %3 to i64*
  %1158 = bitcast float** %1151 to i64*
  %1159 = bitcast i32** %1154 to i64*
  %1160 = bitcast %"class.std::__1::vector.32"* %4 to i64*
  %1161 = bitcast i32** %1155 to i64*
  br label %1297

1162:                                             ; preds = %1545
  %1163 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %505, align 8
  %1164 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1163, i64 0, i32 1, i64 4
  %1165 = load i32, i32* %1164, align 4
  %1166 = icmp slt i32 %1165, 0
  br i1 %1166, label %1171, label %1167

1167:                                             ; preds = %1162
  %1168 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1169 = sext i32 %1165 to i64
  %1170 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1168, i64 %1169
  br label %1171

1171:                                             ; preds = %1167, %1162
  %1172 = phi %struct.TfLiteTensor* [ %1170, %1167 ], [ null, %1162 ]
  %1173 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1172, i64 0, i32 12, i32 1
  %1174 = bitcast i8** %1173 to %struct.TfLiteAffineQuantization**
  %1175 = load %struct.TfLiteAffineQuantization*, %struct.TfLiteAffineQuantization** %1174, align 8
  %1176 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %1175, i64 0, i32 0
  %1177 = load %struct.TfLiteFloatArray*, %struct.TfLiteFloatArray** %1176, align 8
  %1178 = getelementptr inbounds %struct.TfLiteFloatArray, %struct.TfLiteFloatArray* %1177, i64 0, i32 1, i64 0
  %1179 = load float*, float** %1150, align 8
  %1180 = load float*, float** %1151, align 8
  %1181 = icmp eq float* %1179, %1180
  %1182 = ptrtoint float* %1180 to i64
  br i1 %1181, label %1191, label %1183

1183:                                             ; preds = %1171
  %1184 = bitcast float* %1178 to i32*
  %1185 = load i32, i32* %1184, align 4
  %1186 = bitcast float* %1179 to i32*
  store i32 %1185, i32* %1186, align 4
  %1187 = getelementptr inbounds float, float* %1179, i64 1
  %1188 = ptrtoint float* %1187 to i64
  store i64 %1188, i64* %1156, align 8
  %1189 = load i32*, i32** %1154, align 8
  %1190 = ptrtoint i32* %1189 to i64
  br label %1237

1191:                                             ; preds = %1171
  %1192 = ptrtoint float* %1179 to i64
  %1193 = load i64, i64* %1157, align 8
  %1194 = sub i64 %1192, %1193
  %1195 = ashr exact i64 %1194, 2
  %1196 = add nsw i64 %1195, 1
  %1197 = icmp ugt i64 %1196, 4611686018427387903
  br i1 %1197, label %1198, label %1200

1198:                                             ; preds = %1191
  %1199 = bitcast %"class.std::__1::vector.25"* %3 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %1199) #19
  unreachable

1200:                                             ; preds = %1191
  %1201 = sub i64 %1182, %1193
  %1202 = ashr exact i64 %1201, 2
  %1203 = icmp ult i64 %1202, 2305843009213693951
  br i1 %1203, label %1204, label %1212

1204:                                             ; preds = %1200
  %1205 = ashr exact i64 %1201, 1
  %1206 = icmp ult i64 %1205, %1196
  %1207 = select i1 %1206, i64 %1196, i64 %1205
  %1208 = icmp eq i64 %1207, 0
  br i1 %1208, label %1217, label %1209

1209:                                             ; preds = %1204
  %1210 = icmp ugt i64 %1207, 4611686018427387903
  br i1 %1210, label %1211, label %1212

1211:                                             ; preds = %1209
  call void @abort() #19
  unreachable

1212:                                             ; preds = %1209, %1200
  %1213 = phi i64 [ %1207, %1209 ], [ 4611686018427387903, %1200 ]
  %1214 = shl i64 %1213, 2
  %1215 = call i8* @_Znwm(i64 %1214) #17
  %1216 = bitcast i8* %1215 to float*
  br label %1217

1217:                                             ; preds = %1212, %1204
  %1218 = phi i64 [ %1213, %1212 ], [ 0, %1204 ]
  %1219 = phi i8* [ %1215, %1212 ], [ null, %1204 ]
  %1220 = phi float* [ %1216, %1212 ], [ null, %1204 ]
  %1221 = getelementptr inbounds float, float* %1220, i64 %1195
  %1222 = getelementptr inbounds float, float* %1220, i64 %1218
  %1223 = ptrtoint float* %1222 to i64
  %1224 = bitcast float* %1178 to i32*
  %1225 = load i32, i32* %1224, align 4
  %1226 = bitcast float* %1221 to i32*
  store i32 %1225, i32* %1226, align 4
  %1227 = getelementptr inbounds float, float* %1221, i64 1
  %1228 = ptrtoint float* %1227 to i64
  %1229 = ptrtoint float* %1220 to i64
  %1230 = icmp sgt i64 %1194, 0
  br i1 %1230, label %1231, label %1233

1231:                                             ; preds = %1217
  %1232 = inttoptr i64 %1193 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1219, i8* align 4 %1232, i64 %1194, i1 false) #18
  br label %1233

1233:                                             ; preds = %1231, %1217
  store i64 %1229, i64* %1157, align 8
  store i64 %1228, i64* %1156, align 8
  store i64 %1223, i64* %1158, align 8
  %1234 = icmp eq i64 %1193, 0
  br i1 %1234, label %1237, label %1235

1235:                                             ; preds = %1233
  %1236 = inttoptr i64 %1193 to i8*
  call void @_ZdlPv(i8* %1236) #17
  br label %1237

1237:                                             ; preds = %1235, %1233, %1183
  %1238 = phi i64 [ %1190, %1183 ], [ %1547, %1233 ], [ %1547, %1235 ]
  %1239 = phi i32* [ %1189, %1183 ], [ %1546, %1233 ], [ %1546, %1235 ]
  %1240 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %1175, i64 0, i32 1
  %1241 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %1240, align 8
  %1242 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1241, i64 0, i32 1, i64 0
  %1243 = load i32*, i32** %1155, align 8
  %1244 = icmp eq i32* %1239, %1243
  br i1 %1244, label %1249, label %1245

1245:                                             ; preds = %1237
  %1246 = load i32, i32* %1242, align 4
  store i32 %1246, i32* %1239, align 4
  %1247 = getelementptr inbounds i32, i32* %1239, i64 1
  %1248 = ptrtoint i32* %1247 to i64
  store i64 %1248, i64* %1159, align 8
  br label %1295

1249:                                             ; preds = %1237
  %1250 = ptrtoint i32* %1239 to i64
  %1251 = load i64, i64* %1160, align 8
  %1252 = sub i64 %1250, %1251
  %1253 = ashr exact i64 %1252, 2
  %1254 = add nsw i64 %1253, 1
  %1255 = icmp ugt i64 %1254, 4611686018427387903
  br i1 %1255, label %1256, label %1258

1256:                                             ; preds = %1249
  %1257 = bitcast %"class.std::__1::vector.32"* %4 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %1257) #19
  unreachable

1258:                                             ; preds = %1249
  %1259 = icmp ult i64 %1253, 2305843009213693951
  br i1 %1259, label %1260, label %1268

1260:                                             ; preds = %1258
  %1261 = ashr exact i64 %1252, 1
  %1262 = icmp ult i64 %1261, %1254
  %1263 = select i1 %1262, i64 %1254, i64 %1261
  %1264 = icmp eq i64 %1263, 0
  br i1 %1264, label %1273, label %1265

1265:                                             ; preds = %1260
  %1266 = icmp ugt i64 %1263, 4611686018427387903
  br i1 %1266, label %1267, label %1268

1267:                                             ; preds = %1265
  call void @abort() #19
  unreachable

1268:                                             ; preds = %1265, %1258
  %1269 = phi i64 [ %1263, %1265 ], [ 4611686018427387903, %1258 ]
  %1270 = shl i64 %1269, 2
  %1271 = call i8* @_Znwm(i64 %1270) #17
  %1272 = bitcast i8* %1271 to i32*
  br label %1273

1273:                                             ; preds = %1268, %1260
  %1274 = phi i64 [ %1269, %1268 ], [ 0, %1260 ]
  %1275 = phi i32* [ %1272, %1268 ], [ null, %1260 ]
  %1276 = getelementptr inbounds i32, i32* %1275, i64 %1253
  %1277 = getelementptr inbounds i32, i32* %1275, i64 %1274
  %1278 = ptrtoint i32* %1277 to i64
  %1279 = load i32, i32* %1242, align 4
  store i32 %1279, i32* %1276, align 4
  %1280 = getelementptr inbounds i32, i32* %1276, i64 1
  %1281 = ptrtoint i32* %1280 to i64
  %1282 = sub i64 %1238, %1251
  %1283 = ashr exact i64 %1282, 2
  %1284 = sub nsw i64 0, %1283
  %1285 = getelementptr inbounds i32, i32* %1276, i64 %1284
  %1286 = ptrtoint i32* %1285 to i64
  %1287 = icmp sgt i64 %1282, 0
  br i1 %1287, label %1288, label %1291

1288:                                             ; preds = %1273
  %1289 = bitcast i32* %1285 to i8*
  %1290 = inttoptr i64 %1251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1289, i8* align 4 %1290, i64 %1282, i1 false) #18
  br label %1291

1291:                                             ; preds = %1288, %1273
  store i64 %1286, i64* %1160, align 8
  store i64 %1281, i64* %1159, align 8
  store i64 %1278, i64* %1161, align 8
  %1292 = icmp eq i64 %1251, 0
  br i1 %1292, label %1295, label %1293

1293:                                             ; preds = %1291
  %1294 = inttoptr i64 %1251 to i8*
  call void @_ZdlPv(i8* %1294) #17
  br label %1295

1295:                                             ; preds = %1293, %1291, %1245
  %1296 = bitcast i32* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %1296) #18
  store i32 1, i32* %5, align 4
  br i1 %1145, label %1557, label %1550

1297:                                             ; preds = %1545, %1144
  %1298 = phi i32* [ null, %1144 ], [ %1546, %1545 ]
  %1299 = phi i64 [ 0, %1144 ], [ %1547, %1545 ]
  %1300 = phi i64 [ 0, %1144 ], [ %1548, %1545 ]
  br i1 %974, label %1301, label %1434

1301:                                             ; preds = %1297
  %1302 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %505, align 8
  %1303 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1302, i64 0, i32 1, i64 %1300
  %1304 = load i32, i32* %1303, align 4
  %1305 = icmp slt i32 %1304, 0
  br i1 %1305, label %1310, label %1306

1306:                                             ; preds = %1301
  %1307 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1308 = sext i32 %1304 to i64
  %1309 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1307, i64 %1308
  br label %1310

1310:                                             ; preds = %1306, %1301
  %1311 = phi %struct.TfLiteTensor* [ %1309, %1306 ], [ null, %1301 ]
  %1312 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1311, i64 0, i32 12, i32 1
  %1313 = bitcast i8** %1312 to %struct.TfLiteAffineQuantization**
  %1314 = load %struct.TfLiteAffineQuantization*, %struct.TfLiteAffineQuantization** %1313, align 8
  %1315 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %1314, i64 0, i32 0
  %1316 = load %struct.TfLiteFloatArray*, %struct.TfLiteFloatArray** %1315, align 8
  %1317 = getelementptr inbounds %struct.TfLiteFloatArray, %struct.TfLiteFloatArray* %1316, i64 0, i32 1, i64 0
  %1318 = load float*, float** %1150, align 8
  %1319 = load float*, float** %1151, align 8
  %1320 = icmp eq float* %1318, %1319
  %1321 = ptrtoint float* %1319 to i64
  br i1 %1320, label %1330, label %1322

1322:                                             ; preds = %1310
  %1323 = bitcast float* %1317 to i32*
  %1324 = load i32, i32* %1323, align 4
  %1325 = bitcast float* %1318 to i32*
  store i32 %1324, i32* %1325, align 4
  %1326 = getelementptr inbounds float, float* %1318, i64 1
  %1327 = ptrtoint float* %1326 to i64
  store i64 %1327, i64* %1156, align 8
  %1328 = load i32*, i32** %1154, align 8
  %1329 = ptrtoint i32* %1328 to i64
  br label %1376

1330:                                             ; preds = %1310
  %1331 = ptrtoint float* %1318 to i64
  %1332 = load i64, i64* %1157, align 8
  %1333 = sub i64 %1331, %1332
  %1334 = ashr exact i64 %1333, 2
  %1335 = add nsw i64 %1334, 1
  %1336 = icmp ugt i64 %1335, 4611686018427387903
  br i1 %1336, label %1337, label %1339

1337:                                             ; preds = %1330
  %1338 = bitcast %"class.std::__1::vector.25"* %3 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %1338) #19
  unreachable

1339:                                             ; preds = %1330
  %1340 = sub i64 %1321, %1332
  %1341 = ashr exact i64 %1340, 2
  %1342 = icmp ult i64 %1341, 2305843009213693951
  br i1 %1342, label %1343, label %1351

1343:                                             ; preds = %1339
  %1344 = ashr exact i64 %1340, 1
  %1345 = icmp ult i64 %1344, %1335
  %1346 = select i1 %1345, i64 %1335, i64 %1344
  %1347 = icmp eq i64 %1346, 0
  br i1 %1347, label %1356, label %1348

1348:                                             ; preds = %1343
  %1349 = icmp ugt i64 %1346, 4611686018427387903
  br i1 %1349, label %1350, label %1351

1350:                                             ; preds = %1348
  call void @abort() #19
  unreachable

1351:                                             ; preds = %1348, %1339
  %1352 = phi i64 [ %1346, %1348 ], [ 4611686018427387903, %1339 ]
  %1353 = shl i64 %1352, 2
  %1354 = call i8* @_Znwm(i64 %1353) #17
  %1355 = bitcast i8* %1354 to float*
  br label %1356

1356:                                             ; preds = %1351, %1343
  %1357 = phi i64 [ %1352, %1351 ], [ 0, %1343 ]
  %1358 = phi i8* [ %1354, %1351 ], [ null, %1343 ]
  %1359 = phi float* [ %1355, %1351 ], [ null, %1343 ]
  %1360 = getelementptr inbounds float, float* %1359, i64 %1334
  %1361 = getelementptr inbounds float, float* %1359, i64 %1357
  %1362 = ptrtoint float* %1361 to i64
  %1363 = bitcast float* %1317 to i32*
  %1364 = load i32, i32* %1363, align 4
  %1365 = bitcast float* %1360 to i32*
  store i32 %1364, i32* %1365, align 4
  %1366 = getelementptr inbounds float, float* %1360, i64 1
  %1367 = ptrtoint float* %1366 to i64
  %1368 = ptrtoint float* %1359 to i64
  %1369 = icmp sgt i64 %1333, 0
  br i1 %1369, label %1370, label %1372

1370:                                             ; preds = %1356
  %1371 = inttoptr i64 %1332 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1358, i8* align 4 %1371, i64 %1333, i1 false) #18
  br label %1372

1372:                                             ; preds = %1370, %1356
  store i64 %1368, i64* %1157, align 8
  store i64 %1367, i64* %1156, align 8
  store i64 %1362, i64* %1158, align 8
  %1373 = icmp eq i64 %1332, 0
  br i1 %1373, label %1376, label %1374

1374:                                             ; preds = %1372
  %1375 = inttoptr i64 %1332 to i8*
  call void @_ZdlPv(i8* %1375) #17
  br label %1376

1376:                                             ; preds = %1374, %1372, %1322
  %1377 = phi i64 [ %1329, %1322 ], [ %1299, %1372 ], [ %1299, %1374 ]
  %1378 = phi i32* [ %1328, %1322 ], [ %1298, %1372 ], [ %1298, %1374 ]
  %1379 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %1314, i64 0, i32 1
  %1380 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %1379, align 8
  %1381 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1380, i64 0, i32 1, i64 0
  %1382 = load i32*, i32** %1155, align 8
  %1383 = icmp eq i32* %1378, %1382
  br i1 %1383, label %1388, label %1384

1384:                                             ; preds = %1376
  %1385 = load i32, i32* %1381, align 4
  store i32 %1385, i32* %1378, align 4
  %1386 = getelementptr inbounds i32, i32* %1378, i64 1
  %1387 = ptrtoint i32* %1386 to i64
  store i64 %1387, i64* %1159, align 8
  br label %1545

1388:                                             ; preds = %1376
  %1389 = ptrtoint i32* %1378 to i64
  %1390 = load i64, i64* %1160, align 8
  %1391 = sub i64 %1389, %1390
  %1392 = ashr exact i64 %1391, 2
  %1393 = add nsw i64 %1392, 1
  %1394 = icmp ugt i64 %1393, 4611686018427387903
  br i1 %1394, label %1395, label %1397

1395:                                             ; preds = %1388
  %1396 = bitcast %"class.std::__1::vector.32"* %4 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %1396) #19
  unreachable

1397:                                             ; preds = %1388
  %1398 = icmp ult i64 %1392, 2305843009213693951
  br i1 %1398, label %1399, label %1407

1399:                                             ; preds = %1397
  %1400 = ashr exact i64 %1391, 1
  %1401 = icmp ult i64 %1400, %1393
  %1402 = select i1 %1401, i64 %1393, i64 %1400
  %1403 = icmp eq i64 %1402, 0
  br i1 %1403, label %1412, label %1404

1404:                                             ; preds = %1399
  %1405 = icmp ugt i64 %1402, 4611686018427387903
  br i1 %1405, label %1406, label %1407

1406:                                             ; preds = %1404
  call void @abort() #19
  unreachable

1407:                                             ; preds = %1404, %1397
  %1408 = phi i64 [ %1402, %1404 ], [ 4611686018427387903, %1397 ]
  %1409 = shl i64 %1408, 2
  %1410 = call i8* @_Znwm(i64 %1409) #17
  %1411 = bitcast i8* %1410 to i32*
  br label %1412

1412:                                             ; preds = %1407, %1399
  %1413 = phi i64 [ %1408, %1407 ], [ 0, %1399 ]
  %1414 = phi i32* [ %1411, %1407 ], [ null, %1399 ]
  %1415 = getelementptr inbounds i32, i32* %1414, i64 %1392
  %1416 = getelementptr inbounds i32, i32* %1414, i64 %1413
  %1417 = ptrtoint i32* %1416 to i64
  %1418 = load i32, i32* %1381, align 4
  store i32 %1418, i32* %1415, align 4
  %1419 = getelementptr inbounds i32, i32* %1415, i64 1
  %1420 = ptrtoint i32* %1419 to i64
  %1421 = sub i64 %1377, %1390
  %1422 = ashr exact i64 %1421, 2
  %1423 = sub nsw i64 0, %1422
  %1424 = getelementptr inbounds i32, i32* %1415, i64 %1423
  %1425 = ptrtoint i32* %1424 to i64
  %1426 = icmp sgt i64 %1421, 0
  br i1 %1426, label %1427, label %1430

1427:                                             ; preds = %1412
  %1428 = bitcast i32* %1424 to i8*
  %1429 = inttoptr i64 %1390 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1428, i8* align 4 %1429, i64 %1421, i1 false) #18
  br label %1430

1430:                                             ; preds = %1427, %1412
  store i64 %1425, i64* %1160, align 8
  store i64 %1420, i64* %1159, align 8
  store i64 %1417, i64* %1161, align 8
  %1431 = icmp eq i64 %1390, 0
  br i1 %1431, label %1545, label %1432

1432:                                             ; preds = %1430
  %1433 = inttoptr i64 %1390 to i8*
  call void @_ZdlPv(i8* %1433) #17
  br label %1545

1434:                                             ; preds = %1297
  %1435 = load float*, float** %1150, align 8
  %1436 = load float*, float** %1151, align 8
  %1437 = icmp ult float* %1435, %1436
  %1438 = ptrtoint float* %1436 to i64
  br i1 %1437, label %1439, label %1445

1439:                                             ; preds = %1434
  %1440 = bitcast float* %1435 to i32*
  store i32 964689920, i32* %1440, align 4
  %1441 = getelementptr inbounds float, float* %1435, i64 1
  %1442 = ptrtoint float* %1441 to i64
  store i64 %1442, i64* %1156, align 8
  %1443 = load i32*, i32** %1154, align 8
  %1444 = ptrtoint i32* %1443 to i64
  br label %1489

1445:                                             ; preds = %1434
  %1446 = ptrtoint float* %1435 to i64
  %1447 = load i64, i64* %1157, align 8
  %1448 = sub i64 %1446, %1447
  %1449 = ashr exact i64 %1448, 2
  %1450 = add nsw i64 %1449, 1
  %1451 = icmp ugt i64 %1450, 4611686018427387903
  br i1 %1451, label %1452, label %1454

1452:                                             ; preds = %1445
  %1453 = bitcast %"class.std::__1::vector.25"* %3 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %1453) #19
  unreachable

1454:                                             ; preds = %1445
  %1455 = sub i64 %1438, %1447
  %1456 = ashr exact i64 %1455, 2
  %1457 = icmp ult i64 %1456, 2305843009213693951
  br i1 %1457, label %1458, label %1466

1458:                                             ; preds = %1454
  %1459 = ashr exact i64 %1455, 1
  %1460 = icmp ult i64 %1459, %1450
  %1461 = select i1 %1460, i64 %1450, i64 %1459
  %1462 = icmp eq i64 %1461, 0
  br i1 %1462, label %1471, label %1463

1463:                                             ; preds = %1458
  %1464 = icmp ugt i64 %1461, 4611686018427387903
  br i1 %1464, label %1465, label %1466

1465:                                             ; preds = %1463
  call void @abort() #19
  unreachable

1466:                                             ; preds = %1463, %1454
  %1467 = phi i64 [ %1461, %1463 ], [ 4611686018427387903, %1454 ]
  %1468 = shl i64 %1467, 2
  %1469 = call i8* @_Znwm(i64 %1468) #17
  %1470 = bitcast i8* %1469 to float*
  br label %1471

1471:                                             ; preds = %1466, %1458
  %1472 = phi i64 [ %1467, %1466 ], [ 0, %1458 ]
  %1473 = phi i8* [ %1469, %1466 ], [ null, %1458 ]
  %1474 = phi float* [ %1470, %1466 ], [ null, %1458 ]
  %1475 = getelementptr inbounds float, float* %1474, i64 %1449
  %1476 = getelementptr inbounds float, float* %1474, i64 %1472
  %1477 = ptrtoint float* %1476 to i64
  %1478 = bitcast float* %1475 to i32*
  store i32 964689920, i32* %1478, align 4
  %1479 = getelementptr inbounds float, float* %1475, i64 1
  %1480 = ptrtoint float* %1479 to i64
  %1481 = ptrtoint float* %1474 to i64
  %1482 = icmp sgt i64 %1448, 0
  br i1 %1482, label %1483, label %1485

1483:                                             ; preds = %1471
  %1484 = inttoptr i64 %1447 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1473, i8* align 4 %1484, i64 %1448, i1 false) #18
  br label %1485

1485:                                             ; preds = %1483, %1471
  store i64 %1481, i64* %1157, align 8
  store i64 %1480, i64* %1156, align 8
  store i64 %1477, i64* %1158, align 8
  %1486 = icmp eq i64 %1447, 0
  br i1 %1486, label %1489, label %1487

1487:                                             ; preds = %1485
  %1488 = inttoptr i64 %1447 to i8*
  call void @_ZdlPv(i8* %1488) #17
  br label %1489

1489:                                             ; preds = %1487, %1485, %1439
  %1490 = phi i64 [ %1444, %1439 ], [ %1299, %1485 ], [ %1299, %1487 ]
  %1491 = phi i32* [ %1443, %1439 ], [ %1298, %1485 ], [ %1298, %1487 ]
  %1492 = load i32*, i32** %1155, align 8
  %1493 = icmp ult i32* %1491, %1492
  %1494 = ptrtoint i32* %1492 to i64
  br i1 %1493, label %1495, label %1498

1495:                                             ; preds = %1489
  store i32 0, i32* %1491, align 4
  %1496 = getelementptr inbounds i32, i32* %1491, i64 1
  %1497 = ptrtoint i32* %1496 to i64
  store i64 %1497, i64* %1159, align 8
  br label %1545

1498:                                             ; preds = %1489
  %1499 = ptrtoint i32* %1491 to i64
  %1500 = load i64, i64* %1160, align 8
  %1501 = sub i64 %1499, %1500
  %1502 = ashr exact i64 %1501, 2
  %1503 = add nsw i64 %1502, 1
  %1504 = icmp ugt i64 %1503, 4611686018427387903
  br i1 %1504, label %1505, label %1507

1505:                                             ; preds = %1498
  %1506 = bitcast %"class.std::__1::vector.32"* %4 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %1506) #19
  unreachable

1507:                                             ; preds = %1498
  %1508 = sub i64 %1494, %1500
  %1509 = ashr exact i64 %1508, 2
  %1510 = icmp ult i64 %1509, 2305843009213693951
  br i1 %1510, label %1511, label %1519

1511:                                             ; preds = %1507
  %1512 = ashr exact i64 %1508, 1
  %1513 = icmp ult i64 %1512, %1503
  %1514 = select i1 %1513, i64 %1503, i64 %1512
  %1515 = icmp eq i64 %1514, 0
  br i1 %1515, label %1524, label %1516

1516:                                             ; preds = %1511
  %1517 = icmp ugt i64 %1514, 4611686018427387903
  br i1 %1517, label %1518, label %1519

1518:                                             ; preds = %1516
  call void @abort() #19
  unreachable

1519:                                             ; preds = %1516, %1507
  %1520 = phi i64 [ %1514, %1516 ], [ 4611686018427387903, %1507 ]
  %1521 = shl i64 %1520, 2
  %1522 = call i8* @_Znwm(i64 %1521) #17
  %1523 = bitcast i8* %1522 to i32*
  br label %1524

1524:                                             ; preds = %1519, %1511
  %1525 = phi i64 [ %1520, %1519 ], [ 0, %1511 ]
  %1526 = phi i32* [ %1523, %1519 ], [ null, %1511 ]
  %1527 = getelementptr inbounds i32, i32* %1526, i64 %1502
  %1528 = getelementptr inbounds i32, i32* %1526, i64 %1525
  %1529 = ptrtoint i32* %1528 to i64
  store i32 0, i32* %1527, align 4
  %1530 = getelementptr inbounds i32, i32* %1527, i64 1
  %1531 = ptrtoint i32* %1530 to i64
  %1532 = sub i64 %1490, %1500
  %1533 = ashr exact i64 %1532, 2
  %1534 = sub nsw i64 0, %1533
  %1535 = getelementptr inbounds i32, i32* %1527, i64 %1534
  %1536 = ptrtoint i32* %1535 to i64
  %1537 = icmp sgt i64 %1532, 0
  br i1 %1537, label %1538, label %1541

1538:                                             ; preds = %1524
  %1539 = bitcast i32* %1535 to i8*
  %1540 = inttoptr i64 %1500 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1539, i8* align 4 %1540, i64 %1532, i1 false) #18
  br label %1541

1541:                                             ; preds = %1538, %1524
  store i64 %1536, i64* %1160, align 8
  store i64 %1531, i64* %1159, align 8
  store i64 %1529, i64* %1161, align 8
  %1542 = icmp eq i64 %1500, 0
  br i1 %1542, label %1545, label %1543

1543:                                             ; preds = %1541
  %1544 = inttoptr i64 %1500 to i8*
  call void @_ZdlPv(i8* %1544) #17
  br label %1545

1545:                                             ; preds = %1543, %1541, %1495, %1432, %1430, %1384
  %1546 = phi i32* [ %1530, %1543 ], [ %1530, %1541 ], [ %1496, %1495 ], [ %1419, %1432 ], [ %1419, %1430 ], [ %1386, %1384 ]
  %1547 = phi i64 [ %1531, %1543 ], [ %1531, %1541 ], [ %1497, %1495 ], [ %1420, %1432 ], [ %1420, %1430 ], [ %1387, %1384 ]
  %1548 = add nuw nsw i64 %1300, 1
  %1549 = icmp eq i64 %1548, 4
  br i1 %1549, label %1162, label %1297

1550:                                             ; preds = %1295
  %1551 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %993, i64 0, i32 3, i32 0
  %1552 = load float, float* %1551, align 8
  %1553 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1029, i64 0, i32 3, i32 0
  %1554 = load float, float* %1553, align 8
  %1555 = insertelement <2 x float> undef, float %1552, i32 0
  %1556 = insertelement <2 x float> %1555, float %1554, i32 1
  br label %1557

1557:                                             ; preds = %1550, %1295
  %1558 = phi <2 x float> [ <float 1.000000e+00, float 1.000000e+00>, %1295 ], [ %1556, %1550 ]
  br i1 %1146, label %1559, label %1572

1559:                                             ; preds = %1557
  br i1 %1145, label %1563, label %1560

1560:                                             ; preds = %1559
  %1561 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1065, i64 0, i32 3, i32 0
  %1562 = load float, float* %1561, align 8
  br label %1563

1563:                                             ; preds = %1560, %1559
  %1564 = phi float [ 1.000000e+00, %1559 ], [ %1562, %1560 ]
  %1565 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1074, i64 0, i32 3, i32 0
  %1566 = load float, float* %1565, align 8
  %1567 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1083, i64 0, i32 3, i32 0
  %1568 = load float, float* %1567, align 8
  %1569 = insertelement <2 x float> undef, float %1566, i32 0
  %1570 = insertelement <2 x float> %1569, float %1568, i32 1
  %1571 = fpext <2 x float> %1570 to <2 x double>
  br label %1572

1572:                                             ; preds = %1563, %1557
  %1573 = phi float [ %1564, %1563 ], [ 1.000000e+00, %1557 ]
  %1574 = phi <2 x double> [ %1571, %1563 ], [ <double 1.000000e+00, double 1.000000e+00>, %1557 ]
  br i1 %974, label %1575, label %1587

1575:                                             ; preds = %1572
  br i1 %1145, label %1579, label %1576

1576:                                             ; preds = %1575
  %1577 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1092, i64 0, i32 3, i32 0
  %1578 = load float, float* %1577, align 8
  br label %1579

1579:                                             ; preds = %1576, %1575
  %1580 = phi float [ 1.000000e+00, %1575 ], [ %1578, %1576 ]
  %1581 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1101, i64 0, i32 3, i32 0
  %1582 = load float, float* %1581, align 8
  %1583 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1110, i64 0, i32 3, i32 0
  %1584 = load float, float* %1583, align 8
  %1585 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1119, i64 0, i32 3, i32 0
  %1586 = load float, float* %1585, align 8
  br label %1587

1587:                                             ; preds = %1579, %1572
  %1588 = phi float [ %1580, %1579 ], [ 1.000000e+00, %1572 ]
  %1589 = phi float [ %1582, %1579 ], [ 1.000000e+00, %1572 ]
  %1590 = phi float [ %1584, %1579 ], [ 1.000000e+00, %1572 ]
  %1591 = phi float [ %1586, %1579 ], [ 1.000000e+00, %1572 ]
  br i1 %1147, label %1595, label %1592

1592:                                             ; preds = %1587
  %1593 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1128, i64 0, i32 3, i32 0
  %1594 = load float, float* %1593, align 8
  br label %1595

1595:                                             ; preds = %1592, %1587
  %1596 = phi float [ %1594, %1592 ], [ 1.000000e+00, %1587 ]
  %1597 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1133, i64 %1134, i32 3, i32 0
  %1598 = load float, float* %1597, align 8
  %1599 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1002, i64 0, i32 3, i32 0
  %1600 = load float, float* %1599, align 8
  %1601 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1011, i64 0, i32 3, i32 0
  %1602 = load float, float* %1601, align 8
  %1603 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1020, i64 0, i32 3, i32 0
  %1604 = load float, float* %1603, align 8
  %1605 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1038, i64 0, i32 3, i32 0
  %1606 = load float, float* %1605, align 8
  %1607 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1047, i64 0, i32 3, i32 0
  %1608 = load float, float* %1607, align 8
  %1609 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1056, i64 0, i32 3, i32 0
  %1610 = load float, float* %1609, align 8
  %1611 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %916, i64 %917, i32 3, i32 0
  %1612 = load float, float* %1611, align 8
  %1613 = call zeroext i1 @_ZN6tflite11CheckedLog2EfPi(float %1612, i32* nonnull %5) #18
  br i1 %1613, label %1617, label %1614

1614:                                             ; preds = %1595
  %1615 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %1616 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %1615, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %1616(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 244, i8* getelementptr inbounds ([51 x i8], [51 x i8]* @.str.129, i64 0, i64 0)) #18
  br label %1777

1617:                                             ; preds = %1595
  %1618 = load i32, i32* %5, align 4
  %1619 = icmp slt i32 %1618, -8
  br i1 %1619, label %1623, label %1620

1620:                                             ; preds = %1617
  %1621 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %1622 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %1621, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %1622(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 245, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.130, i64 0, i64 0)) #18
  br label %1777

1623:                                             ; preds = %1617
  %1624 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 37
  store i32 %1618, i32* %1624, align 8
  %1625 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %984, i64 0, i32 3, i32 0
  %1626 = load float, float* %1625, align 8
  %1627 = load float*, float** %1149, align 8
  br i1 %1145, label %1637, label %1628

1628:                                             ; preds = %1623
  %1629 = load float, float* %1627, align 4
  %1630 = insertelement <2 x float> undef, float %1626, i32 0
  %1631 = insertelement <2 x float> %1630, float %1598, i32 1
  %1632 = fmul <2 x float> %1558, %1631
  %1633 = insertelement <2 x float> undef, float %1629, i32 0
  %1634 = shufflevector <2 x float> %1633, <2 x float> undef, <2 x i32> zeroinitializer
  %1635 = fdiv <2 x float> %1632, %1634
  %1636 = fpext <2 x float> %1635 to <2 x double>
  br label %1637

1637:                                             ; preds = %1623, %1628
  %1638 = phi <2 x double> [ %1636, %1628 ], [ <double 1.000000e+00, double 1.000000e+00>, %1623 ]
  %1639 = fmul float %1600, %1626
  %1640 = getelementptr inbounds float, float* %1627, i64 1
  %1641 = load float, float* %1640, align 4
  %1642 = fdiv float %1639, %1641
  %1643 = fmul float %1598, %1606
  %1644 = fdiv float %1643, %1641
  %1645 = fmul float %1602, %1626
  %1646 = getelementptr inbounds float, float* %1627, i64 2
  %1647 = load float, float* %1646, align 4
  %1648 = fdiv float %1645, %1647
  %1649 = fmul float %1598, %1608
  %1650 = fdiv float %1649, %1647
  %1651 = fmul float %1604, %1626
  %1652 = getelementptr inbounds float, float* %1627, i64 3
  %1653 = load float, float* %1652, align 4
  %1654 = fdiv float %1651, %1653
  %1655 = fmul float %1598, %1610
  %1656 = fdiv float %1655, %1653
  %1657 = getelementptr inbounds float, float* %1627, i64 4
  %1658 = load float, float* %1657, align 4
  %1659 = fpext float %1658 to double
  %1660 = fdiv double 0x3F00000000000000, %1659
  %1661 = fmul double %1660, 0x3F00000000000000
  %1662 = fptrunc double %1661 to float
  %1663 = fmul float %1596, %1658
  %1664 = fdiv float %1663, %1598
  br i1 %1146, label %1665, label %1697

1665:                                             ; preds = %1637
  br i1 %1145, label %1676, label %1666

1666:                                             ; preds = %1665
  %1667 = call double @ldexp(double 1.000000e+00, i32 %1618) #18
  %1668 = fpext float %1573 to double
  %1669 = fmul double %1667, %1668
  %1670 = load float*, float** %1149, align 8
  %1671 = load float, float* %1670, align 4
  %1672 = fpext float %1671 to double
  %1673 = fdiv double %1669, %1672
  %1674 = fptrunc double %1673 to float
  %1675 = load i32, i32* %5, align 4
  br label %1676

1676:                                             ; preds = %1666, %1665
  %1677 = phi i32 [ %1618, %1665 ], [ %1675, %1666 ]
  %1678 = phi float [ 1.000000e+00, %1665 ], [ %1674, %1666 ]
  %1679 = call double @ldexp(double 1.000000e+00, i32 %1677) #18
  %1680 = load float*, float** %1149, align 8
  %1681 = getelementptr inbounds float, float* %1680, i64 1
  %1682 = load float, float* %1681, align 4
  %1683 = load i32, i32* %5, align 4
  %1684 = call double @ldexp(double 1.000000e+00, i32 %1683) #18
  %1685 = insertelement <2 x double> undef, double %1679, i32 0
  %1686 = insertelement <2 x double> %1685, double %1684, i32 1
  %1687 = fmul <2 x double> %1574, %1686
  %1688 = load float*, float** %1149, align 8
  %1689 = getelementptr inbounds float, float* %1688, i64 3
  %1690 = load float, float* %1689, align 4
  %1691 = insertelement <2 x float> undef, float %1682, i32 0
  %1692 = insertelement <2 x float> %1691, float %1690, i32 1
  %1693 = fpext <2 x float> %1692 to <2 x double>
  %1694 = fdiv <2 x double> %1687, %1693
  %1695 = fptrunc <2 x double> %1694 to <2 x float>
  %1696 = fpext <2 x float> %1695 to <2 x double>
  br label %1697

1697:                                             ; preds = %1676, %1637
  %1698 = phi float [ %1678, %1676 ], [ 1.000000e+00, %1637 ]
  %1699 = phi <2 x double> [ %1696, %1676 ], [ <double 1.000000e+00, double 1.000000e+00>, %1637 ]
  %1700 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 0
  %1701 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 1
  %1702 = extractelement <2 x double> %1638, i32 0
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1702, i32* %1700, i32* %1701) #18
  %1703 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 2
  %1704 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 3
  %1705 = extractelement <2 x double> %1638, i32 1
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1705, i32* %1703, i32* %1704) #18
  %1706 = fpext float %1698 to double
  %1707 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 4
  %1708 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 5
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1706, i32* %1707, i32* %1708) #18
  %1709 = fpext float %1642 to double
  %1710 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 6
  %1711 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 7
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1709, i32* %1710, i32* %1711) #18
  %1712 = fpext float %1644 to double
  %1713 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 8
  %1714 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 9
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1712, i32* %1713, i32* %1714) #18
  %1715 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 10
  %1716 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 11
  %1717 = extractelement <2 x double> %1699, i32 0
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1717, i32* %1715, i32* %1716) #18
  %1718 = fpext float %1648 to double
  %1719 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 12
  %1720 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 13
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1718, i32* %1719, i32* %1720) #18
  %1721 = fpext float %1650 to double
  %1722 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 14
  %1723 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 15
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1721, i32* %1722, i32* %1723) #18
  %1724 = fpext float %1654 to double
  %1725 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 16
  %1726 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 17
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1724, i32* %1725, i32* %1726) #18
  %1727 = fpext float %1656 to double
  %1728 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 18
  %1729 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 19
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1727, i32* %1728, i32* %1729) #18
  %1730 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 20
  %1731 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 21
  %1732 = extractelement <2 x double> %1699, i32 1
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1732, i32* %1730, i32* %1731) #18
  %1733 = fpext float %1664 to double
  %1734 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 22
  %1735 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 23
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1733, i32* %1734, i32* %1735) #18
  %1736 = fpext float %1662 to double
  %1737 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 24
  %1738 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 25
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1736, i32* %1737, i32* %1738) #18
  %1739 = fpext float %1588 to double
  %1740 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 26
  %1741 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 27
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1739, i32* %1740, i32* %1741) #18
  %1742 = fpext float %1589 to double
  %1743 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 28
  %1744 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 29
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1742, i32* %1743, i32* %1744) #18
  %1745 = fpext float %1590 to double
  %1746 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 30
  %1747 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 31
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1745, i32* %1746, i32* %1747) #18
  %1748 = fpext float %1591 to double
  %1749 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 32
  %1750 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 33
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %1748, i32* %1749, i32* %1750) #18
  %1751 = load i32*, i32** %1153, align 8
  %1752 = getelementptr inbounds i32, i32* %1751, i64 4
  %1753 = load i32, i32* %1752, align 4
  %1754 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 36
  store i32 %1753, i32* %1754, align 4
  br i1 %1145, label %1761, label %1755

1755:                                             ; preds = %1697
  %1756 = fmul float %1588, 1.000000e+04
  %1757 = fptosi float %1756 to i32
  %1758 = icmp sgt i32 %1757, 1
  %1759 = select i1 %1758, i32 %1757, i32 1
  %1760 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 38
  store i32 %1759, i32* %1760, align 4
  br label %1761

1761:                                             ; preds = %1755, %1697
  %1762 = fmul float %1589, 1.000000e+04
  %1763 = fptosi float %1762 to i32
  %1764 = icmp sgt i32 %1763, 1
  %1765 = select i1 %1764, i32 %1763, i32 1
  %1766 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 39
  store i32 %1765, i32* %1766, align 8
  %1767 = fmul float %1590, 1.000000e+04
  %1768 = fptosi float %1767 to i32
  %1769 = icmp sgt i32 %1768, 1
  %1770 = select i1 %1769, i32 %1768, i32 1
  %1771 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 40
  store i32 %1770, i32* %1771, align 4
  %1772 = fmul float %1591, 1.000000e+04
  %1773 = fptosi float %1772 to i32
  %1774 = icmp sgt i32 %1773, 1
  %1775 = select i1 %1774, i32 %1773, i32 1
  %1776 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 41
  store i32 %1775, i32* %1776, align 8
  br label %1777

1777:                                             ; preds = %1761, %1620, %1614
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %1296) #18
  %1778 = load i32*, i32** %1153, align 8
  %1779 = icmp eq i32* %1778, null
  br i1 %1779, label %1783, label %1780

1780:                                             ; preds = %1777
  %1781 = ptrtoint i32* %1778 to i64
  store i64 %1781, i64* %1159, align 8
  %1782 = bitcast i32* %1778 to i8*
  call void @_ZdlPv(i8* %1782) #17
  br label %1783

1783:                                             ; preds = %1780, %1777
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %1152) #18
  %1784 = load float*, float** %1149, align 8
  %1785 = icmp eq float* %1784, null
  br i1 %1785, label %1789, label %1786

1786:                                             ; preds = %1783
  %1787 = ptrtoint float* %1784 to i64
  store i64 %1787, i64* %1156, align 8
  %1788 = bitcast float* %1784 to i8*
  call void @_ZdlPv(i8* %1788) #17
  br label %1789

1789:                                             ; preds = %1786, %1783
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %1148) #18
  br label %1790

1790:                                             ; preds = %924, %1141, %1789
  %1791 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 3
  %1792 = bitcast [2 x i32]* %12 to i8*
  %1793 = getelementptr inbounds [2 x i32], [2 x i32]* %12, i64 0, i64 0
  %1794 = getelementptr inbounds [2 x i32], [2 x i32]* %12, i64 0, i64 1
  br label %1795

1795:                                             ; preds = %1829, %1790
  %1796 = phi i64 [ 0, %1790 ], [ %1830, %1829 ]
  %1797 = load i32, i32* %1791, align 8
  %1798 = trunc i64 %1796 to i32
  %1799 = add nsw i32 %1797, %1798
  %1800 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %1801 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1800, i64 0, i32 1, i64 %1796
  store i32 %1799, i32* %1801, align 4
  %1802 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %1803 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1802, i64 0, i32 1, i64 %1796
  %1804 = load i32, i32* %1803, align 4
  %1805 = icmp slt i32 %1804, 0
  br i1 %1805, label %1810, label %1806

1806:                                             ; preds = %1795
  %1807 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1808 = sext i32 %1804 to i64
  %1809 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1807, i64 %1808
  br label %1810

1810:                                             ; preds = %1795, %1806
  %1811 = phi %struct.TfLiteTensor* [ %1809, %1806 ], [ null, %1795 ]
  %1812 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1811, i64 0, i32 0
  store i32 7, i32* %1812, align 8
  switch i32 %1798, label %1816 [
    i32 4, label %1814
    i32 5, label %1813
  ]

1813:                                             ; preds = %1810
  br label %1814

1814:                                             ; preds = %1810, %1813
  %1815 = phi i32 [ 2, %1813 ], [ 9, %1810 ]
  store i32 %1815, i32* %1812, align 8
  br label %1816

1816:                                             ; preds = %1814, %1810
  %1817 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1811, i64 0, i32 4
  store i32 2, i32* %1817, align 8
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1792) #18
  store i32 %76, i32* %1793, align 4
  store i32 %92, i32* %1794, align 4
  %1818 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1811, i64 0, i32 2
  %1819 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %1818, align 8
  %1820 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %1819, i32 2, i32* nonnull %1793) #18
  %1821 = icmp eq i32 %1820, 0
  br i1 %1821, label %1822, label %1829

1822:                                             ; preds = %1816
  %1823 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #18
  %1824 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1823, i64 0, i32 1, i64 0
  store i32 %76, i32* %1824, align 4
  %1825 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1823, i64 0, i32 1, i64 1
  store i32 %92, i32* %1825, align 4
  %1826 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %1827 = call i32 %1826(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %1811, %struct.TfLiteIntArray* %1823) #18
  %1828 = icmp eq i32 %1827, 0
  br i1 %1828, label %1829, label %1832

1829:                                             ; preds = %1822, %1816
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1792) #18
  %1830 = add nuw nsw i64 %1796, 1
  %1831 = icmp eq i64 %1830, 6
  br i1 %1831, label %1833, label %1795

1832:                                             ; preds = %1822
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1792) #18
  br label %2453

1833:                                             ; preds = %1829
  %1834 = call i32 @_ZN6tflite3ops7builtin4lstm4full41PopulatePrecomputedZPTimesWeightsWithBiasEP13TfLiteContextPNS2_6OpDataEP10TfLiteNode(%struct.TfLiteContext* %0, %"struct.tflite::ops::builtin::lstm::OpData"* %16, %struct.TfLiteNode* %1)
  %1835 = icmp eq i32 %1834, 0
  br i1 %1835, label %2452, label %2453

1836:                                             ; preds = %521, %902
  %1837 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %1838 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 0
  %1839 = load i32, i32* %1838, align 4
  %1840 = icmp slt i32 %1839, 0
  br i1 %1840, label %1845, label %1841

1841:                                             ; preds = %1836
  %1842 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1843 = sext i32 %1839 to i64
  %1844 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1842, i64 %1843
  br label %1845

1845:                                             ; preds = %1841, %1836
  %1846 = phi %struct.TfLiteTensor* [ %1844, %1841 ], [ null, %1836 ]
  %1847 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 1
  %1848 = load i32, i32* %1847, align 4
  %1849 = icmp slt i32 %1848, 0
  br i1 %1849, label %1854, label %1850

1850:                                             ; preds = %1845
  %1851 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1852 = sext i32 %1848 to i64
  %1853 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1851, i64 %1852
  br label %1854

1854:                                             ; preds = %1850, %1845
  %1855 = phi %struct.TfLiteTensor* [ %1853, %1850 ], [ null, %1845 ]
  %1856 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 2
  %1857 = load i32, i32* %1856, align 4
  %1858 = icmp slt i32 %1857, 0
  br i1 %1858, label %1863, label %1859

1859:                                             ; preds = %1854
  %1860 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1861 = sext i32 %1857 to i64
  %1862 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1860, i64 %1861
  br label %1863

1863:                                             ; preds = %1859, %1854
  %1864 = phi %struct.TfLiteTensor* [ %1862, %1859 ], [ null, %1854 ]
  %1865 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 3
  %1866 = load i32, i32* %1865, align 4
  %1867 = icmp slt i32 %1866, 0
  br i1 %1867, label %1872, label %1868

1868:                                             ; preds = %1863
  %1869 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1870 = sext i32 %1866 to i64
  %1871 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1869, i64 %1870
  br label %1872

1872:                                             ; preds = %1868, %1863
  %1873 = phi %struct.TfLiteTensor* [ %1871, %1868 ], [ null, %1863 ]
  %1874 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 4
  %1875 = load i32, i32* %1874, align 4
  %1876 = icmp slt i32 %1875, 0
  br i1 %1876, label %1881, label %1877

1877:                                             ; preds = %1872
  %1878 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1879 = sext i32 %1875 to i64
  %1880 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1878, i64 %1879
  br label %1881

1881:                                             ; preds = %1877, %1872
  %1882 = phi %struct.TfLiteTensor* [ %1880, %1877 ], [ null, %1872 ]
  %1883 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 5
  %1884 = load i32, i32* %1883, align 4
  %1885 = icmp slt i32 %1884, 0
  br i1 %1885, label %1890, label %1886

1886:                                             ; preds = %1881
  %1887 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1888 = sext i32 %1884 to i64
  %1889 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1887, i64 %1888
  br label %1890

1890:                                             ; preds = %1886, %1881
  %1891 = phi %struct.TfLiteTensor* [ %1889, %1886 ], [ null, %1881 ]
  %1892 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 6
  %1893 = load i32, i32* %1892, align 4
  %1894 = icmp slt i32 %1893, 0
  br i1 %1894, label %1899, label %1895

1895:                                             ; preds = %1890
  %1896 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1897 = sext i32 %1893 to i64
  %1898 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1896, i64 %1897
  br label %1899

1899:                                             ; preds = %1895, %1890
  %1900 = phi %struct.TfLiteTensor* [ %1898, %1895 ], [ null, %1890 ]
  %1901 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 7
  %1902 = load i32, i32* %1901, align 4
  %1903 = icmp slt i32 %1902, 0
  br i1 %1903, label %1908, label %1904

1904:                                             ; preds = %1899
  %1905 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1906 = sext i32 %1902 to i64
  %1907 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1905, i64 %1906
  br label %1908

1908:                                             ; preds = %1904, %1899
  %1909 = phi %struct.TfLiteTensor* [ %1907, %1904 ], [ null, %1899 ]
  %1910 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 8
  %1911 = load i32, i32* %1910, align 4
  %1912 = icmp slt i32 %1911, 0
  br i1 %1912, label %1917, label %1913

1913:                                             ; preds = %1908
  %1914 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1915 = sext i32 %1911 to i64
  %1916 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1914, i64 %1915
  br label %1917

1917:                                             ; preds = %1913, %1908
  %1918 = phi %struct.TfLiteTensor* [ %1916, %1913 ], [ null, %1908 ]
  %1919 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 9
  %1920 = load i32, i32* %1919, align 4
  %1921 = icmp slt i32 %1920, 0
  br i1 %1921, label %1926, label %1922

1922:                                             ; preds = %1917
  %1923 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1924 = sext i32 %1920 to i64
  %1925 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1923, i64 %1924
  br label %1926

1926:                                             ; preds = %1922, %1917
  %1927 = phi %struct.TfLiteTensor* [ %1925, %1922 ], [ null, %1917 ]
  %1928 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 10
  %1929 = load i32, i32* %1928, align 4
  %1930 = icmp slt i32 %1929, 0
  br i1 %1930, label %1935, label %1931

1931:                                             ; preds = %1926
  %1932 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1933 = sext i32 %1929 to i64
  %1934 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1932, i64 %1933
  br label %1935

1935:                                             ; preds = %1931, %1926
  %1936 = phi %struct.TfLiteTensor* [ %1934, %1931 ], [ null, %1926 ]
  %1937 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 11
  %1938 = load i32, i32* %1937, align 4
  %1939 = icmp slt i32 %1938, 0
  br i1 %1939, label %1944, label %1940

1940:                                             ; preds = %1935
  %1941 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1942 = sext i32 %1938 to i64
  %1943 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1941, i64 %1942
  br label %1944

1944:                                             ; preds = %1940, %1935
  %1945 = phi %struct.TfLiteTensor* [ %1943, %1940 ], [ null, %1935 ]
  %1946 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 20
  %1947 = load i32, i32* %1946, align 4
  %1948 = icmp slt i32 %1947, 0
  br i1 %1948, label %1953, label %1949

1949:                                             ; preds = %1944
  %1950 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1951 = sext i32 %1947 to i64
  %1952 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1950, i64 %1951
  br label %1953

1953:                                             ; preds = %1949, %1944
  %1954 = phi %struct.TfLiteTensor* [ %1952, %1949 ], [ null, %1944 ]
  %1955 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 21
  %1956 = load i32, i32* %1955, align 4
  %1957 = icmp slt i32 %1956, 0
  br i1 %1957, label %1962, label %1958

1958:                                             ; preds = %1953
  %1959 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1960 = sext i32 %1956 to i64
  %1961 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1959, i64 %1960
  br label %1962

1962:                                             ; preds = %1958, %1953
  %1963 = phi %struct.TfLiteTensor* [ %1961, %1958 ], [ null, %1953 ]
  %1964 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 22
  %1965 = load i32, i32* %1964, align 4
  %1966 = icmp slt i32 %1965, 0
  br i1 %1966, label %1971, label %1967

1967:                                             ; preds = %1962
  %1968 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1969 = sext i32 %1965 to i64
  %1970 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1968, i64 %1969
  br label %1971

1971:                                             ; preds = %1967, %1962
  %1972 = phi %struct.TfLiteTensor* [ %1970, %1967 ], [ null, %1962 ]
  %1973 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 23
  %1974 = load i32, i32* %1973, align 4
  %1975 = icmp slt i32 %1974, 0
  br i1 %1975, label %1980, label %1976

1976:                                             ; preds = %1971
  %1977 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1978 = sext i32 %1974 to i64
  %1979 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1977, i64 %1978
  br label %1980

1980:                                             ; preds = %1976, %1971
  %1981 = phi %struct.TfLiteTensor* [ %1979, %1976 ], [ null, %1971 ]
  %1982 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 16
  %1983 = load i32, i32* %1982, align 4
  %1984 = icmp slt i32 %1983, 0
  br i1 %1984, label %1989, label %1985

1985:                                             ; preds = %1980
  %1986 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1987 = sext i32 %1983 to i64
  %1988 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1986, i64 %1987
  br label %1989

1989:                                             ; preds = %1985, %1980
  %1990 = phi %struct.TfLiteTensor* [ %1988, %1985 ], [ null, %1980 ]
  %1991 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 18
  %1992 = load i32, i32* %1991, align 4
  %1993 = icmp slt i32 %1992, 0
  br i1 %1993, label %2003, label %1994

1994:                                             ; preds = %1989
  %1995 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %1996 = sext i32 %1992 to i64
  %1997 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1995, i64 %1996
  %1998 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1995, i64 %1996, i32 11
  %1999 = load i8, i8* %1998, align 1, !range !5
  %2000 = icmp eq i8 %1999, 0
  %2001 = icmp eq %struct.TfLiteTensor* %1997, null
  %2002 = or i1 %2000, %2001
  br i1 %2002, label %2003, label %2006

2003:                                             ; preds = %1994, %1989
  %2004 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %2005 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %2004, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %2005(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 422, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.93, i64 0, i64 0)) #18
  br label %2411

2006:                                             ; preds = %1994
  %2007 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1837, i64 0, i32 1, i64 19
  %2008 = load i32, i32* %2007, align 4
  %2009 = icmp slt i32 %2008, 0
  br i1 %2009, label %2018, label %2010

2010:                                             ; preds = %2006
  %2011 = sext i32 %2008 to i64
  %2012 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1995, i64 %2011
  %2013 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1995, i64 %2011, i32 11
  %2014 = load i8, i8* %2013, align 1, !range !5
  %2015 = icmp eq i8 %2014, 0
  %2016 = icmp eq %struct.TfLiteTensor* %2012, null
  %2017 = or i1 %2016, %2015
  br i1 %2017, label %2018, label %2021

2018:                                             ; preds = %2010, %2006
  %2019 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %2020 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %2019, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %2020(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 424, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.101, i64 0, i64 0)) #18
  br label %2411

2021:                                             ; preds = %2010
  %2022 = icmp eq %struct.TfLiteTensor* %1855, null
  %2023 = icmp ne %struct.TfLiteTensor* %1945, null
  %2024 = icmp eq %struct.TfLiteTensor* %1963, null
  %2025 = icmp eq %struct.TfLiteTensor* %1990, null
  br i1 %2022, label %2033, label %2026

2026:                                             ; preds = %2021
  %2027 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1855, i64 0, i32 3, i32 0
  %2028 = load float, float* %2027, align 8
  %2029 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1891, i64 0, i32 3, i32 0
  %2030 = load float, float* %2029, align 8
  %2031 = insertelement <2 x float> undef, float %2028, i32 0
  %2032 = insertelement <2 x float> %2031, float %2030, i32 1
  br label %2033

2033:                                             ; preds = %2026, %2021
  %2034 = phi <2 x float> [ <float 1.000000e+00, float 1.000000e+00>, %2021 ], [ %2032, %2026 ]
  br i1 %2023, label %2035, label %2049

2035:                                             ; preds = %2033
  br i1 %2022, label %2039, label %2036

2036:                                             ; preds = %2035
  %2037 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1927, i64 0, i32 3, i32 0
  %2038 = load float, float* %2037, align 8
  br label %2039

2039:                                             ; preds = %2036, %2035
  %2040 = phi float [ 1.000000e+00, %2035 ], [ %2038, %2036 ]
  %2041 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1936, i64 0, i32 3, i32 0
  %2042 = load float, float* %2041, align 8
  %2043 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1945, i64 0, i32 3, i32 0
  %2044 = load float, float* %2043, align 8
  %2045 = insertelement <2 x float> undef, float %2042, i32 0
  %2046 = insertelement <2 x float> %2045, float %2044, i32 1
  %2047 = fpext <2 x float> %2046 to <2 x double>
  %2048 = fmul <2 x double> %2047, <double 0x3F00000000000000, double 0x3F00000000000000>
  br label %2049

2049:                                             ; preds = %2039, %2033
  %2050 = phi float [ %2040, %2039 ], [ 1.000000e+00, %2033 ]
  %2051 = phi <2 x double> [ %2048, %2039 ], [ <double 0x3F00000000000000, double 0x3F00000000000000>, %2033 ]
  br i1 %2024, label %2067, label %2052

2052:                                             ; preds = %2049
  br i1 %2022, label %2056, label %2053

2053:                                             ; preds = %2052
  %2054 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1954, i64 0, i32 3, i32 0
  %2055 = load float, float* %2054, align 8
  br label %2056

2056:                                             ; preds = %2053, %2052
  %2057 = phi float [ 1.000000e+00, %2052 ], [ %2055, %2053 ]
  %2058 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1963, i64 0, i32 3, i32 0
  %2059 = load float, float* %2058, align 8
  %2060 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1972, i64 0, i32 3, i32 0
  %2061 = load float, float* %2060, align 8
  %2062 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1981, i64 0, i32 3, i32 0
  %2063 = load float, float* %2062, align 8
  %2064 = fpext float %2059 to double
  %2065 = fpext float %2061 to double
  %2066 = fpext float %2063 to double
  br label %2067

2067:                                             ; preds = %2056, %2049
  %2068 = phi float [ %2057, %2056 ], [ 1.000000e+00, %2049 ]
  %2069 = phi double [ %2064, %2056 ], [ 1.000000e+00, %2049 ]
  %2070 = phi double [ %2065, %2056 ], [ 1.000000e+00, %2049 ]
  %2071 = phi double [ %2066, %2056 ], [ 1.000000e+00, %2049 ]
  br i1 %2025, label %2077, label %2072

2072:                                             ; preds = %2067
  %2073 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1990, i64 0, i32 3, i32 0
  %2074 = load float, float* %2073, align 8
  %2075 = fpext float %2074 to double
  %2076 = fmul double %2075, 0x3F00000000000000
  br label %2077

2077:                                             ; preds = %2072, %2067
  %2078 = phi double [ 0x3F00000000000000, %2067 ], [ %2076, %2072 ]
  %2079 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1995, i64 %1996, i32 3, i32 0
  %2080 = load float, float* %2079, align 8
  %2081 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1864, i64 0, i32 3, i32 0
  %2082 = load float, float* %2081, align 8
  %2083 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1873, i64 0, i32 3, i32 0
  %2084 = load float, float* %2083, align 8
  %2085 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1882, i64 0, i32 3, i32 0
  %2086 = load float, float* %2085, align 8
  %2087 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1900, i64 0, i32 3, i32 0
  %2088 = load float, float* %2087, align 8
  %2089 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1909, i64 0, i32 3, i32 0
  %2090 = load float, float* %2089, align 8
  %2091 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1918, i64 0, i32 3, i32 0
  %2092 = load float, float* %2091, align 8
  %2093 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1846, i64 0, i32 3, i32 0
  %2094 = load float, float* %2093, align 8
  %2095 = bitcast %"class.std::__1::vector.25"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %2095) #18
  %2096 = getelementptr inbounds %"class.std::__1::vector.25", %"class.std::__1::vector.25"* %6, i64 0, i32 0, i32 0
  %2097 = getelementptr inbounds %"class.std::__1::vector.25", %"class.std::__1::vector.25"* %6, i64 0, i32 0, i32 1
  %2098 = getelementptr inbounds %"class.std::__1::vector.25", %"class.std::__1::vector.25"* %6, i64 0, i32 0, i32 2, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %2095, i8 0, i64 24, i1 false) #18
  %2099 = bitcast float** %2097 to i64*
  %2100 = bitcast %"class.std::__1::vector.25"* %6 to i64*
  %2101 = bitcast float** %2098 to i64*
  br label %2104

2102:                                             ; preds = %2175
  %2103 = load float*, float** %2096, align 8
  br i1 %2022, label %2197, label %2188

2104:                                             ; preds = %2185, %2077
  %2105 = phi i64 [ 0, %2077 ], [ %2176, %2185 ]
  %2106 = phi float* [ null, %2077 ], [ %2187, %2185 ]
  %2107 = phi float* [ null, %2077 ], [ %2177, %2185 ]
  %2108 = phi %struct.TfLiteTensor* [ %1995, %2077 ], [ %2186, %2185 ]
  %2109 = phi i64 [ 0, %2077 ], [ %2183, %2185 ]
  %2110 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %505, align 8
  %2111 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %2110, i64 0, i32 1, i64 %2109
  %2112 = load i32, i32* %2111, align 4
  %2113 = sext i32 %2112 to i64
  %2114 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2108, i64 %2113, i32 12, i32 1
  %2115 = bitcast i8** %2114 to %struct.TfLiteAffineQuantization**
  %2116 = load %struct.TfLiteAffineQuantization*, %struct.TfLiteAffineQuantization** %2115, align 8
  %2117 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %2116, i64 0, i32 0
  %2118 = load %struct.TfLiteFloatArray*, %struct.TfLiteFloatArray** %2117, align 8
  %2119 = getelementptr inbounds %struct.TfLiteFloatArray, %struct.TfLiteFloatArray* %2118, i64 0, i32 1, i64 0
  %2120 = icmp eq float* %2107, %2106
  br i1 %2120, label %2127, label %2121

2121:                                             ; preds = %2104
  %2122 = bitcast float* %2119 to i32*
  %2123 = load i32, i32* %2122, align 4
  %2124 = bitcast float* %2107 to i32*
  store i32 %2123, i32* %2124, align 4
  %2125 = getelementptr inbounds float, float* %2107, i64 1
  %2126 = ptrtoint float* %2125 to i64
  store i64 %2126, i64* %2099, align 8
  br label %2175

2127:                                             ; preds = %2104
  %2128 = ptrtoint float* %2106 to i64
  %2129 = load i64, i64* %2100, align 8
  %2130 = sub i64 %2128, %2129
  %2131 = ashr exact i64 %2130, 2
  %2132 = add nsw i64 %2131, 1
  %2133 = icmp ugt i64 %2132, 4611686018427387903
  br i1 %2133, label %2134, label %2136

2134:                                             ; preds = %2127
  %2135 = bitcast %"class.std::__1::vector.25"* %6 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %2135) #19
  unreachable

2136:                                             ; preds = %2127
  %2137 = icmp ult i64 %2131, 2305843009213693951
  br i1 %2137, label %2138, label %2146

2138:                                             ; preds = %2136
  %2139 = ashr exact i64 %2130, 1
  %2140 = icmp ult i64 %2139, %2132
  %2141 = select i1 %2140, i64 %2132, i64 %2139
  %2142 = icmp eq i64 %2141, 0
  br i1 %2142, label %2151, label %2143

2143:                                             ; preds = %2138
  %2144 = icmp ugt i64 %2141, 4611686018427387903
  br i1 %2144, label %2145, label %2146

2145:                                             ; preds = %2143
  call void @abort() #19
  unreachable

2146:                                             ; preds = %2143, %2136
  %2147 = phi i64 [ %2141, %2143 ], [ 4611686018427387903, %2136 ]
  %2148 = shl i64 %2147, 2
  %2149 = call i8* @_Znwm(i64 %2148) #17
  %2150 = bitcast i8* %2149 to float*
  br label %2151

2151:                                             ; preds = %2146, %2138
  %2152 = phi i64 [ %2147, %2146 ], [ 0, %2138 ]
  %2153 = phi float* [ %2150, %2146 ], [ null, %2138 ]
  %2154 = getelementptr inbounds float, float* %2153, i64 %2131
  %2155 = getelementptr inbounds float, float* %2153, i64 %2152
  %2156 = ptrtoint float* %2155 to i64
  %2157 = bitcast float* %2119 to i32*
  %2158 = load i32, i32* %2157, align 4
  %2159 = bitcast float* %2154 to i32*
  store i32 %2158, i32* %2159, align 4
  %2160 = getelementptr inbounds float, float* %2154, i64 1
  %2161 = ptrtoint float* %2160 to i64
  %2162 = sub i64 %2105, %2129
  %2163 = ashr exact i64 %2162, 2
  %2164 = sub nsw i64 0, %2163
  %2165 = getelementptr inbounds float, float* %2154, i64 %2164
  %2166 = ptrtoint float* %2165 to i64
  %2167 = icmp sgt i64 %2162, 0
  br i1 %2167, label %2168, label %2171

2168:                                             ; preds = %2151
  %2169 = bitcast float* %2165 to i8*
  %2170 = inttoptr i64 %2129 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %2169, i8* align 4 %2170, i64 %2162, i1 false) #18
  br label %2171

2171:                                             ; preds = %2168, %2151
  store i64 %2166, i64* %2100, align 8
  store i64 %2161, i64* %2099, align 8
  store i64 %2156, i64* %2101, align 8
  %2172 = icmp eq i64 %2129, 0
  br i1 %2172, label %2175, label %2173

2173:                                             ; preds = %2171
  %2174 = inttoptr i64 %2129 to i8*
  call void @_ZdlPv(i8* %2174) #17
  br label %2175

2175:                                             ; preds = %2173, %2171, %2121
  %2176 = phi i64 [ %2126, %2121 ], [ %2161, %2171 ], [ %2161, %2173 ]
  %2177 = phi float* [ %2125, %2121 ], [ %2160, %2171 ], [ %2160, %2173 ]
  %2178 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %2116, i64 0, i32 1
  %2179 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %2178, align 8
  %2180 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %2179, i64 0, i32 1, i64 0
  %2181 = load i32, i32* %2180, align 4
  %2182 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 53, i64 %2109
  store i32 %2181, i32* %2182, align 4
  %2183 = add nuw nsw i64 %2109, 1
  %2184 = icmp eq i64 %2183, 12
  br i1 %2184, label %2102, label %2185

2185:                                             ; preds = %2175
  %2186 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %2187 = load float*, float** %2098, align 8
  br label %2104

2188:                                             ; preds = %2102
  %2189 = getelementptr inbounds float, float* %2103, i64 1
  %2190 = insertelement <2 x float> undef, float %2094, i32 0
  %2191 = insertelement <2 x float> %2190, float %2080, i32 1
  %2192 = fmul <2 x float> %2034, %2191
  %2193 = bitcast float* %2189 to <2 x float>*
  %2194 = load <2 x float>, <2 x float>* %2193, align 4
  %2195 = fdiv <2 x float> %2192, %2194
  %2196 = fpext <2 x float> %2195 to <2 x double>
  br label %2197

2197:                                             ; preds = %2102, %2188
  %2198 = phi <2 x double> [ %2196, %2188 ], [ <double 1.000000e+00, double 1.000000e+00>, %2102 ]
  %2199 = fmul float %2082, %2094
  %2200 = getelementptr inbounds float, float* %2103, i64 4
  %2201 = load float, float* %2200, align 4
  %2202 = fdiv float %2199, %2201
  %2203 = fmul float %2080, %2088
  %2204 = getelementptr inbounds float, float* %2103, i64 5
  %2205 = load float, float* %2204, align 4
  %2206 = fdiv float %2203, %2205
  %2207 = fmul float %2084, %2094
  %2208 = getelementptr inbounds float, float* %2103, i64 7
  %2209 = load float, float* %2208, align 4
  %2210 = fdiv float %2207, %2209
  %2211 = fmul float %2080, %2090
  %2212 = getelementptr inbounds float, float* %2103, i64 8
  %2213 = load float, float* %2212, align 4
  %2214 = fdiv float %2211, %2213
  %2215 = fmul float %2086, %2094
  %2216 = getelementptr inbounds float, float* %2103, i64 10
  %2217 = load float, float* %2216, align 4
  %2218 = fdiv float %2215, %2217
  %2219 = fmul float %2080, %2092
  %2220 = getelementptr inbounds float, float* %2103, i64 11
  %2221 = load float, float* %2220, align 4
  %2222 = fdiv float %2219, %2221
  %2223 = fpext float %2080 to double
  %2224 = fdiv double %2078, %2223
  %2225 = fptrunc double %2224 to float
  br i1 %2023, label %2226, label %2246

2226:                                             ; preds = %2197
  br i1 %2022, label %2234, label %2227

2227:                                             ; preds = %2226
  %2228 = fpext float %2050 to double
  %2229 = fmul double %2228, 0x3F00000000000000
  %2230 = load float, float* %2103, align 4
  %2231 = fpext float %2230 to double
  %2232 = fdiv double %2229, %2231
  %2233 = fptrunc double %2232 to float
  br label %2234

2234:                                             ; preds = %2227, %2226
  %2235 = phi float [ 1.000000e+00, %2226 ], [ %2233, %2227 ]
  %2236 = getelementptr inbounds float, float* %2103, i64 3
  %2237 = load float, float* %2236, align 4
  %2238 = getelementptr inbounds float, float* %2103, i64 9
  %2239 = load float, float* %2238, align 4
  %2240 = insertelement <2 x float> undef, float %2237, i32 0
  %2241 = insertelement <2 x float> %2240, float %2239, i32 1
  %2242 = fpext <2 x float> %2241 to <2 x double>
  %2243 = fdiv <2 x double> %2051, %2242
  %2244 = fptrunc <2 x double> %2243 to <2 x float>
  %2245 = fpext <2 x float> %2244 to <2 x double>
  br label %2246

2246:                                             ; preds = %2234, %2197
  %2247 = phi float [ %2235, %2234 ], [ 1.000000e+00, %2197 ]
  %2248 = phi <2 x double> [ %2245, %2234 ], [ <double 1.000000e+00, double 1.000000e+00>, %2197 ]
  %2249 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 0
  %2250 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 1
  %2251 = extractelement <2 x double> %2198, i32 0
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2251, i32* %2249, i32* %2250) #18
  %2252 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 2
  %2253 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 3
  %2254 = extractelement <2 x double> %2198, i32 1
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2254, i32* %2252, i32* %2253) #18
  %2255 = fpext float %2247 to double
  %2256 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 4
  %2257 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 5
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2255, i32* %2256, i32* %2257) #18
  %2258 = fpext float %2202 to double
  %2259 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 6
  %2260 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 7
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2258, i32* %2259, i32* %2260) #18
  %2261 = fpext float %2206 to double
  %2262 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 8
  %2263 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 9
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2261, i32* %2262, i32* %2263) #18
  %2264 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 10
  %2265 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 11
  %2266 = extractelement <2 x double> %2248, i32 0
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2266, i32* %2264, i32* %2265) #18
  %2267 = fpext float %2210 to double
  %2268 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 12
  %2269 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 13
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2267, i32* %2268, i32* %2269) #18
  %2270 = fpext float %2214 to double
  %2271 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 14
  %2272 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 15
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2270, i32* %2271, i32* %2272) #18
  %2273 = fpext float %2218 to double
  %2274 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 16
  %2275 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 17
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2273, i32* %2274, i32* %2275) #18
  %2276 = fpext float %2222 to double
  %2277 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 18
  %2278 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 19
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2276, i32* %2277, i32* %2278) #18
  %2279 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 20
  %2280 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 21
  %2281 = extractelement <2 x double> %2248, i32 1
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2281, i32* %2279, i32* %2280) #18
  %2282 = fpext float %2225 to double
  %2283 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 22
  %2284 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 23
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2282, i32* %2283, i32* %2284) #18
  %2285 = fpext float %2068 to double
  %2286 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 26
  %2287 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 27
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2285, i32* %2286, i32* %2287) #18
  %2288 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 28
  %2289 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 29
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2069, i32* %2288, i32* %2289) #18
  %2290 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 30
  %2291 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 31
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2070, i32* %2290, i32* %2291) #18
  %2292 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 32
  %2293 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 33
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2071, i32* %2292, i32* %2293) #18
  %2294 = getelementptr inbounds float, float* %2103, i64 1
  %2295 = load float, float* %2294, align 4
  %2296 = load float, float* %2103, align 4
  %2297 = fdiv float %2295, %2296
  %2298 = getelementptr inbounds float, float* %2103, i64 2
  %2299 = load float, float* %2298, align 4
  %2300 = fdiv float %2299, %2296
  %2301 = load float, float* %2200, align 4
  %2302 = getelementptr inbounds float, float* %2103, i64 3
  %2303 = load float, float* %2302, align 4
  %2304 = fdiv float %2301, %2303
  %2305 = load float, float* %2204, align 4
  %2306 = fdiv float %2305, %2303
  %2307 = load float, float* %2208, align 4
  %2308 = getelementptr inbounds float, float* %2103, i64 6
  %2309 = load float, float* %2308, align 4
  %2310 = fdiv float %2307, %2309
  %2311 = load float, float* %2212, align 4
  %2312 = fdiv float %2311, %2309
  %2313 = load float, float* %2216, align 4
  %2314 = getelementptr inbounds float, float* %2103, i64 9
  %2315 = load float, float* %2314, align 4
  %2316 = fdiv float %2313, %2315
  %2317 = load float, float* %2220, align 4
  %2318 = fdiv float %2317, %2315
  %2319 = fpext float %2297 to double
  %2320 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 51, i64 0
  %2321 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 52, i64 0
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2319, i32* %2320, i32* %2321) #18
  %2322 = fpext float %2300 to double
  %2323 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 51, i64 1
  %2324 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 52, i64 1
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2322, i32* %2323, i32* %2324) #18
  %2325 = fpext float %2304 to double
  %2326 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 51, i64 2
  %2327 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 52, i64 2
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2325, i32* %2326, i32* %2327) #18
  %2328 = fpext float %2306 to double
  %2329 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 51, i64 3
  %2330 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 52, i64 3
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2328, i32* %2329, i32* %2330) #18
  %2331 = fpext float %2310 to double
  %2332 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 51, i64 4
  %2333 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 52, i64 4
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2331, i32* %2332, i32* %2333) #18
  %2334 = fpext float %2312 to double
  %2335 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 51, i64 5
  %2336 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 52, i64 5
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2334, i32* %2335, i32* %2336) #18
  %2337 = fpext float %2316 to double
  %2338 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 51, i64 6
  %2339 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 52, i64 6
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2337, i32* %2338, i32* %2339) #18
  %2340 = fpext float %2318 to double
  %2341 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 51, i64 7
  %2342 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 52, i64 7
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %2340, i32* %2341, i32* %2342) #18
  %2343 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %2344 = bitcast i8** %2343 to %struct.TfLiteLSTMParams**
  %2345 = load %struct.TfLiteLSTMParams*, %struct.TfLiteLSTMParams** %2344, align 8
  %2346 = getelementptr inbounds %struct.TfLiteLSTMParams, %struct.TfLiteLSTMParams* %2345, i64 0, i32 1
  %2347 = load float, float* %2346, align 4
  %2348 = getelementptr inbounds %struct.TfLiteLSTMParams, %struct.TfLiteLSTMParams* %2345, i64 0, i32 2
  %2349 = load float, float* %2348, align 4
  %2350 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %17, align 8
  %2351 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %2350, i64 0, i32 1, i64 0
  %2352 = load i32, i32* %2351, align 4
  %2353 = icmp slt i32 %2352, 0
  br i1 %2353, label %2358, label %2354

2354:                                             ; preds = %2246
  %2355 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %2356 = sext i32 %2352 to i64
  %2357 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2355, i64 %2356
  br label %2358

2358:                                             ; preds = %2354, %2246
  %2359 = phi %struct.TfLiteTensor* [ %2357, %2354 ], [ null, %2246 ]
  %2360 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1995, i64 %2011, i32 12, i32 1
  %2361 = bitcast i8** %2360 to %struct.TfLiteAffineQuantization**
  %2362 = load %struct.TfLiteAffineQuantization*, %struct.TfLiteAffineQuantization** %2361, align 8
  %2363 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2359, i64 0, i32 12, i32 1
  %2364 = bitcast i8** %2363 to %struct.TfLiteAffineQuantization**
  %2365 = load %struct.TfLiteAffineQuantization*, %struct.TfLiteAffineQuantization** %2364, align 8
  %2366 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %2362, i64 0, i32 0
  %2367 = load %struct.TfLiteFloatArray*, %struct.TfLiteFloatArray** %2366, align 8
  %2368 = getelementptr inbounds %struct.TfLiteFloatArray, %struct.TfLiteFloatArray* %2367, i64 0, i32 1, i64 0
  %2369 = load float, float* %2368, align 4
  %2370 = fcmp une float %2369, 0x3F00000000000000
  br i1 %2370, label %2371, label %2375

2371:                                             ; preds = %2358
  %2372 = fpext float %2369 to double
  %2373 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %2374 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %2373, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %2374(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 705, i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.132, i64 0, i64 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.133, i64 0, i64 0), double %2372, double 0x3F00000000000000) #18
  br label %2404

2375:                                             ; preds = %2358
  %2376 = fcmp ogt float %2347, 0.000000e+00
  %2377 = fcmp olt float %2347, 1.000000e+00
  %2378 = and i1 %2376, %2377
  br i1 %2378, label %2379, label %2386

2379:                                             ; preds = %2375
  %2380 = fmul float %2347, 3.276800e+04
  %2381 = fcmp olt float %2380, -3.276800e+04
  %2382 = select i1 %2381, float -3.276800e+04, float %2380
  %2383 = fcmp ogt float %2382, 3.276700e+04
  %2384 = select i1 %2383, float 3.276700e+04, float %2382
  %2385 = fptosi float %2384 to i16
  br label %2386

2386:                                             ; preds = %2379, %2375
  %2387 = phi i16 [ %2385, %2379 ], [ 0, %2375 ]
  %2388 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 34
  store i16 %2387, i16* %2388, align 8
  %2389 = fcmp ogt float %2349, 0.000000e+00
  br i1 %2389, label %2390, label %2402

2390:                                             ; preds = %2386
  %2391 = getelementptr inbounds %struct.TfLiteAffineQuantization, %struct.TfLiteAffineQuantization* %2365, i64 0, i32 0
  %2392 = load %struct.TfLiteFloatArray*, %struct.TfLiteFloatArray** %2391, align 8
  %2393 = getelementptr inbounds %struct.TfLiteFloatArray, %struct.TfLiteFloatArray* %2392, i64 0, i32 1, i64 0
  %2394 = load float, float* %2393, align 4
  %2395 = fdiv float %2349, %2394
  %2396 = fcmp olt float %2395, -1.280000e+02
  %2397 = select i1 %2396, float -1.280000e+02, float %2395
  %2398 = fcmp ogt float %2397, 1.270000e+02
  %2399 = select i1 %2398, float 1.270000e+02, float %2397
  %2400 = fptosi float %2399 to i8
  %2401 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 35
  store i8 %2400, i8* %2401, align 2
  br label %2404

2402:                                             ; preds = %2386
  %2403 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 5, i32 35
  store i8 0, i8* %2403, align 2
  br label %2404

2404:                                             ; preds = %2402, %2390, %2371
  %2405 = load float*, float** %2096, align 8
  %2406 = icmp eq float* %2405, null
  br i1 %2406, label %2410, label %2407

2407:                                             ; preds = %2404
  %2408 = ptrtoint float* %2405 to i64
  store i64 %2408, i64* %2099, align 8
  %2409 = bitcast float* %2405 to i8*
  call void @_ZdlPv(i8* %2409) #17
  br label %2410

2410:                                             ; preds = %2407, %2404
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %2095) #18
  br label %2411

2411:                                             ; preds = %2003, %2018, %2410
  %2412 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %16, i64 0, i32 3
  %2413 = bitcast [2 x i32]* %13 to i8*
  %2414 = getelementptr inbounds [2 x i32], [2 x i32]* %13, i64 0, i64 0
  %2415 = getelementptr inbounds [2 x i32], [2 x i32]* %13, i64 0, i64 1
  br label %2416

2416:                                             ; preds = %2448, %2411
  %2417 = phi i64 [ 0, %2411 ], [ %2449, %2448 ]
  %2418 = load i32, i32* %2412, align 8
  %2419 = trunc i64 %2417 to i32
  %2420 = add nsw i32 %2418, %2419
  %2421 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %2422 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %2421, i64 0, i32 1, i64 %2417
  store i32 %2420, i32* %2422, align 4
  %2423 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %515, align 8
  %2424 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %2423, i64 0, i32 1, i64 %2417
  %2425 = load i32, i32* %2424, align 4
  %2426 = icmp slt i32 %2425, 0
  br i1 %2426, label %2431, label %2427

2427:                                             ; preds = %2416
  %2428 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %154, align 8
  %2429 = sext i32 %2425 to i64
  %2430 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2428, i64 %2429
  br label %2431

2431:                                             ; preds = %2416, %2427
  %2432 = phi %struct.TfLiteTensor* [ %2430, %2427 ], [ null, %2416 ]
  %2433 = icmp ult i64 %2417, 2
  %2434 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2432, i64 0, i32 0
  %2435 = select i1 %2433, i32 9, i32 7
  store i32 %2435, i32* %2434, align 8
  %2436 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2432, i64 0, i32 4
  store i32 2, i32* %2436, align 8
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %2413) #18
  store i32 %76, i32* %2414, align 4
  store i32 %92, i32* %2415, align 4
  %2437 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2432, i64 0, i32 2
  %2438 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %2437, align 8
  %2439 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %2438, i32 2, i32* nonnull %2414) #18
  %2440 = icmp eq i32 %2439, 0
  br i1 %2440, label %2441, label %2448

2441:                                             ; preds = %2431
  %2442 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #18
  %2443 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %2442, i64 0, i32 1, i64 0
  store i32 %76, i32* %2443, align 4
  %2444 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %2442, i64 0, i32 1, i64 1
  store i32 %92, i32* %2444, align 4
  %2445 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %493, align 8
  %2446 = call i32 %2445(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %2432, %struct.TfLiteIntArray* %2442) #18
  %2447 = icmp eq i32 %2446, 0
  br i1 %2447, label %2448, label %2451

2448:                                             ; preds = %2441, %2431
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %2413) #18
  %2449 = add nuw nsw i64 %2417, 1
  %2450 = icmp eq i64 %2449, 8
  br i1 %2450, label %2452, label %2416

2451:                                             ; preds = %2441
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %2413) #18
  br label %2453

2452:                                             ; preds = %2448, %565, %1833, %901
  br label %2453

2453:                                             ; preds = %1832, %2451, %71, %122, %129, %163, %489, %2452, %553, %1833, %897, %510, %487, %333, %178, %132, %103, %96, %46, %22
  %2454 = phi i32 [ 1, %22 ], [ 1, %46 ], [ 1, %71 ], [ 1, %96 ], [ 1, %103 ], [ 1, %122 ], [ 1, %129 ], [ %135, %132 ], [ 1, %163 ], [ 1, %333 ], [ 1, %487 ], [ 1, %178 ], [ %495, %489 ], [ 1, %510 ], [ 0, %2452 ], [ %1834, %1833 ], [ %899, %897 ], [ %563, %553 ], [ %1827, %1832 ], [ %2446, %2451 ]
  ret i32 %2454
}

declare %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32) local_unnamed_addr #3

declare void @TfLiteIntArrayFree(%struct.TfLiteIntArray*) local_unnamed_addr #3

declare i32 @TfLiteIntArrayEqual(%struct.TfLiteIntArray*, %struct.TfLiteIntArray*) local_unnamed_addr #3

declare %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray*) local_unnamed_addr #3

declare i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray*, i32, i32*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm4full4EvalEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode* readonly) local_unnamed_addr #1 {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %4 = bitcast i8** %3 to %struct.TfLiteLSTMParams**
  %5 = load %struct.TfLiteLSTMParams*, %struct.TfLiteLSTMParams** %4, align 8
  %6 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 4
  %7 = bitcast i8** %6 to %"struct.tflite::ops::builtin::lstm::OpData"**
  %8 = load %"struct.tflite::ops::builtin::lstm::OpData"*, %"struct.tflite::ops::builtin::lstm::OpData"** %7, align 8
  %9 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %10 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %9, align 8
  %11 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 0
  %12 = load i32, i32* %11, align 4
  %13 = icmp slt i32 %12, 0
  br i1 %13, label %19, label %14

14:                                               ; preds = %2
  %15 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %16 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %15, align 8
  %17 = sext i32 %12 to i64
  %18 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %16, i64 %17
  br label %19

19:                                               ; preds = %2, %14
  %20 = phi %struct.TfLiteTensor* [ %18, %14 ], [ null, %2 ]
  %21 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 1
  %22 = load i32, i32* %21, align 4
  %23 = icmp slt i32 %22, 0
  br i1 %23, label %29, label %24

24:                                               ; preds = %19
  %25 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %26 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %25, align 8
  %27 = sext i32 %22 to i64
  %28 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %26, i64 %27
  br label %29

29:                                               ; preds = %19, %24
  %30 = phi %struct.TfLiteTensor* [ %28, %24 ], [ null, %19 ]
  %31 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 2
  %32 = load i32, i32* %31, align 4
  %33 = icmp slt i32 %32, 0
  br i1 %33, label %39, label %34

34:                                               ; preds = %29
  %35 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %36 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %35, align 8
  %37 = sext i32 %32 to i64
  %38 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %36, i64 %37
  br label %39

39:                                               ; preds = %29, %34
  %40 = phi %struct.TfLiteTensor* [ %38, %34 ], [ null, %29 ]
  %41 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 3
  %42 = load i32, i32* %41, align 4
  %43 = icmp slt i32 %42, 0
  br i1 %43, label %49, label %44

44:                                               ; preds = %39
  %45 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %46 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %45, align 8
  %47 = sext i32 %42 to i64
  %48 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %46, i64 %47
  br label %49

49:                                               ; preds = %39, %44
  %50 = phi %struct.TfLiteTensor* [ %48, %44 ], [ null, %39 ]
  %51 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 4
  %52 = load i32, i32* %51, align 4
  %53 = icmp slt i32 %52, 0
  br i1 %53, label %59, label %54

54:                                               ; preds = %49
  %55 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %56 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %55, align 8
  %57 = sext i32 %52 to i64
  %58 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %56, i64 %57
  br label %59

59:                                               ; preds = %49, %54
  %60 = phi %struct.TfLiteTensor* [ %58, %54 ], [ null, %49 ]
  %61 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 5
  %62 = load i32, i32* %61, align 4
  %63 = icmp slt i32 %62, 0
  br i1 %63, label %69, label %64

64:                                               ; preds = %59
  %65 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %66 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %65, align 8
  %67 = sext i32 %62 to i64
  %68 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %66, i64 %67
  br label %69

69:                                               ; preds = %59, %64
  %70 = phi %struct.TfLiteTensor* [ %68, %64 ], [ null, %59 ]
  %71 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 6
  %72 = load i32, i32* %71, align 4
  %73 = icmp slt i32 %72, 0
  br i1 %73, label %79, label %74

74:                                               ; preds = %69
  %75 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %76 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %75, align 8
  %77 = sext i32 %72 to i64
  %78 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %76, i64 %77
  br label %79

79:                                               ; preds = %69, %74
  %80 = phi %struct.TfLiteTensor* [ %78, %74 ], [ null, %69 ]
  %81 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 7
  %82 = load i32, i32* %81, align 4
  %83 = icmp slt i32 %82, 0
  br i1 %83, label %89, label %84

84:                                               ; preds = %79
  %85 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %86 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %85, align 8
  %87 = sext i32 %82 to i64
  %88 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %86, i64 %87
  br label %89

89:                                               ; preds = %79, %84
  %90 = phi %struct.TfLiteTensor* [ %88, %84 ], [ null, %79 ]
  %91 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 8
  %92 = load i32, i32* %91, align 4
  %93 = icmp slt i32 %92, 0
  br i1 %93, label %99, label %94

94:                                               ; preds = %89
  %95 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %96 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %95, align 8
  %97 = sext i32 %92 to i64
  %98 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %96, i64 %97
  br label %99

99:                                               ; preds = %89, %94
  %100 = phi %struct.TfLiteTensor* [ %98, %94 ], [ null, %89 ]
  %101 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 9
  %102 = load i32, i32* %101, align 4
  %103 = icmp slt i32 %102, 0
  br i1 %103, label %109, label %104

104:                                              ; preds = %99
  %105 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %106 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %105, align 8
  %107 = sext i32 %102 to i64
  %108 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %106, i64 %107
  br label %109

109:                                              ; preds = %99, %104
  %110 = phi %struct.TfLiteTensor* [ %108, %104 ], [ null, %99 ]
  %111 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 10
  %112 = load i32, i32* %111, align 4
  %113 = icmp slt i32 %112, 0
  br i1 %113, label %119, label %114

114:                                              ; preds = %109
  %115 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %116 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %115, align 8
  %117 = sext i32 %112 to i64
  %118 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %116, i64 %117
  br label %119

119:                                              ; preds = %109, %114
  %120 = phi %struct.TfLiteTensor* [ %118, %114 ], [ null, %109 ]
  %121 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 11
  %122 = load i32, i32* %121, align 4
  %123 = icmp slt i32 %122, 0
  br i1 %123, label %129, label %124

124:                                              ; preds = %119
  %125 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %126 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %125, align 8
  %127 = sext i32 %122 to i64
  %128 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %126, i64 %127
  br label %129

129:                                              ; preds = %119, %124
  %130 = phi %struct.TfLiteTensor* [ %128, %124 ], [ null, %119 ]
  %131 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 20
  %132 = load i32, i32* %131, align 4
  %133 = icmp slt i32 %132, 0
  br i1 %133, label %139, label %134

134:                                              ; preds = %129
  %135 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %136 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %135, align 8
  %137 = sext i32 %132 to i64
  %138 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %136, i64 %137
  br label %139

139:                                              ; preds = %129, %134
  %140 = phi %struct.TfLiteTensor* [ %138, %134 ], [ null, %129 ]
  %141 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 21
  %142 = load i32, i32* %141, align 4
  %143 = icmp slt i32 %142, 0
  br i1 %143, label %149, label %144

144:                                              ; preds = %139
  %145 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %146 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %145, align 8
  %147 = sext i32 %142 to i64
  %148 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %146, i64 %147
  br label %149

149:                                              ; preds = %139, %144
  %150 = phi %struct.TfLiteTensor* [ %148, %144 ], [ null, %139 ]
  %151 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 22
  %152 = load i32, i32* %151, align 4
  %153 = icmp slt i32 %152, 0
  br i1 %153, label %159, label %154

154:                                              ; preds = %149
  %155 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %156 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %155, align 8
  %157 = sext i32 %152 to i64
  %158 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %156, i64 %157
  br label %159

159:                                              ; preds = %149, %154
  %160 = phi %struct.TfLiteTensor* [ %158, %154 ], [ null, %149 ]
  %161 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 23
  %162 = load i32, i32* %161, align 4
  %163 = icmp slt i32 %162, 0
  br i1 %163, label %169, label %164

164:                                              ; preds = %159
  %165 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %166 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %165, align 8
  %167 = sext i32 %162 to i64
  %168 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %166, i64 %167
  br label %169

169:                                              ; preds = %159, %164
  %170 = phi %struct.TfLiteTensor* [ %168, %164 ], [ null, %159 ]
  %171 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 12
  %172 = load i32, i32* %171, align 4
  %173 = icmp slt i32 %172, 0
  br i1 %173, label %179, label %174

174:                                              ; preds = %169
  %175 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %176 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %175, align 8
  %177 = sext i32 %172 to i64
  %178 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %176, i64 %177
  br label %179

179:                                              ; preds = %169, %174
  %180 = phi %struct.TfLiteTensor* [ %178, %174 ], [ null, %169 ]
  %181 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 13
  %182 = load i32, i32* %181, align 4
  %183 = icmp slt i32 %182, 0
  br i1 %183, label %189, label %184

184:                                              ; preds = %179
  %185 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %186 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %185, align 8
  %187 = sext i32 %182 to i64
  %188 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %186, i64 %187
  br label %189

189:                                              ; preds = %179, %184
  %190 = phi %struct.TfLiteTensor* [ %188, %184 ], [ null, %179 ]
  %191 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 14
  %192 = load i32, i32* %191, align 4
  %193 = icmp slt i32 %192, 0
  br i1 %193, label %199, label %194

194:                                              ; preds = %189
  %195 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %196 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %195, align 8
  %197 = sext i32 %192 to i64
  %198 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %196, i64 %197
  br label %199

199:                                              ; preds = %189, %194
  %200 = phi %struct.TfLiteTensor* [ %198, %194 ], [ null, %189 ]
  %201 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 15
  %202 = load i32, i32* %201, align 4
  %203 = icmp slt i32 %202, 0
  br i1 %203, label %209, label %204

204:                                              ; preds = %199
  %205 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %206 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %205, align 8
  %207 = sext i32 %202 to i64
  %208 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %206, i64 %207
  br label %209

209:                                              ; preds = %199, %204
  %210 = phi %struct.TfLiteTensor* [ %208, %204 ], [ null, %199 ]
  %211 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 16
  %212 = load i32, i32* %211, align 4
  %213 = icmp slt i32 %212, 0
  br i1 %213, label %219, label %214

214:                                              ; preds = %209
  %215 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %216 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %215, align 8
  %217 = sext i32 %212 to i64
  %218 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %216, i64 %217
  br label %219

219:                                              ; preds = %209, %214
  %220 = phi %struct.TfLiteTensor* [ %218, %214 ], [ null, %209 ]
  %221 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 17
  %222 = load i32, i32* %221, align 4
  %223 = icmp slt i32 %222, 0
  br i1 %223, label %229, label %224

224:                                              ; preds = %219
  %225 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %226 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %225, align 8
  %227 = sext i32 %222 to i64
  %228 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %226, i64 %227
  br label %229

229:                                              ; preds = %219, %224
  %230 = phi %struct.TfLiteTensor* [ %228, %224 ], [ null, %219 ]
  %231 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 18
  %232 = load i32, i32* %231, align 4
  %233 = icmp slt i32 %232, 0
  br i1 %233, label %244, label %234

234:                                              ; preds = %229
  %235 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %236 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %235, align 8
  %237 = sext i32 %232 to i64
  %238 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %237
  %239 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %237, i32 11
  %240 = load i8, i8* %239, align 1, !range !5
  %241 = icmp eq i8 %240, 0
  %242 = icmp eq %struct.TfLiteTensor* %238, null
  %243 = or i1 %241, %242
  br i1 %243, label %244, label %247

244:                                              ; preds = %234, %229
  %245 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %246 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %245, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %246(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1543, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.93, i64 0, i64 0)) #18
  br label %423

247:                                              ; preds = %234
  %248 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 19
  %249 = load i32, i32* %248, align 4
  %250 = icmp slt i32 %249, 0
  br i1 %250, label %259, label %251

251:                                              ; preds = %247
  %252 = sext i32 %249 to i64
  %253 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %252
  %254 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %252, i32 11
  %255 = load i8, i8* %254, align 1, !range !5
  %256 = icmp eq i8 %255, 0
  %257 = icmp eq %struct.TfLiteTensor* %253, null
  %258 = or i1 %256, %257
  br i1 %258, label %259, label %262

259:                                              ; preds = %251, %247
  %260 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %261 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %260, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %261(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1545, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.101, i64 0, i64 0)) #18
  br label %423

262:                                              ; preds = %251
  %263 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 1
  %264 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %263, align 8
  %265 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %264, i64 0, i32 1, i64 0
  %266 = load i32, i32* %265, align 4
  %267 = icmp slt i32 %266, 0
  %268 = sext i32 %266 to i64
  %269 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %268
  %270 = select i1 %267, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %269
  %271 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %60, i64 0, i32 0
  %272 = load i32, i32* %271, align 8
  switch i32 %272, label %420 [
    i32 1, label %273
    i32 3, label %283
    i32 9, label %283
  ]

273:                                              ; preds = %262
  %274 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 3
  %275 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %274, align 8
  %276 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %275, i64 0, i32 1, i64 0
  %277 = load i32, i32* %276, align 4
  %278 = icmp slt i32 %277, 0
  %279 = sext i32 %277 to i64
  %280 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %279
  %281 = select i1 %278, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %280
  %282 = tail call i32 @_ZN6tflite3ops7builtin9lstm_eval9EvalFloatEPK12TfLiteTensorS5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_PK16TfLiteLSTMParamsbbiPS3_S9_S9_S9_(%struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %40, %struct.TfLiteTensor* %50, %struct.TfLiteTensor* %60, %struct.TfLiteTensor* %70, %struct.TfLiteTensor* %80, %struct.TfLiteTensor* %90, %struct.TfLiteTensor* %100, %struct.TfLiteTensor* %110, %struct.TfLiteTensor* %120, %struct.TfLiteTensor* %130, %struct.TfLiteTensor* %140, %struct.TfLiteTensor* %150, %struct.TfLiteTensor* %160, %struct.TfLiteTensor* %170, %struct.TfLiteTensor* null, %struct.TfLiteTensor* null, %struct.TfLiteTensor* null, %struct.TfLiteTensor* null, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %180, %struct.TfLiteTensor* %190, %struct.TfLiteTensor* %200, %struct.TfLiteTensor* %210, %struct.TfLiteTensor* %220, %struct.TfLiteTensor* %230, %struct.TfLiteLSTMParams* %5, i1 zeroext true, i1 zeroext true, i32 0, %struct.TfLiteTensor* %281, %struct.TfLiteTensor* nonnull %238, %struct.TfLiteTensor* nonnull %253, %struct.TfLiteTensor* %270) #18
  br label %423

283:                                              ; preds = %262, %262
  %284 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %20, i64 0, i32 0
  %285 = load i32, i32* %284, align 8
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %287, label %357

287:                                              ; preds = %283
  %288 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 3
  %289 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %288, align 8
  %290 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 0
  %291 = load i32, i32* %290, align 4
  %292 = icmp slt i32 %291, 0
  %293 = sext i32 %291 to i64
  %294 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %293
  %295 = select i1 %292, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %294
  %296 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 1
  %297 = load i32, i32* %296, align 4
  %298 = icmp slt i32 %297, 0
  %299 = sext i32 %297 to i64
  %300 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %299
  %301 = select i1 %298, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %300
  %302 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 2
  %303 = load i32, i32* %302, align 4
  %304 = icmp slt i32 %303, 0
  %305 = sext i32 %303 to i64
  %306 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %305
  %307 = select i1 %304, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %306
  %308 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp slt i32 %309, 0
  %311 = sext i32 %309 to i64
  %312 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %311
  %313 = select i1 %310, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %312
  %314 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 4
  %315 = load i32, i32* %314, align 4
  %316 = icmp slt i32 %315, 0
  %317 = sext i32 %315 to i64
  %318 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %317
  %319 = select i1 %316, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %318
  %320 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 5
  %321 = load i32, i32* %320, align 4
  %322 = icmp slt i32 %321, 0
  %323 = sext i32 %321 to i64
  %324 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %323
  %325 = select i1 %322, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %324
  %326 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 6
  %327 = load i32, i32* %326, align 4
  %328 = icmp slt i32 %327, 0
  %329 = sext i32 %327 to i64
  %330 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %329
  %331 = select i1 %328, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %330
  %332 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 7
  %333 = load i32, i32* %332, align 4
  %334 = icmp slt i32 %333, 0
  %335 = sext i32 %333 to i64
  %336 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %335
  %337 = select i1 %334, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %336
  %338 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 8
  %339 = load i32, i32* %338, align 4
  %340 = icmp slt i32 %339, 0
  %341 = sext i32 %339 to i64
  %342 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %341
  %343 = select i1 %340, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %342
  %344 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %289, i64 0, i32 1, i64 9
  %345 = load i32, i32* %344, align 4
  %346 = icmp slt i32 %345, 0
  %347 = sext i32 %345 to i64
  %348 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %347
  %349 = select i1 %346, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %348
  %350 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %349, i64 0, i32 2
  %351 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %350, align 8
  %352 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %351, i64 0, i32 1, i64 0
  %353 = load i32, i32* %352, align 4
  %354 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %8, i64 0, i32 6
  %355 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #18
  %356 = tail call i32 @_ZN6tflite3ops7builtin9lstm_eval10EvalHybridEPK12TfLiteTensorS5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_PK16TfLiteLSTMParamsbbiPS3_S9_S9_S9_S9_S9_S9_S9_S9_S9_S9_S9_S9_S9_iPbPNS_17CpuBackendContextE(%struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %40, %struct.TfLiteTensor* %50, %struct.TfLiteTensor* %60, %struct.TfLiteTensor* %70, %struct.TfLiteTensor* %80, %struct.TfLiteTensor* %90, %struct.TfLiteTensor* %100, %struct.TfLiteTensor* %110, %struct.TfLiteTensor* %120, %struct.TfLiteTensor* %130, %struct.TfLiteTensor* %140, %struct.TfLiteTensor* %150, %struct.TfLiteTensor* %160, %struct.TfLiteTensor* %170, %struct.TfLiteTensor* null, %struct.TfLiteTensor* null, %struct.TfLiteTensor* null, %struct.TfLiteTensor* null, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %180, %struct.TfLiteTensor* %190, %struct.TfLiteTensor* %200, %struct.TfLiteTensor* %210, %struct.TfLiteTensor* %220, %struct.TfLiteTensor* %230, %struct.TfLiteLSTMParams* %5, i1 zeroext true, i1 zeroext true, i32 0, %struct.TfLiteTensor* %295, %struct.TfLiteTensor* %319, %struct.TfLiteTensor* %325, %struct.TfLiteTensor* %331, %struct.TfLiteTensor* %301, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %307, %struct.TfLiteTensor* %313, %struct.TfLiteTensor* nonnull %238, %struct.TfLiteTensor* nonnull %253, %struct.TfLiteTensor* %337, %struct.TfLiteTensor* %270, %struct.TfLiteTensor* %343, %struct.TfLiteTensor* %349, i32 %353, i8* %354, %"class.tflite::CpuBackendContext"* %355) #18
  br label %423

357:                                              ; preds = %283
  %358 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 2
  %359 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %358, align 8
  %360 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %359, i64 0, i32 0
  %361 = load i32, i32* %360, align 4
  %362 = icmp eq i32 %361, 5
  %363 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 3
  %364 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %363, align 8
  %365 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %364, i64 0, i32 1, i64 0
  %366 = load i32, i32* %365, align 4
  %367 = icmp slt i32 %366, 0
  %368 = sext i32 %366 to i64
  %369 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %368
  %370 = select i1 %367, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %369
  %371 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %364, i64 0, i32 1, i64 1
  %372 = load i32, i32* %371, align 4
  %373 = icmp slt i32 %372, 0
  %374 = sext i32 %372 to i64
  %375 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %374
  %376 = select i1 %373, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %375
  %377 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %364, i64 0, i32 1, i64 2
  %378 = load i32, i32* %377, align 4
  %379 = icmp slt i32 %378, 0
  %380 = sext i32 %378 to i64
  %381 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %380
  %382 = select i1 %379, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %381
  %383 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %364, i64 0, i32 1, i64 3
  %384 = load i32, i32* %383, align 4
  %385 = icmp slt i32 %384, 0
  %386 = sext i32 %384 to i64
  %387 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %386
  %388 = select i1 %385, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %387
  %389 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %364, i64 0, i32 1, i64 4
  %390 = load i32, i32* %389, align 4
  %391 = icmp slt i32 %390, 0
  %392 = sext i32 %390 to i64
  %393 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %392
  %394 = select i1 %391, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %393
  %395 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %364, i64 0, i32 1, i64 5
  %396 = load i32, i32* %395, align 4
  %397 = icmp slt i32 %396, 0
  %398 = sext i32 %396 to i64
  %399 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %398
  %400 = select i1 %397, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %399
  br i1 %362, label %401, label %405

401:                                              ; preds = %357
  %402 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %8, i64 0, i32 5
  %403 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #18
  %404 = tail call i32 @_ZN6tflite3ops7builtin9lstm_eval17EvalInteger8x8_16EPK12TfLiteTensorS5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_PK16TfLiteLSTMParamsPKNS2_20IntegerLstmParameterEPS3_SC_SC_SC_SC_SC_SC_SC_SC_PNS_17CpuBackendContextE(%struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %40, %struct.TfLiteTensor* %50, %struct.TfLiteTensor* %60, %struct.TfLiteTensor* %70, %struct.TfLiteTensor* %80, %struct.TfLiteTensor* %90, %struct.TfLiteTensor* %100, %struct.TfLiteTensor* %110, %struct.TfLiteTensor* %120, %struct.TfLiteTensor* %130, %struct.TfLiteTensor* %140, %struct.TfLiteTensor* %150, %struct.TfLiteTensor* %160, %struct.TfLiteTensor* %170, %struct.TfLiteTensor* %180, %struct.TfLiteTensor* %190, %struct.TfLiteTensor* %200, %struct.TfLiteTensor* %210, %struct.TfLiteTensor* %220, %struct.TfLiteTensor* %230, %struct.TfLiteLSTMParams* %5, %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %402, %struct.TfLiteTensor* nonnull %238, %struct.TfLiteTensor* nonnull %253, %struct.TfLiteTensor* %270, %struct.TfLiteTensor* %370, %struct.TfLiteTensor* %376, %struct.TfLiteTensor* %382, %struct.TfLiteTensor* %388, %struct.TfLiteTensor* %394, %struct.TfLiteTensor* %400, %"class.tflite::CpuBackendContext"* %403) #18
  br label %423

405:                                              ; preds = %357
  %406 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %364, i64 0, i32 1, i64 6
  %407 = load i32, i32* %406, align 4
  %408 = icmp slt i32 %407, 0
  %409 = sext i32 %407 to i64
  %410 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %409
  %411 = select i1 %408, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %410
  %412 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %364, i64 0, i32 1, i64 7
  %413 = load i32, i32* %412, align 4
  %414 = icmp slt i32 %413, 0
  %415 = sext i32 %413 to i64
  %416 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %236, i64 %415
  %417 = select i1 %414, %struct.TfLiteTensor* null, %struct.TfLiteTensor* %416
  %418 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %8, i64 0, i32 5
  %419 = tail call i32 @_ZN6tflite3ops7builtin9lstm_eval16EvalInteger8x8_8EPK12TfLiteTensorS5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_PK16TfLiteLSTMParamsPS3_S9_S9_PKNS2_20IntegerLstmParameterES9_S9_S9_S9_S9_S9_S9_S9_(%struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %40, %struct.TfLiteTensor* %50, %struct.TfLiteTensor* %60, %struct.TfLiteTensor* %70, %struct.TfLiteTensor* %80, %struct.TfLiteTensor* %90, %struct.TfLiteTensor* %100, %struct.TfLiteTensor* %110, %struct.TfLiteTensor* %120, %struct.TfLiteTensor* %130, %struct.TfLiteTensor* %140, %struct.TfLiteTensor* %150, %struct.TfLiteTensor* %160, %struct.TfLiteTensor* %170, %struct.TfLiteTensor* %180, %struct.TfLiteTensor* %190, %struct.TfLiteTensor* %200, %struct.TfLiteTensor* %210, %struct.TfLiteTensor* %220, %struct.TfLiteTensor* %230, %struct.TfLiteLSTMParams* %5, %struct.TfLiteTensor* nonnull %238, %struct.TfLiteTensor* nonnull %253, %struct.TfLiteTensor* %270, %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %418, %struct.TfLiteTensor* %370, %struct.TfLiteTensor* %376, %struct.TfLiteTensor* %382, %struct.TfLiteTensor* %388, %struct.TfLiteTensor* %394, %struct.TfLiteTensor* %400, %struct.TfLiteTensor* %411, %struct.TfLiteTensor* %417) #18
  br label %423

420:                                              ; preds = %262
  %421 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %422 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %421, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %422(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.107, i64 0, i64 0), i32 %272) #18
  br label %423

423:                                              ; preds = %259, %287, %405, %401, %420, %273, %244
  %424 = phi i32 [ 1, %244 ], [ 1, %259 ], [ 1, %420 ], [ %282, %273 ], [ %356, %287 ], [ %404, %401 ], [ %419, %405 ]
  ret i32 %424
}

declare i32 @_ZN6tflite3ops7builtin9lstm_eval9EvalFloatEPK12TfLiteTensorS5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_PK16TfLiteLSTMParamsbbiPS3_S9_S9_S9_(%struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteLSTMParams*, i1 zeroext, i1 zeroext, i32, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #3

declare i32 @_ZN6tflite3ops7builtin9lstm_eval10EvalHybridEPK12TfLiteTensorS5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_PK16TfLiteLSTMParamsbbiPS3_S9_S9_S9_S9_S9_S9_S9_S9_S9_S9_S9_S9_S9_iPbPNS_17CpuBackendContextE(%struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteLSTMParams*, i1 zeroext, i1 zeroext, i32, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, i32, i8*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #3

declare %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext*) local_unnamed_addr #3

declare i32 @_ZN6tflite3ops7builtin9lstm_eval17EvalInteger8x8_16EPK12TfLiteTensorS5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_PK16TfLiteLSTMParamsPKNS2_20IntegerLstmParameterEPS3_SC_SC_SC_SC_SC_SC_SC_SC_PNS_17CpuBackendContextE(%struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteLSTMParams*, %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #3

declare i32 @_ZN6tflite3ops7builtin9lstm_eval16EvalInteger8x8_8EPK12TfLiteTensorS5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_S5_PK16TfLiteLSTMParamsPS3_S9_S9_PKNS2_20IntegerLstmParameterES9_S9_S9_S9_S9_S9_S9_S9_(%struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteLSTMParams*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden noalias nonnull i8* @_ZN6tflite3ops7builtin4lstm5basic4InitEP13TfLiteContextPKcm(%struct.TfLiteContext* nocapture readnone, i8* nocapture readnone, i64) local_unnamed_addr #1 {
  %4 = tail call i8* @_Znwm(i64 376) #17
  %5 = bitcast i8* %4 to i32*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 376, i1 false)
  store i32 1, i32* %5, align 8
  %6 = getelementptr inbounds i8, i8* %4, i64 8
  %7 = bitcast i8* %6 to i32*
  store i32 -1, i32* %7, align 8
  ret i8* %4
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm5basic7PrepareEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode* nocapture readonly) local_unnamed_addr #1 {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %4 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %3, align 8
  %5 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %4, i64 0, i32 0
  %6 = load i32, i32* %5, align 4
  %7 = icmp eq i32 %6, 5
  br i1 %7, label %11, label %8

8:                                                ; preds = %2
  %9 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %10 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %9, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %10(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1710, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.108, i64 0, i64 0)) #18
  br label %245

11:                                               ; preds = %2
  %12 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 1
  %13 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %12, align 8
  %14 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %13, i64 0, i32 0
  %15 = load i32, i32* %14, align 4
  %16 = icmp eq i32 %15, 4
  br i1 %16, label %20, label %17

17:                                               ; preds = %11
  %18 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %19 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %18, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %19(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1711, i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.109, i64 0, i64 0)) #18
  br label %245

20:                                               ; preds = %11
  %21 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %4, i64 0, i32 1, i64 0
  %22 = load i32, i32* %21, align 4
  %23 = icmp slt i32 %22, 0
  br i1 %23, label %29, label %24

24:                                               ; preds = %20
  %25 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %26 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %25, align 8
  %27 = sext i32 %22 to i64
  %28 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %26, i64 %27
  br label %29

29:                                               ; preds = %20, %24
  %30 = phi %struct.TfLiteTensor* [ %28, %24 ], [ null, %20 ]
  %31 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %4, i64 0, i32 1, i64 1
  %32 = load i32, i32* %31, align 4
  %33 = icmp slt i32 %32, 0
  br i1 %33, label %39, label %34

34:                                               ; preds = %29
  %35 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %36 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %35, align 8
  %37 = sext i32 %32 to i64
  %38 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %36, i64 %37
  br label %39

39:                                               ; preds = %29, %34
  %40 = phi %struct.TfLiteTensor* [ %38, %34 ], [ null, %29 ]
  %41 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %4, i64 0, i32 1, i64 2
  %42 = load i32, i32* %41, align 4
  %43 = icmp slt i32 %42, 0
  br i1 %43, label %49, label %44

44:                                               ; preds = %39
  %45 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %46 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %45, align 8
  %47 = sext i32 %42 to i64
  %48 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %46, i64 %47
  br label %49

49:                                               ; preds = %39, %44
  %50 = phi %struct.TfLiteTensor* [ %48, %44 ], [ null, %39 ]
  %51 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %4, i64 0, i32 1, i64 3
  %52 = load i32, i32* %51, align 4
  %53 = icmp slt i32 %52, 0
  br i1 %53, label %59, label %54

54:                                               ; preds = %49
  %55 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %56 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %55, align 8
  %57 = sext i32 %52 to i64
  %58 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %56, i64 %57
  br label %59

59:                                               ; preds = %49, %54
  %60 = phi %struct.TfLiteTensor* [ %58, %54 ], [ null, %49 ]
  %61 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %4, i64 0, i32 1, i64 4
  %62 = load i32, i32* %61, align 4
  %63 = icmp slt i32 %62, 0
  br i1 %63, label %69, label %64

64:                                               ; preds = %59
  %65 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %66 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %65, align 8
  %67 = sext i32 %62 to i64
  %68 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %66, i64 %67
  br label %69

69:                                               ; preds = %59, %64
  %70 = phi %struct.TfLiteTensor* [ %68, %64 ], [ null, %59 ]
  %71 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %30, i64 0, i32 2
  %72 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %71, align 8
  %73 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %72, i64 0, i32 0
  %74 = load i32, i32* %73, align 4
  %75 = icmp eq i32 %74, 2
  br i1 %75, label %79, label %76

76:                                               ; preds = %69
  %77 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %78 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %77, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %78(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1720, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.110, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %74, i32 2) #18
  br label %245

79:                                               ; preds = %69
  %80 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %72, i64 0, i32 1, i64 0
  %81 = load i32, i32* %80, align 4
  %82 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %72, i64 0, i32 1, i64 1
  %83 = load i32, i32* %82, align 4
  %84 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %40, i64 0, i32 2
  %85 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %84, align 8
  %86 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %85, i64 0, i32 0
  %87 = load i32, i32* %86, align 4
  %88 = icmp eq i32 %87, 2
  br i1 %88, label %92, label %89

89:                                               ; preds = %79
  %90 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %91 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %90, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %91(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1724, i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.111, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %87, i32 2) #18
  br label %245

92:                                               ; preds = %79
  %93 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %85, i64 0, i32 1, i64 0
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, %81
  br i1 %95, label %99, label %96

96:                                               ; preds = %92
  %97 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %98 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %97, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %98(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1725, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.112, i64 0, i64 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.113, i64 0, i64 0), i32 %94, i32 %81) #18
  br label %245

99:                                               ; preds = %92
  %100 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %85, i64 0, i32 1, i64 1
  %101 = load i32, i32* %100, align 4
  %102 = add nsw i32 %101, %83
  %103 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %50, i64 0, i32 2
  %104 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %103, align 8
  %105 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %104, i64 0, i32 0
  %106 = load i32, i32* %105, align 4
  %107 = icmp eq i32 %106, 2
  br i1 %107, label %111, label %108

108:                                              ; preds = %99
  %109 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %110 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %109, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %110(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1729, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.114, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %106, i32 2) #18
  br label %245

111:                                              ; preds = %99
  %112 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %104, i64 0, i32 1, i64 0
  %113 = load i32, i32* %112, align 4
  %114 = shl nsw i32 %101, 2
  %115 = icmp eq i32 %113, %114
  br i1 %115, label %119, label %116

116:                                              ; preds = %111
  %117 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %118 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %117, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %118(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1730, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.115, i64 0, i64 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.116, i64 0, i64 0), i32 %113, i32 %114) #18
  br label %245

119:                                              ; preds = %111
  %120 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %104, i64 0, i32 1, i64 1
  %121 = load i32, i32* %120, align 4
  %122 = icmp eq i32 %121, %102
  br i1 %122, label %126, label %123

123:                                              ; preds = %119
  %124 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %125 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %124, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %125(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1731, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.117, i64 0, i64 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.118, i64 0, i64 0), i32 %121, i32 %102) #18
  br label %245

126:                                              ; preds = %119
  %127 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %60, i64 0, i32 2
  %128 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %127, align 8
  %129 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %128, i64 0, i32 0
  %130 = load i32, i32* %129, align 4
  %131 = icmp eq i32 %130, 1
  br i1 %131, label %135, label %132

132:                                              ; preds = %126
  %133 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %134 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %133, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %134(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1733, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.119, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39, i64 0, i64 0), i32 %130, i32 1) #18
  br label %245

135:                                              ; preds = %126
  %136 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %128, i64 0, i32 1, i64 0
  %137 = load i32, i32* %136, align 4
  %138 = icmp eq i32 %137, %113
  br i1 %138, label %142, label %139

139:                                              ; preds = %135
  %140 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %141 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %140, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %141(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1734, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.120, i64 0, i64 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.116, i64 0, i64 0), i32 %137, i32 %113) #18
  br label %245

142:                                              ; preds = %135
  %143 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %70, i64 0, i32 2
  %144 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %143, align 8
  %145 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 0
  %146 = load i32, i32* %145, align 4
  %147 = icmp eq i32 %146, 2
  br i1 %147, label %151, label %148

148:                                              ; preds = %142
  %149 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %150 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %149, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %150(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1736, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.121, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.8, i64 0, i64 0), i32 %146, i32 2) #18
  br label %245

151:                                              ; preds = %142
  %152 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 1, i64 0
  %153 = load i32, i32* %152, align 4
  %154 = icmp eq i32 %153, %81
  br i1 %154, label %158, label %155

155:                                              ; preds = %151
  %156 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %157 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %156, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %157(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1737, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.122, i64 0, i64 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.113, i64 0, i64 0), i32 %153, i32 %81) #18
  br label %245

158:                                              ; preds = %151
  %159 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 1, i64 1
  %160 = load i32, i32* %159, align 4
  %161 = icmp eq i32 %160, %101
  br i1 %161, label %165, label %162

162:                                              ; preds = %158
  %163 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %164 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %163, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %164(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.3, i64 0, i64 0), i32 1738, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.123, i64 0, i64 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.124, i64 0, i64 0), i32 %160, i32 %101) #18
  br label %245

165:                                              ; preds = %158
  %166 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %13, i64 0, i32 1, i64 0
  %167 = load i32, i32* %166, align 4
  %168 = icmp slt i32 %167, 0
  br i1 %168, label %174, label %169

169:                                              ; preds = %165
  %170 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %171 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %170, align 8
  %172 = sext i32 %167 to i64
  %173 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %171, i64 %172
  br label %174

174:                                              ; preds = %165, %169
  %175 = phi %struct.TfLiteTensor* [ %173, %169 ], [ null, %165 ]
  %176 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %13, i64 0, i32 1, i64 1
  %177 = load i32, i32* %176, align 4
  %178 = icmp slt i32 %177, 0
  br i1 %178, label %184, label %179

179:                                              ; preds = %174
  %180 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %181 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %180, align 8
  %182 = sext i32 %177 to i64
  %183 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %181, i64 %182
  br label %184

184:                                              ; preds = %174, %179
  %185 = phi %struct.TfLiteTensor* [ %183, %179 ], [ null, %174 ]
  %186 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %13, i64 0, i32 1, i64 2
  %187 = load i32, i32* %186, align 4
  %188 = icmp slt i32 %187, 0
  br i1 %188, label %194, label %189

189:                                              ; preds = %184
  %190 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %191 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %190, align 8
  %192 = sext i32 %187 to i64
  %193 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %191, i64 %192
  br label %194

194:                                              ; preds = %184, %189
  %195 = phi %struct.TfLiteTensor* [ %193, %189 ], [ null, %184 ]
  %196 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %13, i64 0, i32 1, i64 3
  %197 = load i32, i32* %196, align 4
  %198 = icmp slt i32 %197, 0
  br i1 %198, label %204, label %199

199:                                              ; preds = %194
  %200 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %201 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %200, align 8
  %202 = sext i32 %197 to i64
  %203 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %201, i64 %202
  br label %204

204:                                              ; preds = %194, %199
  %205 = phi %struct.TfLiteTensor* [ %203, %199 ], [ null, %194 ]
  %206 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 4
  %207 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %206, align 8
  %208 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray* %85) #18
  %209 = tail call i32 %207(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %175, %struct.TfLiteIntArray* %208) #18
  %210 = icmp eq i32 %209, 0
  br i1 %210, label %211, label %245

211:                                              ; preds = %204
  %212 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %206, align 8
  %213 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %143, align 8
  %214 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray* %213) #18
  %215 = tail call i32 %212(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %185, %struct.TfLiteIntArray* %214) #18
  %216 = icmp eq i32 %215, 0
  br i1 %216, label %217, label %245

217:                                              ; preds = %211
  %218 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #18
  %219 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %218, i64 0, i32 1, i64 0
  store i32 %81, i32* %219, align 4
  %220 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %218, i64 0, i32 1, i64 1
  store i32 %102, i32* %220, align 4
  %221 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %206, align 8
  %222 = tail call i32 %221(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %195, %struct.TfLiteIntArray* %218) #18
  %223 = icmp eq i32 %222, 0
  br i1 %223, label %224, label %245

224:                                              ; preds = %217
  %225 = tail call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #18
  %226 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %225, i64 0, i32 1, i64 0
  store i32 %81, i32* %226, align 4
  %227 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %225, i64 0, i32 1, i64 1
  store i32 %113, i32* %227, align 4
  %228 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %206, align 8
  %229 = tail call i32 %228(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %205, %struct.TfLiteIntArray* %225) #18
  %230 = icmp eq i32 %229, 0
  br i1 %230, label %231, label %245

231:                                              ; preds = %224
  %232 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %233 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %232, align 8
  %234 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %3, align 8
  %235 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %234, i64 0, i32 1, i64 1
  %236 = load i32, i32* %235, align 4
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %233, i64 %237, i32 4
  store i32 3, i32* %238, align 8
  %239 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %232, align 8
  %240 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %3, align 8
  %241 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %240, i64 0, i32 1, i64 4
  %242 = load i32, i32* %241, align 4
  %243 = sext i32 %242 to i64
  %244 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %239, i64 %243, i32 4
  store i32 3, i32* %244, align 8
  br label %245

245:                                              ; preds = %231, %76, %108, %116, %123, %132, %139, %148, %155, %162, %217, %224, %211, %204, %96, %89, %17, %8
  %246 = phi i32 [ 1, %17 ], [ 1, %8 ], [ 1, %76 ], [ 1, %89 ], [ 1, %96 ], [ 1, %108 ], [ 1, %116 ], [ 1, %123 ], [ 1, %132 ], [ 1, %139 ], [ 1, %148 ], [ 1, %155 ], [ 1, %162 ], [ %215, %211 ], [ %209, %204 ], [ %222, %217 ], [ %229, %224 ], [ 0, %231 ]
  ret i32 %246
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm5basic4EvalEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode* nocapture readonly) local_unnamed_addr #1 {
  %3 = alloca %"struct.tflite::LstmCellParams", align 4
  %4 = alloca %"class.tflite::RuntimeShape", align 8
  %5 = alloca %"class.tflite::RuntimeShape", align 8
  %6 = alloca %"class.tflite::RuntimeShape", align 8
  %7 = alloca %"class.tflite::RuntimeShape", align 8
  %8 = alloca %"class.tflite::RuntimeShape", align 8
  %9 = alloca %"class.tflite::RuntimeShape", align 8
  %10 = alloca %"class.tflite::RuntimeShape", align 8
  %11 = alloca %"class.tflite::RuntimeShape", align 8
  %12 = alloca %"class.tflite::RuntimeShape", align 8
  %13 = alloca i32, align 4
  %14 = alloca i32, align 4
  %15 = alloca i32, align 4
  %16 = alloca %"struct.tflite::LstmCellParams", align 4
  %17 = alloca %"class.tflite::RuntimeShape", align 8
  %18 = alloca %"class.tflite::RuntimeShape", align 8
  %19 = alloca %"class.tflite::RuntimeShape", align 8
  %20 = alloca %"class.tflite::RuntimeShape", align 8
  %21 = alloca %"class.tflite::RuntimeShape", align 8
  %22 = alloca %"class.tflite::RuntimeShape", align 8
  %23 = alloca %"class.tflite::RuntimeShape", align 8
  %24 = alloca %"class.tflite::RuntimeShape", align 8
  %25 = alloca %"class.tflite::RuntimeShape", align 8
  %26 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %27 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %26, align 8
  %28 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %27, i64 0, i32 1, i64 0
  %29 = load i32, i32* %28, align 4
  %30 = icmp slt i32 %29, 0
  br i1 %30, label %36, label %31

31:                                               ; preds = %2
  %32 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %33 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %32, align 8
  %34 = sext i32 %29 to i64
  %35 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %33, i64 %34
  br label %36

36:                                               ; preds = %2, %31
  %37 = phi %struct.TfLiteTensor* [ %35, %31 ], [ null, %2 ]
  %38 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %27, i64 0, i32 1, i64 1
  %39 = load i32, i32* %38, align 4
  %40 = icmp slt i32 %39, 0
  br i1 %40, label %46, label %41

41:                                               ; preds = %36
  %42 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %43 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %42, align 8
  %44 = sext i32 %39 to i64
  %45 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %43, i64 %44
  br label %46

46:                                               ; preds = %36, %41
  %47 = phi %struct.TfLiteTensor* [ %45, %41 ], [ null, %36 ]
  %48 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %27, i64 0, i32 1, i64 2
  %49 = load i32, i32* %48, align 4
  %50 = icmp slt i32 %49, 0
  br i1 %50, label %56, label %51

51:                                               ; preds = %46
  %52 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %53 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %52, align 8
  %54 = sext i32 %49 to i64
  %55 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %53, i64 %54
  br label %56

56:                                               ; preds = %46, %51
  %57 = phi %struct.TfLiteTensor* [ %55, %51 ], [ null, %46 ]
  %58 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %27, i64 0, i32 1, i64 3
  %59 = load i32, i32* %58, align 4
  %60 = icmp slt i32 %59, 0
  br i1 %60, label %66, label %61

61:                                               ; preds = %56
  %62 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %63 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %62, align 8
  %64 = sext i32 %59 to i64
  %65 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %63, i64 %64
  br label %66

66:                                               ; preds = %56, %61
  %67 = phi %struct.TfLiteTensor* [ %65, %61 ], [ null, %56 ]
  %68 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %27, i64 0, i32 1, i64 4
  %69 = load i32, i32* %68, align 4
  %70 = icmp slt i32 %69, 0
  br i1 %70, label %76, label %71

71:                                               ; preds = %66
  %72 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %73 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %72, align 8
  %74 = sext i32 %69 to i64
  %75 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %73, i64 %74
  br label %76

76:                                               ; preds = %66, %71
  %77 = phi %struct.TfLiteTensor* [ %75, %71 ], [ null, %66 ]
  %78 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 1
  %79 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %78, align 8
  %80 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %79, i64 0, i32 1, i64 0
  %81 = load i32, i32* %80, align 4
  %82 = icmp slt i32 %81, 0
  br i1 %82, label %88, label %83

83:                                               ; preds = %76
  %84 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %85 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %84, align 8
  %86 = sext i32 %81 to i64
  %87 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %85, i64 %86
  br label %88

88:                                               ; preds = %76, %83
  %89 = phi %struct.TfLiteTensor* [ %87, %83 ], [ null, %76 ]
  %90 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %79, i64 0, i32 1, i64 1
  %91 = load i32, i32* %90, align 4
  %92 = icmp slt i32 %91, 0
  br i1 %92, label %98, label %93

93:                                               ; preds = %88
  %94 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %95 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %94, align 8
  %96 = sext i32 %91 to i64
  %97 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %95, i64 %96
  br label %98

98:                                               ; preds = %88, %93
  %99 = phi %struct.TfLiteTensor* [ %97, %93 ], [ null, %88 ]
  %100 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %79, i64 0, i32 1, i64 2
  %101 = load i32, i32* %100, align 4
  %102 = icmp slt i32 %101, 0
  br i1 %102, label %108, label %103

103:                                              ; preds = %98
  %104 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %105 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %104, align 8
  %106 = sext i32 %101 to i64
  %107 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %105, i64 %106
  br label %108

108:                                              ; preds = %98, %103
  %109 = phi %struct.TfLiteTensor* [ %107, %103 ], [ null, %98 ]
  %110 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %79, i64 0, i32 1, i64 3
  %111 = load i32, i32* %110, align 4
  %112 = icmp slt i32 %111, 0
  br i1 %112, label %118, label %113

113:                                              ; preds = %108
  %114 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %115 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %114, align 8
  %116 = sext i32 %111 to i64
  %117 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %115, i64 %116
  br label %118

118:                                              ; preds = %108, %113
  %119 = phi %struct.TfLiteTensor* [ %117, %113 ], [ null, %108 ]
  %120 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %37, i64 0, i32 0
  %121 = load i32, i32* %120, align 8
  switch i32 %121, label %1013 [
    i32 1, label %122
    i32 3, label %554
  ]

122:                                              ; preds = %118
  %123 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %47, i64 0, i32 0
  %124 = load i32, i32* %123, align 8
  %125 = icmp eq i32 %124, 1
  br i1 %125, label %126, label %1013

126:                                              ; preds = %122
  %127 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %57, i64 0, i32 0
  %128 = load i32, i32* %127, align 8
  %129 = icmp eq i32 %128, 1
  br i1 %129, label %130, label %1013

130:                                              ; preds = %126
  %131 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %67, i64 0, i32 0
  %132 = load i32, i32* %131, align 8
  %133 = icmp eq i32 %132, 1
  br i1 %133, label %134, label %1013

134:                                              ; preds = %130
  %135 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %77, i64 0, i32 0
  %136 = load i32, i32* %135, align 8
  %137 = icmp eq i32 %136, 1
  br i1 %137, label %138, label %1013

138:                                              ; preds = %134
  %139 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 0
  %140 = load i32, i32* %139, align 8
  %141 = icmp eq i32 %140, 1
  br i1 %141, label %142, label %1013

142:                                              ; preds = %138
  %143 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %89, i64 0, i32 0
  %144 = load i32, i32* %143, align 8
  %145 = icmp eq i32 %144, 1
  br i1 %145, label %146, label %1013

146:                                              ; preds = %142
  %147 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %109, i64 0, i32 0
  %148 = load i32, i32* %147, align 8
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %150, label %1013

150:                                              ; preds = %146
  %151 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %119, i64 0, i32 0
  %152 = load i32, i32* %151, align 8
  %153 = icmp eq i32 %152, 1
  br i1 %153, label %154, label %1013

154:                                              ; preds = %150
  %155 = bitcast %"struct.tflite::LstmCellParams"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %155) #18
  %156 = bitcast %"class.tflite::RuntimeShape"* %4 to i8*
  %157 = bitcast %"struct.tflite::LstmCellParams"* %3 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %157, i8 -86, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %156) #18
  %158 = icmp eq %struct.TfLiteTensor* %37, null
  br i1 %158, label %159, label %161

159:                                              ; preds = %154
  %160 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 0
  store i32 0, i32* %160, align 8, !alias.scope !11
  br label %189

161:                                              ; preds = %154
  %162 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %37, i64 0, i32 2
  %163 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %162, align 8, !noalias !11
  %164 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %163, i64 0, i32 0
  %165 = load i32, i32* %164, align 4, !noalias !11
  %166 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %163, i64 0, i32 1, i64 0
  %167 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 0
  store i32 %165, i32* %167, align 8, !alias.scope !11
  %168 = icmp sgt i32 %165, 5
  br i1 %168, label %169, label %176

169:                                              ; preds = %161
  %170 = sext i32 %165 to i64
  %171 = shl nsw i64 %170, 2
  %172 = tail call i8* @_Znam(i64 %171) #17, !noalias !11
  %173 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 1, i32 0
  %174 = bitcast i32** %173 to i8**
  store i8* %172, i8** %174, align 8, !alias.scope !11
  %175 = bitcast i8* %172 to i32*
  br label %181

176:                                              ; preds = %161
  %177 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 1
  %178 = bitcast %union.anon* %177 to i32*
  %179 = sext i32 %165 to i64
  %180 = shl nsw i64 %179, 2
  br label %181

181:                                              ; preds = %176, %169
  %182 = phi i64 [ %171, %169 ], [ %180, %176 ]
  %183 = phi i32* [ %175, %169 ], [ %178, %176 ]
  %184 = bitcast i32* %183 to i8*
  %185 = bitcast i32* %166 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %184, i8* align 4 %185, i64 %182, i1 false) #18
  %186 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %37, i64 0, i32 1
  %187 = bitcast %union.TfLitePtrUnion* %186 to float**
  %188 = load float*, float** %187, align 8
  br label %189

189:                                              ; preds = %159, %181
  %190 = phi float* [ %188, %181 ], [ null, %159 ]
  %191 = bitcast %"class.tflite::RuntimeShape"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %191) #18
  %192 = icmp eq %struct.TfLiteTensor* %47, null
  br i1 %192, label %193, label %195

193:                                              ; preds = %189
  %194 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %5, i64 0, i32 0
  store i32 0, i32* %194, align 8, !alias.scope !14
  br label %223

195:                                              ; preds = %189
  %196 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %47, i64 0, i32 2
  %197 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %196, align 8, !noalias !14
  %198 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %197, i64 0, i32 0
  %199 = load i32, i32* %198, align 4, !noalias !14
  %200 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %197, i64 0, i32 1, i64 0
  %201 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %5, i64 0, i32 0
  store i32 %199, i32* %201, align 8, !alias.scope !14
  %202 = icmp sgt i32 %199, 5
  br i1 %202, label %203, label %210

203:                                              ; preds = %195
  %204 = sext i32 %199 to i64
  %205 = shl nsw i64 %204, 2
  %206 = tail call i8* @_Znam(i64 %205) #17, !noalias !14
  %207 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %5, i64 0, i32 1, i32 0
  %208 = bitcast i32** %207 to i8**
  store i8* %206, i8** %208, align 8, !alias.scope !14
  %209 = bitcast i8* %206 to i32*
  br label %215

210:                                              ; preds = %195
  %211 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %5, i64 0, i32 1
  %212 = bitcast %union.anon* %211 to i32*
  %213 = sext i32 %199 to i64
  %214 = shl nsw i64 %213, 2
  br label %215

215:                                              ; preds = %210, %203
  %216 = phi i64 [ %205, %203 ], [ %214, %210 ]
  %217 = phi i32* [ %209, %203 ], [ %212, %210 ]
  %218 = bitcast i32* %217 to i8*
  %219 = bitcast i32* %200 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %218, i8* align 4 %219, i64 %216, i1 false) #18
  %220 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %47, i64 0, i32 1
  %221 = bitcast %union.TfLitePtrUnion* %220 to float**
  %222 = load float*, float** %221, align 8
  br label %223

223:                                              ; preds = %193, %215
  %224 = phi float* [ %222, %215 ], [ null, %193 ]
  %225 = bitcast %"class.tflite::RuntimeShape"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %225) #18
  %226 = icmp eq %struct.TfLiteTensor* %57, null
  br i1 %226, label %227, label %229

227:                                              ; preds = %223
  %228 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 0
  store i32 0, i32* %228, align 8, !alias.scope !17
  br label %257

229:                                              ; preds = %223
  %230 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %57, i64 0, i32 2
  %231 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %230, align 8, !noalias !17
  %232 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %231, i64 0, i32 0
  %233 = load i32, i32* %232, align 4, !noalias !17
  %234 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %231, i64 0, i32 1, i64 0
  %235 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 0
  store i32 %233, i32* %235, align 8, !alias.scope !17
  %236 = icmp sgt i32 %233, 5
  br i1 %236, label %237, label %244

237:                                              ; preds = %229
  %238 = sext i32 %233 to i64
  %239 = shl nsw i64 %238, 2
  %240 = tail call i8* @_Znam(i64 %239) #17, !noalias !17
  %241 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 1, i32 0
  %242 = bitcast i32** %241 to i8**
  store i8* %240, i8** %242, align 8, !alias.scope !17
  %243 = bitcast i8* %240 to i32*
  br label %249

244:                                              ; preds = %229
  %245 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 1
  %246 = bitcast %union.anon* %245 to i32*
  %247 = sext i32 %233 to i64
  %248 = shl nsw i64 %247, 2
  br label %249

249:                                              ; preds = %244, %237
  %250 = phi i64 [ %239, %237 ], [ %248, %244 ]
  %251 = phi i32* [ %243, %237 ], [ %246, %244 ]
  %252 = bitcast i32* %251 to i8*
  %253 = bitcast i32* %234 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %252, i8* align 4 %253, i64 %250, i1 false) #18
  %254 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %57, i64 0, i32 1
  %255 = bitcast %union.TfLitePtrUnion* %254 to float**
  %256 = load float*, float** %255, align 8
  br label %257

257:                                              ; preds = %227, %249
  %258 = phi float* [ %256, %249 ], [ null, %227 ]
  %259 = bitcast %"class.tflite::RuntimeShape"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %259) #18
  %260 = icmp eq %struct.TfLiteTensor* %67, null
  br i1 %260, label %261, label %263

261:                                              ; preds = %257
  %262 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  store i32 0, i32* %262, align 8, !alias.scope !20
  br label %291

263:                                              ; preds = %257
  %264 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %67, i64 0, i32 2
  %265 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %264, align 8, !noalias !20
  %266 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %265, i64 0, i32 0
  %267 = load i32, i32* %266, align 4, !noalias !20
  %268 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %265, i64 0, i32 1, i64 0
  %269 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  store i32 %267, i32* %269, align 8, !alias.scope !20
  %270 = icmp sgt i32 %267, 5
  br i1 %270, label %271, label %278

271:                                              ; preds = %263
  %272 = sext i32 %267 to i64
  %273 = shl nsw i64 %272, 2
  %274 = tail call i8* @_Znam(i64 %273) #17, !noalias !20
  %275 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1, i32 0
  %276 = bitcast i32** %275 to i8**
  store i8* %274, i8** %276, align 8, !alias.scope !20
  %277 = bitcast i8* %274 to i32*
  br label %283

278:                                              ; preds = %263
  %279 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %280 = bitcast %union.anon* %279 to i32*
  %281 = sext i32 %267 to i64
  %282 = shl nsw i64 %281, 2
  br label %283

283:                                              ; preds = %278, %271
  %284 = phi i64 [ %273, %271 ], [ %282, %278 ]
  %285 = phi i32* [ %277, %271 ], [ %280, %278 ]
  %286 = bitcast i32* %285 to i8*
  %287 = bitcast i32* %268 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %286, i8* align 4 %287, i64 %284, i1 false) #18
  %288 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %67, i64 0, i32 1
  %289 = bitcast %union.TfLitePtrUnion* %288 to float**
  %290 = load float*, float** %289, align 8
  br label %291

291:                                              ; preds = %261, %283
  %292 = phi float* [ %290, %283 ], [ null, %261 ]
  %293 = bitcast %"class.tflite::RuntimeShape"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %293) #18
  %294 = icmp eq %struct.TfLiteTensor* %77, null
  br i1 %294, label %295, label %297

295:                                              ; preds = %291
  %296 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 0
  store i32 0, i32* %296, align 8, !alias.scope !23
  br label %325

297:                                              ; preds = %291
  %298 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %77, i64 0, i32 2
  %299 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %298, align 8, !noalias !23
  %300 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %299, i64 0, i32 0
  %301 = load i32, i32* %300, align 4, !noalias !23
  %302 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %299, i64 0, i32 1, i64 0
  %303 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 0
  store i32 %301, i32* %303, align 8, !alias.scope !23
  %304 = icmp sgt i32 %301, 5
  br i1 %304, label %305, label %312

305:                                              ; preds = %297
  %306 = sext i32 %301 to i64
  %307 = shl nsw i64 %306, 2
  %308 = tail call i8* @_Znam(i64 %307) #17, !noalias !23
  %309 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 1, i32 0
  %310 = bitcast i32** %309 to i8**
  store i8* %308, i8** %310, align 8, !alias.scope !23
  %311 = bitcast i8* %308 to i32*
  br label %317

312:                                              ; preds = %297
  %313 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 1
  %314 = bitcast %union.anon* %313 to i32*
  %315 = sext i32 %301 to i64
  %316 = shl nsw i64 %315, 2
  br label %317

317:                                              ; preds = %312, %305
  %318 = phi i64 [ %307, %305 ], [ %316, %312 ]
  %319 = phi i32* [ %311, %305 ], [ %314, %312 ]
  %320 = bitcast i32* %319 to i8*
  %321 = bitcast i32* %302 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %320, i8* align 4 %321, i64 %318, i1 false) #18
  %322 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %77, i64 0, i32 1
  %323 = bitcast %union.TfLitePtrUnion* %322 to float**
  %324 = load float*, float** %323, align 8
  br label %325

325:                                              ; preds = %295, %317
  %326 = phi float* [ %324, %317 ], [ null, %295 ]
  %327 = bitcast %"class.tflite::RuntimeShape"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %327) #18
  %328 = icmp eq %struct.TfLiteTensor* %99, null
  br i1 %328, label %329, label %331

329:                                              ; preds = %325
  %330 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 0
  store i32 0, i32* %330, align 8, !alias.scope !26
  br label %359

331:                                              ; preds = %325
  %332 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 2
  %333 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %332, align 8, !noalias !26
  %334 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %333, i64 0, i32 0
  %335 = load i32, i32* %334, align 4, !noalias !26
  %336 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %333, i64 0, i32 1, i64 0
  %337 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 0
  store i32 %335, i32* %337, align 8, !alias.scope !26
  %338 = icmp sgt i32 %335, 5
  br i1 %338, label %339, label %346

339:                                              ; preds = %331
  %340 = sext i32 %335 to i64
  %341 = shl nsw i64 %340, 2
  %342 = tail call i8* @_Znam(i64 %341) #17, !noalias !26
  %343 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 1, i32 0
  %344 = bitcast i32** %343 to i8**
  store i8* %342, i8** %344, align 8, !alias.scope !26
  %345 = bitcast i8* %342 to i32*
  br label %351

346:                                              ; preds = %331
  %347 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 1
  %348 = bitcast %union.anon* %347 to i32*
  %349 = sext i32 %335 to i64
  %350 = shl nsw i64 %349, 2
  br label %351

351:                                              ; preds = %346, %339
  %352 = phi i64 [ %341, %339 ], [ %350, %346 ]
  %353 = phi i32* [ %345, %339 ], [ %348, %346 ]
  %354 = bitcast i32* %353 to i8*
  %355 = bitcast i32* %336 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %354, i8* align 4 %355, i64 %352, i1 false) #18
  %356 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 1
  %357 = bitcast %union.TfLitePtrUnion* %356 to float**
  %358 = load float*, float** %357, align 8
  br label %359

359:                                              ; preds = %329, %351
  %360 = phi float* [ %358, %351 ], [ null, %329 ]
  %361 = bitcast %"class.tflite::RuntimeShape"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %361) #18
  %362 = icmp eq %struct.TfLiteTensor* %89, null
  br i1 %362, label %363, label %365

363:                                              ; preds = %359
  %364 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  store i32 0, i32* %364, align 8, !alias.scope !29
  br label %393

365:                                              ; preds = %359
  %366 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %89, i64 0, i32 2
  %367 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %366, align 8, !noalias !29
  %368 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %367, i64 0, i32 0
  %369 = load i32, i32* %368, align 4, !noalias !29
  %370 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %367, i64 0, i32 1, i64 0
  %371 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  store i32 %369, i32* %371, align 8, !alias.scope !29
  %372 = icmp sgt i32 %369, 5
  br i1 %372, label %373, label %380

373:                                              ; preds = %365
  %374 = sext i32 %369 to i64
  %375 = shl nsw i64 %374, 2
  %376 = tail call i8* @_Znam(i64 %375) #17, !noalias !29
  %377 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1, i32 0
  %378 = bitcast i32** %377 to i8**
  store i8* %376, i8** %378, align 8, !alias.scope !29
  %379 = bitcast i8* %376 to i32*
  br label %385

380:                                              ; preds = %365
  %381 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1
  %382 = bitcast %union.anon* %381 to i32*
  %383 = sext i32 %369 to i64
  %384 = shl nsw i64 %383, 2
  br label %385

385:                                              ; preds = %380, %373
  %386 = phi i64 [ %375, %373 ], [ %384, %380 ]
  %387 = phi i32* [ %379, %373 ], [ %382, %380 ]
  %388 = bitcast i32* %387 to i8*
  %389 = bitcast i32* %370 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %388, i8* align 4 %389, i64 %386, i1 false) #18
  %390 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %89, i64 0, i32 1
  %391 = bitcast %union.TfLitePtrUnion* %390 to float**
  %392 = load float*, float** %391, align 8
  br label %393

393:                                              ; preds = %363, %385
  %394 = phi float* [ %392, %385 ], [ null, %363 ]
  %395 = bitcast %"class.tflite::RuntimeShape"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %395) #18
  %396 = icmp eq %struct.TfLiteTensor* %109, null
  br i1 %396, label %397, label %399

397:                                              ; preds = %393
  %398 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 0, i32* %398, align 8, !alias.scope !32
  br label %427

399:                                              ; preds = %393
  %400 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %109, i64 0, i32 2
  %401 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %400, align 8, !noalias !32
  %402 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %401, i64 0, i32 0
  %403 = load i32, i32* %402, align 4, !noalias !32
  %404 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %401, i64 0, i32 1, i64 0
  %405 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 %403, i32* %405, align 8, !alias.scope !32
  %406 = icmp sgt i32 %403, 5
  br i1 %406, label %407, label %414

407:                                              ; preds = %399
  %408 = sext i32 %403 to i64
  %409 = shl nsw i64 %408, 2
  %410 = tail call i8* @_Znam(i64 %409) #17, !noalias !32
  %411 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %412 = bitcast i32** %411 to i8**
  store i8* %410, i8** %412, align 8, !alias.scope !32
  %413 = bitcast i8* %410 to i32*
  br label %419

414:                                              ; preds = %399
  %415 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %416 = bitcast %union.anon* %415 to i32*
  %417 = sext i32 %403 to i64
  %418 = shl nsw i64 %417, 2
  br label %419

419:                                              ; preds = %414, %407
  %420 = phi i64 [ %409, %407 ], [ %418, %414 ]
  %421 = phi i32* [ %413, %407 ], [ %416, %414 ]
  %422 = bitcast i32* %421 to i8*
  %423 = bitcast i32* %404 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %422, i8* align 4 %423, i64 %420, i1 false) #18
  %424 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %109, i64 0, i32 1
  %425 = bitcast %union.TfLitePtrUnion* %424 to float**
  %426 = load float*, float** %425, align 8
  br label %427

427:                                              ; preds = %397, %419
  %428 = phi float* [ %426, %419 ], [ null, %397 ]
  %429 = bitcast %"class.tflite::RuntimeShape"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %429) #18
  %430 = icmp eq %struct.TfLiteTensor* %119, null
  br i1 %430, label %431, label %433

431:                                              ; preds = %427
  %432 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 0, i32* %432, align 8, !alias.scope !35
  br label %461

433:                                              ; preds = %427
  %434 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %119, i64 0, i32 2
  %435 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %434, align 8, !noalias !35
  %436 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %435, i64 0, i32 0
  %437 = load i32, i32* %436, align 4, !noalias !35
  %438 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %435, i64 0, i32 1, i64 0
  %439 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 %437, i32* %439, align 8, !alias.scope !35
  %440 = icmp sgt i32 %437, 5
  br i1 %440, label %441, label %448

441:                                              ; preds = %433
  %442 = sext i32 %437 to i64
  %443 = shl nsw i64 %442, 2
  %444 = tail call i8* @_Znam(i64 %443) #17, !noalias !35
  %445 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %446 = bitcast i32** %445 to i8**
  store i8* %444, i8** %446, align 8, !alias.scope !35
  %447 = bitcast i8* %444 to i32*
  br label %453

448:                                              ; preds = %433
  %449 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %450 = bitcast %union.anon* %449 to i32*
  %451 = sext i32 %437 to i64
  %452 = shl nsw i64 %451, 2
  br label %453

453:                                              ; preds = %448, %441
  %454 = phi i64 [ %443, %441 ], [ %452, %448 ]
  %455 = phi i32* [ %447, %441 ], [ %450, %448 ]
  %456 = bitcast i32* %455 to i8*
  %457 = bitcast i32* %438 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %456, i8* align 4 %457, i64 %454, i1 false) #18
  %458 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %119, i64 0, i32 1
  %459 = bitcast %union.TfLitePtrUnion* %458 to float**
  %460 = load float*, float** %459, align 8
  br label %461

461:                                              ; preds = %431, %453
  %462 = phi float* [ %460, %453 ], [ null, %431 ]
  %463 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #18
  call void @_ZN6tflite13optimized_ops8LstmCellERKNS_14LstmCellParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_S8_S6_S8_S6_PfS6_S9_S6_S9_S6_S9_PNS_17CpuBackendContextE(%"struct.tflite::LstmCellParams"* nonnull dereferenceable(16) %3, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %4, float* %190, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %5, float* %224, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %6, float* %258, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %7, float* %292, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %8, float* %326, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %9, float* %360, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %10, float* %394, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %11, float* %428, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %12, float* %462, %"class.tflite::CpuBackendContext"* %463)
  %464 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  %465 = load i32, i32* %464, align 8
  %466 = icmp sgt i32 %465, 5
  br i1 %466, label %467, label %473

467:                                              ; preds = %461
  %468 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %469 = load i32*, i32** %468, align 8
  %470 = icmp eq i32* %469, null
  br i1 %470, label %473, label %471

471:                                              ; preds = %467
  %472 = bitcast i32* %469 to i8*
  call void @_ZdaPv(i8* %472) #17
  br label %473

473:                                              ; preds = %461, %467, %471
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %429) #18
  %474 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %475 = load i32, i32* %474, align 8
  %476 = icmp sgt i32 %475, 5
  br i1 %476, label %477, label %483

477:                                              ; preds = %473
  %478 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %479 = load i32*, i32** %478, align 8
  %480 = icmp eq i32* %479, null
  br i1 %480, label %483, label %481

481:                                              ; preds = %477
  %482 = bitcast i32* %479 to i8*
  call void @_ZdaPv(i8* %482) #17
  br label %483

483:                                              ; preds = %473, %477, %481
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %395) #18
  %484 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  %485 = load i32, i32* %484, align 8
  %486 = icmp sgt i32 %485, 5
  br i1 %486, label %487, label %493

487:                                              ; preds = %483
  %488 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1, i32 0
  %489 = load i32*, i32** %488, align 8
  %490 = icmp eq i32* %489, null
  br i1 %490, label %493, label %491

491:                                              ; preds = %487
  %492 = bitcast i32* %489 to i8*
  call void @_ZdaPv(i8* %492) #17
  br label %493

493:                                              ; preds = %483, %487, %491
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %361) #18
  %494 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 0
  %495 = load i32, i32* %494, align 8
  %496 = icmp sgt i32 %495, 5
  br i1 %496, label %497, label %503

497:                                              ; preds = %493
  %498 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 1, i32 0
  %499 = load i32*, i32** %498, align 8
  %500 = icmp eq i32* %499, null
  br i1 %500, label %503, label %501

501:                                              ; preds = %497
  %502 = bitcast i32* %499 to i8*
  call void @_ZdaPv(i8* %502) #17
  br label %503

503:                                              ; preds = %493, %497, %501
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %327) #18
  %504 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 0
  %505 = load i32, i32* %504, align 8
  %506 = icmp sgt i32 %505, 5
  br i1 %506, label %507, label %513

507:                                              ; preds = %503
  %508 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 1, i32 0
  %509 = load i32*, i32** %508, align 8
  %510 = icmp eq i32* %509, null
  br i1 %510, label %513, label %511

511:                                              ; preds = %507
  %512 = bitcast i32* %509 to i8*
  call void @_ZdaPv(i8* %512) #17
  br label %513

513:                                              ; preds = %503, %507, %511
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %293) #18
  %514 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %515 = load i32, i32* %514, align 8
  %516 = icmp sgt i32 %515, 5
  br i1 %516, label %517, label %523

517:                                              ; preds = %513
  %518 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1, i32 0
  %519 = load i32*, i32** %518, align 8
  %520 = icmp eq i32* %519, null
  br i1 %520, label %523, label %521

521:                                              ; preds = %517
  %522 = bitcast i32* %519 to i8*
  call void @_ZdaPv(i8* %522) #17
  br label %523

523:                                              ; preds = %513, %517, %521
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %259) #18
  %524 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 0
  %525 = load i32, i32* %524, align 8
  %526 = icmp sgt i32 %525, 5
  br i1 %526, label %527, label %533

527:                                              ; preds = %523
  %528 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 1, i32 0
  %529 = load i32*, i32** %528, align 8
  %530 = icmp eq i32* %529, null
  br i1 %530, label %533, label %531

531:                                              ; preds = %527
  %532 = bitcast i32* %529 to i8*
  call void @_ZdaPv(i8* %532) #17
  br label %533

533:                                              ; preds = %523, %527, %531
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %225) #18
  %534 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %5, i64 0, i32 0
  %535 = load i32, i32* %534, align 8
  %536 = icmp sgt i32 %535, 5
  br i1 %536, label %537, label %543

537:                                              ; preds = %533
  %538 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %5, i64 0, i32 1, i32 0
  %539 = load i32*, i32** %538, align 8
  %540 = icmp eq i32* %539, null
  br i1 %540, label %543, label %541

541:                                              ; preds = %537
  %542 = bitcast i32* %539 to i8*
  call void @_ZdaPv(i8* %542) #17
  br label %543

543:                                              ; preds = %533, %537, %541
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %191) #18
  %544 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 0
  %545 = load i32, i32* %544, align 8
  %546 = icmp sgt i32 %545, 5
  br i1 %546, label %547, label %553

547:                                              ; preds = %543
  %548 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 1, i32 0
  %549 = load i32*, i32** %548, align 8
  %550 = icmp eq i32* %549, null
  br i1 %550, label %553, label %551

551:                                              ; preds = %547
  %552 = bitcast i32* %549 to i8*
  call void @_ZdaPv(i8* %552) #17
  br label %553

553:                                              ; preds = %543, %547, %551
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %156) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %155) #18
  br label %1016

554:                                              ; preds = %118
  %555 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %47, i64 0, i32 0
  %556 = load i32, i32* %555, align 8
  %557 = icmp eq i32 %556, 3
  br i1 %557, label %558, label %1013

558:                                              ; preds = %554
  %559 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %57, i64 0, i32 0
  %560 = load i32, i32* %559, align 8
  %561 = icmp eq i32 %560, 3
  br i1 %561, label %562, label %1013

562:                                              ; preds = %558
  %563 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %67, i64 0, i32 0
  %564 = load i32, i32* %563, align 8
  %565 = icmp eq i32 %564, 2
  br i1 %565, label %566, label %1013

566:                                              ; preds = %562
  %567 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %77, i64 0, i32 0
  %568 = load i32, i32* %567, align 8
  %569 = icmp eq i32 %568, 7
  br i1 %569, label %570, label %1013

570:                                              ; preds = %566
  %571 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 0
  %572 = load i32, i32* %571, align 8
  %573 = icmp eq i32 %572, 7
  br i1 %573, label %574, label %1013

574:                                              ; preds = %570
  %575 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %89, i64 0, i32 0
  %576 = load i32, i32* %575, align 8
  %577 = icmp eq i32 %576, 3
  br i1 %577, label %578, label %1013

578:                                              ; preds = %574
  %579 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %109, i64 0, i32 0
  %580 = load i32, i32* %579, align 8
  %581 = icmp eq i32 %580, 3
  br i1 %581, label %582, label %1013

582:                                              ; preds = %578
  %583 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %119, i64 0, i32 0
  %584 = load i32, i32* %583, align 8
  %585 = icmp eq i32 %584, 7
  br i1 %585, label %586, label %1013

586:                                              ; preds = %582
  %587 = bitcast i32* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %587) #18
  store i32 -1431655766, i32* %13, align 4
  %588 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 3, i32 0
  %589 = load float, float* %588, align 8
  %590 = call zeroext i1 @_ZN6tflite11CheckedLog2EfPi(float %589, i32* nonnull %13) #18
  br i1 %590, label %594, label %591

591:                                              ; preds = %586
  %592 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %593 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %592, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %593(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([66 x i8], [66 x i8]* @.str.125, i64 0, i64 0)) #18
  br label %1011

594:                                              ; preds = %586
  %595 = load i32, i32* %13, align 4
  %596 = icmp eq i32 %595, -11
  br i1 %596, label %600, label %597

597:                                              ; preds = %594
  %598 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %599 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %598, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %599(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([84 x i8], [84 x i8]* @.str.126, i64 0, i64 0)) #18
  br label %1011

600:                                              ; preds = %594
  %601 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %67, i64 0, i32 3, i32 0
  %602 = load float, float* %601, align 8
  %603 = fmul float %602, 4.096000e+03
  %604 = fpext float %603 to double
  %605 = bitcast i32* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %605) #18
  store i32 -1431655766, i32* %14, align 4
  %606 = bitcast i32* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %606) #18
  store i32 -1431655766, i32* %15, align 4
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %604, i32* nonnull %14, i32* nonnull %15) #18
  %607 = bitcast %"struct.tflite::LstmCellParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %607) #18
  %608 = getelementptr inbounds %"struct.tflite::LstmCellParams", %"struct.tflite::LstmCellParams"* %16, i64 0, i32 0
  %609 = getelementptr inbounds %"struct.tflite::LstmCellParams", %"struct.tflite::LstmCellParams"* %16, i64 0, i32 1
  %610 = getelementptr inbounds %"struct.tflite::LstmCellParams", %"struct.tflite::LstmCellParams"* %16, i64 0, i32 2
  %611 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %57, i64 0, i32 3, i32 1
  %612 = getelementptr inbounds %"struct.tflite::LstmCellParams", %"struct.tflite::LstmCellParams"* %16, i64 0, i32 3
  store i32 -1431655766, i32* %612, align 4
  %613 = load i32, i32* %611, align 4
  store i32 %613, i32* %608, align 4
  %614 = load i32, i32* %14, align 4
  store i32 %614, i32* %609, align 4
  %615 = load i32, i32* %15, align 4
  store i32 %615, i32* %610, align 4
  %616 = bitcast %"class.tflite::RuntimeShape"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %616) #18
  %617 = icmp eq %struct.TfLiteTensor* %37, null
  br i1 %617, label %618, label %620

618:                                              ; preds = %600
  %619 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 0, i32* %619, align 8, !alias.scope !38
  br label %648

620:                                              ; preds = %600
  %621 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %37, i64 0, i32 2
  %622 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %621, align 8, !noalias !38
  %623 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %622, i64 0, i32 0
  %624 = load i32, i32* %623, align 4, !noalias !38
  %625 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %622, i64 0, i32 1, i64 0
  %626 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 %624, i32* %626, align 8, !alias.scope !38
  %627 = icmp sgt i32 %624, 5
  br i1 %627, label %628, label %635

628:                                              ; preds = %620
  %629 = sext i32 %624 to i64
  %630 = shl nsw i64 %629, 2
  %631 = call i8* @_Znam(i64 %630) #17, !noalias !38
  %632 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %633 = bitcast i32** %632 to i8**
  store i8* %631, i8** %633, align 8, !alias.scope !38
  %634 = bitcast i8* %631 to i32*
  br label %640

635:                                              ; preds = %620
  %636 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  %637 = bitcast %union.anon* %636 to i32*
  %638 = sext i32 %624 to i64
  %639 = shl nsw i64 %638, 2
  br label %640

640:                                              ; preds = %635, %628
  %641 = phi i64 [ %630, %628 ], [ %639, %635 ]
  %642 = phi i32* [ %634, %628 ], [ %637, %635 ]
  %643 = bitcast i32* %642 to i8*
  %644 = bitcast i32* %625 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %643, i8* align 4 %644, i64 %641, i1 false) #18
  %645 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %37, i64 0, i32 1
  %646 = bitcast %union.TfLitePtrUnion* %645 to i8**
  %647 = load i8*, i8** %646, align 8
  br label %648

648:                                              ; preds = %618, %640
  %649 = phi i8* [ %647, %640 ], [ null, %618 ]
  %650 = bitcast %"class.tflite::RuntimeShape"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %650) #18
  %651 = icmp eq %struct.TfLiteTensor* %47, null
  br i1 %651, label %652, label %654

652:                                              ; preds = %648
  %653 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 0, i32* %653, align 8, !alias.scope !41
  br label %682

654:                                              ; preds = %648
  %655 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %47, i64 0, i32 2
  %656 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %655, align 8, !noalias !41
  %657 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %656, i64 0, i32 0
  %658 = load i32, i32* %657, align 4, !noalias !41
  %659 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %656, i64 0, i32 1, i64 0
  %660 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 %658, i32* %660, align 8, !alias.scope !41
  %661 = icmp sgt i32 %658, 5
  br i1 %661, label %662, label %669

662:                                              ; preds = %654
  %663 = sext i32 %658 to i64
  %664 = shl nsw i64 %663, 2
  %665 = call i8* @_Znam(i64 %664) #17, !noalias !41
  %666 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1, i32 0
  %667 = bitcast i32** %666 to i8**
  store i8* %665, i8** %667, align 8, !alias.scope !41
  %668 = bitcast i8* %665 to i32*
  br label %674

669:                                              ; preds = %654
  %670 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1
  %671 = bitcast %union.anon* %670 to i32*
  %672 = sext i32 %658 to i64
  %673 = shl nsw i64 %672, 2
  br label %674

674:                                              ; preds = %669, %662
  %675 = phi i64 [ %664, %662 ], [ %673, %669 ]
  %676 = phi i32* [ %668, %662 ], [ %671, %669 ]
  %677 = bitcast i32* %676 to i8*
  %678 = bitcast i32* %659 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %677, i8* align 4 %678, i64 %675, i1 false) #18
  %679 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %47, i64 0, i32 1
  %680 = bitcast %union.TfLitePtrUnion* %679 to i8**
  %681 = load i8*, i8** %680, align 8
  br label %682

682:                                              ; preds = %652, %674
  %683 = phi i8* [ %681, %674 ], [ null, %652 ]
  %684 = bitcast %"class.tflite::RuntimeShape"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %684) #18
  %685 = icmp eq %struct.TfLiteTensor* %57, null
  br i1 %685, label %686, label %688

686:                                              ; preds = %682
  %687 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 0, i32* %687, align 8, !alias.scope !44
  br label %716

688:                                              ; preds = %682
  %689 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %57, i64 0, i32 2
  %690 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %689, align 8, !noalias !44
  %691 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %690, i64 0, i32 0
  %692 = load i32, i32* %691, align 4, !noalias !44
  %693 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %690, i64 0, i32 1, i64 0
  %694 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 %692, i32* %694, align 8, !alias.scope !44
  %695 = icmp sgt i32 %692, 5
  br i1 %695, label %696, label %703

696:                                              ; preds = %688
  %697 = sext i32 %692 to i64
  %698 = shl nsw i64 %697, 2
  %699 = call i8* @_Znam(i64 %698) #17, !noalias !44
  %700 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %701 = bitcast i32** %700 to i8**
  store i8* %699, i8** %701, align 8, !alias.scope !44
  %702 = bitcast i8* %699 to i32*
  br label %708

703:                                              ; preds = %688
  %704 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1
  %705 = bitcast %union.anon* %704 to i32*
  %706 = sext i32 %692 to i64
  %707 = shl nsw i64 %706, 2
  br label %708

708:                                              ; preds = %703, %696
  %709 = phi i64 [ %698, %696 ], [ %707, %703 ]
  %710 = phi i32* [ %702, %696 ], [ %705, %703 ]
  %711 = bitcast i32* %710 to i8*
  %712 = bitcast i32* %693 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %711, i8* align 4 %712, i64 %709, i1 false) #18
  %713 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %57, i64 0, i32 1
  %714 = bitcast %union.TfLitePtrUnion* %713 to i8**
  %715 = load i8*, i8** %714, align 8
  br label %716

716:                                              ; preds = %686, %708
  %717 = phi i8* [ %715, %708 ], [ null, %686 ]
  %718 = bitcast %"class.tflite::RuntimeShape"* %20 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %718) #18
  %719 = icmp eq %struct.TfLiteTensor* %67, null
  br i1 %719, label %720, label %722

720:                                              ; preds = %716
  %721 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 0, i32* %721, align 8, !alias.scope !47
  br label %749

722:                                              ; preds = %716
  %723 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %67, i64 0, i32 2
  %724 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %723, align 8, !noalias !47
  %725 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %724, i64 0, i32 0
  %726 = load i32, i32* %725, align 4, !noalias !47
  %727 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %724, i64 0, i32 1, i64 0
  %728 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 %726, i32* %728, align 8, !alias.scope !47
  %729 = icmp sgt i32 %726, 5
  br i1 %729, label %730, label %737

730:                                              ; preds = %722
  %731 = sext i32 %726 to i64
  %732 = shl nsw i64 %731, 2
  %733 = call i8* @_Znam(i64 %732) #17, !noalias !47
  %734 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %735 = bitcast i32** %734 to i8**
  store i8* %733, i8** %735, align 8, !alias.scope !47
  %736 = bitcast i8* %733 to i32*
  br label %742

737:                                              ; preds = %722
  %738 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  %739 = bitcast %union.anon* %738 to i32*
  %740 = sext i32 %726 to i64
  %741 = shl nsw i64 %740, 2
  br label %742

742:                                              ; preds = %737, %730
  %743 = phi i64 [ %732, %730 ], [ %741, %737 ]
  %744 = phi i32* [ %736, %730 ], [ %739, %737 ]
  %745 = bitcast i32* %744 to i8*
  %746 = bitcast i32* %727 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %745, i8* align 4 %746, i64 %743, i1 false) #18
  %747 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %67, i64 0, i32 1, i32 0
  %748 = load i32*, i32** %747, align 8
  br label %749

749:                                              ; preds = %720, %742
  %750 = phi i32* [ %748, %742 ], [ null, %720 ]
  %751 = bitcast %"class.tflite::RuntimeShape"* %21 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %751) #18
  %752 = icmp eq %struct.TfLiteTensor* %77, null
  br i1 %752, label %753, label %755

753:                                              ; preds = %749
  %754 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  store i32 0, i32* %754, align 8, !alias.scope !50
  br label %783

755:                                              ; preds = %749
  %756 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %77, i64 0, i32 2
  %757 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %756, align 8, !noalias !50
  %758 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %757, i64 0, i32 0
  %759 = load i32, i32* %758, align 4, !noalias !50
  %760 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %757, i64 0, i32 1, i64 0
  %761 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  store i32 %759, i32* %761, align 8, !alias.scope !50
  %762 = icmp sgt i32 %759, 5
  br i1 %762, label %763, label %770

763:                                              ; preds = %755
  %764 = sext i32 %759 to i64
  %765 = shl nsw i64 %764, 2
  %766 = call i8* @_Znam(i64 %765) #17, !noalias !50
  %767 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %768 = bitcast i32** %767 to i8**
  store i8* %766, i8** %768, align 8, !alias.scope !50
  %769 = bitcast i8* %766 to i32*
  br label %775

770:                                              ; preds = %755
  %771 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1
  %772 = bitcast %union.anon* %771 to i32*
  %773 = sext i32 %759 to i64
  %774 = shl nsw i64 %773, 2
  br label %775

775:                                              ; preds = %770, %763
  %776 = phi i64 [ %765, %763 ], [ %774, %770 ]
  %777 = phi i32* [ %769, %763 ], [ %772, %770 ]
  %778 = bitcast i32* %777 to i8*
  %779 = bitcast i32* %760 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %778, i8* align 4 %779, i64 %776, i1 false) #18
  %780 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %77, i64 0, i32 1
  %781 = bitcast %union.TfLitePtrUnion* %780 to i16**
  %782 = load i16*, i16** %781, align 8
  br label %783

783:                                              ; preds = %753, %775
  %784 = phi i16* [ %782, %775 ], [ null, %753 ]
  %785 = bitcast %"class.tflite::RuntimeShape"* %22 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %785) #18
  %786 = icmp eq %struct.TfLiteTensor* %99, null
  br i1 %786, label %787, label %789

787:                                              ; preds = %783
  %788 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 0, i32* %788, align 8, !alias.scope !53
  br label %817

789:                                              ; preds = %783
  %790 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 2
  %791 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %790, align 8, !noalias !53
  %792 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %791, i64 0, i32 0
  %793 = load i32, i32* %792, align 4, !noalias !53
  %794 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %791, i64 0, i32 1, i64 0
  %795 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 %793, i32* %795, align 8, !alias.scope !53
  %796 = icmp sgt i32 %793, 5
  br i1 %796, label %797, label %804

797:                                              ; preds = %789
  %798 = sext i32 %793 to i64
  %799 = shl nsw i64 %798, 2
  %800 = call i8* @_Znam(i64 %799) #17, !noalias !53
  %801 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %802 = bitcast i32** %801 to i8**
  store i8* %800, i8** %802, align 8, !alias.scope !53
  %803 = bitcast i8* %800 to i32*
  br label %809

804:                                              ; preds = %789
  %805 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1
  %806 = bitcast %union.anon* %805 to i32*
  %807 = sext i32 %793 to i64
  %808 = shl nsw i64 %807, 2
  br label %809

809:                                              ; preds = %804, %797
  %810 = phi i64 [ %799, %797 ], [ %808, %804 ]
  %811 = phi i32* [ %803, %797 ], [ %806, %804 ]
  %812 = bitcast i32* %811 to i8*
  %813 = bitcast i32* %794 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %812, i8* align 4 %813, i64 %810, i1 false) #18
  %814 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 1
  %815 = bitcast %union.TfLitePtrUnion* %814 to i16**
  %816 = load i16*, i16** %815, align 8
  br label %817

817:                                              ; preds = %787, %809
  %818 = phi i16* [ %816, %809 ], [ null, %787 ]
  %819 = bitcast %"class.tflite::RuntimeShape"* %23 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %819) #18
  %820 = icmp eq %struct.TfLiteTensor* %89, null
  br i1 %820, label %821, label %823

821:                                              ; preds = %817
  %822 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 0, i32* %822, align 8, !alias.scope !56
  br label %851

823:                                              ; preds = %817
  %824 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %89, i64 0, i32 2
  %825 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %824, align 8, !noalias !56
  %826 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %825, i64 0, i32 0
  %827 = load i32, i32* %826, align 4, !noalias !56
  %828 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %825, i64 0, i32 1, i64 0
  %829 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 %827, i32* %829, align 8, !alias.scope !56
  %830 = icmp sgt i32 %827, 5
  br i1 %830, label %831, label %838

831:                                              ; preds = %823
  %832 = sext i32 %827 to i64
  %833 = shl nsw i64 %832, 2
  %834 = call i8* @_Znam(i64 %833) #17, !noalias !56
  %835 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %836 = bitcast i32** %835 to i8**
  store i8* %834, i8** %836, align 8, !alias.scope !56
  %837 = bitcast i8* %834 to i32*
  br label %843

838:                                              ; preds = %823
  %839 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1
  %840 = bitcast %union.anon* %839 to i32*
  %841 = sext i32 %827 to i64
  %842 = shl nsw i64 %841, 2
  br label %843

843:                                              ; preds = %838, %831
  %844 = phi i64 [ %833, %831 ], [ %842, %838 ]
  %845 = phi i32* [ %837, %831 ], [ %840, %838 ]
  %846 = bitcast i32* %845 to i8*
  %847 = bitcast i32* %828 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %846, i8* align 4 %847, i64 %844, i1 false) #18
  %848 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %89, i64 0, i32 1
  %849 = bitcast %union.TfLitePtrUnion* %848 to i8**
  %850 = load i8*, i8** %849, align 8
  br label %851

851:                                              ; preds = %821, %843
  %852 = phi i8* [ %850, %843 ], [ null, %821 ]
  %853 = bitcast %"class.tflite::RuntimeShape"* %24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %853) #18
  %854 = icmp eq %struct.TfLiteTensor* %109, null
  br i1 %854, label %855, label %857

855:                                              ; preds = %851
  %856 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 0, i32* %856, align 8, !alias.scope !59
  br label %885

857:                                              ; preds = %851
  %858 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %109, i64 0, i32 2
  %859 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %858, align 8, !noalias !59
  %860 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %859, i64 0, i32 0
  %861 = load i32, i32* %860, align 4, !noalias !59
  %862 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %859, i64 0, i32 1, i64 0
  %863 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 %861, i32* %863, align 8, !alias.scope !59
  %864 = icmp sgt i32 %861, 5
  br i1 %864, label %865, label %872

865:                                              ; preds = %857
  %866 = sext i32 %861 to i64
  %867 = shl nsw i64 %866, 2
  %868 = call i8* @_Znam(i64 %867) #17, !noalias !59
  %869 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %870 = bitcast i32** %869 to i8**
  store i8* %868, i8** %870, align 8, !alias.scope !59
  %871 = bitcast i8* %868 to i32*
  br label %877

872:                                              ; preds = %857
  %873 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1
  %874 = bitcast %union.anon* %873 to i32*
  %875 = sext i32 %861 to i64
  %876 = shl nsw i64 %875, 2
  br label %877

877:                                              ; preds = %872, %865
  %878 = phi i64 [ %867, %865 ], [ %876, %872 ]
  %879 = phi i32* [ %871, %865 ], [ %874, %872 ]
  %880 = bitcast i32* %879 to i8*
  %881 = bitcast i32* %862 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %880, i8* align 4 %881, i64 %878, i1 false) #18
  %882 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %109, i64 0, i32 1
  %883 = bitcast %union.TfLitePtrUnion* %882 to i8**
  %884 = load i8*, i8** %883, align 8
  br label %885

885:                                              ; preds = %855, %877
  %886 = phi i8* [ %884, %877 ], [ null, %855 ]
  %887 = bitcast %"class.tflite::RuntimeShape"* %25 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %887) #18
  %888 = icmp eq %struct.TfLiteTensor* %119, null
  br i1 %888, label %889, label %891

889:                                              ; preds = %885
  %890 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 0, i32* %890, align 8, !alias.scope !62
  br label %919

891:                                              ; preds = %885
  %892 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %119, i64 0, i32 2
  %893 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %892, align 8, !noalias !62
  %894 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %893, i64 0, i32 0
  %895 = load i32, i32* %894, align 4, !noalias !62
  %896 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %893, i64 0, i32 1, i64 0
  %897 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 %895, i32* %897, align 8, !alias.scope !62
  %898 = icmp sgt i32 %895, 5
  br i1 %898, label %899, label %906

899:                                              ; preds = %891
  %900 = sext i32 %895 to i64
  %901 = shl nsw i64 %900, 2
  %902 = call i8* @_Znam(i64 %901) #17, !noalias !62
  %903 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %904 = bitcast i32** %903 to i8**
  store i8* %902, i8** %904, align 8, !alias.scope !62
  %905 = bitcast i8* %902 to i32*
  br label %911

906:                                              ; preds = %891
  %907 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1
  %908 = bitcast %union.anon* %907 to i32*
  %909 = sext i32 %895 to i64
  %910 = shl nsw i64 %909, 2
  br label %911

911:                                              ; preds = %906, %899
  %912 = phi i64 [ %901, %899 ], [ %910, %906 ]
  %913 = phi i32* [ %905, %899 ], [ %908, %906 ]
  %914 = bitcast i32* %913 to i8*
  %915 = bitcast i32* %896 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %914, i8* align 4 %915, i64 %912, i1 false) #18
  %916 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %119, i64 0, i32 1
  %917 = bitcast %union.TfLitePtrUnion* %916 to i16**
  %918 = load i16*, i16** %917, align 8
  br label %919

919:                                              ; preds = %889, %911
  %920 = phi i16* [ %918, %911 ], [ null, %889 ]
  %921 = call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #18
  call void @_ZN6tflite13optimized_ops8LstmCellILi4EEEvRKNS_14LstmCellParamsERKNS_12RuntimeShapeEPKhS7_S9_S7_S9_S7_PKiS7_PKsS7_PsS7_PhS7_SF_S7_SE_PNS_17CpuBackendContextE(%"struct.tflite::LstmCellParams"* nonnull dereferenceable(16) %16, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %17, i8* %649, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %18, i8* %683, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %19, i8* %717, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %20, i32* %750, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %21, i16* %784, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %22, i16* %818, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %23, i8* %852, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %24, i8* %886, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %25, i16* %920, %"class.tflite::CpuBackendContext"* %921)
  %922 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  %923 = load i32, i32* %922, align 8
  %924 = icmp sgt i32 %923, 5
  br i1 %924, label %925, label %931

925:                                              ; preds = %919
  %926 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %927 = load i32*, i32** %926, align 8
  %928 = icmp eq i32* %927, null
  br i1 %928, label %931, label %929

929:                                              ; preds = %925
  %930 = bitcast i32* %927 to i8*
  call void @_ZdaPv(i8* %930) #17
  br label %931

931:                                              ; preds = %919, %925, %929
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %887) #18
  %932 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  %933 = load i32, i32* %932, align 8
  %934 = icmp sgt i32 %933, 5
  br i1 %934, label %935, label %941

935:                                              ; preds = %931
  %936 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %937 = load i32*, i32** %936, align 8
  %938 = icmp eq i32* %937, null
  br i1 %938, label %941, label %939

939:                                              ; preds = %935
  %940 = bitcast i32* %937 to i8*
  call void @_ZdaPv(i8* %940) #17
  br label %941

941:                                              ; preds = %931, %935, %939
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %853) #18
  %942 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  %943 = load i32, i32* %942, align 8
  %944 = icmp sgt i32 %943, 5
  br i1 %944, label %945, label %951

945:                                              ; preds = %941
  %946 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %947 = load i32*, i32** %946, align 8
  %948 = icmp eq i32* %947, null
  br i1 %948, label %951, label %949

949:                                              ; preds = %945
  %950 = bitcast i32* %947 to i8*
  call void @_ZdaPv(i8* %950) #17
  br label %951

951:                                              ; preds = %941, %945, %949
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %819) #18
  %952 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  %953 = load i32, i32* %952, align 8
  %954 = icmp sgt i32 %953, 5
  br i1 %954, label %955, label %961

955:                                              ; preds = %951
  %956 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %957 = load i32*, i32** %956, align 8
  %958 = icmp eq i32* %957, null
  br i1 %958, label %961, label %959

959:                                              ; preds = %955
  %960 = bitcast i32* %957 to i8*
  call void @_ZdaPv(i8* %960) #17
  br label %961

961:                                              ; preds = %951, %955, %959
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %785) #18
  %962 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  %963 = load i32, i32* %962, align 8
  %964 = icmp sgt i32 %963, 5
  br i1 %964, label %965, label %971

965:                                              ; preds = %961
  %966 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %967 = load i32*, i32** %966, align 8
  %968 = icmp eq i32* %967, null
  br i1 %968, label %971, label %969

969:                                              ; preds = %965
  %970 = bitcast i32* %967 to i8*
  call void @_ZdaPv(i8* %970) #17
  br label %971

971:                                              ; preds = %961, %965, %969
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %751) #18
  %972 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  %973 = load i32, i32* %972, align 8
  %974 = icmp sgt i32 %973, 5
  br i1 %974, label %975, label %981

975:                                              ; preds = %971
  %976 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %977 = load i32*, i32** %976, align 8
  %978 = icmp eq i32* %977, null
  br i1 %978, label %981, label %979

979:                                              ; preds = %975
  %980 = bitcast i32* %977 to i8*
  call void @_ZdaPv(i8* %980) #17
  br label %981

981:                                              ; preds = %971, %975, %979
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %718) #18
  %982 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  %983 = load i32, i32* %982, align 8
  %984 = icmp sgt i32 %983, 5
  br i1 %984, label %985, label %991

985:                                              ; preds = %981
  %986 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %987 = load i32*, i32** %986, align 8
  %988 = icmp eq i32* %987, null
  br i1 %988, label %991, label %989

989:                                              ; preds = %985
  %990 = bitcast i32* %987 to i8*
  call void @_ZdaPv(i8* %990) #17
  br label %991

991:                                              ; preds = %981, %985, %989
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %684) #18
  %992 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  %993 = load i32, i32* %992, align 8
  %994 = icmp sgt i32 %993, 5
  br i1 %994, label %995, label %1001

995:                                              ; preds = %991
  %996 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1, i32 0
  %997 = load i32*, i32** %996, align 8
  %998 = icmp eq i32* %997, null
  br i1 %998, label %1001, label %999

999:                                              ; preds = %995
  %1000 = bitcast i32* %997 to i8*
  call void @_ZdaPv(i8* %1000) #17
  br label %1001

1001:                                             ; preds = %991, %995, %999
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %650) #18
  %1002 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  %1003 = load i32, i32* %1002, align 8
  %1004 = icmp sgt i32 %1003, 5
  br i1 %1004, label %1005, label %1012

1005:                                             ; preds = %1001
  %1006 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %1007 = load i32*, i32** %1006, align 8
  %1008 = icmp eq i32* %1007, null
  br i1 %1008, label %1012, label %1009

1009:                                             ; preds = %1005
  %1010 = bitcast i32* %1007 to i8*
  call void @_ZdaPv(i8* %1010) #17
  br label %1012

1011:                                             ; preds = %591, %597
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %587) #18
  br label %1033

1012:                                             ; preds = %1009, %1005, %1001
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %616) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %607) #18
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %606) #18
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %605) #18
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %587) #18
  br label %1016

1013:                                             ; preds = %118, %122, %126, %130, %134, %138, %142, %146, %150, %582, %578, %574, %570, %566, %562, %558, %554
  %1014 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %1015 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %1014, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %1015(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([51 x i8], [51 x i8]* @.str.127, i64 0, i64 0)) #18
  br label %1033

1016:                                             ; preds = %1012, %553
  %1017 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %47, i64 0, i32 1
  %1018 = bitcast %union.TfLitePtrUnion* %1017 to i8**
  %1019 = load i8*, i8** %1018, align 8
  %1020 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %89, i64 0, i32 1
  %1021 = bitcast %union.TfLitePtrUnion* %1020 to i8**
  %1022 = load i8*, i8** %1021, align 8
  %1023 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %89, i64 0, i32 5
  %1024 = load i64, i64* %1023, align 8
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %1019, i8* align 1 %1022, i64 %1024, i1 false)
  %1025 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %77, i64 0, i32 1
  %1026 = bitcast %union.TfLitePtrUnion* %1025 to i8**
  %1027 = load i8*, i8** %1026, align 8
  %1028 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 1
  %1029 = bitcast %union.TfLitePtrUnion* %1028 to i8**
  %1030 = load i8*, i8** %1029, align 8
  %1031 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %99, i64 0, i32 5
  %1032 = load i64, i64* %1031, align 8
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %1027, i8* align 1 %1030, i64 %1032, i1 false)
  br label %1033

1033:                                             ; preds = %1011, %1016, %1013
  %1034 = phi i32 [ 0, %1016 ], [ 1, %1013 ], [ 1, %1011 ]
  ret i32 %1034
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops8LstmCellERKNS_14LstmCellParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_S8_S6_S8_S6_PfS6_S9_S6_S9_S6_S9_PNS_17CpuBackendContextE(%"struct.tflite::LstmCellParams"* dereferenceable(16), %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #5 comdat {
  %21 = alloca %"class.tflite::RuntimeShape", align 8
  %22 = alloca %"struct.Eigen::internal::evaluator", align 8
  %23 = alloca %"struct.Eigen::internal::evaluator.206", align 8
  %24 = alloca %"class.Eigen::internal::generic_dense_assignment_kernel", align 8
  %25 = alloca %"struct.Eigen::internal::assign_op", align 1
  %26 = alloca %"struct.Eigen::internal::evaluator.213", align 8
  %27 = alloca %"struct.Eigen::internal::evaluator.206", align 8
  %28 = alloca %"class.Eigen::internal::generic_dense_assignment_kernel.223", align 8
  %29 = alloca %"struct.Eigen::internal::assign_op", align 1
  %30 = alloca %"class.tflite::RuntimeShape", align 8
  %31 = alloca %"class.tflite::RuntimeShape", align 8
  %32 = alloca %"class.tflite::RuntimeShape", align 8
  %33 = alloca %"class.tflite::RuntimeShape", align 8
  %34 = alloca %"class.tflite::RuntimeShape", align 8
  %35 = alloca %"class.tflite::RuntimeShape", align 8
  %36 = alloca %"class.tflite::RuntimeShape", align 8
  %37 = alloca %"class.tflite::RuntimeShape", align 8
  %38 = alloca %"class.tflite::RuntimeShape", align 8
  %39 = alloca %"class.tflite::RuntimeShape", align 8
  %40 = alloca %"class.tflite::RuntimeShape", align 8
  %41 = alloca %"class.tflite::RuntimeShape", align 8
  %42 = alloca %"class.tflite::RuntimeShape", align 8
  %43 = alloca %"class.tflite::RuntimeShape", align 8
  %44 = alloca %"class.tflite::RuntimeShape", align 8
  %45 = alloca %"class.tflite::RuntimeShape", align 8
  %46 = alloca %"class.tflite::RuntimeShape", align 8
  %47 = alloca %"class.tflite::RuntimeShape", align 8
  %48 = alloca %"class.tflite::RuntimeShape", align 8
  %49 = alloca %"class.std::__1::vector.45", align 8
  %50 = alloca %"class.std::__1::vector.52", align 8
  %51 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %52 = alloca %"class.Eigen::Map", align 8
  %53 = alloca %"class.Eigen::Map", align 8
  %54 = ptrtoint float* %2 to i64
  %55 = ptrtoint float* %4 to i64
  %56 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1, i64 0, i32 0
  %57 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %58 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %59 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 0
  %60 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %61 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  %62 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  %63 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  %64 = bitcast %"class.tflite::RuntimeShape"* %30 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %64) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %64, i8 -86, i64 32, i1 false)
  %65 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %30, i64 0, i32 0
  store i32 0, i32* %65, align 8, !alias.scope !65
  %66 = load i32, i32* %56, align 8, !noalias !65
  %67 = icmp sgt i32 %66, 4
  br i1 %67, label %68, label %69

68:                                               ; preds = %20
  tail call void @abort() #19, !noalias !65
  unreachable

69:                                               ; preds = %20
  store i32 4, i32* %65, align 8, !alias.scope !65
  %70 = sub i32 4, %66
  %71 = icmp sgt i32 %70, 0
  %72 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %30, i64 0, i32 1
  br i1 %71, label %73, label %153

73:                                               ; preds = %69
  %74 = bitcast %union.anon* %72 to [5 x i32]*
  %75 = zext i32 %70 to i64
  %76 = icmp ult i32 %70, 8
  br i1 %76, label %146, label %77

77:                                               ; preds = %73
  %78 = and i64 %75, 4294967288
  %79 = add nsw i64 %78, -8
  %80 = lshr exact i64 %79, 3
  %81 = add nuw nsw i64 %80, 1
  %82 = and i64 %81, 7
  %83 = icmp ult i64 %79, 56
  br i1 %83, label %131, label %84

84:                                               ; preds = %77
  %85 = sub nsw i64 %81, %82
  br label %86

86:                                               ; preds = %86, %84
  %87 = phi i64 [ 0, %84 ], [ %128, %86 ]
  %88 = phi i64 [ %85, %84 ], [ %129, %86 ]
  %89 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %87
  %90 = bitcast i32* %89 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %90, align 8, !alias.scope !65
  %91 = getelementptr inbounds i32, i32* %89, i64 4
  %92 = bitcast i32* %91 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %92, align 8, !alias.scope !65
  %93 = or i64 %87, 8
  %94 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %93
  %95 = bitcast i32* %94 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %95, align 8, !alias.scope !65
  %96 = getelementptr inbounds i32, i32* %94, i64 4
  %97 = bitcast i32* %96 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %97, align 8, !alias.scope !65
  %98 = or i64 %87, 16
  %99 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %98
  %100 = bitcast i32* %99 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %100, align 8, !alias.scope !65
  %101 = getelementptr inbounds i32, i32* %99, i64 4
  %102 = bitcast i32* %101 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %102, align 8, !alias.scope !65
  %103 = or i64 %87, 24
  %104 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %103
  %105 = bitcast i32* %104 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %105, align 8, !alias.scope !65
  %106 = getelementptr inbounds i32, i32* %104, i64 4
  %107 = bitcast i32* %106 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %107, align 8, !alias.scope !65
  %108 = or i64 %87, 32
  %109 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %108
  %110 = bitcast i32* %109 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %110, align 8, !alias.scope !65
  %111 = getelementptr inbounds i32, i32* %109, i64 4
  %112 = bitcast i32* %111 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %112, align 8, !alias.scope !65
  %113 = or i64 %87, 40
  %114 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %113
  %115 = bitcast i32* %114 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %115, align 8, !alias.scope !65
  %116 = getelementptr inbounds i32, i32* %114, i64 4
  %117 = bitcast i32* %116 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %117, align 8, !alias.scope !65
  %118 = or i64 %87, 48
  %119 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %118
  %120 = bitcast i32* %119 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %120, align 8, !alias.scope !65
  %121 = getelementptr inbounds i32, i32* %119, i64 4
  %122 = bitcast i32* %121 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %122, align 8, !alias.scope !65
  %123 = or i64 %87, 56
  %124 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %123
  %125 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %125, align 8, !alias.scope !65
  %126 = getelementptr inbounds i32, i32* %124, i64 4
  %127 = bitcast i32* %126 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %127, align 8, !alias.scope !65
  %128 = add i64 %87, 64
  %129 = add i64 %88, -8
  %130 = icmp eq i64 %129, 0
  br i1 %130, label %131, label %86, !llvm.loop !68

131:                                              ; preds = %86, %77
  %132 = phi i64 [ 0, %77 ], [ %128, %86 ]
  %133 = icmp eq i64 %82, 0
  br i1 %133, label %144, label %134

134:                                              ; preds = %131, %134
  %135 = phi i64 [ %141, %134 ], [ %132, %131 ]
  %136 = phi i64 [ %142, %134 ], [ %82, %131 ]
  %137 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %135
  %138 = bitcast i32* %137 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %138, align 8, !alias.scope !65
  %139 = getelementptr inbounds i32, i32* %137, i64 4
  %140 = bitcast i32* %139 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %140, align 8, !alias.scope !65
  %141 = add i64 %135, 8
  %142 = add i64 %136, -1
  %143 = icmp eq i64 %142, 0
  br i1 %143, label %144, label %134, !llvm.loop !70

144:                                              ; preds = %134, %131
  %145 = icmp eq i64 %78, %75
  br i1 %145, label %153, label %146

146:                                              ; preds = %144, %73
  %147 = phi i64 [ 0, %73 ], [ %78, %144 ]
  br label %148

148:                                              ; preds = %146, %148
  %149 = phi i64 [ %151, %148 ], [ %147, %146 ]
  %150 = getelementptr inbounds [5 x i32], [5 x i32]* %74, i64 0, i64 %149
  store i32 1, i32* %150, align 4, !alias.scope !65
  %151 = add nuw nsw i64 %149, 1
  %152 = icmp eq i64 %151, %75
  br i1 %152, label %153, label %148, !llvm.loop !71

153:                                              ; preds = %148, %144, %69
  %154 = bitcast %union.anon* %72 to i32*
  %155 = sext i32 %70 to i64
  %156 = getelementptr inbounds i32, i32* %154, i64 %155
  %157 = bitcast i32* %156 to i8*
  %158 = icmp sgt i32 %66, 5
  %159 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1, i64 0, i32 1
  %160 = getelementptr inbounds %union.anon, %union.anon* %159, i64 0, i32 0
  %161 = load i32*, i32** %160, align 8, !noalias !65
  %162 = bitcast %union.anon* %159 to i32*
  %163 = select i1 %158, i32* %161, i32* %162
  %164 = bitcast i32* %163 to i8*
  %165 = sext i32 %66 to i64
  %166 = shl nsw i64 %165, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %157, i8* align 4 %164, i64 %166, i1 false) #18
  %167 = bitcast %"class.tflite::RuntimeShape"* %31 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %167) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %167, i8 -86, i64 32, i1 false)
  %168 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %31, i64 0, i32 0
  store i32 0, i32* %168, align 8, !alias.scope !73
  %169 = load i32, i32* %57, align 8, !noalias !73
  %170 = icmp sgt i32 %169, 4
  br i1 %170, label %171, label %172

171:                                              ; preds = %153
  tail call void @abort() #19, !noalias !73
  unreachable

172:                                              ; preds = %153
  store i32 4, i32* %168, align 8, !alias.scope !73
  %173 = sub i32 4, %169
  %174 = icmp sgt i32 %173, 0
  %175 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %31, i64 0, i32 1
  br i1 %174, label %176, label %256

176:                                              ; preds = %172
  %177 = bitcast %union.anon* %175 to [5 x i32]*
  %178 = zext i32 %173 to i64
  %179 = icmp ult i32 %173, 8
  br i1 %179, label %249, label %180

180:                                              ; preds = %176
  %181 = and i64 %178, 4294967288
  %182 = add nsw i64 %181, -8
  %183 = lshr exact i64 %182, 3
  %184 = add nuw nsw i64 %183, 1
  %185 = and i64 %184, 7
  %186 = icmp ult i64 %182, 56
  br i1 %186, label %234, label %187

187:                                              ; preds = %180
  %188 = sub nsw i64 %184, %185
  br label %189

189:                                              ; preds = %189, %187
  %190 = phi i64 [ 0, %187 ], [ %231, %189 ]
  %191 = phi i64 [ %188, %187 ], [ %232, %189 ]
  %192 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %190
  %193 = bitcast i32* %192 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %193, align 8, !alias.scope !73
  %194 = getelementptr inbounds i32, i32* %192, i64 4
  %195 = bitcast i32* %194 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %195, align 8, !alias.scope !73
  %196 = or i64 %190, 8
  %197 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %196
  %198 = bitcast i32* %197 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %198, align 8, !alias.scope !73
  %199 = getelementptr inbounds i32, i32* %197, i64 4
  %200 = bitcast i32* %199 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %200, align 8, !alias.scope !73
  %201 = or i64 %190, 16
  %202 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %201
  %203 = bitcast i32* %202 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %203, align 8, !alias.scope !73
  %204 = getelementptr inbounds i32, i32* %202, i64 4
  %205 = bitcast i32* %204 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %205, align 8, !alias.scope !73
  %206 = or i64 %190, 24
  %207 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %206
  %208 = bitcast i32* %207 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %208, align 8, !alias.scope !73
  %209 = getelementptr inbounds i32, i32* %207, i64 4
  %210 = bitcast i32* %209 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %210, align 8, !alias.scope !73
  %211 = or i64 %190, 32
  %212 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %211
  %213 = bitcast i32* %212 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %213, align 8, !alias.scope !73
  %214 = getelementptr inbounds i32, i32* %212, i64 4
  %215 = bitcast i32* %214 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %215, align 8, !alias.scope !73
  %216 = or i64 %190, 40
  %217 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %216
  %218 = bitcast i32* %217 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %218, align 8, !alias.scope !73
  %219 = getelementptr inbounds i32, i32* %217, i64 4
  %220 = bitcast i32* %219 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %220, align 8, !alias.scope !73
  %221 = or i64 %190, 48
  %222 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %221
  %223 = bitcast i32* %222 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %223, align 8, !alias.scope !73
  %224 = getelementptr inbounds i32, i32* %222, i64 4
  %225 = bitcast i32* %224 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %225, align 8, !alias.scope !73
  %226 = or i64 %190, 56
  %227 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %226
  %228 = bitcast i32* %227 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %228, align 8, !alias.scope !73
  %229 = getelementptr inbounds i32, i32* %227, i64 4
  %230 = bitcast i32* %229 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %230, align 8, !alias.scope !73
  %231 = add i64 %190, 64
  %232 = add i64 %191, -8
  %233 = icmp eq i64 %232, 0
  br i1 %233, label %234, label %189, !llvm.loop !76

234:                                              ; preds = %189, %180
  %235 = phi i64 [ 0, %180 ], [ %231, %189 ]
  %236 = icmp eq i64 %185, 0
  br i1 %236, label %247, label %237

237:                                              ; preds = %234, %237
  %238 = phi i64 [ %244, %237 ], [ %235, %234 ]
  %239 = phi i64 [ %245, %237 ], [ %185, %234 ]
  %240 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %238
  %241 = bitcast i32* %240 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %241, align 8, !alias.scope !73
  %242 = getelementptr inbounds i32, i32* %240, i64 4
  %243 = bitcast i32* %242 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %243, align 8, !alias.scope !73
  %244 = add i64 %238, 8
  %245 = add i64 %239, -1
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %247, label %237, !llvm.loop !77

247:                                              ; preds = %237, %234
  %248 = icmp eq i64 %181, %178
  br i1 %248, label %256, label %249

249:                                              ; preds = %247, %176
  %250 = phi i64 [ 0, %176 ], [ %181, %247 ]
  br label %251

251:                                              ; preds = %249, %251
  %252 = phi i64 [ %254, %251 ], [ %250, %249 ]
  %253 = getelementptr inbounds [5 x i32], [5 x i32]* %177, i64 0, i64 %252
  store i32 1, i32* %253, align 4, !alias.scope !73
  %254 = add nuw nsw i64 %252, 1
  %255 = icmp eq i64 %254, %178
  br i1 %255, label %256, label %251, !llvm.loop !78

256:                                              ; preds = %251, %247, %172
  %257 = bitcast %union.anon* %175 to i32*
  %258 = sext i32 %173 to i64
  %259 = getelementptr inbounds i32, i32* %257, i64 %258
  %260 = bitcast i32* %259 to i8*
  %261 = icmp sgt i32 %169, 5
  %262 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %263 = getelementptr inbounds %union.anon, %union.anon* %262, i64 0, i32 0
  %264 = load i32*, i32** %263, align 8, !noalias !73
  %265 = bitcast %union.anon* %262 to i32*
  %266 = select i1 %261, i32* %264, i32* %265
  %267 = bitcast i32* %266 to i8*
  %268 = sext i32 %169 to i64
  %269 = shl nsw i64 %268, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %260, i8* align 4 %267, i64 %269, i1 false) #18
  %270 = bitcast %"class.tflite::RuntimeShape"* %32 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %270) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %270, i8 -86, i64 32, i1 false)
  %271 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %32, i64 0, i32 0
  store i32 0, i32* %271, align 8, !alias.scope !79
  %272 = load i32, i32* %58, align 8, !noalias !79
  %273 = icmp sgt i32 %272, 4
  br i1 %273, label %274, label %275

274:                                              ; preds = %256
  tail call void @abort() #19, !noalias !79
  unreachable

275:                                              ; preds = %256
  store i32 4, i32* %271, align 8, !alias.scope !79
  %276 = sub i32 4, %272
  %277 = icmp sgt i32 %276, 0
  %278 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %32, i64 0, i32 1
  br i1 %277, label %279, label %359

279:                                              ; preds = %275
  %280 = bitcast %union.anon* %278 to [5 x i32]*
  %281 = zext i32 %276 to i64
  %282 = icmp ult i32 %276, 8
  br i1 %282, label %352, label %283

283:                                              ; preds = %279
  %284 = and i64 %281, 4294967288
  %285 = add nsw i64 %284, -8
  %286 = lshr exact i64 %285, 3
  %287 = add nuw nsw i64 %286, 1
  %288 = and i64 %287, 7
  %289 = icmp ult i64 %285, 56
  br i1 %289, label %337, label %290

290:                                              ; preds = %283
  %291 = sub nsw i64 %287, %288
  br label %292

292:                                              ; preds = %292, %290
  %293 = phi i64 [ 0, %290 ], [ %334, %292 ]
  %294 = phi i64 [ %291, %290 ], [ %335, %292 ]
  %295 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %293
  %296 = bitcast i32* %295 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %296, align 8, !alias.scope !79
  %297 = getelementptr inbounds i32, i32* %295, i64 4
  %298 = bitcast i32* %297 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %298, align 8, !alias.scope !79
  %299 = or i64 %293, 8
  %300 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %299
  %301 = bitcast i32* %300 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %301, align 8, !alias.scope !79
  %302 = getelementptr inbounds i32, i32* %300, i64 4
  %303 = bitcast i32* %302 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %303, align 8, !alias.scope !79
  %304 = or i64 %293, 16
  %305 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %304
  %306 = bitcast i32* %305 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %306, align 8, !alias.scope !79
  %307 = getelementptr inbounds i32, i32* %305, i64 4
  %308 = bitcast i32* %307 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %308, align 8, !alias.scope !79
  %309 = or i64 %293, 24
  %310 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %309
  %311 = bitcast i32* %310 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %311, align 8, !alias.scope !79
  %312 = getelementptr inbounds i32, i32* %310, i64 4
  %313 = bitcast i32* %312 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %313, align 8, !alias.scope !79
  %314 = or i64 %293, 32
  %315 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %314
  %316 = bitcast i32* %315 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %316, align 8, !alias.scope !79
  %317 = getelementptr inbounds i32, i32* %315, i64 4
  %318 = bitcast i32* %317 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %318, align 8, !alias.scope !79
  %319 = or i64 %293, 40
  %320 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %319
  %321 = bitcast i32* %320 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %321, align 8, !alias.scope !79
  %322 = getelementptr inbounds i32, i32* %320, i64 4
  %323 = bitcast i32* %322 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %323, align 8, !alias.scope !79
  %324 = or i64 %293, 48
  %325 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %324
  %326 = bitcast i32* %325 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %326, align 8, !alias.scope !79
  %327 = getelementptr inbounds i32, i32* %325, i64 4
  %328 = bitcast i32* %327 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %328, align 8, !alias.scope !79
  %329 = or i64 %293, 56
  %330 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %329
  %331 = bitcast i32* %330 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %331, align 8, !alias.scope !79
  %332 = getelementptr inbounds i32, i32* %330, i64 4
  %333 = bitcast i32* %332 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %333, align 8, !alias.scope !79
  %334 = add i64 %293, 64
  %335 = add i64 %294, -8
  %336 = icmp eq i64 %335, 0
  br i1 %336, label %337, label %292, !llvm.loop !82

337:                                              ; preds = %292, %283
  %338 = phi i64 [ 0, %283 ], [ %334, %292 ]
  %339 = icmp eq i64 %288, 0
  br i1 %339, label %350, label %340

340:                                              ; preds = %337, %340
  %341 = phi i64 [ %347, %340 ], [ %338, %337 ]
  %342 = phi i64 [ %348, %340 ], [ %288, %337 ]
  %343 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %341
  %344 = bitcast i32* %343 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %344, align 8, !alias.scope !79
  %345 = getelementptr inbounds i32, i32* %343, i64 4
  %346 = bitcast i32* %345 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %346, align 8, !alias.scope !79
  %347 = add i64 %341, 8
  %348 = add i64 %342, -1
  %349 = icmp eq i64 %348, 0
  br i1 %349, label %350, label %340, !llvm.loop !83

350:                                              ; preds = %340, %337
  %351 = icmp eq i64 %284, %281
  br i1 %351, label %359, label %352

352:                                              ; preds = %350, %279
  %353 = phi i64 [ 0, %279 ], [ %284, %350 ]
  br label %354

354:                                              ; preds = %352, %354
  %355 = phi i64 [ %357, %354 ], [ %353, %352 ]
  %356 = getelementptr inbounds [5 x i32], [5 x i32]* %280, i64 0, i64 %355
  store i32 1, i32* %356, align 4, !alias.scope !79
  %357 = add nuw nsw i64 %355, 1
  %358 = icmp eq i64 %357, %281
  br i1 %358, label %359, label %354, !llvm.loop !84

359:                                              ; preds = %354, %350, %275
  %360 = bitcast %union.anon* %278 to i32*
  %361 = sext i32 %276 to i64
  %362 = getelementptr inbounds i32, i32* %360, i64 %361
  %363 = bitcast i32* %362 to i8*
  %364 = icmp sgt i32 %272, 5
  %365 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %366 = getelementptr inbounds %union.anon, %union.anon* %365, i64 0, i32 0
  %367 = load i32*, i32** %366, align 8, !noalias !79
  %368 = bitcast %union.anon* %365 to i32*
  %369 = select i1 %364, i32* %367, i32* %368
  %370 = bitcast i32* %369 to i8*
  %371 = sext i32 %272 to i64
  %372 = shl nsw i64 %371, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %363, i8* align 4 %370, i64 %372, i1 false) #18
  %373 = bitcast %"class.tflite::RuntimeShape"* %33 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %373) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %373, i8 -86, i64 32, i1 false)
  %374 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %33, i64 0, i32 0
  store i32 0, i32* %374, align 8, !alias.scope !85
  %375 = load i32, i32* %59, align 8, !noalias !85
  %376 = icmp sgt i32 %375, 4
  br i1 %376, label %377, label %378

377:                                              ; preds = %359
  tail call void @abort() #19, !noalias !85
  unreachable

378:                                              ; preds = %359
  store i32 4, i32* %374, align 8, !alias.scope !85
  %379 = sub i32 4, %375
  %380 = icmp sgt i32 %379, 0
  %381 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %33, i64 0, i32 1
  br i1 %380, label %382, label %462

382:                                              ; preds = %378
  %383 = bitcast %union.anon* %381 to [5 x i32]*
  %384 = zext i32 %379 to i64
  %385 = icmp ult i32 %379, 8
  br i1 %385, label %455, label %386

386:                                              ; preds = %382
  %387 = and i64 %384, 4294967288
  %388 = add nsw i64 %387, -8
  %389 = lshr exact i64 %388, 3
  %390 = add nuw nsw i64 %389, 1
  %391 = and i64 %390, 7
  %392 = icmp ult i64 %388, 56
  br i1 %392, label %440, label %393

393:                                              ; preds = %386
  %394 = sub nsw i64 %390, %391
  br label %395

395:                                              ; preds = %395, %393
  %396 = phi i64 [ 0, %393 ], [ %437, %395 ]
  %397 = phi i64 [ %394, %393 ], [ %438, %395 ]
  %398 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %396
  %399 = bitcast i32* %398 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %399, align 8, !alias.scope !85
  %400 = getelementptr inbounds i32, i32* %398, i64 4
  %401 = bitcast i32* %400 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %401, align 8, !alias.scope !85
  %402 = or i64 %396, 8
  %403 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %402
  %404 = bitcast i32* %403 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %404, align 8, !alias.scope !85
  %405 = getelementptr inbounds i32, i32* %403, i64 4
  %406 = bitcast i32* %405 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %406, align 8, !alias.scope !85
  %407 = or i64 %396, 16
  %408 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %407
  %409 = bitcast i32* %408 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %409, align 8, !alias.scope !85
  %410 = getelementptr inbounds i32, i32* %408, i64 4
  %411 = bitcast i32* %410 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %411, align 8, !alias.scope !85
  %412 = or i64 %396, 24
  %413 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %412
  %414 = bitcast i32* %413 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %414, align 8, !alias.scope !85
  %415 = getelementptr inbounds i32, i32* %413, i64 4
  %416 = bitcast i32* %415 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %416, align 8, !alias.scope !85
  %417 = or i64 %396, 32
  %418 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %417
  %419 = bitcast i32* %418 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %419, align 8, !alias.scope !85
  %420 = getelementptr inbounds i32, i32* %418, i64 4
  %421 = bitcast i32* %420 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %421, align 8, !alias.scope !85
  %422 = or i64 %396, 40
  %423 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %422
  %424 = bitcast i32* %423 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %424, align 8, !alias.scope !85
  %425 = getelementptr inbounds i32, i32* %423, i64 4
  %426 = bitcast i32* %425 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %426, align 8, !alias.scope !85
  %427 = or i64 %396, 48
  %428 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %427
  %429 = bitcast i32* %428 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %429, align 8, !alias.scope !85
  %430 = getelementptr inbounds i32, i32* %428, i64 4
  %431 = bitcast i32* %430 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %431, align 8, !alias.scope !85
  %432 = or i64 %396, 56
  %433 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %432
  %434 = bitcast i32* %433 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %434, align 8, !alias.scope !85
  %435 = getelementptr inbounds i32, i32* %433, i64 4
  %436 = bitcast i32* %435 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %436, align 8, !alias.scope !85
  %437 = add i64 %396, 64
  %438 = add i64 %397, -8
  %439 = icmp eq i64 %438, 0
  br i1 %439, label %440, label %395, !llvm.loop !88

440:                                              ; preds = %395, %386
  %441 = phi i64 [ 0, %386 ], [ %437, %395 ]
  %442 = icmp eq i64 %391, 0
  br i1 %442, label %453, label %443

443:                                              ; preds = %440, %443
  %444 = phi i64 [ %450, %443 ], [ %441, %440 ]
  %445 = phi i64 [ %451, %443 ], [ %391, %440 ]
  %446 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %444
  %447 = bitcast i32* %446 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %447, align 8, !alias.scope !85
  %448 = getelementptr inbounds i32, i32* %446, i64 4
  %449 = bitcast i32* %448 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %449, align 8, !alias.scope !85
  %450 = add i64 %444, 8
  %451 = add i64 %445, -1
  %452 = icmp eq i64 %451, 0
  br i1 %452, label %453, label %443, !llvm.loop !89

453:                                              ; preds = %443, %440
  %454 = icmp eq i64 %387, %384
  br i1 %454, label %462, label %455

455:                                              ; preds = %453, %382
  %456 = phi i64 [ 0, %382 ], [ %387, %453 ]
  br label %457

457:                                              ; preds = %455, %457
  %458 = phi i64 [ %460, %457 ], [ %456, %455 ]
  %459 = getelementptr inbounds [5 x i32], [5 x i32]* %383, i64 0, i64 %458
  store i32 1, i32* %459, align 4, !alias.scope !85
  %460 = add nuw nsw i64 %458, 1
  %461 = icmp eq i64 %460, %384
  br i1 %461, label %462, label %457, !llvm.loop !90

462:                                              ; preds = %457, %453, %378
  %463 = getelementptr inbounds %union.anon, %union.anon* %381, i64 0, i32 0
  %464 = bitcast %union.anon* %381 to i32*
  %465 = sext i32 %379 to i64
  %466 = getelementptr inbounds i32, i32* %464, i64 %465
  %467 = bitcast i32* %466 to i8*
  %468 = icmp sgt i32 %375, 5
  %469 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 1
  %470 = getelementptr inbounds %union.anon, %union.anon* %469, i64 0, i32 0
  %471 = load i32*, i32** %470, align 8, !noalias !85
  %472 = bitcast %union.anon* %469 to i32*
  %473 = select i1 %468, i32* %471, i32* %472
  %474 = bitcast i32* %473 to i8*
  %475 = sext i32 %375 to i64
  %476 = shl nsw i64 %475, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %467, i8* align 4 %474, i64 %476, i1 false) #18
  %477 = bitcast %"class.tflite::RuntimeShape"* %34 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %477) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %477, i8 -86, i64 32, i1 false)
  %478 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %34, i64 0, i32 0
  store i32 0, i32* %478, align 8, !alias.scope !91
  %479 = load i32, i32* %60, align 8, !noalias !91
  %480 = icmp sgt i32 %479, 4
  br i1 %480, label %481, label %482

481:                                              ; preds = %462
  tail call void @abort() #19, !noalias !91
  unreachable

482:                                              ; preds = %462
  store i32 4, i32* %478, align 8, !alias.scope !91
  %483 = sub i32 4, %479
  %484 = icmp sgt i32 %483, 0
  %485 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %34, i64 0, i32 1
  br i1 %484, label %486, label %566

486:                                              ; preds = %482
  %487 = bitcast %union.anon* %485 to [5 x i32]*
  %488 = zext i32 %483 to i64
  %489 = icmp ult i32 %483, 8
  br i1 %489, label %559, label %490

490:                                              ; preds = %486
  %491 = and i64 %488, 4294967288
  %492 = add nsw i64 %491, -8
  %493 = lshr exact i64 %492, 3
  %494 = add nuw nsw i64 %493, 1
  %495 = and i64 %494, 7
  %496 = icmp ult i64 %492, 56
  br i1 %496, label %544, label %497

497:                                              ; preds = %490
  %498 = sub nsw i64 %494, %495
  br label %499

499:                                              ; preds = %499, %497
  %500 = phi i64 [ 0, %497 ], [ %541, %499 ]
  %501 = phi i64 [ %498, %497 ], [ %542, %499 ]
  %502 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %500
  %503 = bitcast i32* %502 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %503, align 8, !alias.scope !91
  %504 = getelementptr inbounds i32, i32* %502, i64 4
  %505 = bitcast i32* %504 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %505, align 8, !alias.scope !91
  %506 = or i64 %500, 8
  %507 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %506
  %508 = bitcast i32* %507 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %508, align 8, !alias.scope !91
  %509 = getelementptr inbounds i32, i32* %507, i64 4
  %510 = bitcast i32* %509 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %510, align 8, !alias.scope !91
  %511 = or i64 %500, 16
  %512 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %511
  %513 = bitcast i32* %512 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %513, align 8, !alias.scope !91
  %514 = getelementptr inbounds i32, i32* %512, i64 4
  %515 = bitcast i32* %514 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %515, align 8, !alias.scope !91
  %516 = or i64 %500, 24
  %517 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %516
  %518 = bitcast i32* %517 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %518, align 8, !alias.scope !91
  %519 = getelementptr inbounds i32, i32* %517, i64 4
  %520 = bitcast i32* %519 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %520, align 8, !alias.scope !91
  %521 = or i64 %500, 32
  %522 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %521
  %523 = bitcast i32* %522 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %523, align 8, !alias.scope !91
  %524 = getelementptr inbounds i32, i32* %522, i64 4
  %525 = bitcast i32* %524 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %525, align 8, !alias.scope !91
  %526 = or i64 %500, 40
  %527 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %526
  %528 = bitcast i32* %527 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %528, align 8, !alias.scope !91
  %529 = getelementptr inbounds i32, i32* %527, i64 4
  %530 = bitcast i32* %529 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %530, align 8, !alias.scope !91
  %531 = or i64 %500, 48
  %532 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %531
  %533 = bitcast i32* %532 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %533, align 8, !alias.scope !91
  %534 = getelementptr inbounds i32, i32* %532, i64 4
  %535 = bitcast i32* %534 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %535, align 8, !alias.scope !91
  %536 = or i64 %500, 56
  %537 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %536
  %538 = bitcast i32* %537 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %538, align 8, !alias.scope !91
  %539 = getelementptr inbounds i32, i32* %537, i64 4
  %540 = bitcast i32* %539 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %540, align 8, !alias.scope !91
  %541 = add i64 %500, 64
  %542 = add i64 %501, -8
  %543 = icmp eq i64 %542, 0
  br i1 %543, label %544, label %499, !llvm.loop !94

544:                                              ; preds = %499, %490
  %545 = phi i64 [ 0, %490 ], [ %541, %499 ]
  %546 = icmp eq i64 %495, 0
  br i1 %546, label %557, label %547

547:                                              ; preds = %544, %547
  %548 = phi i64 [ %554, %547 ], [ %545, %544 ]
  %549 = phi i64 [ %555, %547 ], [ %495, %544 ]
  %550 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %548
  %551 = bitcast i32* %550 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %551, align 8, !alias.scope !91
  %552 = getelementptr inbounds i32, i32* %550, i64 4
  %553 = bitcast i32* %552 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %553, align 8, !alias.scope !91
  %554 = add i64 %548, 8
  %555 = add i64 %549, -1
  %556 = icmp eq i64 %555, 0
  br i1 %556, label %557, label %547, !llvm.loop !95

557:                                              ; preds = %547, %544
  %558 = icmp eq i64 %491, %488
  br i1 %558, label %566, label %559

559:                                              ; preds = %557, %486
  %560 = phi i64 [ 0, %486 ], [ %491, %557 ]
  br label %561

561:                                              ; preds = %559, %561
  %562 = phi i64 [ %564, %561 ], [ %560, %559 ]
  %563 = getelementptr inbounds [5 x i32], [5 x i32]* %487, i64 0, i64 %562
  store i32 1, i32* %563, align 4, !alias.scope !91
  %564 = add nuw nsw i64 %562, 1
  %565 = icmp eq i64 %564, %488
  br i1 %565, label %566, label %561, !llvm.loop !96

566:                                              ; preds = %561, %557, %482
  %567 = getelementptr inbounds %union.anon, %union.anon* %485, i64 0, i32 0
  %568 = bitcast %union.anon* %485 to i32*
  %569 = sext i32 %483 to i64
  %570 = getelementptr inbounds i32, i32* %568, i64 %569
  %571 = bitcast i32* %570 to i8*
  %572 = icmp sgt i32 %479, 5
  %573 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %574 = getelementptr inbounds %union.anon, %union.anon* %573, i64 0, i32 0
  %575 = load i32*, i32** %574, align 8, !noalias !91
  %576 = bitcast %union.anon* %573 to i32*
  %577 = select i1 %572, i32* %575, i32* %576
  %578 = bitcast i32* %577 to i8*
  %579 = sext i32 %479 to i64
  %580 = shl nsw i64 %579, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %571, i8* align 4 %578, i64 %580, i1 false) #18
  %581 = bitcast %"class.tflite::RuntimeShape"* %35 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %581) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %581, i8 -86, i64 32, i1 false)
  %582 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %35, i64 0, i32 0
  store i32 0, i32* %582, align 8, !alias.scope !97
  %583 = load i32, i32* %61, align 8, !noalias !97
  %584 = icmp sgt i32 %583, 4
  br i1 %584, label %585, label %586

585:                                              ; preds = %566
  tail call void @abort() #19, !noalias !97
  unreachable

586:                                              ; preds = %566
  store i32 4, i32* %582, align 8, !alias.scope !97
  %587 = sub i32 4, %583
  %588 = icmp sgt i32 %587, 0
  %589 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %35, i64 0, i32 1
  br i1 %588, label %590, label %670

590:                                              ; preds = %586
  %591 = bitcast %union.anon* %589 to [5 x i32]*
  %592 = zext i32 %587 to i64
  %593 = icmp ult i32 %587, 8
  br i1 %593, label %663, label %594

594:                                              ; preds = %590
  %595 = and i64 %592, 4294967288
  %596 = add nsw i64 %595, -8
  %597 = lshr exact i64 %596, 3
  %598 = add nuw nsw i64 %597, 1
  %599 = and i64 %598, 7
  %600 = icmp ult i64 %596, 56
  br i1 %600, label %648, label %601

601:                                              ; preds = %594
  %602 = sub nsw i64 %598, %599
  br label %603

603:                                              ; preds = %603, %601
  %604 = phi i64 [ 0, %601 ], [ %645, %603 ]
  %605 = phi i64 [ %602, %601 ], [ %646, %603 ]
  %606 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %604
  %607 = bitcast i32* %606 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %607, align 8, !alias.scope !97
  %608 = getelementptr inbounds i32, i32* %606, i64 4
  %609 = bitcast i32* %608 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %609, align 8, !alias.scope !97
  %610 = or i64 %604, 8
  %611 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %610
  %612 = bitcast i32* %611 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %612, align 8, !alias.scope !97
  %613 = getelementptr inbounds i32, i32* %611, i64 4
  %614 = bitcast i32* %613 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %614, align 8, !alias.scope !97
  %615 = or i64 %604, 16
  %616 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %615
  %617 = bitcast i32* %616 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %617, align 8, !alias.scope !97
  %618 = getelementptr inbounds i32, i32* %616, i64 4
  %619 = bitcast i32* %618 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %619, align 8, !alias.scope !97
  %620 = or i64 %604, 24
  %621 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %620
  %622 = bitcast i32* %621 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %622, align 8, !alias.scope !97
  %623 = getelementptr inbounds i32, i32* %621, i64 4
  %624 = bitcast i32* %623 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %624, align 8, !alias.scope !97
  %625 = or i64 %604, 32
  %626 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %625
  %627 = bitcast i32* %626 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %627, align 8, !alias.scope !97
  %628 = getelementptr inbounds i32, i32* %626, i64 4
  %629 = bitcast i32* %628 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %629, align 8, !alias.scope !97
  %630 = or i64 %604, 40
  %631 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %630
  %632 = bitcast i32* %631 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %632, align 8, !alias.scope !97
  %633 = getelementptr inbounds i32, i32* %631, i64 4
  %634 = bitcast i32* %633 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %634, align 8, !alias.scope !97
  %635 = or i64 %604, 48
  %636 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %635
  %637 = bitcast i32* %636 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %637, align 8, !alias.scope !97
  %638 = getelementptr inbounds i32, i32* %636, i64 4
  %639 = bitcast i32* %638 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %639, align 8, !alias.scope !97
  %640 = or i64 %604, 56
  %641 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %640
  %642 = bitcast i32* %641 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %642, align 8, !alias.scope !97
  %643 = getelementptr inbounds i32, i32* %641, i64 4
  %644 = bitcast i32* %643 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %644, align 8, !alias.scope !97
  %645 = add i64 %604, 64
  %646 = add i64 %605, -8
  %647 = icmp eq i64 %646, 0
  br i1 %647, label %648, label %603, !llvm.loop !100

648:                                              ; preds = %603, %594
  %649 = phi i64 [ 0, %594 ], [ %645, %603 ]
  %650 = icmp eq i64 %599, 0
  br i1 %650, label %661, label %651

651:                                              ; preds = %648, %651
  %652 = phi i64 [ %658, %651 ], [ %649, %648 ]
  %653 = phi i64 [ %659, %651 ], [ %599, %648 ]
  %654 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %652
  %655 = bitcast i32* %654 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %655, align 8, !alias.scope !97
  %656 = getelementptr inbounds i32, i32* %654, i64 4
  %657 = bitcast i32* %656 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %657, align 8, !alias.scope !97
  %658 = add i64 %652, 8
  %659 = add i64 %653, -1
  %660 = icmp eq i64 %659, 0
  br i1 %660, label %661, label %651, !llvm.loop !101

661:                                              ; preds = %651, %648
  %662 = icmp eq i64 %595, %592
  br i1 %662, label %670, label %663

663:                                              ; preds = %661, %590
  %664 = phi i64 [ 0, %590 ], [ %595, %661 ]
  br label %665

665:                                              ; preds = %663, %665
  %666 = phi i64 [ %668, %665 ], [ %664, %663 ]
  %667 = getelementptr inbounds [5 x i32], [5 x i32]* %591, i64 0, i64 %666
  store i32 1, i32* %667, align 4, !alias.scope !97
  %668 = add nuw nsw i64 %666, 1
  %669 = icmp eq i64 %668, %592
  br i1 %669, label %670, label %665, !llvm.loop !102

670:                                              ; preds = %665, %661, %586
  %671 = getelementptr inbounds %union.anon, %union.anon* %589, i64 0, i32 0
  %672 = bitcast %union.anon* %589 to i32*
  %673 = sext i32 %587 to i64
  %674 = getelementptr inbounds i32, i32* %672, i64 %673
  %675 = bitcast i32* %674 to i8*
  %676 = icmp sgt i32 %583, 5
  %677 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %678 = getelementptr inbounds %union.anon, %union.anon* %677, i64 0, i32 0
  %679 = load i32*, i32** %678, align 8, !noalias !97
  %680 = bitcast %union.anon* %677 to i32*
  %681 = select i1 %676, i32* %679, i32* %680
  %682 = bitcast i32* %681 to i8*
  %683 = sext i32 %583 to i64
  %684 = shl nsw i64 %683, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %675, i8* align 4 %682, i64 %684, i1 false) #18
  %685 = bitcast %"class.tflite::RuntimeShape"* %36 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %685) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %685, i8 -86, i64 32, i1 false)
  %686 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %36, i64 0, i32 0
  store i32 0, i32* %686, align 8, !alias.scope !103
  %687 = load i32, i32* %62, align 8, !noalias !103
  %688 = icmp sgt i32 %687, 4
  br i1 %688, label %689, label %690

689:                                              ; preds = %670
  tail call void @abort() #19, !noalias !103
  unreachable

690:                                              ; preds = %670
  store i32 4, i32* %686, align 8, !alias.scope !103
  %691 = sub i32 4, %687
  %692 = icmp sgt i32 %691, 0
  %693 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %36, i64 0, i32 1
  br i1 %692, label %694, label %774

694:                                              ; preds = %690
  %695 = bitcast %union.anon* %693 to [5 x i32]*
  %696 = zext i32 %691 to i64
  %697 = icmp ult i32 %691, 8
  br i1 %697, label %767, label %698

698:                                              ; preds = %694
  %699 = and i64 %696, 4294967288
  %700 = add nsw i64 %699, -8
  %701 = lshr exact i64 %700, 3
  %702 = add nuw nsw i64 %701, 1
  %703 = and i64 %702, 7
  %704 = icmp ult i64 %700, 56
  br i1 %704, label %752, label %705

705:                                              ; preds = %698
  %706 = sub nsw i64 %702, %703
  br label %707

707:                                              ; preds = %707, %705
  %708 = phi i64 [ 0, %705 ], [ %749, %707 ]
  %709 = phi i64 [ %706, %705 ], [ %750, %707 ]
  %710 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %708
  %711 = bitcast i32* %710 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %711, align 8, !alias.scope !103
  %712 = getelementptr inbounds i32, i32* %710, i64 4
  %713 = bitcast i32* %712 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %713, align 8, !alias.scope !103
  %714 = or i64 %708, 8
  %715 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %714
  %716 = bitcast i32* %715 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %716, align 8, !alias.scope !103
  %717 = getelementptr inbounds i32, i32* %715, i64 4
  %718 = bitcast i32* %717 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %718, align 8, !alias.scope !103
  %719 = or i64 %708, 16
  %720 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %719
  %721 = bitcast i32* %720 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %721, align 8, !alias.scope !103
  %722 = getelementptr inbounds i32, i32* %720, i64 4
  %723 = bitcast i32* %722 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %723, align 8, !alias.scope !103
  %724 = or i64 %708, 24
  %725 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %724
  %726 = bitcast i32* %725 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %726, align 8, !alias.scope !103
  %727 = getelementptr inbounds i32, i32* %725, i64 4
  %728 = bitcast i32* %727 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %728, align 8, !alias.scope !103
  %729 = or i64 %708, 32
  %730 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %729
  %731 = bitcast i32* %730 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %731, align 8, !alias.scope !103
  %732 = getelementptr inbounds i32, i32* %730, i64 4
  %733 = bitcast i32* %732 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %733, align 8, !alias.scope !103
  %734 = or i64 %708, 40
  %735 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %734
  %736 = bitcast i32* %735 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %736, align 8, !alias.scope !103
  %737 = getelementptr inbounds i32, i32* %735, i64 4
  %738 = bitcast i32* %737 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %738, align 8, !alias.scope !103
  %739 = or i64 %708, 48
  %740 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %739
  %741 = bitcast i32* %740 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %741, align 8, !alias.scope !103
  %742 = getelementptr inbounds i32, i32* %740, i64 4
  %743 = bitcast i32* %742 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %743, align 8, !alias.scope !103
  %744 = or i64 %708, 56
  %745 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %744
  %746 = bitcast i32* %745 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %746, align 8, !alias.scope !103
  %747 = getelementptr inbounds i32, i32* %745, i64 4
  %748 = bitcast i32* %747 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %748, align 8, !alias.scope !103
  %749 = add i64 %708, 64
  %750 = add i64 %709, -8
  %751 = icmp eq i64 %750, 0
  br i1 %751, label %752, label %707, !llvm.loop !106

752:                                              ; preds = %707, %698
  %753 = phi i64 [ 0, %698 ], [ %749, %707 ]
  %754 = icmp eq i64 %703, 0
  br i1 %754, label %765, label %755

755:                                              ; preds = %752, %755
  %756 = phi i64 [ %762, %755 ], [ %753, %752 ]
  %757 = phi i64 [ %763, %755 ], [ %703, %752 ]
  %758 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %756
  %759 = bitcast i32* %758 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %759, align 8, !alias.scope !103
  %760 = getelementptr inbounds i32, i32* %758, i64 4
  %761 = bitcast i32* %760 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %761, align 8, !alias.scope !103
  %762 = add i64 %756, 8
  %763 = add i64 %757, -1
  %764 = icmp eq i64 %763, 0
  br i1 %764, label %765, label %755, !llvm.loop !107

765:                                              ; preds = %755, %752
  %766 = icmp eq i64 %699, %696
  br i1 %766, label %774, label %767

767:                                              ; preds = %765, %694
  %768 = phi i64 [ 0, %694 ], [ %699, %765 ]
  br label %769

769:                                              ; preds = %767, %769
  %770 = phi i64 [ %772, %769 ], [ %768, %767 ]
  %771 = getelementptr inbounds [5 x i32], [5 x i32]* %695, i64 0, i64 %770
  store i32 1, i32* %771, align 4, !alias.scope !103
  %772 = add nuw nsw i64 %770, 1
  %773 = icmp eq i64 %772, %696
  br i1 %773, label %774, label %769, !llvm.loop !108

774:                                              ; preds = %769, %765, %690
  %775 = getelementptr inbounds %union.anon, %union.anon* %693, i64 0, i32 0
  %776 = bitcast %union.anon* %693 to i32*
  %777 = sext i32 %691 to i64
  %778 = getelementptr inbounds i32, i32* %776, i64 %777
  %779 = bitcast i32* %778 to i8*
  %780 = icmp sgt i32 %687, 5
  %781 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1
  %782 = getelementptr inbounds %union.anon, %union.anon* %781, i64 0, i32 0
  %783 = load i32*, i32** %782, align 8, !noalias !103
  %784 = bitcast %union.anon* %781 to i32*
  %785 = select i1 %780, i32* %783, i32* %784
  %786 = bitcast i32* %785 to i8*
  %787 = sext i32 %687 to i64
  %788 = shl nsw i64 %787, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %779, i8* align 4 %786, i64 %788, i1 false) #18
  %789 = bitcast %"class.tflite::RuntimeShape"* %37 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %789) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %789, i8 -86, i64 32, i1 false)
  %790 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %37, i64 0, i32 0
  store i32 0, i32* %790, align 8, !alias.scope !109
  %791 = load i32, i32* %63, align 8, !noalias !109
  %792 = icmp sgt i32 %791, 4
  br i1 %792, label %793, label %794

793:                                              ; preds = %774
  tail call void @abort() #19, !noalias !109
  unreachable

794:                                              ; preds = %774
  store i32 4, i32* %790, align 8, !alias.scope !109
  %795 = sub i32 4, %791
  %796 = icmp sgt i32 %795, 0
  %797 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %37, i64 0, i32 1
  br i1 %796, label %798, label %878

798:                                              ; preds = %794
  %799 = bitcast %union.anon* %797 to [5 x i32]*
  %800 = zext i32 %795 to i64
  %801 = icmp ult i32 %795, 8
  br i1 %801, label %871, label %802

802:                                              ; preds = %798
  %803 = and i64 %800, 4294967288
  %804 = add nsw i64 %803, -8
  %805 = lshr exact i64 %804, 3
  %806 = add nuw nsw i64 %805, 1
  %807 = and i64 %806, 7
  %808 = icmp ult i64 %804, 56
  br i1 %808, label %856, label %809

809:                                              ; preds = %802
  %810 = sub nsw i64 %806, %807
  br label %811

811:                                              ; preds = %811, %809
  %812 = phi i64 [ 0, %809 ], [ %853, %811 ]
  %813 = phi i64 [ %810, %809 ], [ %854, %811 ]
  %814 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %812
  %815 = bitcast i32* %814 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %815, align 8, !alias.scope !109
  %816 = getelementptr inbounds i32, i32* %814, i64 4
  %817 = bitcast i32* %816 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %817, align 8, !alias.scope !109
  %818 = or i64 %812, 8
  %819 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %818
  %820 = bitcast i32* %819 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %820, align 8, !alias.scope !109
  %821 = getelementptr inbounds i32, i32* %819, i64 4
  %822 = bitcast i32* %821 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %822, align 8, !alias.scope !109
  %823 = or i64 %812, 16
  %824 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %823
  %825 = bitcast i32* %824 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %825, align 8, !alias.scope !109
  %826 = getelementptr inbounds i32, i32* %824, i64 4
  %827 = bitcast i32* %826 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %827, align 8, !alias.scope !109
  %828 = or i64 %812, 24
  %829 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %828
  %830 = bitcast i32* %829 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %830, align 8, !alias.scope !109
  %831 = getelementptr inbounds i32, i32* %829, i64 4
  %832 = bitcast i32* %831 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %832, align 8, !alias.scope !109
  %833 = or i64 %812, 32
  %834 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %833
  %835 = bitcast i32* %834 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %835, align 8, !alias.scope !109
  %836 = getelementptr inbounds i32, i32* %834, i64 4
  %837 = bitcast i32* %836 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %837, align 8, !alias.scope !109
  %838 = or i64 %812, 40
  %839 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %838
  %840 = bitcast i32* %839 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %840, align 8, !alias.scope !109
  %841 = getelementptr inbounds i32, i32* %839, i64 4
  %842 = bitcast i32* %841 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %842, align 8, !alias.scope !109
  %843 = or i64 %812, 48
  %844 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %843
  %845 = bitcast i32* %844 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %845, align 8, !alias.scope !109
  %846 = getelementptr inbounds i32, i32* %844, i64 4
  %847 = bitcast i32* %846 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %847, align 8, !alias.scope !109
  %848 = or i64 %812, 56
  %849 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %848
  %850 = bitcast i32* %849 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %850, align 8, !alias.scope !109
  %851 = getelementptr inbounds i32, i32* %849, i64 4
  %852 = bitcast i32* %851 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %852, align 8, !alias.scope !109
  %853 = add i64 %812, 64
  %854 = add i64 %813, -8
  %855 = icmp eq i64 %854, 0
  br i1 %855, label %856, label %811, !llvm.loop !112

856:                                              ; preds = %811, %802
  %857 = phi i64 [ 0, %802 ], [ %853, %811 ]
  %858 = icmp eq i64 %807, 0
  br i1 %858, label %869, label %859

859:                                              ; preds = %856, %859
  %860 = phi i64 [ %866, %859 ], [ %857, %856 ]
  %861 = phi i64 [ %867, %859 ], [ %807, %856 ]
  %862 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %860
  %863 = bitcast i32* %862 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %863, align 8, !alias.scope !109
  %864 = getelementptr inbounds i32, i32* %862, i64 4
  %865 = bitcast i32* %864 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %865, align 8, !alias.scope !109
  %866 = add i64 %860, 8
  %867 = add i64 %861, -1
  %868 = icmp eq i64 %867, 0
  br i1 %868, label %869, label %859, !llvm.loop !113

869:                                              ; preds = %859, %856
  %870 = icmp eq i64 %803, %800
  br i1 %870, label %878, label %871

871:                                              ; preds = %869, %798
  %872 = phi i64 [ 0, %798 ], [ %803, %869 ]
  br label %873

873:                                              ; preds = %871, %873
  %874 = phi i64 [ %876, %873 ], [ %872, %871 ]
  %875 = getelementptr inbounds [5 x i32], [5 x i32]* %799, i64 0, i64 %874
  store i32 1, i32* %875, align 4, !alias.scope !109
  %876 = add nuw nsw i64 %874, 1
  %877 = icmp eq i64 %876, %800
  br i1 %877, label %878, label %873, !llvm.loop !114

878:                                              ; preds = %873, %869, %794
  %879 = getelementptr inbounds %union.anon, %union.anon* %797, i64 0, i32 0
  %880 = bitcast %union.anon* %797 to i32*
  %881 = sext i32 %795 to i64
  %882 = getelementptr inbounds i32, i32* %880, i64 %881
  %883 = bitcast i32* %882 to i8*
  %884 = icmp sgt i32 %791, 5
  %885 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  %886 = getelementptr inbounds %union.anon, %union.anon* %885, i64 0, i32 0
  %887 = load i32*, i32** %886, align 8, !noalias !109
  %888 = bitcast %union.anon* %885 to i32*
  %889 = select i1 %884, i32* %887, i32* %888
  %890 = bitcast i32* %889 to i8*
  %891 = sext i32 %791 to i64
  %892 = shl nsw i64 %891, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %883, i8* align 4 %890, i64 %892, i1 false) #18
  %893 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %38, i64 0, i32 0
  %894 = load i32, i32* %374, align 8
  store i32 %894, i32* %893, align 8
  %895 = icmp sgt i32 %894, 5
  br i1 %895, label %896, label %903

896:                                              ; preds = %878
  %897 = sext i32 %894 to i64
  %898 = shl nsw i64 %897, 2
  %899 = tail call i8* @_Znam(i64 %898) #17
  %900 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %38, i64 0, i32 1, i32 0
  %901 = bitcast i32** %900 to i8**
  store i8* %899, i8** %901, align 8
  %902 = bitcast i8* %899 to i32*
  br label %908

903:                                              ; preds = %878
  %904 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %38, i64 0, i32 1
  %905 = bitcast %union.anon* %904 to i32*
  %906 = sext i32 %894 to i64
  %907 = shl nsw i64 %906, 2
  br label %908

908:                                              ; preds = %896, %903
  %909 = phi i64 [ %898, %896 ], [ %907, %903 ]
  %910 = phi i32* [ %902, %896 ], [ %905, %903 ]
  %911 = bitcast i32* %910 to i8*
  %912 = load i32*, i32** %463, align 8
  %913 = select i1 %895, i32* %912, i32* %464
  %914 = bitcast i32* %913 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %911, i8* align 4 %914, i64 %909, i1 false) #18
  %915 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %39, i64 0, i32 0
  %916 = load i32, i32* %478, align 8
  store i32 %916, i32* %915, align 8
  %917 = icmp sgt i32 %916, 5
  br i1 %917, label %918, label %925

918:                                              ; preds = %908
  %919 = sext i32 %916 to i64
  %920 = shl nsw i64 %919, 2
  %921 = tail call i8* @_Znam(i64 %920) #17
  %922 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %39, i64 0, i32 1, i32 0
  %923 = bitcast i32** %922 to i8**
  store i8* %921, i8** %923, align 8
  %924 = bitcast i8* %921 to i32*
  br label %930

925:                                              ; preds = %908
  %926 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %39, i64 0, i32 1
  %927 = bitcast %union.anon* %926 to i32*
  %928 = sext i32 %916 to i64
  %929 = shl nsw i64 %928, 2
  br label %930

930:                                              ; preds = %918, %925
  %931 = phi i64 [ %920, %918 ], [ %929, %925 ]
  %932 = phi i32* [ %924, %918 ], [ %927, %925 ]
  %933 = bitcast i32* %932 to i8*
  %934 = load i32*, i32** %567, align 8
  %935 = select i1 %917, i32* %934, i32* %568
  %936 = bitcast i32* %935 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %933, i8* align 4 %936, i64 %931, i1 false) #18
  %937 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %40, i64 0, i32 0
  %938 = load i32, i32* %582, align 8
  store i32 %938, i32* %937, align 8
  %939 = icmp sgt i32 %938, 5
  br i1 %939, label %940, label %947

940:                                              ; preds = %930
  %941 = sext i32 %938 to i64
  %942 = shl nsw i64 %941, 2
  %943 = tail call i8* @_Znam(i64 %942) #17
  %944 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %40, i64 0, i32 1, i32 0
  %945 = bitcast i32** %944 to i8**
  store i8* %943, i8** %945, align 8
  %946 = bitcast i8* %943 to i32*
  br label %952

947:                                              ; preds = %930
  %948 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %40, i64 0, i32 1
  %949 = bitcast %union.anon* %948 to i32*
  %950 = sext i32 %938 to i64
  %951 = shl nsw i64 %950, 2
  br label %952

952:                                              ; preds = %940, %947
  %953 = phi i64 [ %942, %940 ], [ %951, %947 ]
  %954 = phi i32* [ %946, %940 ], [ %949, %947 ]
  %955 = bitcast i32* %954 to i8*
  %956 = load i32*, i32** %671, align 8
  %957 = select i1 %939, i32* %956, i32* %672
  %958 = bitcast i32* %957 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %955, i8* align 4 %958, i64 %953, i1 false) #18
  %959 = call i32 @_ZN6tflite11MatchingDimIJNS_12RuntimeShapeEiS1_iS1_iEEEiRKS1_iS3_iDpT_(%"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %30, i32 0, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %31, i32 0, %"class.tflite::RuntimeShape"* nonnull %38, i32 0, %"class.tflite::RuntimeShape"* nonnull %39, i32 0, %"class.tflite::RuntimeShape"* nonnull %40, i32 0)
  %960 = load i32, i32* %937, align 8
  %961 = icmp sgt i32 %960, 5
  br i1 %961, label %962, label %968

962:                                              ; preds = %952
  %963 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %40, i64 0, i32 1, i32 0
  %964 = load i32*, i32** %963, align 8
  %965 = icmp eq i32* %964, null
  br i1 %965, label %968, label %966

966:                                              ; preds = %962
  %967 = bitcast i32* %964 to i8*
  call void @_ZdaPv(i8* %967) #17
  br label %968

968:                                              ; preds = %952, %962, %966
  %969 = load i32, i32* %915, align 8
  %970 = icmp sgt i32 %969, 5
  br i1 %970, label %971, label %977

971:                                              ; preds = %968
  %972 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %39, i64 0, i32 1, i32 0
  %973 = load i32*, i32** %972, align 8
  %974 = icmp eq i32* %973, null
  br i1 %974, label %977, label %975

975:                                              ; preds = %971
  %976 = bitcast i32* %973 to i8*
  call void @_ZdaPv(i8* %976) #17
  br label %977

977:                                              ; preds = %968, %971, %975
  %978 = load i32, i32* %893, align 8
  %979 = icmp sgt i32 %978, 5
  br i1 %979, label %980, label %986

980:                                              ; preds = %977
  %981 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %38, i64 0, i32 1, i32 0
  %982 = load i32*, i32** %981, align 8
  %983 = icmp eq i32* %982, null
  br i1 %983, label %986, label %984

984:                                              ; preds = %980
  %985 = bitcast i32* %982 to i8*
  call void @_ZdaPv(i8* %985) #17
  br label %986

986:                                              ; preds = %977, %980, %984
  %987 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %41, i64 0, i32 0
  store i32 %894, i32* %987, align 8
  br i1 %895, label %988, label %995

988:                                              ; preds = %986
  %989 = sext i32 %894 to i64
  %990 = shl nsw i64 %989, 2
  %991 = call i8* @_Znam(i64 %990) #17
  %992 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %41, i64 0, i32 1, i32 0
  %993 = bitcast i32** %992 to i8**
  store i8* %991, i8** %993, align 8
  %994 = bitcast i8* %991 to i32*
  br label %1000

995:                                              ; preds = %986
  %996 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %41, i64 0, i32 1
  %997 = bitcast %union.anon* %996 to i32*
  %998 = sext i32 %894 to i64
  %999 = shl nsw i64 %998, 2
  br label %1000

1000:                                             ; preds = %988, %995
  %1001 = phi i64 [ %990, %988 ], [ %999, %995 ]
  %1002 = phi i32* [ %994, %988 ], [ %997, %995 ]
  %1003 = bitcast i32* %1002 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1003, i8* align 4 %914, i64 %1001, i1 false) #18
  %1004 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %42, i64 0, i32 0
  store i32 %916, i32* %1004, align 8
  br i1 %917, label %1005, label %1012

1005:                                             ; preds = %1000
  %1006 = sext i32 %916 to i64
  %1007 = shl nsw i64 %1006, 2
  %1008 = call i8* @_Znam(i64 %1007) #17
  %1009 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %42, i64 0, i32 1, i32 0
  %1010 = bitcast i32** %1009 to i8**
  store i8* %1008, i8** %1010, align 8
  %1011 = bitcast i8* %1008 to i32*
  br label %1017

1012:                                             ; preds = %1000
  %1013 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %42, i64 0, i32 1
  %1014 = bitcast %union.anon* %1013 to i32*
  %1015 = sext i32 %916 to i64
  %1016 = shl nsw i64 %1015, 2
  br label %1017

1017:                                             ; preds = %1005, %1012
  %1018 = phi i64 [ %1007, %1005 ], [ %1016, %1012 ]
  %1019 = phi i32* [ %1011, %1005 ], [ %1014, %1012 ]
  %1020 = bitcast i32* %1019 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1020, i8* align 4 %936, i64 %1018, i1 false) #18
  %1021 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %43, i64 0, i32 0
  store i32 %938, i32* %1021, align 8
  br i1 %939, label %1022, label %1029

1022:                                             ; preds = %1017
  %1023 = sext i32 %938 to i64
  %1024 = shl nsw i64 %1023, 2
  %1025 = call i8* @_Znam(i64 %1024) #17
  %1026 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %43, i64 0, i32 1, i32 0
  %1027 = bitcast i32** %1026 to i8**
  store i8* %1025, i8** %1027, align 8
  %1028 = bitcast i8* %1025 to i32*
  br label %1034

1029:                                             ; preds = %1017
  %1030 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %43, i64 0, i32 1
  %1031 = bitcast %union.anon* %1030 to i32*
  %1032 = sext i32 %938 to i64
  %1033 = shl nsw i64 %1032, 2
  br label %1034

1034:                                             ; preds = %1022, %1029
  %1035 = phi i64 [ %1024, %1022 ], [ %1033, %1029 ]
  %1036 = phi i32* [ %1028, %1022 ], [ %1031, %1029 ]
  %1037 = bitcast i32* %1036 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1037, i8* align 4 %958, i64 %1035, i1 false) #18
  %1038 = call i32 @_ZN6tflite11MatchingDimIJNS_12RuntimeShapeEiS1_iS1_iEEEiRKS1_iS3_iDpT_(%"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %30, i32 1, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %31, i32 1, %"class.tflite::RuntimeShape"* nonnull %41, i32 1, %"class.tflite::RuntimeShape"* nonnull %42, i32 1, %"class.tflite::RuntimeShape"* nonnull %43, i32 1)
  %1039 = load i32, i32* %1021, align 8
  %1040 = icmp sgt i32 %1039, 5
  br i1 %1040, label %1041, label %1047

1041:                                             ; preds = %1034
  %1042 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %43, i64 0, i32 1, i32 0
  %1043 = load i32*, i32** %1042, align 8
  %1044 = icmp eq i32* %1043, null
  br i1 %1044, label %1047, label %1045

1045:                                             ; preds = %1041
  %1046 = bitcast i32* %1043 to i8*
  call void @_ZdaPv(i8* %1046) #17
  br label %1047

1047:                                             ; preds = %1034, %1041, %1045
  %1048 = load i32, i32* %1004, align 8
  %1049 = icmp sgt i32 %1048, 5
  br i1 %1049, label %1050, label %1056

1050:                                             ; preds = %1047
  %1051 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %42, i64 0, i32 1, i32 0
  %1052 = load i32*, i32** %1051, align 8
  %1053 = icmp eq i32* %1052, null
  br i1 %1053, label %1056, label %1054

1054:                                             ; preds = %1050
  %1055 = bitcast i32* %1052 to i8*
  call void @_ZdaPv(i8* %1055) #17
  br label %1056

1056:                                             ; preds = %1047, %1050, %1054
  %1057 = load i32, i32* %987, align 8
  %1058 = icmp sgt i32 %1057, 5
  br i1 %1058, label %1059, label %1065

1059:                                             ; preds = %1056
  %1060 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %41, i64 0, i32 1, i32 0
  %1061 = load i32*, i32** %1060, align 8
  %1062 = icmp eq i32* %1061, null
  br i1 %1062, label %1065, label %1063

1063:                                             ; preds = %1059
  %1064 = bitcast i32* %1061 to i8*
  call void @_ZdaPv(i8* %1064) #17
  br label %1065

1065:                                             ; preds = %1056, %1059, %1063
  %1066 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %44, i64 0, i32 0
  store i32 %894, i32* %1066, align 8
  br i1 %895, label %1067, label %1074

1067:                                             ; preds = %1065
  %1068 = sext i32 %894 to i64
  %1069 = shl nsw i64 %1068, 2
  %1070 = call i8* @_Znam(i64 %1069) #17
  %1071 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %44, i64 0, i32 1, i32 0
  %1072 = bitcast i32** %1071 to i8**
  store i8* %1070, i8** %1072, align 8
  %1073 = bitcast i8* %1070 to i32*
  br label %1079

1074:                                             ; preds = %1065
  %1075 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %44, i64 0, i32 1
  %1076 = bitcast %union.anon* %1075 to i32*
  %1077 = sext i32 %894 to i64
  %1078 = shl nsw i64 %1077, 2
  br label %1079

1079:                                             ; preds = %1067, %1074
  %1080 = phi i64 [ %1069, %1067 ], [ %1078, %1074 ]
  %1081 = phi i32* [ %1073, %1067 ], [ %1076, %1074 ]
  %1082 = bitcast i32* %1081 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1082, i8* align 4 %914, i64 %1080, i1 false) #18
  %1083 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %45, i64 0, i32 0
  store i32 %916, i32* %1083, align 8
  br i1 %917, label %1084, label %1091

1084:                                             ; preds = %1079
  %1085 = sext i32 %916 to i64
  %1086 = shl nsw i64 %1085, 2
  %1087 = call i8* @_Znam(i64 %1086) #17
  %1088 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %45, i64 0, i32 1, i32 0
  %1089 = bitcast i32** %1088 to i8**
  store i8* %1087, i8** %1089, align 8
  %1090 = bitcast i8* %1087 to i32*
  br label %1096

1091:                                             ; preds = %1079
  %1092 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %45, i64 0, i32 1
  %1093 = bitcast %union.anon* %1092 to i32*
  %1094 = sext i32 %916 to i64
  %1095 = shl nsw i64 %1094, 2
  br label %1096

1096:                                             ; preds = %1084, %1091
  %1097 = phi i64 [ %1086, %1084 ], [ %1095, %1091 ]
  %1098 = phi i32* [ %1090, %1084 ], [ %1093, %1091 ]
  %1099 = bitcast i32* %1098 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1099, i8* align 4 %936, i64 %1097, i1 false) #18
  %1100 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %46, i64 0, i32 0
  store i32 %938, i32* %1100, align 8
  br i1 %939, label %1101, label %1108

1101:                                             ; preds = %1096
  %1102 = sext i32 %938 to i64
  %1103 = shl nsw i64 %1102, 2
  %1104 = call i8* @_Znam(i64 %1103) #17
  %1105 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %46, i64 0, i32 1, i32 0
  %1106 = bitcast i32** %1105 to i8**
  store i8* %1104, i8** %1106, align 8
  %1107 = bitcast i8* %1104 to i32*
  br label %1113

1108:                                             ; preds = %1096
  %1109 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %46, i64 0, i32 1
  %1110 = bitcast %union.anon* %1109 to i32*
  %1111 = sext i32 %938 to i64
  %1112 = shl nsw i64 %1111, 2
  br label %1113

1113:                                             ; preds = %1101, %1108
  %1114 = phi i64 [ %1103, %1101 ], [ %1112, %1108 ]
  %1115 = phi i32* [ %1107, %1101 ], [ %1110, %1108 ]
  %1116 = bitcast i32* %1115 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1116, i8* align 4 %958, i64 %1114, i1 false) #18
  %1117 = call i32 @_ZN6tflite11MatchingDimIJNS_12RuntimeShapeEiS1_iS1_iEEEiRKS1_iS3_iDpT_(%"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %30, i32 2, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %31, i32 2, %"class.tflite::RuntimeShape"* nonnull %44, i32 2, %"class.tflite::RuntimeShape"* nonnull %45, i32 2, %"class.tflite::RuntimeShape"* nonnull %46, i32 2)
  %1118 = load i32, i32* %1100, align 8
  %1119 = icmp sgt i32 %1118, 5
  br i1 %1119, label %1120, label %1126

1120:                                             ; preds = %1113
  %1121 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %46, i64 0, i32 1, i32 0
  %1122 = load i32*, i32** %1121, align 8
  %1123 = icmp eq i32* %1122, null
  br i1 %1123, label %1126, label %1124

1124:                                             ; preds = %1120
  %1125 = bitcast i32* %1122 to i8*
  call void @_ZdaPv(i8* %1125) #17
  br label %1126

1126:                                             ; preds = %1113, %1120, %1124
  %1127 = load i32, i32* %1083, align 8
  %1128 = icmp sgt i32 %1127, 5
  br i1 %1128, label %1129, label %1135

1129:                                             ; preds = %1126
  %1130 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %45, i64 0, i32 1, i32 0
  %1131 = load i32*, i32** %1130, align 8
  %1132 = icmp eq i32* %1131, null
  br i1 %1132, label %1135, label %1133

1133:                                             ; preds = %1129
  %1134 = bitcast i32* %1131 to i8*
  call void @_ZdaPv(i8* %1134) #17
  br label %1135

1135:                                             ; preds = %1126, %1129, %1133
  %1136 = load i32, i32* %1066, align 8
  %1137 = icmp sgt i32 %1136, 5
  br i1 %1137, label %1138, label %1144

1138:                                             ; preds = %1135
  %1139 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %44, i64 0, i32 1, i32 0
  %1140 = load i32*, i32** %1139, align 8
  %1141 = icmp eq i32* %1140, null
  br i1 %1141, label %1144, label %1142

1142:                                             ; preds = %1138
  %1143 = bitcast i32* %1140 to i8*
  call void @_ZdaPv(i8* %1143) #17
  br label %1144

1144:                                             ; preds = %1135, %1138, %1142
  %1145 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %47, i64 0, i32 0
  store i32 %916, i32* %1145, align 8
  br i1 %917, label %1146, label %1153

1146:                                             ; preds = %1144
  %1147 = sext i32 %916 to i64
  %1148 = shl nsw i64 %1147, 2
  %1149 = call i8* @_Znam(i64 %1148) #17
  %1150 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %47, i64 0, i32 1, i32 0
  %1151 = bitcast i32** %1150 to i8**
  store i8* %1149, i8** %1151, align 8
  %1152 = bitcast i8* %1149 to i32*
  br label %1158

1153:                                             ; preds = %1144
  %1154 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %47, i64 0, i32 1
  %1155 = bitcast %union.anon* %1154 to i32*
  %1156 = sext i32 %916 to i64
  %1157 = shl nsw i64 %1156, 2
  br label %1158

1158:                                             ; preds = %1146, %1153
  %1159 = phi i64 [ %1148, %1146 ], [ %1157, %1153 ]
  %1160 = phi i32* [ %1152, %1146 ], [ %1155, %1153 ]
  %1161 = bitcast i32* %1160 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1161, i8* align 4 %936, i64 %1159, i1 false) #18
  %1162 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %48, i64 0, i32 0
  store i32 %938, i32* %1162, align 8
  br i1 %939, label %1163, label %1175

1163:                                             ; preds = %1158
  %1164 = sext i32 %938 to i64
  %1165 = shl nsw i64 %1164, 2
  %1166 = call i8* @_Znam(i64 %1165) #17
  %1167 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %48, i64 0, i32 1, i32 0
  %1168 = bitcast i32** %1167 to i8**
  store i8* %1166, i8** %1168, align 8
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %1166, i8* align 4 %958, i64 %1165, i1 false) #18
  %1169 = bitcast %"class.tflite::RuntimeShape"* %21 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1169)
  %1170 = call i8* @_Znam(i64 %1165) #17
  %1171 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %1172 = bitcast i32** %1171 to i8**
  store i8* %1170, i8** %1172, align 8
  %1173 = bitcast i8* %1170 to i32*
  %1174 = bitcast i8* %1166 to i32*
  br label %1186

1175:                                             ; preds = %1158
  %1176 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %48, i64 0, i32 1
  %1177 = sext i32 %938 to i64
  %1178 = shl nsw i64 %1177, 2
  %1179 = bitcast %union.anon* %1176 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %1179, i8* align 4 %958, i64 %1178, i1 false) #18
  %1180 = bitcast %"class.tflite::RuntimeShape"* %21 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1180)
  %1181 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1
  %1182 = bitcast %union.anon* %1181 to i32*
  %1183 = getelementptr inbounds %union.anon, %union.anon* %1176, i64 0, i32 0
  %1184 = load i32*, i32** %1183, align 8
  %1185 = bitcast i32* %1184 to i8*
  br label %1186

1186:                                             ; preds = %1175, %1163
  %1187 = phi i8* [ %1166, %1163 ], [ %1185, %1175 ]
  %1188 = phi i32* [ %1174, %1163 ], [ %1184, %1175 ]
  %1189 = phi i8* [ %1169, %1163 ], [ %1180, %1175 ]
  %1190 = phi i64 [ %1165, %1163 ], [ %1178, %1175 ]
  %1191 = phi i32* [ %1173, %1163 ], [ %1182, %1175 ]
  %1192 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  store i32 %938, i32* %1192, align 8
  %1193 = bitcast i32* %1191 to i8*
  %1194 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %48, i64 0, i32 1
  %1195 = bitcast %union.anon* %1194 to i32*
  %1196 = select i1 %939, i32* %1188, i32* %1195
  %1197 = bitcast i32* %1196 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1193, i8* align 4 %1197, i64 %1190, i1 false) #18
  %1198 = getelementptr inbounds i32, i32* %912, i64 3
  %1199 = bitcast %union.anon* %381 to [5 x i32]*
  %1200 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %33, i64 0, i32 1, i32 1, i64 4
  %1201 = bitcast i8* %1200 to i32*
  %1202 = select i1 %895, i32* %1198, i32* %1201
  %1203 = load i32, i32* %1202, align 4
  %1204 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %1205 = load i32*, i32** %1204, align 8
  %1206 = getelementptr inbounds i32, i32* %1205, i64 3
  %1207 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 1, i64 4
  %1208 = bitcast i8* %1207 to i32*
  %1209 = select i1 %939, i32* %1206, i32* %1208
  %1210 = load i32, i32* %1209, align 4
  %1211 = icmp slt i32 %1210, %1203
  %1212 = select i1 %1211, i32 %1210, i32 %1203
  %1213 = xor i1 %939, true
  %1214 = icmp eq i32* %1205, null
  %1215 = or i1 %1214, %1213
  br i1 %1215, label %1218, label %1216

1216:                                             ; preds = %1186
  %1217 = bitcast i32* %1205 to i8*
  call void @_ZdaPv(i8* %1217) #17
  br label %1218

1218:                                             ; preds = %1186, %1216
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1189)
  %1219 = xor i1 %939, true
  %1220 = icmp eq i32* %1188, null
  %1221 = or i1 %1220, %1219
  br i1 %1221, label %1223, label %1222

1222:                                             ; preds = %1218
  call void @_ZdaPv(i8* %1187) #17
  br label %1223

1223:                                             ; preds = %1218, %1222
  br i1 %917, label %1224, label %1230

1224:                                             ; preds = %1223
  %1225 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %47, i64 0, i32 1, i32 0
  %1226 = load i32*, i32** %1225, align 8
  %1227 = icmp eq i32* %1226, null
  br i1 %1227, label %1230, label %1228

1228:                                             ; preds = %1224
  %1229 = bitcast i32* %1226 to i8*
  call void @_ZdaPv(i8* %1229) #17
  br label %1230

1230:                                             ; preds = %1223, %1224, %1228
  %1231 = bitcast %"class.std::__1::vector.45"* %49 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %1231) #18
  %1232 = getelementptr inbounds %"class.std::__1::vector.45", %"class.std::__1::vector.45"* %49, i64 0, i32 0, i32 0
  %1233 = getelementptr inbounds %"class.std::__1::vector.45", %"class.std::__1::vector.45"* %49, i64 0, i32 0, i32 1
  %1234 = getelementptr inbounds %"class.std::__1::vector.45", %"class.std::__1::vector.45"* %49, i64 0, i32 0, i32 2, i32 0, i32 0
  %1235 = bitcast %"class.std::__1::vector.52"* %50 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %1235) #18
  %1236 = getelementptr inbounds %"class.std::__1::vector.52", %"class.std::__1::vector.52"* %50, i64 0, i32 0, i32 0
  %1237 = getelementptr inbounds %"class.std::__1::vector.52", %"class.std::__1::vector.52"* %50, i64 0, i32 0, i32 1
  %1238 = getelementptr inbounds %"class.std::__1::vector.52", %"class.std::__1::vector.52"* %50, i64 0, i32 0, i32 2, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1235, i8 0, i64 24, i1 false) #18
  %1239 = bitcast float*** %1233 to i64*
  %1240 = bitcast %"class.std::__1::vector.45"* %49 to i64*
  %1241 = bitcast float*** %1234 to i64*
  %1242 = call i8* @_Znwm(i64 8) #17
  %1243 = getelementptr inbounds i8, i8* %1242, i64 8
  %1244 = ptrtoint i8* %1243 to i64
  %1245 = bitcast i8* %1242 to i64*
  store i64 %54, i64* %1245, align 8
  %1246 = ptrtoint i8* %1242 to i64
  store i64 %1246, i64* %1240, align 8
  store i64 %1244, i64* %1239, align 8
  store i64 %1244, i64* %1241, align 8
  %1247 = bitcast %"class.std::__1::vector.45"* %49 to i64*
  %1248 = call i8* @_Znwm(i64 16) #17
  %1249 = getelementptr inbounds i8, i8* %1248, i64 8
  %1250 = bitcast i8* %1249 to i64*
  store i64 %55, i64* %1250, align 8
  %1251 = insertelement <2 x i8*> undef, i8* %1248, i32 0
  %1252 = shufflevector <2 x i8*> %1251, <2 x i8*> undef, <2 x i32> zeroinitializer
  %1253 = getelementptr i8, <2 x i8*> %1252, <2 x i64> <i64 16, i64 16>
  %1254 = ptrtoint <2 x i8*> %1253 to <2 x i64>
  %1255 = ptrtoint i8* %1248 to i64
  %1256 = bitcast i8* %1242 to i64*
  %1257 = bitcast i8* %1248 to i64*
  %1258 = load i64, i64* %1256, align 8
  store i64 %1258, i64* %1257, align 8
  store i64 %1255, i64* %1247, align 8
  %1259 = bitcast float*** %1233 to <2 x i64>*
  store <2 x i64> %1254, <2 x i64>* %1259, align 8
  call void @_ZdlPv(i8* nonnull %1242) #17
  %1260 = load %"class.tflite::RuntimeShape"**, %"class.tflite::RuntimeShape"*** %1237, align 8
  %1261 = ptrtoint %"class.tflite::RuntimeShape"* %30 to i64
  %1262 = load %"class.tflite::RuntimeShape"**, %"class.tflite::RuntimeShape"*** %1238, align 8
  %1263 = icmp ult %"class.tflite::RuntimeShape"** %1260, %1262
  %1264 = ptrtoint %"class.tflite::RuntimeShape"** %1262 to i64
  br i1 %1263, label %1265, label %1270

1265:                                             ; preds = %1230
  %1266 = bitcast %"class.tflite::RuntimeShape"** %1260 to i64*
  store i64 %1261, i64* %1266, align 8
  %1267 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1260, i64 1
  %1268 = ptrtoint %"class.tflite::RuntimeShape"** %1267 to i64
  %1269 = bitcast %"class.tflite::RuntimeShape"*** %1237 to i64*
  store i64 %1268, i64* %1269, align 8
  br label %1319

1270:                                             ; preds = %1230
  %1271 = ptrtoint %"class.tflite::RuntimeShape"** %1260 to i64
  %1272 = bitcast %"class.tflite::RuntimeShape"*** %1237 to i64*
  %1273 = bitcast %"class.std::__1::vector.52"* %50 to i64*
  %1274 = load i64, i64* %1273, align 8
  %1275 = sub i64 %1271, %1274
  %1276 = ashr exact i64 %1275, 3
  %1277 = add nsw i64 %1276, 1
  %1278 = icmp ugt i64 %1277, 2305843009213693951
  br i1 %1278, label %1279, label %1281

1279:                                             ; preds = %1270
  %1280 = bitcast %"class.std::__1::vector.52"* %50 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %1280) #19
  unreachable

1281:                                             ; preds = %1270
  %1282 = bitcast %"class.tflite::RuntimeShape"*** %1238 to i64*
  %1283 = sub i64 %1264, %1274
  %1284 = ashr exact i64 %1283, 3
  %1285 = icmp ult i64 %1284, 1152921504606846975
  br i1 %1285, label %1286, label %1294

1286:                                             ; preds = %1281
  %1287 = ashr exact i64 %1283, 2
  %1288 = icmp ult i64 %1287, %1277
  %1289 = select i1 %1288, i64 %1277, i64 %1287
  %1290 = icmp eq i64 %1289, 0
  br i1 %1290, label %1299, label %1291

1291:                                             ; preds = %1286
  %1292 = icmp ugt i64 %1289, 2305843009213693951
  br i1 %1292, label %1293, label %1294

1293:                                             ; preds = %1291
  call void @abort() #19
  unreachable

1294:                                             ; preds = %1291, %1281
  %1295 = phi i64 [ %1289, %1291 ], [ 2305843009213693951, %1281 ]
  %1296 = shl i64 %1295, 3
  %1297 = call i8* @_Znwm(i64 %1296) #17
  %1298 = bitcast i8* %1297 to %"class.tflite::RuntimeShape"**
  br label %1299

1299:                                             ; preds = %1294, %1286
  %1300 = phi i64 [ %1295, %1294 ], [ 0, %1286 ]
  %1301 = phi i8* [ %1297, %1294 ], [ null, %1286 ]
  %1302 = phi %"class.tflite::RuntimeShape"** [ %1298, %1294 ], [ null, %1286 ]
  %1303 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1302, i64 %1276
  %1304 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1302, i64 %1300
  %1305 = ptrtoint %"class.tflite::RuntimeShape"** %1304 to i64
  %1306 = bitcast %"class.tflite::RuntimeShape"** %1303 to i64*
  store i64 %1261, i64* %1306, align 8
  %1307 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1303, i64 1
  %1308 = ptrtoint %"class.tflite::RuntimeShape"** %1307 to i64
  %1309 = ptrtoint %"class.tflite::RuntimeShape"** %1302 to i64
  %1310 = icmp sgt i64 %1275, 0
  br i1 %1310, label %1311, label %1313

1311:                                             ; preds = %1299
  %1312 = inttoptr i64 %1274 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %1301, i8* align 8 %1312, i64 %1275, i1 false) #18
  br label %1313

1313:                                             ; preds = %1311, %1299
  store i64 %1309, i64* %1273, align 8
  store i64 %1308, i64* %1272, align 8
  store i64 %1305, i64* %1282, align 8
  %1314 = icmp eq i64 %1274, 0
  br i1 %1314, label %1319, label %1315

1315:                                             ; preds = %1313
  %1316 = inttoptr i64 %1274 to i8*
  call void @_ZdlPv(i8* %1316) #17
  %1317 = load %"class.tflite::RuntimeShape"**, %"class.tflite::RuntimeShape"*** %1237, align 8
  %1318 = ptrtoint %"class.tflite::RuntimeShape"** %1317 to i64
  br label %1319

1319:                                             ; preds = %1265, %1313, %1315
  %1320 = phi i64 [ %1268, %1265 ], [ %1308, %1313 ], [ %1318, %1315 ]
  %1321 = phi %"class.tflite::RuntimeShape"** [ %1267, %1265 ], [ %1307, %1313 ], [ %1317, %1315 ]
  %1322 = ptrtoint %"class.tflite::RuntimeShape"* %31 to i64
  %1323 = load %"class.tflite::RuntimeShape"**, %"class.tflite::RuntimeShape"*** %1238, align 8
  %1324 = icmp ult %"class.tflite::RuntimeShape"** %1321, %1323
  %1325 = ptrtoint %"class.tflite::RuntimeShape"** %1323 to i64
  br i1 %1324, label %1326, label %1331

1326:                                             ; preds = %1319
  %1327 = bitcast %"class.tflite::RuntimeShape"** %1321 to i64*
  store i64 %1322, i64* %1327, align 8
  %1328 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1321, i64 1
  %1329 = ptrtoint %"class.tflite::RuntimeShape"** %1328 to i64
  %1330 = bitcast %"class.tflite::RuntimeShape"*** %1237 to i64*
  store i64 %1329, i64* %1330, align 8
  br label %1382

1331:                                             ; preds = %1319
  %1332 = ptrtoint %"class.tflite::RuntimeShape"** %1321 to i64
  %1333 = bitcast %"class.tflite::RuntimeShape"*** %1237 to i64*
  %1334 = bitcast %"class.std::__1::vector.52"* %50 to i64*
  %1335 = load i64, i64* %1334, align 8
  %1336 = sub i64 %1332, %1335
  %1337 = ashr exact i64 %1336, 3
  %1338 = add nsw i64 %1337, 1
  %1339 = icmp ugt i64 %1338, 2305843009213693951
  br i1 %1339, label %1340, label %1342

1340:                                             ; preds = %1331
  %1341 = bitcast %"class.std::__1::vector.52"* %50 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %1341) #19
  unreachable

1342:                                             ; preds = %1331
  %1343 = bitcast %"class.tflite::RuntimeShape"*** %1238 to i64*
  %1344 = sub i64 %1325, %1335
  %1345 = ashr exact i64 %1344, 3
  %1346 = icmp ult i64 %1345, 1152921504606846975
  br i1 %1346, label %1347, label %1355

1347:                                             ; preds = %1342
  %1348 = ashr exact i64 %1344, 2
  %1349 = icmp ult i64 %1348, %1338
  %1350 = select i1 %1349, i64 %1338, i64 %1348
  %1351 = icmp eq i64 %1350, 0
  br i1 %1351, label %1360, label %1352

1352:                                             ; preds = %1347
  %1353 = icmp ugt i64 %1350, 2305843009213693951
  br i1 %1353, label %1354, label %1355

1354:                                             ; preds = %1352
  call void @abort() #19
  unreachable

1355:                                             ; preds = %1352, %1342
  %1356 = phi i64 [ %1350, %1352 ], [ 2305843009213693951, %1342 ]
  %1357 = shl i64 %1356, 3
  %1358 = call i8* @_Znwm(i64 %1357) #17
  %1359 = bitcast i8* %1358 to %"class.tflite::RuntimeShape"**
  br label %1360

1360:                                             ; preds = %1355, %1347
  %1361 = phi i64 [ %1356, %1355 ], [ 0, %1347 ]
  %1362 = phi %"class.tflite::RuntimeShape"** [ %1359, %1355 ], [ null, %1347 ]
  %1363 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1362, i64 %1337
  %1364 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1362, i64 %1361
  %1365 = ptrtoint %"class.tflite::RuntimeShape"** %1364 to i64
  %1366 = bitcast %"class.tflite::RuntimeShape"** %1363 to i64*
  store i64 %1322, i64* %1366, align 8
  %1367 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1363, i64 1
  %1368 = ptrtoint %"class.tflite::RuntimeShape"** %1367 to i64
  %1369 = sub i64 %1320, %1335
  %1370 = ashr exact i64 %1369, 3
  %1371 = sub nsw i64 0, %1370
  %1372 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1363, i64 %1371
  %1373 = ptrtoint %"class.tflite::RuntimeShape"** %1372 to i64
  %1374 = icmp sgt i64 %1369, 0
  br i1 %1374, label %1375, label %1378

1375:                                             ; preds = %1360
  %1376 = bitcast %"class.tflite::RuntimeShape"** %1372 to i8*
  %1377 = inttoptr i64 %1335 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %1376, i8* align 8 %1377, i64 %1369, i1 false) #18
  br label %1378

1378:                                             ; preds = %1375, %1360
  store i64 %1373, i64* %1334, align 8
  store i64 %1368, i64* %1333, align 8
  store i64 %1365, i64* %1343, align 8
  %1379 = icmp eq i64 %1335, 0
  br i1 %1379, label %1382, label %1380

1380:                                             ; preds = %1378
  %1381 = inttoptr i64 %1335 to i8*
  call void @_ZdlPv(i8* %1381) #17
  br label %1382

1382:                                             ; preds = %1380, %1378, %1326
  %1383 = bitcast float*** %1233 to i64*
  %1384 = load i64, i64* %1383, align 8
  %1385 = bitcast %"class.std::__1::vector.45"* %49 to i64*
  %1386 = load i64, i64* %1385, align 8
  %1387 = sub i64 %1384, %1386
  %1388 = lshr exact i64 %1387, 3
  %1389 = load %"class.tflite::RuntimeShape"**, %"class.tflite::RuntimeShape"*** %1236, align 8
  %1390 = load i32, i32* %686, align 8
  %1391 = icmp sgt i32 %1390, 5
  %1392 = load i32*, i32** %775, align 8
  %1393 = bitcast %union.anon* %693 to [5 x i32]*
  %1394 = bitcast %union.anon* %693 to i32*
  %1395 = select i1 %1391, i32* %1392, i32* %1394
  %1396 = load i32, i32* %1395, align 4
  %1397 = sext i32 %1396 to i64
  %1398 = getelementptr inbounds i32, i32* %1392, i64 1
  %1399 = getelementptr inbounds [5 x i32], [5 x i32]* %1393, i64 0, i64 1
  %1400 = select i1 %1391, i32* %1398, i32* %1399
  %1401 = load i32, i32* %1400, align 4
  %1402 = sext i32 %1401 to i64
  %1403 = mul nsw i64 %1397, %1402
  %1404 = getelementptr inbounds i32, i32* %1392, i64 2
  %1405 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %36, i64 0, i32 1, i32 1
  %1406 = bitcast [16 x i8]* %1405 to i32*
  %1407 = select i1 %1391, i32* %1404, i32* %1406
  %1408 = load i32, i32* %1407, align 4
  %1409 = sext i32 %1408 to i64
  %1410 = mul nsw i64 %1403, %1409
  %1411 = trunc i64 %1388 to i16
  %1412 = inttoptr i64 %1386 to float**
  %1413 = icmp eq i16 %1411, 0
  %1414 = icmp sgt i32 %1390, 4
  br i1 %1414, label %1415, label %1443

1415:                                             ; preds = %1382
  %1416 = add i32 %1390, -4
  %1417 = add i32 %1390, -5
  %1418 = and i32 %1416, 3
  %1419 = icmp ult i32 %1417, 3
  br i1 %1419, label %1422, label %1420

1420:                                             ; preds = %1415
  %1421 = sub i32 %1416, %1418
  br label %1448

1422:                                             ; preds = %1448, %1415
  %1423 = phi i64 [ undef, %1415 ], [ %1478, %1448 ]
  %1424 = phi i64 [ 4, %1415 ], [ %1479, %1448 ]
  %1425 = phi i64 [ 1, %1415 ], [ %1478, %1448 ]
  %1426 = icmp eq i32 %1418, 0
  br i1 %1426, label %1440, label %1427

1427:                                             ; preds = %1422, %1427
  %1428 = phi i64 [ %1437, %1427 ], [ %1424, %1422 ]
  %1429 = phi i64 [ %1436, %1427 ], [ %1425, %1422 ]
  %1430 = phi i32 [ %1438, %1427 ], [ %1418, %1422 ]
  %1431 = getelementptr inbounds i32, i32* %1392, i64 %1428
  %1432 = getelementptr inbounds [5 x i32], [5 x i32]* %1393, i64 0, i64 %1428
  %1433 = select i1 %1391, i32* %1431, i32* %1432
  %1434 = load i32, i32* %1433, align 4
  %1435 = sext i32 %1434 to i64
  %1436 = mul nsw i64 %1429, %1435
  %1437 = add nuw nsw i64 %1428, 1
  %1438 = add i32 %1430, -1
  %1439 = icmp eq i32 %1438, 0
  br i1 %1439, label %1440, label %1427, !llvm.loop !115

1440:                                             ; preds = %1427, %1422
  %1441 = phi i64 [ %1423, %1422 ], [ %1436, %1427 ]
  %1442 = trunc i64 %1441 to i32
  br label %1443

1443:                                             ; preds = %1440, %1382
  %1444 = phi i32 [ 1, %1382 ], [ %1442, %1440 ]
  %1445 = icmp sgt i64 %1410, 0
  br i1 %1445, label %1446, label %1522

1446:                                             ; preds = %1443
  %1447 = and i64 %1388, 65535
  br label %1482

1448:                                             ; preds = %1448, %1420
  %1449 = phi i64 [ 4, %1420 ], [ %1479, %1448 ]
  %1450 = phi i64 [ 1, %1420 ], [ %1478, %1448 ]
  %1451 = phi i32 [ %1421, %1420 ], [ %1480, %1448 ]
  %1452 = getelementptr inbounds i32, i32* %1392, i64 %1449
  %1453 = getelementptr inbounds [5 x i32], [5 x i32]* %1393, i64 0, i64 %1449
  %1454 = select i1 %1391, i32* %1452, i32* %1453
  %1455 = load i32, i32* %1454, align 4
  %1456 = sext i32 %1455 to i64
  %1457 = mul nsw i64 %1450, %1456
  %1458 = or i64 %1449, 1
  %1459 = getelementptr inbounds i32, i32* %1392, i64 %1458
  %1460 = getelementptr inbounds [5 x i32], [5 x i32]* %1393, i64 0, i64 %1458
  %1461 = select i1 %1391, i32* %1459, i32* %1460
  %1462 = load i32, i32* %1461, align 4
  %1463 = sext i32 %1462 to i64
  %1464 = mul nsw i64 %1457, %1463
  %1465 = or i64 %1449, 2
  %1466 = getelementptr inbounds i32, i32* %1392, i64 %1465
  %1467 = getelementptr inbounds [5 x i32], [5 x i32]* %1393, i64 0, i64 %1465
  %1468 = select i1 %1391, i32* %1466, i32* %1467
  %1469 = load i32, i32* %1468, align 4
  %1470 = sext i32 %1469 to i64
  %1471 = mul nsw i64 %1464, %1470
  %1472 = or i64 %1449, 3
  %1473 = getelementptr inbounds i32, i32* %1392, i64 %1472
  %1474 = getelementptr inbounds [5 x i32], [5 x i32]* %1393, i64 0, i64 %1472
  %1475 = select i1 %1391, i32* %1473, i32* %1474
  %1476 = load i32, i32* %1475, align 4
  %1477 = sext i32 %1476 to i64
  %1478 = mul nsw i64 %1471, %1477
  %1479 = add nuw nsw i64 %1449, 4
  %1480 = add i32 %1451, -4
  %1481 = icmp eq i32 %1480, 0
  br i1 %1481, label %1422, label %1448

1482:                                             ; preds = %1487, %1446
  %1483 = phi i64 [ 0, %1446 ], [ %1489, %1487 ]
  %1484 = phi float* [ %16, %1446 ], [ %1488, %1487 ]
  br i1 %1413, label %1487, label %1485

1485:                                             ; preds = %1482
  %1486 = trunc i64 %1483 to i32
  br label %1491

1487:                                             ; preds = %1506, %1482
  %1488 = phi float* [ %1484, %1482 ], [ %1519, %1506 ]
  %1489 = add nuw nsw i64 %1483, 1
  %1490 = icmp eq i64 %1489, %1410
  br i1 %1490, label %1522, label %1482

1491:                                             ; preds = %1506, %1485
  %1492 = phi i64 [ 0, %1485 ], [ %1520, %1506 ]
  %1493 = phi float* [ %1484, %1485 ], [ %1519, %1506 ]
  %1494 = getelementptr inbounds %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1389, i64 %1492
  %1495 = load %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1494, align 8
  %1496 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1495, i64 0, i32 0
  %1497 = load i32, i32* %1496, align 8
  %1498 = icmp sgt i32 %1497, 5
  br i1 %1498, label %1499, label %1503

1499:                                             ; preds = %1491
  %1500 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1495, i64 0, i32 1, i32 0
  %1501 = load i32*, i32** %1500, align 8
  %1502 = getelementptr inbounds i32, i32* %1501, i64 3
  br label %1506

1503:                                             ; preds = %1491
  %1504 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1495, i64 0, i32 1, i32 1, i64 4
  %1505 = bitcast i8* %1504 to i32*
  br label %1506

1506:                                             ; preds = %1503, %1499
  %1507 = phi i32* [ %1502, %1499 ], [ %1505, %1503 ]
  %1508 = load i32, i32* %1507, align 4
  %1509 = mul i32 %1508, %1444
  %1510 = getelementptr inbounds float*, float** %1412, i64 %1492
  %1511 = load float*, float** %1510, align 8
  %1512 = mul nsw i32 %1509, %1486
  %1513 = sext i32 %1512 to i64
  %1514 = getelementptr inbounds float, float* %1511, i64 %1513
  %1515 = bitcast float* %1493 to i8*
  %1516 = bitcast float* %1514 to i8*
  %1517 = sext i32 %1509 to i64
  %1518 = shl nsw i64 %1517, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1515, i8* align 4 %1516, i64 %1518, i1 false) #18
  %1519 = getelementptr inbounds float, float* %1493, i64 %1517
  %1520 = add nuw nsw i64 %1492, 1
  %1521 = icmp eq i64 %1520, %1447
  br i1 %1521, label %1487, label %1491

1522:                                             ; preds = %1487, %1443
  %1523 = bitcast %"struct.tflite::FullyConnectedParams"* %51 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %1523) #18
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %1523, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite13optimized_ops8LstmCellERKNS_14LstmCellParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_S8_S6_S8_S6_PfS6_S9_S6_S9_S6_S9_PNS_17CpuBackendContextE.fc_params to i8*), i64 40, i1 false)
  %1524 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %51, i64 0, i32 7
  store float 0xC7EFFFFFE0000000, float* %1524, align 4
  %1525 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %51, i64 0, i32 8
  store float 0x47EFFFFFE0000000, float* %1525, align 4
  %1526 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %51, i64 0, i32 9
  store i8 0, i8* %1526, align 4
  %1527 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %51, i64 0, i32 10
  store i8 0, i8* %1527, align 1
  call void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %51, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %36, float* %16, %"class.tflite::RuntimeShape"* dereferenceable(32) %5, float* %6, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %32, float* %8, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %37, float* %18, %"class.tflite::CpuBackendContext"* %19)
  %1528 = load i32, i32* %790, align 8, !noalias !116
  %1529 = add nsw i32 %1528, -1
  %1530 = icmp sgt i32 %1528, 5
  %1531 = load i32*, i32** %879, align 8
  %1532 = sext i32 %1529 to i64
  %1533 = getelementptr inbounds i32, i32* %1531, i64 %1532
  %1534 = bitcast %union.anon* %797 to [5 x i32]*
  %1535 = sext i32 %1529 to i64
  %1536 = getelementptr inbounds [5 x i32], [5 x i32]* %1534, i64 0, i64 %1535
  %1537 = select i1 %1530, i32* %1533, i32* %1536
  %1538 = load i32, i32* %1537, align 4, !noalias !116
  %1539 = sext i32 %1538 to i64
  %1540 = ptrtoint float* %18 to i64
  %1541 = sext i32 %1212 to i64
  %1542 = getelementptr inbounds float, float* %18, i64 %1541
  %1543 = ptrtoint float* %1542 to i64
  %1544 = shl nsw i32 %1212, 1
  %1545 = sext i32 %1544 to i64
  %1546 = getelementptr inbounds float, float* %18, i64 %1545
  %1547 = ptrtoint float* %1546 to i64
  %1548 = mul nsw i32 %1212, 3
  %1549 = sext i32 %1548 to i64
  %1550 = getelementptr inbounds float, float* %18, i64 %1549
  %1551 = ptrtoint float* %1550 to i64
  %1552 = load i32, i32* %374, align 8, !noalias !119
  %1553 = add nsw i32 %1552, -1
  %1554 = icmp sgt i32 %1552, 5
  %1555 = load i32*, i32** %463, align 8
  %1556 = sext i32 %1553 to i64
  %1557 = getelementptr inbounds i32, i32* %1555, i64 %1556
  %1558 = sext i32 %1553 to i64
  %1559 = getelementptr inbounds [5 x i32], [5 x i32]* %1199, i64 0, i64 %1558
  %1560 = select i1 %1554, i32* %1557, i32* %1559
  %1561 = load i32, i32* %1560, align 4, !noalias !119
  %1562 = sext i32 %1561 to i64
  %1563 = ptrtoint float* %10 to i64
  %1564 = bitcast %"class.Eigen::Map"* %52 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1564) #18
  %1565 = getelementptr inbounds %"class.Eigen::Map", %"class.Eigen::Map"* %52, i64 0, i32 0, i32 0, i32 0
  %1566 = getelementptr inbounds %"class.Eigen::Map", %"class.Eigen::Map"* %52, i64 0, i32 0, i32 0, i32 1, i32 0
  %1567 = getelementptr inbounds %"class.Eigen::Map", %"class.Eigen::Map"* %52, i64 0, i32 0, i32 0, i32 2, i32 0
  %1568 = bitcast %"class.Eigen::Map"* %52 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1568, i8 -86, i64 32, i1 false)
  %1569 = load i32, i32* %478, align 8, !noalias !122
  %1570 = add nsw i32 %1569, -1
  %1571 = icmp sgt i32 %1569, 5
  br i1 %1571, label %1572, label %1577

1572:                                             ; preds = %1522
  %1573 = load i32*, i32** %567, align 8, !noalias !122
  %1574 = sext i32 %1570 to i64
  %1575 = getelementptr inbounds i32, i32* %1573, i64 %1574
  %1576 = load i32, i32* %1575, align 4, !noalias !122
  br label %1583

1577:                                             ; preds = %1522
  %1578 = bitcast %union.anon* %485 to [5 x i32]*
  %1579 = sext i32 %1570 to i64
  %1580 = getelementptr inbounds [5 x i32], [5 x i32]* %1578, i64 0, i64 %1579
  %1581 = load i32, i32* %1580, align 4, !noalias !122
  %1582 = icmp sgt i32 %1569, 0
  br i1 %1582, label %1583, label %1628

1583:                                             ; preds = %1577, %1572
  %1584 = phi i32* [ %1573, %1572 ], [ %568, %1577 ]
  %1585 = phi i32 [ %1576, %1572 ], [ %1581, %1577 ]
  %1586 = zext i32 %1570 to i64
  %1587 = zext i32 %1569 to i64
  %1588 = add nsw i64 %1587, -1
  %1589 = and i64 %1587, 3
  %1590 = icmp ult i64 %1588, 3
  br i1 %1590, label %1606, label %1591

1591:                                             ; preds = %1583
  %1592 = sub nsw i64 %1587, %1589
  br label %1593

1593:                                             ; preds = %1876, %1591
  %1594 = phi i64 [ 0, %1591 ], [ %1879, %1876 ]
  %1595 = phi i32 [ 1, %1591 ], [ %1878, %1876 ]
  %1596 = phi i64 [ %1592, %1591 ], [ %1880, %1876 ]
  %1597 = icmp eq i64 %1594, %1586
  br i1 %1597, label %1601, label %1598

1598:                                             ; preds = %1593
  %1599 = getelementptr inbounds i32, i32* %1584, i64 %1594
  %1600 = load i32, i32* %1599, align 4, !noalias !122
  br label %1601

1601:                                             ; preds = %1598, %1593
  %1602 = phi i32 [ %1600, %1598 ], [ 1, %1593 ]
  %1603 = mul nsw i32 %1602, %1595
  %1604 = or i64 %1594, 1
  %1605 = icmp eq i64 %1604, %1586
  br i1 %1605, label %1860, label %1857

1606:                                             ; preds = %1876, %1583
  %1607 = phi i32 [ undef, %1583 ], [ %1878, %1876 ]
  %1608 = phi i64 [ 0, %1583 ], [ %1879, %1876 ]
  %1609 = phi i32 [ 1, %1583 ], [ %1878, %1876 ]
  %1610 = icmp eq i64 %1589, 0
  br i1 %1610, label %1625, label %1611

1611:                                             ; preds = %1606, %1619
  %1612 = phi i64 [ %1622, %1619 ], [ %1608, %1606 ]
  %1613 = phi i32 [ %1621, %1619 ], [ %1609, %1606 ]
  %1614 = phi i64 [ %1623, %1619 ], [ %1589, %1606 ]
  %1615 = icmp eq i64 %1612, %1586
  br i1 %1615, label %1619, label %1616

1616:                                             ; preds = %1611
  %1617 = getelementptr inbounds i32, i32* %1584, i64 %1612
  %1618 = load i32, i32* %1617, align 4, !noalias !122
  br label %1619

1619:                                             ; preds = %1616, %1611
  %1620 = phi i32 [ %1618, %1616 ], [ 1, %1611 ]
  %1621 = mul nsw i32 %1620, %1613
  %1622 = add nuw nsw i64 %1612, 1
  %1623 = add i64 %1614, -1
  %1624 = icmp eq i64 %1623, 0
  br i1 %1624, label %1625, label %1611, !llvm.loop !125

1625:                                             ; preds = %1619, %1606
  %1626 = phi i32 [ %1607, %1606 ], [ %1621, %1619 ]
  %1627 = sext i32 %1626 to i64
  br label %1628

1628:                                             ; preds = %1577, %1625
  %1629 = phi i32 [ %1581, %1577 ], [ %1585, %1625 ]
  %1630 = phi i64 [ 1, %1577 ], [ %1627, %1625 ]
  %1631 = sext i32 %1629 to i64
  store float* %12, float** %1565, align 8, !alias.scope !122
  store i64 %1631, i64* %1566, align 8, !alias.scope !122
  store i64 %1630, i64* %1567, align 8, !alias.scope !122
  %1632 = bitcast %"class.Eigen::Map"* %53 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1632) #18
  %1633 = getelementptr inbounds %"class.Eigen::Map", %"class.Eigen::Map"* %53, i64 0, i32 0, i32 0, i32 0
  %1634 = getelementptr inbounds %"class.Eigen::Map", %"class.Eigen::Map"* %53, i64 0, i32 0, i32 0, i32 1, i32 0
  %1635 = getelementptr inbounds %"class.Eigen::Map", %"class.Eigen::Map"* %53, i64 0, i32 0, i32 0, i32 2, i32 0
  %1636 = bitcast %"class.Eigen::Map"* %53 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1636, i8 -86, i64 32, i1 false)
  %1637 = load i32, i32* %582, align 8, !noalias !126
  %1638 = add nsw i32 %1637, -1
  %1639 = icmp sgt i32 %1637, 5
  %1640 = ptrtoint float* %12 to i64
  br i1 %1639, label %1641, label %1646

1641:                                             ; preds = %1628
  %1642 = load i32*, i32** %671, align 8, !noalias !126
  %1643 = sext i32 %1638 to i64
  %1644 = getelementptr inbounds i32, i32* %1642, i64 %1643
  %1645 = load i32, i32* %1644, align 4, !noalias !126
  br label %1652

1646:                                             ; preds = %1628
  %1647 = bitcast %union.anon* %589 to [5 x i32]*
  %1648 = sext i32 %1638 to i64
  %1649 = getelementptr inbounds [5 x i32], [5 x i32]* %1647, i64 0, i64 %1648
  %1650 = load i32, i32* %1649, align 4, !noalias !126
  %1651 = icmp sgt i32 %1637, 0
  br i1 %1651, label %1652, label %1697

1652:                                             ; preds = %1646, %1641
  %1653 = phi i32* [ %1642, %1641 ], [ %672, %1646 ]
  %1654 = phi i32 [ %1645, %1641 ], [ %1650, %1646 ]
  %1655 = zext i32 %1638 to i64
  %1656 = zext i32 %1637 to i64
  %1657 = add nsw i64 %1656, -1
  %1658 = and i64 %1656, 3
  %1659 = icmp ult i64 %1657, 3
  br i1 %1659, label %1675, label %1660

1660:                                             ; preds = %1652
  %1661 = sub nsw i64 %1656, %1658
  br label %1662

1662:                                             ; preds = %1851, %1660
  %1663 = phi i64 [ 0, %1660 ], [ %1854, %1851 ]
  %1664 = phi i32 [ 1, %1660 ], [ %1853, %1851 ]
  %1665 = phi i64 [ %1661, %1660 ], [ %1855, %1851 ]
  %1666 = icmp eq i64 %1663, %1655
  br i1 %1666, label %1670, label %1667

1667:                                             ; preds = %1662
  %1668 = getelementptr inbounds i32, i32* %1653, i64 %1663
  %1669 = load i32, i32* %1668, align 4, !noalias !126
  br label %1670

1670:                                             ; preds = %1667, %1662
  %1671 = phi i32 [ %1669, %1667 ], [ 1, %1662 ]
  %1672 = mul nsw i32 %1671, %1664
  %1673 = or i64 %1663, 1
  %1674 = icmp eq i64 %1673, %1655
  br i1 %1674, label %1835, label %1832

1675:                                             ; preds = %1851, %1652
  %1676 = phi i32 [ undef, %1652 ], [ %1853, %1851 ]
  %1677 = phi i64 [ 0, %1652 ], [ %1854, %1851 ]
  %1678 = phi i32 [ 1, %1652 ], [ %1853, %1851 ]
  %1679 = icmp eq i64 %1658, 0
  br i1 %1679, label %1694, label %1680

1680:                                             ; preds = %1675, %1688
  %1681 = phi i64 [ %1691, %1688 ], [ %1677, %1675 ]
  %1682 = phi i32 [ %1690, %1688 ], [ %1678, %1675 ]
  %1683 = phi i64 [ %1692, %1688 ], [ %1658, %1675 ]
  %1684 = icmp eq i64 %1681, %1655
  br i1 %1684, label %1688, label %1685

1685:                                             ; preds = %1680
  %1686 = getelementptr inbounds i32, i32* %1653, i64 %1681
  %1687 = load i32, i32* %1686, align 4, !noalias !126
  br label %1688

1688:                                             ; preds = %1685, %1680
  %1689 = phi i32 [ %1687, %1685 ], [ 1, %1680 ]
  %1690 = mul nsw i32 %1689, %1682
  %1691 = add nuw nsw i64 %1681, 1
  %1692 = add i64 %1683, -1
  %1693 = icmp eq i64 %1692, 0
  br i1 %1693, label %1694, label %1680, !llvm.loop !129

1694:                                             ; preds = %1688, %1675
  %1695 = phi i32 [ %1676, %1675 ], [ %1690, %1688 ]
  %1696 = sext i32 %1695 to i64
  br label %1697

1697:                                             ; preds = %1646, %1694
  %1698 = phi i32 [ %1650, %1646 ], [ %1654, %1694 ]
  %1699 = phi i64 [ 1, %1646 ], [ %1696, %1694 ]
  %1700 = sext i32 %1698 to i64
  store float* %14, float** %1633, align 8, !alias.scope !126
  store i64 %1700, i64* %1634, align 8, !alias.scope !126
  store i64 %1699, i64* %1635, align 8, !alias.scope !126
  %1701 = getelementptr inbounds %"struct.Eigen::internal::assign_op", %"struct.Eigen::internal::assign_op"* %25, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %1701) #18
  %1702 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 104, i8* nonnull %1702) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1702, i8 -86, i64 96, i1 false) #18
  %1703 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 1
  %1704 = bitcast %"struct.Eigen::internal::evaluator.176"* %1703 to i64*
  store i64 %1540, i64* %1704, align 8
  %1705 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  store i64 %1539, i64* %1705, align 8
  %1706 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1
  %1707 = bitcast %"struct.Eigen::internal::evaluator.191"* %1706 to i64*
  store i64 %1543, i64* %1707, align 8
  %1708 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  store i64 %1539, i64* %1708, align 8
  %1709 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 2
  %1710 = bitcast %"struct.Eigen::internal::evaluator.196"* %1709 to i64*
  store i64 %1547, i64* %1710, align 8
  %1711 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  store i64 %1539, i64* %1711, align 8
  %1712 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1
  %1713 = bitcast %"struct.Eigen::internal::evaluator.201"* %1712 to i64*
  store i64 %1563, i64* %1713, align 8
  %1714 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %22, i64 0, i32 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 2, i32 0
  store i64 %1562, i64* %1714, align 8
  %1715 = bitcast %"struct.Eigen::internal::evaluator.206"* %23 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %1715) #18
  %1716 = getelementptr inbounds %"struct.Eigen::internal::evaluator.206", %"struct.Eigen::internal::evaluator.206"* %23, i64 0, i32 0, i32 1, i32 0
  %1717 = bitcast i8* %1716 to i64*
  store i64 -6148914691236517206, i64* %1717, align 8
  %1718 = bitcast %"class.Eigen::Map"* %52 to i64*
  %1719 = bitcast %"struct.Eigen::internal::evaluator.206"* %23 to i64*
  store i64 %1640, i64* %1719, align 8
  %1720 = getelementptr inbounds %"struct.Eigen::internal::evaluator.206", %"struct.Eigen::internal::evaluator.206"* %23, i64 0, i32 0, i32 2, i32 0
  store i64 %1631, i64* %1720, align 8
  %1721 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel"* %24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1721) #18
  %1722 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %24, i64 0, i32 0
  %1723 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %24, i64 0, i32 1
  %1724 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %24, i64 0, i32 2
  %1725 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %24, i64 0, i32 3
  store %"struct.Eigen::internal::evaluator.206"* %23, %"struct.Eigen::internal::evaluator.206"** %1722, align 8
  store %"struct.Eigen::internal::evaluator"* %22, %"struct.Eigen::internal::evaluator"** %1723, align 8
  store %"struct.Eigen::internal::assign_op"* %25, %"struct.Eigen::internal::assign_op"** %1724, align 8
  store %"class.Eigen::Map"* %52, %"class.Eigen::Map"** %1725, align 8
  call void @_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS3_INS_13CwiseBinaryOpINS0_13scalar_sum_opIffEEKNSB_INS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS9_Lin1ELin1ELb0EEEEEKNSG_INS0_14scalar_tanh_opIfEESL_EEEEKNSB_ISF_SN_KNS4_IKS6_Li0ES8_EEEEEEEENS0_9assign_opIffEELi0EEELi4ELi0EE3runERS13_(%"class.Eigen::internal::generic_dense_assignment_kernel"* nonnull dereferenceable(32) %24) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1721) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %1715) #18
  call void @llvm.lifetime.end.p0i8(i64 104, i8* nonnull %1702) #18
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %1701) #18
  %1726 = load i64, i64* %1718, align 8
  %1727 = load i64, i64* %1566, align 8
  %1728 = getelementptr inbounds %"struct.Eigen::internal::assign_op", %"struct.Eigen::internal::assign_op"* %29, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %1728) #18
  %1729 = bitcast %"struct.Eigen::internal::evaluator.213"* %26 to i8*
  call void @llvm.lifetime.start.p0i8(i64 48, i8* nonnull %1729) #18
  %1730 = getelementptr inbounds %"struct.Eigen::internal::evaluator.213", %"struct.Eigen::internal::evaluator.213"* %26, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1730, i8 -86, i64 32, i1 false) #18
  %1731 = bitcast %"struct.Eigen::internal::evaluator.213"* %26 to i64*
  store i64 %1551, i64* %1731, align 8
  %1732 = getelementptr inbounds %"struct.Eigen::internal::evaluator.213", %"struct.Eigen::internal::evaluator.213"* %26, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  store i64 %1539, i64* %1732, align 8
  %1733 = getelementptr inbounds %"struct.Eigen::internal::evaluator.213", %"struct.Eigen::internal::evaluator.213"* %26, i64 0, i32 0, i32 0, i32 1
  %1734 = bitcast %"struct.Eigen::internal::evaluator.217"* %1733 to i64*
  store i64 %1726, i64* %1734, align 8
  %1735 = getelementptr inbounds %"struct.Eigen::internal::evaluator.213", %"struct.Eigen::internal::evaluator.213"* %26, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  store i64 %1727, i64* %1735, align 8
  %1736 = bitcast %"struct.Eigen::internal::evaluator.206"* %27 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %1736) #18
  %1737 = getelementptr inbounds %"struct.Eigen::internal::evaluator.206", %"struct.Eigen::internal::evaluator.206"* %27, i64 0, i32 0, i32 1, i32 0
  %1738 = bitcast i8* %1737 to i64*
  store i64 -6148914691236517206, i64* %1738, align 8
  %1739 = ptrtoint float* %14 to i64
  %1740 = bitcast %"struct.Eigen::internal::evaluator.206"* %27 to i64*
  store i64 %1739, i64* %1740, align 8
  %1741 = getelementptr inbounds %"struct.Eigen::internal::evaluator.206", %"struct.Eigen::internal::evaluator.206"* %27, i64 0, i32 0, i32 2, i32 0
  store i64 %1700, i64* %1741, align 8
  %1742 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %28 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1742) #18
  %1743 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel.223", %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %28, i64 0, i32 0
  %1744 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel.223", %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %28, i64 0, i32 1
  %1745 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel.223", %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %28, i64 0, i32 2
  %1746 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel.223", %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %28, i64 0, i32 3
  store %"struct.Eigen::internal::evaluator.206"* %27, %"struct.Eigen::internal::evaluator.206"** %1743, align 8
  store %"struct.Eigen::internal::evaluator.213"* %26, %"struct.Eigen::internal::evaluator.213"** %1744, align 8
  store %"struct.Eigen::internal::assign_op"* %29, %"struct.Eigen::internal::assign_op"** %1745, align 8
  store %"class.Eigen::Map"* %53, %"class.Eigen::Map"** %1746, align 8
  call void @_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS3_INS_13CwiseBinaryOpINS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS9_Lin1ELin1ELb0EEEEEKNSE_INS0_14scalar_tanh_opIfEEKS9_EEEEEENS0_9assign_opIffEELi0EEELi4ELi0EE3runERSV_(%"class.Eigen::internal::generic_dense_assignment_kernel.223"* nonnull dereferenceable(32) %28) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1742) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %1736) #18
  call void @llvm.lifetime.end.p0i8(i64 48, i8* nonnull %1729) #18
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %1728) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1632) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1564) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %1523) #18
  %1747 = load %"class.tflite::RuntimeShape"**, %"class.tflite::RuntimeShape"*** %1236, align 8
  %1748 = icmp eq %"class.tflite::RuntimeShape"** %1747, null
  br i1 %1748, label %1753, label %1749

1749:                                             ; preds = %1697
  %1750 = ptrtoint %"class.tflite::RuntimeShape"** %1747 to i64
  %1751 = bitcast %"class.tflite::RuntimeShape"*** %1237 to i64*
  store i64 %1750, i64* %1751, align 8
  %1752 = bitcast %"class.tflite::RuntimeShape"** %1747 to i8*
  call void @_ZdlPv(i8* %1752) #17
  br label %1753

1753:                                             ; preds = %1697, %1749
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %1235) #18
  %1754 = load float**, float*** %1232, align 8
  %1755 = icmp eq float** %1754, null
  br i1 %1755, label %1759, label %1756

1756:                                             ; preds = %1753
  %1757 = ptrtoint float** %1754 to i64
  store i64 %1757, i64* %1383, align 8
  %1758 = bitcast float** %1754 to i8*
  call void @_ZdlPv(i8* %1758) #17
  br label %1759

1759:                                             ; preds = %1753, %1756
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %1231) #18
  %1760 = load i32, i32* %790, align 8
  %1761 = icmp sgt i32 %1760, 5
  br i1 %1761, label %1762, label %1768

1762:                                             ; preds = %1759
  %1763 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %37, i64 0, i32 1, i32 0
  %1764 = load i32*, i32** %1763, align 8
  %1765 = icmp eq i32* %1764, null
  br i1 %1765, label %1768, label %1766

1766:                                             ; preds = %1762
  %1767 = bitcast i32* %1764 to i8*
  call void @_ZdaPv(i8* %1767) #17
  br label %1768

1768:                                             ; preds = %1759, %1762, %1766
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %789) #18
  %1769 = load i32, i32* %686, align 8
  %1770 = icmp sgt i32 %1769, 5
  br i1 %1770, label %1771, label %1777

1771:                                             ; preds = %1768
  %1772 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %36, i64 0, i32 1, i32 0
  %1773 = load i32*, i32** %1772, align 8
  %1774 = icmp eq i32* %1773, null
  br i1 %1774, label %1777, label %1775

1775:                                             ; preds = %1771
  %1776 = bitcast i32* %1773 to i8*
  call void @_ZdaPv(i8* %1776) #17
  br label %1777

1777:                                             ; preds = %1768, %1771, %1775
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %685) #18
  %1778 = load i32, i32* %582, align 8
  %1779 = icmp sgt i32 %1778, 5
  br i1 %1779, label %1780, label %1786

1780:                                             ; preds = %1777
  %1781 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %35, i64 0, i32 1, i32 0
  %1782 = load i32*, i32** %1781, align 8
  %1783 = icmp eq i32* %1782, null
  br i1 %1783, label %1786, label %1784

1784:                                             ; preds = %1780
  %1785 = bitcast i32* %1782 to i8*
  call void @_ZdaPv(i8* %1785) #17
  br label %1786

1786:                                             ; preds = %1777, %1780, %1784
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %581) #18
  %1787 = load i32, i32* %478, align 8
  %1788 = icmp sgt i32 %1787, 5
  br i1 %1788, label %1789, label %1795

1789:                                             ; preds = %1786
  %1790 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %34, i64 0, i32 1, i32 0
  %1791 = load i32*, i32** %1790, align 8
  %1792 = icmp eq i32* %1791, null
  br i1 %1792, label %1795, label %1793

1793:                                             ; preds = %1789
  %1794 = bitcast i32* %1791 to i8*
  call void @_ZdaPv(i8* %1794) #17
  br label %1795

1795:                                             ; preds = %1786, %1789, %1793
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %477) #18
  %1796 = load i32, i32* %374, align 8
  %1797 = icmp sgt i32 %1796, 5
  br i1 %1797, label %1798, label %1804

1798:                                             ; preds = %1795
  %1799 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %33, i64 0, i32 1, i32 0
  %1800 = load i32*, i32** %1799, align 8
  %1801 = icmp eq i32* %1800, null
  br i1 %1801, label %1804, label %1802

1802:                                             ; preds = %1798
  %1803 = bitcast i32* %1800 to i8*
  call void @_ZdaPv(i8* %1803) #17
  br label %1804

1804:                                             ; preds = %1795, %1798, %1802
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %373) #18
  %1805 = load i32, i32* %271, align 8
  %1806 = icmp sgt i32 %1805, 5
  br i1 %1806, label %1807, label %1813

1807:                                             ; preds = %1804
  %1808 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %32, i64 0, i32 1, i32 0
  %1809 = load i32*, i32** %1808, align 8
  %1810 = icmp eq i32* %1809, null
  br i1 %1810, label %1813, label %1811

1811:                                             ; preds = %1807
  %1812 = bitcast i32* %1809 to i8*
  call void @_ZdaPv(i8* %1812) #17
  br label %1813

1813:                                             ; preds = %1804, %1807, %1811
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %270) #18
  %1814 = load i32, i32* %168, align 8
  %1815 = icmp sgt i32 %1814, 5
  br i1 %1815, label %1816, label %1822

1816:                                             ; preds = %1813
  %1817 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %31, i64 0, i32 1, i32 0
  %1818 = load i32*, i32** %1817, align 8
  %1819 = icmp eq i32* %1818, null
  br i1 %1819, label %1822, label %1820

1820:                                             ; preds = %1816
  %1821 = bitcast i32* %1818 to i8*
  call void @_ZdaPv(i8* %1821) #17
  br label %1822

1822:                                             ; preds = %1813, %1816, %1820
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %167) #18
  %1823 = load i32, i32* %65, align 8
  %1824 = icmp sgt i32 %1823, 5
  br i1 %1824, label %1825, label %1831

1825:                                             ; preds = %1822
  %1826 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %30, i64 0, i32 1, i32 0
  %1827 = load i32*, i32** %1826, align 8
  %1828 = icmp eq i32* %1827, null
  br i1 %1828, label %1831, label %1829

1829:                                             ; preds = %1825
  %1830 = bitcast i32* %1827 to i8*
  call void @_ZdaPv(i8* %1830) #17
  br label %1831

1831:                                             ; preds = %1822, %1825, %1829
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %64) #18
  ret void

1832:                                             ; preds = %1670
  %1833 = getelementptr inbounds i32, i32* %1653, i64 %1673
  %1834 = load i32, i32* %1833, align 4, !noalias !126
  br label %1835

1835:                                             ; preds = %1832, %1670
  %1836 = phi i32 [ %1834, %1832 ], [ 1, %1670 ]
  %1837 = mul nsw i32 %1836, %1672
  %1838 = or i64 %1663, 2
  %1839 = icmp eq i64 %1838, %1655
  br i1 %1839, label %1843, label %1840

1840:                                             ; preds = %1835
  %1841 = getelementptr inbounds i32, i32* %1653, i64 %1838
  %1842 = load i32, i32* %1841, align 4, !noalias !126
  br label %1843

1843:                                             ; preds = %1840, %1835
  %1844 = phi i32 [ %1842, %1840 ], [ 1, %1835 ]
  %1845 = mul nsw i32 %1844, %1837
  %1846 = or i64 %1663, 3
  %1847 = icmp eq i64 %1846, %1655
  br i1 %1847, label %1851, label %1848

1848:                                             ; preds = %1843
  %1849 = getelementptr inbounds i32, i32* %1653, i64 %1846
  %1850 = load i32, i32* %1849, align 4, !noalias !126
  br label %1851

1851:                                             ; preds = %1848, %1843
  %1852 = phi i32 [ %1850, %1848 ], [ 1, %1843 ]
  %1853 = mul nsw i32 %1852, %1845
  %1854 = add nuw nsw i64 %1663, 4
  %1855 = add i64 %1665, -4
  %1856 = icmp eq i64 %1855, 0
  br i1 %1856, label %1675, label %1662

1857:                                             ; preds = %1601
  %1858 = getelementptr inbounds i32, i32* %1584, i64 %1604
  %1859 = load i32, i32* %1858, align 4, !noalias !122
  br label %1860

1860:                                             ; preds = %1857, %1601
  %1861 = phi i32 [ %1859, %1857 ], [ 1, %1601 ]
  %1862 = mul nsw i32 %1861, %1603
  %1863 = or i64 %1594, 2
  %1864 = icmp eq i64 %1863, %1586
  br i1 %1864, label %1868, label %1865

1865:                                             ; preds = %1860
  %1866 = getelementptr inbounds i32, i32* %1584, i64 %1863
  %1867 = load i32, i32* %1866, align 4, !noalias !122
  br label %1868

1868:                                             ; preds = %1865, %1860
  %1869 = phi i32 [ %1867, %1865 ], [ 1, %1860 ]
  %1870 = mul nsw i32 %1869, %1862
  %1871 = or i64 %1594, 3
  %1872 = icmp eq i64 %1871, %1586
  br i1 %1872, label %1876, label %1873

1873:                                             ; preds = %1868
  %1874 = getelementptr inbounds i32, i32* %1584, i64 %1871
  %1875 = load i32, i32* %1874, align 4, !noalias !122
  br label %1876

1876:                                             ; preds = %1873, %1868
  %1877 = phi i32 [ %1875, %1873 ], [ 1, %1868 ]
  %1878 = mul nsw i32 %1877, %1870
  %1879 = add nuw nsw i64 %1594, 4
  %1880 = add i64 %1596, -4
  %1881 = icmp eq i64 %1880, 0
  br i1 %1881, label %1606, label %1593
}

declare zeroext i1 @_ZN6tflite11CheckedLog2EfPi(float, i32*) local_unnamed_addr #3

declare void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double, i32*, i32*) local_unnamed_addr #3

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops8LstmCellILi4EEEvRKNS_14LstmCellParamsERKNS_12RuntimeShapeEPKhS7_S9_S7_S9_S7_PKiS7_PKsS7_PsS7_PhS7_SF_S7_SE_PNS_17CpuBackendContextE(%"struct.tflite::LstmCellParams"* dereferenceable(16), %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i32*, %"class.tflite::RuntimeShape"* dereferenceable(32), i16*, %"class.tflite::RuntimeShape"* dereferenceable(32), i16*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i16*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #5 comdat {
  %21 = alloca %"class.tflite::RuntimeShape", align 8
  %22 = alloca %"class.tflite::RuntimeShape", align 8
  %23 = alloca %"class.tflite::RuntimeShape", align 8
  %24 = alloca %"class.tflite::RuntimeShape", align 8
  %25 = alloca %"class.tflite::RuntimeShape", align 8
  %26 = alloca %"class.tflite::RuntimeShape", align 8
  %27 = alloca %"class.tflite::RuntimeShape", align 8
  %28 = alloca %"class.tflite::RuntimeShape", align 8
  %29 = alloca %"class.tflite::RuntimeShape", align 8
  %30 = alloca %"class.tflite::RuntimeShape", align 8
  %31 = alloca %"class.tflite::RuntimeShape", align 8
  %32 = alloca [2 x i8*], align 16
  %33 = alloca [2 x %"class.tflite::RuntimeShape"*], align 16
  %34 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.224", align 4
  %35 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.224", align 4
  %36 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.226", align 4
  %37 = alloca %"struct.tflite::cpu_backend_gemm::GemmParams.228", align 8
  %38 = getelementptr inbounds %"struct.tflite::LstmCellParams", %"struct.tflite::LstmCellParams"* %0, i64 0, i32 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"struct.tflite::LstmCellParams", %"struct.tflite::LstmCellParams"* %0, i64 0, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.tflite::LstmCellParams", %"struct.tflite::LstmCellParams"* %0, i64 0, i32 2
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1, i64 0, i32 0
  %45 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %46 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %47 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 0
  %48 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %49 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  %50 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  %51 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  %52 = bitcast %"class.tflite::RuntimeShape"* %22 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %52) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %52, i8 -86, i64 32, i1 false)
  %53 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 0, i32* %53, align 8, !alias.scope !130
  %54 = load i32, i32* %44, align 8, !noalias !130
  %55 = icmp sgt i32 %54, 4
  br i1 %55, label %56, label %57

56:                                               ; preds = %20
  tail call void @abort() #19, !noalias !130
  unreachable

57:                                               ; preds = %20
  store i32 4, i32* %53, align 8, !alias.scope !130
  %58 = sub i32 4, %54
  %59 = icmp sgt i32 %58, 0
  %60 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1
  br i1 %59, label %61, label %141

61:                                               ; preds = %57
  %62 = bitcast %union.anon* %60 to [5 x i32]*
  %63 = zext i32 %58 to i64
  %64 = icmp ult i32 %58, 8
  br i1 %64, label %134, label %65

65:                                               ; preds = %61
  %66 = and i64 %63, 4294967288
  %67 = add nsw i64 %66, -8
  %68 = lshr exact i64 %67, 3
  %69 = add nuw nsw i64 %68, 1
  %70 = and i64 %69, 7
  %71 = icmp ult i64 %67, 56
  br i1 %71, label %119, label %72

72:                                               ; preds = %65
  %73 = sub nsw i64 %69, %70
  br label %74

74:                                               ; preds = %74, %72
  %75 = phi i64 [ 0, %72 ], [ %116, %74 ]
  %76 = phi i64 [ %73, %72 ], [ %117, %74 ]
  %77 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %75
  %78 = bitcast i32* %77 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %78, align 8, !alias.scope !130
  %79 = getelementptr inbounds i32, i32* %77, i64 4
  %80 = bitcast i32* %79 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %80, align 8, !alias.scope !130
  %81 = or i64 %75, 8
  %82 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %81
  %83 = bitcast i32* %82 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %83, align 8, !alias.scope !130
  %84 = getelementptr inbounds i32, i32* %82, i64 4
  %85 = bitcast i32* %84 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %85, align 8, !alias.scope !130
  %86 = or i64 %75, 16
  %87 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %86
  %88 = bitcast i32* %87 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %88, align 8, !alias.scope !130
  %89 = getelementptr inbounds i32, i32* %87, i64 4
  %90 = bitcast i32* %89 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %90, align 8, !alias.scope !130
  %91 = or i64 %75, 24
  %92 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %91
  %93 = bitcast i32* %92 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %93, align 8, !alias.scope !130
  %94 = getelementptr inbounds i32, i32* %92, i64 4
  %95 = bitcast i32* %94 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %95, align 8, !alias.scope !130
  %96 = or i64 %75, 32
  %97 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %96
  %98 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %98, align 8, !alias.scope !130
  %99 = getelementptr inbounds i32, i32* %97, i64 4
  %100 = bitcast i32* %99 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %100, align 8, !alias.scope !130
  %101 = or i64 %75, 40
  %102 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %101
  %103 = bitcast i32* %102 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %103, align 8, !alias.scope !130
  %104 = getelementptr inbounds i32, i32* %102, i64 4
  %105 = bitcast i32* %104 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %105, align 8, !alias.scope !130
  %106 = or i64 %75, 48
  %107 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %106
  %108 = bitcast i32* %107 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %108, align 8, !alias.scope !130
  %109 = getelementptr inbounds i32, i32* %107, i64 4
  %110 = bitcast i32* %109 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %110, align 8, !alias.scope !130
  %111 = or i64 %75, 56
  %112 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %111
  %113 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %113, align 8, !alias.scope !130
  %114 = getelementptr inbounds i32, i32* %112, i64 4
  %115 = bitcast i32* %114 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %115, align 8, !alias.scope !130
  %116 = add i64 %75, 64
  %117 = add i64 %76, -8
  %118 = icmp eq i64 %117, 0
  br i1 %118, label %119, label %74, !llvm.loop !133

119:                                              ; preds = %74, %65
  %120 = phi i64 [ 0, %65 ], [ %116, %74 ]
  %121 = icmp eq i64 %70, 0
  br i1 %121, label %132, label %122

122:                                              ; preds = %119, %122
  %123 = phi i64 [ %129, %122 ], [ %120, %119 ]
  %124 = phi i64 [ %130, %122 ], [ %70, %119 ]
  %125 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %123
  %126 = bitcast i32* %125 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %126, align 8, !alias.scope !130
  %127 = getelementptr inbounds i32, i32* %125, i64 4
  %128 = bitcast i32* %127 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %128, align 8, !alias.scope !130
  %129 = add i64 %123, 8
  %130 = add i64 %124, -1
  %131 = icmp eq i64 %130, 0
  br i1 %131, label %132, label %122, !llvm.loop !134

132:                                              ; preds = %122, %119
  %133 = icmp eq i64 %66, %63
  br i1 %133, label %141, label %134

134:                                              ; preds = %132, %61
  %135 = phi i64 [ 0, %61 ], [ %66, %132 ]
  br label %136

136:                                              ; preds = %134, %136
  %137 = phi i64 [ %139, %136 ], [ %135, %134 ]
  %138 = getelementptr inbounds [5 x i32], [5 x i32]* %62, i64 0, i64 %137
  store i32 1, i32* %138, align 4, !alias.scope !130
  %139 = add nuw nsw i64 %137, 1
  %140 = icmp eq i64 %139, %63
  br i1 %140, label %141, label %136, !llvm.loop !135

141:                                              ; preds = %136, %132, %57
  %142 = getelementptr inbounds %union.anon, %union.anon* %60, i64 0, i32 0
  %143 = bitcast %union.anon* %60 to i32*
  %144 = sext i32 %58 to i64
  %145 = getelementptr inbounds i32, i32* %143, i64 %144
  %146 = bitcast i32* %145 to i8*
  %147 = icmp sgt i32 %54, 5
  %148 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1, i64 0, i32 1
  %149 = getelementptr inbounds %union.anon, %union.anon* %148, i64 0, i32 0
  %150 = load i32*, i32** %149, align 8, !noalias !130
  %151 = bitcast %union.anon* %148 to i32*
  %152 = select i1 %147, i32* %150, i32* %151
  %153 = bitcast i32* %152 to i8*
  %154 = sext i32 %54 to i64
  %155 = shl nsw i64 %154, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %146, i8* align 4 %153, i64 %155, i1 false) #18
  %156 = bitcast %"class.tflite::RuntimeShape"* %23 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %156) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %156, i8 -86, i64 32, i1 false)
  %157 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 0, i32* %157, align 8, !alias.scope !136
  %158 = load i32, i32* %45, align 8, !noalias !136
  %159 = icmp sgt i32 %158, 4
  br i1 %159, label %160, label %161

160:                                              ; preds = %141
  tail call void @abort() #19, !noalias !136
  unreachable

161:                                              ; preds = %141
  store i32 4, i32* %157, align 8, !alias.scope !136
  %162 = sub i32 4, %158
  %163 = icmp sgt i32 %162, 0
  %164 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1
  br i1 %163, label %165, label %245

165:                                              ; preds = %161
  %166 = bitcast %union.anon* %164 to [5 x i32]*
  %167 = zext i32 %162 to i64
  %168 = icmp ult i32 %162, 8
  br i1 %168, label %238, label %169

169:                                              ; preds = %165
  %170 = and i64 %167, 4294967288
  %171 = add nsw i64 %170, -8
  %172 = lshr exact i64 %171, 3
  %173 = add nuw nsw i64 %172, 1
  %174 = and i64 %173, 7
  %175 = icmp ult i64 %171, 56
  br i1 %175, label %223, label %176

176:                                              ; preds = %169
  %177 = sub nsw i64 %173, %174
  br label %178

178:                                              ; preds = %178, %176
  %179 = phi i64 [ 0, %176 ], [ %220, %178 ]
  %180 = phi i64 [ %177, %176 ], [ %221, %178 ]
  %181 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %179
  %182 = bitcast i32* %181 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %182, align 8, !alias.scope !136
  %183 = getelementptr inbounds i32, i32* %181, i64 4
  %184 = bitcast i32* %183 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %184, align 8, !alias.scope !136
  %185 = or i64 %179, 8
  %186 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %185
  %187 = bitcast i32* %186 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %187, align 8, !alias.scope !136
  %188 = getelementptr inbounds i32, i32* %186, i64 4
  %189 = bitcast i32* %188 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %189, align 8, !alias.scope !136
  %190 = or i64 %179, 16
  %191 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %190
  %192 = bitcast i32* %191 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %192, align 8, !alias.scope !136
  %193 = getelementptr inbounds i32, i32* %191, i64 4
  %194 = bitcast i32* %193 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %194, align 8, !alias.scope !136
  %195 = or i64 %179, 24
  %196 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %195
  %197 = bitcast i32* %196 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %197, align 8, !alias.scope !136
  %198 = getelementptr inbounds i32, i32* %196, i64 4
  %199 = bitcast i32* %198 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %199, align 8, !alias.scope !136
  %200 = or i64 %179, 32
  %201 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %200
  %202 = bitcast i32* %201 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %202, align 8, !alias.scope !136
  %203 = getelementptr inbounds i32, i32* %201, i64 4
  %204 = bitcast i32* %203 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %204, align 8, !alias.scope !136
  %205 = or i64 %179, 40
  %206 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %205
  %207 = bitcast i32* %206 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %207, align 8, !alias.scope !136
  %208 = getelementptr inbounds i32, i32* %206, i64 4
  %209 = bitcast i32* %208 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %209, align 8, !alias.scope !136
  %210 = or i64 %179, 48
  %211 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %210
  %212 = bitcast i32* %211 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %212, align 8, !alias.scope !136
  %213 = getelementptr inbounds i32, i32* %211, i64 4
  %214 = bitcast i32* %213 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %214, align 8, !alias.scope !136
  %215 = or i64 %179, 56
  %216 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %215
  %217 = bitcast i32* %216 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %217, align 8, !alias.scope !136
  %218 = getelementptr inbounds i32, i32* %216, i64 4
  %219 = bitcast i32* %218 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %219, align 8, !alias.scope !136
  %220 = add i64 %179, 64
  %221 = add i64 %180, -8
  %222 = icmp eq i64 %221, 0
  br i1 %222, label %223, label %178, !llvm.loop !139

223:                                              ; preds = %178, %169
  %224 = phi i64 [ 0, %169 ], [ %220, %178 ]
  %225 = icmp eq i64 %174, 0
  br i1 %225, label %236, label %226

226:                                              ; preds = %223, %226
  %227 = phi i64 [ %233, %226 ], [ %224, %223 ]
  %228 = phi i64 [ %234, %226 ], [ %174, %223 ]
  %229 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %227
  %230 = bitcast i32* %229 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %230, align 8, !alias.scope !136
  %231 = getelementptr inbounds i32, i32* %229, i64 4
  %232 = bitcast i32* %231 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %232, align 8, !alias.scope !136
  %233 = add i64 %227, 8
  %234 = add i64 %228, -1
  %235 = icmp eq i64 %234, 0
  br i1 %235, label %236, label %226, !llvm.loop !140

236:                                              ; preds = %226, %223
  %237 = icmp eq i64 %170, %167
  br i1 %237, label %245, label %238

238:                                              ; preds = %236, %165
  %239 = phi i64 [ 0, %165 ], [ %170, %236 ]
  br label %240

240:                                              ; preds = %238, %240
  %241 = phi i64 [ %243, %240 ], [ %239, %238 ]
  %242 = getelementptr inbounds [5 x i32], [5 x i32]* %166, i64 0, i64 %241
  store i32 1, i32* %242, align 4, !alias.scope !136
  %243 = add nuw nsw i64 %241, 1
  %244 = icmp eq i64 %243, %167
  br i1 %244, label %245, label %240, !llvm.loop !141

245:                                              ; preds = %240, %236, %161
  %246 = getelementptr inbounds %union.anon, %union.anon* %164, i64 0, i32 0
  %247 = bitcast %union.anon* %164 to i32*
  %248 = sext i32 %162 to i64
  %249 = getelementptr inbounds i32, i32* %247, i64 %248
  %250 = bitcast i32* %249 to i8*
  %251 = icmp sgt i32 %158, 5
  %252 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %253 = getelementptr inbounds %union.anon, %union.anon* %252, i64 0, i32 0
  %254 = load i32*, i32** %253, align 8, !noalias !136
  %255 = bitcast %union.anon* %252 to i32*
  %256 = select i1 %251, i32* %254, i32* %255
  %257 = bitcast i32* %256 to i8*
  %258 = sext i32 %158 to i64
  %259 = shl nsw i64 %258, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %250, i8* align 4 %257, i64 %259, i1 false) #18
  %260 = bitcast %"class.tflite::RuntimeShape"* %24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %260) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %260, i8 -86, i64 32, i1 false)
  %261 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 0, i32* %261, align 8, !alias.scope !142
  %262 = load i32, i32* %46, align 8, !noalias !142
  %263 = icmp sgt i32 %262, 4
  br i1 %263, label %264, label %265

264:                                              ; preds = %245
  tail call void @abort() #19, !noalias !142
  unreachable

265:                                              ; preds = %245
  store i32 4, i32* %261, align 8, !alias.scope !142
  %266 = sub i32 4, %262
  %267 = icmp sgt i32 %266, 0
  %268 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1
  br i1 %267, label %269, label %349

269:                                              ; preds = %265
  %270 = bitcast %union.anon* %268 to [5 x i32]*
  %271 = zext i32 %266 to i64
  %272 = icmp ult i32 %266, 8
  br i1 %272, label %342, label %273

273:                                              ; preds = %269
  %274 = and i64 %271, 4294967288
  %275 = add nsw i64 %274, -8
  %276 = lshr exact i64 %275, 3
  %277 = add nuw nsw i64 %276, 1
  %278 = and i64 %277, 7
  %279 = icmp ult i64 %275, 56
  br i1 %279, label %327, label %280

280:                                              ; preds = %273
  %281 = sub nsw i64 %277, %278
  br label %282

282:                                              ; preds = %282, %280
  %283 = phi i64 [ 0, %280 ], [ %324, %282 ]
  %284 = phi i64 [ %281, %280 ], [ %325, %282 ]
  %285 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %283
  %286 = bitcast i32* %285 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %286, align 8, !alias.scope !142
  %287 = getelementptr inbounds i32, i32* %285, i64 4
  %288 = bitcast i32* %287 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %288, align 8, !alias.scope !142
  %289 = or i64 %283, 8
  %290 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %289
  %291 = bitcast i32* %290 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %291, align 8, !alias.scope !142
  %292 = getelementptr inbounds i32, i32* %290, i64 4
  %293 = bitcast i32* %292 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %293, align 8, !alias.scope !142
  %294 = or i64 %283, 16
  %295 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %294
  %296 = bitcast i32* %295 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %296, align 8, !alias.scope !142
  %297 = getelementptr inbounds i32, i32* %295, i64 4
  %298 = bitcast i32* %297 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %298, align 8, !alias.scope !142
  %299 = or i64 %283, 24
  %300 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %299
  %301 = bitcast i32* %300 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %301, align 8, !alias.scope !142
  %302 = getelementptr inbounds i32, i32* %300, i64 4
  %303 = bitcast i32* %302 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %303, align 8, !alias.scope !142
  %304 = or i64 %283, 32
  %305 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %304
  %306 = bitcast i32* %305 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %306, align 8, !alias.scope !142
  %307 = getelementptr inbounds i32, i32* %305, i64 4
  %308 = bitcast i32* %307 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %308, align 8, !alias.scope !142
  %309 = or i64 %283, 40
  %310 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %309
  %311 = bitcast i32* %310 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %311, align 8, !alias.scope !142
  %312 = getelementptr inbounds i32, i32* %310, i64 4
  %313 = bitcast i32* %312 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %313, align 8, !alias.scope !142
  %314 = or i64 %283, 48
  %315 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %314
  %316 = bitcast i32* %315 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %316, align 8, !alias.scope !142
  %317 = getelementptr inbounds i32, i32* %315, i64 4
  %318 = bitcast i32* %317 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %318, align 8, !alias.scope !142
  %319 = or i64 %283, 56
  %320 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %319
  %321 = bitcast i32* %320 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %321, align 8, !alias.scope !142
  %322 = getelementptr inbounds i32, i32* %320, i64 4
  %323 = bitcast i32* %322 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %323, align 8, !alias.scope !142
  %324 = add i64 %283, 64
  %325 = add i64 %284, -8
  %326 = icmp eq i64 %325, 0
  br i1 %326, label %327, label %282, !llvm.loop !145

327:                                              ; preds = %282, %273
  %328 = phi i64 [ 0, %273 ], [ %324, %282 ]
  %329 = icmp eq i64 %278, 0
  br i1 %329, label %340, label %330

330:                                              ; preds = %327, %330
  %331 = phi i64 [ %337, %330 ], [ %328, %327 ]
  %332 = phi i64 [ %338, %330 ], [ %278, %327 ]
  %333 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %331
  %334 = bitcast i32* %333 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %334, align 8, !alias.scope !142
  %335 = getelementptr inbounds i32, i32* %333, i64 4
  %336 = bitcast i32* %335 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %336, align 8, !alias.scope !142
  %337 = add i64 %331, 8
  %338 = add i64 %332, -1
  %339 = icmp eq i64 %338, 0
  br i1 %339, label %340, label %330, !llvm.loop !146

340:                                              ; preds = %330, %327
  %341 = icmp eq i64 %274, %271
  br i1 %341, label %349, label %342

342:                                              ; preds = %340, %269
  %343 = phi i64 [ 0, %269 ], [ %274, %340 ]
  br label %344

344:                                              ; preds = %342, %344
  %345 = phi i64 [ %347, %344 ], [ %343, %342 ]
  %346 = getelementptr inbounds [5 x i32], [5 x i32]* %270, i64 0, i64 %345
  store i32 1, i32* %346, align 4, !alias.scope !142
  %347 = add nuw nsw i64 %345, 1
  %348 = icmp eq i64 %347, %271
  br i1 %348, label %349, label %344, !llvm.loop !147

349:                                              ; preds = %344, %340, %265
  %350 = bitcast %union.anon* %268 to i32*
  %351 = sext i32 %266 to i64
  %352 = getelementptr inbounds i32, i32* %350, i64 %351
  %353 = bitcast i32* %352 to i8*
  %354 = icmp sgt i32 %262, 5
  %355 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %356 = getelementptr inbounds %union.anon, %union.anon* %355, i64 0, i32 0
  %357 = load i32*, i32** %356, align 8, !noalias !142
  %358 = bitcast %union.anon* %355 to i32*
  %359 = select i1 %354, i32* %357, i32* %358
  %360 = bitcast i32* %359 to i8*
  %361 = sext i32 %262 to i64
  %362 = shl nsw i64 %361, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %353, i8* align 4 %360, i64 %362, i1 false) #18
  %363 = bitcast %"class.tflite::RuntimeShape"* %25 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %363) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %363, i8 -86, i64 32, i1 false)
  %364 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 0, i32* %364, align 8, !alias.scope !148
  %365 = load i32, i32* %47, align 8, !noalias !148
  %366 = icmp sgt i32 %365, 4
  br i1 %366, label %367, label %368

367:                                              ; preds = %349
  tail call void @abort() #19, !noalias !148
  unreachable

368:                                              ; preds = %349
  store i32 4, i32* %364, align 8, !alias.scope !148
  %369 = sub i32 4, %365
  %370 = icmp sgt i32 %369, 0
  %371 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1
  br i1 %370, label %372, label %452

372:                                              ; preds = %368
  %373 = bitcast %union.anon* %371 to [5 x i32]*
  %374 = zext i32 %369 to i64
  %375 = icmp ult i32 %369, 8
  br i1 %375, label %445, label %376

376:                                              ; preds = %372
  %377 = and i64 %374, 4294967288
  %378 = add nsw i64 %377, -8
  %379 = lshr exact i64 %378, 3
  %380 = add nuw nsw i64 %379, 1
  %381 = and i64 %380, 7
  %382 = icmp ult i64 %378, 56
  br i1 %382, label %430, label %383

383:                                              ; preds = %376
  %384 = sub nsw i64 %380, %381
  br label %385

385:                                              ; preds = %385, %383
  %386 = phi i64 [ 0, %383 ], [ %427, %385 ]
  %387 = phi i64 [ %384, %383 ], [ %428, %385 ]
  %388 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %386
  %389 = bitcast i32* %388 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %389, align 8, !alias.scope !148
  %390 = getelementptr inbounds i32, i32* %388, i64 4
  %391 = bitcast i32* %390 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %391, align 8, !alias.scope !148
  %392 = or i64 %386, 8
  %393 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %392
  %394 = bitcast i32* %393 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %394, align 8, !alias.scope !148
  %395 = getelementptr inbounds i32, i32* %393, i64 4
  %396 = bitcast i32* %395 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %396, align 8, !alias.scope !148
  %397 = or i64 %386, 16
  %398 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %397
  %399 = bitcast i32* %398 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %399, align 8, !alias.scope !148
  %400 = getelementptr inbounds i32, i32* %398, i64 4
  %401 = bitcast i32* %400 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %401, align 8, !alias.scope !148
  %402 = or i64 %386, 24
  %403 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %402
  %404 = bitcast i32* %403 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %404, align 8, !alias.scope !148
  %405 = getelementptr inbounds i32, i32* %403, i64 4
  %406 = bitcast i32* %405 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %406, align 8, !alias.scope !148
  %407 = or i64 %386, 32
  %408 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %407
  %409 = bitcast i32* %408 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %409, align 8, !alias.scope !148
  %410 = getelementptr inbounds i32, i32* %408, i64 4
  %411 = bitcast i32* %410 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %411, align 8, !alias.scope !148
  %412 = or i64 %386, 40
  %413 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %412
  %414 = bitcast i32* %413 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %414, align 8, !alias.scope !148
  %415 = getelementptr inbounds i32, i32* %413, i64 4
  %416 = bitcast i32* %415 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %416, align 8, !alias.scope !148
  %417 = or i64 %386, 48
  %418 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %417
  %419 = bitcast i32* %418 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %419, align 8, !alias.scope !148
  %420 = getelementptr inbounds i32, i32* %418, i64 4
  %421 = bitcast i32* %420 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %421, align 8, !alias.scope !148
  %422 = or i64 %386, 56
  %423 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %422
  %424 = bitcast i32* %423 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %424, align 8, !alias.scope !148
  %425 = getelementptr inbounds i32, i32* %423, i64 4
  %426 = bitcast i32* %425 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %426, align 8, !alias.scope !148
  %427 = add i64 %386, 64
  %428 = add i64 %387, -8
  %429 = icmp eq i64 %428, 0
  br i1 %429, label %430, label %385, !llvm.loop !151

430:                                              ; preds = %385, %376
  %431 = phi i64 [ 0, %376 ], [ %427, %385 ]
  %432 = icmp eq i64 %381, 0
  br i1 %432, label %443, label %433

433:                                              ; preds = %430, %433
  %434 = phi i64 [ %440, %433 ], [ %431, %430 ]
  %435 = phi i64 [ %441, %433 ], [ %381, %430 ]
  %436 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %434
  %437 = bitcast i32* %436 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %437, align 8, !alias.scope !148
  %438 = getelementptr inbounds i32, i32* %436, i64 4
  %439 = bitcast i32* %438 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %439, align 8, !alias.scope !148
  %440 = add i64 %434, 8
  %441 = add i64 %435, -1
  %442 = icmp eq i64 %441, 0
  br i1 %442, label %443, label %433, !llvm.loop !152

443:                                              ; preds = %433, %430
  %444 = icmp eq i64 %377, %374
  br i1 %444, label %452, label %445

445:                                              ; preds = %443, %372
  %446 = phi i64 [ 0, %372 ], [ %377, %443 ]
  br label %447

447:                                              ; preds = %445, %447
  %448 = phi i64 [ %450, %447 ], [ %446, %445 ]
  %449 = getelementptr inbounds [5 x i32], [5 x i32]* %373, i64 0, i64 %448
  store i32 1, i32* %449, align 4, !alias.scope !148
  %450 = add nuw nsw i64 %448, 1
  %451 = icmp eq i64 %450, %374
  br i1 %451, label %452, label %447, !llvm.loop !153

452:                                              ; preds = %447, %443, %368
  %453 = getelementptr inbounds %union.anon, %union.anon* %371, i64 0, i32 0
  %454 = bitcast %union.anon* %371 to i32*
  %455 = sext i32 %369 to i64
  %456 = getelementptr inbounds i32, i32* %454, i64 %455
  %457 = bitcast i32* %456 to i8*
  %458 = icmp sgt i32 %365, 5
  %459 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 1
  %460 = getelementptr inbounds %union.anon, %union.anon* %459, i64 0, i32 0
  %461 = load i32*, i32** %460, align 8, !noalias !148
  %462 = bitcast %union.anon* %459 to i32*
  %463 = select i1 %458, i32* %461, i32* %462
  %464 = bitcast i32* %463 to i8*
  %465 = sext i32 %365 to i64
  %466 = shl nsw i64 %465, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %457, i8* align 4 %464, i64 %466, i1 false) #18
  %467 = bitcast %"class.tflite::RuntimeShape"* %26 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %467) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %467, i8 -86, i64 32, i1 false)
  %468 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 0
  store i32 0, i32* %468, align 8, !alias.scope !154
  %469 = load i32, i32* %48, align 8, !noalias !154
  %470 = icmp sgt i32 %469, 4
  br i1 %470, label %471, label %472

471:                                              ; preds = %452
  tail call void @abort() #19, !noalias !154
  unreachable

472:                                              ; preds = %452
  store i32 4, i32* %468, align 8, !alias.scope !154
  %473 = sub i32 4, %469
  %474 = icmp sgt i32 %473, 0
  %475 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 1
  br i1 %474, label %476, label %556

476:                                              ; preds = %472
  %477 = bitcast %union.anon* %475 to [5 x i32]*
  %478 = zext i32 %473 to i64
  %479 = icmp ult i32 %473, 8
  br i1 %479, label %549, label %480

480:                                              ; preds = %476
  %481 = and i64 %478, 4294967288
  %482 = add nsw i64 %481, -8
  %483 = lshr exact i64 %482, 3
  %484 = add nuw nsw i64 %483, 1
  %485 = and i64 %484, 7
  %486 = icmp ult i64 %482, 56
  br i1 %486, label %534, label %487

487:                                              ; preds = %480
  %488 = sub nsw i64 %484, %485
  br label %489

489:                                              ; preds = %489, %487
  %490 = phi i64 [ 0, %487 ], [ %531, %489 ]
  %491 = phi i64 [ %488, %487 ], [ %532, %489 ]
  %492 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %490
  %493 = bitcast i32* %492 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %493, align 8, !alias.scope !154
  %494 = getelementptr inbounds i32, i32* %492, i64 4
  %495 = bitcast i32* %494 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %495, align 8, !alias.scope !154
  %496 = or i64 %490, 8
  %497 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %496
  %498 = bitcast i32* %497 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %498, align 8, !alias.scope !154
  %499 = getelementptr inbounds i32, i32* %497, i64 4
  %500 = bitcast i32* %499 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %500, align 8, !alias.scope !154
  %501 = or i64 %490, 16
  %502 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %501
  %503 = bitcast i32* %502 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %503, align 8, !alias.scope !154
  %504 = getelementptr inbounds i32, i32* %502, i64 4
  %505 = bitcast i32* %504 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %505, align 8, !alias.scope !154
  %506 = or i64 %490, 24
  %507 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %506
  %508 = bitcast i32* %507 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %508, align 8, !alias.scope !154
  %509 = getelementptr inbounds i32, i32* %507, i64 4
  %510 = bitcast i32* %509 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %510, align 8, !alias.scope !154
  %511 = or i64 %490, 32
  %512 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %511
  %513 = bitcast i32* %512 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %513, align 8, !alias.scope !154
  %514 = getelementptr inbounds i32, i32* %512, i64 4
  %515 = bitcast i32* %514 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %515, align 8, !alias.scope !154
  %516 = or i64 %490, 40
  %517 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %516
  %518 = bitcast i32* %517 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %518, align 8, !alias.scope !154
  %519 = getelementptr inbounds i32, i32* %517, i64 4
  %520 = bitcast i32* %519 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %520, align 8, !alias.scope !154
  %521 = or i64 %490, 48
  %522 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %521
  %523 = bitcast i32* %522 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %523, align 8, !alias.scope !154
  %524 = getelementptr inbounds i32, i32* %522, i64 4
  %525 = bitcast i32* %524 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %525, align 8, !alias.scope !154
  %526 = or i64 %490, 56
  %527 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %526
  %528 = bitcast i32* %527 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %528, align 8, !alias.scope !154
  %529 = getelementptr inbounds i32, i32* %527, i64 4
  %530 = bitcast i32* %529 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %530, align 8, !alias.scope !154
  %531 = add i64 %490, 64
  %532 = add i64 %491, -8
  %533 = icmp eq i64 %532, 0
  br i1 %533, label %534, label %489, !llvm.loop !157

534:                                              ; preds = %489, %480
  %535 = phi i64 [ 0, %480 ], [ %531, %489 ]
  %536 = icmp eq i64 %485, 0
  br i1 %536, label %547, label %537

537:                                              ; preds = %534, %537
  %538 = phi i64 [ %544, %537 ], [ %535, %534 ]
  %539 = phi i64 [ %545, %537 ], [ %485, %534 ]
  %540 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %538
  %541 = bitcast i32* %540 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %541, align 8, !alias.scope !154
  %542 = getelementptr inbounds i32, i32* %540, i64 4
  %543 = bitcast i32* %542 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %543, align 8, !alias.scope !154
  %544 = add i64 %538, 8
  %545 = add i64 %539, -1
  %546 = icmp eq i64 %545, 0
  br i1 %546, label %547, label %537, !llvm.loop !158

547:                                              ; preds = %537, %534
  %548 = icmp eq i64 %481, %478
  br i1 %548, label %556, label %549

549:                                              ; preds = %547, %476
  %550 = phi i64 [ 0, %476 ], [ %481, %547 ]
  br label %551

551:                                              ; preds = %549, %551
  %552 = phi i64 [ %554, %551 ], [ %550, %549 ]
  %553 = getelementptr inbounds [5 x i32], [5 x i32]* %477, i64 0, i64 %552
  store i32 1, i32* %553, align 4, !alias.scope !154
  %554 = add nuw nsw i64 %552, 1
  %555 = icmp eq i64 %554, %478
  br i1 %555, label %556, label %551, !llvm.loop !159

556:                                              ; preds = %551, %547, %472
  %557 = getelementptr inbounds %union.anon, %union.anon* %475, i64 0, i32 0
  %558 = bitcast %union.anon* %475 to i32*
  %559 = sext i32 %473 to i64
  %560 = getelementptr inbounds i32, i32* %558, i64 %559
  %561 = bitcast i32* %560 to i8*
  %562 = icmp sgt i32 %469, 5
  %563 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %564 = getelementptr inbounds %union.anon, %union.anon* %563, i64 0, i32 0
  %565 = load i32*, i32** %564, align 8, !noalias !154
  %566 = bitcast %union.anon* %563 to i32*
  %567 = select i1 %562, i32* %565, i32* %566
  %568 = bitcast i32* %567 to i8*
  %569 = sext i32 %469 to i64
  %570 = shl nsw i64 %569, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %561, i8* align 4 %568, i64 %570, i1 false) #18
  %571 = bitcast %"class.tflite::RuntimeShape"* %27 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %571) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %571, i8 -86, i64 32, i1 false)
  %572 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 0
  store i32 0, i32* %572, align 8, !alias.scope !160
  %573 = load i32, i32* %49, align 8, !noalias !160
  %574 = icmp sgt i32 %573, 4
  br i1 %574, label %575, label %576

575:                                              ; preds = %556
  tail call void @abort() #19, !noalias !160
  unreachable

576:                                              ; preds = %556
  store i32 4, i32* %572, align 8, !alias.scope !160
  %577 = sub i32 4, %573
  %578 = icmp sgt i32 %577, 0
  %579 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 1
  br i1 %578, label %580, label %660

580:                                              ; preds = %576
  %581 = bitcast %union.anon* %579 to [5 x i32]*
  %582 = zext i32 %577 to i64
  %583 = icmp ult i32 %577, 8
  br i1 %583, label %653, label %584

584:                                              ; preds = %580
  %585 = and i64 %582, 4294967288
  %586 = add nsw i64 %585, -8
  %587 = lshr exact i64 %586, 3
  %588 = add nuw nsw i64 %587, 1
  %589 = and i64 %588, 7
  %590 = icmp ult i64 %586, 56
  br i1 %590, label %638, label %591

591:                                              ; preds = %584
  %592 = sub nsw i64 %588, %589
  br label %593

593:                                              ; preds = %593, %591
  %594 = phi i64 [ 0, %591 ], [ %635, %593 ]
  %595 = phi i64 [ %592, %591 ], [ %636, %593 ]
  %596 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %594
  %597 = bitcast i32* %596 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %597, align 8, !alias.scope !160
  %598 = getelementptr inbounds i32, i32* %596, i64 4
  %599 = bitcast i32* %598 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %599, align 8, !alias.scope !160
  %600 = or i64 %594, 8
  %601 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %600
  %602 = bitcast i32* %601 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %602, align 8, !alias.scope !160
  %603 = getelementptr inbounds i32, i32* %601, i64 4
  %604 = bitcast i32* %603 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %604, align 8, !alias.scope !160
  %605 = or i64 %594, 16
  %606 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %605
  %607 = bitcast i32* %606 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %607, align 8, !alias.scope !160
  %608 = getelementptr inbounds i32, i32* %606, i64 4
  %609 = bitcast i32* %608 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %609, align 8, !alias.scope !160
  %610 = or i64 %594, 24
  %611 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %610
  %612 = bitcast i32* %611 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %612, align 8, !alias.scope !160
  %613 = getelementptr inbounds i32, i32* %611, i64 4
  %614 = bitcast i32* %613 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %614, align 8, !alias.scope !160
  %615 = or i64 %594, 32
  %616 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %615
  %617 = bitcast i32* %616 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %617, align 8, !alias.scope !160
  %618 = getelementptr inbounds i32, i32* %616, i64 4
  %619 = bitcast i32* %618 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %619, align 8, !alias.scope !160
  %620 = or i64 %594, 40
  %621 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %620
  %622 = bitcast i32* %621 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %622, align 8, !alias.scope !160
  %623 = getelementptr inbounds i32, i32* %621, i64 4
  %624 = bitcast i32* %623 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %624, align 8, !alias.scope !160
  %625 = or i64 %594, 48
  %626 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %625
  %627 = bitcast i32* %626 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %627, align 8, !alias.scope !160
  %628 = getelementptr inbounds i32, i32* %626, i64 4
  %629 = bitcast i32* %628 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %629, align 8, !alias.scope !160
  %630 = or i64 %594, 56
  %631 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %630
  %632 = bitcast i32* %631 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %632, align 8, !alias.scope !160
  %633 = getelementptr inbounds i32, i32* %631, i64 4
  %634 = bitcast i32* %633 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %634, align 8, !alias.scope !160
  %635 = add i64 %594, 64
  %636 = add i64 %595, -8
  %637 = icmp eq i64 %636, 0
  br i1 %637, label %638, label %593, !llvm.loop !163

638:                                              ; preds = %593, %584
  %639 = phi i64 [ 0, %584 ], [ %635, %593 ]
  %640 = icmp eq i64 %589, 0
  br i1 %640, label %651, label %641

641:                                              ; preds = %638, %641
  %642 = phi i64 [ %648, %641 ], [ %639, %638 ]
  %643 = phi i64 [ %649, %641 ], [ %589, %638 ]
  %644 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %642
  %645 = bitcast i32* %644 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %645, align 8, !alias.scope !160
  %646 = getelementptr inbounds i32, i32* %644, i64 4
  %647 = bitcast i32* %646 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %647, align 8, !alias.scope !160
  %648 = add i64 %642, 8
  %649 = add i64 %643, -1
  %650 = icmp eq i64 %649, 0
  br i1 %650, label %651, label %641, !llvm.loop !164

651:                                              ; preds = %641, %638
  %652 = icmp eq i64 %585, %582
  br i1 %652, label %660, label %653

653:                                              ; preds = %651, %580
  %654 = phi i64 [ 0, %580 ], [ %585, %651 ]
  br label %655

655:                                              ; preds = %653, %655
  %656 = phi i64 [ %658, %655 ], [ %654, %653 ]
  %657 = getelementptr inbounds [5 x i32], [5 x i32]* %581, i64 0, i64 %656
  store i32 1, i32* %657, align 4, !alias.scope !160
  %658 = add nuw nsw i64 %656, 1
  %659 = icmp eq i64 %658, %582
  br i1 %659, label %660, label %655, !llvm.loop !165

660:                                              ; preds = %655, %651, %576
  %661 = getelementptr inbounds %union.anon, %union.anon* %579, i64 0, i32 0
  %662 = bitcast %union.anon* %579 to i32*
  %663 = sext i32 %577 to i64
  %664 = getelementptr inbounds i32, i32* %662, i64 %663
  %665 = bitcast i32* %664 to i8*
  %666 = icmp sgt i32 %573, 5
  %667 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %668 = getelementptr inbounds %union.anon, %union.anon* %667, i64 0, i32 0
  %669 = load i32*, i32** %668, align 8, !noalias !160
  %670 = bitcast %union.anon* %667 to i32*
  %671 = select i1 %666, i32* %669, i32* %670
  %672 = bitcast i32* %671 to i8*
  %673 = sext i32 %573 to i64
  %674 = shl nsw i64 %673, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %665, i8* align 4 %672, i64 %674, i1 false) #18
  %675 = bitcast %"class.tflite::RuntimeShape"* %28 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %675) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %675, i8 -86, i64 32, i1 false)
  %676 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 0
  store i32 0, i32* %676, align 8, !alias.scope !166
  %677 = load i32, i32* %50, align 8, !noalias !166
  %678 = icmp sgt i32 %677, 4
  br i1 %678, label %679, label %680

679:                                              ; preds = %660
  tail call void @abort() #19, !noalias !166
  unreachable

680:                                              ; preds = %660
  store i32 4, i32* %676, align 8, !alias.scope !166
  %681 = sub i32 4, %677
  %682 = icmp sgt i32 %681, 0
  %683 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1
  br i1 %682, label %684, label %764

684:                                              ; preds = %680
  %685 = bitcast %union.anon* %683 to [5 x i32]*
  %686 = zext i32 %681 to i64
  %687 = icmp ult i32 %681, 8
  br i1 %687, label %757, label %688

688:                                              ; preds = %684
  %689 = and i64 %686, 4294967288
  %690 = add nsw i64 %689, -8
  %691 = lshr exact i64 %690, 3
  %692 = add nuw nsw i64 %691, 1
  %693 = and i64 %692, 7
  %694 = icmp ult i64 %690, 56
  br i1 %694, label %742, label %695

695:                                              ; preds = %688
  %696 = sub nsw i64 %692, %693
  br label %697

697:                                              ; preds = %697, %695
  %698 = phi i64 [ 0, %695 ], [ %739, %697 ]
  %699 = phi i64 [ %696, %695 ], [ %740, %697 ]
  %700 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %698
  %701 = bitcast i32* %700 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %701, align 8, !alias.scope !166
  %702 = getelementptr inbounds i32, i32* %700, i64 4
  %703 = bitcast i32* %702 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %703, align 8, !alias.scope !166
  %704 = or i64 %698, 8
  %705 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %704
  %706 = bitcast i32* %705 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %706, align 8, !alias.scope !166
  %707 = getelementptr inbounds i32, i32* %705, i64 4
  %708 = bitcast i32* %707 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %708, align 8, !alias.scope !166
  %709 = or i64 %698, 16
  %710 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %709
  %711 = bitcast i32* %710 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %711, align 8, !alias.scope !166
  %712 = getelementptr inbounds i32, i32* %710, i64 4
  %713 = bitcast i32* %712 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %713, align 8, !alias.scope !166
  %714 = or i64 %698, 24
  %715 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %714
  %716 = bitcast i32* %715 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %716, align 8, !alias.scope !166
  %717 = getelementptr inbounds i32, i32* %715, i64 4
  %718 = bitcast i32* %717 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %718, align 8, !alias.scope !166
  %719 = or i64 %698, 32
  %720 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %719
  %721 = bitcast i32* %720 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %721, align 8, !alias.scope !166
  %722 = getelementptr inbounds i32, i32* %720, i64 4
  %723 = bitcast i32* %722 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %723, align 8, !alias.scope !166
  %724 = or i64 %698, 40
  %725 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %724
  %726 = bitcast i32* %725 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %726, align 8, !alias.scope !166
  %727 = getelementptr inbounds i32, i32* %725, i64 4
  %728 = bitcast i32* %727 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %728, align 8, !alias.scope !166
  %729 = or i64 %698, 48
  %730 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %729
  %731 = bitcast i32* %730 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %731, align 8, !alias.scope !166
  %732 = getelementptr inbounds i32, i32* %730, i64 4
  %733 = bitcast i32* %732 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %733, align 8, !alias.scope !166
  %734 = or i64 %698, 56
  %735 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %734
  %736 = bitcast i32* %735 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %736, align 8, !alias.scope !166
  %737 = getelementptr inbounds i32, i32* %735, i64 4
  %738 = bitcast i32* %737 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %738, align 8, !alias.scope !166
  %739 = add i64 %698, 64
  %740 = add i64 %699, -8
  %741 = icmp eq i64 %740, 0
  br i1 %741, label %742, label %697, !llvm.loop !169

742:                                              ; preds = %697, %688
  %743 = phi i64 [ 0, %688 ], [ %739, %697 ]
  %744 = icmp eq i64 %693, 0
  br i1 %744, label %755, label %745

745:                                              ; preds = %742, %745
  %746 = phi i64 [ %752, %745 ], [ %743, %742 ]
  %747 = phi i64 [ %753, %745 ], [ %693, %742 ]
  %748 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %746
  %749 = bitcast i32* %748 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %749, align 8, !alias.scope !166
  %750 = getelementptr inbounds i32, i32* %748, i64 4
  %751 = bitcast i32* %750 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %751, align 8, !alias.scope !166
  %752 = add i64 %746, 8
  %753 = add i64 %747, -1
  %754 = icmp eq i64 %753, 0
  br i1 %754, label %755, label %745, !llvm.loop !170

755:                                              ; preds = %745, %742
  %756 = icmp eq i64 %689, %686
  br i1 %756, label %764, label %757

757:                                              ; preds = %755, %684
  %758 = phi i64 [ 0, %684 ], [ %689, %755 ]
  br label %759

759:                                              ; preds = %757, %759
  %760 = phi i64 [ %762, %759 ], [ %758, %757 ]
  %761 = getelementptr inbounds [5 x i32], [5 x i32]* %685, i64 0, i64 %760
  store i32 1, i32* %761, align 4, !alias.scope !166
  %762 = add nuw nsw i64 %760, 1
  %763 = icmp eq i64 %762, %686
  br i1 %763, label %764, label %759, !llvm.loop !171

764:                                              ; preds = %759, %755, %680
  %765 = getelementptr inbounds %union.anon, %union.anon* %683, i64 0, i32 0
  %766 = bitcast %union.anon* %683 to i32*
  %767 = sext i32 %681 to i64
  %768 = getelementptr inbounds i32, i32* %766, i64 %767
  %769 = bitcast i32* %768 to i8*
  %770 = icmp sgt i32 %677, 5
  %771 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1
  %772 = getelementptr inbounds %union.anon, %union.anon* %771, i64 0, i32 0
  %773 = load i32*, i32** %772, align 8, !noalias !166
  %774 = bitcast %union.anon* %771 to i32*
  %775 = select i1 %770, i32* %773, i32* %774
  %776 = bitcast i32* %775 to i8*
  %777 = sext i32 %677 to i64
  %778 = shl nsw i64 %777, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %769, i8* align 4 %776, i64 %778, i1 false) #18
  %779 = bitcast %"class.tflite::RuntimeShape"* %29 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %779) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %779, i8 -86, i64 32, i1 false)
  %780 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 0
  store i32 0, i32* %780, align 8, !alias.scope !172
  %781 = load i32, i32* %51, align 8, !noalias !172
  %782 = icmp sgt i32 %781, 4
  br i1 %782, label %783, label %784

783:                                              ; preds = %764
  tail call void @abort() #19, !noalias !172
  unreachable

784:                                              ; preds = %764
  store i32 4, i32* %780, align 8, !alias.scope !172
  %785 = sub i32 4, %781
  %786 = icmp sgt i32 %785, 0
  %787 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1
  br i1 %786, label %788, label %868

788:                                              ; preds = %784
  %789 = bitcast %union.anon* %787 to [5 x i32]*
  %790 = zext i32 %785 to i64
  %791 = icmp ult i32 %785, 8
  br i1 %791, label %861, label %792

792:                                              ; preds = %788
  %793 = and i64 %790, 4294967288
  %794 = add nsw i64 %793, -8
  %795 = lshr exact i64 %794, 3
  %796 = add nuw nsw i64 %795, 1
  %797 = and i64 %796, 7
  %798 = icmp ult i64 %794, 56
  br i1 %798, label %846, label %799

799:                                              ; preds = %792
  %800 = sub nsw i64 %796, %797
  br label %801

801:                                              ; preds = %801, %799
  %802 = phi i64 [ 0, %799 ], [ %843, %801 ]
  %803 = phi i64 [ %800, %799 ], [ %844, %801 ]
  %804 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %802
  %805 = bitcast i32* %804 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %805, align 8, !alias.scope !172
  %806 = getelementptr inbounds i32, i32* %804, i64 4
  %807 = bitcast i32* %806 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %807, align 8, !alias.scope !172
  %808 = or i64 %802, 8
  %809 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %808
  %810 = bitcast i32* %809 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %810, align 8, !alias.scope !172
  %811 = getelementptr inbounds i32, i32* %809, i64 4
  %812 = bitcast i32* %811 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %812, align 8, !alias.scope !172
  %813 = or i64 %802, 16
  %814 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %813
  %815 = bitcast i32* %814 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %815, align 8, !alias.scope !172
  %816 = getelementptr inbounds i32, i32* %814, i64 4
  %817 = bitcast i32* %816 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %817, align 8, !alias.scope !172
  %818 = or i64 %802, 24
  %819 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %818
  %820 = bitcast i32* %819 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %820, align 8, !alias.scope !172
  %821 = getelementptr inbounds i32, i32* %819, i64 4
  %822 = bitcast i32* %821 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %822, align 8, !alias.scope !172
  %823 = or i64 %802, 32
  %824 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %823
  %825 = bitcast i32* %824 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %825, align 8, !alias.scope !172
  %826 = getelementptr inbounds i32, i32* %824, i64 4
  %827 = bitcast i32* %826 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %827, align 8, !alias.scope !172
  %828 = or i64 %802, 40
  %829 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %828
  %830 = bitcast i32* %829 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %830, align 8, !alias.scope !172
  %831 = getelementptr inbounds i32, i32* %829, i64 4
  %832 = bitcast i32* %831 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %832, align 8, !alias.scope !172
  %833 = or i64 %802, 48
  %834 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %833
  %835 = bitcast i32* %834 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %835, align 8, !alias.scope !172
  %836 = getelementptr inbounds i32, i32* %834, i64 4
  %837 = bitcast i32* %836 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %837, align 8, !alias.scope !172
  %838 = or i64 %802, 56
  %839 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %838
  %840 = bitcast i32* %839 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %840, align 8, !alias.scope !172
  %841 = getelementptr inbounds i32, i32* %839, i64 4
  %842 = bitcast i32* %841 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %842, align 8, !alias.scope !172
  %843 = add i64 %802, 64
  %844 = add i64 %803, -8
  %845 = icmp eq i64 %844, 0
  br i1 %845, label %846, label %801, !llvm.loop !175

846:                                              ; preds = %801, %792
  %847 = phi i64 [ 0, %792 ], [ %843, %801 ]
  %848 = icmp eq i64 %797, 0
  br i1 %848, label %859, label %849

849:                                              ; preds = %846, %849
  %850 = phi i64 [ %856, %849 ], [ %847, %846 ]
  %851 = phi i64 [ %857, %849 ], [ %797, %846 ]
  %852 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %850
  %853 = bitcast i32* %852 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %853, align 8, !alias.scope !172
  %854 = getelementptr inbounds i32, i32* %852, i64 4
  %855 = bitcast i32* %854 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %855, align 8, !alias.scope !172
  %856 = add i64 %850, 8
  %857 = add i64 %851, -1
  %858 = icmp eq i64 %857, 0
  br i1 %858, label %859, label %849, !llvm.loop !176

859:                                              ; preds = %849, %846
  %860 = icmp eq i64 %793, %790
  br i1 %860, label %868, label %861

861:                                              ; preds = %859, %788
  %862 = phi i64 [ 0, %788 ], [ %793, %859 ]
  br label %863

863:                                              ; preds = %861, %863
  %864 = phi i64 [ %866, %863 ], [ %862, %861 ]
  %865 = getelementptr inbounds [5 x i32], [5 x i32]* %789, i64 0, i64 %864
  store i32 1, i32* %865, align 4, !alias.scope !172
  %866 = add nuw nsw i64 %864, 1
  %867 = icmp eq i64 %866, %790
  br i1 %867, label %868, label %863, !llvm.loop !177

868:                                              ; preds = %863, %859, %784
  %869 = getelementptr inbounds %union.anon, %union.anon* %787, i64 0, i32 0
  %870 = bitcast %union.anon* %787 to i32*
  %871 = sext i32 %785 to i64
  %872 = getelementptr inbounds i32, i32* %870, i64 %871
  %873 = bitcast i32* %872 to i8*
  %874 = icmp sgt i32 %781, 5
  %875 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  %876 = getelementptr inbounds %union.anon, %union.anon* %875, i64 0, i32 0
  %877 = load i32*, i32** %876, align 8, !noalias !172
  %878 = bitcast %union.anon* %875 to i32*
  %879 = select i1 %874, i32* %877, i32* %878
  %880 = bitcast i32* %879 to i8*
  %881 = sext i32 %781 to i64
  %882 = shl nsw i64 %881, 2
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %873, i8* align 4 %880, i64 %882, i1 false) #18
  %883 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %5, i64 0, i32 0
  %884 = load i32, i32* %883, align 8
  %885 = load i32, i32* %53, align 8
  %886 = icmp sgt i32 %885, 5
  %887 = load i32*, i32** %142, align 8
  %888 = select i1 %886, i32* %887, i32* %143
  %889 = icmp sgt i32 %885, 0
  br i1 %889, label %890, label %932

890:                                              ; preds = %868
  %891 = zext i32 %885 to i64
  %892 = add nsw i64 %891, -1
  %893 = and i64 %891, 3
  %894 = icmp ult i64 %892, 3
  br i1 %894, label %913, label %895

895:                                              ; preds = %890
  %896 = sub nsw i64 %891, %893
  br label %897

897:                                              ; preds = %1567, %895
  %898 = phi i64 [ 0, %895 ], [ %1570, %1567 ]
  %899 = phi i32 [ 1, %895 ], [ %1569, %1567 ]
  %900 = phi i64 [ %896, %895 ], [ %1571, %1567 ]
  %901 = getelementptr inbounds i32, i32* %888, i64 %898
  %902 = load i32, i32* %901, align 4
  %903 = mul nsw i32 %902, %899
  %904 = or i64 %898, 1
  %905 = getelementptr inbounds i32, i32* %888, i64 %904
  %906 = load i32, i32* %905, align 4
  %907 = mul nsw i32 %906, %903
  %908 = or i64 %898, 2
  %909 = getelementptr inbounds i32, i32* %888, i64 %908
  %910 = load i32, i32* %909, align 4
  %911 = mul nsw i32 %910, %907
  %912 = icmp eq i64 %898, 0
  br i1 %912, label %1567, label %1563

913:                                              ; preds = %1567, %890
  %914 = phi i32 [ undef, %890 ], [ %1569, %1567 ]
  %915 = phi i64 [ 0, %890 ], [ %1570, %1567 ]
  %916 = phi i32 [ 1, %890 ], [ %1569, %1567 ]
  %917 = icmp eq i64 %893, 0
  br i1 %917, label %932, label %918

918:                                              ; preds = %913, %926
  %919 = phi i64 [ %929, %926 ], [ %915, %913 ]
  %920 = phi i32 [ %928, %926 ], [ %916, %913 ]
  %921 = phi i64 [ %930, %926 ], [ %893, %913 ]
  %922 = icmp eq i64 %919, 3
  br i1 %922, label %926, label %923

923:                                              ; preds = %918
  %924 = getelementptr inbounds i32, i32* %888, i64 %919
  %925 = load i32, i32* %924, align 4
  br label %926

926:                                              ; preds = %923, %918
  %927 = phi i32 [ %925, %923 ], [ 1, %918 ]
  %928 = mul nsw i32 %927, %920
  %929 = add nuw nsw i64 %919, 1
  %930 = add i64 %921, -1
  %931 = icmp eq i64 %930, 0
  br i1 %931, label %932, label %918, !llvm.loop !178

932:                                              ; preds = %913, %926, %868
  %933 = phi i32 [ 1, %868 ], [ %914, %913 ], [ %928, %926 ]
  %934 = getelementptr inbounds i32, i32* %887, i64 3
  %935 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 1, i64 4
  %936 = bitcast i8* %935 to i32*
  %937 = select i1 %886, i32* %934, i32* %936
  %938 = load i32, i32* %937, align 4
  %939 = load i32, i32* %157, align 8
  %940 = icmp sgt i32 %939, 5
  %941 = load i32*, i32** %246, align 8
  %942 = getelementptr inbounds i32, i32* %941, i64 3
  %943 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 1, i64 4
  %944 = bitcast i8* %943 to i32*
  %945 = select i1 %940, i32* %942, i32* %944
  %946 = load i32, i32* %945, align 4
  %947 = add nsw i32 %946, %938
  %948 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %5, i64 0, i32 1
  %949 = add nsw i32 %884, -2
  %950 = getelementptr inbounds %union.anon, %union.anon* %948, i64 0, i32 0
  %951 = sext i32 %949 to i64
  %952 = bitcast %union.anon* %948 to [5 x i32]*
  %953 = getelementptr inbounds [5 x i32], [5 x i32]* %952, i64 0, i64 %951
  %954 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %30, i64 0, i32 0
  %955 = load i32, i32* %468, align 8
  store i32 %955, i32* %954, align 8
  %956 = icmp sgt i32 %955, 5
  br i1 %956, label %957, label %964

957:                                              ; preds = %932
  %958 = sext i32 %955 to i64
  %959 = shl nsw i64 %958, 2
  %960 = tail call i8* @_Znam(i64 %959) #17
  %961 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %30, i64 0, i32 1, i32 0
  %962 = bitcast i32** %961 to i8**
  store i8* %960, i8** %962, align 8
  %963 = bitcast i8* %960 to i32*
  br label %969

964:                                              ; preds = %932
  %965 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %30, i64 0, i32 1
  %966 = bitcast %union.anon* %965 to i32*
  %967 = sext i32 %955 to i64
  %968 = shl nsw i64 %967, 2
  br label %969

969:                                              ; preds = %957, %964
  %970 = phi i64 [ %959, %957 ], [ %968, %964 ]
  %971 = phi i32* [ %963, %957 ], [ %966, %964 ]
  %972 = bitcast i32* %971 to i8*
  %973 = load i32*, i32** %557, align 8
  %974 = select i1 %956, i32* %973, i32* %558
  %975 = bitcast i32* %974 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %972, i8* align 4 %975, i64 %970, i1 false) #18
  %976 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %31, i64 0, i32 0
  %977 = load i32, i32* %572, align 8
  store i32 %977, i32* %976, align 8
  %978 = icmp sgt i32 %977, 5
  br i1 %978, label %979, label %986

979:                                              ; preds = %969
  %980 = sext i32 %977 to i64
  %981 = shl nsw i64 %980, 2
  %982 = tail call i8* @_Znam(i64 %981) #17
  %983 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %31, i64 0, i32 1, i32 0
  %984 = bitcast i32** %983 to i8**
  store i8* %982, i8** %984, align 8
  %985 = bitcast i8* %982 to i32*
  br label %991

986:                                              ; preds = %969
  %987 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %31, i64 0, i32 1
  %988 = bitcast %union.anon* %987 to i32*
  %989 = sext i32 %977 to i64
  %990 = shl nsw i64 %989, 2
  br label %991

991:                                              ; preds = %979, %986
  %992 = phi i64 [ %981, %979 ], [ %990, %986 ]
  %993 = phi i32* [ %985, %979 ], [ %988, %986 ]
  %994 = bitcast i32* %993 to i8*
  %995 = load i32*, i32** %661, align 8
  %996 = select i1 %978, i32* %995, i32* %662
  %997 = bitcast i32* %996 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %994, i8* align 4 %997, i64 %992, i1 false) #18
  %998 = bitcast %"class.tflite::RuntimeShape"* %21 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %998)
  %999 = load i32, i32* %364, align 8
  %1000 = icmp sgt i32 %999, 5
  %1001 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  store i32 %977, i32* %1001, align 8
  br i1 %978, label %1002, label %1009

1002:                                             ; preds = %991
  %1003 = sext i32 %977 to i64
  %1004 = shl nsw i64 %1003, 2
  %1005 = tail call i8* @_Znam(i64 %1004) #17
  %1006 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %1007 = bitcast i32** %1006 to i8**
  store i8* %1005, i8** %1007, align 8
  %1008 = bitcast i8* %1005 to i32*
  br label %1014

1009:                                             ; preds = %991
  %1010 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1
  %1011 = bitcast %union.anon* %1010 to i32*
  %1012 = sext i32 %977 to i64
  %1013 = shl nsw i64 %1012, 2
  br label %1014

1014:                                             ; preds = %1009, %1002
  %1015 = phi i64 [ %1004, %1002 ], [ %1013, %1009 ]
  %1016 = phi i32* [ %1008, %1002 ], [ %1011, %1009 ]
  %1017 = bitcast i32* %1016 to i8*
  %1018 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %31, i64 0, i32 1
  %1019 = getelementptr inbounds %union.anon, %union.anon* %1018, i64 0, i32 0
  %1020 = load i32*, i32** %1019, align 8
  %1021 = bitcast %union.anon* %1018 to i32*
  %1022 = select i1 %978, i32* %1020, i32* %1021
  %1023 = bitcast i32* %1022 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1017, i8* align 4 %1023, i64 %1015, i1 false) #18
  %1024 = load i32*, i32** %453, align 8
  %1025 = getelementptr inbounds i32, i32* %1024, i64 3
  %1026 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 1, i64 4
  %1027 = bitcast i8* %1026 to i32*
  %1028 = select i1 %1000, i32* %1025, i32* %1027
  %1029 = load i32, i32* %1028, align 4
  %1030 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %1031 = load i32*, i32** %1030, align 8
  %1032 = getelementptr inbounds i32, i32* %1031, i64 3
  %1033 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 1, i64 4
  %1034 = bitcast i8* %1033 to i32*
  %1035 = select i1 %978, i32* %1032, i32* %1034
  %1036 = load i32, i32* %1035, align 4
  %1037 = icmp slt i32 %1036, %1029
  %1038 = select i1 %1037, i32 %1036, i32 %1029
  %1039 = xor i1 %978, true
  %1040 = icmp eq i32* %1031, null
  %1041 = or i1 %1040, %1039
  br i1 %1041, label %1044, label %1042

1042:                                             ; preds = %1014
  %1043 = bitcast i32* %1031 to i8*
  tail call void @_ZdaPv(i8* %1043) #17
  br label %1044

1044:                                             ; preds = %1014, %1042
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %998)
  %1045 = xor i1 %978, true
  %1046 = icmp eq i32* %1020, null
  %1047 = or i1 %1046, %1045
  br i1 %1047, label %1050, label %1048

1048:                                             ; preds = %1044
  %1049 = bitcast i32* %1020 to i8*
  tail call void @_ZdaPv(i8* %1049) #17
  br label %1050

1050:                                             ; preds = %1044, %1048
  br i1 %956, label %1051, label %1057

1051:                                             ; preds = %1050
  %1052 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %30, i64 0, i32 1, i32 0
  %1053 = load i32*, i32** %1052, align 8
  %1054 = icmp eq i32* %1053, null
  br i1 %1054, label %1057, label %1055

1055:                                             ; preds = %1051
  %1056 = bitcast i32* %1053 to i8*
  tail call void @_ZdaPv(i8* %1056) #17
  br label %1057

1057:                                             ; preds = %1050, %1051, %1055
  %1058 = load i32, i32* %780, align 8
  %1059 = icmp sgt i32 %1058, 5
  %1060 = load i32*, i32** %869, align 8
  %1061 = select i1 %1059, i32* %1060, i32* %870
  %1062 = icmp sgt i32 %1058, 0
  br i1 %1062, label %1063, label %1105

1063:                                             ; preds = %1057
  %1064 = zext i32 %1058 to i64
  %1065 = add nsw i64 %1064, -1
  %1066 = and i64 %1064, 3
  %1067 = icmp ult i64 %1065, 3
  br i1 %1067, label %1086, label %1068

1068:                                             ; preds = %1063
  %1069 = sub nsw i64 %1064, %1066
  br label %1070

1070:                                             ; preds = %1557, %1068
  %1071 = phi i64 [ 0, %1068 ], [ %1560, %1557 ]
  %1072 = phi i32 [ 1, %1068 ], [ %1559, %1557 ]
  %1073 = phi i64 [ %1069, %1068 ], [ %1561, %1557 ]
  %1074 = getelementptr inbounds i32, i32* %1061, i64 %1071
  %1075 = load i32, i32* %1074, align 4
  %1076 = mul nsw i32 %1075, %1072
  %1077 = or i64 %1071, 1
  %1078 = getelementptr inbounds i32, i32* %1061, i64 %1077
  %1079 = load i32, i32* %1078, align 4
  %1080 = mul nsw i32 %1079, %1076
  %1081 = or i64 %1071, 2
  %1082 = getelementptr inbounds i32, i32* %1061, i64 %1081
  %1083 = load i32, i32* %1082, align 4
  %1084 = mul nsw i32 %1083, %1080
  %1085 = icmp eq i64 %1071, 0
  br i1 %1085, label %1557, label %1553

1086:                                             ; preds = %1557, %1063
  %1087 = phi i32 [ undef, %1063 ], [ %1559, %1557 ]
  %1088 = phi i64 [ 0, %1063 ], [ %1560, %1557 ]
  %1089 = phi i32 [ 1, %1063 ], [ %1559, %1557 ]
  %1090 = icmp eq i64 %1066, 0
  br i1 %1090, label %1105, label %1091

1091:                                             ; preds = %1086, %1099
  %1092 = phi i64 [ %1102, %1099 ], [ %1088, %1086 ]
  %1093 = phi i32 [ %1101, %1099 ], [ %1089, %1086 ]
  %1094 = phi i64 [ %1103, %1099 ], [ %1066, %1086 ]
  %1095 = icmp eq i64 %1092, 3
  br i1 %1095, label %1099, label %1096

1096:                                             ; preds = %1091
  %1097 = getelementptr inbounds i32, i32* %1061, i64 %1092
  %1098 = load i32, i32* %1097, align 4
  br label %1099

1099:                                             ; preds = %1096, %1091
  %1100 = phi i32 [ %1098, %1096 ], [ 1, %1091 ]
  %1101 = mul nsw i32 %1100, %1093
  %1102 = add nuw nsw i64 %1092, 1
  %1103 = add i64 %1094, -1
  %1104 = icmp eq i64 %1103, 0
  br i1 %1104, label %1105, label %1091, !llvm.loop !179

1105:                                             ; preds = %1086, %1099, %1057
  %1106 = phi i32 [ 1, %1057 ], [ %1087, %1086 ], [ %1101, %1099 ]
  %1107 = load i32, i32* %883, align 8
  %1108 = icmp sgt i32 %1107, 5
  %1109 = load i32*, i32** %950, align 8
  %1110 = getelementptr inbounds i32, i32* %1109, i64 %951
  %1111 = select i1 %1108, i32* %1110, i32* %953
  %1112 = load i32, i32* %1111, align 4
  %1113 = getelementptr inbounds i32, i32* %1060, i64 3
  %1114 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1, i32 1, i64 4
  %1115 = bitcast i8* %1114 to i32*
  %1116 = select i1 %1059, i32* %1113, i32* %1115
  %1117 = load i32, i32* %1116, align 4
  %1118 = icmp slt i32 %1117, %1112
  %1119 = bitcast [2 x i8*]* %32 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1119) #18
  %1120 = getelementptr inbounds [2 x i8*], [2 x i8*]* %32, i64 0, i64 0
  %1121 = getelementptr inbounds [2 x i8*], [2 x i8*]* %32, i64 0, i64 1
  store i8* %2, i8** %1120, align 16
  store i8* %4, i8** %1121, align 8
  %1122 = bitcast [2 x %"class.tflite::RuntimeShape"*]* %33 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1122) #18
  %1123 = getelementptr inbounds [2 x %"class.tflite::RuntimeShape"*], [2 x %"class.tflite::RuntimeShape"*]* %33, i64 0, i64 0
  %1124 = getelementptr inbounds [2 x %"class.tflite::RuntimeShape"*], [2 x %"class.tflite::RuntimeShape"*]* %33, i64 0, i64 1
  store %"class.tflite::RuntimeShape"* %22, %"class.tflite::RuntimeShape"** %1123, align 16
  store %"class.tflite::RuntimeShape"* %23, %"class.tflite::RuntimeShape"** %1124, align 8
  %1125 = load i32, i32* %676, align 8
  %1126 = icmp sgt i32 %1125, 5
  %1127 = load i32*, i32** %765, align 8
  %1128 = bitcast %union.anon* %683 to [5 x i32]*
  %1129 = bitcast %union.anon* %683 to i32*
  %1130 = select i1 %1126, i32* %1127, i32* %1129
  %1131 = load i32, i32* %1130, align 4
  %1132 = sext i32 %1131 to i64
  %1133 = getelementptr inbounds i32, i32* %1127, i64 1
  %1134 = getelementptr inbounds [5 x i32], [5 x i32]* %1128, i64 0, i64 1
  %1135 = select i1 %1126, i32* %1133, i32* %1134
  %1136 = load i32, i32* %1135, align 4
  %1137 = sext i32 %1136 to i64
  %1138 = mul nsw i64 %1132, %1137
  %1139 = getelementptr inbounds i32, i32* %1127, i64 2
  %1140 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1, i32 1
  %1141 = bitcast [16 x i8]* %1140 to i32*
  %1142 = select i1 %1126, i32* %1139, i32* %1141
  %1143 = load i32, i32* %1142, align 4
  %1144 = sext i32 %1143 to i64
  %1145 = mul nsw i64 %1138, %1144
  %1146 = select i1 %1118, i32 %1117, i32 %1112
  %1147 = icmp sgt i32 %1125, 4
  br i1 %1147, label %1148, label %1176

1148:                                             ; preds = %1105
  %1149 = add i32 %1125, -4
  %1150 = add i32 %1125, -5
  %1151 = and i32 %1149, 3
  %1152 = icmp ult i32 %1150, 3
  br i1 %1152, label %1155, label %1153

1153:                                             ; preds = %1148
  %1154 = sub i32 %1149, %1151
  br label %1179

1155:                                             ; preds = %1179, %1148
  %1156 = phi i64 [ undef, %1148 ], [ %1209, %1179 ]
  %1157 = phi i64 [ 4, %1148 ], [ %1210, %1179 ]
  %1158 = phi i64 [ 1, %1148 ], [ %1209, %1179 ]
  %1159 = icmp eq i32 %1151, 0
  br i1 %1159, label %1173, label %1160

1160:                                             ; preds = %1155, %1160
  %1161 = phi i64 [ %1170, %1160 ], [ %1157, %1155 ]
  %1162 = phi i64 [ %1169, %1160 ], [ %1158, %1155 ]
  %1163 = phi i32 [ %1171, %1160 ], [ %1151, %1155 ]
  %1164 = getelementptr inbounds i32, i32* %1127, i64 %1161
  %1165 = getelementptr inbounds [5 x i32], [5 x i32]* %1128, i64 0, i64 %1161
  %1166 = select i1 %1126, i32* %1164, i32* %1165
  %1167 = load i32, i32* %1166, align 4
  %1168 = sext i32 %1167 to i64
  %1169 = mul nsw i64 %1162, %1168
  %1170 = add nuw nsw i64 %1161, 1
  %1171 = add i32 %1163, -1
  %1172 = icmp eq i32 %1171, 0
  br i1 %1172, label %1173, label %1160, !llvm.loop !180

1173:                                             ; preds = %1160, %1155
  %1174 = phi i64 [ %1156, %1155 ], [ %1169, %1160 ]
  %1175 = trunc i64 %1174 to i32
  br label %1176

1176:                                             ; preds = %1173, %1105
  %1177 = phi i32 [ 1, %1105 ], [ %1175, %1173 ]
  %1178 = icmp sgt i64 %1145, 0
  br i1 %1178, label %1213, label %1241

1179:                                             ; preds = %1179, %1153
  %1180 = phi i64 [ 4, %1153 ], [ %1210, %1179 ]
  %1181 = phi i64 [ 1, %1153 ], [ %1209, %1179 ]
  %1182 = phi i32 [ %1154, %1153 ], [ %1211, %1179 ]
  %1183 = getelementptr inbounds i32, i32* %1127, i64 %1180
  %1184 = getelementptr inbounds [5 x i32], [5 x i32]* %1128, i64 0, i64 %1180
  %1185 = select i1 %1126, i32* %1183, i32* %1184
  %1186 = load i32, i32* %1185, align 4
  %1187 = sext i32 %1186 to i64
  %1188 = mul nsw i64 %1181, %1187
  %1189 = or i64 %1180, 1
  %1190 = getelementptr inbounds i32, i32* %1127, i64 %1189
  %1191 = getelementptr inbounds [5 x i32], [5 x i32]* %1128, i64 0, i64 %1189
  %1192 = select i1 %1126, i32* %1190, i32* %1191
  %1193 = load i32, i32* %1192, align 4
  %1194 = sext i32 %1193 to i64
  %1195 = mul nsw i64 %1188, %1194
  %1196 = or i64 %1180, 2
  %1197 = getelementptr inbounds i32, i32* %1127, i64 %1196
  %1198 = getelementptr inbounds [5 x i32], [5 x i32]* %1128, i64 0, i64 %1196
  %1199 = select i1 %1126, i32* %1197, i32* %1198
  %1200 = load i32, i32* %1199, align 4
  %1201 = sext i32 %1200 to i64
  %1202 = mul nsw i64 %1195, %1201
  %1203 = or i64 %1180, 3
  %1204 = getelementptr inbounds i32, i32* %1127, i64 %1203
  %1205 = getelementptr inbounds [5 x i32], [5 x i32]* %1128, i64 0, i64 %1203
  %1206 = select i1 %1126, i32* %1204, i32* %1205
  %1207 = load i32, i32* %1206, align 4
  %1208 = sext i32 %1207 to i64
  %1209 = mul nsw i64 %1202, %1208
  %1210 = add nuw nsw i64 %1180, 4
  %1211 = add i32 %1182, -4
  %1212 = icmp eq i32 %1211, 0
  br i1 %1212, label %1155, label %1179

1213:                                             ; preds = %1176, %1548
  %1214 = phi i32 [ %1552, %1548 ], [ %885, %1176 ]
  %1215 = phi %"class.tflite::RuntimeShape"* [ %1550, %1548 ], [ %22, %1176 ]
  %1216 = phi i64 [ %1546, %1548 ], [ 0, %1176 ]
  %1217 = phi i8* [ %1549, %1548 ], [ %16, %1176 ]
  %1218 = trunc i64 %1216 to i32
  %1219 = icmp sgt i32 %1214, 5
  br i1 %1219, label %1220, label %1224

1220:                                             ; preds = %1213
  %1221 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1215, i64 0, i32 1, i32 0
  %1222 = load i32*, i32** %1221, align 8
  %1223 = getelementptr inbounds i32, i32* %1222, i64 3
  br label %1227

1224:                                             ; preds = %1213
  %1225 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1215, i64 0, i32 1, i32 1, i64 4
  %1226 = bitcast i8* %1225 to i32*
  br label %1227

1227:                                             ; preds = %1224, %1220
  %1228 = phi i32* [ %1223, %1220 ], [ %1226, %1224 ]
  %1229 = load i32, i32* %1228, align 4
  %1230 = mul i32 %1229, %1177
  %1231 = load i8*, i8** %1120, align 16
  %1232 = mul nsw i32 %1230, %1218
  %1233 = sext i32 %1232 to i64
  %1234 = getelementptr inbounds i8, i8* %1231, i64 %1233
  %1235 = sext i32 %1230 to i64
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %1217, i8* align 1 %1234, i64 %1235, i1 false) #18
  %1236 = getelementptr inbounds i8, i8* %1217, i64 %1235
  %1237 = load %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1124, align 8
  %1238 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1237, i64 0, i32 0
  %1239 = load i32, i32* %1238, align 8
  %1240 = icmp sgt i32 %1239, 5
  br i1 %1240, label %1533, label %1530

1241:                                             ; preds = %1537, %1176
  %1242 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %34 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1242) #18
  %1243 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %34, i64 0, i32 0
  %1244 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %34, i64 0, i32 1
  %1245 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %34, i64 0, i32 2
  %1246 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %34, i64 0, i32 3
  %1247 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %34 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %1247, i8 -86, i64 16, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %1242, i8 0, i64 14, i1 false) #18
  store i32 %1146, i32* %1244, align 4
  store i32 %947, i32* %1245, align 4
  store i32 1, i32* %1243, align 4
  %1248 = trunc i32 %39 to i8
  store i8 %1248, i8* %1246, align 4
  %1249 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %35 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1249) #18
  %1250 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %35, i64 0, i32 0
  %1251 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %35, i64 0, i32 1
  %1252 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %35, i64 0, i32 2
  %1253 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %35, i64 0, i32 3
  %1254 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %35 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %1254, i8 -86, i64 16, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %1249, i8 0, i64 14, i1 false) #18
  store i32 %947, i32* %1251, align 4
  store i32 %1106, i32* %1252, align 4
  store i32 0, i32* %1250, align 4
  store i8 -128, i8* %1253, align 4
  %1255 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %36 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %1255) #18
  %1256 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %36, i64 0, i32 0
  %1257 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %36, i64 0, i32 1
  %1258 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %36, i64 0, i32 2
  %1259 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %36, i64 0, i32 3
  %1260 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %36 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %1260, i8 -86, i64 16, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %1255, i8 0, i64 15, i1 false) #18
  store i32 %1146, i32* %1257, align 4
  store i32 %1106, i32* %1258, align 4
  store i32 0, i32* %1256, align 4
  store i16 0, i16* %1259, align 4
  %1261 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %37 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %1261) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1261, i8 -86, i64 40, i1 false)
  %1262 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %37, i64 0, i32 5
  %1263 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %37, i64 0, i32 2
  %1264 = bitcast i32** %1263 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1264, i8 0, i64 16, i1 false) #18
  store i16 -32768, i16* %1262, align 8
  %1265 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %37, i64 0, i32 6
  store i16 32767, i16* %1265, align 2
  %1266 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %37, i64 0, i32 4
  store i32* %8, i32** %1266, align 8
  %1267 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %37, i64 0, i32 0
  store i32 %41, i32* %1267, align 8
  %1268 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %37, i64 0, i32 1
  store i32 %43, i32* %1268, align 4
  %1269 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %19, i64 0, i32 4
  %1270 = load i8, i8* %1269, align 4, !range !5
  %1271 = icmp eq i8 %1270, 0
  br i1 %1271, label %1273, label %1272

1272:                                             ; preds = %1241
  call void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.224"* nonnull dereferenceable(16) %34, i8* %6, %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* nonnull dereferenceable(16) %35, i8* %16, %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* nonnull dereferenceable(16) %36, i16* %18, %"struct.tflite::cpu_backend_gemm::GemmParams.228"* nonnull dereferenceable(40) %37, %"class.tflite::CpuBackendContext"* %19) #18
  br label %1274

1273:                                             ; preds = %1241
  call void @_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.224"* nonnull dereferenceable(16) %34, i8* %6, %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* nonnull dereferenceable(16) %35, i8* %16, %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* nonnull dereferenceable(16) %36, i16* %18, %"struct.tflite::cpu_backend_gemm::GemmParams.228"* nonnull dereferenceable(40) %37, %"class.tflite::CpuBackendContext"* %19) #18
  br label %1274

1274:                                             ; preds = %1272, %1273
  %1275 = mul nsw i32 %1038, 3
  %1276 = sext i32 %1275 to i64
  %1277 = icmp sgt i32 %933, 0
  br i1 %1277, label %1278, label %1285

1278:                                             ; preds = %1274
  %1279 = shl nsw i32 %1038, 1
  %1280 = sext i32 %1279 to i64
  %1281 = getelementptr inbounds i16, i16* %18, i64 %1280
  %1282 = sext i32 %1038 to i64
  %1283 = getelementptr inbounds i16, i16* %18, i64 %1282
  %1284 = icmp sgt i32 %1038, 0
  br label %1358

1285:                                             ; preds = %1517, %1274
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %1261) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1255) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1249) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1242) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1122) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %1119) #18
  %1286 = load i32, i32* %780, align 8
  %1287 = icmp sgt i32 %1286, 5
  br i1 %1287, label %1288, label %1294

1288:                                             ; preds = %1285
  %1289 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1, i32 0
  %1290 = load i32*, i32** %1289, align 8
  %1291 = icmp eq i32* %1290, null
  br i1 %1291, label %1294, label %1292

1292:                                             ; preds = %1288
  %1293 = bitcast i32* %1290 to i8*
  call void @_ZdaPv(i8* %1293) #17
  br label %1294

1294:                                             ; preds = %1285, %1288, %1292
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %779) #18
  %1295 = load i32, i32* %676, align 8
  %1296 = icmp sgt i32 %1295, 5
  br i1 %1296, label %1297, label %1303

1297:                                             ; preds = %1294
  %1298 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1, i32 0
  %1299 = load i32*, i32** %1298, align 8
  %1300 = icmp eq i32* %1299, null
  br i1 %1300, label %1303, label %1301

1301:                                             ; preds = %1297
  %1302 = bitcast i32* %1299 to i8*
  call void @_ZdaPv(i8* %1302) #17
  br label %1303

1303:                                             ; preds = %1294, %1297, %1301
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %675) #18
  %1304 = load i32, i32* %572, align 8
  %1305 = icmp sgt i32 %1304, 5
  br i1 %1305, label %1306, label %1312

1306:                                             ; preds = %1303
  %1307 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 1, i32 0
  %1308 = load i32*, i32** %1307, align 8
  %1309 = icmp eq i32* %1308, null
  br i1 %1309, label %1312, label %1310

1310:                                             ; preds = %1306
  %1311 = bitcast i32* %1308 to i8*
  call void @_ZdaPv(i8* %1311) #17
  br label %1312

1312:                                             ; preds = %1303, %1306, %1310
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %571) #18
  %1313 = load i32, i32* %468, align 8
  %1314 = icmp sgt i32 %1313, 5
  br i1 %1314, label %1315, label %1321

1315:                                             ; preds = %1312
  %1316 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 1, i32 0
  %1317 = load i32*, i32** %1316, align 8
  %1318 = icmp eq i32* %1317, null
  br i1 %1318, label %1321, label %1319

1319:                                             ; preds = %1315
  %1320 = bitcast i32* %1317 to i8*
  call void @_ZdaPv(i8* %1320) #17
  br label %1321

1321:                                             ; preds = %1312, %1315, %1319
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %467) #18
  %1322 = load i32, i32* %364, align 8
  %1323 = icmp sgt i32 %1322, 5
  br i1 %1323, label %1324, label %1330

1324:                                             ; preds = %1321
  %1325 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %1326 = load i32*, i32** %1325, align 8
  %1327 = icmp eq i32* %1326, null
  br i1 %1327, label %1330, label %1328

1328:                                             ; preds = %1324
  %1329 = bitcast i32* %1326 to i8*
  call void @_ZdaPv(i8* %1329) #17
  br label %1330

1330:                                             ; preds = %1321, %1324, %1328
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %363) #18
  %1331 = load i32, i32* %261, align 8
  %1332 = icmp sgt i32 %1331, 5
  br i1 %1332, label %1333, label %1339

1333:                                             ; preds = %1330
  %1334 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %1335 = load i32*, i32** %1334, align 8
  %1336 = icmp eq i32* %1335, null
  br i1 %1336, label %1339, label %1337

1337:                                             ; preds = %1333
  %1338 = bitcast i32* %1335 to i8*
  call void @_ZdaPv(i8* %1338) #17
  br label %1339

1339:                                             ; preds = %1330, %1333, %1337
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %260) #18
  %1340 = load i32, i32* %157, align 8
  %1341 = icmp sgt i32 %1340, 5
  br i1 %1341, label %1342, label %1348

1342:                                             ; preds = %1339
  %1343 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %1344 = load i32*, i32** %1343, align 8
  %1345 = icmp eq i32* %1344, null
  br i1 %1345, label %1348, label %1346

1346:                                             ; preds = %1342
  %1347 = bitcast i32* %1344 to i8*
  call void @_ZdaPv(i8* %1347) #17
  br label %1348

1348:                                             ; preds = %1339, %1342, %1346
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %156) #18
  %1349 = load i32, i32* %53, align 8
  %1350 = icmp sgt i32 %1349, 5
  br i1 %1350, label %1351, label %1357

1351:                                             ; preds = %1348
  %1352 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %1353 = load i32*, i32** %1352, align 8
  %1354 = icmp eq i32* %1353, null
  br i1 %1354, label %1357, label %1355

1355:                                             ; preds = %1351
  %1356 = bitcast i32* %1353 to i8*
  call void @_ZdaPv(i8* %1356) #17
  br label %1357

1357:                                             ; preds = %1348, %1351, %1355
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %52) #18
  ret void

1358:                                             ; preds = %1517, %1278
  %1359 = phi i16* [ %18, %1278 ], [ %1525, %1517 ]
  %1360 = phi i16* [ %1283, %1278 ], [ %1526, %1517 ]
  %1361 = phi i16* [ %1281, %1278 ], [ %1527, %1517 ]
  %1362 = phi i16* [ %18, %1278 ], [ %1521, %1517 ]
  %1363 = phi i16* [ %10, %1278 ], [ %1520, %1517 ]
  %1364 = phi i16* [ %12, %1278 ], [ %1519, %1517 ]
  %1365 = phi i8* [ %14, %1278 ], [ %1518, %1517 ]
  %1366 = phi i32 [ 0, %1278 ], [ %1528, %1517 ]
  %1367 = getelementptr inbounds i16, i16* %1362, i64 %1276
  br i1 %1284, label %1368, label %1517

1368:                                             ; preds = %1358, %1498
  %1369 = phi i16* [ %1377, %1498 ], [ %1359, %1358 ]
  %1370 = phi i16* [ %1388, %1498 ], [ %1360, %1358 ]
  %1371 = phi i16* [ %1399, %1498 ], [ %1361, %1358 ]
  %1372 = phi i16* [ %1410, %1498 ], [ %1367, %1358 ]
  %1373 = phi i16* [ %1435, %1498 ], [ %1363, %1358 ]
  %1374 = phi i16* [ %1500, %1498 ], [ %1364, %1358 ]
  %1375 = phi i8* [ %1514, %1498 ], [ %1365, %1358 ]
  %1376 = phi i32 [ %1515, %1498 ], [ 0, %1358 ]
  %1377 = getelementptr inbounds i16, i16* %1369, i64 1
  %1378 = load i16, i16* %1369, align 2
  %1379 = icmp slt i16 %1378, 1
  %1380 = icmp eq i16 %1378, 0
  %1381 = sub i16 0, %1378
  %1382 = select i1 %1379, i16 %1378, i16 %1381
  %1383 = call i16 @_ZN8gemmlowp22exp_on_negative_valuesIsLi3EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE(i16 %1382) #18
  %1384 = call i16 @_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_(i16 %1383) #18
  %1385 = sub i16 32767, %1384
  %1386 = select i1 %1379, i16 %1385, i16 %1384
  %1387 = select i1 %1380, i16 16384, i16 %1386
  %1388 = getelementptr inbounds i16, i16* %1370, i64 1
  %1389 = load i16, i16* %1370, align 2
  %1390 = icmp eq i16 %1389, 0
  %1391 = sub i16 0, %1389
  %1392 = icmp slt i16 %1389, 0
  %1393 = select i1 %1392, i16 %1389, i16 %1391
  %1394 = call i16 @_ZN8gemmlowp22exp_on_negative_valuesIsLi4EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE(i16 %1393) #18
  %1395 = call i16 @_ZN8gemmlowp40one_minus_x_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_(i16 %1394) #18
  %1396 = sub i16 0, %1395
  %1397 = select i1 %1392, i16 %1396, i16 %1395
  %1398 = select i1 %1390, i16 0, i16 %1397
  %1399 = getelementptr inbounds i16, i16* %1371, i64 1
  %1400 = load i16, i16* %1371, align 2
  %1401 = icmp slt i16 %1400, 1
  %1402 = icmp eq i16 %1400, 0
  %1403 = sub i16 0, %1400
  %1404 = select i1 %1401, i16 %1400, i16 %1403
  %1405 = call i16 @_ZN8gemmlowp22exp_on_negative_valuesIsLi3EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE(i16 %1404) #18
  %1406 = call i16 @_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_(i16 %1405) #18
  %1407 = sub i16 32767, %1406
  %1408 = select i1 %1401, i16 %1407, i16 %1406
  %1409 = select i1 %1402, i16 16384, i16 %1408
  %1410 = getelementptr inbounds i16, i16* %1372, i64 1
  %1411 = load i16, i16* %1372, align 2
  %1412 = icmp slt i16 %1411, 1
  %1413 = icmp eq i16 %1411, 0
  %1414 = sub i16 0, %1411
  %1415 = select i1 %1412, i16 %1411, i16 %1414
  %1416 = call i16 @_ZN8gemmlowp22exp_on_negative_valuesIsLi3EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE(i16 %1415) #18
  %1417 = call i16 @_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_(i16 %1416) #18
  %1418 = sub i16 32767, %1417
  %1419 = select i1 %1412, i16 %1418, i16 %1417
  %1420 = select i1 %1413, i16 16384, i16 %1419
  %1421 = icmp eq i16 %1387, %1398
  %1422 = icmp eq i16 %1387, -32768
  %1423 = and i1 %1422, %1421
  br i1 %1423, label %1433, label %1424

1424:                                             ; preds = %1368
  %1425 = sext i16 %1398 to i32
  %1426 = sext i16 %1387 to i32
  %1427 = mul nsw i32 %1425, %1426
  %1428 = icmp sgt i32 %1427, -1
  %1429 = select i1 %1428, i32 16384, i32 -16383
  %1430 = add nsw i32 %1429, %1427
  %1431 = sdiv i32 %1430, 32768
  %1432 = trunc i32 %1431 to i16
  br label %1433

1433:                                             ; preds = %1368, %1424
  %1434 = phi i16 [ %1432, %1424 ], [ 32767, %1368 ]
  %1435 = getelementptr inbounds i16, i16* %1373, i64 1
  %1436 = load i16, i16* %1373, align 2
  %1437 = icmp eq i16 %1409, %1436
  %1438 = icmp eq i16 %1409, -32768
  %1439 = and i1 %1438, %1437
  br i1 %1439, label %1448, label %1440

1440:                                             ; preds = %1433
  %1441 = sext i16 %1436 to i32
  %1442 = sext i16 %1409 to i32
  %1443 = mul nsw i32 %1441, %1442
  %1444 = icmp sgt i32 %1443, -1
  %1445 = select i1 %1444, i32 16384, i32 -16383
  %1446 = add nsw i32 %1445, %1443
  %1447 = sdiv i32 %1446, 32768
  br label %1448

1448:                                             ; preds = %1433, %1440
  %1449 = phi i32 [ %1447, %1440 ], [ 32767, %1433 ]
  %1450 = and i16 %1434, 15
  %1451 = lshr i16 %1434, 15
  %1452 = add nuw nsw i16 %1451, 7
  %1453 = ashr i16 %1434, 4
  %1454 = icmp ugt i16 %1450, %1452
  %1455 = zext i1 %1454 to i16
  %1456 = add nsw i16 %1453, %1455
  %1457 = sext i16 %1456 to i32
  %1458 = shl i32 %1449, 16
  %1459 = ashr exact i32 %1458, 16
  %1460 = add nsw i32 %1459, %1457
  %1461 = icmp sgt i32 %1460, -32768
  %1462 = select i1 %1461, i32 %1460, i32 -32768
  %1463 = icmp slt i32 %1462, 32767
  %1464 = select i1 %1463, i32 %1462, i32 32767
  %1465 = trunc i32 %1464 to i16
  %1466 = icmp slt i16 %1465, 16384
  %1467 = icmp sgt i16 %1465, -16384
  %1468 = sext i16 %1465 to i64
  %1469 = shl nsw i64 %1468, 1
  %1470 = icmp slt i64 %1469, 32767
  %1471 = select i1 %1470, i64 %1469, i64 32767
  %1472 = icmp sgt i64 %1471, -32768
  %1473 = select i1 %1472, i64 %1471, i64 -32768
  %1474 = trunc i64 %1473 to i16
  %1475 = select i1 %1466, i16 %1474, i16 32767
  %1476 = select i1 %1467, i16 %1475, i16 -32768
  %1477 = icmp eq i16 %1476, 0
  %1478 = sub i16 0, %1476
  %1479 = icmp slt i16 %1476, 0
  %1480 = select i1 %1479, i16 %1476, i16 %1478
  %1481 = call i16 @_ZN8gemmlowp22exp_on_negative_valuesIsLi4EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE(i16 %1480) #18
  %1482 = call i16 @_ZN8gemmlowp40one_minus_x_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_(i16 %1481) #18
  %1483 = sub i16 0, %1482
  %1484 = select i1 %1479, i16 %1483, i16 %1482
  %1485 = select i1 %1477, i16 0, i16 %1484
  %1486 = icmp eq i16 %1420, %1485
  %1487 = icmp eq i16 %1420, -32768
  %1488 = and i1 %1487, %1486
  br i1 %1488, label %1498, label %1489

1489:                                             ; preds = %1448
  %1490 = sext i16 %1485 to i32
  %1491 = sext i16 %1420 to i32
  %1492 = mul nsw i32 %1490, %1491
  %1493 = icmp sgt i32 %1492, -1
  %1494 = select i1 %1493, i32 16384, i32 -16383
  %1495 = add nsw i32 %1494, %1492
  %1496 = sdiv i32 %1495, 32768
  %1497 = trunc i32 %1496 to i16
  br label %1498

1498:                                             ; preds = %1448, %1489
  %1499 = phi i16 [ %1497, %1489 ], [ 32767, %1448 ]
  %1500 = getelementptr inbounds i16, i16* %1374, i64 1
  store i16 %1465, i16* %1374, align 2
  %1501 = and i16 %1499, 255
  %1502 = lshr i16 %1499, 15
  %1503 = add nuw nsw i16 %1502, 127
  %1504 = ashr i16 %1499, 8
  %1505 = icmp ugt i16 %1501, %1503
  %1506 = zext i1 %1505 to i16
  %1507 = add nsw i16 %1504, %1506
  %1508 = icmp slt i16 %1507, 127
  %1509 = select i1 %1508, i16 %1507, i16 127
  %1510 = icmp sgt i16 %1509, -128
  %1511 = select i1 %1510, i16 %1509, i16 -128
  %1512 = trunc i16 %1511 to i8
  %1513 = xor i8 %1512, -128
  %1514 = getelementptr inbounds i8, i8* %1375, i64 1
  store i8 %1513, i8* %1375, align 1
  %1515 = add nuw nsw i32 %1376, 1
  %1516 = icmp slt i32 %1515, %1038
  br i1 %1516, label %1368, label %1517

1517:                                             ; preds = %1498, %1358
  %1518 = phi i8* [ %1365, %1358 ], [ %1514, %1498 ]
  %1519 = phi i16* [ %1364, %1358 ], [ %1500, %1498 ]
  %1520 = phi i16* [ %1363, %1358 ], [ %1435, %1498 ]
  %1521 = phi i16* [ %1367, %1358 ], [ %1410, %1498 ]
  %1522 = phi i16* [ %1361, %1358 ], [ %1399, %1498 ]
  %1523 = phi i16* [ %1360, %1358 ], [ %1388, %1498 ]
  %1524 = phi i16* [ %1359, %1358 ], [ %1377, %1498 ]
  %1525 = getelementptr inbounds i16, i16* %1524, i64 %1276
  %1526 = getelementptr inbounds i16, i16* %1523, i64 %1276
  %1527 = getelementptr inbounds i16, i16* %1522, i64 %1276
  %1528 = add nuw nsw i32 %1366, 1
  %1529 = icmp eq i32 %1528, %933
  br i1 %1529, label %1285, label %1358

1530:                                             ; preds = %1227
  %1531 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1237, i64 0, i32 1, i32 1, i64 4
  %1532 = bitcast i8* %1531 to i32*
  br label %1537

1533:                                             ; preds = %1227
  %1534 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1237, i64 0, i32 1, i32 0
  %1535 = load i32*, i32** %1534, align 8
  %1536 = getelementptr inbounds i32, i32* %1535, i64 3
  br label %1537

1537:                                             ; preds = %1533, %1530
  %1538 = phi i32* [ %1536, %1533 ], [ %1532, %1530 ]
  %1539 = load i32, i32* %1538, align 4
  %1540 = mul i32 %1539, %1177
  %1541 = load i8*, i8** %1121, align 8
  %1542 = mul nsw i32 %1540, %1218
  %1543 = sext i32 %1542 to i64
  %1544 = getelementptr inbounds i8, i8* %1541, i64 %1543
  %1545 = sext i32 %1540 to i64
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %1236, i8* align 1 %1544, i64 %1545, i1 false) #18
  %1546 = add nuw nsw i64 %1216, 1
  %1547 = icmp eq i64 %1546, %1145
  br i1 %1547, label %1241, label %1548

1548:                                             ; preds = %1537
  %1549 = getelementptr inbounds i8, i8* %1236, i64 %1545
  %1550 = load %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %1123, align 16
  %1551 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1550, i64 0, i32 0
  %1552 = load i32, i32* %1551, align 8
  br label %1213

1553:                                             ; preds = %1070
  %1554 = or i64 %1071, 3
  %1555 = getelementptr inbounds i32, i32* %1061, i64 %1554
  %1556 = load i32, i32* %1555, align 4
  br label %1557

1557:                                             ; preds = %1553, %1070
  %1558 = phi i32 [ %1556, %1553 ], [ 1, %1070 ]
  %1559 = mul nsw i32 %1558, %1084
  %1560 = add nuw nsw i64 %1071, 4
  %1561 = add i64 %1073, -4
  %1562 = icmp eq i64 %1561, 0
  br i1 %1562, label %1086, label %1070

1563:                                             ; preds = %897
  %1564 = or i64 %898, 3
  %1565 = getelementptr inbounds i32, i32* %888, i64 %1564
  %1566 = load i32, i32* %1565, align 4
  br label %1567

1567:                                             ; preds = %1563, %897
  %1568 = phi i32 [ %1566, %1563 ], [ 1, %897 ]
  %1569 = mul nsw i32 %1568, %911
  %1570 = add nuw nsw i64 %898, 4
  %1571 = add i64 %900, -4
  %1572 = icmp eq i64 %1571, 0
  br i1 %1572, label %913, label %897
}

; Function Attrs: nounwind ssp uwtable
define hidden i8* @_ZN6tflite3ops7builtin4lstm4InitEP13TfLiteContextPKcm(%struct.TfLiteContext*, i8* nocapture readonly, i64) #1 {
  %4 = getelementptr inbounds i8, i8* %1, i64 12
  %5 = bitcast i8* %4 to i32*
  %6 = load i32, i32* %5, align 4
  switch i32 %6, label %19 [
    i32 0, label %7
    i32 1, label %14
  ]

7:                                                ; preds = %3
  %8 = tail call i8* @_Znwm(i64 376) #17
  %9 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 6
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %8, i8 0, i64 376, i1 false) #18
  %10 = load i32 (%struct.TfLiteContext*, i32, i32*)*, i32 (%struct.TfLiteContext*, i32, i32*)** %9, align 8
  %11 = getelementptr inbounds i8, i8* %8, i64 8
  %12 = bitcast i8* %11 to i32*
  %13 = tail call i32 %10(%struct.TfLiteContext* %0, i32 10, i32* %12) #18
  br label %19

14:                                               ; preds = %3
  %15 = tail call i8* @_Znwm(i64 376) #17
  %16 = bitcast i8* %15 to i32*
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 0, i64 376, i1 false) #18
  store i32 1, i32* %16, align 8
  %17 = getelementptr inbounds i8, i8* %15, i64 8
  %18 = bitcast i8* %17 to i32*
  store i32 -1, i32* %18, align 8
  br label %19

19:                                               ; preds = %3, %14, %7
  %20 = phi i8* [ %15, %14 ], [ %8, %7 ], [ null, %3 ]
  ret i8* %20
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN6tflite3ops7builtin4lstm4FreeEP13TfLiteContextPv(%struct.TfLiteContext* nocapture readnone, i8*) #1 {
  %3 = icmp eq i8* %1, null
  br i1 %3, label %7, label %4

4:                                                ; preds = %2
  %5 = getelementptr inbounds i8, i8* %1, i64 16
  %6 = bitcast i8* %5 to %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"*
  tail call void @_ZN6tflite3ops7builtin9lstm_eval20IntegerLstmParameterD2Ev(%"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %6) #18
  tail call void @_ZdlPv(i8* nonnull %1) #17
  br label %7

7:                                                ; preds = %4, %2
  ret void
}

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm7PrepareEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode*) #1 {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 4
  %4 = bitcast i8** %3 to %"struct.tflite::ops::builtin::lstm::OpData"**
  %5 = load %"struct.tflite::ops::builtin::lstm::OpData"*, %"struct.tflite::ops::builtin::lstm::OpData"** %4, align 8
  %6 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %5, i64 0, i32 0
  %7 = load i32, i32* %6, align 8
  switch i32 %7, label %12 [
    i32 0, label %8
    i32 1, label %10
  ]

8:                                                ; preds = %2
  %9 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full7PrepareEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1)
  br label %12

10:                                               ; preds = %2
  %11 = tail call i32 @_ZN6tflite3ops7builtin4lstm5basic7PrepareEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1)
  br label %12

12:                                               ; preds = %2, %10, %8
  %13 = phi i32 [ %11, %10 ], [ %9, %8 ], [ 1, %2 ]
  ret i32 %13
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin4lstm4EvalEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode* readonly) #1 {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 4
  %4 = bitcast i8** %3 to %"struct.tflite::ops::builtin::lstm::OpData"**
  %5 = load %"struct.tflite::ops::builtin::lstm::OpData"*, %"struct.tflite::ops::builtin::lstm::OpData"** %4, align 8
  %6 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm::OpData", %"struct.tflite::ops::builtin::lstm::OpData"* %5, i64 0, i32 0
  %7 = load i32, i32* %6, align 8
  switch i32 %7, label %12 [
    i32 0, label %8
    i32 1, label %10
  ]

8:                                                ; preds = %2
  %9 = tail call i32 @_ZN6tflite3ops7builtin4lstm4full4EvalEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1)
  br label %12

10:                                               ; preds = %2
  %11 = tail call i32 @_ZN6tflite3ops7builtin4lstm5basic4EvalEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1)
  br label %12

12:                                               ; preds = %2, %10, %8
  %13 = phi i32 [ %11, %10 ], [ %9, %8 ], [ 1, %2 ]
  ret i32 %13
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden %struct.TfLiteRegistration* @_ZN6tflite3ops7builtin13Register_LSTMEv() local_unnamed_addr #7 {
  ret %struct.TfLiteRegistration* bitcast ({ i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 }* @_ZZN6tflite3ops7builtin13Register_LSTMEvE1r to %struct.TfLiteRegistration*)
}

; Function Attrs: nobuiltin nounwind
declare void @_ZdaPv(i8*) local_unnamed_addr #6

; Function Attrs: nounwind readnone speculatable
declare float @llvm.ceil.f32(float) #4

; Function Attrs: noreturn
declare void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"*) local_unnamed_addr #8

; Function Attrs: noreturn nounwind
declare void @abort() local_unnamed_addr #9

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite11MatchingDimIJNS_12RuntimeShapeEiS1_iS1_iEEEiRKS1_iS3_iDpT_(%"class.tflite::RuntimeShape"* dereferenceable(32), i32, %"class.tflite::RuntimeShape"* dereferenceable(32), i32, %"class.tflite::RuntimeShape"*, i32, %"class.tflite::RuntimeShape"*, i32, %"class.tflite::RuntimeShape"*, i32) local_unnamed_addr #1 comdat {
  %11 = alloca %"class.tflite::RuntimeShape", align 8
  %12 = alloca %"class.tflite::RuntimeShape", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %0, i64 0, i32 0
  %15 = load i32, i32* %14, align 8
  %16 = icmp sgt i32 %15, 5
  %17 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %0, i64 0, i32 1
  %18 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  %19 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 0
  %20 = load i32, i32* %19, align 8
  store i32 %20, i32* %18, align 8
  %21 = icmp sgt i32 %20, 5
  br i1 %21, label %22, label %29

22:                                               ; preds = %10
  %23 = sext i32 %20 to i64
  %24 = shl nsw i64 %23, 2
  %25 = tail call i8* @_Znam(i64 %24) #17
  %26 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %27 = bitcast i32** %26 to i8**
  store i8* %25, i8** %27, align 8
  %28 = bitcast i8* %25 to i32*
  br label %34

29:                                               ; preds = %10
  %30 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %31 = bitcast %union.anon* %30 to i32*
  %32 = sext i32 %20 to i64
  %33 = shl nsw i64 %32, 2
  br label %34

34:                                               ; preds = %22, %29
  %35 = phi i64 [ %24, %22 ], [ %33, %29 ]
  %36 = phi i32* [ %28, %22 ], [ %31, %29 ]
  %37 = bitcast i32* %36 to i8*
  %38 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %6, i64 0, i32 1
  %39 = getelementptr inbounds %union.anon, %union.anon* %38, i64 0, i32 0
  %40 = load i32*, i32** %39, align 8
  %41 = bitcast %union.anon* %38 to i32*
  %42 = select i1 %21, i32* %40, i32* %41
  %43 = bitcast i32* %42 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %37, i8* align 4 %43, i64 %35, i1 false) #18
  %44 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  %45 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 0
  %46 = load i32, i32* %45, align 8
  store i32 %46, i32* %44, align 8
  %47 = icmp sgt i32 %46, 5
  br i1 %47, label %48, label %55

48:                                               ; preds = %34
  %49 = sext i32 %46 to i64
  %50 = shl nsw i64 %49, 2
  %51 = tail call i8* @_Znam(i64 %50) #17
  %52 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %53 = bitcast i32** %52 to i8**
  store i8* %51, i8** %53, align 8
  %54 = bitcast i8* %51 to i32*
  br label %60

55:                                               ; preds = %34
  %56 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %57 = bitcast %union.anon* %56 to i32*
  %58 = sext i32 %46 to i64
  %59 = shl nsw i64 %58, 2
  br label %60

60:                                               ; preds = %48, %55
  %61 = phi i64 [ %50, %48 ], [ %59, %55 ]
  %62 = phi i32* [ %54, %48 ], [ %57, %55 ]
  %63 = bitcast i32* %62 to i8*
  %64 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 1
  %65 = getelementptr inbounds %union.anon, %union.anon* %64, i64 0, i32 0
  %66 = load i32*, i32** %65, align 8
  %67 = bitcast %union.anon* %64 to i32*
  %68 = select i1 %47, i32* %66, i32* %67
  %69 = bitcast i32* %68 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %63, i8* align 4 %69, i64 %61, i1 false) #18
  %70 = bitcast %"class.tflite::RuntimeShape"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %70)
  %71 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 %46, i32* %71, align 8
  br i1 %47, label %72, label %79

72:                                               ; preds = %60
  %73 = sext i32 %46 to i64
  %74 = shl nsw i64 %73, 2
  %75 = tail call i8* @_Znam(i64 %74) #17
  %76 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %77 = bitcast i32** %76 to i8**
  store i8* %75, i8** %77, align 8
  %78 = bitcast i8* %75 to i32*
  br label %84

79:                                               ; preds = %60
  %80 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %81 = bitcast %union.anon* %80 to i32*
  %82 = sext i32 %46 to i64
  %83 = shl nsw i64 %82, 2
  br label %84

84:                                               ; preds = %79, %72
  %85 = phi i64 [ %74, %72 ], [ %83, %79 ]
  %86 = phi i32* [ %78, %72 ], [ %81, %79 ]
  %87 = bitcast i32* %86 to i8*
  %88 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %89 = getelementptr inbounds %union.anon, %union.anon* %88, i64 0, i32 0
  %90 = load i32*, i32** %89, align 8
  %91 = bitcast %union.anon* %88 to i32*
  %92 = select i1 %47, i32* %90, i32* %91
  %93 = bitcast i32* %92 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %87, i8* align 4 %93, i64 %85, i1 false) #18
  %94 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %95 = getelementptr inbounds %union.anon, %union.anon* %17, i64 0, i32 0
  %96 = load i32*, i32** %95, align 8
  %97 = sext i32 %1 to i64
  %98 = getelementptr inbounds i32, i32* %96, i64 %97
  %99 = bitcast %union.anon* %17 to [5 x i32]*
  %100 = getelementptr inbounds [5 x i32], [5 x i32]* %99, i64 0, i64 %97
  %101 = select i1 %16, i32* %98, i32* %100
  %102 = load i32, i32* %101, align 4
  %103 = getelementptr inbounds %union.anon, %union.anon* %94, i64 0, i32 0
  %104 = load i32*, i32** %103, align 8
  %105 = sext i32 %9 to i64
  %106 = getelementptr inbounds i32, i32* %104, i64 %105
  %107 = bitcast %union.anon* %94 to [5 x i32]*
  %108 = getelementptr inbounds [5 x i32], [5 x i32]* %107, i64 0, i64 %105
  %109 = select i1 %47, i32* %106, i32* %108
  %110 = load i32, i32* %109, align 4
  %111 = icmp slt i32 %110, %102
  %112 = select i1 %111, i32 %110, i32 %102
  %113 = xor i1 %47, true
  %114 = icmp eq i32* %104, null
  %115 = or i1 %114, %113
  br i1 %115, label %118, label %116

116:                                              ; preds = %84
  %117 = bitcast i32* %104 to i8*
  tail call void @_ZdaPv(i8* %117) #17
  br label %118

118:                                              ; preds = %84, %116
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %70)
  %119 = xor i1 %47, true
  %120 = icmp eq i32* %90, null
  %121 = or i1 %120, %119
  br i1 %121, label %124, label %122

122:                                              ; preds = %118
  %123 = bitcast i32* %90 to i8*
  tail call void @_ZdaPv(i8* %123) #17
  br label %124

124:                                              ; preds = %118, %122
  br i1 %21, label %125, label %131

125:                                              ; preds = %124
  %126 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %127 = load i32*, i32** %126, align 8
  %128 = icmp eq i32* %127, null
  br i1 %128, label %131, label %129

129:                                              ; preds = %125
  %130 = bitcast i32* %127 to i8*
  tail call void @_ZdaPv(i8* %130) #17
  br label %131

131:                                              ; preds = %124, %125, %129
  ret i32 %112
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #5 comdat {
  %11 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams", align 4
  %12 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams", align 4
  %13 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams", align 4
  %14 = alloca %"struct.tflite::cpu_backend_gemm::GemmParams", align 8
  %15 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %16 = load i32, i32* %15, align 8
  %17 = add nsw i32 %16, -1
  %18 = icmp sgt i32 %16, 5
  %19 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %20 = getelementptr inbounds %union.anon, %union.anon* %19, i64 0, i32 0
  %21 = load i32*, i32** %20, align 8
  %22 = sext i32 %17 to i64
  %23 = getelementptr inbounds i32, i32* %21, i64 %22
  %24 = bitcast %union.anon* %19 to [5 x i32]*
  %25 = getelementptr inbounds [5 x i32], [5 x i32]* %24, i64 0, i64 %22
  %26 = select i1 %18, i32* %23, i32* %25
  %27 = load i32, i32* %26, align 4
  %28 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %28) #18
  %29 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11, i64 0, i32 1
  %30 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11, i64 0, i32 2
  %31 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11, i64 0, i32 4
  %32 = bitcast i8* %31 to i32*
  store i32 -1431655766, i32* %32, align 4
  %33 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %33, i8 0, i64 17, i1 false)
  store i32 %27, i32* %29, align 4
  %34 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1, i64 0, i32 0
  %35 = load i32, i32* %34, align 8
  %36 = icmp sgt i32 %35, 5
  %37 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1, i64 0, i32 1
  br i1 %36, label %38, label %41

38:                                               ; preds = %10
  %39 = getelementptr inbounds %union.anon, %union.anon* %37, i64 0, i32 0
  %40 = load i32*, i32** %39, align 8
  br label %48

41:                                               ; preds = %10
  %42 = bitcast %union.anon* %37 to i32*
  %43 = icmp sgt i32 %35, 0
  br i1 %43, label %48, label %44

44:                                               ; preds = %41
  %45 = add i32 %27, 1
  %46 = icmp ult i32 %45, 3
  %47 = select i1 %46, i32 %27, i32 0
  br label %151

48:                                               ; preds = %41, %38
  %49 = phi i32* [ %40, %38 ], [ %42, %41 ]
  %50 = zext i32 %35 to i64
  %51 = icmp ult i32 %35, 8
  br i1 %51, label %137, label %52

52:                                               ; preds = %48
  %53 = and i64 %50, 4294967288
  %54 = add nsw i64 %53, -8
  %55 = lshr exact i64 %54, 3
  %56 = add nuw nsw i64 %55, 1
  %57 = and i64 %56, 3
  %58 = icmp ult i64 %54, 24
  br i1 %58, label %104, label %59

59:                                               ; preds = %52
  %60 = sub nsw i64 %56, %57
  br label %61

61:                                               ; preds = %61, %59
  %62 = phi i64 [ 0, %59 ], [ %101, %61 ]
  %63 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %59 ], [ %99, %61 ]
  %64 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %59 ], [ %100, %61 ]
  %65 = phi i64 [ %60, %59 ], [ %102, %61 ]
  %66 = getelementptr inbounds i32, i32* %49, i64 %62
  %67 = bitcast i32* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 4
  %69 = getelementptr inbounds i32, i32* %66, i64 4
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 4
  %72 = mul nsw <4 x i32> %68, %63
  %73 = mul nsw <4 x i32> %71, %64
  %74 = or i64 %62, 8
  %75 = getelementptr inbounds i32, i32* %49, i64 %74
  %76 = bitcast i32* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 4
  %78 = getelementptr inbounds i32, i32* %75, i64 4
  %79 = bitcast i32* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 4
  %81 = mul nsw <4 x i32> %77, %72
  %82 = mul nsw <4 x i32> %80, %73
  %83 = or i64 %62, 16
  %84 = getelementptr inbounds i32, i32* %49, i64 %83
  %85 = bitcast i32* %84 to <4 x i32>*
  %86 = load <4 x i32>, <4 x i32>* %85, align 4
  %87 = getelementptr inbounds i32, i32* %84, i64 4
  %88 = bitcast i32* %87 to <4 x i32>*
  %89 = load <4 x i32>, <4 x i32>* %88, align 4
  %90 = mul nsw <4 x i32> %86, %81
  %91 = mul nsw <4 x i32> %89, %82
  %92 = or i64 %62, 24
  %93 = getelementptr inbounds i32, i32* %49, i64 %92
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 4
  %96 = getelementptr inbounds i32, i32* %93, i64 4
  %97 = bitcast i32* %96 to <4 x i32>*
  %98 = load <4 x i32>, <4 x i32>* %97, align 4
  %99 = mul nsw <4 x i32> %95, %90
  %100 = mul nsw <4 x i32> %98, %91
  %101 = add i64 %62, 32
  %102 = add i64 %65, -4
  %103 = icmp eq i64 %102, 0
  br i1 %103, label %104, label %61, !llvm.loop !181

104:                                              ; preds = %61, %52
  %105 = phi <4 x i32> [ undef, %52 ], [ %99, %61 ]
  %106 = phi <4 x i32> [ undef, %52 ], [ %100, %61 ]
  %107 = phi i64 [ 0, %52 ], [ %101, %61 ]
  %108 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %52 ], [ %99, %61 ]
  %109 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %52 ], [ %100, %61 ]
  %110 = icmp eq i64 %57, 0
  br i1 %110, label %127, label %111

111:                                              ; preds = %104, %111
  %112 = phi i64 [ %124, %111 ], [ %107, %104 ]
  %113 = phi <4 x i32> [ %122, %111 ], [ %108, %104 ]
  %114 = phi <4 x i32> [ %123, %111 ], [ %109, %104 ]
  %115 = phi i64 [ %125, %111 ], [ %57, %104 ]
  %116 = getelementptr inbounds i32, i32* %49, i64 %112
  %117 = bitcast i32* %116 to <4 x i32>*
  %118 = load <4 x i32>, <4 x i32>* %117, align 4
  %119 = getelementptr inbounds i32, i32* %116, i64 4
  %120 = bitcast i32* %119 to <4 x i32>*
  %121 = load <4 x i32>, <4 x i32>* %120, align 4
  %122 = mul nsw <4 x i32> %118, %113
  %123 = mul nsw <4 x i32> %121, %114
  %124 = add i64 %112, 8
  %125 = add i64 %115, -1
  %126 = icmp eq i64 %125, 0
  br i1 %126, label %127, label %111, !llvm.loop !182

127:                                              ; preds = %111, %104
  %128 = phi <4 x i32> [ %105, %104 ], [ %122, %111 ]
  %129 = phi <4 x i32> [ %106, %104 ], [ %123, %111 ]
  %130 = mul <4 x i32> %129, %128
  %131 = shufflevector <4 x i32> %130, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %132 = mul <4 x i32> %130, %131
  %133 = shufflevector <4 x i32> %132, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %134 = mul <4 x i32> %132, %133
  %135 = extractelement <4 x i32> %134, i32 0
  %136 = icmp eq i64 %53, %50
  br i1 %136, label %148, label %137

137:                                              ; preds = %127, %48
  %138 = phi i64 [ 0, %48 ], [ %53, %127 ]
  %139 = phi i32 [ 1, %48 ], [ %135, %127 ]
  br label %140

140:                                              ; preds = %137, %140
  %141 = phi i64 [ %146, %140 ], [ %138, %137 ]
  %142 = phi i32 [ %145, %140 ], [ %139, %137 ]
  %143 = getelementptr inbounds i32, i32* %49, i64 %141
  %144 = load i32, i32* %143, align 4
  %145 = mul nsw i32 %144, %142
  %146 = add nuw nsw i64 %141, 1
  %147 = icmp eq i64 %146, %50
  br i1 %147, label %148, label %140, !llvm.loop !183

148:                                              ; preds = %140, %127
  %149 = phi i32 [ %135, %127 ], [ %145, %140 ]
  %150 = sdiv i32 %149, %27
  br label %151

151:                                              ; preds = %148, %44
  %152 = phi i32 [ %47, %44 ], [ %150, %148 ]
  store i32 %152, i32* %30, align 4
  %153 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 10
  %154 = load i8, i8* %153, align 1, !range !5
  store i8 %154, i8* %31, align 4
  %155 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %155) #18
  %156 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 0
  %157 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 1
  %158 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 2
  %159 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 4
  %160 = bitcast i8* %159 to i32*
  store i32 -1431655766, i32* %160, align 4
  %161 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 1
  %162 = bitcast i32* %161 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %162, i8 0, i64 13, i1 false) #18
  store i32 1, i32* %156, align 4
  br i1 %18, label %163, label %165

163:                                              ; preds = %151
  %164 = load i32, i32* %23, align 4
  store i32 %164, i32* %158, align 4
  br label %169

165:                                              ; preds = %151
  %166 = load i32, i32* %25, align 4
  store i32 %166, i32* %158, align 4
  %167 = bitcast %union.anon* %19 to i32*
  %168 = icmp sgt i32 %16, 0
  br i1 %168, label %169, label %210

169:                                              ; preds = %163, %165
  %170 = phi i32* [ %21, %163 ], [ %167, %165 ]
  %171 = zext i32 %17 to i64
  %172 = zext i32 %16 to i64
  %173 = add nsw i64 %172, -1
  %174 = and i64 %172, 3
  %175 = icmp ult i64 %173, 3
  br i1 %175, label %191, label %176

176:                                              ; preds = %169
  %177 = sub nsw i64 %172, %174
  br label %178

178:                                              ; preds = %343, %176
  %179 = phi i64 [ 0, %176 ], [ %346, %343 ]
  %180 = phi i32 [ 1, %176 ], [ %345, %343 ]
  %181 = phi i64 [ %177, %176 ], [ %347, %343 ]
  %182 = icmp eq i64 %179, %171
  br i1 %182, label %186, label %183

183:                                              ; preds = %178
  %184 = getelementptr inbounds i32, i32* %170, i64 %179
  %185 = load i32, i32* %184, align 4
  br label %186

186:                                              ; preds = %183, %178
  %187 = phi i32 [ %185, %183 ], [ 1, %178 ]
  %188 = mul nsw i32 %187, %180
  %189 = or i64 %179, 1
  %190 = icmp eq i64 %189, %171
  br i1 %190, label %327, label %324

191:                                              ; preds = %343, %169
  %192 = phi i32 [ undef, %169 ], [ %345, %343 ]
  %193 = phi i64 [ 0, %169 ], [ %346, %343 ]
  %194 = phi i32 [ 1, %169 ], [ %345, %343 ]
  %195 = icmp eq i64 %174, 0
  br i1 %195, label %210, label %196

196:                                              ; preds = %191, %204
  %197 = phi i64 [ %207, %204 ], [ %193, %191 ]
  %198 = phi i32 [ %206, %204 ], [ %194, %191 ]
  %199 = phi i64 [ %208, %204 ], [ %174, %191 ]
  %200 = icmp eq i64 %197, %171
  br i1 %200, label %204, label %201

201:                                              ; preds = %196
  %202 = getelementptr inbounds i32, i32* %170, i64 %197
  %203 = load i32, i32* %202, align 4
  br label %204

204:                                              ; preds = %201, %196
  %205 = phi i32 [ %203, %201 ], [ 1, %196 ]
  %206 = mul nsw i32 %205, %198
  %207 = add nuw nsw i64 %197, 1
  %208 = add i64 %199, -1
  %209 = icmp eq i64 %208, 0
  br i1 %209, label %210, label %196, !llvm.loop !184

210:                                              ; preds = %191, %204, %165
  %211 = phi i32 [ 1, %165 ], [ %192, %191 ], [ %206, %204 ]
  store i32 %211, i32* %157, align 4
  %212 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 9
  %213 = load i8, i8* %212, align 4, !range !5
  store i8 %213, i8* %159, align 4
  %214 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %214) #18
  %215 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13, i64 0, i32 1
  %216 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13, i64 0, i32 2
  %217 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13, i64 0, i32 4
  %218 = bitcast i8* %217 to i32*
  store i32 -1431655766, i32* %218, align 4
  %219 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %220 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %220, i8 0, i64 17, i1 false)
  %221 = load i32, i32* %219, align 8
  %222 = add nsw i32 %221, -1
  %223 = icmp sgt i32 %221, 5
  %224 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  br i1 %223, label %225, label %231

225:                                              ; preds = %210
  %226 = getelementptr inbounds %union.anon, %union.anon* %224, i64 0, i32 0
  %227 = load i32*, i32** %226, align 8
  %228 = sext i32 %222 to i64
  %229 = getelementptr inbounds i32, i32* %227, i64 %228
  %230 = load i32, i32* %229, align 4
  store i32 %230, i32* %215, align 4
  br label %238

231:                                              ; preds = %210
  %232 = bitcast %union.anon* %224 to [5 x i32]*
  %233 = sext i32 %222 to i64
  %234 = getelementptr inbounds [5 x i32], [5 x i32]* %232, i64 0, i64 %233
  %235 = load i32, i32* %234, align 4
  store i32 %235, i32* %215, align 4
  %236 = bitcast %union.anon* %224 to i32*
  %237 = icmp sgt i32 %221, 0
  br i1 %237, label %238, label %279

238:                                              ; preds = %225, %231
  %239 = phi i32* [ %227, %225 ], [ %236, %231 ]
  %240 = zext i32 %222 to i64
  %241 = zext i32 %221 to i64
  %242 = add nsw i64 %241, -1
  %243 = and i64 %241, 3
  %244 = icmp ult i64 %242, 3
  br i1 %244, label %260, label %245

245:                                              ; preds = %238
  %246 = sub nsw i64 %241, %243
  br label %247

247:                                              ; preds = %318, %245
  %248 = phi i64 [ 0, %245 ], [ %321, %318 ]
  %249 = phi i32 [ 1, %245 ], [ %320, %318 ]
  %250 = phi i64 [ %246, %245 ], [ %322, %318 ]
  %251 = icmp eq i64 %248, %240
  br i1 %251, label %255, label %252

252:                                              ; preds = %247
  %253 = getelementptr inbounds i32, i32* %239, i64 %248
  %254 = load i32, i32* %253, align 4
  br label %255

255:                                              ; preds = %252, %247
  %256 = phi i32 [ %254, %252 ], [ 1, %247 ]
  %257 = mul nsw i32 %256, %249
  %258 = or i64 %248, 1
  %259 = icmp eq i64 %258, %240
  br i1 %259, label %302, label %299

260:                                              ; preds = %318, %238
  %261 = phi i32 [ undef, %238 ], [ %320, %318 ]
  %262 = phi i64 [ 0, %238 ], [ %321, %318 ]
  %263 = phi i32 [ 1, %238 ], [ %320, %318 ]
  %264 = icmp eq i64 %243, 0
  br i1 %264, label %279, label %265

265:                                              ; preds = %260, %273
  %266 = phi i64 [ %276, %273 ], [ %262, %260 ]
  %267 = phi i32 [ %275, %273 ], [ %263, %260 ]
  %268 = phi i64 [ %277, %273 ], [ %243, %260 ]
  %269 = icmp eq i64 %266, %240
  br i1 %269, label %273, label %270

270:                                              ; preds = %265
  %271 = getelementptr inbounds i32, i32* %239, i64 %266
  %272 = load i32, i32* %271, align 4
  br label %273

273:                                              ; preds = %270, %265
  %274 = phi i32 [ %272, %270 ], [ 1, %265 ]
  %275 = mul nsw i32 %274, %267
  %276 = add nuw nsw i64 %266, 1
  %277 = add i64 %268, -1
  %278 = icmp eq i64 %277, 0
  br i1 %278, label %279, label %265, !llvm.loop !185

279:                                              ; preds = %260, %273, %231
  %280 = phi i32 [ 1, %231 ], [ %261, %260 ], [ %275, %273 ]
  store i32 %280, i32* %216, align 4
  %281 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %281) #18
  %282 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %14, i64 0, i32 4
  %283 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %14, i64 0, i32 5
  %284 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %14, i64 0, i32 6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %281, i8 0, i64 24, i1 false) #18
  store float* %6, float** %282, align 8
  %285 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 7
  %286 = bitcast float* %285 to i32*
  %287 = load i32, i32* %286, align 4
  %288 = bitcast float* %283 to i32*
  store i32 %287, i32* %288, align 8
  %289 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 8
  %290 = bitcast float* %289 to i32*
  %291 = load i32, i32* %290, align 4
  %292 = bitcast float* %284 to i32*
  store i32 %291, i32* %292, align 4
  %293 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %9, i64 0, i32 4
  %294 = load i8, i8* %293, align 4, !range !5
  %295 = icmp eq i8 %294, 0
  br i1 %295, label %297, label %296

296:                                              ; preds = %279
  call void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIffffLNS0_18QuantizationFlavorE0EE3RunERKNS0_12MatrixParamsIfEEPKfS8_SA_S8_PfRKNS0_10GemmParamsIffLS3_0EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %12, float* %4, %"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %11, float* %2, %"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %13, float* %8, %"struct.tflite::cpu_backend_gemm::GemmParams"* nonnull dereferenceable(40) %14, %"class.tflite::CpuBackendContext"* %9) #18
  br label %298

297:                                              ; preds = %279
  call void @_ZN6tflite16cpu_backend_gemm6detail18GemmImplUsingEigen3RunERKNS0_12MatrixParamsIfEEPKfS6_S8_S6_PfRKNS0_10GemmParamsIffLNS0_18QuantizationFlavorE0EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %12, float* %4, %"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %11, float* %2, %"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %13, float* %8, %"struct.tflite::cpu_backend_gemm::GemmParams"* nonnull dereferenceable(40) %14, %"class.tflite::CpuBackendContext"* %9) #18
  br label %298

298:                                              ; preds = %296, %297
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %281) #18
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %214) #18
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %155) #18
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %28) #18
  ret void

299:                                              ; preds = %255
  %300 = getelementptr inbounds i32, i32* %239, i64 %258
  %301 = load i32, i32* %300, align 4
  br label %302

302:                                              ; preds = %299, %255
  %303 = phi i32 [ %301, %299 ], [ 1, %255 ]
  %304 = mul nsw i32 %303, %257
  %305 = or i64 %248, 2
  %306 = icmp eq i64 %305, %240
  br i1 %306, label %310, label %307

307:                                              ; preds = %302
  %308 = getelementptr inbounds i32, i32* %239, i64 %305
  %309 = load i32, i32* %308, align 4
  br label %310

310:                                              ; preds = %307, %302
  %311 = phi i32 [ %309, %307 ], [ 1, %302 ]
  %312 = mul nsw i32 %311, %304
  %313 = or i64 %248, 3
  %314 = icmp eq i64 %313, %240
  br i1 %314, label %318, label %315

315:                                              ; preds = %310
  %316 = getelementptr inbounds i32, i32* %239, i64 %313
  %317 = load i32, i32* %316, align 4
  br label %318

318:                                              ; preds = %315, %310
  %319 = phi i32 [ %317, %315 ], [ 1, %310 ]
  %320 = mul nsw i32 %319, %312
  %321 = add nuw nsw i64 %248, 4
  %322 = add i64 %250, -4
  %323 = icmp eq i64 %322, 0
  br i1 %323, label %260, label %247

324:                                              ; preds = %186
  %325 = getelementptr inbounds i32, i32* %170, i64 %189
  %326 = load i32, i32* %325, align 4
  br label %327

327:                                              ; preds = %324, %186
  %328 = phi i32 [ %326, %324 ], [ 1, %186 ]
  %329 = mul nsw i32 %328, %188
  %330 = or i64 %179, 2
  %331 = icmp eq i64 %330, %171
  br i1 %331, label %335, label %332

332:                                              ; preds = %327
  %333 = getelementptr inbounds i32, i32* %170, i64 %330
  %334 = load i32, i32* %333, align 4
  br label %335

335:                                              ; preds = %332, %327
  %336 = phi i32 [ %334, %332 ], [ 1, %327 ]
  %337 = mul nsw i32 %336, %329
  %338 = or i64 %179, 3
  %339 = icmp eq i64 %338, %171
  br i1 %339, label %343, label %340

340:                                              ; preds = %335
  %341 = getelementptr inbounds i32, i32* %170, i64 %338
  %342 = load i32, i32* %341, align 4
  br label %343

343:                                              ; preds = %340, %335
  %344 = phi i32 [ %342, %340 ], [ 1, %335 ]
  %345 = mul nsw i32 %344, %337
  %346 = add nuw nsw i64 %179, 4
  %347 = add i64 %181, -4
  %348 = icmp eq i64 %347, 0
  br i1 %348, label %191, label %178
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIffffLNS0_18QuantizationFlavorE0EE3RunERKNS0_12MatrixParamsIfEEPKfS8_SA_S8_PfRKNS0_10GemmParamsIffLS3_0EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::GemmParams"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"struct.ruy::Mat", align 8
  %10 = alloca %"struct.ruy::Mat", align 8
  %11 = alloca %"struct.ruy::Mat", align 8
  %12 = alloca %"class.ruy::MulParams", align 8
  %13 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 4
  %14 = load i8, i8* %13, align 4, !range !5
  %15 = icmp ne i8 %14, 0
  %16 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = icmp ne i32 %17, 0
  %19 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 2
  %22 = load i32, i32* %21, align 4
  %23 = select i1 %18, i32 %22, i32 %20
  %24 = ptrtoint float* %1 to i64
  %25 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 3
  %26 = bitcast float* %25 to i32*
  %27 = load i32, i32* %26, align 4
  br i1 %15, label %28, label %35

28:                                               ; preds = %8
  %29 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 4
  %30 = load i8, i8* %29, align 4
  %31 = icmp eq i8 %30, 1
  %32 = zext i1 %31 to i8
  %33 = icmp eq i8 %30, 2
  %34 = select i1 %33, i8 3, i8 %32
  br label %35

35:                                               ; preds = %8, %28
  %36 = phi i8 [ %34, %28 ], [ 0, %8 ]
  %37 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 0
  %38 = load i32, i32* %37, align 4
  %39 = icmp ne i32 %38, 0
  %40 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4
  %44 = select i1 %39, i32 %43, i32 %41
  %45 = ptrtoint float* %3 to i64
  %46 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 3
  %47 = bitcast float* %46 to i32*
  %48 = load i32, i32* %47, align 4
  br i1 %15, label %49, label %56

49:                                               ; preds = %35
  %50 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 4
  %51 = load i8, i8* %50, align 4
  %52 = icmp eq i8 %51, 1
  %53 = zext i1 %52 to i8
  %54 = icmp eq i8 %51, 2
  %55 = select i1 %54, i8 3, i8 %53
  br label %56

56:                                               ; preds = %35, %49
  %57 = phi i8 [ %55, %49 ], [ 0, %35 ]
  %58 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %4, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = icmp ne i32 %59, 0
  %61 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %4, i64 0, i32 1
  %62 = load i32, i32* %61, align 4
  %63 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %4, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = select i1 %60, i32 %64, i32 %62
  %66 = ptrtoint float* %5 to i64
  %67 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %4, i64 0, i32 3
  %68 = bitcast float* %67 to i32*
  %69 = load i32, i32* %68, align 4
  %70 = bitcast %"class.ruy::MulParams"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %70) #18
  %71 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 1
  %72 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 2
  %73 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 3
  %74 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 5
  %75 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 6
  %76 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams"* %6 to i32*
  %77 = load i32, i32* %76, align 8
  %78 = bitcast float* %71 to i32*
  store i32 %77, i32* %78, align 8
  %79 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 1
  %80 = load i32, i32* %79, align 4
  store i32 %80, i32* %72, align 4
  %81 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 2
  %82 = bitcast float** %81 to <2 x i64>*
  %83 = load <2 x i64>, <2 x i64>* %82, align 8
  %84 = bitcast float** %73 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %84, align 8
  %85 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 4
  %86 = bitcast float** %85 to i64*
  %87 = load i64, i64* %86, align 8
  %88 = bitcast %"class.ruy::MulParams"* %12 to i64*
  store i64 %87, i64* %88, align 8
  %89 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 5
  %90 = bitcast float* %89 to i32*
  %91 = load i32, i32* %90, align 8
  %92 = bitcast float* %74 to i32*
  store i32 %91, i32* %92, align 8
  %93 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 6
  %94 = bitcast float* %93 to i32*
  %95 = load i32, i32* %94, align 4
  %96 = bitcast float* %75 to i32*
  store i32 %95, i32* %96, align 4
  %97 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 1, i32 0, i32 0, i32 0
  %98 = load %"class.ruy::Context"*, %"class.ruy::Context"** %97, align 8
  %99 = bitcast %"struct.ruy::Mat"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %99) #18
  %100 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %9, i64 0, i32 1, i32 2
  %101 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %9, i64 0, i32 2
  %102 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %9, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %99, i8 -86, i64 24, i1 false) #18, !alias.scope !186
  %103 = bitcast i8* %102 to i32*
  store i32 -1431655936, i32* %103, align 4, !alias.scope !186
  %104 = bitcast %"struct.ruy::Mat"* %9 to i64*
  store i64 %24, i64* %104, align 8, !alias.scope !186
  %105 = zext i32 %23 to i64
  %106 = zext i1 %18 to i64
  %107 = shl nuw nsw i64 %106, 32
  %108 = or i64 %107, %105
  %109 = zext i32 %22 to i64
  %110 = shl nuw i64 %109, 32
  %111 = zext i32 %20 to i64
  %112 = or i64 %110, %111
  %113 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %9, i64 0, i32 1
  %114 = bitcast %"struct.ruy::MatLayout"* %113 to i64*
  store i64 %112, i64* %114, align 8, !alias.scope !186
  %115 = bitcast i32* %100 to i40*
  %116 = trunc i64 %108 to i40
  store i40 %116, i40* %115, align 8, !alias.scope !186
  %117 = bitcast float* %101 to i32*
  store i32 %27, i32* %117, align 8, !alias.scope !186
  store i8 %36, i8* %102, align 4, !alias.scope !186
  %118 = bitcast %"struct.ruy::Mat"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %118) #18
  %119 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %10, i64 0, i32 1, i32 2
  %120 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %10, i64 0, i32 2
  %121 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %10, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %118, i8 -86, i64 24, i1 false) #18, !alias.scope !189
  %122 = bitcast i8* %121 to i32*
  store i32 -1431655936, i32* %122, align 4, !alias.scope !189
  %123 = bitcast %"struct.ruy::Mat"* %10 to i64*
  store i64 %45, i64* %123, align 8, !alias.scope !189
  %124 = zext i32 %44 to i64
  %125 = zext i1 %39 to i64
  %126 = shl nuw nsw i64 %125, 32
  %127 = or i64 %126, %124
  %128 = zext i32 %43 to i64
  %129 = shl nuw i64 %128, 32
  %130 = zext i32 %41 to i64
  %131 = or i64 %129, %130
  %132 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %10, i64 0, i32 1
  %133 = bitcast %"struct.ruy::MatLayout"* %132 to i64*
  store i64 %131, i64* %133, align 8, !alias.scope !189
  %134 = bitcast i32* %119 to i40*
  %135 = trunc i64 %127 to i40
  store i40 %135, i40* %134, align 8, !alias.scope !189
  %136 = bitcast float* %120 to i32*
  store i32 %48, i32* %136, align 8, !alias.scope !189
  store i8 %57, i8* %121, align 4, !alias.scope !189
  %137 = bitcast %"struct.ruy::Mat"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %137) #18
  %138 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %11, i64 0, i32 1, i32 2
  %139 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %11, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %11, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 -86, i64 24, i1 false) #18, !alias.scope !192
  %141 = bitcast i8* %140 to i32*
  store i32 -1431655936, i32* %141, align 4, !alias.scope !192
  %142 = bitcast %"struct.ruy::Mat"* %11 to i64*
  store i64 %66, i64* %142, align 8, !alias.scope !192
  %143 = zext i32 %65 to i64
  %144 = zext i1 %60 to i64
  %145 = shl nuw nsw i64 %144, 32
  %146 = or i64 %145, %143
  %147 = zext i32 %64 to i64
  %148 = shl nuw i64 %147, 32
  %149 = zext i32 %62 to i64
  %150 = or i64 %148, %149
  %151 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %11, i64 0, i32 1
  %152 = bitcast %"struct.ruy::MatLayout"* %151 to i64*
  store i64 %150, i64* %152, align 8, !alias.scope !192
  %153 = bitcast i32* %138 to i40*
  %154 = trunc i64 %146 to i40
  store i40 %154, i40* %153, align 8, !alias.scope !192
  %155 = bitcast float* %139 to i32*
  store i32 %69, i32* %155, align 8, !alias.scope !192
  %156 = tail call %"class.ruy::Ctx"* @_ZN3ruy7get_ctxEPNS_7ContextE(%"class.ruy::Context"* %98) #18
  call void @_ZN3ruy11DispatchMulILNS_4PathE26EfffNS_9MulParamsIffEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat"* nonnull dereferenceable(32) %9, %"struct.ruy::Mat"* nonnull dereferenceable(32) %10, %"class.ruy::MulParams"* nonnull dereferenceable(40) %12, %"class.ruy::Ctx"* %156, %"struct.ruy::Mat"* nonnull %11) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %137) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %118) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %99) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %70) #18
  ret void
}

declare void @_ZN6tflite16cpu_backend_gemm6detail18GemmImplUsingEigen3RunERKNS0_12MatrixParamsIfEEPKfS6_S8_S6_PfRKNS0_10GemmParamsIffLNS0_18QuantizationFlavorE0EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::GemmParams"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy11DispatchMulILNS_4PathE26EfffNS_9MulParamsIffEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat"* dereferenceable(32), %"struct.ruy::Mat"* dereferenceable(32), %"class.ruy::MulParams"* dereferenceable(40), %"class.ruy::Ctx"*, %"struct.ruy::Mat"*) local_unnamed_addr #1 comdat {
  %6 = alloca %"struct.ruy::TrMulParams", align 8
  %7 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 1, i32 1
  %8 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 2
  %9 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 2
  %10 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %4, i64 0, i32 2
  %11 = tail call zeroext i8 @_ZN3ruy3Ctx10SelectPathENS_4PathE(%"class.ruy::Ctx"* %3, i8 zeroext 26) #18
  %12 = bitcast %"struct.ruy::Mat"* %0 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 1, i32 0
  %15 = load i32, i32* %14, align 8
  %16 = load i32, i32* %7, align 4
  %17 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 1, i32 2
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 1, i32 3
  %20 = load i8, i8* %19, align 4
  %21 = load float, float* %8, align 8
  %22 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 3
  %23 = load i8, i8* %22, align 4
  %24 = icmp eq i8 %20, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 280, i8* nonnull %26) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %26, i8 -86, i64 272, i1 false)
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 2
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 4
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 5
  %31 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 2
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 0, i32* %32, align 8
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 5
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 0
  store i8 0, i8* %34, align 8
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 1
  store i8 0, i8* %35, align 1
  %36 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 2
  store i8 0, i8* %36, align 2
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 2
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 4
  store i32 0, i32* %38, align 8
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 5
  store i8 0, i8* %39, align 4
  %40 = bitcast i8** %37 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %40, i8 0, i64 21, i1 false) #18
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 0
  store i8 0, i8* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 1
  store i8 0, i8* %42, align 1
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 2
  store i8 0, i8* %43, align 2
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 2
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 5
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  %47 = bitcast i8** %44 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %47, i8 0, i64 11, i1 false) #18
  %48 = bitcast i8** %45 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %48, i8 0, i64 22, i1 false) #18
  %49 = bitcast %"class.ruy::SidePair"* %27 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %49, i8 0, i64 24, i1 false) #18
  store i8 1, i8* %46, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 0, i32* %51, align 8
  %52 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %52, align 8
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %53, align 1
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %54, align 2
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 2
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 5
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  %58 = bitcast i8** %55 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %58, i8 0, i64 11, i1 false) #18
  %59 = bitcast i8** %56 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %59, i8 0, i64 22, i1 false) #18
  store i8 1, i8* %57, align 1
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %60, align 1
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 0, i32* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 6, i32 0, i64 0
  store i8 0, i8* %62, align 8
  %63 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 6, i32 0, i64 1
  store i8 0, i8* %63, align 1
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 7
  %65 = fptosi float %21 to i32
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3
  %67 = bitcast %"class.ruy::SidePair.130"* %66 to i24*
  store i24 262401, i24* %67, align 8
  %68 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %68, i8 -86, i64 5, i1 false) #18
  %69 = bitcast i8** %28 to i64*
  store i64 %13, i64* %69, align 8
  %70 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  store i32 %16, i32* %70, align 8
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  store i32 %15, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 2
  store i32 %18, i32* %72, align 8
  %73 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  store i8 %25, i8* %73, align 4
  %74 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %74, i8 -86, i64 3, i1 false) #18
  store i32 %65, i32* %29, align 8
  store i8 %23, i8* %30, align 4
  %75 = bitcast %"struct.ruy::Mat"* %1 to i64*
  %76 = load i64, i64* %75, align 8, !noalias !195
  %77 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1
  %78 = bitcast %"struct.ruy::MatLayout"* %77 to i8*
  %79 = load float, float* %9, align 8, !noalias !195
  %80 = fptosi float %79 to i32
  %81 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 3
  %82 = load i8, i8* %81, align 4, !noalias !195
  %83 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1
  %84 = bitcast %"struct.ruy::EMat"* %83 to i24*
  store i24 262401, i24* %84, align 8
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %85, i8 -86, i64 5, i1 false) #18
  %86 = bitcast i8** %31 to i64*
  store i64 %76, i64* %86, align 8
  %87 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3
  %88 = bitcast %"struct.ruy::MatLayout"* %87 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %88, i8* align 4 %78, i64 13, i1 false)
  %89 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %89, i8 -86, i64 3, i1 false) #18
  store i32 %80, i32* %32, align 8
  store i8 %82, i8* %33, align 4
  %90 = bitcast %"struct.ruy::Mat"* %4 to i64*
  %91 = load i64, i64* %90, align 8, !noalias !198
  %92 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %4, i64 0, i32 1
  %93 = bitcast %"struct.ruy::MatLayout"* %92 to i8*
  %94 = load float, float* %10, align 8, !noalias !198
  %95 = fptosi float %94 to i32
  %96 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %4, i64 0, i32 3
  %97 = load i8, i8* %96, align 4, !noalias !198
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4
  %99 = bitcast %"struct.ruy::EMat"* %98 to i24*
  store i24 262401, i24* %99, align 8
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %100, i8 -86, i64 5, i1 false) #18
  %101 = bitcast i8** %37 to i64*
  store i64 %91, i64* %101, align 8
  %102 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3
  %103 = bitcast %"struct.ruy::MatLayout"* %102 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %103, i8* align 4 %93, i64 13, i1 false)
  %104 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %104, i8 -86, i64 3, i1 false) #18
  store i32 %95, i32* %38, align 8
  store i8 %97, i8* %39, align 4
  %105 = bitcast i8** %64 to %"class.ruy::MulParams"**
  store %"class.ruy::MulParams"* %2, %"class.ruy::MulParams"** %105, align 8
  %106 = icmp eq i8 %11, 16
  br i1 %106, label %107, label %196

107:                                              ; preds = %5
  br i1 %24, label %116, label %108

108:                                              ; preds = %107
  %109 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %110 = load i8, i8* %109, align 4
  %111 = icmp eq i8 %110, 0
  br i1 %111, label %112, label %116

112:                                              ; preds = %108
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3, i32 3
  %114 = load i8, i8* %113, align 4
  %115 = icmp eq i8 %114, 0
  br i1 %115, label %154, label %116

116:                                              ; preds = %107, %112, %108
  store i8 2, i8* %26, align 8
  %117 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0
  %118 = bitcast %"struct.ruy::PEMat"* %117 to i24*
  store i24 262401, i24* %118, align 8
  %119 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 3
  %120 = bitcast %"struct.ruy::Type"* %119 to i24*
  store i24 262401, i24* %120, align 8
  %121 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %121, align 4
  %122 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %16, i32* %122, align 8
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %15, i32* %123, align 4
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %124, align 1
  store i8 1, i8* %46, align 1
  store i8 1, i8* %50, align 1
  %125 = and i32 %16, 255
  %126 = icmp eq i32 %125, 0
  %127 = add nsw i32 %16, 64
  %128 = select i1 %126, i32 %127, i32 %16
  %129 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %128, i32* %129, align 8
  %130 = sitofp i32 %65 to float
  %131 = fptosi float %130 to i32
  store i32 %131, i32* %51, align 8
  %132 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1
  %133 = bitcast %"struct.ruy::PEMat"* %132 to i24*
  store i24 262401, i24* %133, align 8
  %134 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 3
  %135 = bitcast %"struct.ruy::Type"* %134 to i24*
  store i24 262401, i24* %135, align 8
  %136 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %138 = load i32, i32* %137, align 8
  %139 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %138, i32* %139, align 8
  %140 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %141 = load i32, i32* %140, align 4
  %142 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %141, i32* %142, align 4
  %143 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %143, align 1
  store i8 1, i8* %57, align 1
  store i8 1, i8* %60, align 1
  %144 = and i32 %138, 255
  %145 = icmp eq i32 %144, 0
  %146 = add nsw i32 %138, 64
  %147 = select i1 %145, i32 %146, i32 %138
  %148 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %147, i32* %148, align 8
  %149 = sitofp i32 %80 to float
  %150 = fptosi float %149 to i32
  store i32 %150, i32* %61, align 8
  %151 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1, i32 0, i64 0
  %152 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %151 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %152, align 8
  %153 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)** %153, align 8
  br label %197

154:                                              ; preds = %112
  store i8 16, i8* %26, align 8
  %155 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0
  %156 = bitcast %"struct.ruy::PEMat"* %155 to i24*
  store i24 262401, i24* %156, align 8
  %157 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 3
  %158 = bitcast %"struct.ruy::Type"* %157 to i24*
  store i24 262401, i24* %158, align 8
  %159 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %159, align 4
  %160 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %16, i32* %160, align 8
  %161 = add i32 %15, 15
  %162 = and i32 %161, -16
  %163 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %162, i32* %163, align 4
  %164 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 1, i8* %164, align 1
  store i8 1, i8* %46, align 1
  store i8 16, i8* %50, align 1
  %165 = and i32 %16, 255
  %166 = icmp eq i32 %165, 0
  %167 = add nsw i32 %16, 64
  %168 = select i1 %166, i32 %167, i32 %16
  %169 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %168, i32* %169, align 8
  %170 = sitofp i32 %65 to float
  %171 = fptosi float %170 to i32
  store i32 %171, i32* %51, align 8
  %172 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1
  %173 = bitcast %"struct.ruy::PEMat"* %172 to i24*
  store i24 262401, i24* %173, align 8
  %174 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 3
  %175 = bitcast %"struct.ruy::Type"* %174 to i24*
  store i24 262401, i24* %175, align 8
  %176 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %176, align 4
  %177 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %178 = load i32, i32* %177, align 8
  %179 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %178, i32* %179, align 8
  %180 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %181 = load i32, i32* %180, align 4
  %182 = add i32 %181, 15
  %183 = and i32 %182, -16
  %184 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %183, i32* %184, align 4
  %185 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 1, i8* %185, align 1
  store i8 1, i8* %57, align 1
  store i8 16, i8* %60, align 1
  %186 = and i32 %178, 255
  %187 = icmp eq i32 %186, 0
  %188 = add nsw i32 %178, 64
  %189 = select i1 %187, i32 %188, i32 %178
  %190 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %189, i32* %190, align 8
  %191 = sitofp i32 %80 to float
  %192 = fptosi float %191 to i32
  store i32 %192, i32* %61, align 8
  %193 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1, i32 0, i64 0
  %194 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %193 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %194, align 8
  %195 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE16EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)** %195, align 8
  br label %197

196:                                              ; preds = %5
  call void @_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EfffNS_9MulParamsIffEEE6SearchES1_PNS_11TrMulParamsE(i8 zeroext %11, %"struct.ruy::TrMulParams"* nonnull %6) #18
  br label %197

197:                                              ; preds = %154, %116, %196
  call void @_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %6, %"class.ruy::Ctx"* %3)
  call void @_ZN3ruy5TrMulEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %6, %"class.ruy::Ctx"* %3) #18
  call void @llvm.lifetime.end.p0i8(i64 280, i8* nonnull %26) #18
  ret void
}

declare %"class.ruy::Ctx"* @_ZN3ruy7get_ctxEPNS_7ContextE(%"class.ruy::Context"*) local_unnamed_addr #3

declare zeroext i8 @_ZN3ruy3Ctx10SelectPathENS_4PathE(%"class.ruy::Ctx"*, i8 zeroext) local_unnamed_addr #3

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"*, %"class.ruy::Ctx"*) local_unnamed_addr #5 comdat {
  %3 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 5
  %4 = load i8, i8* %3, align 4
  %5 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %6 = load i32, i32* %5, align 4
  %7 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  switch i8 %4, label %31 [
    i8 2, label %10
    i8 3, label %15
    i8 1, label %13
  ]

10:                                               ; preds = %2
  %11 = shl nuw nsw i32 %9, 2
  %12 = icmp sgt i32 %6, %11
  br i1 %12, label %31, label %15

13:                                               ; preds = %2
  %14 = icmp sgt i32 %6, %9
  br i1 %14, label %31, label %15

15:                                               ; preds = %10, %13, %2
  %16 = tail call %"class.ruy::PrepackedCache"* @_ZN3ruy3Ctx17GetPrepackedCacheEv(%"class.ruy::Ctx"* %1) #18
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 2
  %18 = load i8*, i8** %17, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %20 = tail call i32 @_ZN3ruy14PrepackedCache3GetEPKvPNS_5PEMatE(%"class.ruy::PrepackedCache"* %16, i8* %18, %"struct.ruy::PEMat"* %19) #18
  %21 = icmp eq i32 %20, 1
  br i1 %21, label %22, label %29

22:                                               ; preds = %15
  %23 = tail call i32 @_ZN3ruy3Ctx19GetMainThreadTuningEv(%"class.ruy::Ctx"* %1) #18
  %24 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  %27 = load void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %26, align 8
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0
  tail call void %27(i32 %23, %"struct.ruy::EMat"* dereferenceable(40) %28, %"struct.ruy::PEMat"* %19, i32 0, i32 %25) #18
  br label %29

29:                                               ; preds = %22, %15
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 6, i32 0, i64 0
  store i8 1, i8* %30, align 1
  br label %31

31:                                               ; preds = %10, %13, %2, %29
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 5
  %33 = load i8, i8* %32, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  switch i8 %33, label %60 [
    i8 2, label %41
    i8 3, label %44
    i8 1, label %39
  ]

39:                                               ; preds = %31
  %40 = icmp sgt i32 %35, %38
  br i1 %40, label %60, label %44

41:                                               ; preds = %31
  %42 = shl nuw nsw i32 %38, 2
  %43 = icmp sgt i32 %35, %42
  br i1 %43, label %60, label %44

44:                                               ; preds = %41, %39, %31
  %45 = tail call %"class.ruy::PrepackedCache"* @_ZN3ruy3Ctx17GetPrepackedCacheEv(%"class.ruy::Ctx"* %1) #18
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 2
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %49 = tail call i32 @_ZN3ruy14PrepackedCache3GetEPKvPNS_5PEMatE(%"class.ruy::PrepackedCache"* %45, i8* %47, %"struct.ruy::PEMat"* %48) #18
  %50 = icmp eq i32 %49, 1
  br i1 %50, label %51, label %58

51:                                               ; preds = %44
  %52 = tail call i32 @_ZN3ruy3Ctx19GetMainThreadTuningEv(%"class.ruy::Ctx"* %1) #18
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  %54 = load i32, i32* %53, align 4
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  %56 = load void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %55, align 8
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1
  tail call void %56(i32 %52, %"struct.ruy::EMat"* dereferenceable(40) %57, %"struct.ruy::PEMat"* %48, i32 0, i32 %54) #18
  br label %58

58:                                               ; preds = %51, %44
  %59 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 6, i32 0, i64 1
  store i8 1, i8* %59, align 1
  br label %60

60:                                               ; preds = %58, %41, %39, %31
  ret void
}

declare void @_ZN3ruy5TrMulEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"*, %"class.ruy::Ctx"*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %7 = bitcast i8** %6 to float**
  %8 = load float*, float** %7, align 8, !noalias !201
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %14 = bitcast i8** %13 to float**
  %15 = load float*, float** %14, align 8, !noalias !204
  %16 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = icmp slt i32 %3, %4
  br i1 %18, label %19, label %38

19:                                               ; preds = %5
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = sext i32 %3 to i64
  %23 = sext i32 %4 to i64
  %24 = sext i32 %12 to i64
  br label %25

25:                                               ; preds = %19, %25
  %26 = phi i64 [ %22, %19 ], [ %36, %25 ]
  %27 = mul nsw i64 %26, %24
  %28 = getelementptr inbounds float, float* %8, i64 %27
  %29 = trunc i64 %26 to i32
  %30 = and i32 %29, -16
  %31 = mul nsw i32 %30, %17
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds float, float* %15, i64 %32
  %34 = trunc i64 %26 to i32
  %35 = sub i32 %21, %34
  tail call void @_ZN3ruy15PackFloatAvx512EPKfS1_iiiPf(float* %28, float* getelementptr inbounds ([16 x float], [16 x float]* @_ZZN3ruy8PackImplILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEiiE7zerobuf, i64 0, i64 0), i32 %12, i32 %35, i32 %10, float* %33) #18
  %36 = add i64 %26, 16
  %37 = icmp slt i64 %36, %23
  br i1 %37, label %25, label %38

38:                                               ; preds = %25, %5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE16EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.128"* dereferenceable(112), i8*, %"class.ruy::SidePair.129"* dereferenceable(8), %"class.ruy::SidePair.129"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParamsFloat", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = bitcast i8** %8 to float**
  %10 = load float*, float** %9, align 8, !noalias !207
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 2
  %18 = bitcast i8** %17 to float**
  %19 = load float*, float** %18, align 8, !noalias !210
  %20 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 2
  %25 = bitcast i8** %24 to float**
  %26 = load float*, float** %25, align 8, !noalias !213
  %27 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 0
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 1
  %32 = load i32, i32* %31, align 4
  %33 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 0
  %34 = load i32, i32* %33, align 4
  %35 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 1
  %36 = load i32, i32* %35, align 4
  %37 = bitcast %"struct.ruy::KernelParamsFloat"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1176, i8* nonnull %37) #18
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %37, i8* align 8 bitcast (%"struct.ruy::KernelParamsFloat"* @__const._ZNK3ruy6KernelILNS_4PathE16EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE.params to i8*), i64 1176, i1 false) #18
  %38 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 18, i64 0
  %39 = bitcast float* %38 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %39, i8 0, i64 64, i1 false) #18
  %40 = mul nsw i32 %30, %23
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds float, float* %19, i64 %41
  %43 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 0
  store float* %42, float** %43, align 8
  %44 = mul nsw i32 %32, %28
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %26, i64 %45
  %47 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 1
  store float* %46, float** %47, align 8
  %48 = mul nsw i32 %32, %16
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %10, i64 %49
  %51 = sext i32 %30 to i64
  %52 = getelementptr inbounds float, float* %50, i64 %51
  %53 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 2
  store float* %52, float** %53, align 8
  %54 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 3
  %55 = bitcast i8* %2 to float**
  %56 = load float*, float** %55, align 8
  %57 = icmp eq float* %56, null
  %58 = select i1 %57, float* %38, float* %56
  store float* %58, float** %54, align 8
  %59 = xor i1 %57, true
  %60 = zext i1 %59 to i8
  %61 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 16
  store i8 %60, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 4
  store i32 %30, i32* %62, align 8
  %63 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 5
  store i32 %32, i32* %63, align 4
  %64 = add nsw i32 %34, -16
  %65 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 6
  store i32 %64, i32* %65, align 8
  %66 = add nsw i32 %36, -16
  %67 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 7
  store i32 %66, i32* %67, align 4
  %68 = shl i32 %23, 2
  %69 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 10
  store i32 %68, i32* %69, align 8
  %70 = shl i32 %28, 2
  %71 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 11
  store i32 %70, i32* %71, align 4
  %72 = shl i32 %16, 2
  %73 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 12
  store i32 %72, i32* %73, align 8
  %74 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 13
  store i32 %21, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %2, i64 32
  %76 = bitcast i8* %75 to i32*
  %77 = load i32, i32* %76, align 8
  %78 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 14
  %79 = bitcast float* %78 to i32*
  store i32 %77, i32* %79, align 8
  %80 = getelementptr inbounds i8, i8* %2, i64 36
  %81 = bitcast i8* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 15
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 8
  store i32 %12, i32* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 9
  store i32 %14, i32* %86, align 4
  %87 = icmp eq i32 %14, 1
  br i1 %87, label %88, label %89

88:                                               ; preds = %6
  call void @_ZN3ruy26KernelFloatAvx512SingleColERKNS_17KernelParamsFloatILi16ELi16EEE(%"struct.ruy::KernelParamsFloat"* nonnull dereferenceable(1176) %7) #18
  br label %90

89:                                               ; preds = %6
  call void @_ZN3ruy17KernelFloatAvx512ERKNS_17KernelParamsFloatILi16ELi16EEE(%"struct.ruy::KernelParamsFloat"* nonnull dereferenceable(1176) %7) #18
  br label %90

90:                                               ; preds = %88, %89
  call void @llvm.lifetime.end.p0i8(i64 1176, i8* nonnull %37) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca %"struct.ruy::Mat", align 8
  %7 = alloca %"struct.ruy::PMat", align 8
  %8 = bitcast %"struct.ruy::Mat"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #18
  %9 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %6, i64 0, i32 2
  %10 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %6, i64 0, i32 3
  %11 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %6, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %8, i8 -86, i64 24, i1 false) #18, !alias.scope !216
  %12 = bitcast i8* %10 to i32*
  store i32 -1431655936, i32* %12, align 4, !alias.scope !216
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %14 = bitcast i8** %13 to i64*
  %15 = load i64, i64* %14, align 8, !noalias !216
  %16 = bitcast %"struct.ruy::Mat"* %6 to i64*
  store i64 %15, i64* %16, align 8, !alias.scope !216
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3
  %18 = bitcast %"struct.ruy::MatLayout"* %11 to i8*
  %19 = bitcast %"struct.ruy::MatLayout"* %17 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %18, i8* align 4 %19, i64 13, i1 false) #18
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 4
  %21 = load i32, i32* %20, align 8, !noalias !216
  %22 = sitofp i32 %21 to float
  store float %22, float* %9, align 8, !alias.scope !216
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 5
  %24 = load i8, i8* %23, align 4, !noalias !216
  store i8 %24, i8* %10, align 4, !alias.scope !216
  %25 = bitcast %"struct.ruy::PMat"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %25) #18
  %26 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %7, i64 0, i32 3
  %27 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %28 = bitcast i8** %27 to i64*
  %29 = bitcast %"struct.ruy::PMat"* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %29, i8 -86, i64 40, i1 false)
  %30 = load i64, i64* %28, align 8, !noalias !219
  %31 = bitcast %"struct.ruy::PMat"* %7 to i64*
  store i64 %30, i64* %31, align 8, !alias.scope !219
  %32 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %33 = bitcast i8** %32 to i64*
  %34 = load i64, i64* %33, align 8, !noalias !219
  %35 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %7, i64 0, i32 1
  %36 = bitcast float** %35 to i64*
  store i64 %34, i64* %36, align 8, !alias.scope !219
  %37 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6
  %38 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %7, i64 0, i32 2
  %39 = bitcast %"struct.ruy::PMatLayout"* %38 to i8*
  %40 = bitcast %"struct.ruy::PMatLayout"* %37 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %39, i8* align 4 %40, i64 16, i1 false) #18
  %41 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %42 = load i32, i32* %41, align 8, !noalias !219
  store i32 %42, i32* %26, align 8, !alias.scope !219
  call void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEii(i32 %0, %"struct.ruy::Mat"* nonnull dereferenceable(32) %6, %"struct.ruy::PMat"* nonnull %7, i32 %3, i32 %4)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %25) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.128"* dereferenceable(112), i8*, %"class.ruy::SidePair.129"* dereferenceable(8), %"class.ruy::SidePair.129"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::Kernel", align 1
  %8 = alloca %"struct.ruy::Mat", align 8
  %9 = alloca %"struct.ruy::PMat", align 8
  %10 = alloca %"struct.ruy::PMat", align 8
  %11 = bitcast %"struct.ruy::Mat"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #18
  %12 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 2
  %13 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %11, i8 -86, i64 24, i1 false) #18, !alias.scope !222
  %15 = bitcast i8* %13 to i32*
  store i32 -1431655936, i32* %15, align 4, !alias.scope !222
  %16 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %17 = bitcast i8** %16 to i64*
  %18 = load i64, i64* %17, align 8, !noalias !222
  %19 = bitcast %"struct.ruy::Mat"* %8 to i64*
  store i64 %18, i64* %19, align 8, !alias.scope !222
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3
  %21 = bitcast %"struct.ruy::MatLayout"* %14 to i8*
  %22 = bitcast %"struct.ruy::MatLayout"* %20 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %21, i8* align 4 %22, i64 13, i1 false) #18
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %24 = load i32, i32* %23, align 8, !noalias !222
  %25 = sitofp i32 %24 to float
  store float %25, float* %12, align 8, !alias.scope !222
  %26 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 5
  %27 = load i8, i8* %26, align 4, !noalias !222
  store i8 %27, i8* %13, align 4, !alias.scope !222
  %28 = bitcast %"struct.ruy::PMat"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %28) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 40, i1 false) #18, !alias.scope !225
  %29 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %9, i64 0, i32 3
  %30 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 2
  %31 = bitcast i8** %30 to i64*
  %32 = load i64, i64* %31, align 8, !noalias !225
  %33 = bitcast %"struct.ruy::PMat"* %9 to i64*
  store i64 %32, i64* %33, align 8, !alias.scope !225
  %34 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 5
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !225
  %37 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %9, i64 0, i32 1
  %38 = bitcast float** %37 to i64*
  store i64 %36, i64* %38, align 8, !alias.scope !225
  %39 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6
  %40 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %9, i64 0, i32 2
  %41 = bitcast %"struct.ruy::PMatLayout"* %40 to i8*
  %42 = bitcast %"struct.ruy::PMatLayout"* %39 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %41, i8* align 4 %42, i64 16, i1 false) #18
  %43 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 7
  %44 = load i32, i32* %43, align 8, !noalias !225
  store i32 %44, i32* %29, align 8, !alias.scope !225
  %45 = bitcast %"struct.ruy::PMat"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %45) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %45, i8 -86, i64 40, i1 false) #18, !alias.scope !228
  %46 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %10, i64 0, i32 3
  %47 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 2
  %48 = bitcast i8** %47 to i64*
  %49 = load i64, i64* %48, align 8, !noalias !228
  %50 = bitcast %"struct.ruy::PMat"* %10 to i64*
  store i64 %49, i64* %50, align 8, !alias.scope !228
  %51 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 5
  %52 = bitcast i8** %51 to i64*
  %53 = load i64, i64* %52, align 8, !noalias !228
  %54 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %10, i64 0, i32 1
  %55 = bitcast float** %54 to i64*
  store i64 %53, i64* %55, align 8, !alias.scope !228
  %56 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 6
  %57 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %10, i64 0, i32 2
  %58 = bitcast %"struct.ruy::PMatLayout"* %57 to i8*
  %59 = bitcast %"struct.ruy::PMatLayout"* %56 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %58, i8* align 4 %59, i64 16, i1 false) #18
  %60 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 7
  %61 = load i32, i32* %60, align 8, !noalias !228
  store i32 %61, i32* %46, align 8, !alias.scope !228
  %62 = bitcast i8* %2 to %"class.ruy::MulParams"*
  %63 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 0
  %64 = load i32, i32* %63, align 4
  %65 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 0
  %68 = load i32, i32* %67, align 4
  %69 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 1
  %70 = load i32, i32* %69, align 4
  %71 = getelementptr inbounds %"struct.ruy::Kernel", %"struct.ruy::Kernel"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %71) #18
  store i8 -86, i8* %71, align 1
  call void @_ZNK3ruy6KernelILNS_4PathE2EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE(%"struct.ruy::Kernel"* nonnull %7, %"struct.ruy::PMat"* nonnull dereferenceable(40) %9, %"struct.ruy::PMat"* nonnull dereferenceable(40) %10, %"class.ruy::MulParams"* dereferenceable(40) %62, i32 %64, i32 %66, i32 %68, i32 %70, %"struct.ruy::Mat"* nonnull %8) #18
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %71) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %45) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %28) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEii(i32, %"struct.ruy::Mat"* dereferenceable(32), %"struct.ruy::PMat"*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 1
  %7 = load float*, float** %6, align 8
  %8 = icmp slt i32 %3, %4
  br i1 %8, label %9, label %33

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 0
  %11 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1, i32 1
  %12 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1, i32 0
  %13 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 0, i32 0
  %15 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1, i32 3
  %16 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1, i32 2
  %17 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 0
  %18 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 1
  %19 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 2
  %20 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 3
  %21 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 2
  %22 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 0
  %23 = icmp eq float* %7, null
  %24 = sext i32 %3 to i64
  %25 = sext i32 %4 to i64
  br label %26

26:                                               ; preds = %107, %9
  %27 = phi i64 [ %24, %9 ], [ %108, %107 ]
  %28 = load i32, i32* %10, align 8
  %29 = icmp sgt i32 %28, 0
  br i1 %29, label %30, label %34

30:                                               ; preds = %26
  %31 = trunc i64 %27 to i32
  %32 = trunc i64 %27 to i32
  br label %36

33:                                               ; preds = %107, %5
  ret void

34:                                               ; preds = %65, %26
  %35 = phi float [ 0.000000e+00, %26 ], [ %68, %65 ]
  br i1 %23, label %107, label %105

36:                                               ; preds = %30, %65
  %37 = phi i32 [ %102, %65 ], [ 0, %30 ]
  %38 = phi float [ %68, %65 ], [ 0.000000e+00, %30 ]
  %39 = load i32, i32* %11, align 4
  %40 = sext i32 %39 to i64
  %41 = icmp slt i64 %27, %40
  br i1 %41, label %42, label %62

42:                                               ; preds = %36
  %43 = load i32, i32* %12, align 8
  %44 = icmp slt i32 %37, %43
  br i1 %44, label %45, label %62

45:                                               ; preds = %42
  %46 = load float*, float** %14, align 8
  %47 = load i8, i8* %15, align 4
  %48 = load i32, i32* %16, align 4
  switch i8 %47, label %49 [
    i8 0, label %50
    i8 1, label %52
  ]

49:                                               ; preds = %45
  br label %50

50:                                               ; preds = %49, %45
  %51 = phi i32 [ 1, %45 ], [ %48, %49 ]
  br label %52

52:                                               ; preds = %45, %50
  %53 = phi i32 [ %51, %50 ], [ %48, %45 ]
  %54 = phi i32 [ %48, %50 ], [ 1, %45 ]
  %55 = mul nsw i32 %53, %37
  %56 = mul nsw i32 %54, %32
  %57 = add nsw i32 %56, %55
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds float, float* %46, i64 %58
  %60 = load float, float* %59, align 4
  %61 = fadd float %60, 0.000000e+00
  br label %65

62:                                               ; preds = %42, %36
  %63 = load i32, i32* %13, align 8
  %64 = sitofp i32 %63 to float
  br label %65

65:                                               ; preds = %62, %52
  %66 = phi i32 [ %31, %62 ], [ %32, %52 ]
  %67 = phi float [ %64, %62 ], [ %61, %52 ]
  %68 = fadd float %38, %67
  %69 = load float*, float** %17, align 8
  %70 = load i8, i8* %18, align 1
  %71 = zext i8 %70 to i32
  %72 = sub nsw i32 0, %71
  %73 = and i32 %37, %72
  %74 = load i8, i8* %19, align 1
  %75 = zext i8 %74 to i32
  %76 = sub nsw i32 0, %75
  %77 = and i32 %66, %76
  %78 = load i8, i8* %20, align 4
  %79 = icmp eq i8 %78, 0
  %80 = load i32, i32* %21, align 4
  %81 = select i1 %79, i32 %75, i32 %80
  %82 = icmp eq i8 %78, 1
  %83 = select i1 %82, i32 %71, i32 %80
  %84 = mul nsw i32 %81, %73
  %85 = mul nsw i32 %83, %77
  %86 = sub nsw i32 %37, %73
  %87 = sub nsw i32 %66, %77
  %88 = load i8, i8* %22, align 1
  %89 = icmp eq i8 %88, 0
  %90 = select i1 %89, i8 1, i8 %74
  %91 = zext i8 %90 to i32
  %92 = icmp eq i8 %88, 1
  %93 = select i1 %92, i8 1, i8 %70
  %94 = zext i8 %93 to i32
  %95 = mul nsw i32 %86, %91
  %96 = mul nsw i32 %87, %94
  %97 = add i32 %84, %85
  %98 = add i32 %97, %96
  %99 = add i32 %98, %95
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds float, float* %69, i64 %100
  store float %67, float* %101, align 4
  %102 = add nuw nsw i32 %37, 1
  %103 = load i32, i32* %10, align 8
  %104 = icmp slt i32 %102, %103
  br i1 %104, label %36, label %34

105:                                              ; preds = %34
  %106 = getelementptr inbounds float, float* %7, i64 %27
  store float %35, float* %106, align 4
  br label %107

107:                                              ; preds = %34, %105
  %108 = add nsw i64 %27, 1
  %109 = icmp eq i64 %108, %25
  br i1 %109, label %33, label %26
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK3ruy6KernelILNS_4PathE2EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE(%"struct.ruy::Kernel"*, %"struct.ruy::PMat"* dereferenceable(40), %"struct.ruy::PMat"* dereferenceable(40), %"class.ruy::MulParams"* dereferenceable(40), i32, i32, i32, i32, %"struct.ruy::Mat"*) local_unnamed_addr #1 comdat align 2 {
  %10 = alloca i32, align 4
  %11 = alloca float, align 4
  %12 = alloca float, align 4
  %13 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1, i32 0
  %14 = load i32, i32* %13, align 4
  %15 = icmp slt i32 %14, %6
  %16 = select i1 %15, i32 %14, i32 %6
  %17 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = icmp slt i32 %18, %7
  %20 = select i1 %19, i32 %18, i32 %7
  %21 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 0
  %22 = load i32, i32* %21, align 8
  %23 = icmp sgt i32 %16, %4
  br i1 %23, label %24, label %63

24:                                               ; preds = %9
  %25 = icmp sgt i32 %20, %5
  %26 = bitcast i32* %10 to i8*
  %27 = icmp sgt i32 %22, 0
  %28 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 0
  %29 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 4, i32 1
  %30 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 4, i32 2
  %31 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 3
  %32 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 2
  %33 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 4, i32 0
  %34 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 0
  %35 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 1
  %36 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 2
  %37 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 3
  %38 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 2
  %39 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 0
  %40 = bitcast i32* %10 to float*
  %41 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %3, i64 0, i32 0
  %42 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 3
  %43 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 1
  %44 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 3
  %45 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 1
  %46 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 2
  %47 = bitcast float* %11 to i8*
  %48 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %3, i64 0, i32 6
  %49 = bitcast float* %12 to i8*
  %50 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %3, i64 0, i32 5
  %51 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 0, i32 0
  %52 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1, i32 3
  %53 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1, i32 2
  %54 = sext i32 %5 to i64
  %55 = sext i32 %20 to i64
  %56 = sext i32 %4 to i64
  %57 = sext i32 %16 to i64
  br label %58

58:                                               ; preds = %24, %64
  %59 = phi i64 [ %56, %24 ], [ %65, %64 ]
  br i1 %25, label %60, label %64

60:                                               ; preds = %58
  %61 = trunc i64 %59 to i32
  %62 = trunc i64 %59 to i32
  br label %67

63:                                               ; preds = %64, %9
  ret void

64:                                               ; preds = %204, %58
  %65 = add nsw i64 %59, 1
  %66 = icmp slt i64 %65, %57
  br i1 %66, label %58, label %63

67:                                               ; preds = %60, %204
  %68 = phi i64 [ %54, %60 ], [ %214, %204 ]
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %26)
  store i32 0, i32* %10, align 4
  br i1 %27, label %69, label %120

69:                                               ; preds = %67
  %70 = load float*, float** %28, align 8
  %71 = load i8, i8* %29, align 1
  %72 = zext i8 %71 to i32
  %73 = sub nsw i32 0, %72
  %74 = load i8, i8* %30, align 1
  %75 = zext i8 %74 to i32
  %76 = sub nsw i32 0, %75
  %77 = and i32 %61, %76
  %78 = load i8, i8* %31, align 4
  %79 = icmp eq i8 %78, 0
  %80 = load i32, i32* %32, align 4
  %81 = select i1 %79, i32 %75, i32 %80
  %82 = icmp eq i8 %78, 1
  %83 = select i1 %82, i32 %72, i32 %80
  %84 = mul nsw i32 %83, %77
  %85 = sub nsw i32 %61, %77
  %86 = load i8, i8* %33, align 1
  %87 = icmp eq i8 %86, 0
  %88 = select i1 %87, i8 1, i8 %74
  %89 = zext i8 %88 to i32
  %90 = icmp eq i8 %86, 1
  %91 = select i1 %90, i8 1, i8 %71
  %92 = zext i8 %91 to i32
  %93 = mul nsw i32 %85, %92
  %94 = load float*, float** %34, align 8
  %95 = load i8, i8* %35, align 1
  %96 = zext i8 %95 to i32
  %97 = sub nsw i32 0, %96
  %98 = load i8, i8* %36, align 1
  %99 = zext i8 %98 to i32
  %100 = sub nsw i32 0, %99
  %101 = trunc i64 %68 to i32
  %102 = and i32 %101, %100
  %103 = load i8, i8* %37, align 4
  %104 = icmp eq i8 %103, 0
  %105 = load i32, i32* %38, align 4
  %106 = select i1 %104, i32 %99, i32 %105
  %107 = icmp eq i8 %103, 1
  %108 = select i1 %107, i32 %96, i32 %105
  %109 = mul nsw i32 %108, %102
  %110 = sub nsw i32 %101, %102
  %111 = load i8, i8* %39, align 1
  %112 = icmp eq i8 %111, 0
  %113 = select i1 %112, i8 1, i8 %98
  %114 = zext i8 %113 to i32
  %115 = icmp eq i8 %111, 1
  %116 = select i1 %115, i8 1, i8 %95
  %117 = zext i8 %116 to i32
  %118 = mul nsw i32 %110, %117
  br label %124

119:                                              ; preds = %124
  store float %148, float* %40, align 4
  br label %120

120:                                              ; preds = %119, %67
  %121 = phi float [ %148, %119 ], [ 0.000000e+00, %67 ]
  %122 = load float*, float** %41, align 8
  %123 = icmp eq float* %122, null
  br i1 %123, label %155, label %151

124:                                              ; preds = %124, %69
  %125 = phi float [ 0.000000e+00, %69 ], [ %148, %124 ]
  %126 = phi i32 [ 0, %69 ], [ %149, %124 ]
  %127 = and i32 %126, %73
  %128 = mul nsw i32 %81, %127
  %129 = sub nsw i32 %126, %127
  %130 = mul nsw i32 %129, %89
  %131 = add i32 %128, %84
  %132 = add i32 %131, %93
  %133 = add i32 %132, %130
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds float, float* %70, i64 %134
  %136 = load float, float* %135, align 4
  %137 = and i32 %126, %97
  %138 = mul nsw i32 %106, %137
  %139 = sub nsw i32 %126, %137
  %140 = mul nsw i32 %139, %114
  %141 = add i32 %138, %109
  %142 = add i32 %141, %118
  %143 = add i32 %142, %140
  %144 = sext i32 %143 to i64
  %145 = getelementptr inbounds float, float* %94, i64 %144
  %146 = load float, float* %145, align 4
  %147 = fmul float %136, %146
  %148 = fadd float %125, %147
  %149 = add nuw nsw i32 %126, 1
  %150 = icmp eq i32 %149, %22
  br i1 %150, label %119, label %124

151:                                              ; preds = %120
  %152 = getelementptr inbounds float, float* %122, i64 %59
  %153 = load float, float* %152, align 4
  %154 = fadd float %153, %121
  store float %154, float* %40, align 4
  br label %155

155:                                              ; preds = %120, %151
  %156 = phi float [ %121, %120 ], [ %154, %151 ]
  %157 = load i32, i32* %42, align 8
  %158 = icmp eq i32 %157, 0
  br i1 %158, label %166, label %159

159:                                              ; preds = %155
  %160 = sitofp i32 %157 to float
  %161 = load float*, float** %43, align 8
  %162 = getelementptr inbounds float, float* %161, i64 %68
  %163 = load float, float* %162, align 4
  %164 = fmul float %163, %160
  %165 = fsub float %156, %164
  store float %165, float* %40, align 4
  br label %166

166:                                              ; preds = %155, %159
  %167 = phi float [ %156, %155 ], [ %165, %159 ]
  %168 = load i32, i32* %44, align 8
  %169 = icmp eq i32 %168, 0
  br i1 %169, label %183, label %170

170:                                              ; preds = %166
  %171 = sitofp i32 %168 to float
  %172 = load float*, float** %45, align 8
  %173 = getelementptr inbounds float, float* %172, i64 %59
  %174 = load float, float* %173, align 4
  %175 = fmul float %174, %171
  %176 = fsub float %167, %175
  store float %176, float* %40, align 4
  %177 = or i1 %158, %169
  br i1 %177, label %183, label %178

178:                                              ; preds = %170
  %179 = mul i32 %157, %22
  %180 = mul i32 %179, %168
  %181 = sitofp i32 %180 to float
  %182 = fadd float %176, %181
  store float %182, float* %40, align 4
  br label %183

183:                                              ; preds = %166, %170, %178
  %184 = phi float [ %176, %170 ], [ %182, %178 ], [ %167, %166 ]
  %185 = load float, float* %46, align 8
  %186 = fadd float %185, %184
  store float %186, float* %40, align 4
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %47)
  %187 = load float, float* %48, align 4
  store float %187, float* %11, align 4
  %188 = fcmp olt float %187, %186
  %189 = select i1 %188, float* %11, float* %40
  %190 = bitcast float* %189 to i32*
  %191 = load i32, i32* %190, align 4
  store i32 %191, i32* %10, align 4
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %47)
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %49)
  %192 = load float, float* %50, align 8
  store float %192, float* %12, align 4
  %193 = bitcast i32 %191 to float
  %194 = fcmp ogt float %192, %193
  %195 = select i1 %194, float* %12, float* %40
  %196 = bitcast float* %195 to i32*
  %197 = load i32, i32* %196, align 4
  store i32 %197, i32* %10, align 4
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %49)
  %198 = load float*, float** %51, align 8
  %199 = load i8, i8* %52, align 4
  %200 = load i32, i32* %53, align 4
  switch i8 %199, label %201 [
    i8 0, label %202
    i8 1, label %204
  ]

201:                                              ; preds = %183
  br label %202

202:                                              ; preds = %201, %183
  %203 = phi i32 [ 1, %183 ], [ %200, %201 ]
  br label %204

204:                                              ; preds = %183, %202
  %205 = phi i32 [ %203, %202 ], [ %200, %183 ]
  %206 = phi i32 [ %200, %202 ], [ 1, %183 ]
  %207 = mul nsw i32 %205, %62
  %208 = trunc i64 %68 to i32
  %209 = mul nsw i32 %206, %208
  %210 = add nsw i32 %209, %207
  %211 = sext i32 %210 to i64
  %212 = getelementptr inbounds float, float* %198, i64 %211
  %213 = bitcast float* %212 to i32*
  store i32 %197, i32* %213, align 4
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %26)
  %214 = add nsw i64 %68, 1
  %215 = icmp slt i64 %214, %55
  br i1 %215, label %67, label %64
}

declare void @_ZN3ruy15PackFloatAvx512EPKfS1_iiiPf(float*, float*, i32, i32, i32, float*) local_unnamed_addr #3

declare void @_ZN3ruy26KernelFloatAvx512SingleColERKNS_17KernelParamsFloatILi16ELi16EEE(%"struct.ruy::KernelParamsFloat"* dereferenceable(1176)) local_unnamed_addr #3

declare void @_ZN3ruy17KernelFloatAvx512ERKNS_17KernelParamsFloatILi16ELi16EEE(%"struct.ruy::KernelParamsFloat"* dereferenceable(1176)) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EfffNS_9MulParamsIffEEE6SearchES1_PNS_11TrMulParamsE(i8 zeroext, %"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat align 2 {
  switch i8 %0, label %57 [
    i8 8, label %3
    i8 2, label %4
  ]

3:                                                ; preds = %2
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EfffNS_9MulParamsIffEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %1)
  br label %57

4:                                                ; preds = %2
  %5 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 0
  store i8 2, i8* %5, align 8
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0
  %7 = bitcast %"struct.ruy::PEMat"* %6 to i24*
  store i24 262401, i24* %7, align 8
  %8 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 3
  %9 = bitcast %"struct.ruy::Type"* %8 to i24*
  store i24 262401, i24* %9, align 8
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %10, align 4
  %11 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %12, i32* %13, align 4
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %15, i32* %16, align 4
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %18, align 1
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %19, align 1
  %20 = and i32 %12, 255
  %21 = icmp eq i32 %20, 0
  %22 = add nsw i32 %12, 64
  %23 = select i1 %21, i32 %22, i32 %12
  %24 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %23, i32* %24, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 4
  %26 = load i32, i32* %25, align 8
  %27 = sitofp i32 %26 to float
  %28 = fptosi float %27 to i32
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %28, i32* %29, align 8
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1
  %31 = bitcast %"struct.ruy::PEMat"* %30 to i24*
  store i24 262401, i24* %31, align 8
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 3
  %33 = bitcast %"struct.ruy::Type"* %32 to i24*
  store i24 262401, i24* %33, align 8
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %34, align 4
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %36, i32* %37, align 4
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %39, i32* %40, align 4
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %41, align 1
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %42, align 1
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %43, align 1
  %44 = and i32 %36, 255
  %45 = icmp eq i32 %44, 0
  %46 = add nsw i32 %36, 64
  %47 = select i1 %45, i32 %46, i32 %36
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 4
  %50 = load i32, i32* %49, align 8
  %51 = sitofp i32 %50 to float
  %52 = fptosi float %51 to i32
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %52, i32* %53, align 8
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 1, i32 0, i64 0
  %55 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %54 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %55, align 8
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)** %56, align 8
  br label %57

57:                                               ; preds = %2, %4, %3
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EfffNS_9MulParamsIffEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %49, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 262401, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262401, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 255
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = sitofp i32 %35 to float
  %37 = fptosi float %36 to i32
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %37, i32* %38, align 8
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %40 = bitcast %"struct.ruy::PEMat"* %39 to i24*
  store i24 262401, i24* %40, align 8
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %42 = bitcast %"struct.ruy::Type"* %41 to i24*
  store i24 262401, i24* %42, align 8
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %43, align 4
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %45, i32* %46, align 4
  %47 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %48 = load i32, i32* %47, align 4
  br label %89

49:                                               ; preds = %9
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 8, i8* %50, align 8
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %52 = bitcast %"struct.ruy::PEMat"* %51 to i24*
  store i24 262401, i24* %52, align 8
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %54 = bitcast %"struct.ruy::Type"* %53 to i24*
  store i24 262401, i24* %54, align 8
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %55, align 4
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %57, i32* %58, align 4
  %59 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %60 = load i32, i32* %59, align 4
  %61 = add i32 %60, 7
  %62 = and i32 %61, -8
  %63 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %62, i32* %63, align 4
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 1, i8* %64, align 1
  %65 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %65, align 1
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 8, i8* %66, align 1
  %67 = and i32 %57, 255
  %68 = icmp eq i32 %67, 0
  %69 = add nsw i32 %57, 64
  %70 = select i1 %68, i32 %69, i32 %57
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %73 = load i32, i32* %72, align 8
  %74 = sitofp i32 %73 to float
  %75 = fptosi float %74 to i32
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %75, i32* %76, align 8
  %77 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %78 = bitcast %"struct.ruy::PEMat"* %77 to i24*
  store i24 262401, i24* %78, align 8
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %80 = bitcast %"struct.ruy::Type"* %79 to i24*
  store i24 262401, i24* %80, align 8
  %81 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %81, align 4
  %82 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %83 = load i32, i32* %82, align 4
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %86 = load i32, i32* %85, align 4
  %87 = add i32 %86, 7
  %88 = and i32 %87, -8
  br label %89

89:                                               ; preds = %49, %13
  %90 = phi i32 [ %88, %49 ], [ %48, %13 ]
  %91 = phi i8 [ 1, %49 ], [ 0, %13 ]
  %92 = phi i8 [ 8, %49 ], [ 1, %13 ]
  %93 = phi i32 [ %83, %49 ], [ %45, %13 ]
  %94 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %49 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %95 = phi void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE8EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %49 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %90, i32* %96, align 4
  %97 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 %91, i8* %97, align 1
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %98, align 1
  %99 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 %92, i8* %99, align 1
  %100 = and i32 %93, 255
  %101 = icmp eq i32 %100, 0
  %102 = add nsw i32 %93, 64
  %103 = select i1 %101, i32 %102, i32 %93
  %104 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %103, i32* %104, align 4
  %105 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %106 = load i32, i32* %105, align 8
  %107 = sitofp i32 %106 to float
  %108 = fptosi float %107 to i32
  %109 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %108, i32* %109, align 8
  %110 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %94, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %110, align 8
  %111 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %94, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %111, align 8
  %112 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* %95, void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)** %112, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %7 = bitcast i8** %6 to float**
  %8 = load float*, float** %7, align 8, !noalias !231
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %14 = bitcast i8** %13 to float**
  %15 = load float*, float** %14, align 8, !noalias !234
  %16 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = icmp slt i32 %3, %4
  br i1 %18, label %19, label %38

19:                                               ; preds = %5
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = sext i32 %3 to i64
  %23 = sext i32 %4 to i64
  %24 = sext i32 %12 to i64
  br label %25

25:                                               ; preds = %19, %25
  %26 = phi i64 [ %22, %19 ], [ %36, %25 ]
  %27 = mul nsw i64 %26, %24
  %28 = getelementptr inbounds float, float* %8, i64 %27
  %29 = trunc i64 %26 to i32
  %30 = and i32 %29, -8
  %31 = mul nsw i32 %30, %17
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds float, float* %15, i64 %32
  %34 = trunc i64 %26 to i32
  %35 = sub i32 %21, %34
  tail call void @_ZN3ruy13PackFloatAvx2EPKfS1_iiiPf(float* %28, float* getelementptr inbounds ([8 x float], [8 x float]* @_ZZN3ruy8PackImplILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEiiE7zerobuf, i64 0, i64 0), i32 %12, i32 %35, i32 %10, float* %33) #18
  %36 = add i64 %26, 8
  %37 = icmp slt i64 %36, %23
  br i1 %37, label %25, label %38

38:                                               ; preds = %25, %5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE8EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.128"* dereferenceable(112), i8*, %"class.ruy::SidePair.129"* dereferenceable(8), %"class.ruy::SidePair.129"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParamsFloat.134", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = bitcast i8** %8 to float**
  %10 = load float*, float** %9, align 8, !noalias !237
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 2
  %18 = bitcast i8** %17 to float**
  %19 = load float*, float** %18, align 8, !noalias !240
  %20 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 2
  %25 = bitcast i8** %24 to float**
  %26 = load float*, float** %25, align 8, !noalias !243
  %27 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 0
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 1
  %32 = load i32, i32* %31, align 4
  %33 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 0
  %34 = load i32, i32* %33, align 4
  %35 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 1
  %36 = load i32, i32* %35, align 4
  %37 = bitcast %"struct.ruy::KernelParamsFloat.134"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 376, i8* nonnull %37) #18
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %37, i8* align 8 bitcast (%"struct.ruy::KernelParamsFloat.134"* @__const._ZNK3ruy6KernelILNS_4PathE8EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE.params to i8*), i64 376, i1 false) #18
  %38 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 18, i64 0
  %39 = bitcast float* %38 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %39, i8 0, i64 32, i1 false) #18
  %40 = mul nsw i32 %30, %23
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds float, float* %19, i64 %41
  %43 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 0
  store float* %42, float** %43, align 8
  %44 = mul nsw i32 %32, %28
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %26, i64 %45
  %47 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 1
  store float* %46, float** %47, align 8
  %48 = mul nsw i32 %32, %16
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %10, i64 %49
  %51 = sext i32 %30 to i64
  %52 = getelementptr inbounds float, float* %50, i64 %51
  %53 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 2
  store float* %52, float** %53, align 8
  %54 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 3
  %55 = bitcast i8* %2 to float**
  %56 = load float*, float** %55, align 8
  %57 = icmp eq float* %56, null
  %58 = select i1 %57, float* %38, float* %56
  store float* %58, float** %54, align 8
  %59 = xor i1 %57, true
  %60 = zext i1 %59 to i8
  %61 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 16
  store i8 %60, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 4
  store i32 %30, i32* %62, align 8
  %63 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 5
  store i32 %32, i32* %63, align 4
  %64 = add nsw i32 %34, -8
  %65 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 6
  store i32 %64, i32* %65, align 8
  %66 = add nsw i32 %36, -8
  %67 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 7
  store i32 %66, i32* %67, align 4
  %68 = shl i32 %23, 2
  %69 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 10
  store i32 %68, i32* %69, align 8
  %70 = shl i32 %28, 2
  %71 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 11
  store i32 %70, i32* %71, align 4
  %72 = shl i32 %16, 2
  %73 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 12
  store i32 %72, i32* %73, align 8
  %74 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 13
  store i32 %21, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %2, i64 32
  %76 = bitcast i8* %75 to i32*
  %77 = load i32, i32* %76, align 8
  %78 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 14
  %79 = bitcast float* %78 to i32*
  store i32 %77, i32* %79, align 8
  %80 = getelementptr inbounds i8, i8* %2, i64 36
  %81 = bitcast i8* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 15
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 8
  store i32 %12, i32* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.134", %"struct.ruy::KernelParamsFloat.134"* %7, i64 0, i32 9
  store i32 %14, i32* %86, align 4
  %87 = icmp eq i32 %14, 1
  br i1 %87, label %88, label %89

88:                                               ; preds = %6
  call void @_ZN3ruy24KernelFloatAvx2SingleColERKNS_17KernelParamsFloatILi8ELi8EEE(%"struct.ruy::KernelParamsFloat.134"* nonnull dereferenceable(376) %7) #18
  br label %90

89:                                               ; preds = %6
  call void @_ZN3ruy15KernelFloatAvx2ERKNS_17KernelParamsFloatILi8ELi8EEE(%"struct.ruy::KernelParamsFloat.134"* nonnull dereferenceable(376) %7) #18
  br label %90

90:                                               ; preds = %88, %89
  call void @llvm.lifetime.end.p0i8(i64 376, i8* nonnull %37) #18
  ret void
}

declare void @_ZN3ruy13PackFloatAvx2EPKfS1_iiiPf(float*, float*, i32, i32, i32, float*) local_unnamed_addr #3

declare void @_ZN3ruy24KernelFloatAvx2SingleColERKNS_17KernelParamsFloatILi8ELi8EEE(%"struct.ruy::KernelParamsFloat.134"* dereferenceable(376)) local_unnamed_addr #3

declare void @_ZN3ruy15KernelFloatAvx2ERKNS_17KernelParamsFloatILi8ELi8EEE(%"struct.ruy::KernelParamsFloat.134"* dereferenceable(376)) local_unnamed_addr #3

declare %"class.ruy::PrepackedCache"* @_ZN3ruy3Ctx17GetPrepackedCacheEv(%"class.ruy::Ctx"*) local_unnamed_addr #3

declare i32 @_ZN3ruy14PrepackedCache3GetEPKvPNS_5PEMatE(%"class.ruy::PrepackedCache"*, i8*, %"struct.ruy::PEMat"*) local_unnamed_addr #3

declare i32 @_ZN3ruy3Ctx19GetMainThreadTuningEv(%"class.ruy::Ctx"*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11WorkersPool13CreateWorkersEm(%"class.gemmlowp::WorkersPool"*, i64) local_unnamed_addr #1 comdat align 2 {
  %3 = alloca %"class.std::__1::chrono::duration.170", align 8
  %4 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 1
  %5 = bitcast %"class.gemmlowp::Worker"*** %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = bitcast %"class.gemmlowp::WorkersPool"* %0 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = sub i64 %6, %8
  %10 = ashr exact i64 %9, 3
  %11 = icmp ult i64 %10, %1
  br i1 %11, label %12, label %130

12:                                               ; preds = %2
  %13 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 1
  %14 = sub i64 %1, %10
  %15 = getelementptr inbounds %"class.gemmlowp::BlockingCounter", %"class.gemmlowp::BlockingCounter"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %16 = load atomic i64, i64* %15 monotonic, align 8
  store atomic i64 %14, i64* %15 release, align 8
  %17 = load i64, i64* %5, align 8
  %18 = load i64, i64* %7, align 8
  %19 = sub i64 %17, %18
  %20 = ashr exact i64 %19, 3
  %21 = icmp ult i64 %20, %1
  br i1 %21, label %22, label %115

22:                                               ; preds = %12
  %23 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 2, i32 0, i32 0
  %24 = bitcast %"class.gemmlowp::Worker"*** %23 to i64*
  %25 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 0
  br label %26

26:                                               ; preds = %22, %109
  %27 = tail call i8* @_Znwm(i64 208) #17
  %28 = getelementptr inbounds i8, i8* %27, i64 8
  %29 = bitcast i8* %28 to %"struct.gemmlowp::Task"**
  store %"struct.gemmlowp::Task"* null, %"struct.gemmlowp::Task"** %29, align 8
  %30 = getelementptr inbounds i8, i8* %27, i64 104
  %31 = bitcast i8* %30 to i32*
  store i32 0, i32* %31, align 4
  %32 = getelementptr inbounds i8, i8* %27, i64 112
  store i8 0, i8* %32, align 8
  %33 = getelementptr inbounds i8, i8* %27, i64 120
  %34 = getelementptr inbounds i8, i8* %27, i64 192
  %35 = bitcast i8* %34 to i64*
  store i64 0, i64* %35, align 8
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %33, i8 0, i64 32, i1 false) #18
  %36 = getelementptr inbounds i8, i8* %27, i64 200
  %37 = bitcast i8* %36 to %"class.gemmlowp::BlockingCounter"**
  store %"class.gemmlowp::BlockingCounter"* %13, %"class.gemmlowp::BlockingCounter"** %37, align 8
  %38 = getelementptr inbounds i8, i8* %27, i64 16
  %39 = bitcast i8* %38 to %union.pthread_cond_t*
  %40 = tail call i32 @pthread_cond_init(%union.pthread_cond_t* %39, %union.pthread_condattr_t* null) #18
  %41 = getelementptr inbounds i8, i8* %27, i64 64
  %42 = bitcast i8* %41 to %union.pthread_mutex_t*
  %43 = tail call i32 @pthread_mutex_init(%union.pthread_mutex_t* %42, %union.pthread_mutexattr_t* null) #18
  %44 = bitcast i8* %27 to i64*
  %45 = tail call i32 @pthread_create(i64* nonnull %44, %union.pthread_attr_t* null, i8* (i8*)* nonnull @_ZN8gemmlowp6Worker10ThreadFuncEPv, i8* nonnull %27) #18
  %46 = ptrtoint i8* %27 to i64
  %47 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %4, align 8
  %48 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %23, align 8
  %49 = icmp ult %"class.gemmlowp::Worker"** %47, %48
  %50 = ptrtoint %"class.gemmlowp::Worker"** %48 to i64
  br i1 %49, label %51, label %55

51:                                               ; preds = %26
  %52 = bitcast %"class.gemmlowp::Worker"** %47 to i64*
  store i64 %46, i64* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %47, i64 1
  %54 = ptrtoint %"class.gemmlowp::Worker"** %53 to i64
  store i64 %54, i64* %5, align 8
  br label %109

55:                                               ; preds = %26
  %56 = ptrtoint %"class.gemmlowp::Worker"** %47 to i64
  %57 = load i64, i64* %7, align 8
  %58 = sub i64 %56, %57
  %59 = ashr exact i64 %58, 3
  %60 = add nsw i64 %59, 1
  %61 = icmp ugt i64 %60, 2305843009213693951
  br i1 %61, label %62, label %64

62:                                               ; preds = %55
  %63 = bitcast %"class.gemmlowp::WorkersPool"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %63) #19
  unreachable

64:                                               ; preds = %55
  %65 = sub i64 %50, %57
  %66 = ashr exact i64 %65, 3
  %67 = icmp ult i64 %66, 1152921504606846975
  br i1 %67, label %68, label %76

68:                                               ; preds = %64
  %69 = ashr exact i64 %65, 2
  %70 = icmp ult i64 %69, %60
  %71 = select i1 %70, i64 %60, i64 %69
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %81, label %73

73:                                               ; preds = %68
  %74 = icmp ugt i64 %71, 2305843009213693951
  br i1 %74, label %75, label %76

75:                                               ; preds = %73
  tail call void @abort() #19
  unreachable

76:                                               ; preds = %73, %64
  %77 = phi i64 [ %71, %73 ], [ 2305843009213693951, %64 ]
  %78 = shl i64 %77, 3
  %79 = tail call i8* @_Znwm(i64 %78) #17
  %80 = bitcast i8* %79 to %"class.gemmlowp::Worker"**
  br label %81

81:                                               ; preds = %76, %68
  %82 = phi i64 [ %77, %76 ], [ 0, %68 ]
  %83 = phi %"class.gemmlowp::Worker"** [ %80, %76 ], [ null, %68 ]
  %84 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %83, i64 %59
  %85 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %83, i64 %82
  %86 = ptrtoint %"class.gemmlowp::Worker"** %85 to i64
  %87 = bitcast %"class.gemmlowp::Worker"** %84 to i64*
  store i64 %46, i64* %87, align 8
  %88 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %84, i64 1
  %89 = ptrtoint %"class.gemmlowp::Worker"** %88 to i64
  %90 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %25, align 8
  %91 = load i64, i64* %5, align 8
  %92 = ptrtoint %"class.gemmlowp::Worker"** %90 to i64
  %93 = sub i64 %91, %92
  %94 = ashr exact i64 %93, 3
  %95 = sub nsw i64 0, %94
  %96 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %84, i64 %95
  %97 = ptrtoint %"class.gemmlowp::Worker"** %96 to i64
  %98 = icmp sgt i64 %93, 0
  br i1 %98, label %99, label %103

99:                                               ; preds = %81
  %100 = bitcast %"class.gemmlowp::Worker"** %96 to i8*
  %101 = bitcast %"class.gemmlowp::Worker"** %90 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %100, i8* align 8 %101, i64 %93, i1 false) #18
  %102 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %25, align 8
  br label %103

103:                                              ; preds = %99, %81
  %104 = phi %"class.gemmlowp::Worker"** [ %90, %81 ], [ %102, %99 ]
  store i64 %97, i64* %7, align 8
  store i64 %89, i64* %5, align 8
  store i64 %86, i64* %24, align 8
  %105 = icmp eq %"class.gemmlowp::Worker"** %104, null
  br i1 %105, label %109, label %106

106:                                              ; preds = %103
  %107 = bitcast %"class.gemmlowp::Worker"** %104 to i8*
  tail call void @_ZdlPv(i8* %107) #17
  %108 = load i64, i64* %5, align 8
  br label %109

109:                                              ; preds = %51, %103, %106
  %110 = phi i64 [ %54, %51 ], [ %89, %103 ], [ %108, %106 ]
  %111 = load i64, i64* %7, align 8
  %112 = sub i64 %110, %111
  %113 = ashr exact i64 %112, 3
  %114 = icmp ult i64 %113, %1
  br i1 %114, label %26, label %115

115:                                              ; preds = %109, %12
  %116 = load atomic i64, i64* %15 acquire, align 8
  %117 = icmp eq i64 %116, 0
  br i1 %117, label %130, label %118

118:                                              ; preds = %115
  %119 = bitcast %"class.std::__1::chrono::duration.170"* %3 to i8*
  %120 = getelementptr inbounds %"class.std::__1::chrono::duration.170", %"class.std::__1::chrono::duration.170"* %3, i64 0, i32 0
  br label %121

121:                                              ; preds = %126, %118
  %122 = phi i32 [ 0, %118 ], [ %127, %126 ]
  call void asm sideeffect "nop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0A", "~{dirflag},~{fpsr},~{flags}"() #18, !srcloc !246
  %123 = add nsw i32 %122, 64
  %124 = icmp sgt i32 %123, 4000000
  br i1 %124, label %125, label %126

125:                                              ; preds = %121
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %119) #18
  store i64 1000000, i64* %120, align 8
  call void @_ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE(%"class.std::__1::chrono::duration.170"* nonnull dereferenceable(8) %3) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %119) #18
  br label %126

126:                                              ; preds = %125, %121
  %127 = phi i32 [ 0, %125 ], [ %123, %121 ]
  %128 = load atomic i64, i64* %15 acquire, align 8
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %130, label %121

130:                                              ; preds = %126, %115, %2
  ret void
}

; Function Attrs: nounwind
declare i32 @pthread_cond_init(%union.pthread_cond_t*, %union.pthread_condattr_t*) local_unnamed_addr #10

; Function Attrs: nounwind
declare i32 @pthread_mutex_init(%union.pthread_mutex_t*, %union.pthread_mutexattr_t*) local_unnamed_addr #10

; Function Attrs: nounwind
declare i32 @pthread_create(i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*) local_unnamed_addr #10

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i8* @_ZN8gemmlowp6Worker10ThreadFuncEPv(i8*) #1 comdat align 2 {
  %2 = bitcast i8* %0 to %"class.gemmlowp::Worker"*
  tail call void @_ZN8gemmlowp6Worker10ThreadFuncEv(%"class.gemmlowp::Worker"* %2)
  ret i8* null
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp6Worker10ThreadFuncEv(%"class.gemmlowp::Worker"*) local_unnamed_addr #1 comdat align 2 {
  %2 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 3
  %3 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #18
  %4 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0
  %5 = load atomic i32, i32* %4 monotonic, align 4
  %6 = icmp ult i32 %5, 3
  br i1 %6, label %8, label %7

7:                                                ; preds = %1
  tail call void @abort() #19
  unreachable

8:                                                ; preds = %1
  %9 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 1
  %10 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %9, align 8
  %11 = icmp eq %"struct.gemmlowp::Task"* %10, null
  br i1 %11, label %17, label %12

12:                                               ; preds = %8
  %13 = bitcast %"struct.gemmlowp::Task"* %10 to void (%"struct.gemmlowp::Task"*)***
  %14 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %13, align 8
  %15 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %14, i64 2
  %16 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %15, align 8
  tail call void %16(%"struct.gemmlowp::Task"* nonnull %10) #18
  store %"struct.gemmlowp::Task"* null, %"struct.gemmlowp::Task"** %9, align 8
  br label %17

17:                                               ; preds = %8, %12
  store atomic i32 1, i32* %4 monotonic, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 2
  %19 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %18) #18
  %20 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #18
  %21 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 6
  br label %22

22:                                               ; preds = %61, %17
  %23 = load %"class.gemmlowp::BlockingCounter"*, %"class.gemmlowp::BlockingCounter"** %21, align 8
  %24 = getelementptr inbounds %"class.gemmlowp::BlockingCounter", %"class.gemmlowp::BlockingCounter"* %23, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %25 = atomicrmw sub i64* %24, i64 1 acq_rel
  %26 = load atomic i32, i32* %4 acquire, align 4
  %27 = icmp eq i32 %26, 1
  br i1 %27, label %28, label %46

28:                                               ; preds = %22, %31
  %29 = phi i32 [ %32, %31 ], [ 0, %22 ]
  %30 = icmp ult i32 %29, 4000000
  br i1 %30, label %31, label %35

31:                                               ; preds = %28
  tail call void asm sideeffect "nop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0A", "~{dirflag},~{fpsr},~{flags}"() #18, !srcloc !246
  %32 = add nuw nsw i32 %29, 64
  %33 = load atomic i32, i32* %4 acquire, align 4
  %34 = icmp eq i32 %33, 1
  br i1 %34, label %28, label %46

35:                                               ; preds = %28
  %36 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #18
  %37 = load atomic i32, i32* %4 acquire, align 4
  %38 = icmp eq i32 %37, 1
  br i1 %38, label %39, label %43

39:                                               ; preds = %35, %39
  %40 = tail call i32 @pthread_cond_wait(%union.pthread_cond_t* %18, %union.pthread_mutex_t* %2) #18
  %41 = load atomic i32, i32* %4 acquire, align 4
  %42 = icmp eq i32 %41, 1
  br i1 %42, label %39, label %43

43:                                               ; preds = %39, %35
  %44 = phi i32 [ %37, %35 ], [ %41, %39 ]
  %45 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #18
  br label %46

46:                                               ; preds = %31, %22, %43
  %47 = phi i32 [ %26, %22 ], [ %44, %43 ], [ %33, %31 ]
  switch i32 %47, label %64 [
    i32 2, label %48
    i32 3, label %65
  ]

48:                                               ; preds = %46
  %49 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #18
  %50 = load atomic i32, i32* %4 monotonic, align 4
  %51 = icmp ult i32 %50, 3
  br i1 %51, label %53, label %52

52:                                               ; preds = %48
  tail call void @abort() #19
  unreachable

53:                                               ; preds = %48
  %54 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %9, align 8
  %55 = icmp eq %"struct.gemmlowp::Task"* %54, null
  br i1 %55, label %61, label %56

56:                                               ; preds = %53
  %57 = bitcast %"struct.gemmlowp::Task"* %54 to void (%"struct.gemmlowp::Task"*)***
  %58 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %57, align 8
  %59 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %58, i64 2
  %60 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %59, align 8
  tail call void %60(%"struct.gemmlowp::Task"* nonnull %54) #18
  store %"struct.gemmlowp::Task"* null, %"struct.gemmlowp::Task"** %9, align 8
  br label %61

61:                                               ; preds = %53, %56
  store atomic i32 1, i32* %4 monotonic, align 4
  %62 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %18) #18
  %63 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #18
  br label %22

64:                                               ; preds = %46
  tail call void @abort() #19
  unreachable

65:                                               ; preds = %46
  ret void
}

; Function Attrs: nounwind
declare i32 @pthread_mutex_lock(%union.pthread_mutex_t*) local_unnamed_addr #10

; Function Attrs: nounwind
declare i32 @pthread_cond_broadcast(%union.pthread_cond_t*) local_unnamed_addr #10

; Function Attrs: nounwind
declare i32 @pthread_mutex_unlock(%union.pthread_mutex_t*) local_unnamed_addr #10

declare i32 @pthread_cond_wait(%union.pthread_cond_t*, %union.pthread_mutex_t*) local_unnamed_addr #3

declare void @_ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE(%"class.std::__1::chrono::duration.170"* dereferenceable(8)) local_unnamed_addr #3

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS3_INS_13CwiseBinaryOpINS0_13scalar_sum_opIffEEKNSB_INS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS9_Lin1ELin1ELb0EEEEEKNSG_INS0_14scalar_tanh_opIfEESL_EEEEKNSB_ISF_SN_KNS4_IKS6_Li0ES8_EEEEEEEENS0_9assign_opIffEELi0EEELi4ELi0EE3runERS13_(%"class.Eigen::internal::generic_dense_assignment_kernel"* dereferenceable(32)) local_unnamed_addr #11 comdat align 2 {
  %2 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %0, i64 0, i32 3
  %3 = bitcast %"class.Eigen::Map"** %2 to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %4, align 8
  %6 = and i64 %5, 3
  %7 = icmp eq i64 %6, 0
  %8 = bitcast %"class.Eigen::Map"** %2 to %"class.Eigen::DenseBase"**
  %9 = bitcast i64* %4 to %"class.Eigen::DenseBase"*
  br i1 %7, label %50, label %10

10:                                               ; preds = %1
  %11 = getelementptr inbounds i64, i64* %4, i64 2
  %12 = load i64, i64* %11, align 8
  %13 = icmp sgt i64 %12, 0
  br i1 %13, label %14, label %320

14:                                               ; preds = %10
  %15 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel"* %0 to %"struct.Eigen::internal::mapbase_evaluator.207"**
  %16 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %0, i64 0, i32 1
  %17 = bitcast %"struct.Eigen::internal::evaluator"** %16 to %"struct.Eigen::internal::binary_evaluator"**
  br label %18

18:                                               ; preds = %25, %14
  %19 = phi %"class.Eigen::DenseBase"* [ %9, %14 ], [ %26, %25 ]
  %20 = phi i64 [ 0, %14 ], [ %27, %25 ]
  %21 = getelementptr inbounds %"class.Eigen::DenseBase", %"class.Eigen::DenseBase"* %19, i64 8
  %22 = bitcast %"class.Eigen::DenseBase"* %21 to i64*
  %23 = load i64, i64* %22, align 8
  %24 = icmp sgt i64 %23, 0
  br i1 %24, label %32, label %25

25:                                               ; preds = %32, %18
  %26 = phi %"class.Eigen::DenseBase"* [ %19, %18 ], [ %45, %32 ]
  %27 = add nuw nsw i64 %20, 1
  %28 = getelementptr inbounds %"class.Eigen::DenseBase", %"class.Eigen::DenseBase"* %26, i64 16
  %29 = bitcast %"class.Eigen::DenseBase"* %28 to i64*
  %30 = load i64, i64* %29, align 8
  %31 = icmp slt i64 %27, %30
  br i1 %31, label %18, label %320

32:                                               ; preds = %18, %32
  %33 = phi i64 [ %44, %32 ], [ 0, %18 ]
  %34 = load %"struct.Eigen::internal::mapbase_evaluator.207"*, %"struct.Eigen::internal::mapbase_evaluator.207"** %15, align 8
  %35 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %34, i64 0, i32 0
  %36 = load float*, float** %35, align 8
  %37 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %34, i64 0, i32 2, i32 0
  %38 = load i64, i64* %37, align 8
  %39 = mul nsw i64 %38, %20
  %40 = add nsw i64 %39, %33
  %41 = getelementptr inbounds float, float* %36, i64 %40
  %42 = load %"struct.Eigen::internal::binary_evaluator"*, %"struct.Eigen::internal::binary_evaluator"** %17, align 8
  %43 = tail call float @_ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opIffEEKNS2_INS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEELin1ELin1ELb0EEEEEKNS7_INS0_14scalar_tanh_opIfEESI_EEEEKNS2_IS6_SK_KNSB_IKSD_Li0ESF_EEEEEENS0_10IndexBasedESX_ffE5coeffEll(%"struct.Eigen::internal::binary_evaluator"* %42, i64 %33, i64 %20) #18
  store float %43, float* %41, align 4
  %44 = add nuw nsw i64 %33, 1
  %45 = load %"class.Eigen::DenseBase"*, %"class.Eigen::DenseBase"** %8, align 8
  %46 = getelementptr inbounds %"class.Eigen::DenseBase", %"class.Eigen::DenseBase"* %45, i64 8
  %47 = bitcast %"class.Eigen::DenseBase"* %46 to i64*
  %48 = load i64, i64* %47, align 8
  %49 = icmp slt i64 %44, %48
  br i1 %49, label %32, label %25

50:                                               ; preds = %1
  %51 = getelementptr inbounds i64, i64* %4, i64 1
  %52 = load i64, i64* %51, align 8
  %53 = getelementptr inbounds i64, i64* %4, i64 2
  %54 = load i64, i64* %53, align 8
  %55 = sub i64 0, %52
  %56 = and i64 %55, 3
  %57 = lshr i64 %5, 2
  %58 = sub nsw i64 0, %57
  %59 = and i64 %58, 3
  %60 = icmp sgt i64 %54, 0
  br i1 %60, label %61, label %320

61:                                               ; preds = %50
  %62 = icmp slt i64 %59, %52
  %63 = select i1 %62, i64 %59, i64 %52
  %64 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel"* %0 to %"struct.Eigen::internal::mapbase_evaluator.207"**
  %65 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %0, i64 0, i32 1
  %66 = bitcast %"struct.Eigen::internal::evaluator"** %65 to %"struct.Eigen::internal::binary_evaluator"**
  br label %67

67:                                               ; preds = %299, %61
  %68 = phi i64 [ 0, %61 ], [ %304, %299 ]
  %69 = phi i64 [ %63, %61 ], [ %303, %299 ]
  %70 = sub nsw i64 %52, %69
  %71 = and i64 %70, -4
  %72 = add nsw i64 %71, %69
  %73 = icmp sgt i64 %69, 0
  br i1 %73, label %76, label %74

74:                                               ; preds = %76, %67
  %75 = icmp sgt i64 %71, 0
  br i1 %75, label %92, label %90

76:                                               ; preds = %67, %76
  %77 = phi i64 [ %88, %76 ], [ 0, %67 ]
  %78 = load %"struct.Eigen::internal::mapbase_evaluator.207"*, %"struct.Eigen::internal::mapbase_evaluator.207"** %64, align 8
  %79 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %78, i64 0, i32 0
  %80 = load float*, float** %79, align 8
  %81 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %78, i64 0, i32 2, i32 0
  %82 = load i64, i64* %81, align 8
  %83 = mul nsw i64 %82, %68
  %84 = add nsw i64 %83, %77
  %85 = getelementptr inbounds float, float* %80, i64 %84
  %86 = load %"struct.Eigen::internal::binary_evaluator"*, %"struct.Eigen::internal::binary_evaluator"** %66, align 8
  %87 = tail call float @_ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opIffEEKNS2_INS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEELin1ELin1ELb0EEEEEKNS7_INS0_14scalar_tanh_opIfEESI_EEEEKNS2_IS6_SK_KNSB_IKSD_Li0ESF_EEEEEENS0_10IndexBasedESX_ffE5coeffEll(%"struct.Eigen::internal::binary_evaluator"* %86, i64 %77, i64 %68) #18
  store float %87, float* %85, align 4
  %88 = add nuw nsw i64 %77, 1
  %89 = icmp eq i64 %88, %69
  br i1 %89, label %74, label %76

90:                                               ; preds = %283, %74
  %91 = icmp slt i64 %72, %52
  br i1 %91, label %306, label %299

92:                                               ; preds = %74, %283
  %93 = phi i64 [ %297, %283 ], [ %69, %74 ]
  %94 = load %"struct.Eigen::internal::mapbase_evaluator.207"*, %"struct.Eigen::internal::mapbase_evaluator.207"** %64, align 8
  %95 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %94, i64 0, i32 0
  %96 = load float*, float** %95, align 8
  %97 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %94, i64 0, i32 2, i32 0
  %98 = load i64, i64* %97, align 8
  %99 = mul nsw i64 %98, %68
  %100 = add nsw i64 %99, %93
  %101 = getelementptr inbounds float, float* %96, i64 %100
  %102 = load %"struct.Eigen::internal::binary_evaluator"*, %"struct.Eigen::internal::binary_evaluator"** %66, align 8
  %103 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %102, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %104 = load float*, float** %103, align 8
  %105 = getelementptr inbounds float, float* %104, i64 %93
  %106 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %102, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %107 = load i64, i64* %106, align 8
  %108 = mul nsw i64 %107, %68
  %109 = getelementptr inbounds float, float* %105, i64 %108
  %110 = bitcast float* %109 to <4 x float>*
  %111 = load <4 x float>, <4 x float>* %110, align 1
  %112 = fcmp olt <4 x float> %111, <float -9.000000e+00, float -9.000000e+00, float -9.000000e+00, float -9.000000e+00>
  %113 = bitcast <4 x i1> %112 to i4
  %114 = icmp eq i4 %113, 0
  %115 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %111, <4 x float> <float 0x402F499C60000000, float 0x402F499C60000000, float 0x402F499C60000000, float 0x402F499C60000000>) #13, !srcloc !247
  %116 = fmul <4 x float> %115, %115
  %117 = fmul <4 x float> %116, <float 0x3DC806AA20000000, float 0x3DC806AA20000000, float 0x3DC806AA20000000, float 0x3DC806AA20000000>
  %118 = fadd <4 x float> %117, <float 0x3E7F09D960000000, float 0x3E7F09D960000000, float 0x3E7F09D960000000, float 0x3E7F09D960000000>
  %119 = fmul <4 x float> %116, %118
  %120 = fadd <4 x float> %119, <float 0x3F0FE82760000000, float 0x3F0FE82760000000, float 0x3F0FE82760000000, float 0x3F0FE82760000000>
  %121 = fmul <4 x float> %116, %120
  %122 = fadd <4 x float> %121, <float 0x3F816FAB00000000, float 0x3F816FAB00000000, float 0x3F816FAB00000000, float 0x3F816FAB00000000>
  %123 = fmul <4 x float> %116, %122
  %124 = fadd <4 x float> %123, <float 0x3FCFC7E640000000, float 0x3FCFC7E640000000, float 0x3FCFC7E640000000, float 0x3FCFC7E640000000>
  %125 = fmul <4 x float> %115, %124
  %126 = fmul <4 x float> %116, <float 0x3D65789EA0000000, float 0x3D65789EA0000000, float 0x3D65789EA0000000, float 0x3D65789EA0000000>
  %127 = fadd <4 x float> %126, <float 0x3E38BE4F60000000, float 0x3E38BE4F60000000, float 0x3E38BE4F60000000, float 0x3E38BE4F60000000>
  %128 = fmul <4 x float> %116, %127
  %129 = fadd <4 x float> %128, <float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000>
  %130 = fmul <4 x float> %116, %129
  %131 = fadd <4 x float> %130, <float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000>
  %132 = fmul <4 x float> %116, %131
  %133 = fadd <4 x float> %132, <float 0x3FBDE7C300000000, float 0x3FBDE7C300000000, float 0x3FBDE7C300000000, float 0x3FBDE7C300000000>
  %134 = fmul <4 x float> %116, %133
  %135 = fadd <4 x float> %134, <float 0x3FEFC7E680000000, float 0x3FEFC7E680000000, float 0x3FEFC7E680000000, float 0x3FEFC7E680000000>
  %136 = fdiv <4 x float> %125, %135
  %137 = fadd <4 x float> %136, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  br i1 %114, label %173, label %138, !prof !248

138:                                              ; preds = %92
  %139 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %111, <4 x float> <float 0x40561814C0000000, float 0x40561814C0000000, float 0x40561814C0000000, float 0x40561814C0000000>) #13, !srcloc !247
  %140 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %139, <4 x float> <float 0xC0561814A0000000, float 0xC0561814A0000000, float 0xC0561814A0000000, float 0xC0561814A0000000>) #13, !srcloc !249
  %141 = fmul <4 x float> %140, <float 0x3FF7154760000000, float 0x3FF7154760000000, float 0x3FF7154760000000, float 0x3FF7154760000000>
  %142 = fadd <4 x float> %141, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %143 = tail call <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float> %142) #18
  %144 = sitofp <4 x i32> %143 to <4 x float>
  %145 = fcmp olt <4 x float> %142, %144
  %146 = select <4 x i1> %145, <4 x float> <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>, <4 x float> zeroinitializer
  %147 = fsub <4 x float> %144, %146
  %148 = fmul <4 x float> %147, <float 0x3FE6300000000000, float 0x3FE6300000000000, float 0x3FE6300000000000, float 0x3FE6300000000000>
  %149 = fsub <4 x float> %140, %148
  %150 = fmul <4 x float> %147, <float 0xBF2BD01060000000, float 0xBF2BD01060000000, float 0xBF2BD01060000000, float 0xBF2BD01060000000>
  %151 = fsub <4 x float> %149, %150
  %152 = fmul <4 x float> %151, %151
  %153 = fmul <4 x float> %151, <float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000>
  %154 = fadd <4 x float> %153, <float 0x3F56E879C0000000, float 0x3F56E879C0000000, float 0x3F56E879C0000000, float 0x3F56E879C0000000>
  %155 = fmul <4 x float> %151, %154
  %156 = fadd <4 x float> %155, <float 0x3F81112100000000, float 0x3F81112100000000, float 0x3F81112100000000, float 0x3F81112100000000>
  %157 = fmul <4 x float> %151, %156
  %158 = fadd <4 x float> %157, <float 0x3FA5553820000000, float 0x3FA5553820000000, float 0x3FA5553820000000, float 0x3FA5553820000000>
  %159 = fmul <4 x float> %151, %158
  %160 = fadd <4 x float> %159, <float 0x3FC5555540000000, float 0x3FC5555540000000, float 0x3FC5555540000000, float 0x3FC5555540000000>
  %161 = fmul <4 x float> %151, %160
  %162 = fadd <4 x float> %161, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %163 = fmul <4 x float> %152, %162
  %164 = fadd <4 x float> %151, %163
  %165 = fadd <4 x float> %164, <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>
  %166 = fadd <4 x float> %147, <float 1.270000e+02, float 1.270000e+02, float 1.270000e+02, float 1.270000e+02>
  %167 = tail call <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float> %166) #18
  %168 = shl <4 x i32> %167, <i32 23, i32 23, i32 23, i32 23>
  %169 = bitcast <4 x i32> %168 to <4 x float>
  %170 = fmul <4 x float> %165, %169
  %171 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %170, <4 x float> %111) #13, !srcloc !249
  %172 = select <4 x i1> %112, <4 x float> %171, <4 x float> %137
  br label %173

173:                                              ; preds = %92, %138
  %174 = phi <4 x float> [ %172, %138 ], [ %137, %92 ]
  %175 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %102, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %176 = load float*, float** %175, align 8
  %177 = getelementptr inbounds float, float* %176, i64 %93
  %178 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %102, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %179 = load i64, i64* %178, align 8
  %180 = mul nsw i64 %179, %68
  %181 = getelementptr inbounds float, float* %177, i64 %180
  %182 = bitcast float* %181 to <4 x float>*
  %183 = load <4 x float>, <4 x float>* %182, align 1
  %184 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %183, <4 x float> <float 0x401F9F09E0000000, float 0x401F9F09E0000000, float 0x401F9F09E0000000, float 0x401F9F09E0000000>) #13, !srcloc !247
  %185 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %184, <4 x float> <float 0xC01F9F09E0000000, float 0xC01F9F09E0000000, float 0xC01F9F09E0000000, float 0xC01F9F09E0000000>) #13, !srcloc !249
  %186 = bitcast <4 x float> %183 to <4 x i32>
  %187 = and <4 x i32> %186, <i32 2147483647, i32 2147483647, i32 2147483647, i32 2147483647>
  %188 = bitcast <4 x i32> %187 to <4 x float>
  %189 = fcmp uge <4 x float> %188, <float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000>
  %190 = fmul <4 x float> %185, %185
  %191 = fmul <4 x float> %190, <float 0xBCB3E4B800000000, float 0xBCB3E4B800000000, float 0xBCB3E4B800000000, float 0xBCB3E4B800000000>
  %192 = fadd <4 x float> %191, <float 0x3D4C266FC0000000, float 0x3D4C266FC0000000, float 0x3D4C266FC0000000, float 0x3D4C266FC0000000>
  %193 = fmul <4 x float> %190, %192
  %194 = fadd <4 x float> %193, <float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000>
  %195 = fmul <4 x float> %190, %194
  %196 = fadd <4 x float> %195, <float 0x3E6B800820000000, float 0x3E6B800820000000, float 0x3E6B800820000000, float 0x3E6B800820000000>
  %197 = fmul <4 x float> %190, %196
  %198 = fadd <4 x float> %197, <float 0x3EEF286940000000, float 0x3EEF286940000000, float 0x3EEF286940000000, float 0x3EEF286940000000>
  %199 = fmul <4 x float> %190, %198
  %200 = fadd <4 x float> %199, <float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000>
  %201 = fmul <4 x float> %190, %200
  %202 = fadd <4 x float> %201, <float 0x3F740B3B80000000, float 0x3F740B3B80000000, float 0x3F740B3B80000000, float 0x3F740B3B80000000>
  %203 = fmul <4 x float> %185, %202
  %204 = fmul <4 x float> %190, <float 0x3EB41A7B00000000, float 0x3EB41A7B00000000, float 0x3EB41A7B00000000, float 0x3EB41A7B00000000>
  %205 = fadd <4 x float> %204, <float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000>
  %206 = fmul <4 x float> %190, %205
  %207 = fadd <4 x float> %206, <float 0x3F629540A0000000, float 0x3F629540A0000000, float 0x3F629540A0000000, float 0x3F629540A0000000>
  %208 = fmul <4 x float> %190, %207
  %209 = fadd <4 x float> %208, <float 0x3F740B3BA0000000, float 0x3F740B3BA0000000, float 0x3F740B3BA0000000, float 0x3F740B3BA0000000>
  %210 = fdiv <4 x float> %203, %209
  %211 = select <4 x i1> %189, <4 x float> %210, <4 x float> %185
  %212 = fmul <4 x float> %174, %211
  %213 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %102, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %214 = load float*, float** %213, align 8
  %215 = getelementptr inbounds float, float* %214, i64 %93
  %216 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %102, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %217 = load i64, i64* %216, align 8
  %218 = mul nsw i64 %217, %68
  %219 = getelementptr inbounds float, float* %215, i64 %218
  %220 = bitcast float* %219 to <4 x float>*
  %221 = load <4 x float>, <4 x float>* %220, align 1
  %222 = fcmp olt <4 x float> %221, <float -9.000000e+00, float -9.000000e+00, float -9.000000e+00, float -9.000000e+00>
  %223 = bitcast <4 x i1> %222 to i4
  %224 = icmp eq i4 %223, 0
  %225 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %221, <4 x float> <float 0x402F499C60000000, float 0x402F499C60000000, float 0x402F499C60000000, float 0x402F499C60000000>) #13, !srcloc !247
  %226 = fmul <4 x float> %225, %225
  %227 = fmul <4 x float> %226, <float 0x3DC806AA20000000, float 0x3DC806AA20000000, float 0x3DC806AA20000000, float 0x3DC806AA20000000>
  %228 = fadd <4 x float> %227, <float 0x3E7F09D960000000, float 0x3E7F09D960000000, float 0x3E7F09D960000000, float 0x3E7F09D960000000>
  %229 = fmul <4 x float> %226, %228
  %230 = fadd <4 x float> %229, <float 0x3F0FE82760000000, float 0x3F0FE82760000000, float 0x3F0FE82760000000, float 0x3F0FE82760000000>
  %231 = fmul <4 x float> %226, %230
  %232 = fadd <4 x float> %231, <float 0x3F816FAB00000000, float 0x3F816FAB00000000, float 0x3F816FAB00000000, float 0x3F816FAB00000000>
  %233 = fmul <4 x float> %226, %232
  %234 = fadd <4 x float> %233, <float 0x3FCFC7E640000000, float 0x3FCFC7E640000000, float 0x3FCFC7E640000000, float 0x3FCFC7E640000000>
  %235 = fmul <4 x float> %225, %234
  %236 = fmul <4 x float> %226, <float 0x3D65789EA0000000, float 0x3D65789EA0000000, float 0x3D65789EA0000000, float 0x3D65789EA0000000>
  %237 = fadd <4 x float> %236, <float 0x3E38BE4F60000000, float 0x3E38BE4F60000000, float 0x3E38BE4F60000000, float 0x3E38BE4F60000000>
  %238 = fmul <4 x float> %226, %237
  %239 = fadd <4 x float> %238, <float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000>
  %240 = fmul <4 x float> %226, %239
  %241 = fadd <4 x float> %240, <float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000>
  %242 = fmul <4 x float> %226, %241
  %243 = fadd <4 x float> %242, <float 0x3FBDE7C300000000, float 0x3FBDE7C300000000, float 0x3FBDE7C300000000, float 0x3FBDE7C300000000>
  %244 = fmul <4 x float> %226, %243
  %245 = fadd <4 x float> %244, <float 0x3FEFC7E680000000, float 0x3FEFC7E680000000, float 0x3FEFC7E680000000, float 0x3FEFC7E680000000>
  %246 = fdiv <4 x float> %235, %245
  %247 = fadd <4 x float> %246, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  br i1 %224, label %283, label %248, !prof !248

248:                                              ; preds = %173
  %249 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %221, <4 x float> <float 0x40561814C0000000, float 0x40561814C0000000, float 0x40561814C0000000, float 0x40561814C0000000>) #13, !srcloc !247
  %250 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %249, <4 x float> <float 0xC0561814A0000000, float 0xC0561814A0000000, float 0xC0561814A0000000, float 0xC0561814A0000000>) #13, !srcloc !249
  %251 = fmul <4 x float> %250, <float 0x3FF7154760000000, float 0x3FF7154760000000, float 0x3FF7154760000000, float 0x3FF7154760000000>
  %252 = fadd <4 x float> %251, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %253 = tail call <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float> %252) #18
  %254 = sitofp <4 x i32> %253 to <4 x float>
  %255 = fcmp olt <4 x float> %252, %254
  %256 = select <4 x i1> %255, <4 x float> <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>, <4 x float> zeroinitializer
  %257 = fsub <4 x float> %254, %256
  %258 = fmul <4 x float> %257, <float 0x3FE6300000000000, float 0x3FE6300000000000, float 0x3FE6300000000000, float 0x3FE6300000000000>
  %259 = fsub <4 x float> %250, %258
  %260 = fmul <4 x float> %257, <float 0xBF2BD01060000000, float 0xBF2BD01060000000, float 0xBF2BD01060000000, float 0xBF2BD01060000000>
  %261 = fsub <4 x float> %259, %260
  %262 = fmul <4 x float> %261, %261
  %263 = fmul <4 x float> %261, <float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000>
  %264 = fadd <4 x float> %263, <float 0x3F56E879C0000000, float 0x3F56E879C0000000, float 0x3F56E879C0000000, float 0x3F56E879C0000000>
  %265 = fmul <4 x float> %261, %264
  %266 = fadd <4 x float> %265, <float 0x3F81112100000000, float 0x3F81112100000000, float 0x3F81112100000000, float 0x3F81112100000000>
  %267 = fmul <4 x float> %261, %266
  %268 = fadd <4 x float> %267, <float 0x3FA5553820000000, float 0x3FA5553820000000, float 0x3FA5553820000000, float 0x3FA5553820000000>
  %269 = fmul <4 x float> %261, %268
  %270 = fadd <4 x float> %269, <float 0x3FC5555540000000, float 0x3FC5555540000000, float 0x3FC5555540000000, float 0x3FC5555540000000>
  %271 = fmul <4 x float> %261, %270
  %272 = fadd <4 x float> %271, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %273 = fmul <4 x float> %262, %272
  %274 = fadd <4 x float> %261, %273
  %275 = fadd <4 x float> %274, <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>
  %276 = fadd <4 x float> %257, <float 1.270000e+02, float 1.270000e+02, float 1.270000e+02, float 1.270000e+02>
  %277 = tail call <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float> %276) #18
  %278 = shl <4 x i32> %277, <i32 23, i32 23, i32 23, i32 23>
  %279 = bitcast <4 x i32> %278 to <4 x float>
  %280 = fmul <4 x float> %275, %279
  %281 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %280, <4 x float> %221) #13, !srcloc !249
  %282 = select <4 x i1> %222, <4 x float> %281, <4 x float> %247
  br label %283

283:                                              ; preds = %173, %248
  %284 = phi <4 x float> [ %282, %248 ], [ %247, %173 ]
  %285 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %102, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %286 = load float*, float** %285, align 8
  %287 = getelementptr inbounds float, float* %286, i64 %93
  %288 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %102, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 2, i32 0
  %289 = load i64, i64* %288, align 8
  %290 = mul nsw i64 %289, %68
  %291 = getelementptr inbounds float, float* %287, i64 %290
  %292 = bitcast float* %291 to <4 x float>*
  %293 = load <4 x float>, <4 x float>* %292, align 1
  %294 = fmul <4 x float> %284, %293
  %295 = fadd <4 x float> %212, %294
  %296 = bitcast float* %101 to <4 x float>*
  store <4 x float> %295, <4 x float>* %296, align 16
  %297 = add nsw i64 %93, 4
  %298 = icmp slt i64 %297, %72
  br i1 %298, label %92, label %90

299:                                              ; preds = %306, %90
  %300 = add nsw i64 %69, %56
  %301 = srem i64 %300, 4
  %302 = icmp slt i64 %52, %301
  %303 = select i1 %302, i64 %52, i64 %301
  %304 = add nuw nsw i64 %68, 1
  %305 = icmp eq i64 %304, %54
  br i1 %305, label %320, label %67

306:                                              ; preds = %90, %306
  %307 = phi i64 [ %318, %306 ], [ %72, %90 ]
  %308 = load %"struct.Eigen::internal::mapbase_evaluator.207"*, %"struct.Eigen::internal::mapbase_evaluator.207"** %64, align 8
  %309 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %308, i64 0, i32 0
  %310 = load float*, float** %309, align 8
  %311 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %308, i64 0, i32 2, i32 0
  %312 = load i64, i64* %311, align 8
  %313 = mul nsw i64 %312, %68
  %314 = add nsw i64 %313, %307
  %315 = getelementptr inbounds float, float* %310, i64 %314
  %316 = load %"struct.Eigen::internal::binary_evaluator"*, %"struct.Eigen::internal::binary_evaluator"** %66, align 8
  %317 = tail call float @_ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opIffEEKNS2_INS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEELin1ELin1ELb0EEEEEKNS7_INS0_14scalar_tanh_opIfEESI_EEEEKNS2_IS6_SK_KNSB_IKSD_Li0ESF_EEEEEENS0_10IndexBasedESX_ffE5coeffEll(%"struct.Eigen::internal::binary_evaluator"* %316, i64 %307, i64 %68) #18
  store float %317, float* %315, align 4
  %318 = add i64 %307, 1
  %319 = icmp eq i64 %318, %52
  br i1 %319, label %299, label %306

320:                                              ; preds = %25, %299, %50, %10
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden float @_ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opIffEEKNS2_INS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEELin1ELin1ELb0EEEEEKNS7_INS0_14scalar_tanh_opIfEESI_EEEEKNS2_IS6_SK_KNSB_IKSD_Li0ESF_EEEEEENS0_10IndexBasedESX_ffE5coeffEll(%"struct.Eigen::internal::binary_evaluator"*, i64, i64) local_unnamed_addr #5 comdat align 2 {
  %4 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %5 = load float*, float** %4, align 8
  %6 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = mul nsw i64 %7, %2
  %9 = add nsw i64 %8, %1
  %10 = getelementptr inbounds float, float* %5, i64 %9
  %11 = load float, float* %10, align 4
  %12 = fcmp olt float %11, -9.000000e+00
  %13 = fcmp ogt float %11, 0x402F499C60000000
  %14 = select i1 %13, float 0x402F499C60000000, float %11
  %15 = fmul float %14, %14
  %16 = fmul float %15, 0x3DC806AA20000000
  %17 = fadd float %16, 0x3E7F09D960000000
  %18 = fmul float %15, %17
  %19 = fadd float %18, 0x3F0FE82760000000
  %20 = fmul float %15, %19
  %21 = fadd float %20, 0x3F816FAB00000000
  %22 = fmul float %15, %21
  %23 = fadd float %22, 0x3FCFC7E640000000
  %24 = fmul float %14, %23
  %25 = fmul float %15, 0x3D65789EA0000000
  %26 = fadd float %25, 0x3E38BE4F60000000
  %27 = fmul float %15, %26
  %28 = fadd float %27, 0x3EDA62FBA0000000
  %29 = fmul float %15, %28
  %30 = fadd float %29, 0x3F5BE2A7E0000000
  %31 = fmul float %15, %30
  %32 = fadd float %31, 0x3FBDE7C300000000
  %33 = fmul float %15, %32
  %34 = fadd float %33, 0x3FEFC7E680000000
  %35 = fdiv float %24, %34
  %36 = fadd float %35, 5.000000e-01
  br i1 %12, label %37, label %67, !prof !250

37:                                               ; preds = %3
  %38 = fcmp ogt float %11, 0x40561814C0000000
  %39 = select i1 %38, float 0x40561814C0000000, float %11
  %40 = fcmp olt float %39, 0xC0561814A0000000
  %41 = select i1 %40, float 0xC0561814A0000000, float %39
  %42 = fmul float %41, 0x3FF7154760000000
  %43 = fadd float %42, 5.000000e-01
  %44 = tail call float @llvm.floor.f32(float %43) #18
  %45 = fmul float %44, 0x3FE6300000000000
  %46 = fsub float %41, %45
  %47 = fmul float %44, 0x3F2BD01060000000
  %48 = fadd float %47, %46
  %49 = fmul float %48, %48
  %50 = fmul float %48, 0x3F2A0D2CE0000000
  %51 = fadd float %50, 0x3F56E879C0000000
  %52 = fmul float %48, %51
  %53 = fadd float %52, 0x3F81112100000000
  %54 = fmul float %48, %53
  %55 = fadd float %54, 0x3FA5553820000000
  %56 = fmul float %48, %55
  %57 = fadd float %56, 0x3FC5555540000000
  %58 = fmul float %48, %57
  %59 = fadd float %58, 5.000000e-01
  %60 = fmul float %49, %59
  %61 = fadd float %48, %60
  %62 = fadd float %61, 1.000000e+00
  %63 = fptosi float %44 to i32
  %64 = tail call float @ldexpf(float %62, i32 %63) #18
  %65 = fcmp olt float %64, %11
  %66 = select i1 %65, float %11, float %64
  br label %67

67:                                               ; preds = %3, %37
  %68 = phi float [ %66, %37 ], [ %36, %3 ]
  %69 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %70 = load float*, float** %69, align 8
  %71 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %72 = load i64, i64* %71, align 8
  %73 = mul nsw i64 %72, %2
  %74 = add nsw i64 %73, %1
  %75 = getelementptr inbounds float, float* %70, i64 %74
  %76 = load float, float* %75, align 4
  %77 = fcmp ogt float %76, 0x401F9F09E0000000
  %78 = select i1 %77, float 0x401F9F09E0000000, float %76
  %79 = fcmp olt float %78, 0xC01F9F09E0000000
  %80 = select i1 %79, float 0xC01F9F09E0000000, float %78
  %81 = tail call float @llvm.fabs.f32(float %76) #18
  %82 = fcmp olt float %81, 0x3F3A36E2E0000000
  %83 = select i1 %82, float 0xFFFFFFFFE0000000, float 0.000000e+00
  %84 = fmul float %80, %80
  %85 = fmul float %84, 0x3CB3E4B800000000
  %86 = fsub float 0x3D4C266FC0000000, %85
  %87 = fmul float %84, %86
  %88 = fadd float %87, 0xBDD7A6FFE0000000
  %89 = fmul float %84, %88
  %90 = fadd float %89, 0x3E6B800820000000
  %91 = fmul float %84, %90
  %92 = fadd float %91, 0x3EEF286940000000
  %93 = fmul float %84, %92
  %94 = fadd float %93, 0x3F44E1BDA0000000
  %95 = fmul float %84, %94
  %96 = fadd float %95, 0x3F740B3B80000000
  %97 = fmul float %80, %96
  %98 = fmul float %84, 0x3EB41A7B00000000
  %99 = fadd float %98, 0x3F1F12BAC0000000
  %100 = fmul float %84, %99
  %101 = fadd float %100, 0x3F629540A0000000
  %102 = fmul float %84, %101
  %103 = fadd float %102, 0x3F740B3BA0000000
  %104 = fdiv float %97, %103
  %105 = fcmp oeq float %83, 0.000000e+00
  %106 = select i1 %105, float %104, float %80
  %107 = fmul float %68, %106
  %108 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %109 = load float*, float** %108, align 8
  %110 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %111 = load i64, i64* %110, align 8
  %112 = mul nsw i64 %111, %2
  %113 = add nsw i64 %112, %1
  %114 = getelementptr inbounds float, float* %109, i64 %113
  %115 = load float, float* %114, align 4
  %116 = fcmp olt float %115, -9.000000e+00
  %117 = fcmp ogt float %115, 0x402F499C60000000
  %118 = select i1 %117, float 0x402F499C60000000, float %115
  %119 = fmul float %118, %118
  %120 = fmul float %119, 0x3DC806AA20000000
  %121 = fadd float %120, 0x3E7F09D960000000
  %122 = fmul float %119, %121
  %123 = fadd float %122, 0x3F0FE82760000000
  %124 = fmul float %119, %123
  %125 = fadd float %124, 0x3F816FAB00000000
  %126 = fmul float %119, %125
  %127 = fadd float %126, 0x3FCFC7E640000000
  %128 = fmul float %118, %127
  %129 = fmul float %119, 0x3D65789EA0000000
  %130 = fadd float %129, 0x3E38BE4F60000000
  %131 = fmul float %119, %130
  %132 = fadd float %131, 0x3EDA62FBA0000000
  %133 = fmul float %119, %132
  %134 = fadd float %133, 0x3F5BE2A7E0000000
  %135 = fmul float %119, %134
  %136 = fadd float %135, 0x3FBDE7C300000000
  %137 = fmul float %119, %136
  %138 = fadd float %137, 0x3FEFC7E680000000
  %139 = fdiv float %128, %138
  %140 = fadd float %139, 5.000000e-01
  br i1 %116, label %141, label %171, !prof !250

141:                                              ; preds = %67
  %142 = fcmp ogt float %115, 0x40561814C0000000
  %143 = select i1 %142, float 0x40561814C0000000, float %115
  %144 = fcmp olt float %143, 0xC0561814A0000000
  %145 = select i1 %144, float 0xC0561814A0000000, float %143
  %146 = fmul float %145, 0x3FF7154760000000
  %147 = fadd float %146, 5.000000e-01
  %148 = tail call float @llvm.floor.f32(float %147) #18
  %149 = fmul float %148, 0x3FE6300000000000
  %150 = fsub float %145, %149
  %151 = fmul float %148, 0x3F2BD01060000000
  %152 = fadd float %151, %150
  %153 = fmul float %152, %152
  %154 = fmul float %152, 0x3F2A0D2CE0000000
  %155 = fadd float %154, 0x3F56E879C0000000
  %156 = fmul float %152, %155
  %157 = fadd float %156, 0x3F81112100000000
  %158 = fmul float %152, %157
  %159 = fadd float %158, 0x3FA5553820000000
  %160 = fmul float %152, %159
  %161 = fadd float %160, 0x3FC5555540000000
  %162 = fmul float %152, %161
  %163 = fadd float %162, 5.000000e-01
  %164 = fmul float %153, %163
  %165 = fadd float %152, %164
  %166 = fadd float %165, 1.000000e+00
  %167 = fptosi float %148 to i32
  %168 = tail call float @ldexpf(float %166, i32 %167) #18
  %169 = fcmp olt float %168, %115
  %170 = select i1 %169, float %115, float %168
  br label %171

171:                                              ; preds = %67, %141
  %172 = phi float [ %170, %141 ], [ %140, %67 ]
  %173 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %174 = load float*, float** %173, align 8
  %175 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator", %"struct.Eigen::internal::binary_evaluator"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 2, i32 0
  %176 = load i64, i64* %175, align 8
  %177 = mul nsw i64 %176, %2
  %178 = add nsw i64 %177, %1
  %179 = getelementptr inbounds float, float* %174, i64 %178
  %180 = load float, float* %179, align 4
  %181 = fmul float %172, %180
  %182 = fadd float %107, %181
  ret float %182
}

; Function Attrs: nounwind readnone speculatable
declare float @llvm.floor.f32(float) #4

; Function Attrs: nofree nounwind
declare float @ldexpf(float, i32) local_unnamed_addr #12

; Function Attrs: nounwind readnone speculatable
declare float @llvm.fabs.f32(float) #4

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float>) #13

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS3_INS_13CwiseBinaryOpINS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS9_Lin1ELin1ELb0EEEEEKNSE_INS0_14scalar_tanh_opIfEEKS9_EEEEEENS0_9assign_opIffEELi0EEELi4ELi0EE3runERSV_(%"class.Eigen::internal::generic_dense_assignment_kernel.223"* dereferenceable(32)) local_unnamed_addr #11 comdat align 2 {
  %2 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel.223", %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %0, i64 0, i32 3
  %3 = bitcast %"class.Eigen::Map"** %2 to i64**
  %4 = load i64*, i64** %3, align 8
  %5 = load i64, i64* %4, align 8
  %6 = and i64 %5, 3
  %7 = icmp eq i64 %6, 0
  %8 = bitcast %"class.Eigen::Map"** %2 to %"class.Eigen::DenseBase"**
  br i1 %7, label %37, label %9

9:                                                ; preds = %1
  %10 = getelementptr inbounds i64, i64* %4, i64 2
  %11 = load i64, i64* %10, align 8
  %12 = icmp sgt i64 %11, 0
  br i1 %12, label %13, label %204

13:                                               ; preds = %9
  %14 = bitcast i64* %4 to %"class.Eigen::DenseBase"*
  br label %15

15:                                               ; preds = %13, %22
  %16 = phi %"class.Eigen::DenseBase"* [ %23, %22 ], [ %14, %13 ]
  %17 = phi i64 [ %24, %22 ], [ 0, %13 ]
  %18 = getelementptr inbounds %"class.Eigen::DenseBase", %"class.Eigen::DenseBase"* %16, i64 8
  %19 = bitcast %"class.Eigen::DenseBase"* %18 to i64*
  %20 = load i64, i64* %19, align 8
  %21 = icmp sgt i64 %20, 0
  br i1 %21, label %29, label %22

22:                                               ; preds = %29, %15
  %23 = phi %"class.Eigen::DenseBase"* [ %16, %15 ], [ %32, %29 ]
  %24 = add nuw nsw i64 %17, 1
  %25 = getelementptr inbounds %"class.Eigen::DenseBase", %"class.Eigen::DenseBase"* %23, i64 16
  %26 = bitcast %"class.Eigen::DenseBase"* %25 to i64*
  %27 = load i64, i64* %26, align 8
  %28 = icmp slt i64 %24, %27
  br i1 %28, label %15, label %204

29:                                               ; preds = %15, %29
  %30 = phi i64 [ %31, %29 ], [ 0, %15 ]
  tail call void @_ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS8_Lin1ELin1ELb0EEEEEKNSD_INS0_14scalar_tanh_opIfEEKS8_EEEEEENS0_9assign_opIffEELi0EE23assignCoeffByOuterInnerEll(%"class.Eigen::internal::generic_dense_assignment_kernel.223"* %0, i64 %17, i64 %30) #18
  %31 = add nuw nsw i64 %30, 1
  %32 = load %"class.Eigen::DenseBase"*, %"class.Eigen::DenseBase"** %8, align 8
  %33 = getelementptr inbounds %"class.Eigen::DenseBase", %"class.Eigen::DenseBase"* %32, i64 8
  %34 = bitcast %"class.Eigen::DenseBase"* %33 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = icmp slt i64 %31, %35
  br i1 %36, label %29, label %22

37:                                               ; preds = %1
  %38 = getelementptr inbounds i64, i64* %4, i64 1
  %39 = load i64, i64* %38, align 8
  %40 = getelementptr inbounds i64, i64* %4, i64 2
  %41 = load i64, i64* %40, align 8
  %42 = sub i64 0, %39
  %43 = and i64 %42, 3
  %44 = lshr i64 %5, 2
  %45 = sub nsw i64 0, %44
  %46 = and i64 %45, 3
  %47 = icmp sgt i64 %41, 0
  br i1 %47, label %48, label %204

48:                                               ; preds = %37
  %49 = icmp slt i64 %46, %39
  %50 = select i1 %49, i64 %46, i64 %39
  %51 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %0 to %"struct.Eigen::internal::mapbase_evaluator.207"**
  %52 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel.223", %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %0, i64 0, i32 1
  %53 = bitcast %"struct.Eigen::internal::evaluator.213"** %52 to %"struct.Eigen::internal::binary_evaluator.214"**
  br label %54

54:                                               ; preds = %193, %48
  %55 = phi i64 [ 0, %48 ], [ %198, %193 ]
  %56 = phi i64 [ %50, %48 ], [ %197, %193 ]
  %57 = sub nsw i64 %39, %56
  %58 = and i64 %57, -4
  %59 = add nsw i64 %58, %56
  %60 = icmp sgt i64 %56, 0
  br i1 %60, label %63, label %61

61:                                               ; preds = %63, %54
  %62 = icmp sgt i64 %58, 0
  br i1 %62, label %69, label %67

63:                                               ; preds = %54, %63
  %64 = phi i64 [ %65, %63 ], [ 0, %54 ]
  tail call void @_ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS8_Lin1ELin1ELb0EEEEEKNSD_INS0_14scalar_tanh_opIfEEKS8_EEEEEENS0_9assign_opIffEELi0EE23assignCoeffByOuterInnerEll(%"class.Eigen::internal::generic_dense_assignment_kernel.223"* %0, i64 %55, i64 %64)
  %65 = add nuw nsw i64 %64, 1
  %66 = icmp eq i64 %65, %56
  br i1 %66, label %61, label %63

67:                                               ; preds = %150, %61
  %68 = icmp slt i64 %59, %39
  br i1 %68, label %200, label %193

69:                                               ; preds = %61, %150
  %70 = phi i64 [ %191, %150 ], [ %56, %61 ]
  %71 = load %"struct.Eigen::internal::mapbase_evaluator.207"*, %"struct.Eigen::internal::mapbase_evaluator.207"** %51, align 8
  %72 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %71, i64 0, i32 0
  %73 = load float*, float** %72, align 8
  %74 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %71, i64 0, i32 2, i32 0
  %75 = load i64, i64* %74, align 8
  %76 = mul nsw i64 %75, %55
  %77 = add nsw i64 %76, %70
  %78 = getelementptr inbounds float, float* %73, i64 %77
  %79 = load %"struct.Eigen::internal::binary_evaluator.214"*, %"struct.Eigen::internal::binary_evaluator.214"** %53, align 8
  %80 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator.214", %"struct.Eigen::internal::binary_evaluator.214"* %79, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %81 = load float*, float** %80, align 8
  %82 = getelementptr inbounds float, float* %81, i64 %70
  %83 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator.214", %"struct.Eigen::internal::binary_evaluator.214"* %79, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %84 = load i64, i64* %83, align 8
  %85 = mul nsw i64 %84, %55
  %86 = getelementptr inbounds float, float* %82, i64 %85
  %87 = bitcast float* %86 to <4 x float>*
  %88 = load <4 x float>, <4 x float>* %87, align 1
  %89 = fcmp olt <4 x float> %88, <float -9.000000e+00, float -9.000000e+00, float -9.000000e+00, float -9.000000e+00>
  %90 = bitcast <4 x i1> %89 to i4
  %91 = icmp eq i4 %90, 0
  %92 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %88, <4 x float> <float 0x402F499C60000000, float 0x402F499C60000000, float 0x402F499C60000000, float 0x402F499C60000000>) #13, !srcloc !247
  %93 = fmul <4 x float> %92, %92
  %94 = fmul <4 x float> %93, <float 0x3DC806AA20000000, float 0x3DC806AA20000000, float 0x3DC806AA20000000, float 0x3DC806AA20000000>
  %95 = fadd <4 x float> %94, <float 0x3E7F09D960000000, float 0x3E7F09D960000000, float 0x3E7F09D960000000, float 0x3E7F09D960000000>
  %96 = fmul <4 x float> %93, %95
  %97 = fadd <4 x float> %96, <float 0x3F0FE82760000000, float 0x3F0FE82760000000, float 0x3F0FE82760000000, float 0x3F0FE82760000000>
  %98 = fmul <4 x float> %93, %97
  %99 = fadd <4 x float> %98, <float 0x3F816FAB00000000, float 0x3F816FAB00000000, float 0x3F816FAB00000000, float 0x3F816FAB00000000>
  %100 = fmul <4 x float> %93, %99
  %101 = fadd <4 x float> %100, <float 0x3FCFC7E640000000, float 0x3FCFC7E640000000, float 0x3FCFC7E640000000, float 0x3FCFC7E640000000>
  %102 = fmul <4 x float> %92, %101
  %103 = fmul <4 x float> %93, <float 0x3D65789EA0000000, float 0x3D65789EA0000000, float 0x3D65789EA0000000, float 0x3D65789EA0000000>
  %104 = fadd <4 x float> %103, <float 0x3E38BE4F60000000, float 0x3E38BE4F60000000, float 0x3E38BE4F60000000, float 0x3E38BE4F60000000>
  %105 = fmul <4 x float> %93, %104
  %106 = fadd <4 x float> %105, <float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000>
  %107 = fmul <4 x float> %93, %106
  %108 = fadd <4 x float> %107, <float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000>
  %109 = fmul <4 x float> %93, %108
  %110 = fadd <4 x float> %109, <float 0x3FBDE7C300000000, float 0x3FBDE7C300000000, float 0x3FBDE7C300000000, float 0x3FBDE7C300000000>
  %111 = fmul <4 x float> %93, %110
  %112 = fadd <4 x float> %111, <float 0x3FEFC7E680000000, float 0x3FEFC7E680000000, float 0x3FEFC7E680000000, float 0x3FEFC7E680000000>
  %113 = fdiv <4 x float> %102, %112
  %114 = fadd <4 x float> %113, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  br i1 %91, label %150, label %115, !prof !248

115:                                              ; preds = %69
  %116 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %88, <4 x float> <float 0x40561814C0000000, float 0x40561814C0000000, float 0x40561814C0000000, float 0x40561814C0000000>) #13, !srcloc !247
  %117 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %116, <4 x float> <float 0xC0561814A0000000, float 0xC0561814A0000000, float 0xC0561814A0000000, float 0xC0561814A0000000>) #13, !srcloc !249
  %118 = fmul <4 x float> %117, <float 0x3FF7154760000000, float 0x3FF7154760000000, float 0x3FF7154760000000, float 0x3FF7154760000000>
  %119 = fadd <4 x float> %118, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %120 = tail call <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float> %119) #18
  %121 = sitofp <4 x i32> %120 to <4 x float>
  %122 = fcmp olt <4 x float> %119, %121
  %123 = select <4 x i1> %122, <4 x float> <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>, <4 x float> zeroinitializer
  %124 = fsub <4 x float> %121, %123
  %125 = fmul <4 x float> %124, <float 0x3FE6300000000000, float 0x3FE6300000000000, float 0x3FE6300000000000, float 0x3FE6300000000000>
  %126 = fsub <4 x float> %117, %125
  %127 = fmul <4 x float> %124, <float 0xBF2BD01060000000, float 0xBF2BD01060000000, float 0xBF2BD01060000000, float 0xBF2BD01060000000>
  %128 = fsub <4 x float> %126, %127
  %129 = fmul <4 x float> %128, %128
  %130 = fmul <4 x float> %128, <float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000>
  %131 = fadd <4 x float> %130, <float 0x3F56E879C0000000, float 0x3F56E879C0000000, float 0x3F56E879C0000000, float 0x3F56E879C0000000>
  %132 = fmul <4 x float> %128, %131
  %133 = fadd <4 x float> %132, <float 0x3F81112100000000, float 0x3F81112100000000, float 0x3F81112100000000, float 0x3F81112100000000>
  %134 = fmul <4 x float> %128, %133
  %135 = fadd <4 x float> %134, <float 0x3FA5553820000000, float 0x3FA5553820000000, float 0x3FA5553820000000, float 0x3FA5553820000000>
  %136 = fmul <4 x float> %128, %135
  %137 = fadd <4 x float> %136, <float 0x3FC5555540000000, float 0x3FC5555540000000, float 0x3FC5555540000000, float 0x3FC5555540000000>
  %138 = fmul <4 x float> %128, %137
  %139 = fadd <4 x float> %138, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %140 = fmul <4 x float> %129, %139
  %141 = fadd <4 x float> %128, %140
  %142 = fadd <4 x float> %141, <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>
  %143 = fadd <4 x float> %124, <float 1.270000e+02, float 1.270000e+02, float 1.270000e+02, float 1.270000e+02>
  %144 = tail call <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float> %143) #18
  %145 = shl <4 x i32> %144, <i32 23, i32 23, i32 23, i32 23>
  %146 = bitcast <4 x i32> %145 to <4 x float>
  %147 = fmul <4 x float> %142, %146
  %148 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %147, <4 x float> %88) #13, !srcloc !249
  %149 = select <4 x i1> %89, <4 x float> %148, <4 x float> %114
  br label %150

150:                                              ; preds = %69, %115
  %151 = phi <4 x float> [ %149, %115 ], [ %114, %69 ]
  %152 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator.214", %"struct.Eigen::internal::binary_evaluator.214"* %79, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %153 = load float*, float** %152, align 8
  %154 = getelementptr inbounds float, float* %153, i64 %70
  %155 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator.214", %"struct.Eigen::internal::binary_evaluator.214"* %79, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %156 = load i64, i64* %155, align 8
  %157 = mul nsw i64 %156, %55
  %158 = getelementptr inbounds float, float* %154, i64 %157
  %159 = bitcast float* %158 to <4 x float>*
  %160 = load <4 x float>, <4 x float>* %159, align 1
  %161 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %160, <4 x float> <float 0x401F9F09E0000000, float 0x401F9F09E0000000, float 0x401F9F09E0000000, float 0x401F9F09E0000000>) #13, !srcloc !247
  %162 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %161, <4 x float> <float 0xC01F9F09E0000000, float 0xC01F9F09E0000000, float 0xC01F9F09E0000000, float 0xC01F9F09E0000000>) #13, !srcloc !249
  %163 = bitcast <4 x float> %160 to <4 x i32>
  %164 = and <4 x i32> %163, <i32 2147483647, i32 2147483647, i32 2147483647, i32 2147483647>
  %165 = bitcast <4 x i32> %164 to <4 x float>
  %166 = fcmp uge <4 x float> %165, <float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000>
  %167 = fmul <4 x float> %162, %162
  %168 = fmul <4 x float> %167, <float 0xBCB3E4B800000000, float 0xBCB3E4B800000000, float 0xBCB3E4B800000000, float 0xBCB3E4B800000000>
  %169 = fadd <4 x float> %168, <float 0x3D4C266FC0000000, float 0x3D4C266FC0000000, float 0x3D4C266FC0000000, float 0x3D4C266FC0000000>
  %170 = fmul <4 x float> %167, %169
  %171 = fadd <4 x float> %170, <float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000>
  %172 = fmul <4 x float> %167, %171
  %173 = fadd <4 x float> %172, <float 0x3E6B800820000000, float 0x3E6B800820000000, float 0x3E6B800820000000, float 0x3E6B800820000000>
  %174 = fmul <4 x float> %167, %173
  %175 = fadd <4 x float> %174, <float 0x3EEF286940000000, float 0x3EEF286940000000, float 0x3EEF286940000000, float 0x3EEF286940000000>
  %176 = fmul <4 x float> %167, %175
  %177 = fadd <4 x float> %176, <float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000>
  %178 = fmul <4 x float> %167, %177
  %179 = fadd <4 x float> %178, <float 0x3F740B3B80000000, float 0x3F740B3B80000000, float 0x3F740B3B80000000, float 0x3F740B3B80000000>
  %180 = fmul <4 x float> %162, %179
  %181 = fmul <4 x float> %167, <float 0x3EB41A7B00000000, float 0x3EB41A7B00000000, float 0x3EB41A7B00000000, float 0x3EB41A7B00000000>
  %182 = fadd <4 x float> %181, <float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000>
  %183 = fmul <4 x float> %167, %182
  %184 = fadd <4 x float> %183, <float 0x3F629540A0000000, float 0x3F629540A0000000, float 0x3F629540A0000000, float 0x3F629540A0000000>
  %185 = fmul <4 x float> %167, %184
  %186 = fadd <4 x float> %185, <float 0x3F740B3BA0000000, float 0x3F740B3BA0000000, float 0x3F740B3BA0000000, float 0x3F740B3BA0000000>
  %187 = fdiv <4 x float> %180, %186
  %188 = select <4 x i1> %166, <4 x float> %187, <4 x float> %162
  %189 = fmul <4 x float> %151, %188
  %190 = bitcast float* %78 to <4 x float>*
  store <4 x float> %189, <4 x float>* %190, align 16
  %191 = add nsw i64 %70, 4
  %192 = icmp slt i64 %191, %59
  br i1 %192, label %69, label %67

193:                                              ; preds = %200, %67
  %194 = add nsw i64 %56, %43
  %195 = srem i64 %194, 4
  %196 = icmp slt i64 %39, %195
  %197 = select i1 %196, i64 %39, i64 %195
  %198 = add nuw nsw i64 %55, 1
  %199 = icmp eq i64 %198, %41
  br i1 %199, label %204, label %54

200:                                              ; preds = %67, %200
  %201 = phi i64 [ %202, %200 ], [ %59, %67 ]
  tail call void @_ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS8_Lin1ELin1ELb0EEEEEKNSD_INS0_14scalar_tanh_opIfEEKS8_EEEEEENS0_9assign_opIffEELi0EE23assignCoeffByOuterInnerEll(%"class.Eigen::internal::generic_dense_assignment_kernel.223"* %0, i64 %55, i64 %201)
  %202 = add i64 %201, 1
  %203 = icmp eq i64 %202, %39
  br i1 %203, label %193, label %200

204:                                              ; preds = %22, %193, %37, %9
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_5ArrayIfLin1ELin1ELi0ELin1ELin1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIffEEKNS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKNS_5BlockIS8_Lin1ELin1ELb0EEEEEKNSD_INS0_14scalar_tanh_opIfEEKS8_EEEEEENS0_9assign_opIffEELi0EE23assignCoeffByOuterInnerEll(%"class.Eigen::internal::generic_dense_assignment_kernel.223"*, i64, i64) local_unnamed_addr #5 comdat align 2 {
  %4 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %0 to %"struct.Eigen::internal::mapbase_evaluator.207"**
  %5 = load %"struct.Eigen::internal::mapbase_evaluator.207"*, %"struct.Eigen::internal::mapbase_evaluator.207"** %4, align 8
  %6 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %5, i64 0, i32 0
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %"struct.Eigen::internal::mapbase_evaluator.207", %"struct.Eigen::internal::mapbase_evaluator.207"* %5, i64 0, i32 2, i32 0
  %9 = load i64, i64* %8, align 8
  %10 = mul nsw i64 %9, %1
  %11 = add nsw i64 %10, %2
  %12 = getelementptr inbounds float, float* %7, i64 %11
  %13 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel.223", %"class.Eigen::internal::generic_dense_assignment_kernel.223"* %0, i64 0, i32 1
  %14 = bitcast %"struct.Eigen::internal::evaluator.213"** %13 to %"struct.Eigen::internal::binary_evaluator.214"**
  %15 = load %"struct.Eigen::internal::binary_evaluator.214"*, %"struct.Eigen::internal::binary_evaluator.214"** %14, align 8
  %16 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator.214", %"struct.Eigen::internal::binary_evaluator.214"* %15, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %17 = load float*, float** %16, align 8
  %18 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator.214", %"struct.Eigen::internal::binary_evaluator.214"* %15, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %19 = load i64, i64* %18, align 8
  %20 = mul nsw i64 %19, %1
  %21 = add nsw i64 %20, %2
  %22 = getelementptr inbounds float, float* %17, i64 %21
  %23 = load float, float* %22, align 4
  %24 = fcmp olt float %23, -9.000000e+00
  %25 = fcmp ogt float %23, 0x402F499C60000000
  %26 = select i1 %25, float 0x402F499C60000000, float %23
  %27 = fmul float %26, %26
  %28 = fmul float %27, 0x3DC806AA20000000
  %29 = fadd float %28, 0x3E7F09D960000000
  %30 = fmul float %27, %29
  %31 = fadd float %30, 0x3F0FE82760000000
  %32 = fmul float %27, %31
  %33 = fadd float %32, 0x3F816FAB00000000
  %34 = fmul float %27, %33
  %35 = fadd float %34, 0x3FCFC7E640000000
  %36 = fmul float %26, %35
  %37 = fmul float %27, 0x3D65789EA0000000
  %38 = fadd float %37, 0x3E38BE4F60000000
  %39 = fmul float %27, %38
  %40 = fadd float %39, 0x3EDA62FBA0000000
  %41 = fmul float %27, %40
  %42 = fadd float %41, 0x3F5BE2A7E0000000
  %43 = fmul float %27, %42
  %44 = fadd float %43, 0x3FBDE7C300000000
  %45 = fmul float %27, %44
  %46 = fadd float %45, 0x3FEFC7E680000000
  %47 = fdiv float %36, %46
  %48 = fadd float %47, 5.000000e-01
  br i1 %24, label %49, label %79, !prof !250

49:                                               ; preds = %3
  %50 = fcmp ogt float %23, 0x40561814C0000000
  %51 = select i1 %50, float 0x40561814C0000000, float %23
  %52 = fcmp olt float %51, 0xC0561814A0000000
  %53 = select i1 %52, float 0xC0561814A0000000, float %51
  %54 = fmul float %53, 0x3FF7154760000000
  %55 = fadd float %54, 5.000000e-01
  %56 = tail call float @llvm.floor.f32(float %55) #18
  %57 = fmul float %56, 0x3FE6300000000000
  %58 = fsub float %53, %57
  %59 = fmul float %56, 0x3F2BD01060000000
  %60 = fadd float %59, %58
  %61 = fmul float %60, %60
  %62 = fmul float %60, 0x3F2A0D2CE0000000
  %63 = fadd float %62, 0x3F56E879C0000000
  %64 = fmul float %60, %63
  %65 = fadd float %64, 0x3F81112100000000
  %66 = fmul float %60, %65
  %67 = fadd float %66, 0x3FA5553820000000
  %68 = fmul float %60, %67
  %69 = fadd float %68, 0x3FC5555540000000
  %70 = fmul float %60, %69
  %71 = fadd float %70, 5.000000e-01
  %72 = fmul float %61, %71
  %73 = fadd float %60, %72
  %74 = fadd float %73, 1.000000e+00
  %75 = fptosi float %56 to i32
  %76 = tail call float @ldexpf(float %74, i32 %75) #18
  %77 = fcmp olt float %76, %23
  %78 = select i1 %77, float %23, float %76
  br label %79

79:                                               ; preds = %3, %49
  %80 = phi float [ %78, %49 ], [ %48, %3 ]
  %81 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator.214", %"struct.Eigen::internal::binary_evaluator.214"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %82 = load float*, float** %81, align 8
  %83 = getelementptr inbounds %"struct.Eigen::internal::binary_evaluator.214", %"struct.Eigen::internal::binary_evaluator.214"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %84 = load i64, i64* %83, align 8
  %85 = mul nsw i64 %84, %1
  %86 = add nsw i64 %85, %2
  %87 = getelementptr inbounds float, float* %82, i64 %86
  %88 = load float, float* %87, align 4
  %89 = fcmp ogt float %88, 0x401F9F09E0000000
  %90 = select i1 %89, float 0x401F9F09E0000000, float %88
  %91 = fcmp olt float %90, 0xC01F9F09E0000000
  %92 = select i1 %91, float 0xC01F9F09E0000000, float %90
  %93 = tail call float @llvm.fabs.f32(float %88) #18
  %94 = fcmp olt float %93, 0x3F3A36E2E0000000
  %95 = select i1 %94, float 0xFFFFFFFFE0000000, float 0.000000e+00
  %96 = fmul float %92, %92
  %97 = fmul float %96, 0x3CB3E4B800000000
  %98 = fsub float 0x3D4C266FC0000000, %97
  %99 = fmul float %96, %98
  %100 = fadd float %99, 0xBDD7A6FFE0000000
  %101 = fmul float %96, %100
  %102 = fadd float %101, 0x3E6B800820000000
  %103 = fmul float %96, %102
  %104 = fadd float %103, 0x3EEF286940000000
  %105 = fmul float %96, %104
  %106 = fadd float %105, 0x3F44E1BDA0000000
  %107 = fmul float %96, %106
  %108 = fadd float %107, 0x3F740B3B80000000
  %109 = fmul float %92, %108
  %110 = fmul float %96, 0x3EB41A7B00000000
  %111 = fadd float %110, 0x3F1F12BAC0000000
  %112 = fmul float %96, %111
  %113 = fadd float %112, 0x3F629540A0000000
  %114 = fmul float %96, %113
  %115 = fadd float %114, 0x3F740B3BA0000000
  %116 = fdiv float %109, %115
  %117 = fcmp oeq float %95, 0.000000e+00
  %118 = select i1 %117, float %116, float %92
  %119 = fmul float %80, %118
  store float %119, float* %12, align 4
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite3ops7builtin9lstm_eval20IntegerLstmParameterD2Ev(%"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"*) unnamed_addr #5 comdat align 2 {
  %2 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 50, i32 0, i32 0, i32 0
  %3 = load i32*, i32** %2, align 8
  store i32* null, i32** %2, align 8
  %4 = icmp eq i32* %3, null
  br i1 %4, label %7, label %5

5:                                                ; preds = %1
  %6 = bitcast i32* %3 to i8*
  tail call void @_ZdaPv(i8* %6) #17
  br label %7

7:                                                ; preds = %1, %5
  %8 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 49, i32 0, i32 0, i32 0
  %9 = load i32*, i32** %8, align 8
  store i32* null, i32** %8, align 8
  %10 = icmp eq i32* %9, null
  br i1 %10, label %13, label %11

11:                                               ; preds = %7
  %12 = bitcast i32* %9 to i8*
  tail call void @_ZdaPv(i8* %12) #17
  br label %13

13:                                               ; preds = %7, %11
  %14 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 48, i32 0, i32 0, i32 0
  %15 = load i32*, i32** %14, align 8
  store i32* null, i32** %14, align 8
  %16 = icmp eq i32* %15, null
  br i1 %16, label %19, label %17

17:                                               ; preds = %13
  %18 = bitcast i32* %15 to i8*
  tail call void @_ZdaPv(i8* %18) #17
  br label %19

19:                                               ; preds = %13, %17
  %20 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 47, i32 0, i32 0, i32 0
  %21 = load i32*, i32** %20, align 8
  store i32* null, i32** %20, align 8
  %22 = icmp eq i32* %21, null
  br i1 %22, label %25, label %23

23:                                               ; preds = %19
  %24 = bitcast i32* %21 to i8*
  tail call void @_ZdaPv(i8* %24) #17
  br label %25

25:                                               ; preds = %19, %23
  %26 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 46, i32 0, i32 0, i32 0
  %27 = load i32*, i32** %26, align 8
  store i32* null, i32** %26, align 8
  %28 = icmp eq i32* %27, null
  br i1 %28, label %31, label %29

29:                                               ; preds = %25
  %30 = bitcast i32* %27 to i8*
  tail call void @_ZdaPv(i8* %30) #17
  br label %31

31:                                               ; preds = %25, %29
  %32 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 45, i32 0, i32 0, i32 0
  %33 = load i32*, i32** %32, align 8
  store i32* null, i32** %32, align 8
  %34 = icmp eq i32* %33, null
  br i1 %34, label %37, label %35

35:                                               ; preds = %31
  %36 = bitcast i32* %33 to i8*
  tail call void @_ZdaPv(i8* %36) #17
  br label %37

37:                                               ; preds = %31, %35
  %38 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 44, i32 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8
  store i32* null, i32** %38, align 8
  %40 = icmp eq i32* %39, null
  br i1 %40, label %43, label %41

41:                                               ; preds = %37
  %42 = bitcast i32* %39 to i8*
  tail call void @_ZdaPv(i8* %42) #17
  br label %43

43:                                               ; preds = %37, %41
  %44 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 43, i32 0, i32 0, i32 0
  %45 = load i32*, i32** %44, align 8
  store i32* null, i32** %44, align 8
  %46 = icmp eq i32* %45, null
  br i1 %46, label %49, label %47

47:                                               ; preds = %43
  %48 = bitcast i32* %45 to i8*
  tail call void @_ZdaPv(i8* %48) #17
  br label %49

49:                                               ; preds = %43, %47
  %50 = getelementptr inbounds %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter", %"struct.tflite::ops::builtin::lstm_eval::IntegerLstmParameter"* %0, i64 0, i32 42, i32 0, i32 0, i32 0
  %51 = load i32*, i32** %50, align 8
  store i32* null, i32** %50, align 8
  %52 = icmp eq i32* %51, null
  br i1 %52, label %55, label %53

53:                                               ; preds = %49
  %54 = bitcast i32* %51 to i8*
  tail call void @_ZdaPv(i8* %54) #17
  br label %55

55:                                               ; preds = %49, %53
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.224"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* dereferenceable(16), i16*, %"struct.tflite::cpu_backend_gemm::GemmParams.228"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"struct.ruy::Mat.237", align 8
  %10 = alloca %"struct.ruy::Mat.237", align 8
  %11 = alloca %"struct.ruy::Mat.238", align 8
  %12 = alloca %"class.ruy::MulParams.236", align 8
  %13 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 4
  %14 = load i8, i8* %13, align 4, !range !5
  %15 = icmp ne i8 %14, 0
  %16 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = icmp ne i32 %17, 0
  %19 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 2
  %22 = load i32, i32* %21, align 4
  %23 = select i1 %18, i32 %22, i32 %20
  %24 = ptrtoint i8* %1 to i64
  %25 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 3
  %26 = load i8, i8* %25, align 4
  br i1 %15, label %27, label %34

27:                                               ; preds = %8
  %28 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 4
  %29 = load i8, i8* %28, align 1
  %30 = icmp eq i8 %29, 1
  %31 = zext i1 %30 to i8
  %32 = icmp eq i8 %29, 2
  %33 = select i1 %32, i8 3, i8 %31
  br label %34

34:                                               ; preds = %8, %27
  %35 = phi i8 [ %33, %27 ], [ 0, %8 ]
  %36 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = icmp ne i32 %37, 0
  %39 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 1
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 2
  %42 = load i32, i32* %41, align 4
  %43 = select i1 %38, i32 %42, i32 %40
  %44 = ptrtoint i8* %3 to i64
  %45 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 3
  %46 = load i8, i8* %45, align 4
  br i1 %15, label %47, label %54

47:                                               ; preds = %34
  %48 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 4
  %49 = load i8, i8* %48, align 1
  %50 = icmp eq i8 %49, 1
  %51 = zext i1 %50 to i8
  %52 = icmp eq i8 %49, 2
  %53 = select i1 %52, i8 3, i8 %51
  br label %54

54:                                               ; preds = %34, %47
  %55 = phi i8 [ %53, %47 ], [ 0, %34 ]
  %56 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %4, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = icmp ne i32 %57, 0
  %59 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %4, i64 0, i32 1
  %60 = load i32, i32* %59, align 4
  %61 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %4, i64 0, i32 2
  %62 = load i32, i32* %61, align 4
  %63 = select i1 %58, i32 %62, i32 %60
  %64 = ptrtoint i16* %5 to i64
  %65 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %4, i64 0, i32 3
  %66 = load i16, i16* %65, align 4
  %67 = bitcast %"class.ruy::MulParams.236"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %67) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %67, i8 -86, i64 40, i1 false)
  %68 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %12, i64 0, i32 5
  %69 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %12, i64 0, i32 6
  %70 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 0
  %71 = load i32, i32* %70, align 8
  %72 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %12, i64 0, i32 1
  store i32 %71, i32* %72, align 8
  %73 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 1
  %74 = load i32, i32* %73, align 4
  %75 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %12, i64 0, i32 2
  store i32 %74, i32* %75, align 4
  %76 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 2
  %77 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %12, i64 0, i32 3
  %78 = bitcast i32** %76 to <2 x i64>*
  %79 = load <2 x i64>, <2 x i64>* %78, align 8
  %80 = bitcast i32** %77 to <2 x i64>*
  store <2 x i64> %79, <2 x i64>* %80, align 8
  %81 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 4
  %82 = bitcast i32** %81 to i64*
  %83 = load i64, i64* %82, align 8
  %84 = bitcast %"class.ruy::MulParams.236"* %12 to i64*
  store i64 %83, i64* %84, align 8
  %85 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 5
  %86 = load i16, i16* %85, align 8
  store i16 %86, i16* %68, align 8
  %87 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 6
  %88 = load i16, i16* %87, align 2
  store i16 %88, i16* %69, align 2
  %89 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 1, i32 0, i32 0, i32 0
  %90 = load %"class.ruy::Context"*, %"class.ruy::Context"** %89, align 8
  %91 = bitcast %"struct.ruy::Mat.237"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %91) #18
  %92 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %9, i64 0, i32 1, i32 2
  %93 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %9, i64 0, i32 2
  %94 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %9, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %91, i8 -86, i64 32, i1 false) #18
  %95 = bitcast %"struct.ruy::Mat.237"* %9 to i64*
  store i64 %24, i64* %95, align 8, !alias.scope !251
  %96 = zext i32 %23 to i64
  %97 = zext i1 %18 to i64
  %98 = shl nuw nsw i64 %97, 32
  %99 = or i64 %98, %96
  %100 = zext i32 %22 to i64
  %101 = shl nuw i64 %100, 32
  %102 = zext i32 %20 to i64
  %103 = or i64 %101, %102
  %104 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %9, i64 0, i32 1
  %105 = bitcast %"struct.ruy::MatLayout"* %104 to i64*
  store i64 %103, i64* %105, align 8, !alias.scope !251
  %106 = bitcast i32* %92 to i40*
  %107 = trunc i64 %99 to i40
  store i40 %107, i40* %106, align 8, !alias.scope !251
  store i8 %26, i8* %93, align 8, !alias.scope !251
  store i8 %35, i8* %94, align 1, !alias.scope !251
  %108 = bitcast %"struct.ruy::Mat.237"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %108) #18
  %109 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %10, i64 0, i32 1, i32 2
  %110 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %10, i64 0, i32 2
  %111 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %10, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %108, i8 -86, i64 32, i1 false) #18
  %112 = bitcast %"struct.ruy::Mat.237"* %10 to i64*
  store i64 %44, i64* %112, align 8, !alias.scope !254
  %113 = zext i32 %43 to i64
  %114 = zext i1 %38 to i64
  %115 = shl nuw nsw i64 %114, 32
  %116 = or i64 %115, %113
  %117 = zext i32 %42 to i64
  %118 = shl nuw i64 %117, 32
  %119 = zext i32 %40 to i64
  %120 = or i64 %118, %119
  %121 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %10, i64 0, i32 1
  %122 = bitcast %"struct.ruy::MatLayout"* %121 to i64*
  store i64 %120, i64* %122, align 8, !alias.scope !254
  %123 = bitcast i32* %109 to i40*
  %124 = trunc i64 %116 to i40
  store i40 %124, i40* %123, align 8, !alias.scope !254
  store i8 %46, i8* %110, align 8, !alias.scope !254
  store i8 %55, i8* %111, align 1, !alias.scope !254
  %125 = bitcast %"struct.ruy::Mat.238"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %125) #18
  %126 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %11, i64 0, i32 1, i32 2
  %127 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %11, i64 0, i32 2
  %128 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %11, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %125, i8 -86, i64 32, i1 false) #18
  %129 = bitcast %"struct.ruy::Mat.238"* %11 to i64*
  store i64 %64, i64* %129, align 8, !alias.scope !257
  %130 = zext i32 %63 to i64
  %131 = zext i1 %58 to i64
  %132 = shl nuw nsw i64 %131, 32
  %133 = or i64 %132, %130
  %134 = zext i32 %62 to i64
  %135 = shl nuw i64 %134, 32
  %136 = zext i32 %60 to i64
  %137 = or i64 %135, %136
  %138 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %11, i64 0, i32 1
  %139 = bitcast %"struct.ruy::MatLayout"* %138 to i64*
  store i64 %137, i64* %139, align 8, !alias.scope !257
  %140 = bitcast i32* %126 to i40*
  %141 = trunc i64 %133 to i40
  store i40 %141, i40* %140, align 8, !alias.scope !257
  store i16 %66, i16* %127, align 8, !alias.scope !257
  store i8 0, i8* %128, align 2, !alias.scope !257
  %142 = tail call %"class.ruy::Ctx"* @_ZN3ruy7get_ctxEPNS_7ContextE(%"class.ruy::Context"* %90) #18
  call void @_ZN3ruy11DispatchMulILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat.237"* nonnull dereferenceable(32) %9, %"struct.ruy::Mat.237"* nonnull dereferenceable(32) %10, %"class.ruy::MulParams.236"* nonnull dereferenceable(40) %12, %"class.ruy::Ctx"* %142, %"struct.ruy::Mat.238"* nonnull %11) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %125) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %108) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %91) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %67) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.224"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* dereferenceable(16), i16*, %"struct.tflite::cpu_backend_gemm::GemmParams.228"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %13 = alloca %"class.gemmlowp::MatrixMap", align 8
  %14 = alloca %"class.gemmlowp::MatrixMap.258", align 8
  %15 = alloca %"class.gemmlowp::MatrixMap.260", align 8
  %16 = alloca %"class.std::__1::tuple", align 8
  %17 = alloca %"class.std::__1::tuple.265", align 4
  %18 = bitcast %"class.gemmlowp::MatrixMap"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %18) #18
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 0
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 1
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 2
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 3
  %23 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 1
  %24 = bitcast %"class.gemmlowp::MatrixMap"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %24, i8 -86, i64 24, i1 false)
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 2
  %27 = load i32, i32* %26, align 4
  store i8* %1, i8** %19, align 8
  store i32 %25, i32* %20, align 8
  store i32 %27, i32* %21, align 4
  store i32 %27, i32* %22, align 8
  %28 = bitcast %"class.gemmlowp::MatrixMap.258"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %28) #18
  %29 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %14, i64 0, i32 0
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %14, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %14, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %14, i64 0, i32 3
  %33 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 1
  %34 = bitcast %"class.gemmlowp::MatrixMap.258"* %14 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i32, i32* %33, align 4
  %36 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 2
  %37 = load i32, i32* %36, align 4
  store i8* %3, i8** %29, align 8
  store i32 %35, i32* %30, align 8
  store i32 %37, i32* %31, align 4
  store i32 %35, i32* %32, align 8
  %38 = bitcast %"class.gemmlowp::MatrixMap.260"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %38) #18
  %39 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %15, i64 0, i32 0
  %40 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %15, i64 0, i32 1
  %41 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %15, i64 0, i32 2
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %15, i64 0, i32 3
  %43 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %4, i64 0, i32 1
  %44 = bitcast %"class.gemmlowp::MatrixMap.260"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 24, i1 false)
  %45 = load i32, i32* %43, align 4
  %46 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %4, i64 0, i32 2
  %47 = load i32, i32* %46, align 4
  store i16* %5, i16** %39, align 8
  store i32 %45, i32* %40, align 8
  store i32 %47, i32* %41, align 4
  store i32 %45, i32* %42, align 8
  %48 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.226", %"struct.tflite::cpu_backend_gemm::MatrixParams.226"* %4, i64 0, i32 3
  %49 = load i16, i16* %48, align 4
  %50 = sext i16 %49 to i32
  %51 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 0
  %52 = load i32, i32* %51, align 8
  %53 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 1
  %54 = load i32, i32* %53, align 4
  %55 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 5
  %56 = load i16, i16* %55, align 8
  %57 = sext i16 %56 to i32
  %58 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 6
  %59 = load i16, i16* %58, align 2
  %60 = sext i16 %59 to i32
  %61 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.228", %"struct.tflite::cpu_backend_gemm::GemmParams.228"* %6, i64 0, i32 4
  %62 = load i32*, i32** %61, align 8
  %63 = icmp eq i32* %62, null
  br i1 %63, label %94, label %64

64:                                               ; preds = %8
  %65 = ptrtoint i32* %62 to i64
  %66 = bitcast %"class.std::__1::tuple"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %66) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %66, i8 -86, i64 40, i1 false)
  %67 = bitcast %"class.std::__1::tuple"* %16 to i64*
  store i64 %65, i64* %67, align 8, !alias.scope !260
  %68 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %25, i32* %68, align 8, !alias.scope !260
  %69 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 1, i32 0, i32 0
  store i32 %52, i32* %69, align 8
  %70 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 1, i32 0, i32 1
  store i32 %54, i32* %70, align 4
  %71 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %50, i32* %71, align 8
  %72 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 2
  %73 = bitcast %"class.std::__1::__tuple_leaf.263"* %72 to i64*
  %74 = zext i32 %60 to i64
  %75 = shl nuw i64 %74, 32
  %76 = zext i32 %57 to i64
  %77 = or i64 %75, %76
  store i64 %77, i64* %73, align 4, !alias.scope !260
  %78 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 2, i32 0, i32 0, i32 0
  %79 = load %"class.gemmlowp::GemmContext"*, %"class.gemmlowp::GemmContext"** %78, align 8
  %80 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 3
  %81 = load i8, i8* %80, align 4
  %82 = zext i8 %81 to i32
  %83 = sub nsw i32 0, %82
  %84 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 3
  %85 = load i8, i8* %84, align 4
  %86 = zext i8 %85 to i32
  %87 = sub nsw i32 0, %86
  %88 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %88) #18
  %89 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  store i32 %83, i32* %89, align 4
  store i32 %25, i32* %90, align 4
  %91 = bitcast %"class.gemmlowp::VectorDup.272"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %91) #18
  %92 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %10, i64 0, i32 0
  %93 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %10, i64 0, i32 1
  store i32 %87, i32* %92, align 4
  store i32 %37, i32* %93, align 4
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %79, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %13, %"class.gemmlowp::MatrixMap.258"* nonnull dereferenceable(24) %14, %"class.gemmlowp::MatrixMap.260"* nonnull %15, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %10, %"class.std::__1::tuple"* nonnull dereferenceable(40) %16) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %91) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %88) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %66) #18
  br label %121

94:                                               ; preds = %8
  %95 = bitcast %"class.std::__1::tuple.265"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %95) #18
  %96 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %97 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %98 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %52, i32* %96, align 4
  store i32 %54, i32* %97, align 4
  store i32 %50, i32* %98, align 4
  %99 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %17, i64 0, i32 0, i32 1
  %100 = bitcast %"class.std::__1::__tuple_leaf.268"* %99 to i64*
  %101 = zext i32 %60 to i64
  %102 = shl nuw i64 %101, 32
  %103 = zext i32 %57 to i64
  %104 = or i64 %102, %103
  store i64 %104, i64* %100, align 4, !alias.scope !263
  %105 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 2, i32 0, i32 0, i32 0
  %106 = load %"class.gemmlowp::GemmContext"*, %"class.gemmlowp::GemmContext"** %105, align 8
  %107 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %0, i64 0, i32 3
  %108 = load i8, i8* %107, align 4
  %109 = zext i8 %108 to i32
  %110 = sub nsw i32 0, %109
  %111 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.224", %"struct.tflite::cpu_backend_gemm::MatrixParams.224"* %2, i64 0, i32 3
  %112 = load i8, i8* %111, align 4
  %113 = zext i8 %112 to i32
  %114 = sub nsw i32 0, %113
  %115 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %115) #18
  %116 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %117 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  store i32 %110, i32* %116, align 4
  store i32 %25, i32* %117, align 4
  %118 = bitcast %"class.gemmlowp::VectorDup.272"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %118) #18
  %119 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %12, i64 0, i32 0
  %120 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %12, i64 0, i32 1
  store i32 %114, i32* %119, align 4
  store i32 %37, i32* %120, align 4
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %106, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %13, %"class.gemmlowp::MatrixMap.258"* nonnull dereferenceable(24) %14, %"class.gemmlowp::MatrixMap.260"* nonnull %15, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.265"* nonnull dereferenceable(20) %17) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %118) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %115) #18
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %95) #18
  br label %121

121:                                              ; preds = %94, %64
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %38) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %28) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy11DispatchMulILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat.237"* dereferenceable(32), %"struct.ruy::Mat.237"* dereferenceable(32), %"class.ruy::MulParams.236"* dereferenceable(40), %"class.ruy::Ctx"*, %"struct.ruy::Mat.238"*) local_unnamed_addr #1 comdat {
  %6 = alloca %"struct.ruy::Mat.237", align 8
  %7 = alloca %"struct.ruy::TrMulParams", align 8
  %8 = tail call zeroext i8 @_ZN3ruy3Ctx10SelectPathENS_4PathE(%"class.ruy::Ctx"* %3, i8 zeroext 26) #18
  %9 = bitcast %"struct.ruy::Mat.237"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #18
  %10 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %6, i64 0, i32 1, i32 0
  %11 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %6, i64 0, i32 1, i32 1
  %12 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %6, i64 0, i32 1, i32 3
  %13 = bitcast %"struct.ruy::Mat.237"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %9, i8* align 8 %13, i64 32, i1 false)
  %14 = load i8, i8* %12, align 4
  %15 = icmp eq i8 %14, 0
  %16 = zext i1 %15 to i8
  store i8 %16, i8* %12, align 4
  %17 = load i32, i32* %10, align 8
  %18 = load i32, i32* %11, align 4
  store i32 %18, i32* %10, align 8
  store i32 %17, i32* %11, align 4
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 280, i8* nonnull %19) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %19, i8 -86, i64 272, i1 false)
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 1
  %21 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 2
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 5
  store i8 0, i8* %23, align 4
  %24 = bitcast i8** %21 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %24, i8 0, i64 21, i1 false) #18
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %25, align 8
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %27, align 2
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 2
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 0, i32* %29, align 8
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 5
  store i8 0, i8* %30, align 4
  %31 = bitcast i8** %28 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %31, i8 0, i64 21, i1 false) #18
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 0
  store i8 0, i8* %32, align 8
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 1
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 2
  store i8 0, i8* %34, align 2
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 2
  %36 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 4
  store i32 0, i32* %36, align 8
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 5
  store i8 0, i8* %37, align 4
  %38 = bitcast i8** %35 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %38, i8 0, i64 21, i1 false) #18
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 0
  store i8 0, i8* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 1
  store i8 0, i8* %40, align 1
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 2
  store i8 0, i8* %41, align 2
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 2
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 5
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  %45 = bitcast i8** %42 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %45, i8 0, i64 11, i1 false) #18
  %46 = bitcast i8** %43 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %46, i8 0, i64 22, i1 false) #18
  %47 = bitcast %"class.ruy::SidePair"* %20 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %47, i8 0, i64 27, i1 false) #18
  store i8 1, i8* %44, align 1
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %48, align 1
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 0, i32* %49, align 8
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %50, align 8
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %51, align 1
  %52 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %52, align 2
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 2
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 5
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  %56 = bitcast i8** %53 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %56, i8 0, i64 11, i1 false) #18
  %57 = bitcast i8** %54 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %57, i8 0, i64 22, i1 false) #18
  store i8 1, i8* %55, align 1
  %58 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %58, align 1
  %59 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 0, i32* %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 6, i32 0, i64 0
  store i8 0, i8* %60, align 8
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 6, i32 0, i64 1
  store i8 0, i8* %61, align 1
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 7
  store i8* null, i8** %62, align 8
  call void @_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE(%"struct.ruy::Mat.237"* nonnull dereferenceable(32) %6, %"struct.ruy::Mat.237"* dereferenceable(32) %1, %"class.ruy::MulParams.236"* dereferenceable(40) %2, %"struct.ruy::Mat.238"* %4, i8 zeroext %8, %"struct.ruy::TrMulParams"* nonnull %7)
  call void @_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %7, %"class.ruy::Ctx"* %3)
  call void @_ZN3ruy5TrMulEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %7, %"class.ruy::Ctx"* %3) #18
  call void @llvm.lifetime.end.p0i8(i64 280, i8* nonnull %19) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE(%"struct.ruy::Mat.237"* dereferenceable(32), %"struct.ruy::Mat.237"* dereferenceable(32), %"class.ruy::MulParams.236"* dereferenceable(40), %"struct.ruy::Mat.238"*, i8 zeroext, %"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %7 = alloca [13 x i8], align 8
  %8 = alloca [13 x i8], align 8
  %9 = alloca [13 x i8], align 8
  %10 = getelementptr inbounds [13 x i8], [13 x i8]* %9, i64 0, i64 0
  %11 = getelementptr inbounds [13 x i8], [13 x i8]* %8, i64 0, i64 0
  %12 = getelementptr inbounds [13 x i8], [13 x i8]* %7, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %12)
  %13 = bitcast %"struct.ruy::Mat.237"* %0 to i64*
  %14 = load i64, i64* %13, align 8, !noalias !266
  %15 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %0, i64 0, i32 1
  %16 = bitcast %"struct.ruy::MatLayout"* %15 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %12, i8* align 4 %16, i64 13, i1 false)
  %17 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %0, i64 0, i32 2
  %18 = load i8, i8* %17, align 8, !noalias !266
  %19 = zext i8 %18 to i32
  %20 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %0, i64 0, i32 3
  %21 = load i8, i8* %20, align 1, !noalias !266
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3
  %23 = bitcast %"class.ruy::SidePair.130"* %22 to i24*
  store i24 65536, i24* %23, align 8
  %24 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %24, i8 -86, i64 5, i1 false)
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 2
  %26 = bitcast i8** %25 to i64*
  store i64 %14, i64* %26, align 8
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3
  %28 = bitcast %"struct.ruy::MatLayout"* %27 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %28, i8* nonnull align 8 %12, i64 13, i1 false)
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %29, i8 -86, i64 3, i1 false)
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 4
  store i32 %19, i32* %30, align 8
  %31 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 5
  store i8 %21, i8* %31, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %12)
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %11)
  %32 = bitcast %"struct.ruy::Mat.237"* %1 to i64*
  %33 = load i64, i64* %32, align 8, !noalias !269
  %34 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %1, i64 0, i32 1
  %35 = bitcast %"struct.ruy::MatLayout"* %34 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %11, i8* align 4 %35, i64 13, i1 false)
  %36 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %1, i64 0, i32 2
  %37 = load i8, i8* %36, align 8, !noalias !269
  %38 = zext i8 %37 to i32
  %39 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %1, i64 0, i32 3
  %40 = load i8, i8* %39, align 1, !noalias !269
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1
  %42 = bitcast %"struct.ruy::EMat"* %41 to i24*
  store i24 65536, i24* %42, align 8
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %43, i8 -86, i64 5, i1 false)
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 2
  %45 = bitcast i8** %44 to i64*
  store i64 %33, i64* %45, align 8
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3
  %47 = bitcast %"struct.ruy::MatLayout"* %46 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %47, i8* nonnull align 8 %11, i64 13, i1 false)
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %48, i8 -86, i64 3, i1 false)
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 %38, i32* %49, align 8
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 5
  store i8 %40, i8* %50, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %11)
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %10)
  %51 = bitcast %"struct.ruy::Mat.238"* %3 to i64*
  %52 = load i64, i64* %51, align 8, !noalias !272
  %53 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %3, i64 0, i32 1
  %54 = bitcast %"struct.ruy::MatLayout"* %53 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* align 4 %54, i64 13, i1 false)
  %55 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %3, i64 0, i32 2
  %56 = load i16, i16* %55, align 8, !noalias !272
  %57 = sext i16 %56 to i32
  %58 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %3, i64 0, i32 3
  %59 = load i8, i8* %58, align 2, !noalias !272
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4
  %61 = bitcast %"struct.ruy::EMat"* %60 to i24*
  store i24 131073, i24* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %62, i8 -86, i64 5, i1 false)
  %63 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 2
  %64 = bitcast i8** %63 to i64*
  store i64 %52, i64* %64, align 8
  %65 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 3
  %66 = bitcast %"struct.ruy::MatLayout"* %65 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %66, i8* nonnull align 8 %10, i64 13, i1 false)
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %67, i8 -86, i64 3, i1 false)
  %68 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 4
  store i32 %57, i32* %68, align 8
  %69 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 5
  store i8 %59, i8* %69, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %10)
  %70 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 7
  %71 = bitcast i8** %70 to %"class.ruy::MulParams.236"**
  store %"class.ruy::MulParams.236"* %2, %"class.ruy::MulParams.236"** %71, align 8
  switch i8 %4, label %119 [
    i8 16, label %72
    i8 8, label %73
    i8 2, label %74
  ]

72:                                               ; preds = %6
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %5) #18
  br label %119

73:                                               ; preds = %6
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %5) #18
  br label %119

74:                                               ; preds = %6
  %75 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 0
  store i8 2, i8* %75, align 8
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0
  %77 = bitcast %"struct.ruy::PEMat"* %76 to i24*
  store i24 65536, i24* %77, align 8
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 3
  %79 = bitcast %"struct.ruy::Type"* %78 to i24*
  store i24 262145, i24* %79, align 8
  %80 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %80, align 4
  %81 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %82 = load i32, i32* %81, align 4
  %83 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %82, i32* %83, align 4
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %85, i32* %86, align 4
  %87 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %87, align 1
  %88 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %88, align 1
  %89 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %89, align 1
  %90 = and i32 %82, 1023
  %91 = icmp eq i32 %90, 0
  %92 = add nsw i32 %82, 64
  %93 = select i1 %91, i32 %92, i32 %82
  %94 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %93, i32* %94, align 4
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %19, i32* %95, align 8
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1
  %97 = bitcast %"struct.ruy::PEMat"* %96 to i24*
  store i24 65536, i24* %97, align 8
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 3
  %99 = bitcast %"struct.ruy::Type"* %98 to i24*
  store i24 262145, i24* %99, align 8
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %102 = load i32, i32* %101, align 4
  %103 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %102, i32* %103, align 4
  %104 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %105 = load i32, i32* %104, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %105, i32* %106, align 4
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %108, align 1
  %109 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %109, align 1
  %110 = and i32 %102, 1023
  %111 = icmp eq i32 %110, 0
  %112 = add nsw i32 %102, 64
  %113 = select i1 %111, i32 %112, i32 %102
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %113, i32* %114, align 4
  %115 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %38, i32* %115, align 8
  %116 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 1, i32 0, i64 0
  %117 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %116 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %117, align 8
  %118 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)** %118, align 8
  br label %119

119:                                              ; preds = %6, %74, %73, %72
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %60, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 65536, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262145, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 1023
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = and i32 %35, 255
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %36, i32* %37, align 8
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %39 = bitcast %"struct.ruy::PEMat"* %38 to i24*
  store i24 65536, i24* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %41 = bitcast %"struct.ruy::Type"* %40 to i24*
  store i24 262145, i24* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %42, align 4
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %44, i32* %45, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %47 = load i32, i32* %46, align 4
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %49, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %51, align 1
  %52 = and i32 %44, 1023
  %53 = icmp eq i32 %52, 0
  %54 = add nsw i32 %44, 64
  %55 = select i1 %53, i32 %54, i32 %44
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %55, i32* %56, align 4
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %58 = load i32, i32* %57, align 8
  %59 = and i32 %58, 255
  br label %119

60:                                               ; preds = %9
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 16, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %63 = bitcast %"struct.ruy::PEMat"* %62 to i24*
  store i24 65537, i24* %63, align 8
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %65 = bitcast %"struct.ruy::Type"* %64 to i24*
  store i24 262145, i24* %65, align 8
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %66, align 4
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = add i32 %68, 3
  %70 = and i32 %69, -4
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %73 = load i32, i32* %72, align 4
  %74 = add i32 %73, 15
  %75 = and i32 %74, -16
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %75, i32* %76, align 4
  %77 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %77, align 1
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 4, i8* %78, align 1
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 16, i8* %79, align 1
  %80 = and i32 %69, 1020
  %81 = icmp eq i32 %80, 0
  %82 = add nsw i32 %70, 64
  %83 = select i1 %81, i32 %82, i32 %70
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %86 = load i32, i32* %85, align 8
  %87 = shl i32 %86, 24
  %88 = ashr exact i32 %87, 24
  %89 = xor i32 %88, -128
  %90 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %89, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %92 = bitcast %"struct.ruy::PEMat"* %91 to i24*
  store i24 65537, i24* %92, align 8
  %93 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %94 = bitcast %"struct.ruy::Type"* %93 to i24*
  store i24 262145, i24* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %95, align 4
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %97 = load i32, i32* %96, align 4
  %98 = add i32 %97, 3
  %99 = and i32 %98, -4
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %99, i32* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %102 = load i32, i32* %101, align 4
  %103 = add i32 %102, 15
  %104 = and i32 %103, -16
  %105 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %104, i32* %105, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %106, align 1
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 4, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 16, i8* %108, align 1
  %109 = and i32 %98, 1020
  %110 = icmp eq i32 %109, 0
  %111 = add nsw i32 %99, 64
  %112 = select i1 %110, i32 %111, i32 %99
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %112, i32* %113, align 4
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %115 = load i32, i32* %114, align 8
  %116 = shl i32 %115, 24
  %117 = ashr exact i32 %116, 24
  %118 = xor i32 %117, -128
  br label %119

119:                                              ; preds = %60, %13
  %120 = phi i32 [ %118, %60 ], [ %59, %13 ]
  %121 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %60 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %122 = phi void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE16EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %60 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %120, i32* %123, align 8
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %124, align 8
  %125 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %125, align 8
  %126 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* %122, void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)** %126, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca [32 x i8], align 16
  %7 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %8 = load i8*, i8** %7, align 8, !noalias !275
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %16 = load i8*, i8** %15, align 8, !noalias !278
  %17 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %18 = bitcast i8** %17 to i32**
  %19 = load i32*, i32** %18, align 8, !noalias !278
  %20 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %23 = load i32, i32* %22, align 8, !noalias !278
  %24 = getelementptr inbounds [32 x i8], [32 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %24) #18
  %25 = trunc i32 %23 to i8
  %26 = xor i8 %25, -128
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %24, i8 %26, i64 32, i1 false) #18
  %27 = icmp slt i32 %3, %4
  br i1 %27, label %28, label %47

28:                                               ; preds = %5
  %29 = icmp eq i32* %19, null
  %30 = sext i32 %3 to i64
  %31 = sext i32 %4 to i64
  %32 = sext i32 %14 to i64
  br label %33

33:                                               ; preds = %33, %28
  %34 = phi i64 [ %30, %28 ], [ %45, %33 ]
  %35 = getelementptr inbounds i32, i32* %19, i64 %34
  %36 = select i1 %29, i32* null, i32* %35
  %37 = mul nsw i64 %34, %32
  %38 = getelementptr inbounds i8, i8* %8, i64 %37
  %39 = trunc i64 %34 to i32
  %40 = sub nsw i32 %12, %39
  %41 = and i32 %39, -16
  %42 = mul nsw i32 %41, %21
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i8, i8* %16, i64 %43
  call void @_ZN3ruy14Pack8bitAvx512EPKaaS1_iiiPaPi(i8* %38, i8 signext -128, i8* nonnull %24, i32 %14, i32 %40, i32 %10, i8* %44, i32* %36) #18
  %45 = add nsw i64 %34, 16
  %46 = icmp slt i64 %45, %31
  br i1 %46, label %33, label %47

47:                                               ; preds = %33, %5
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %24) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE16EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.128"* dereferenceable(112), i8*, %"class.ruy::SidePair.129"* dereferenceable(8), %"class.ruy::SidePair.129"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParams8bit", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = bitcast i8** %8 to i16**
  %10 = load i16*, i16** %9, align 8, !noalias !281
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %18 = load i32, i32* %17, align 8, !noalias !281
  %19 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 2
  %20 = load i8*, i8** %19, align 8, !noalias !284
  %21 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 5
  %22 = bitcast i8** %21 to i32**
  %23 = load i32*, i32** %22, align 8, !noalias !284
  %24 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 7
  %29 = load i32, i32* %28, align 8, !noalias !284
  %30 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 2
  %31 = load i8*, i8** %30, align 8, !noalias !287
  %32 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 5
  %33 = bitcast i8** %32 to i32**
  %34 = load i32*, i32** %33, align 8, !noalias !287
  %35 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 7
  %38 = load i32, i32* %37, align 8, !noalias !287
  %39 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 0
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 1
  %42 = load i32, i32* %41, align 4
  %43 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 1
  %46 = load i32, i32* %45, align 4
  %47 = bitcast %"struct.ruy::KernelParams8bit"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1352, i8* nonnull %47) #18
  %48 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 1
  %49 = bitcast i32** %48 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 1344, i1 false) #18
  %50 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 27, i64 0
  %51 = bitcast i32* %50 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %51, i8 0, i64 64, i1 false) #18
  %52 = mul nsw i32 %40, %27
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds i8, i8* %20, i64 %53
  %55 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 3
  store i8* %54, i8** %55, align 8
  %56 = mul nsw i32 %42, %36
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i8, i8* %31, i64 %57
  %59 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 6
  store i8* %58, i8** %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 24
  store i8 0, i8* %60, align 8
  %61 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 0
  store i32* %50, i32** %61, align 8
  %62 = bitcast i8* %2 to i32**
  %63 = load i32*, i32** %62, align 8
  %64 = icmp eq i32* %63, null
  br i1 %64, label %66, label %65

65:                                               ; preds = %6
  store i32* %63, i32** %61, align 8
  store i8 1, i8* %60, align 8
  br label %66

66:                                               ; preds = %65, %6
  %67 = phi i8 [ 0, %6 ], [ 1, %65 ]
  %68 = icmp eq i32* %23, null
  br i1 %68, label %72, label %69

69:                                               ; preds = %66
  %70 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 1
  store i32* %23, i32** %70, align 8
  %71 = or i8 %67, 2
  store i8 %71, i8* %60, align 8
  br label %72

72:                                               ; preds = %69, %66
  %73 = phi i8 [ %67, %66 ], [ %71, %69 ]
  %74 = icmp eq i32* %34, null
  br i1 %74, label %78, label %75

75:                                               ; preds = %72
  %76 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 2
  store i32* %34, i32** %76, align 8
  %77 = or i8 %73, 4
  store i8 %77, i8* %60, align 8
  br label %78

78:                                               ; preds = %75, %72
  %79 = phi i8 [ %73, %72 ], [ %77, %75 ]
  %80 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 12
  store i32 %40, i32* %80, align 8
  %81 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 13
  store i32 %42, i32* %81, align 4
  %82 = add nsw i32 %44, -16
  %83 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 14
  store i32 %82, i32* %83, align 8
  %84 = add nsw i32 %46, -16
  %85 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 15
  store i32 %84, i32* %85, align 4
  %86 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 18
  store i32 %27, i32* %86, align 8
  %87 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 19
  store i32 %36, i32* %87, align 4
  %88 = shl i32 %16, 1
  %89 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 20
  store i32 %88, i32* %89, align 8
  %90 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 8
  store i32 %29, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 9
  store i32 %38, i32* %91, align 4
  %92 = shl i32 %18, 16
  %93 = ashr exact i32 %92, 16
  %94 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 10
  store i32 %93, i32* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 21
  store i32 %25, i32* %95, align 4
  %96 = mul i32 %29, %25
  %97 = mul i32 %96, %38
  %98 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 11
  store i32 %97, i32* %98, align 4
  %99 = getelementptr inbounds i8, i8* %2, i64 16
  %100 = bitcast i8* %99 to i32**
  %101 = load i32*, i32** %100, align 8
  %102 = icmp eq i32* %101, null
  br i1 %102, label %113, label %103

103:                                              ; preds = %78
  %104 = ptrtoint i32* %101 to i64
  %105 = or i8 %79, 24
  store i8 %105, i8* %60, align 8
  %106 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 4
  %107 = bitcast i32** %106 to i64*
  store i64 %104, i64* %107, align 8
  %108 = getelementptr inbounds i8, i8* %2, i64 24
  %109 = bitcast i8* %108 to i64*
  %110 = load i64, i64* %109, align 8
  %111 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 5
  %112 = bitcast i32** %111 to i64*
  store i64 %110, i64* %112, align 8
  br label %150

113:                                              ; preds = %78
  %114 = getelementptr inbounds i8, i8* %2, i64 12
  %115 = bitcast i8* %114 to i32*
  %116 = load i32, i32* %115, align 4
  %117 = icmp sgt i32 %116, 0
  br i1 %117, label %118, label %120

118:                                              ; preds = %113
  %119 = or i8 %79, 16
  store i8 %119, i8* %60, align 8
  br label %120

120:                                              ; preds = %118, %113
  %121 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 0
  %122 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 4
  store i32* %121, i32** %122, align 8
  %123 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 0
  %124 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 5
  store i32* %123, i32** %124, align 8
  %125 = getelementptr inbounds i8, i8* %2, i64 8
  %126 = bitcast i8* %125 to i32*
  %127 = load i32, i32* %126, align 8
  %128 = insertelement <4 x i32> undef, i32 %127, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = bitcast i32* %121 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %130, align 4
  %131 = insertelement <4 x i32> undef, i32 %116, i32 0
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> zeroinitializer
  %133 = bitcast i32* %123 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %133, align 4
  %134 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 4
  store i32 %127, i32* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 4
  store i32 %116, i32* %135, align 4
  %136 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 5
  store i32 %127, i32* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 5
  store i32 %116, i32* %137, align 4
  %138 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 6
  store i32 %127, i32* %138, align 4
  %139 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 6
  store i32 %116, i32* %139, align 4
  %140 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 7
  %141 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 7
  %142 = bitcast i32* %140 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %142, align 4
  %143 = bitcast i32* %141 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %143, align 4
  %144 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 11
  %145 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 11
  %146 = bitcast i32* %144 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %146, align 4
  %147 = bitcast i32* %145 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %147, align 4
  %148 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 15
  store i32 %127, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 15
  store i32 %116, i32* %149, align 4
  br label %150

150:                                              ; preds = %103, %120
  %151 = getelementptr inbounds i8, i8* %2, i64 32
  %152 = bitcast i8* %151 to i16*
  %153 = load i16, i16* %152, align 8
  %154 = sext i16 %153 to i32
  %155 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 22
  store i32 %154, i32* %155, align 8
  %156 = getelementptr inbounds i8, i8* %2, i64 34
  %157 = bitcast i8* %156 to i16*
  %158 = load i16, i16* %157, align 2
  %159 = sext i16 %158 to i32
  %160 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 23
  store i32 %159, i32* %160, align 4
  %161 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 16
  store i32 %12, i32* %161, align 8
  %162 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 17
  store i32 %14, i32* %162, align 4
  %163 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 25
  store i8 3, i8* %163, align 1
  %164 = mul nsw i32 %42, %16
  %165 = sext i32 %164 to i64
  %166 = getelementptr inbounds i16, i16* %10, i64 %165
  %167 = sext i32 %40 to i64
  %168 = getelementptr inbounds i16, i16* %166, i64 %167
  %169 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 7
  %170 = bitcast i8** %169 to i16**
  store i16* %168, i16** %170, align 8
  %171 = icmp eq i32 %14, 1
  br i1 %171, label %172, label %173

172:                                              ; preds = %150
  call void @_ZN3ruy25Kernel8bitAvx512SingleColERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* nonnull dereferenceable(1352) %7) #18
  br label %174

173:                                              ; preds = %150
  call void @_ZN3ruy16Kernel8bitAvx512ERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* nonnull dereferenceable(1352) %7) #18
  br label %174

174:                                              ; preds = %172, %173
  call void @llvm.lifetime.end.p0i8(i64 1352, i8* nonnull %47) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca %"struct.ruy::Mat.237", align 8
  %7 = alloca %"struct.ruy::PMat.239", align 8
  %8 = bitcast %"struct.ruy::Mat.237"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #18
  %9 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %6, i64 0, i32 2
  %10 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %6, i64 0, i32 3
  %11 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %6, i64 0, i32 1
  %12 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %13 = bitcast i8** %12 to i64*
  %14 = bitcast %"struct.ruy::Mat.237"* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %14, i8 -86, i64 32, i1 false)
  %15 = load i64, i64* %13, align 8, !noalias !290
  %16 = bitcast %"struct.ruy::Mat.237"* %6 to i64*
  store i64 %15, i64* %16, align 8, !alias.scope !290
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3
  %18 = bitcast %"struct.ruy::MatLayout"* %11 to i8*
  %19 = bitcast %"struct.ruy::MatLayout"* %17 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %18, i8* align 4 %19, i64 13, i1 false) #18
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 4
  %21 = load i32, i32* %20, align 8, !noalias !290
  %22 = trunc i32 %21 to i8
  store i8 %22, i8* %9, align 8, !alias.scope !290
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 5
  %24 = load i8, i8* %23, align 4, !noalias !290
  store i8 %24, i8* %10, align 1, !alias.scope !290
  %25 = bitcast %"struct.ruy::PMat.239"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %25) #18
  %26 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %7, i64 0, i32 3
  %27 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %28 = bitcast i8** %27 to i64*
  %29 = bitcast %"struct.ruy::PMat.239"* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %29, i8 -86, i64 40, i1 false)
  %30 = load i64, i64* %28, align 8, !noalias !293
  %31 = bitcast %"struct.ruy::PMat.239"* %7 to i64*
  store i64 %30, i64* %31, align 8, !alias.scope !293
  %32 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %33 = bitcast i8** %32 to i64*
  %34 = load i64, i64* %33, align 8, !noalias !293
  %35 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %7, i64 0, i32 1
  %36 = bitcast i32** %35 to i64*
  store i64 %34, i64* %36, align 8, !alias.scope !293
  %37 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6
  %38 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %7, i64 0, i32 2
  %39 = bitcast %"struct.ruy::PMatLayout"* %38 to i8*
  %40 = bitcast %"struct.ruy::PMatLayout"* %37 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %39, i8* align 4 %40, i64 16, i1 false) #18
  %41 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %42 = load i32, i32* %41, align 8, !noalias !293
  store i32 %42, i32* %26, align 8, !alias.scope !293
  call void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhiE3RunENS_6TuningERKNS_3MatIhEEPNS_4PMatIhEEii(i32 %0, %"struct.ruy::Mat.237"* nonnull dereferenceable(32) %6, %"struct.ruy::PMat.239"* nonnull %7, i32 %3, i32 %4)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %25) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.128"* dereferenceable(112), i8*, %"class.ruy::SidePair.129"* dereferenceable(8), %"class.ruy::SidePair.129"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::Kernel.240", align 1
  %8 = alloca %"struct.ruy::Mat.238", align 8
  %9 = alloca %"struct.ruy::PMat.239", align 8
  %10 = alloca %"struct.ruy::PMat.239", align 8
  %11 = bitcast %"struct.ruy::Mat.238"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #18
  %12 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 2
  %13 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 1
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %16 = bitcast i8** %15 to i64*
  %17 = bitcast %"struct.ruy::Mat.238"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %17, i8 -86, i64 32, i1 false)
  %18 = load i64, i64* %16, align 8, !noalias !296
  %19 = bitcast %"struct.ruy::Mat.238"* %8 to i64*
  store i64 %18, i64* %19, align 8, !alias.scope !296
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3
  %21 = bitcast %"struct.ruy::MatLayout"* %14 to i8*
  %22 = bitcast %"struct.ruy::MatLayout"* %20 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %21, i8* align 4 %22, i64 13, i1 false) #18
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %24 = load i32, i32* %23, align 8, !noalias !296
  %25 = trunc i32 %24 to i16
  store i16 %25, i16* %12, align 8, !alias.scope !296
  %26 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 5
  %27 = load i8, i8* %26, align 4, !noalias !296
  store i8 %27, i8* %13, align 2, !alias.scope !296
  %28 = bitcast %"struct.ruy::PMat.239"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %28) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 40, i1 false) #18, !alias.scope !299
  %29 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %9, i64 0, i32 3
  %30 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 2
  %31 = bitcast i8** %30 to i64*
  %32 = load i64, i64* %31, align 8, !noalias !299
  %33 = bitcast %"struct.ruy::PMat.239"* %9 to i64*
  store i64 %32, i64* %33, align 8, !alias.scope !299
  %34 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 5
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !299
  %37 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %9, i64 0, i32 1
  %38 = bitcast i32** %37 to i64*
  store i64 %36, i64* %38, align 8, !alias.scope !299
  %39 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6
  %40 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %9, i64 0, i32 2
  %41 = bitcast %"struct.ruy::PMatLayout"* %40 to i8*
  %42 = bitcast %"struct.ruy::PMatLayout"* %39 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %41, i8* align 4 %42, i64 16, i1 false) #18
  %43 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 7
  %44 = load i32, i32* %43, align 8, !noalias !299
  store i32 %44, i32* %29, align 8, !alias.scope !299
  %45 = bitcast %"struct.ruy::PMat.239"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %45) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %45, i8 -86, i64 40, i1 false) #18, !alias.scope !302
  %46 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %10, i64 0, i32 3
  %47 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 2
  %48 = bitcast i8** %47 to i64*
  %49 = load i64, i64* %48, align 8, !noalias !302
  %50 = bitcast %"struct.ruy::PMat.239"* %10 to i64*
  store i64 %49, i64* %50, align 8, !alias.scope !302
  %51 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 5
  %52 = bitcast i8** %51 to i64*
  %53 = load i64, i64* %52, align 8, !noalias !302
  %54 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %10, i64 0, i32 1
  %55 = bitcast i32** %54 to i64*
  store i64 %53, i64* %55, align 8, !alias.scope !302
  %56 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 6
  %57 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %10, i64 0, i32 2
  %58 = bitcast %"struct.ruy::PMatLayout"* %57 to i8*
  %59 = bitcast %"struct.ruy::PMatLayout"* %56 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %58, i8* align 4 %59, i64 16, i1 false) #18
  %60 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 7
  %61 = load i32, i32* %60, align 8, !noalias !302
  store i32 %61, i32* %46, align 8, !alias.scope !302
  %62 = bitcast i8* %2 to %"class.ruy::MulParams.236"*
  %63 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 0
  %64 = load i32, i32* %63, align 4
  %65 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 0
  %68 = load i32, i32* %67, align 4
  %69 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 1
  %70 = load i32, i32* %69, align 4
  %71 = getelementptr inbounds %"struct.ruy::Kernel.240", %"struct.ruy::Kernel.240"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %71) #18
  store i8 -86, i8* %71, align 1
  call void @_ZNK3ruy6KernelILNS_4PathE2EhhsNS_9MulParamsIisEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIsEE(%"struct.ruy::Kernel.240"* nonnull %7, %"struct.ruy::PMat.239"* nonnull dereferenceable(40) %9, %"struct.ruy::PMat.239"* nonnull dereferenceable(40) %10, %"class.ruy::MulParams.236"* dereferenceable(40) %62, i32 %64, i32 %66, i32 %68, i32 %70, %"struct.ruy::Mat.238"* nonnull %8) #18
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %71) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %45) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %28) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhiE3RunENS_6TuningERKNS_3MatIhEEPNS_4PMatIhEEii(i32, %"struct.ruy::Mat.237"* dereferenceable(32), %"struct.ruy::PMat.239"*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 1
  %7 = load i32*, i32** %6, align 8
  %8 = icmp slt i32 %3, %4
  br i1 %8, label %9, label %33

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 0
  %11 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %1, i64 0, i32 1, i32 1
  %12 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %1, i64 0, i32 1, i32 0
  %13 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %1, i64 0, i32 0, i32 0
  %15 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %1, i64 0, i32 1, i32 3
  %16 = getelementptr inbounds %"struct.ruy::Mat.237", %"struct.ruy::Mat.237"* %1, i64 0, i32 1, i32 2
  %17 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 0
  %18 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 4, i32 1
  %19 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 4, i32 2
  %20 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 3
  %21 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 2
  %22 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 4, i32 0
  %23 = icmp eq i32* %7, null
  %24 = sext i32 %3 to i64
  %25 = sext i32 %4 to i64
  br label %26

26:                                               ; preds = %107, %9
  %27 = phi i64 [ %24, %9 ], [ %108, %107 ]
  %28 = load i32, i32* %10, align 8
  %29 = icmp sgt i32 %28, 0
  br i1 %29, label %30, label %34

30:                                               ; preds = %26
  %31 = trunc i64 %27 to i32
  %32 = trunc i64 %27 to i32
  br label %36

33:                                               ; preds = %107, %5
  ret void

34:                                               ; preds = %64, %26
  %35 = phi i32 [ 0, %26 ], [ %68, %64 ]
  br i1 %23, label %107, label %105

36:                                               ; preds = %30, %64
  %37 = phi i32 [ %102, %64 ], [ 0, %30 ]
  %38 = phi i32 [ %68, %64 ], [ 0, %30 ]
  %39 = load i32, i32* %11, align 4
  %40 = sext i32 %39 to i64
  %41 = icmp slt i64 %27, %40
  br i1 %41, label %42, label %61

42:                                               ; preds = %36
  %43 = load i32, i32* %12, align 8
  %44 = icmp slt i32 %37, %43
  br i1 %44, label %45, label %61

45:                                               ; preds = %42
  %46 = load i8*, i8** %14, align 8
  %47 = load i8, i8* %15, align 4
  %48 = load i32, i32* %16, align 4
  switch i8 %47, label %49 [
    i8 0, label %50
    i8 1, label %52
  ]

49:                                               ; preds = %45
  br label %50

50:                                               ; preds = %49, %45
  %51 = phi i32 [ 1, %45 ], [ %48, %49 ]
  br label %52

52:                                               ; preds = %45, %50
  %53 = phi i32 [ %51, %50 ], [ %48, %45 ]
  %54 = phi i32 [ %48, %50 ], [ 1, %45 ]
  %55 = mul nsw i32 %53, %37
  %56 = mul nsw i32 %54, %32
  %57 = add nsw i32 %56, %55
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds i8, i8* %46, i64 %58
  %60 = load i8, i8* %59, align 1
  br label %64

61:                                               ; preds = %42, %36
  %62 = load i32, i32* %13, align 8
  %63 = trunc i32 %62 to i8
  br label %64

64:                                               ; preds = %61, %52
  %65 = phi i32 [ %31, %61 ], [ %32, %52 ]
  %66 = phi i8 [ %63, %61 ], [ %60, %52 ]
  %67 = zext i8 %66 to i32
  %68 = add nuw nsw i32 %38, %67
  %69 = load i8*, i8** %17, align 8
  %70 = load i8, i8* %18, align 1
  %71 = zext i8 %70 to i32
  %72 = sub nsw i32 0, %71
  %73 = and i32 %37, %72
  %74 = load i8, i8* %19, align 1
  %75 = zext i8 %74 to i32
  %76 = sub nsw i32 0, %75
  %77 = and i32 %65, %76
  %78 = load i8, i8* %20, align 4
  %79 = icmp eq i8 %78, 0
  %80 = load i32, i32* %21, align 4
  %81 = select i1 %79, i32 %75, i32 %80
  %82 = icmp eq i8 %78, 1
  %83 = select i1 %82, i32 %71, i32 %80
  %84 = mul nsw i32 %81, %73
  %85 = mul nsw i32 %83, %77
  %86 = sub nsw i32 %37, %73
  %87 = sub nsw i32 %65, %77
  %88 = load i8, i8* %22, align 1
  %89 = icmp eq i8 %88, 0
  %90 = select i1 %89, i8 1, i8 %74
  %91 = zext i8 %90 to i32
  %92 = icmp eq i8 %88, 1
  %93 = select i1 %92, i8 1, i8 %70
  %94 = zext i8 %93 to i32
  %95 = mul nsw i32 %86, %91
  %96 = mul nsw i32 %87, %94
  %97 = add i32 %84, %85
  %98 = add i32 %97, %96
  %99 = add i32 %98, %95
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i8, i8* %69, i64 %100
  store i8 %66, i8* %101, align 1
  %102 = add nuw nsw i32 %37, 1
  %103 = load i32, i32* %10, align 8
  %104 = icmp slt i32 %102, %103
  br i1 %104, label %36, label %34

105:                                              ; preds = %34
  %106 = getelementptr inbounds i32, i32* %7, i64 %27
  store i32 %35, i32* %106, align 4
  br label %107

107:                                              ; preds = %34, %105
  %108 = add nsw i64 %27, 1
  %109 = icmp eq i64 %108, %25
  br i1 %109, label %33, label %26
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK3ruy6KernelILNS_4PathE2EhhsNS_9MulParamsIisEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIsEE(%"struct.ruy::Kernel.240"*, %"struct.ruy::PMat.239"* dereferenceable(40), %"struct.ruy::PMat.239"* dereferenceable(40), %"class.ruy::MulParams.236"* dereferenceable(40), i32, i32, i32, i32, %"struct.ruy::Mat.238"*) local_unnamed_addr #1 comdat align 2 {
  %10 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 1, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = icmp slt i32 %11, %6
  %13 = select i1 %12, i32 %11, i32 %6
  %14 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 1, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = icmp slt i32 %15, %7
  %17 = select i1 %16, i32 %15, i32 %7
  %18 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 2, i32 0
  %19 = load i32, i32* %18, align 8
  %20 = icmp sgt i32 %13, %4
  br i1 %20, label %21, label %60

21:                                               ; preds = %9
  %22 = icmp sgt i32 %17, %5
  %23 = icmp sgt i32 %19, 0
  %24 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 0
  %25 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 2, i32 4, i32 1
  %26 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 2, i32 4, i32 2
  %27 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 2, i32 3
  %28 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 2, i32 2
  %29 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 2, i32 4, i32 0
  %30 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 0
  %31 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 4, i32 1
  %32 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 4, i32 2
  %33 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 3
  %34 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 2
  %35 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 2, i32 4, i32 0
  %36 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %3, i64 0, i32 0
  %37 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 3
  %38 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 1
  %39 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %2, i64 0, i32 3
  %40 = getelementptr inbounds %"struct.ruy::PMat.239", %"struct.ruy::PMat.239"* %1, i64 0, i32 1
  %41 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %3, i64 0, i32 3
  %42 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %3, i64 0, i32 1
  %43 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %3, i64 0, i32 4
  %44 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %3, i64 0, i32 2
  %45 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 2
  %46 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %3, i64 0, i32 6
  %47 = getelementptr inbounds %"class.ruy::MulParams.236", %"class.ruy::MulParams.236"* %3, i64 0, i32 5
  %48 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 0, i32 0
  %49 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 1, i32 3
  %50 = getelementptr inbounds %"struct.ruy::Mat.238", %"struct.ruy::Mat.238"* %8, i64 0, i32 1, i32 2
  %51 = sext i32 %5 to i64
  %52 = sext i32 %17 to i64
  %53 = sext i32 %4 to i64
  %54 = sext i32 %13 to i64
  br label %55

55:                                               ; preds = %21, %113
  %56 = phi i64 [ %53, %21 ], [ %114, %113 ]
  br i1 %22, label %57, label %113

57:                                               ; preds = %55
  %58 = trunc i64 %56 to i32
  %59 = trunc i64 %56 to i32
  br label %61

60:                                               ; preds = %113, %9
  ret void

61:                                               ; preds = %57, %209
  %62 = phi i64 [ %51, %57 ], [ %218, %209 ]
  br i1 %23, label %63, label %116

63:                                               ; preds = %61
  %64 = load i8*, i8** %24, align 8
  %65 = load i8, i8* %25, align 1
  %66 = zext i8 %65 to i32
  %67 = sub nsw i32 0, %66
  %68 = load i8, i8* %26, align 1
  %69 = zext i8 %68 to i32
  %70 = sub nsw i32 0, %69
  %71 = and i32 %58, %70
  %72 = load i8, i8* %27, align 4
  %73 = icmp eq i8 %72, 0
  %74 = load i32, i32* %28, align 4
  %75 = select i1 %73, i32 %69, i32 %74
  %76 = icmp eq i8 %72, 1
  %77 = select i1 %76, i32 %66, i32 %74
  %78 = mul nsw i32 %77, %71
  %79 = sub nsw i32 %58, %71
  %80 = load i8, i8* %29, align 1
  %81 = icmp eq i8 %80, 0
  %82 = select i1 %81, i8 1, i8 %68
  %83 = zext i8 %82 to i32
  %84 = icmp eq i8 %80, 1
  %85 = select i1 %84, i8 1, i8 %65
  %86 = zext i8 %85 to i32
  %87 = mul nsw i32 %79, %86
  %88 = load i8*, i8** %30, align 8
  %89 = load i8, i8* %31, align 1
  %90 = zext i8 %89 to i32
  %91 = sub nsw i32 0, %90
  %92 = load i8, i8* %32, align 1
  %93 = zext i8 %92 to i32
  %94 = sub nsw i32 0, %93
  %95 = trunc i64 %62 to i32
  %96 = and i32 %95, %94
  %97 = load i8, i8* %33, align 4
  %98 = icmp eq i8 %97, 0
  %99 = load i32, i32* %34, align 4
  %100 = select i1 %98, i32 %93, i32 %99
  %101 = icmp eq i8 %97, 1
  %102 = select i1 %101, i32 %90, i32 %99
  %103 = mul nsw i32 %102, %96
  %104 = sub nsw i32 %95, %96
  %105 = load i8, i8* %35, align 1
  %106 = icmp eq i8 %105, 0
  %107 = select i1 %106, i8 1, i8 %92
  %108 = zext i8 %107 to i32
  %109 = icmp eq i8 %105, 1
  %110 = select i1 %109, i8 1, i8 %89
  %111 = zext i8 %110 to i32
  %112 = mul nsw i32 %104, %111
  br label %120

113:                                              ; preds = %209, %55
  %114 = add nsw i64 %56, 1
  %115 = icmp slt i64 %114, %54
  br i1 %115, label %55, label %60

116:                                              ; preds = %120, %61
  %117 = phi i32 [ 0, %61 ], [ %146, %120 ]
  %118 = load i32*, i32** %36, align 8
  %119 = icmp eq i32* %118, null
  br i1 %119, label %153, label %149

120:                                              ; preds = %120, %63
  %121 = phi i32 [ 0, %63 ], [ %147, %120 ]
  %122 = phi i32 [ 0, %63 ], [ %146, %120 ]
  %123 = and i32 %121, %67
  %124 = mul nsw i32 %75, %123
  %125 = sub nsw i32 %121, %123
  %126 = mul nsw i32 %125, %83
  %127 = add i32 %124, %78
  %128 = add i32 %127, %87
  %129 = add i32 %128, %126
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds i8, i8* %64, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = zext i8 %132 to i32
  %134 = and i32 %121, %91
  %135 = mul nsw i32 %100, %134
  %136 = sub nsw i32 %121, %134
  %137 = mul nsw i32 %136, %108
  %138 = add i32 %135, %103
  %139 = add i32 %138, %112
  %140 = add i32 %139, %137
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds i8, i8* %88, i64 %141
  %143 = load i8, i8* %142, align 1
  %144 = zext i8 %143 to i32
  %145 = mul nuw nsw i32 %144, %133
  %146 = add nuw nsw i32 %145, %122
  %147 = add nuw nsw i32 %121, 1
  %148 = icmp eq i32 %147, %19
  br i1 %148, label %116, label %120

149:                                              ; preds = %116
  %150 = getelementptr inbounds i32, i32* %118, i64 %56
  %151 = load i32, i32* %150, align 4
  %152 = add nsw i32 %151, %117
  br label %153

153:                                              ; preds = %116, %149
  %154 = phi i32 [ %117, %116 ], [ %152, %149 ]
  %155 = load i32, i32* %37, align 8
  %156 = icmp eq i32 %155, 0
  br i1 %156, label %163, label %157

157:                                              ; preds = %153
  %158 = load i32*, i32** %38, align 8
  %159 = getelementptr inbounds i32, i32* %158, i64 %62
  %160 = load i32, i32* %159, align 4
  %161 = mul nsw i32 %160, %155
  %162 = sub nsw i32 %154, %161
  br label %163

163:                                              ; preds = %153, %157
  %164 = phi i32 [ %154, %153 ], [ %162, %157 ]
  %165 = load i32, i32* %39, align 8
  %166 = icmp eq i32 %165, 0
  br i1 %166, label %178, label %167

167:                                              ; preds = %163
  %168 = load i32*, i32** %40, align 8
  %169 = getelementptr inbounds i32, i32* %168, i64 %56
  %170 = load i32, i32* %169, align 4
  %171 = mul nsw i32 %170, %165
  %172 = sub nsw i32 %164, %171
  %173 = or i1 %156, %166
  br i1 %173, label %178, label %174

174:                                              ; preds = %167
  %175 = mul i32 %155, %19
  %176 = mul i32 %175, %165
  %177 = add nsw i32 %172, %176
  br label %178

178:                                              ; preds = %163, %167, %174
  %179 = phi i32 [ %172, %167 ], [ %177, %174 ], [ %164, %163 ]
  %180 = load i32*, i32** %41, align 8
  %181 = icmp eq i32* %180, null
  %182 = getelementptr inbounds i32, i32* %180, i64 %56
  %183 = select i1 %181, i32* %42, i32* %182
  %184 = load i32, i32* %183, align 4
  %185 = load i32*, i32** %43, align 8
  %186 = icmp eq i32* %185, null
  %187 = getelementptr inbounds i32, i32* %185, i64 %56
  %188 = select i1 %186, i32* %44, i32* %187
  %189 = load i32, i32* %188, align 4
  %190 = tail call i32 @_ZN3ruy6detail29MultiplyByQuantizedMultiplierEiii(i32 %179, i32 %184, i32 %189) #18
  %191 = load i16, i16* %45, align 8
  %192 = sext i16 %191 to i32
  %193 = add nsw i32 %190, %192
  %194 = load i16, i16* %46, align 2
  %195 = sext i16 %194 to i32
  %196 = icmp sgt i32 %193, %195
  %197 = select i1 %196, i32 %195, i32 %193
  %198 = load i16, i16* %47, align 8
  %199 = sext i16 %198 to i32
  %200 = icmp slt i32 %197, %199
  %201 = select i1 %200, i32 %199, i32 %197
  %202 = trunc i32 %201 to i16
  %203 = load i16*, i16** %48, align 8
  %204 = load i8, i8* %49, align 4
  %205 = load i32, i32* %50, align 4
  switch i8 %204, label %206 [
    i8 0, label %207
    i8 1, label %209
  ]

206:                                              ; preds = %178
  br label %207

207:                                              ; preds = %206, %178
  %208 = phi i32 [ 1, %178 ], [ %205, %206 ]
  br label %209

209:                                              ; preds = %178, %207
  %210 = phi i32 [ %208, %207 ], [ %205, %178 ]
  %211 = phi i32 [ %205, %207 ], [ 1, %178 ]
  %212 = mul nsw i32 %210, %59
  %213 = trunc i64 %62 to i32
  %214 = mul nsw i32 %211, %213
  %215 = add nsw i32 %214, %212
  %216 = sext i32 %215 to i64
  %217 = getelementptr inbounds i16, i16* %203, i64 %216
  store i16 %202, i16* %217, align 2
  %218 = add nsw i64 %62, 1
  %219 = icmp slt i64 %218, %52
  br i1 %219, label %61, label %113
}

declare i32 @_ZN3ruy6detail29MultiplyByQuantizedMultiplierEiii(i32, i32, i32) local_unnamed_addr #3

declare void @_ZN3ruy14Pack8bitAvx512EPKaaS1_iiiPaPi(i8*, i8 signext, i8*, i32, i32, i32, i8*, i32*) local_unnamed_addr #3

declare void @_ZN3ruy25Kernel8bitAvx512SingleColERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* dereferenceable(1352)) local_unnamed_addr #3

declare void @_ZN3ruy16Kernel8bitAvx512ERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* dereferenceable(1352)) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %60, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 65536, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262145, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 1023
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = and i32 %35, 255
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %36, i32* %37, align 8
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %39 = bitcast %"struct.ruy::PEMat"* %38 to i24*
  store i24 65536, i24* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %41 = bitcast %"struct.ruy::Type"* %40 to i24*
  store i24 262145, i24* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %42, align 4
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %44, i32* %45, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %47 = load i32, i32* %46, align 4
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %49, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %51, align 1
  %52 = and i32 %44, 1023
  %53 = icmp eq i32 %52, 0
  %54 = add nsw i32 %44, 64
  %55 = select i1 %53, i32 %54, i32 %44
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %55, i32* %56, align 4
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %58 = load i32, i32* %57, align 8
  %59 = and i32 %58, 255
  br label %119

60:                                               ; preds = %9
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 8, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %63 = bitcast %"struct.ruy::PEMat"* %62 to i24*
  store i24 65537, i24* %63, align 8
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %65 = bitcast %"struct.ruy::Type"* %64 to i24*
  store i24 262145, i24* %65, align 8
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %66, align 4
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = add i32 %68, 3
  %70 = and i32 %69, -4
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %73 = load i32, i32* %72, align 4
  %74 = add i32 %73, 7
  %75 = and i32 %74, -8
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %75, i32* %76, align 4
  %77 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %77, align 1
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 4, i8* %78, align 1
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 8, i8* %79, align 1
  %80 = and i32 %69, 1020
  %81 = icmp eq i32 %80, 0
  %82 = add nsw i32 %70, 64
  %83 = select i1 %81, i32 %82, i32 %70
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %86 = load i32, i32* %85, align 8
  %87 = shl i32 %86, 24
  %88 = ashr exact i32 %87, 24
  %89 = xor i32 %88, -128
  %90 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %89, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %92 = bitcast %"struct.ruy::PEMat"* %91 to i24*
  store i24 65537, i24* %92, align 8
  %93 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %94 = bitcast %"struct.ruy::Type"* %93 to i24*
  store i24 262145, i24* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %95, align 4
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %97 = load i32, i32* %96, align 4
  %98 = add i32 %97, 3
  %99 = and i32 %98, -4
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %99, i32* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %102 = load i32, i32* %101, align 4
  %103 = add i32 %102, 7
  %104 = and i32 %103, -8
  %105 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %104, i32* %105, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %106, align 1
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 4, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 8, i8* %108, align 1
  %109 = and i32 %98, 1020
  %110 = icmp eq i32 %109, 0
  %111 = add nsw i32 %99, 64
  %112 = select i1 %110, i32 %111, i32 %99
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %112, i32* %113, align 4
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %115 = load i32, i32* %114, align 8
  %116 = shl i32 %115, 24
  %117 = ashr exact i32 %116, 24
  %118 = xor i32 %117, -128
  br label %119

119:                                              ; preds = %60, %13
  %120 = phi i32 [ %118, %60 ], [ %59, %13 ]
  %121 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %60 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %122 = phi void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE8EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %60 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %120, i32* %123, align 8
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %124, align 8
  %125 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %125, align 8
  %126 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)* %122, void (i32, %"class.ruy::SidePair.128"*, i8*, %"class.ruy::SidePair.129"*, %"class.ruy::SidePair.129"*, %"struct.ruy::EMat"*)** %126, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca [32 x i8], align 16
  %7 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %8 = load i8*, i8** %7, align 8, !noalias !305
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %16 = load i8*, i8** %15, align 8, !noalias !308
  %17 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %18 = bitcast i8** %17 to i32**
  %19 = load i32*, i32** %18, align 8, !noalias !308
  %20 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %23 = load i32, i32* %22, align 8, !noalias !308
  %24 = getelementptr inbounds [32 x i8], [32 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %24) #18
  %25 = trunc i32 %23 to i8
  %26 = xor i8 %25, -128
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %24, i8 %26, i64 32, i1 false) #18
  %27 = icmp slt i32 %3, %4
  br i1 %27, label %28, label %47

28:                                               ; preds = %5
  %29 = icmp eq i32* %19, null
  %30 = sext i32 %3 to i64
  %31 = sext i32 %4 to i64
  %32 = sext i32 %14 to i64
  br label %33

33:                                               ; preds = %33, %28
  %34 = phi i64 [ %30, %28 ], [ %45, %33 ]
  %35 = getelementptr inbounds i32, i32* %19, i64 %34
  %36 = select i1 %29, i32* null, i32* %35
  %37 = mul nsw i64 %34, %32
  %38 = getelementptr inbounds i8, i8* %8, i64 %37
  %39 = trunc i64 %34 to i32
  %40 = sub nsw i32 %12, %39
  %41 = and i32 %39, -8
  %42 = mul nsw i32 %41, %21
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i8, i8* %16, i64 %43
  call void @_ZN3ruy12Pack8bitAvx2EPKaaS1_iiiPaPi(i8* %38, i8 signext -128, i8* nonnull %24, i32 %14, i32 %40, i32 %10, i8* %44, i32* %36) #18
  %45 = add nsw i64 %34, 8
  %46 = icmp slt i64 %45, %31
  br i1 %46, label %33, label %47

47:                                               ; preds = %33, %5
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %24) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE8EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.128"* dereferenceable(112), i8*, %"class.ruy::SidePair.129"* dereferenceable(8), %"class.ruy::SidePair.129"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParams8bit.245", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = bitcast i8** %8 to i16**
  %10 = load i16*, i16** %9, align 8, !noalias !311
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %18 = load i32, i32* %17, align 8, !noalias !311
  %19 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 2
  %20 = load i8*, i8** %19, align 8, !noalias !314
  %21 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 5
  %22 = bitcast i8** %21 to i32**
  %23 = load i32*, i32** %22, align 8, !noalias !314
  %24 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 0, i32 7
  %29 = load i32, i32* %28, align 8, !noalias !314
  %30 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 2
  %31 = load i8*, i8** %30, align 8, !noalias !317
  %32 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 5
  %33 = bitcast i8** %32 to i32**
  %34 = load i32*, i32** %33, align 8, !noalias !317
  %35 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"class.ruy::SidePair.128", %"class.ruy::SidePair.128"* %1, i64 0, i32 0, i64 1, i32 7
  %38 = load i32, i32* %37, align 8, !noalias !317
  %39 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 0
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %3, i64 0, i32 0, i64 1
  %42 = load i32, i32* %41, align 4
  %43 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"class.ruy::SidePair.129", %"class.ruy::SidePair.129"* %4, i64 0, i32 0, i64 1
  %46 = load i32, i32* %45, align 4
  %47 = bitcast %"struct.ruy::KernelParams8bit.245"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 488, i8* nonnull %47) #18
  %48 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 1
  %49 = bitcast i32** %48 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 480, i1 false) #18
  %50 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 27, i64 0
  %51 = bitcast i32* %50 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %51, i8 0, i64 32, i1 false) #18
  %52 = mul nsw i32 %40, %27
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds i8, i8* %20, i64 %53
  %55 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 3
  store i8* %54, i8** %55, align 8
  %56 = mul nsw i32 %42, %36
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i8, i8* %31, i64 %57
  %59 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 6
  store i8* %58, i8** %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 24
  store i8 0, i8* %60, align 8
  %61 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 0
  store i32* %50, i32** %61, align 8
  %62 = bitcast i8* %2 to i32**
  %63 = load i32*, i32** %62, align 8
  %64 = icmp eq i32* %63, null
  br i1 %64, label %66, label %65

65:                                               ; preds = %6
  store i32* %63, i32** %61, align 8
  store i8 1, i8* %60, align 8
  br label %66

66:                                               ; preds = %65, %6
  %67 = phi i8 [ 0, %6 ], [ 1, %65 ]
  %68 = icmp eq i32* %23, null
  br i1 %68, label %72, label %69

69:                                               ; preds = %66
  %70 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 1
  store i32* %23, i32** %70, align 8
  %71 = or i8 %67, 2
  store i8 %71, i8* %60, align 8
  br label %72

72:                                               ; preds = %69, %66
  %73 = phi i8 [ %67, %66 ], [ %71, %69 ]
  %74 = icmp eq i32* %34, null
  br i1 %74, label %78, label %75

75:                                               ; preds = %72
  %76 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 2
  store i32* %34, i32** %76, align 8
  %77 = or i8 %73, 4
  store i8 %77, i8* %60, align 8
  br label %78

78:                                               ; preds = %75, %72
  %79 = phi i8 [ %73, %72 ], [ %77, %75 ]
  %80 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 12
  store i32 %40, i32* %80, align 8
  %81 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 13
  store i32 %42, i32* %81, align 4
  %82 = add nsw i32 %44, -8
  %83 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 14
  store i32 %82, i32* %83, align 8
  %84 = add nsw i32 %46, -8
  %85 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 15
  store i32 %84, i32* %85, align 4
  %86 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 18
  store i32 %27, i32* %86, align 8
  %87 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 19
  store i32 %36, i32* %87, align 4
  %88 = shl i32 %16, 1
  %89 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 20
  store i32 %88, i32* %89, align 8
  %90 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 8
  store i32 %29, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 9
  store i32 %38, i32* %91, align 4
  %92 = shl i32 %18, 16
  %93 = ashr exact i32 %92, 16
  %94 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 10
  store i32 %93, i32* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 21
  store i32 %25, i32* %95, align 4
  %96 = mul i32 %29, %25
  %97 = mul i32 %96, %38
  %98 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 11
  store i32 %97, i32* %98, align 4
  %99 = getelementptr inbounds i8, i8* %2, i64 16
  %100 = bitcast i8* %99 to i32**
  %101 = load i32*, i32** %100, align 8
  %102 = icmp eq i32* %101, null
  br i1 %102, label %113, label %103

103:                                              ; preds = %78
  %104 = ptrtoint i32* %101 to i64
  %105 = or i8 %79, 24
  store i8 %105, i8* %60, align 8
  %106 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 4
  %107 = bitcast i32** %106 to i64*
  store i64 %104, i64* %107, align 8
  %108 = getelementptr inbounds i8, i8* %2, i64 24
  %109 = bitcast i8* %108 to i64*
  %110 = load i64, i64* %109, align 8
  %111 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 5
  %112 = bitcast i32** %111 to i64*
  store i64 %110, i64* %112, align 8
  br label %142

113:                                              ; preds = %78
  %114 = getelementptr inbounds i8, i8* %2, i64 12
  %115 = bitcast i8* %114 to i32*
  %116 = load i32, i32* %115, align 4
  %117 = icmp sgt i32 %116, 0
  br i1 %117, label %118, label %120

118:                                              ; preds = %113
  %119 = or i8 %79, 16
  store i8 %119, i8* %60, align 8
  br label %120

120:                                              ; preds = %118, %113
  %121 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 29, i64 0
  %122 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 4
  store i32* %121, i32** %122, align 8
  %123 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 30, i64 0
  %124 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 5
  store i32* %123, i32** %124, align 8
  %125 = getelementptr inbounds i8, i8* %2, i64 8
  %126 = bitcast i8* %125 to i32*
  %127 = load i32, i32* %126, align 8
  %128 = insertelement <4 x i32> undef, i32 %127, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = bitcast i32* %121 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %130, align 4
  %131 = insertelement <4 x i32> undef, i32 %116, i32 0
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> zeroinitializer
  %133 = bitcast i32* %123 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %133, align 4
  %134 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 29, i64 4
  store i32 %127, i32* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 30, i64 4
  store i32 %116, i32* %135, align 4
  %136 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 29, i64 5
  store i32 %127, i32* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 30, i64 5
  store i32 %116, i32* %137, align 4
  %138 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 29, i64 6
  store i32 %127, i32* %138, align 4
  %139 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 30, i64 6
  store i32 %116, i32* %139, align 4
  %140 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 29, i64 7
  store i32 %127, i32* %140, align 4
  %141 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 30, i64 7
  store i32 %116, i32* %141, align 4
  br label %142

142:                                              ; preds = %103, %120
  %143 = getelementptr inbounds i8, i8* %2, i64 32
  %144 = bitcast i8* %143 to i16*
  %145 = load i16, i16* %144, align 8
  %146 = sext i16 %145 to i32
  %147 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 22
  store i32 %146, i32* %147, align 8
  %148 = getelementptr inbounds i8, i8* %2, i64 34
  %149 = bitcast i8* %148 to i16*
  %150 = load i16, i16* %149, align 2
  %151 = sext i16 %150 to i32
  %152 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 23
  store i32 %151, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 16
  store i32 %12, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 17
  store i32 %14, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 25
  store i8 3, i8* %155, align 1
  %156 = mul nsw i32 %42, %16
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds i16, i16* %10, i64 %157
  %159 = sext i32 %40 to i64
  %160 = getelementptr inbounds i16, i16* %158, i64 %159
  %161 = getelementptr inbounds %"struct.ruy::KernelParams8bit.245", %"struct.ruy::KernelParams8bit.245"* %7, i64 0, i32 7
  %162 = bitcast i8** %161 to i16**
  store i16* %160, i16** %162, align 8
  %163 = icmp eq i32 %14, 1
  br i1 %163, label %164, label %165

164:                                              ; preds = %142
  call void @_ZN3ruy23Kernel8bitAvx2SingleColERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.245"* nonnull dereferenceable(488) %7) #18
  br label %166

165:                                              ; preds = %142
  call void @_ZN3ruy14Kernel8bitAvx2ERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.245"* nonnull dereferenceable(488) %7) #18
  br label %166

166:                                              ; preds = %164, %165
  call void @llvm.lifetime.end.p0i8(i64 488, i8* nonnull %47) #18
  ret void
}

declare void @_ZN3ruy12Pack8bitAvx2EPKaaS1_iiiPaPi(i8*, i8 signext, i8*, i32, i32, i32, i8*, i32*) local_unnamed_addr #3

declare void @_ZN3ruy23Kernel8bitAvx2SingleColERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.245"* dereferenceable(488)) local_unnamed_addr #3

declare void @_ZN3ruy14Kernel8bitAvx2ERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.245"* dereferenceable(488)) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.std::__1::tuple"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.273", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.258", align 8
  %11 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %12 = alloca %"class.gemmlowp::VectorDup", align 4
  %13 = alloca %"class.std::__1::tuple.275", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %101, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %97

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.273"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #18
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.260"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.273"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !320
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !320
  %38 = bitcast %"class.gemmlowp::MatrixMap.273"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !320
  store i32 %18, i32* %30, align 8, !alias.scope !320
  store i32 %16, i32* %31, align 4, !alias.scope !320
  store i32 %37, i32* %32, align 8, !alias.scope !320
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #18
  %40 = bitcast %"class.gemmlowp::MatrixMap.258"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !325
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !325
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !325
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !325
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !325
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !325
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !325
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !325
  %52 = bitcast %"class.gemmlowp::MatrixMap.258"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #18
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !330
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !330
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !330
  %59 = bitcast %"class.gemmlowp::MatrixMap.258"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !330
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !330
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !330
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !330
  %63 = bitcast %"class.gemmlowp::VectorDup.272"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #18
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !335
  store i32 %66, i32* %64, align 4, !alias.scope !335
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !335
  store i32 %69, i32* %67, align 4, !alias.scope !335
  %70 = bitcast %"class.gemmlowp::VectorDup"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #18
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !340
  store i32 %73, i32* %71, align 4, !alias.scope !340
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !340
  store i32 %76, i32* %74, align 4, !alias.scope !340
  %77 = bitcast %"class.std::__1::tuple.275"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %77) #18
  %78 = bitcast %"class.std::__1::tuple"* %6 to i64*
  %79 = load i64, i64* %78, align 8, !noalias !345
  %80 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  %81 = load i32, i32* %80, align 8, !noalias !345
  %82 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !356
  %85 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %6, i64 0, i32 0, i32 1, i32 0, i32 2
  %86 = load i32, i32* %85, align 4, !noalias !356
  %87 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %6, i64 0, i32 0, i32 2, i32 0
  %88 = bitcast %"struct.gemmlowp::OutputStageClamp"* %87 to i64*
  %89 = load i64, i64* %88, align 4, !noalias !356
  %90 = bitcast %"class.std::__1::tuple.275"* %13 to i64*
  store i64 %79, i64* %90, align 8, !alias.scope !357
  %91 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %81, i32* %91, align 8, !alias.scope !357
  %92 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %13, i64 0, i32 0, i32 1
  %93 = bitcast %"class.std::__1::__tuple_leaf.262"* %92 to i64*
  store i64 %84, i64* %93, align 8, !alias.scope !356
  %94 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %13, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %86, i32* %94, align 8, !alias.scope !356
  %95 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %13, i64 0, i32 0, i32 2
  %96 = bitcast %"class.std::__1::__tuple_leaf.263"* %95 to i64*
  store i64 %89, i64* %96, align 4, !alias.scope !357
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.258"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.273"* nonnull %8, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.275"* nonnull dereferenceable(40) %13)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %77) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #18
  br label %101

97:                                               ; preds = %26
  %98 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %98) #18
  %99 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %99, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %100, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.258"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.260"* %3, %"class.gemmlowp::VectorDup"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %5, %"class.std::__1::tuple"* dereferenceable(40) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %98) #18
  br label %101

101:                                              ; preds = %7, %97, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.275"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.260", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.258", align 8
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %13 = alloca %"class.std::__1::tuple", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %101, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %97

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.260"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #18
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.273"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.260"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !360
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !360
  %38 = bitcast %"class.gemmlowp::MatrixMap.260"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !360
  store i32 %18, i32* %30, align 8, !alias.scope !360
  store i32 %16, i32* %31, align 4, !alias.scope !360
  store i32 %37, i32* %32, align 8, !alias.scope !360
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #18
  %40 = bitcast %"class.gemmlowp::MatrixMap.258"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !365
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !365
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !365
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !365
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !365
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !365
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !365
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !365
  %52 = bitcast %"class.gemmlowp::MatrixMap.258"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #18
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !370
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !370
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !370
  %59 = bitcast %"class.gemmlowp::MatrixMap.258"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !370
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !370
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !370
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !370
  %63 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #18
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !375
  store i32 %66, i32* %64, align 4, !alias.scope !375
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !375
  store i32 %69, i32* %67, align 4, !alias.scope !375
  %70 = bitcast %"class.gemmlowp::VectorDup.272"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #18
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !380
  store i32 %73, i32* %71, align 4, !alias.scope !380
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !380
  store i32 %76, i32* %74, align 4, !alias.scope !380
  %77 = bitcast %"class.std::__1::tuple"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %77) #18
  %78 = bitcast %"class.std::__1::tuple.275"* %6 to i64*
  %79 = load i64, i64* %78, align 8, !noalias !385
  %80 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  %81 = load i32, i32* %80, align 8, !noalias !385
  %82 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !396
  %85 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %6, i64 0, i32 0, i32 1, i32 0, i32 2
  %86 = load i32, i32* %85, align 4, !noalias !396
  %87 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %6, i64 0, i32 0, i32 2, i32 0
  %88 = bitcast %"struct.gemmlowp::OutputStageClamp"* %87 to i64*
  %89 = load i64, i64* %88, align 4, !noalias !396
  %90 = bitcast %"class.std::__1::tuple"* %13 to i64*
  store i64 %79, i64* %90, align 8, !alias.scope !397
  %91 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %81, i32* %91, align 8, !alias.scope !397
  %92 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %13, i64 0, i32 0, i32 1
  %93 = bitcast %"class.std::__1::__tuple_leaf.262"* %92 to i64*
  store i64 %84, i64* %93, align 8, !alias.scope !396
  %94 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %13, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %86, i32* %94, align 8, !alias.scope !396
  %95 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %13, i64 0, i32 0, i32 2
  %96 = bitcast %"class.std::__1::__tuple_leaf.263"* %95 to i64*
  store i64 %89, i64* %96, align 4, !alias.scope !397
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.258"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.260"* nonnull %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple"* nonnull dereferenceable(40) %13)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %77) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #18
  br label %101

97:                                               ; preds = %26
  %98 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %98) #18
  %99 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %99, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %100, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.258"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.273"* %3, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.std::__1::tuple.275"* dereferenceable(40) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %98) #18
  br label %101

101:                                              ; preds = %7, %97, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.std::__1::tuple"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.283", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !400

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #18
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #18
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #18
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #18
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.258"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.260"* %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.std::__1::tuple"* dereferenceable(40) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #18
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !401
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !401
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !401
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !401
  %101 = load i64, i64* %95, align 8, !noalias !401
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !401
  %103 = load i64, i64* %93, align 8, !noalias !401
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !401
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #18
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !404
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !404
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !404
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !404
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #18
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.283"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.260"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.283"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #18
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !407
  %162 = load i32, i32* %128, align 8, !noalias !407
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #18
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #18
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #18
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #18
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.283"* nonnull dereferenceable(24) %13) #18
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #17
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #18
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !410
  %192 = load i32, i32* %143, align 8, !noalias !410
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #17
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #18
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %5, %"class.gemmlowp::VectorDup"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup.272"**
  store %"class.gemmlowp::VectorDup.272"* %6, %"class.gemmlowp::VectorDup.272"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple"**
  store %"class.std::__1::tuple"* %7, %"class.std::__1::tuple"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.283"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #19
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #19
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #17
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #18
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #17
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.275"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.283", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !400

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #18
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #18
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #18
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #18
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.258"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.273"* %4, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.std::__1::tuple.275"* dereferenceable(40) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #18
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !413
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !413
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !413
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !413
  %101 = load i64, i64* %95, align 8, !noalias !413
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !413
  %103 = load i64, i64* %93, align 8, !noalias !413
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !413
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #18
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !416
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !416
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !416
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !416
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #18
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.283"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.273"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.283"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #18
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !419
  %162 = load i32, i32* %128, align 8, !noalias !419
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #18
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #18
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #18
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #18
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.283"* nonnull dereferenceable(24) %13) #18
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #17
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #18
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !422
  %192 = load i32, i32* %143, align 8, !noalias !422
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #17
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #18
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup.272"**
  store %"class.gemmlowp::VectorDup.272"* %5, %"class.gemmlowp::VectorDup.272"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %6, %"class.gemmlowp::VectorDup"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.275"**
  store %"class.std::__1::tuple.275"* %7, %"class.std::__1::tuple.275"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.283"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #19
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #19
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #17
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #18
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #17
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.275"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %22 = alloca %"class.gemmlowp::VectorDup", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #18
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !425
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !425
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !425
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !425
  %67 = load i64, i64* %61, align 8, !noalias !425
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !425
  %69 = load i64, i64* %59, align 8, !noalias !425
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !425
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #18
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !428
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !428
  %82 = load i64, i64* %61, align 8, !noalias !428
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !428
  %84 = load i64, i64* %59, align 8, !noalias !428
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !428
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #18
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !431
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !431
  %106 = load i64, i64* %61, align 8, !noalias !431
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !431
  %108 = load i64, i64* %59, align 8, !noalias !431
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !431
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #18
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !434
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !434
  %121 = load i64, i64* %61, align 8, !noalias !434
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !434
  %123 = load i64, i64* %59, align 8, !noalias !434
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !434
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #18
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !437
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !437
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !437
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !437
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #18
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #18
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.258"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #18
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #18
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #18
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup.272"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #18
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !440
  %228 = load i32, i32* %173, align 8, !noalias !440
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #18
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #18
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #18
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !443
  %247 = load i32, i32* %184, align 8, !noalias !443
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #18
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #18
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #18
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #18
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #18
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #18
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #18
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #18
  %332 = load i32, i32* %208, align 4, !noalias !446
  store i32 %332, i32* %209, align 4, !alias.scope !446
  store i32 %226, i32* %210, align 4, !alias.scope !446
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #18
  %333 = load i32, i32* %212, align 4, !noalias !449
  store i32 %333, i32* %213, align 4, !alias.scope !449
  store i32 %244, i32* %214, align 4, !alias.scope !449
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.273"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.275"* dereferenceable(40) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #18
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"*, i32, i32, i32, i32, i32, i32, float) local_unnamed_addr #1 comdat align 2 {
  %9 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 3
  %10 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 4
  %11 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 5
  %12 = add i32 %1, 3
  %13 = and i32 %12, -4
  %14 = sdiv i32 %13, %4
  %15 = icmp sgt i32 %14, 1
  %16 = select i1 %15, i32 %14, i32 1
  %17 = add i32 %3, 15
  %18 = and i32 %17, -16
  %19 = sdiv i32 %6, %18
  %20 = sitofp i32 %19 to float
  %21 = fmul float %20, %7
  %22 = fptosi float %21 to i32
  %23 = icmp sgt i32 %22, 1
  %24 = select i1 %23, i32 %22, i32 1
  %25 = add i32 %2, -1
  %26 = add i32 %24, %25
  %27 = sdiv i32 %26, %24
  %28 = icmp sgt i32 %27, 1
  %29 = select i1 %28, i32 %27, i32 1
  %30 = add i32 %29, %25
  %31 = sdiv i32 %30, %29
  %32 = add i32 %31, 3
  %33 = and i32 %32, -4
  %34 = fcmp oeq float %7, 1.000000e+00
  br i1 %34, label %35, label %37

35:                                               ; preds = %8
  %36 = shl i32 %33, 2
  br label %53

37:                                               ; preds = %8
  %38 = mul nsw i32 %33, %18
  %39 = sub nsw i32 %6, %38
  %40 = shl i32 %33, 2
  %41 = add nsw i32 %40, %18
  %42 = mul nsw i32 %41, %4
  %43 = sdiv i32 %39, %42
  %44 = icmp sgt i32 %43, 1
  %45 = select i1 %44, i32 %43, i32 1
  %46 = add nsw i32 %16, -1
  %47 = add nuw i32 %45, %46
  %48 = sdiv i32 %47, %45
  %49 = icmp sgt i32 %48, 1
  %50 = select i1 %49, i32 %48, i32 1
  %51 = add nuw i32 %50, %46
  %52 = sdiv i32 %51, %50
  br label %53

53:                                               ; preds = %35, %37
  %54 = phi i32 [ %36, %35 ], [ %40, %37 ]
  %55 = phi i32 [ %16, %35 ], [ %52, %37 ]
  %56 = add i32 %55, 3
  %57 = and i32 %56, -4
  store i32 %57, i32* %9, align 4
  store i32 %33, i32* %10, align 4
  store i32 %18, i32* %11, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 0
  %59 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 1
  %60 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 2
  %61 = add nsw i32 %5, -64
  %62 = sdiv i32 %61, 8
  %63 = icmp sgt i32 %62, 1
  %64 = select i1 %63, i32 %62, i32 1
  %65 = add i32 %18, -1
  %66 = add i32 %64, %65
  %67 = sdiv i32 %66, %64
  %68 = icmp sgt i32 %67, 1
  %69 = select i1 %68, i32 %67, i32 1
  %70 = add i32 %69, %65
  %71 = sdiv i32 %70, %69
  %72 = add i32 %71, 15
  %73 = and i32 %72, -16
  %74 = add nsw i32 %73, %54
  %75 = sdiv i32 %5, %74
  %76 = icmp sgt i32 %75, 1
  %77 = select i1 %76, i32 %75, i32 1
  %78 = add i32 %57, -1
  %79 = add i32 %77, %78
  %80 = sdiv i32 %79, %77
  %81 = icmp sgt i32 %80, 1
  %82 = select i1 %81, i32 %80, i32 1
  %83 = add i32 %82, %78
  %84 = sdiv i32 %83, %82
  %85 = add i32 %84, 3
  %86 = and i32 %85, -4
  store i32 %86, i32* %58, align 4
  store i32 %33, i32* %59, align 4
  store i32 %73, i32* %60, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"*) local_unnamed_addr #1 comdat align 2 {
  %2 = alloca i8*, align 8
  %3 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 4
  %4 = load i64, i64* %3, align 8
  %5 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = icmp ugt i64 %4, %6
  br i1 %7, label %8, label %33

8:                                                ; preds = %1
  %9 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 2
  %10 = load i8*, i8** %9, align 8
  tail call void @free(i8* %10) #18
  %11 = load i64, i64* %3, align 8
  %12 = add i64 %11, -1
  %13 = lshr i64 %12, 1
  %14 = or i64 %13, %12
  %15 = lshr i64 %14, 2
  %16 = or i64 %15, %14
  %17 = lshr i64 %16, 4
  %18 = or i64 %17, %16
  %19 = lshr i64 %18, 8
  %20 = or i64 %19, %18
  %21 = lshr i64 %20, 16
  %22 = or i64 %21, %20
  %23 = add i64 %22, 1
  store i64 %23, i64* %5, align 8
  %24 = bitcast i8** %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %24) #18
  store i8* inttoptr (i64 -6148914691236517206 to i8*), i8** %2, align 8
  %25 = call i32 @posix_memalign(i8** nonnull %2, i64 64, i64 %23) #18
  %26 = icmp eq i32 %25, 0
  br i1 %26, label %27, label %29

27:                                               ; preds = %8
  %28 = load i8*, i8** %2, align 8
  br label %30

29:                                               ; preds = %8
  store i8* null, i8** %2, align 8
  br label %30

30:                                               ; preds = %27, %29
  %31 = phi i8* [ %28, %27 ], [ null, %29 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %24) #18
  store i8* %31, i8** %9, align 8
  %32 = load i64, i64* %5, align 8
  br label %33

33:                                               ; preds = %30, %1
  %34 = phi i64 [ %32, %30 ], [ %6, %1 ]
  %35 = icmp eq i64 %34, 0
  br i1 %35, label %43, label %36

36:                                               ; preds = %33
  %37 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 2
  %38 = load i8*, i8** %37, align 8
  %39 = icmp eq i8* %38, null
  br i1 %39, label %40, label %43

40:                                               ; preds = %36
  %41 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %42 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* %41, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.159, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.158, i64 0, i64 0)) #20
  call void @abort() #19
  unreachable

43:                                               ; preds = %36, %33
  %44 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 0
  store i8 1, i8* %44, align 8
  ret void
}

; Function Attrs: nofree nounwind
declare i32 @__cxa_guard_acquire(i64*) local_unnamed_addr #14

; Function Attrs: nounwind
declare i64 @sysconf(i32) local_unnamed_addr #10

; Function Attrs: nofree nounwind
declare void @__cxa_guard_release(i64*) local_unnamed_addr #14

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.273"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.275"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.gemmlowp::RegisterBlock", align 8
  %11 = alloca %"class.gemmlowp::MatrixMap.292", align 8
  %12 = alloca %"class.gemmlowp::VectorMap", align 8
  %13 = alloca %"class.gemmlowp::VectorMap.279", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.304", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.320", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.336", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.348", align 8
  %19 = alloca %"struct.gemmlowp::OutputPipelineExecutor.364", align 8
  %20 = alloca [64 x i16], align 16
  %21 = alloca %"class.gemmlowp::MatrixMap.260", align 8
  %22 = bitcast %"class.gemmlowp::MatrixMap.292"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %22) #18
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 0
  %24 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 1
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 2
  %26 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 3
  %27 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %28 = bitcast %"class.gemmlowp::MatrixMap.292"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 24, i1 false)
  %29 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %27, align 8, !noalias !452
  %30 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %31 = load i8, i8* %30, align 8, !noalias !452
  %32 = zext i8 %31 to i64
  %33 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %29, i64 0, i32 5, i64 %32
  %34 = load i64, i64* %33, align 8, !noalias !452
  %35 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %29, i64 0, i32 2
  %36 = bitcast i8** %35 to i64*
  %37 = load i64, i64* %36, align 8, !noalias !452
  %38 = add i64 %37, %34
  %39 = inttoptr i64 %38 to i32*
  %40 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %41 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %40, align 8, !noalias !452
  %42 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %41, i64 0, i32 3
  %43 = load i32, i32* %42, align 4, !noalias !452
  %44 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %41, i64 0, i32 4
  %45 = load i32, i32* %44, align 4, !noalias !452
  store i32* %39, i32** %23, align 8, !alias.scope !452
  store i32 %43, i32* %24, align 8, !alias.scope !452
  store i32 %45, i32* %25, align 4, !alias.scope !452
  store i32 %43, i32* %26, align 8, !alias.scope !452
  %46 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %46) #18
  %47 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 0
  %48 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 1
  %49 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %50 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %50, i8 -86, i64 16, i1 false)
  %51 = load i32, i32* %49, align 4
  store i32* %4, i32** %47, align 8
  store i32 %51, i32* %48, align 8
  %52 = bitcast %"class.gemmlowp::VectorMap.279"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %52) #18
  %53 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %13, i64 0, i32 0
  %54 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %13, i64 0, i32 1
  %55 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %56 = bitcast %"class.gemmlowp::VectorMap.279"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %56, i8 -86, i64 16, i1 false)
  %57 = load i32, i32* %55, align 4
  store i32* %5, i32** %53, align 8
  store i32 %57, i32* %54, align 8
  %58 = bitcast %"struct.gemmlowp::OutputPipelineExecutor"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %58) #18
  %59 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %60 = bitcast i8* %59 to i64*
  store i64 -6148914691236517206, i64* %60, align 8
  %61 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %8, i64 0, i32 0, i32 0, i32 0
  %62 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.278"* %61, %"struct.gemmlowp::OutputStageBiasAddition.278"** %62, align 8
  %63 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %8, i64 0, i32 0, i32 1, i32 0
  %64 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %64, align 8
  %65 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %66 = load i32, i32* %65, align 4
  %67 = icmp sgt i32 %66, 0
  %68 = select i1 %67, i32 %66, i32 0
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %69, align 8
  %70 = sub nsw i32 0, %66
  %71 = icmp sgt i32 %70, 0
  %72 = select i1 %71, i32 %70, i32 0
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %73, align 4
  %74 = getelementptr inbounds %"class.std::__1::tuple.275", %"class.std::__1::tuple.275"* %8, i64 0, i32 0, i32 2, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %75, align 8
  %76 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.304"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %76) #18
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %15, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %78 = bitcast i8* %77 to i64*
  store i64 -6148914691236517206, i64* %78, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %15, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.278"* %61, %"struct.gemmlowp::OutputStageBiasAddition.278"** %79, align 8
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %80, align 8
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %81, align 8
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %82, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %83, align 8
  %84 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.320"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %84) #18
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.320", %"struct.gemmlowp::OutputPipelineExecutor.320"* %16, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %86 = bitcast i8* %85 to i64*
  store i64 -6148914691236517206, i64* %86, align 8
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.320", %"struct.gemmlowp::OutputPipelineExecutor.320"* %16, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.278"* %61, %"struct.gemmlowp::OutputStageBiasAddition.278"** %87, align 8
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.320", %"struct.gemmlowp::OutputPipelineExecutor.320"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %88, align 8
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.320", %"struct.gemmlowp::OutputPipelineExecutor.320"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %89, align 8
  %90 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.320", %"struct.gemmlowp::OutputPipelineExecutor.320"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %90, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.320", %"struct.gemmlowp::OutputPipelineExecutor.320"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %91, align 8
  %92 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.336"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %92) #18
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %17, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %94 = bitcast i8* %93 to i64*
  store i64 -6148914691236517206, i64* %94, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %17, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.278"* %61, %"struct.gemmlowp::OutputStageBiasAddition.278"** %95, align 8
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %96, align 8
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %97, align 8
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %98, align 4
  %99 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %99, align 8
  %100 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.348"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %100) #18
  %101 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.348", %"struct.gemmlowp::OutputPipelineExecutor.348"* %18, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %102 = bitcast i8* %101 to i64*
  store i64 -6148914691236517206, i64* %102, align 8
  %103 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.348", %"struct.gemmlowp::OutputPipelineExecutor.348"* %18, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.278"* %61, %"struct.gemmlowp::OutputStageBiasAddition.278"** %103, align 8
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.348", %"struct.gemmlowp::OutputPipelineExecutor.348"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %104, align 8
  %105 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.348", %"struct.gemmlowp::OutputPipelineExecutor.348"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %105, align 8
  %106 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.348", %"struct.gemmlowp::OutputPipelineExecutor.348"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %106, align 4
  %107 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.348", %"struct.gemmlowp::OutputPipelineExecutor.348"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %107, align 8
  %108 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.364"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %108) #18
  %109 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %19, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %110 = bitcast i8* %109 to i64*
  store i64 -6148914691236517206, i64* %110, align 8
  %111 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %19, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.278"* %61, %"struct.gemmlowp::OutputStageBiasAddition.278"** %111, align 8
  %112 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %112, align 8
  %113 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %113, align 8
  %114 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %114, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %19, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %115, align 8
  %116 = icmp slt i32 %57, 8
  br i1 %116, label %130, label %117

117:                                              ; preds = %9
  %118 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %119 = bitcast [64 x i16]* %20 to i8*
  %120 = bitcast %"class.gemmlowp::MatrixMap.260"* %21 to i8*
  %121 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %21, i64 0, i32 0
  %122 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %21, i64 0, i32 1
  %123 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %21, i64 0, i32 2
  %124 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %21, i64 0, i32 3
  %125 = getelementptr inbounds [64 x i16], [64 x i16]* %20, i64 0, i64 0
  %126 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %127 = bitcast %"struct.gemmlowp::RegisterBlock"* %10 to i8*
  %128 = load i32, i32* %49, align 4
  %129 = bitcast %"class.gemmlowp::MatrixMap.260"* %21 to i8*
  br label %139

130:                                              ; preds = %301, %9
  %131 = phi i32 [ %57, %9 ], [ %304, %301 ]
  %132 = phi i32 [ 0, %9 ], [ %303, %301 ]
  %133 = add nsw i32 %131, -4
  %134 = icmp sgt i32 %132, %133
  br i1 %134, label %307, label %135

135:                                              ; preds = %130
  %136 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %138 = load i32, i32* %49, align 4
  br label %318

139:                                              ; preds = %117, %301
  %140 = phi i32 [ %128, %117 ], [ %302, %301 ]
  %141 = phi i32 [ 0, %117 ], [ %303, %301 ]
  %142 = load i32*, i32** %23, align 8
  %143 = load i32, i32* %26, align 8
  %144 = mul nsw i32 %143, %141
  %145 = sext i32 %144 to i64
  %146 = load i32*, i32** %47, align 8
  %147 = bitcast i32* %146 to i8*
  call void @llvm.prefetch(i8* %147, i32 0, i32 3, i32 1) #18
  %148 = getelementptr inbounds i32, i32* %146, i64 4
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #18
  %150 = getelementptr inbounds i32, i32* %142, i64 %145
  %151 = sext i32 %143 to i64
  %152 = bitcast i32* %150 to i8*
  call void @llvm.prefetch(i8* %152, i32 0, i32 3, i32 1) #18
  %153 = getelementptr inbounds i32, i32* %150, i64 4
  %154 = bitcast i32* %153 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #18
  %155 = getelementptr inbounds i32, i32* %150, i64 %151
  %156 = bitcast i32* %155 to i8*
  call void @llvm.prefetch(i8* %156, i32 0, i32 3, i32 1) #18
  %157 = getelementptr inbounds i32, i32* %155, i64 4
  %158 = bitcast i32* %157 to i8*
  call void @llvm.prefetch(i8* %158, i32 0, i32 3, i32 1) #18
  %159 = shl nsw i64 %151, 1
  %160 = getelementptr inbounds i32, i32* %150, i64 %159
  %161 = bitcast i32* %160 to i8*
  call void @llvm.prefetch(i8* %161, i32 0, i32 3, i32 1) #18
  %162 = getelementptr inbounds i32, i32* %160, i64 4
  %163 = bitcast i32* %162 to i8*
  call void @llvm.prefetch(i8* %163, i32 0, i32 3, i32 1) #18
  %164 = mul nsw i64 %151, 3
  %165 = getelementptr inbounds i32, i32* %150, i64 %164
  %166 = bitcast i32* %165 to i8*
  call void @llvm.prefetch(i8* %166, i32 0, i32 3, i32 1) #18
  %167 = getelementptr inbounds i32, i32* %165, i64 4
  %168 = bitcast i32* %167 to i8*
  call void @llvm.prefetch(i8* %168, i32 0, i32 3, i32 1) #18
  %169 = shl nsw i64 %151, 2
  %170 = getelementptr inbounds i32, i32* %150, i64 %169
  %171 = bitcast i32* %170 to i8*
  call void @llvm.prefetch(i8* %171, i32 0, i32 3, i32 1) #18
  %172 = getelementptr inbounds i32, i32* %170, i64 4
  %173 = bitcast i32* %172 to i8*
  call void @llvm.prefetch(i8* %173, i32 0, i32 3, i32 1) #18
  %174 = mul nsw i64 %151, 5
  %175 = getelementptr inbounds i32, i32* %150, i64 %174
  %176 = bitcast i32* %175 to i8*
  call void @llvm.prefetch(i8* %176, i32 0, i32 3, i32 1) #18
  %177 = getelementptr inbounds i32, i32* %175, i64 4
  %178 = bitcast i32* %177 to i8*
  call void @llvm.prefetch(i8* %178, i32 0, i32 3, i32 1) #18
  %179 = mul nsw i64 %151, 6
  %180 = getelementptr inbounds i32, i32* %150, i64 %179
  %181 = bitcast i32* %180 to i8*
  call void @llvm.prefetch(i8* %181, i32 0, i32 3, i32 1) #18
  %182 = getelementptr inbounds i32, i32* %180, i64 4
  %183 = bitcast i32* %182 to i8*
  call void @llvm.prefetch(i8* %183, i32 0, i32 3, i32 1) #18
  %184 = mul nsw i64 %151, 7
  %185 = getelementptr inbounds i32, i32* %150, i64 %184
  %186 = bitcast i32* %185 to i8*
  call void @llvm.prefetch(i8* %186, i32 0, i32 3, i32 1) #18
  %187 = getelementptr inbounds i32, i32* %185, i64 4
  %188 = bitcast i32* %187 to i8*
  call void @llvm.prefetch(i8* %188, i32 0, i32 3, i32 1) #18
  %189 = icmp slt i32 %140, 8
  br i1 %189, label %194, label %190

190:                                              ; preds = %139
  %191 = or i32 %141, 4
  br label %201

192:                                              ; preds = %201
  %193 = trunc i64 %209 to i32
  br label %194

194:                                              ; preds = %192, %139
  %195 = phi i32 [ %140, %139 ], [ %264, %192 ]
  %196 = phi i32 [ 0, %139 ], [ %193, %192 ]
  %197 = add nsw i32 %195, -4
  %198 = icmp sgt i32 %196, %197
  br i1 %198, label %272, label %199

199:                                              ; preds = %194
  %200 = or i32 %141, 4
  br label %278

201:                                              ; preds = %268, %190
  %202 = phi i32* [ %146, %190 ], [ %271, %268 ]
  %203 = phi i32 [ %143, %190 ], [ %270, %268 ]
  %204 = phi i32* [ %142, %190 ], [ %269, %268 ]
  %205 = phi i64 [ 0, %190 ], [ %209, %268 ]
  %206 = load i32, i32* %118, align 4
  %207 = trunc i64 %205 to i32
  %208 = add nsw i32 %206, %207
  %209 = add nuw i64 %205, 8
  %210 = mul nsw i32 %203, %141
  %211 = sext i32 %210 to i64
  %212 = getelementptr inbounds i32, i32* %202, i64 %209
  %213 = bitcast i32* %212 to i8*
  call void @llvm.prefetch(i8* %213, i32 0, i32 3, i32 1) #18
  %214 = getelementptr inbounds i32, i32* %212, i64 4
  %215 = bitcast i32* %214 to i8*
  call void @llvm.prefetch(i8* %215, i32 0, i32 3, i32 1) #18
  %216 = getelementptr inbounds i32, i32* %204, i64 %209
  %217 = getelementptr inbounds i32, i32* %216, i64 %211
  %218 = sext i32 %203 to i64
  %219 = bitcast i32* %217 to i8*
  call void @llvm.prefetch(i8* %219, i32 0, i32 3, i32 1) #18
  %220 = getelementptr inbounds i32, i32* %217, i64 4
  %221 = bitcast i32* %220 to i8*
  call void @llvm.prefetch(i8* %221, i32 0, i32 3, i32 1) #18
  %222 = getelementptr inbounds i32, i32* %217, i64 %218
  %223 = bitcast i32* %222 to i8*
  call void @llvm.prefetch(i8* %223, i32 0, i32 3, i32 1) #18
  %224 = getelementptr inbounds i32, i32* %222, i64 4
  %225 = bitcast i32* %224 to i8*
  call void @llvm.prefetch(i8* %225, i32 0, i32 3, i32 1) #18
  %226 = shl nsw i64 %218, 1
  %227 = getelementptr inbounds i32, i32* %217, i64 %226
  %228 = bitcast i32* %227 to i8*
  call void @llvm.prefetch(i8* %228, i32 0, i32 3, i32 1) #18
  %229 = getelementptr inbounds i32, i32* %227, i64 4
  %230 = bitcast i32* %229 to i8*
  call void @llvm.prefetch(i8* %230, i32 0, i32 3, i32 1) #18
  %231 = mul nsw i64 %218, 3
  %232 = getelementptr inbounds i32, i32* %217, i64 %231
  %233 = bitcast i32* %232 to i8*
  call void @llvm.prefetch(i8* %233, i32 0, i32 3, i32 1) #18
  %234 = getelementptr inbounds i32, i32* %232, i64 4
  %235 = bitcast i32* %234 to i8*
  call void @llvm.prefetch(i8* %235, i32 0, i32 3, i32 1) #18
  %236 = shl nsw i64 %218, 2
  %237 = getelementptr inbounds i32, i32* %217, i64 %236
  %238 = bitcast i32* %237 to i8*
  call void @llvm.prefetch(i8* %238, i32 0, i32 3, i32 1) #18
  %239 = getelementptr inbounds i32, i32* %237, i64 4
  %240 = bitcast i32* %239 to i8*
  call void @llvm.prefetch(i8* %240, i32 0, i32 3, i32 1) #18
  %241 = mul nsw i64 %218, 5
  %242 = getelementptr inbounds i32, i32* %217, i64 %241
  %243 = bitcast i32* %242 to i8*
  call void @llvm.prefetch(i8* %243, i32 0, i32 3, i32 1) #18
  %244 = getelementptr inbounds i32, i32* %242, i64 4
  %245 = bitcast i32* %244 to i8*
  call void @llvm.prefetch(i8* %245, i32 0, i32 3, i32 1) #18
  %246 = mul nsw i64 %218, 6
  %247 = getelementptr inbounds i32, i32* %217, i64 %246
  %248 = bitcast i32* %247 to i8*
  call void @llvm.prefetch(i8* %248, i32 0, i32 3, i32 1) #18
  %249 = getelementptr inbounds i32, i32* %247, i64 4
  %250 = bitcast i32* %249 to i8*
  call void @llvm.prefetch(i8* %250, i32 0, i32 3, i32 1) #18
  %251 = mul nsw i64 %218, 7
  %252 = getelementptr inbounds i32, i32* %217, i64 %251
  %253 = bitcast i32* %252 to i8*
  call void @llvm.prefetch(i8* %253, i32 0, i32 3, i32 1) #18
  %254 = getelementptr inbounds i32, i32* %252, i64 4
  %255 = bitcast i32* %254 to i8*
  call void @llvm.prefetch(i8* %255, i32 0, i32 3, i32 1) #18
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %119) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %119, i8 -86, i64 128, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %120) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false)
  store i16* %125, i16** %121, align 8
  store i32 8, i32* %122, align 8
  store i32 8, i32* %123, align 4
  store i32 8, i32* %124, align 8
  %256 = load i32, i32* %126, align 4
  %257 = add nsw i32 %256, %141
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.364"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.260"* nonnull %21, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %207, i32 %141, i32 %208, i32 %257, i32 0, i32 0)
  %258 = load i32, i32* %126, align 4
  %259 = add nsw i32 %258, %191
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.364"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.260"* nonnull %21, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %207, i32 %191, i32 %208, i32 %259, i32 0, i32 4)
  %260 = load i32, i32* %118, align 4
  %261 = add nsw i32 %260, %207
  %262 = load i32, i32* %126, align 4
  %263 = add nsw i32 %262, %141
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %127)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %127, i8* nonnull align 16 %119, i64 128, i1 false)
  call void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIsLi8ELi8EEENS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock"* nonnull dereferenceable(128) %10, %"class.gemmlowp::MatrixMap.273"* %0, i32 %261, i32 %263) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %127)
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %120) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %119) #18
  %264 = load i32, i32* %49, align 4
  %265 = add nsw i32 %264, -8
  %266 = trunc i64 %209 to i32
  %267 = icmp slt i32 %265, %266
  br i1 %267, label %192, label %268

268:                                              ; preds = %201
  %269 = load i32*, i32** %23, align 8
  %270 = load i32, i32* %26, align 8
  %271 = load i32*, i32** %47, align 8
  br label %201

272:                                              ; preds = %278, %194
  %273 = phi i32 [ %195, %194 ], [ %287, %278 ]
  %274 = phi i32 [ %196, %194 ], [ %286, %278 ]
  %275 = icmp slt i32 %274, %273
  br i1 %275, label %276, label %301

276:                                              ; preds = %272
  %277 = or i32 %141, 4
  br label %290

278:                                              ; preds = %199, %278
  %279 = phi i32 [ %286, %278 ], [ %196, %199 ]
  %280 = load i32, i32* %118, align 4
  %281 = add nsw i32 %280, %279
  %282 = load i32, i32* %126, align 4
  %283 = add nsw i32 %282, %141
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.348"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %279, i32 %141, i32 %281, i32 %283, i32 %281, i32 %283)
  %284 = load i32, i32* %126, align 4
  %285 = add nsw i32 %284, %200
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.348"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %279, i32 %200, i32 %281, i32 %285, i32 %281, i32 %285)
  %286 = add nuw nsw i32 %279, 4
  %287 = load i32, i32* %49, align 4
  %288 = add nsw i32 %287, -4
  %289 = icmp sgt i32 %286, %288
  br i1 %289, label %272, label %278

290:                                              ; preds = %276, %290
  %291 = phi i32 [ %298, %290 ], [ %274, %276 ]
  %292 = load i32, i32* %118, align 4
  %293 = add nsw i32 %292, %291
  %294 = load i32, i32* %126, align 4
  %295 = add nsw i32 %294, %141
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.336"* nonnull dereferenceable(40) %17, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %291, i32 %141, i32 %293, i32 %295, i32 %293, i32 %295)
  %296 = load i32, i32* %126, align 4
  %297 = add nsw i32 %296, %277
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.336"* nonnull dereferenceable(40) %17, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %291, i32 %277, i32 %293, i32 %297, i32 %293, i32 %297)
  %298 = add nuw nsw i32 %291, 1
  %299 = load i32, i32* %49, align 4
  %300 = icmp slt i32 %298, %299
  br i1 %300, label %290, label %301

301:                                              ; preds = %290, %272
  %302 = phi i32 [ %273, %272 ], [ %299, %290 ]
  %303 = add nuw nsw i32 %141, 8
  %304 = load i32, i32* %55, align 4
  %305 = add nsw i32 %304, -8
  %306 = icmp sgt i32 %303, %305
  br i1 %306, label %130, label %139

307:                                              ; preds = %420, %130
  %308 = phi i32 [ %131, %130 ], [ %423, %420 ]
  %309 = phi i32 [ %132, %130 ], [ %422, %420 ]
  %310 = icmp slt i32 %309, %308
  br i1 %310, label %311, label %565

311:                                              ; preds = %307
  %312 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %313 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %314 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %315 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %7, i64 0, i32 0
  %316 = zext i32 %309 to i64
  %317 = load i32, i32* %49, align 4
  br label %426

318:                                              ; preds = %135, %420
  %319 = phi i32 [ %138, %135 ], [ %421, %420 ]
  %320 = phi i32 [ %132, %135 ], [ %422, %420 ]
  %321 = load i32, i32* %136, align 4
  %322 = add nsw i32 %321, %320
  %323 = load i32*, i32** %23, align 8
  %324 = load i32, i32* %26, align 8
  %325 = mul nsw i32 %324, %320
  %326 = sext i32 %325 to i64
  %327 = load i32*, i32** %47, align 8
  %328 = bitcast i32* %327 to i8*
  call void @llvm.prefetch(i8* %328, i32 0, i32 3, i32 1) #18
  %329 = getelementptr inbounds i32, i32* %327, i64 4
  %330 = bitcast i32* %329 to i8*
  call void @llvm.prefetch(i8* %330, i32 0, i32 3, i32 1) #18
  %331 = getelementptr inbounds i32, i32* %323, i64 %326
  %332 = sext i32 %324 to i64
  %333 = bitcast i32* %331 to i8*
  call void @llvm.prefetch(i8* %333, i32 0, i32 3, i32 1) #18
  %334 = getelementptr inbounds i32, i32* %331, i64 4
  %335 = bitcast i32* %334 to i8*
  call void @llvm.prefetch(i8* %335, i32 0, i32 3, i32 1) #18
  %336 = getelementptr inbounds i32, i32* %331, i64 %332
  %337 = bitcast i32* %336 to i8*
  call void @llvm.prefetch(i8* %337, i32 0, i32 3, i32 1) #18
  %338 = getelementptr inbounds i32, i32* %336, i64 4
  %339 = bitcast i32* %338 to i8*
  call void @llvm.prefetch(i8* %339, i32 0, i32 3, i32 1) #18
  %340 = shl nsw i64 %332, 1
  %341 = getelementptr inbounds i32, i32* %331, i64 %340
  %342 = bitcast i32* %341 to i8*
  call void @llvm.prefetch(i8* %342, i32 0, i32 3, i32 1) #18
  %343 = getelementptr inbounds i32, i32* %341, i64 4
  %344 = bitcast i32* %343 to i8*
  call void @llvm.prefetch(i8* %344, i32 0, i32 3, i32 1) #18
  %345 = mul nsw i64 %332, 3
  %346 = getelementptr inbounds i32, i32* %331, i64 %345
  %347 = bitcast i32* %346 to i8*
  call void @llvm.prefetch(i8* %347, i32 0, i32 3, i32 1) #18
  %348 = getelementptr inbounds i32, i32* %346, i64 4
  %349 = bitcast i32* %348 to i8*
  call void @llvm.prefetch(i8* %349, i32 0, i32 3, i32 1) #18
  %350 = icmp slt i32 %319, 8
  br i1 %350, label %353, label %358

351:                                              ; preds = %358
  %352 = trunc i64 %366 to i32
  br label %353

353:                                              ; preds = %351, %318
  %354 = phi i32 [ %319, %318 ], [ %393, %351 ]
  %355 = phi i32 [ 0, %318 ], [ %352, %351 ]
  %356 = add nsw i32 %354, -4
  %357 = icmp sgt i32 %355, %356
  br i1 %357, label %401, label %405

358:                                              ; preds = %318, %397
  %359 = phi i32* [ %400, %397 ], [ %327, %318 ]
  %360 = phi i32 [ %399, %397 ], [ %324, %318 ]
  %361 = phi i32* [ %398, %397 ], [ %323, %318 ]
  %362 = phi i64 [ %366, %397 ], [ 0, %318 ]
  %363 = load i32, i32* %137, align 4
  %364 = trunc i64 %362 to i32
  %365 = add nsw i32 %363, %364
  %366 = add nuw i64 %362, 8
  %367 = mul nsw i32 %360, %320
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i32, i32* %359, i64 %366
  %370 = bitcast i32* %369 to i8*
  call void @llvm.prefetch(i8* %370, i32 0, i32 3, i32 1) #18
  %371 = getelementptr inbounds i32, i32* %369, i64 4
  %372 = bitcast i32* %371 to i8*
  call void @llvm.prefetch(i8* %372, i32 0, i32 3, i32 1) #18
  %373 = getelementptr inbounds i32, i32* %361, i64 %366
  %374 = getelementptr inbounds i32, i32* %373, i64 %368
  %375 = sext i32 %360 to i64
  %376 = bitcast i32* %374 to i8*
  call void @llvm.prefetch(i8* %376, i32 0, i32 3, i32 1) #18
  %377 = getelementptr inbounds i32, i32* %374, i64 4
  %378 = bitcast i32* %377 to i8*
  call void @llvm.prefetch(i8* %378, i32 0, i32 3, i32 1) #18
  %379 = getelementptr inbounds i32, i32* %374, i64 %375
  %380 = bitcast i32* %379 to i8*
  call void @llvm.prefetch(i8* %380, i32 0, i32 3, i32 1) #18
  %381 = getelementptr inbounds i32, i32* %379, i64 4
  %382 = bitcast i32* %381 to i8*
  call void @llvm.prefetch(i8* %382, i32 0, i32 3, i32 1) #18
  %383 = shl nsw i64 %375, 1
  %384 = getelementptr inbounds i32, i32* %374, i64 %383
  %385 = bitcast i32* %384 to i8*
  call void @llvm.prefetch(i8* %385, i32 0, i32 3, i32 1) #18
  %386 = getelementptr inbounds i32, i32* %384, i64 4
  %387 = bitcast i32* %386 to i8*
  call void @llvm.prefetch(i8* %387, i32 0, i32 3, i32 1) #18
  %388 = mul nsw i64 %375, 3
  %389 = getelementptr inbounds i32, i32* %374, i64 %388
  %390 = bitcast i32* %389 to i8*
  call void @llvm.prefetch(i8* %390, i32 0, i32 3, i32 1) #18
  %391 = getelementptr inbounds i32, i32* %389, i64 4
  %392 = bitcast i32* %391 to i8*
  call void @llvm.prefetch(i8* %392, i32 0, i32 3, i32 1) #18
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.364"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %364, i32 %320, i32 %365, i32 %322, i32 %365, i32 %322)
  %393 = load i32, i32* %49, align 4
  %394 = add nsw i32 %393, -8
  %395 = trunc i64 %366 to i32
  %396 = icmp slt i32 %394, %395
  br i1 %396, label %351, label %397

397:                                              ; preds = %358
  %398 = load i32*, i32** %23, align 8
  %399 = load i32, i32* %26, align 8
  %400 = load i32*, i32** %47, align 8
  br label %358

401:                                              ; preds = %405, %353
  %402 = phi i32 [ %354, %353 ], [ %410, %405 ]
  %403 = phi i32 [ %355, %353 ], [ %409, %405 ]
  %404 = icmp slt i32 %403, %402
  br i1 %404, label %413, label %420

405:                                              ; preds = %353, %405
  %406 = phi i32 [ %409, %405 ], [ %355, %353 ]
  %407 = load i32, i32* %137, align 4
  %408 = add nsw i32 %407, %406
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.348"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %406, i32 %320, i32 %408, i32 %322, i32 %408, i32 %322)
  %409 = add nuw nsw i32 %406, 4
  %410 = load i32, i32* %49, align 4
  %411 = add nsw i32 %410, -4
  %412 = icmp sgt i32 %409, %411
  br i1 %412, label %401, label %405

413:                                              ; preds = %401, %413
  %414 = phi i32 [ %417, %413 ], [ %403, %401 ]
  %415 = load i32, i32* %137, align 4
  %416 = add nsw i32 %415, %414
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.336"* nonnull dereferenceable(40) %17, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %414, i32 %320, i32 %416, i32 %322, i32 %416, i32 %322)
  %417 = add nuw nsw i32 %414, 1
  %418 = load i32, i32* %49, align 4
  %419 = icmp slt i32 %417, %418
  br i1 %419, label %413, label %420

420:                                              ; preds = %413, %401
  %421 = phi i32 [ %402, %401 ], [ %418, %413 ]
  %422 = add nuw nsw i32 %320, 4
  %423 = load i32, i32* %55, align 4
  %424 = add nsw i32 %423, -4
  %425 = icmp sgt i32 %422, %424
  br i1 %425, label %307, label %318

426:                                              ; preds = %311, %559
  %427 = phi i32 [ %317, %311 ], [ %560, %559 ]
  %428 = phi i64 [ %316, %311 ], [ %561, %559 ]
  %429 = load i32, i32* %312, align 4
  %430 = trunc i64 %428 to i32
  %431 = add nsw i32 %429, %430
  %432 = load i32*, i32** %23, align 8
  %433 = load i32, i32* %26, align 8
  %434 = mul nsw i32 %433, %430
  %435 = sext i32 %434 to i64
  %436 = load i32*, i32** %47, align 8
  %437 = bitcast i32* %436 to i8*
  call void @llvm.prefetch(i8* %437, i32 0, i32 3, i32 1) #18
  %438 = getelementptr inbounds i32, i32* %436, i64 4
  %439 = bitcast i32* %438 to i8*
  call void @llvm.prefetch(i8* %439, i32 0, i32 3, i32 1) #18
  %440 = getelementptr inbounds i32, i32* %432, i64 %435
  %441 = bitcast i32* %440 to i8*
  call void @llvm.prefetch(i8* %441, i32 0, i32 3, i32 1) #18
  %442 = getelementptr inbounds i32, i32* %440, i64 4
  %443 = bitcast i32* %442 to i8*
  call void @llvm.prefetch(i8* %443, i32 0, i32 3, i32 1) #18
  %444 = icmp slt i32 %427, 8
  br i1 %444, label %447, label %454

445:                                              ; preds = %454
  %446 = trunc i64 %462 to i32
  br label %447

447:                                              ; preds = %445, %426
  %448 = phi i32 [ %427, %426 ], [ %474, %445 ]
  %449 = phi i32 [ 0, %426 ], [ %446, %445 ]
  %450 = add nsw i32 %448, -4
  %451 = icmp sgt i32 %449, %450
  br i1 %451, label %484, label %452

452:                                              ; preds = %447
  %453 = zext i32 %449 to i64
  br label %488

454:                                              ; preds = %426, %478
  %455 = phi i32* [ %481, %478 ], [ %436, %426 ]
  %456 = phi i32 [ %480, %478 ], [ %433, %426 ]
  %457 = phi i32* [ %479, %478 ], [ %432, %426 ]
  %458 = phi i64 [ %462, %478 ], [ 0, %426 ]
  %459 = load i32, i32* %313, align 4
  %460 = trunc i64 %458 to i32
  %461 = add nsw i32 %459, %460
  %462 = add nuw i64 %458, 8
  %463 = mul nsw i32 %456, %430
  %464 = sext i32 %463 to i64
  %465 = getelementptr inbounds i32, i32* %455, i64 %462
  %466 = bitcast i32* %465 to i8*
  call void @llvm.prefetch(i8* %466, i32 0, i32 3, i32 1) #18
  %467 = getelementptr inbounds i32, i32* %465, i64 4
  %468 = bitcast i32* %467 to i8*
  call void @llvm.prefetch(i8* %468, i32 0, i32 3, i32 1) #18
  %469 = getelementptr inbounds i32, i32* %457, i64 %462
  %470 = getelementptr inbounds i32, i32* %469, i64 %464
  %471 = bitcast i32* %470 to i8*
  call void @llvm.prefetch(i8* %471, i32 0, i32 3, i32 1) #18
  %472 = getelementptr inbounds i32, i32* %470, i64 4
  %473 = bitcast i32* %472 to i8*
  call void @llvm.prefetch(i8* %473, i32 0, i32 3, i32 1) #18
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.320"* nonnull dereferenceable(40) %16, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %460, i32 %430, i32 %461, i32 %431, i32 %461, i32 %431)
  %474 = load i32, i32* %49, align 4
  %475 = add nsw i32 %474, -8
  %476 = trunc i64 %462 to i32
  %477 = icmp slt i32 %475, %476
  br i1 %477, label %445, label %478

478:                                              ; preds = %454
  %479 = load i32*, i32** %23, align 8
  %480 = load i32, i32* %26, align 8
  %481 = load i32*, i32** %47, align 8
  br label %454

482:                                              ; preds = %488
  %483 = trunc i64 %547 to i32
  br label %484

484:                                              ; preds = %482, %447
  %485 = phi i32 [ %448, %447 ], [ %548, %482 ]
  %486 = phi i32 [ %449, %447 ], [ %483, %482 ]
  %487 = icmp slt i32 %486, %485
  br i1 %487, label %552, label %559

488:                                              ; preds = %452, %488
  %489 = phi i64 [ %453, %452 ], [ %547, %488 ]
  %490 = load i32, i32* %313, align 4
  %491 = trunc i64 %489 to i32
  %492 = add nsw i32 %490, %491
  %493 = load i32*, i32** %23, align 8
  %494 = getelementptr inbounds i32, i32* %493, i64 %489
  %495 = load i32, i32* %26, align 8
  %496 = mul nsw i32 %495, %430
  %497 = sext i32 %496 to i64
  %498 = getelementptr inbounds i32, i32* %494, i64 %497
  %499 = getelementptr inbounds i32, i32* %498, i64 1
  %500 = load i32, i32* %498, align 4
  %501 = getelementptr inbounds i32, i32* %499, i64 1
  %502 = load i32, i32* %499, align 4
  %503 = getelementptr inbounds i32, i32* %501, i64 1
  %504 = load i32, i32* %501, align 4
  %505 = load i32, i32* %503, align 4
  %506 = load i32*, i32** %47, align 8
  %507 = getelementptr i32, i32* %506, i64 %489
  %508 = bitcast i32* %507 to i64*
  %509 = load i64, i64* %508, align 4
  %510 = getelementptr inbounds i32, i32* %507, i64 2
  %511 = bitcast i32* %510 to i64*
  %512 = load i64, i64* %511, align 4
  %513 = trunc i64 %509 to i32
  %514 = lshr i64 %509, 32
  %515 = trunc i64 %514 to i32
  %516 = load i32*, i32** %53, align 8
  %517 = getelementptr inbounds i32, i32* %516, i64 %428
  %518 = load i32, i32* %517, align 4
  %519 = load i32, i32* %314, align 4
  %520 = load i32, i32* %315, align 4
  %521 = mul nsw i32 %520, %513
  %522 = add nsw i32 %521, %500
  %523 = mul nsw i32 %520, %515
  %524 = add nsw i32 %523, %502
  %525 = trunc i64 %512 to i32
  %526 = mul nsw i32 %520, %525
  %527 = add nsw i32 %526, %504
  %528 = lshr i64 %512, 32
  %529 = trunc i64 %528 to i32
  %530 = mul nsw i32 %520, %529
  %531 = add nsw i32 %530, %505
  %532 = mul nsw i32 %520, %3
  %533 = add nsw i32 %532, %518
  %534 = mul nsw i32 %533, %519
  %535 = add nsw i32 %522, %534
  %536 = add nsw i32 %524, %534
  %537 = add nsw i32 %527, %534
  %538 = zext i32 %537 to i64
  %539 = add nsw i32 %531, %534
  %540 = zext i32 %539 to i64
  %541 = shl nuw i64 %540, 32
  %542 = or i64 %541, %538
  %543 = zext i32 %536 to i64
  %544 = shl nuw i64 %543, 32
  %545 = zext i32 %535 to i64
  %546 = or i64 %544, %545
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.304"* nonnull %15, i64 %546, i64 %542, %"class.gemmlowp::MatrixMap.273"* %0, i32 %492, i32 %431, i32 %492, i32 %431) #18
  %547 = add nuw i64 %489, 4
  %548 = load i32, i32* %49, align 4
  %549 = add nsw i32 %548, -4
  %550 = trunc i64 %547 to i32
  %551 = icmp slt i32 %549, %550
  br i1 %551, label %482, label %488

552:                                              ; preds = %484, %552
  %553 = phi i32 [ %556, %552 ], [ %486, %484 ]
  %554 = load i32, i32* %313, align 4
  %555 = add nsw i32 %554, %553
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor"* nonnull dereferenceable(40) %14, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %553, i32 %430, i32 %555, i32 %431, i32 %555, i32 %431)
  %556 = add nuw nsw i32 %553, 1
  %557 = load i32, i32* %49, align 4
  %558 = icmp slt i32 %556, %557
  br i1 %558, label %552, label %559

559:                                              ; preds = %552, %484
  %560 = phi i32 [ %485, %484 ], [ %557, %552 ]
  %561 = add nuw nsw i64 %428, 1
  %562 = load i32, i32* %55, align 4
  %563 = trunc i64 %561 to i32
  %564 = icmp sgt i32 %562, %563
  br i1 %564, label %426, label %565

565:                                              ; preds = %559, %307
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %108) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %100) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %92) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %84) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %76) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %58) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %52) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %46) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %22) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"*) local_unnamed_addr #1 comdat align 2 {
  %2 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 0
  %3 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %2, align 8
  %4 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %3, i64 0, i32 1
  %5 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %4, align 8
  %6 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %3, i64 0, i32 3, i32 0
  %7 = load i8, i8* %6, align 8
  %8 = zext i8 %7 to i64
  %9 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 5, i64 %8
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 2
  %12 = bitcast i8** %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = add i64 %13, %10
  %15 = inttoptr i64 %14 to i8*
  %16 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %3, i64 0, i32 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = sext i32 %17 to i64
  %19 = shl nsw i64 %18, 2
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %15, i8 0, i64 %19, i1 false)
  %20 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 1
  %21 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %20, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %21, i64 0, i32 2
  %23 = load i32, i32* %22, align 4
  %24 = icmp sgt i32 %23, 0
  br i1 %24, label %25, label %27

25:                                               ; preds = %1
  %26 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %2, align 8
  br label %28

27:                                               ; preds = %46, %1
  ret void

28:                                               ; preds = %25, %46
  %29 = phi %"class.gemmlowp::SideMap"* [ %47, %46 ], [ %21, %25 ]
  %30 = phi %"class.gemmlowp::PackedSideBlock"* [ %48, %46 ], [ %26, %25 ]
  %31 = phi %"class.gemmlowp::PackedSideBlock"* [ %49, %46 ], [ %26, %25 ]
  %32 = phi i32 [ %54, %46 ], [ %23, %25 ]
  %33 = phi i32 [ %52, %46 ], [ 0, %25 ]
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %31, i64 0, i32 0, i32 1
  %35 = sub nsw i32 %32, %33
  %36 = load i32, i32* %34, align 4
  %37 = icmp slt i32 %35, %36
  %38 = select i1 %37, i32 %35, i32 %36
  %39 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %29, i64 0, i32 1
  %40 = load i32, i32* %39, align 8
  %41 = icmp sgt i32 %40, 0
  br i1 %41, label %42, label %46

42:                                               ; preds = %28
  %43 = icmp sgt i32 %38, 0
  %44 = sext i32 %33 to i64
  %45 = sext i32 %38 to i64
  br label %56

46:                                               ; preds = %151, %28
  %47 = phi %"class.gemmlowp::SideMap"* [ %29, %28 ], [ %152, %151 ]
  %48 = phi %"class.gemmlowp::PackedSideBlock"* [ %30, %28 ], [ %153, %151 ]
  %49 = phi %"class.gemmlowp::PackedSideBlock"* [ %31, %28 ], [ %153, %151 ]
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %49, i64 0, i32 0, i32 1
  %51 = load i32, i32* %50, align 4
  %52 = add nsw i32 %51, %33
  %53 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %47, i64 0, i32 2
  %54 = load i32, i32* %53, align 4
  %55 = icmp sgt i32 %54, %52
  br i1 %55, label %28, label %27

56:                                               ; preds = %42, %151
  %57 = phi %"class.gemmlowp::SideMap"* [ %29, %42 ], [ %152, %151 ]
  %58 = phi %"class.gemmlowp::PackedSideBlock"* [ %30, %42 ], [ %153, %151 ]
  %59 = phi %"class.gemmlowp::SideMap"* [ %29, %42 ], [ %154, %151 ]
  %60 = phi %"class.gemmlowp::PackedSideBlock"* [ %31, %42 ], [ %153, %151 ]
  %61 = phi i32 [ %40, %42 ], [ %158, %151 ]
  %62 = phi i32 [ 0, %42 ], [ %156, %151 ]
  %63 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %60, i64 0, i32 0, i32 0
  %64 = sub nsw i32 %61, %62
  %65 = load i32, i32* %63, align 4
  %66 = icmp slt i32 %64, %65
  %67 = select i1 %66, i32 %64, i32 %65
  br i1 %43, label %68, label %122

68:                                               ; preds = %56
  %69 = icmp sgt i32 %67, 0
  %70 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %59, i64 0, i32 0
  %71 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %59, i64 0, i32 3
  %72 = sext i32 %62 to i64
  %73 = zext i32 %67 to i64
  %74 = add nsw i64 %73, -1
  %75 = and i64 %73, 3
  %76 = icmp ult i64 %74, 3
  %77 = sub nsw i64 %73, %75
  %78 = icmp eq i64 %75, 0
  br label %79

79:                                               ; preds = %98, %68
  %80 = phi i64 [ 0, %68 ], [ %99, %98 ]
  br i1 %69, label %81, label %98

81:                                               ; preds = %79
  %82 = add nsw i64 %80, %44
  %83 = load i8*, i8** %70, align 8
  %84 = load i32, i32* %71, align 8
  %85 = getelementptr inbounds i8, i8* %83, i64 %82
  %86 = sext i32 %84 to i64
  br i1 %76, label %87, label %101

87:                                               ; preds = %101, %81
  %88 = phi i64 [ 0, %81 ], [ %119, %101 ]
  br i1 %78, label %98, label %89

89:                                               ; preds = %87, %89
  %90 = phi i64 [ %95, %89 ], [ %88, %87 ]
  %91 = phi i64 [ %96, %89 ], [ %75, %87 ]
  %92 = add nsw i64 %90, %72
  %93 = mul nsw i64 %92, %86
  %94 = getelementptr inbounds i8, i8* %85, i64 %93
  tail call void @llvm.prefetch(i8* %94, i32 0, i32 3, i32 1) #18
  %95 = add nuw nsw i64 %90, 1
  %96 = add i64 %91, -1
  %97 = icmp eq i64 %96, 0
  br i1 %97, label %98, label %89, !llvm.loop !455

98:                                               ; preds = %87, %89, %79
  %99 = add nuw nsw i64 %80, 64
  %100 = icmp slt i64 %99, %45
  br i1 %100, label %79, label %122

101:                                              ; preds = %81, %101
  %102 = phi i64 [ %119, %101 ], [ 0, %81 ]
  %103 = phi i64 [ %120, %101 ], [ %77, %81 ]
  %104 = add nsw i64 %102, %72
  %105 = mul nsw i64 %104, %86
  %106 = getelementptr inbounds i8, i8* %85, i64 %105
  tail call void @llvm.prefetch(i8* %106, i32 0, i32 3, i32 1) #18
  %107 = or i64 %102, 1
  %108 = add nsw i64 %107, %72
  %109 = mul nsw i64 %108, %86
  %110 = getelementptr inbounds i8, i8* %85, i64 %109
  tail call void @llvm.prefetch(i8* %110, i32 0, i32 3, i32 1) #18
  %111 = or i64 %102, 2
  %112 = add nsw i64 %111, %72
  %113 = mul nsw i64 %112, %86
  %114 = getelementptr inbounds i8, i8* %85, i64 %113
  tail call void @llvm.prefetch(i8* %114, i32 0, i32 3, i32 1) #18
  %115 = or i64 %102, 3
  %116 = add nsw i64 %115, %72
  %117 = mul nsw i64 %116, %86
  %118 = getelementptr inbounds i8, i8* %85, i64 %117
  tail call void @llvm.prefetch(i8* %118, i32 0, i32 3, i32 1) #18
  %119 = add nuw nsw i64 %102, 4
  %120 = add i64 %103, -4
  %121 = icmp eq i64 %120, 0
  br i1 %121, label %87, label %101

122:                                              ; preds = %98, %56
  %123 = icmp sgt i32 %67, 0
  br i1 %123, label %124, label %151

124:                                              ; preds = %122, %124
  %125 = phi %"class.gemmlowp::PackedSideBlock"* [ %146, %124 ], [ %60, %122 ]
  %126 = phi i32 [ %144, %124 ], [ 0, %122 ]
  %127 = sub nsw i32 %67, %126
  %128 = icmp slt i32 %127, 4
  %129 = select i1 %128, i32 %127, i32 4
  %130 = add nsw i32 %126, %62
  %131 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %125, i64 0, i32 0, i32 1
  %132 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %125, i64 0, i32 0, i32 3
  %133 = load i32, i32* %132, align 4
  %134 = sub nsw i32 %133, %33
  %135 = load i32, i32* %131, align 4
  %136 = icmp slt i32 %134, %135
  %137 = select i1 %136, i32 %134, i32 %135
  %138 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %125, i64 0, i32 0, i32 2
  %139 = load i32, i32* %138, align 8
  %140 = mul nsw i32 %139, %33
  %141 = mul nsw i32 %137, %130
  %142 = add nsw i32 %141, %140
  %143 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %125, i64 0, i32 4
  store i32 %142, i32* %143, align 8
  tail call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE7PackRunEiiii(%"class.gemmlowp::PackSideBlockImpl"* %0, i32 %130, i32 %129, i32 %33, i32 %38) #18
  %144 = add nuw nsw i32 %126, 4
  %145 = icmp slt i32 %144, %67
  %146 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %2, align 8
  br i1 %145, label %124, label %147

147:                                              ; preds = %124
  %148 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %146, i64 0, i32 0, i32 0
  %149 = load i32, i32* %148, align 4
  %150 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %20, align 8
  br label %151

151:                                              ; preds = %147, %122
  %152 = phi %"class.gemmlowp::SideMap"* [ %150, %147 ], [ %57, %122 ]
  %153 = phi %"class.gemmlowp::PackedSideBlock"* [ %146, %147 ], [ %58, %122 ]
  %154 = phi %"class.gemmlowp::SideMap"* [ %150, %147 ], [ %59, %122 ]
  %155 = phi i32 [ %149, %147 ], [ %65, %122 ]
  %156 = add nsw i32 %155, %62
  %157 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %154, i64 0, i32 1
  %158 = load i32, i32* %157, align 8
  %159 = icmp sgt i32 %158, %156
  br i1 %159, label %56, label %46
}

; Function Attrs: inaccessiblemem_or_argmemonly nounwind
declare void @llvm.prefetch(i8* nocapture readonly, i32 immarg, i32 immarg, i32) #15

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE7PackRunEiiii(%"class.gemmlowp::PackSideBlockImpl"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"class.gemmlowp::PackingRegisterBlock", align 8
  %7 = bitcast %"class.gemmlowp::PackingRegisterBlock"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 88, i8* nonnull %7) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %7, i8 -86, i64 88, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %7, i8 0, i64 20, i1 false) #18
  %8 = icmp eq i32 %2, 4
  br i1 %8, label %28, label %9

9:                                                ; preds = %5
  %10 = icmp sgt i32 %4, 0
  br i1 %10, label %11, label %149

11:                                               ; preds = %9
  %12 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0
  %13 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 1
  %14 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 0
  %15 = icmp sgt i32 %2, 0
  %16 = sext i32 %2 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 0
  %18 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 1
  %19 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 2
  %20 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 3
  %21 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 0
  %22 = sext i32 %3 to i64
  %23 = sext i32 %4 to i64
  %24 = and i64 %16, 1
  %25 = icmp eq i32 %2, 1
  %26 = sub nsw i64 %16, %24
  %27 = icmp eq i64 %24, 0
  br label %96

28:                                               ; preds = %5
  %29 = and i32 %4, -16
  %30 = icmp sgt i32 %29, 0
  br i1 %30, label %31, label %56

31:                                               ; preds = %28
  %32 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0
  %33 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 1
  %34 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 0
  %35 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 1
  %36 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 2
  %37 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 3
  %38 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 0
  %39 = sext i32 %3 to i64
  %40 = sext i32 %29 to i64
  br label %41

41:                                               ; preds = %31, %41
  %42 = phi i64 [ 0, %31 ], [ %54, %41 ]
  %43 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %33, align 8
  %44 = add nsw i64 %42, %39
  %45 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %43, i64 0, i32 0
  %46 = load i8*, i8** %45, align 8, !noalias !456
  %47 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %43, i64 0, i32 3
  %48 = load i32, i32* %47, align 8, !noalias !456
  %49 = mul nsw i32 %48, %1
  %50 = sext i32 %49 to i64
  %51 = getelementptr inbounds i8, i8* %46, i64 %50
  %52 = getelementptr inbounds i8, i8* %51, i64 %44
  store i8* %52, i8** %34, align 8
  store i32 4, i32* %35, align 8
  store i32 16, i32* %36, align 4
  store i32 %48, i32* %37, align 8
  %53 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %38, align 8
  call void @_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i(%"class.gemmlowp::PackingRegisterBlockBase"* nonnull %32, %"class.gemmlowp::PackedSideBlock"* %53, i32 %1)
  %54 = add nuw nsw i64 %42, 16
  %55 = icmp slt i64 %54, %40
  br i1 %55, label %41, label %56

56:                                               ; preds = %41, %28
  %57 = icmp slt i32 %29, %4
  br i1 %57, label %58, label %149

58:                                               ; preds = %56
  %59 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 1
  %60 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %59, align 8
  %61 = add nsw i32 %29, %3
  %62 = sub nsw i32 %4, %29
  %63 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %60, i64 0, i32 0
  %64 = load i8*, i8** %63, align 8, !noalias !459
  %65 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %60, i64 0, i32 3
  %66 = load i32, i32* %65, align 8, !noalias !459
  %67 = mul nsw i32 %66, %1
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds i8, i8* %64, i64 %68
  %70 = sext i32 %61 to i64
  %71 = getelementptr inbounds i8, i8* %69, i64 %70
  %72 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 0
  %73 = sext i32 %62 to i64
  %74 = icmp ugt i32 %62, 63
  %75 = sub nsw i64 64, %73
  %76 = select i1 %74, i64 0, i64 %75
  %77 = getelementptr %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 %73
  call void @llvm.memset.p0i8.i64(i8* align 1 %77, i8 0, i64 %76, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %72, i8* align 1 %71, i64 %73, i1 false) #18
  %78 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 16
  %79 = sext i32 %66 to i64
  %80 = getelementptr inbounds i8, i8* %71, i64 %79
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %78, i8* align 1 %80, i64 %73, i1 false) #18
  %81 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 32
  %82 = shl nsw i32 %66, 1
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds i8, i8* %71, i64 %83
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %81, i8* align 1 %84, i64 %73, i1 false) #18
  %85 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 48
  %86 = mul nsw i32 %66, 3
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds i8, i8* %71, i64 %87
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %85, i8* align 1 %88, i64 %73, i1 false) #18
  %89 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0
  %90 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 0
  store i8* %72, i8** %90, align 8
  %91 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 1
  store i32 4, i32* %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 2
  store i32 16, i32* %92, align 4
  %93 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 3
  store i32 16, i32* %93, align 8
  %94 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 0
  %95 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %94, align 8
  call void @_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i(%"class.gemmlowp::PackingRegisterBlockBase"* nonnull %89, %"class.gemmlowp::PackedSideBlock"* %95, i32 %1)
  br label %149

96:                                               ; preds = %11, %145
  %97 = phi i64 [ 0, %11 ], [ %147, %145 ]
  %98 = sub nsw i64 %23, %97
  %99 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %13, align 8
  %100 = add nsw i64 %97, %22
  %101 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %99, i64 0, i32 0
  %102 = load i8*, i8** %101, align 8, !noalias !462
  %103 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %99, i64 0, i32 3
  %104 = load i32, i32* %103, align 8, !noalias !462
  %105 = mul nsw i32 %104, %1
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i8, i8* %102, i64 %106
  %108 = getelementptr inbounds i8, i8* %107, i64 %100
  call void @llvm.memset.p0i8.i64(i8* align 8 %14, i8 0, i64 64, i1 false) #18
  br i1 %15, label %109, label %145

109:                                              ; preds = %96
  %110 = icmp slt i64 %98, 16
  %111 = select i1 %110, i64 %98, i64 16
  %112 = shl i64 %111, 32
  %113 = ashr exact i64 %112, 32
  br i1 %25, label %135, label %114

114:                                              ; preds = %109, %114
  %115 = phi i64 [ %132, %114 ], [ 0, %109 ]
  %116 = phi i64 [ %133, %114 ], [ %26, %109 ]
  %117 = trunc i64 %115 to i32
  %118 = shl i64 %115, 4
  %119 = and i64 %118, 4294967264
  %120 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 %119
  %121 = mul nsw i32 %104, %117
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds i8, i8* %108, i64 %122
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %120, i8* align 1 %123, i64 %113, i1 false) #18
  %124 = or i64 %115, 1
  %125 = trunc i64 %124 to i32
  %126 = shl i64 %124, 4
  %127 = and i64 %126, 4294967280
  %128 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 %127
  %129 = mul nsw i32 %104, %125
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds i8, i8* %108, i64 %130
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %128, i8* align 1 %131, i64 %113, i1 false) #18
  %132 = add nuw nsw i64 %115, 2
  %133 = add i64 %116, -2
  %134 = icmp eq i64 %133, 0
  br i1 %134, label %135, label %114

135:                                              ; preds = %114, %109
  %136 = phi i64 [ 0, %109 ], [ %132, %114 ]
  br i1 %27, label %145, label %137

137:                                              ; preds = %135
  %138 = trunc i64 %136 to i32
  %139 = shl i64 %136, 4
  %140 = and i64 %139, 4294967280
  %141 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 %140
  %142 = mul nsw i32 %104, %138
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds i8, i8* %108, i64 %143
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %141, i8* align 1 %144, i64 %113, i1 false) #18
  br label %145

145:                                              ; preds = %137, %135, %96
  store i8* %14, i8** %17, align 8
  store i32 4, i32* %18, align 8
  store i32 16, i32* %19, align 4
  store i32 16, i32* %20, align 8
  %146 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %21, align 8
  call void @_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i(%"class.gemmlowp::PackingRegisterBlockBase"* nonnull %12, %"class.gemmlowp::PackedSideBlock"* %146, i32 %1)
  %147 = add nuw i64 %97, 16
  %148 = icmp slt i64 %147, %23
  br i1 %148, label %96, label %149

149:                                              ; preds = %145, %9, %56, %58
  call void @llvm.lifetime.end.p0i8(i64 88, i8* nonnull %7) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i(%"class.gemmlowp::PackingRegisterBlockBase"*, %"class.gemmlowp::PackedSideBlock"*, i32) local_unnamed_addr #1 comdat align 2 {
  %4 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %1, i64 0, i32 1
  %5 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %4, align 8
  %6 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %1, i64 0, i32 2, i32 0
  %7 = load i8, i8* %6, align 8
  %8 = zext i8 %7 to i64
  %9 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 5, i64 %8
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 2
  %12 = bitcast i8** %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = add i64 %13, %10
  %15 = inttoptr i64 %14 to i8*
  %16 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %1, i64 0, i32 4
  %17 = load i32, i32* %16, align 8
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds i8, i8* %15, i64 %18
  %20 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %1, i64 0, i32 3, i32 0
  %21 = sext i32 %2 to i64
  %22 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlockBase", %"class.gemmlowp::PackingRegisterBlockBase"* %0, i64 0, i32 0, i32 0
  %23 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlockBase", %"class.gemmlowp::PackingRegisterBlockBase"* %0, i64 0, i32 0, i32 3
  %24 = load i8, i8* %20, align 8
  %25 = zext i8 %24 to i64
  %26 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 5, i64 %25
  %27 = load i64, i64* %26, align 8
  %28 = add i64 %13, %27
  %29 = inttoptr i64 %28 to i32*
  %30 = getelementptr inbounds i32, i32* %29, i64 %21
  %31 = load i8*, i8** %22, align 8, !noalias !465
  %32 = load i32, i32* %23, align 8, !noalias !465
  %33 = sext i32 %32 to i64
  br label %34

34:                                               ; preds = %34, %3
  %35 = phi i64 [ 0, %3 ], [ %135, %34 ]
  %36 = mul nsw i64 %35, %33
  %37 = getelementptr inbounds i8, i8* %31, i64 %36
  %38 = shl i64 %35, 4
  %39 = load i8, i8* %37, align 1
  %40 = getelementptr inbounds i8, i8* %19, i64 %38
  store i8 %39, i8* %40, align 1
  %41 = zext i8 %39 to i32
  %42 = getelementptr inbounds i8, i8* %37, i64 1
  %43 = load i8, i8* %42, align 1
  %44 = or i64 %38, 1
  %45 = getelementptr inbounds i8, i8* %19, i64 %44
  store i8 %43, i8* %45, align 1
  %46 = zext i8 %43 to i32
  %47 = add nuw nsw i32 %41, %46
  %48 = getelementptr inbounds i8, i8* %37, i64 2
  %49 = load i8, i8* %48, align 1
  %50 = or i64 %38, 2
  %51 = getelementptr inbounds i8, i8* %19, i64 %50
  store i8 %49, i8* %51, align 1
  %52 = zext i8 %49 to i32
  %53 = add nuw nsw i32 %47, %52
  %54 = getelementptr inbounds i8, i8* %37, i64 3
  %55 = load i8, i8* %54, align 1
  %56 = or i64 %38, 3
  %57 = getelementptr inbounds i8, i8* %19, i64 %56
  store i8 %55, i8* %57, align 1
  %58 = zext i8 %55 to i32
  %59 = add nuw nsw i32 %53, %58
  %60 = getelementptr inbounds i8, i8* %37, i64 4
  %61 = load i8, i8* %60, align 1
  %62 = or i64 %38, 4
  %63 = getelementptr inbounds i8, i8* %19, i64 %62
  store i8 %61, i8* %63, align 1
  %64 = zext i8 %61 to i32
  %65 = add nuw nsw i32 %59, %64
  %66 = getelementptr inbounds i8, i8* %37, i64 5
  %67 = load i8, i8* %66, align 1
  %68 = or i64 %38, 5
  %69 = getelementptr inbounds i8, i8* %19, i64 %68
  store i8 %67, i8* %69, align 1
  %70 = zext i8 %67 to i32
  %71 = add nuw nsw i32 %65, %70
  %72 = getelementptr inbounds i8, i8* %37, i64 6
  %73 = load i8, i8* %72, align 1
  %74 = or i64 %38, 6
  %75 = getelementptr inbounds i8, i8* %19, i64 %74
  store i8 %73, i8* %75, align 1
  %76 = zext i8 %73 to i32
  %77 = add nuw nsw i32 %71, %76
  %78 = getelementptr inbounds i8, i8* %37, i64 7
  %79 = load i8, i8* %78, align 1
  %80 = or i64 %38, 7
  %81 = getelementptr inbounds i8, i8* %19, i64 %80
  store i8 %79, i8* %81, align 1
  %82 = zext i8 %79 to i32
  %83 = add nuw nsw i32 %77, %82
  %84 = getelementptr inbounds i8, i8* %37, i64 8
  %85 = load i8, i8* %84, align 1
  %86 = or i64 %38, 8
  %87 = getelementptr inbounds i8, i8* %19, i64 %86
  store i8 %85, i8* %87, align 1
  %88 = zext i8 %85 to i32
  %89 = add nuw nsw i32 %83, %88
  %90 = getelementptr inbounds i8, i8* %37, i64 9
  %91 = load i8, i8* %90, align 1
  %92 = or i64 %38, 9
  %93 = getelementptr inbounds i8, i8* %19, i64 %92
  store i8 %91, i8* %93, align 1
  %94 = zext i8 %91 to i32
  %95 = add nuw nsw i32 %89, %94
  %96 = getelementptr inbounds i8, i8* %37, i64 10
  %97 = load i8, i8* %96, align 1
  %98 = or i64 %38, 10
  %99 = getelementptr inbounds i8, i8* %19, i64 %98
  store i8 %97, i8* %99, align 1
  %100 = zext i8 %97 to i32
  %101 = add nuw nsw i32 %95, %100
  %102 = getelementptr inbounds i8, i8* %37, i64 11
  %103 = load i8, i8* %102, align 1
  %104 = or i64 %38, 11
  %105 = getelementptr inbounds i8, i8* %19, i64 %104
  store i8 %103, i8* %105, align 1
  %106 = zext i8 %103 to i32
  %107 = add nuw nsw i32 %101, %106
  %108 = getelementptr inbounds i8, i8* %37, i64 12
  %109 = load i8, i8* %108, align 1
  %110 = or i64 %38, 12
  %111 = getelementptr inbounds i8, i8* %19, i64 %110
  store i8 %109, i8* %111, align 1
  %112 = zext i8 %109 to i32
  %113 = add nuw nsw i32 %107, %112
  %114 = getelementptr inbounds i8, i8* %37, i64 13
  %115 = load i8, i8* %114, align 1
  %116 = or i64 %38, 13
  %117 = getelementptr inbounds i8, i8* %19, i64 %116
  store i8 %115, i8* %117, align 1
  %118 = zext i8 %115 to i32
  %119 = add nuw nsw i32 %113, %118
  %120 = getelementptr inbounds i8, i8* %37, i64 14
  %121 = load i8, i8* %120, align 1
  %122 = or i64 %38, 14
  %123 = getelementptr inbounds i8, i8* %19, i64 %122
  store i8 %121, i8* %123, align 1
  %124 = zext i8 %121 to i32
  %125 = add nuw nsw i32 %119, %124
  %126 = getelementptr inbounds i8, i8* %37, i64 15
  %127 = load i8, i8* %126, align 1
  %128 = or i64 %38, 15
  %129 = getelementptr inbounds i8, i8* %19, i64 %128
  store i8 %127, i8* %129, align 1
  %130 = zext i8 %127 to i32
  %131 = add nuw nsw i32 %125, %130
  %132 = getelementptr inbounds i32, i32* %30, i64 %35
  %133 = load i32, i32* %132, align 4
  %134 = add nsw i32 %133, %131
  store i32 %134, i32* %132, align 4
  %135 = add nuw nsw i64 %35, 1
  %136 = icmp eq i64 %135, 4
  br i1 %136, label %137, label %34

137:                                              ; preds = %34
  %138 = load i32, i32* %16, align 8
  %139 = add nsw i32 %138, 64
  store i32 %139, i32* %16, align 8
  ret void
}

; Function Attrs: noinline nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"*, i32, i32, i32, i32) local_unnamed_addr #16 comdat align 2 {
  %6 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %0, i64 0, i32 3
  %7 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %6, align 8
  %8 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %7, i64 0, i32 0, i32 1
  %9 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %7, i64 0, i32 0, i32 3
  %10 = load i32, i32* %9, align 4
  %11 = sub nsw i32 %10, %3
  %12 = load i32, i32* %8, align 4
  %13 = icmp slt i32 %11, %12
  %14 = select i1 %13, i32 %11, i32 %12
  %15 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %7, i64 0, i32 0, i32 2
  %16 = load i32, i32* %15, align 8
  %17 = mul nsw i32 %16, %3
  %18 = mul nsw i32 %14, %1
  %19 = add nsw i32 %18, %17
  %20 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %7, i64 0, i32 4
  store i32 %19, i32* %20, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %0, i64 0, i32 4
  %22 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %21, align 8
  %23 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %22, i64 0, i32 0, i32 1
  %24 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %22, i64 0, i32 0, i32 3
  %25 = load i32, i32* %24, align 4
  %26 = sub nsw i32 %25, %3
  %27 = load i32, i32* %23, align 4
  %28 = icmp slt i32 %26, %27
  %29 = select i1 %28, i32 %26, i32 %27
  %30 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %22, i64 0, i32 0, i32 2
  %31 = load i32, i32* %30, align 8
  %32 = mul nsw i32 %31, %3
  %33 = mul nsw i32 %29, %2
  %34 = add nsw i32 %33, %32
  %35 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %22, i64 0, i32 4
  store i32 %34, i32* %35, align 8
  %36 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %0, i64 0, i32 2
  %37 = load %"class.gemmlowp::PackedResult"*, %"class.gemmlowp::PackedResult"** %36, align 8
  %38 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %37, i64 0, i32 0
  %39 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %38, align 8, !noalias !468
  %40 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %37, i64 0, i32 1, i32 0
  %41 = load i8, i8* %40, align 8, !noalias !468
  %42 = zext i8 %41 to i64
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %39, i64 0, i32 5, i64 %42
  %44 = load i64, i64* %43, align 8, !noalias !468
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %39, i64 0, i32 2
  %46 = bitcast i8** %45 to i64*
  %47 = load i64, i64* %46, align 8, !noalias !468
  %48 = add i64 %47, %44
  %49 = inttoptr i64 %48 to i32*
  %50 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %37, i64 0, i32 2
  %51 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %50, align 8, !noalias !468
  %52 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %51, i64 0, i32 3
  %53 = load i32, i32* %52, align 4, !noalias !468
  %54 = sext i32 %1 to i64
  %55 = getelementptr inbounds i32, i32* %49, i64 %54
  %56 = mul nsw i32 %53, %2
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i32, i32* %55, i64 %57
  %59 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %0, i64 0, i32 0
  %60 = load %"struct.gemmlowp::KernelBase"*, %"struct.gemmlowp::KernelBase"** %59, align 8
  %61 = sext i32 %53 to i64
  %62 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %6, align 8
  %63 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %62, i64 0, i32 1
  %64 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %63, align 8
  %65 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %62, i64 0, i32 2, i32 0
  %66 = load i8, i8* %65, align 8
  %67 = zext i8 %66 to i64
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %64, i64 0, i32 5, i64 %67
  %69 = load i64, i64* %68, align 8
  %70 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %64, i64 0, i32 2
  %71 = bitcast i8** %70 to i64*
  %72 = load i64, i64* %71, align 8
  %73 = add i64 %72, %69
  %74 = inttoptr i64 %73 to i8*
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %62, i64 0, i32 4
  %76 = load i32, i32* %75, align 8
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds i8, i8* %74, i64 %77
  %79 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %21, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %79, i64 0, i32 1
  %81 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %80, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %79, i64 0, i32 2, i32 0
  %83 = load i8, i8* %82, align 8
  %84 = zext i8 %83 to i64
  %85 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %81, i64 0, i32 5, i64 %84
  %86 = load i64, i64* %85, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %81, i64 0, i32 2
  %88 = bitcast i8** %87 to i64*
  %89 = load i64, i64* %88, align 8
  %90 = add i64 %89, %86
  %91 = inttoptr i64 %90 to i8*
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %79, i64 0, i32 4
  %93 = load i32, i32* %92, align 8
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds i8, i8* %91, i64 %94
  %96 = sext i32 %3 to i64
  %97 = sext i32 %4 to i64
  %98 = bitcast %"struct.gemmlowp::KernelBase"* %60 to void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)***
  %99 = load void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)**, void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)*** %98, align 8
  %100 = getelementptr inbounds void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)*, void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)** %99, i64 1
  %101 = load void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)*, void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)** %100, align 8
  tail call void %101(%"struct.gemmlowp::KernelBase"* %60, i32* %58, i64 1, i64 %61, i8* %78, i8* %95, i64 %96, i64 %97) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.364"* dereferenceable(40), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #18
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !471
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !471
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !471
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !471
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !471
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !471
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !471
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !471
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !471
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !471
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !471
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !471
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !471
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !471
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !471
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !471
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !471
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !471
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !471
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !471
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !471
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !471
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !471
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !471
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !471
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !471
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !471
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !471
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !471
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !471
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !471
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !471
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !471
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !471
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !474
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.364"* %1, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %15, %"class.gemmlowp::MatrixMap.260"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.348"* dereferenceable(40), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.393", align 2
  %16 = alloca %"struct.gemmlowp::RegisterBlock.390", align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %20 = load i32*, i32** %17, align 8, !noalias !479
  %21 = getelementptr inbounds i32, i32* %20, i64 %18
  %22 = load i32, i32* %19, align 8, !noalias !479
  %23 = mul nsw i32 %22, %9
  %24 = sext i32 %23 to i64
  %25 = getelementptr inbounds i32, i32* %21, i64 %24
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = load i32, i32* %25, align 4, !noalias !479
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4, !noalias !479
  %30 = getelementptr inbounds i32, i32* %28, i64 1
  %31 = load i32, i32* %28, align 4, !noalias !479
  %32 = load i32, i32* %30, align 4, !noalias !479
  %33 = add nsw i32 %9, 1
  %34 = mul nsw i32 %22, %33
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds i32, i32* %21, i64 %35
  %37 = getelementptr inbounds i32, i32* %36, i64 1
  %38 = load i32, i32* %36, align 4, !noalias !479
  %39 = getelementptr inbounds i32, i32* %37, i64 1
  %40 = load i32, i32* %37, align 4, !noalias !479
  %41 = getelementptr inbounds i32, i32* %39, i64 1
  %42 = load i32, i32* %39, align 4, !noalias !479
  %43 = load i32, i32* %41, align 4, !noalias !479
  %44 = add nsw i32 %9, 2
  %45 = mul nsw i32 %22, %44
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i32, i32* %21, i64 %46
  %48 = getelementptr inbounds i32, i32* %47, i64 1
  %49 = load i32, i32* %47, align 4, !noalias !479
  %50 = getelementptr inbounds i32, i32* %48, i64 1
  %51 = load i32, i32* %48, align 4, !noalias !479
  %52 = getelementptr inbounds i32, i32* %50, i64 1
  %53 = load i32, i32* %50, align 4, !noalias !479
  %54 = load i32, i32* %52, align 4, !noalias !479
  %55 = add nsw i32 %9, 3
  %56 = mul nsw i32 %22, %55
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i32, i32* %21, i64 %57
  %59 = getelementptr inbounds i32, i32* %58, i64 1
  %60 = load i32, i32* %58, align 4, !noalias !479
  %61 = getelementptr inbounds i32, i32* %59, i64 1
  %62 = load i32, i32* %59, align 4, !noalias !479
  %63 = getelementptr inbounds i32, i32* %61, i64 1
  %64 = load i32, i32* %61, align 4, !noalias !479
  %65 = load i32, i32* %63, align 4, !noalias !479
  %66 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %67 = load i32*, i32** %66, align 8
  %68 = getelementptr i32, i32* %67, i64 %18
  %69 = bitcast i32* %68 to i64*
  %70 = load i64, i64* %69, align 4
  %71 = getelementptr inbounds i32, i32* %68, i64 2
  %72 = bitcast i32* %71 to i64*
  %73 = load i64, i64* %72, align 4
  %74 = trunc i64 %70 to i32
  %75 = lshr i64 %70, 32
  %76 = trunc i64 %75 to i32
  %77 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %78 = load i32*, i32** %77, align 8
  %79 = sext i32 %9 to i64
  %80 = getelementptr i32, i32* %78, i64 %79
  %81 = bitcast i32* %80 to i64*
  %82 = load i64, i64* %81, align 4
  %83 = getelementptr inbounds i32, i32* %80, i64 2
  %84 = bitcast i32* %83 to i64*
  %85 = load i64, i64* %84, align 4
  %86 = trunc i64 %82 to i32
  %87 = lshr i64 %82, 32
  %88 = trunc i64 %87 to i32
  %89 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %90 = load i32, i32* %89, align 4
  %91 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %92 = load i32, i32* %91, align 4
  %93 = mul nsw i32 %92, %74
  %94 = add nsw i32 %93, %27
  %95 = mul nsw i32 %92, %76
  %96 = add nsw i32 %95, %29
  %97 = trunc i64 %73 to i32
  %98 = mul nsw i32 %92, %97
  %99 = add nsw i32 %98, %31
  %100 = lshr i64 %73, 32
  %101 = trunc i64 %100 to i32
  %102 = mul nsw i32 %92, %101
  %103 = add nsw i32 %102, %32
  %104 = add nsw i32 %93, %38
  %105 = add nsw i32 %95, %40
  %106 = add nsw i32 %98, %42
  %107 = add nsw i32 %102, %43
  %108 = add nsw i32 %93, %49
  %109 = add nsw i32 %95, %51
  %110 = add nsw i32 %98, %53
  %111 = add nsw i32 %102, %54
  %112 = add nsw i32 %93, %60
  %113 = add nsw i32 %95, %62
  %114 = add nsw i32 %98, %64
  %115 = add nsw i32 %102, %65
  %116 = mul nsw i32 %92, %7
  %117 = add nsw i32 %116, %86
  %118 = add nsw i32 %116, %88
  %119 = trunc i64 %85 to i32
  %120 = add nsw i32 %116, %119
  %121 = lshr i64 %85, 32
  %122 = trunc i64 %121 to i32
  %123 = add nsw i32 %116, %122
  %124 = mul nsw i32 %117, %90
  %125 = add nsw i32 %94, %124
  %126 = add nsw i32 %96, %124
  %127 = add nsw i32 %99, %124
  %128 = add nsw i32 %103, %124
  %129 = mul nsw i32 %118, %90
  %130 = add nsw i32 %104, %129
  %131 = add nsw i32 %105, %129
  %132 = add nsw i32 %106, %129
  %133 = add nsw i32 %107, %129
  %134 = mul nsw i32 %120, %90
  %135 = add nsw i32 %108, %134
  %136 = add nsw i32 %109, %134
  %137 = add nsw i32 %110, %134
  %138 = add nsw i32 %111, %134
  %139 = mul nsw i32 %123, %90
  %140 = add nsw i32 %112, %139
  %141 = add nsw i32 %113, %139
  %142 = add nsw i32 %114, %139
  %143 = add nsw i32 %115, %139
  %144 = bitcast %"struct.gemmlowp::RegisterBlock.390"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %144)
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 0
  store i32 %125, i32* %145, align 8
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 1
  store i32 %126, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 2
  store i32 %127, i32* %147, align 8
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 3
  store i32 %128, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 4
  store i32 %130, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 5
  store i32 %131, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 6
  store i32 %132, i32* %151, align 8
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 7
  store i32 %133, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 8
  store i32 %135, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 9
  store i32 %136, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 10
  store i32 %137, i32* %155, align 8
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 11
  store i32 %138, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 12
  store i32 %140, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 13
  store i32 %141, i32* %158, align 4
  %159 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 14
  store i32 %142, i32* %159, align 8
  %160 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 15
  store i32 %143, i32* %160, align 4
  %161 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %161) #18
  %162 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.348", %"struct.gemmlowp::OutputPipelineExecutor.348"* %1, i64 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %161, i8 -86, i64 32, i1 false) #18
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.393"* nonnull sret %15, %"struct.gemmlowp::OutputPipelineEvalImpl.349"* %162, %"struct.gemmlowp::RegisterBlock.390"* nonnull byval(%"struct.gemmlowp::RegisterBlock.390") align 8 %16, i32 %10, i32 %11) #18
  %163 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 0
  %164 = load i16, i16* %163, align 2
  %165 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 1
  %166 = load i16, i16* %165, align 2
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 2
  %168 = load i16, i16* %167, align 2
  %169 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 3
  %170 = load i16, i16* %169, align 2
  %171 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 4
  %172 = load i16, i16* %171, align 2
  %173 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 5
  %174 = load i16, i16* %173, align 2
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 6
  %176 = load i16, i16* %175, align 2
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 7
  %178 = load i16, i16* %177, align 2
  %179 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 8
  %180 = load i16, i16* %179, align 2
  %181 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 9
  %182 = load i16, i16* %181, align 2
  %183 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 10
  %184 = load i16, i16* %183, align 2
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 11
  %186 = load i16, i16* %185, align 2
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 12
  %188 = load i16, i16* %187, align 2
  %189 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 13
  %190 = load i16, i16* %189, align 2
  %191 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 14
  %192 = load i16, i16* %191, align 2
  %193 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 15
  %194 = load i16, i16* %193, align 2
  %195 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %196 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %197 = sext i32 %13 to i64
  %198 = sext i32 %12 to i64
  %199 = load i16*, i16** %195, align 8
  %200 = load i32, i32* %196, align 8
  %201 = sext i32 %200 to i64
  %202 = mul nsw i64 %201, %198
  %203 = getelementptr inbounds i16, i16* %199, i64 %202
  %204 = getelementptr inbounds i16, i16* %203, i64 %197
  store i16 %164, i16* %204, align 2
  %205 = add nsw i64 %197, 1
  %206 = load i16*, i16** %195, align 8
  %207 = load i32, i32* %196, align 8
  %208 = sext i32 %207 to i64
  %209 = mul nsw i64 %208, %198
  %210 = getelementptr inbounds i16, i16* %206, i64 %209
  %211 = getelementptr inbounds i16, i16* %210, i64 %205
  store i16 %172, i16* %211, align 2
  %212 = add nsw i64 %197, 2
  %213 = load i16*, i16** %195, align 8
  %214 = load i32, i32* %196, align 8
  %215 = sext i32 %214 to i64
  %216 = mul nsw i64 %215, %198
  %217 = getelementptr inbounds i16, i16* %213, i64 %216
  %218 = getelementptr inbounds i16, i16* %217, i64 %212
  store i16 %180, i16* %218, align 2
  %219 = add nsw i64 %197, 3
  %220 = load i16*, i16** %195, align 8
  %221 = load i32, i32* %196, align 8
  %222 = sext i32 %221 to i64
  %223 = mul nsw i64 %222, %198
  %224 = getelementptr inbounds i16, i16* %220, i64 %223
  %225 = getelementptr inbounds i16, i16* %224, i64 %219
  store i16 %188, i16* %225, align 2
  %226 = add nsw i64 %198, 1
  %227 = load i16*, i16** %195, align 8
  %228 = load i32, i32* %196, align 8
  %229 = sext i32 %228 to i64
  %230 = mul nsw i64 %226, %229
  %231 = getelementptr inbounds i16, i16* %227, i64 %230
  %232 = getelementptr inbounds i16, i16* %231, i64 %197
  store i16 %166, i16* %232, align 2
  %233 = load i16*, i16** %195, align 8
  %234 = load i32, i32* %196, align 8
  %235 = sext i32 %234 to i64
  %236 = mul nsw i64 %226, %235
  %237 = getelementptr inbounds i16, i16* %233, i64 %236
  %238 = getelementptr inbounds i16, i16* %237, i64 %205
  store i16 %174, i16* %238, align 2
  %239 = load i16*, i16** %195, align 8
  %240 = load i32, i32* %196, align 8
  %241 = sext i32 %240 to i64
  %242 = mul nsw i64 %226, %241
  %243 = getelementptr inbounds i16, i16* %239, i64 %242
  %244 = getelementptr inbounds i16, i16* %243, i64 %212
  store i16 %182, i16* %244, align 2
  %245 = load i16*, i16** %195, align 8
  %246 = load i32, i32* %196, align 8
  %247 = sext i32 %246 to i64
  %248 = mul nsw i64 %226, %247
  %249 = getelementptr inbounds i16, i16* %245, i64 %248
  %250 = getelementptr inbounds i16, i16* %249, i64 %219
  store i16 %190, i16* %250, align 2
  %251 = add nsw i64 %198, 2
  %252 = load i16*, i16** %195, align 8
  %253 = load i32, i32* %196, align 8
  %254 = sext i32 %253 to i64
  %255 = mul nsw i64 %251, %254
  %256 = getelementptr inbounds i16, i16* %252, i64 %255
  %257 = getelementptr inbounds i16, i16* %256, i64 %197
  store i16 %168, i16* %257, align 2
  %258 = load i16*, i16** %195, align 8
  %259 = load i32, i32* %196, align 8
  %260 = sext i32 %259 to i64
  %261 = mul nsw i64 %251, %260
  %262 = getelementptr inbounds i16, i16* %258, i64 %261
  %263 = getelementptr inbounds i16, i16* %262, i64 %205
  store i16 %176, i16* %263, align 2
  %264 = load i16*, i16** %195, align 8
  %265 = load i32, i32* %196, align 8
  %266 = sext i32 %265 to i64
  %267 = mul nsw i64 %251, %266
  %268 = getelementptr inbounds i16, i16* %264, i64 %267
  %269 = getelementptr inbounds i16, i16* %268, i64 %212
  store i16 %184, i16* %269, align 2
  %270 = load i16*, i16** %195, align 8
  %271 = load i32, i32* %196, align 8
  %272 = sext i32 %271 to i64
  %273 = mul nsw i64 %251, %272
  %274 = getelementptr inbounds i16, i16* %270, i64 %273
  %275 = getelementptr inbounds i16, i16* %274, i64 %219
  store i16 %192, i16* %275, align 2
  %276 = add nsw i64 %198, 3
  %277 = load i16*, i16** %195, align 8
  %278 = load i32, i32* %196, align 8
  %279 = sext i32 %278 to i64
  %280 = mul nsw i64 %276, %279
  %281 = getelementptr inbounds i16, i16* %277, i64 %280
  %282 = getelementptr inbounds i16, i16* %281, i64 %197
  store i16 %170, i16* %282, align 2
  %283 = load i16*, i16** %195, align 8
  %284 = load i32, i32* %196, align 8
  %285 = sext i32 %284 to i64
  %286 = mul nsw i64 %276, %285
  %287 = getelementptr inbounds i16, i16* %283, i64 %286
  %288 = getelementptr inbounds i16, i16* %287, i64 %205
  store i16 %178, i16* %288, align 2
  %289 = load i16*, i16** %195, align 8
  %290 = load i32, i32* %196, align 8
  %291 = sext i32 %290 to i64
  %292 = mul nsw i64 %276, %291
  %293 = getelementptr inbounds i16, i16* %289, i64 %292
  %294 = getelementptr inbounds i16, i16* %293, i64 %212
  store i16 %186, i16* %294, align 2
  %295 = load i16*, i16** %195, align 8
  %296 = load i32, i32* %196, align 8
  %297 = sext i32 %296 to i64
  %298 = mul nsw i64 %276, %297
  %299 = getelementptr inbounds i16, i16* %295, i64 %298
  %300 = getelementptr inbounds i16, i16* %299, i64 %219
  store i16 %194, i16* %300, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %161) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %144)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.336"* dereferenceable(40), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %9, 1
  %26 = mul nsw i32 %20, %25
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %19, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %9, 2
  %31 = mul nsw i32 %20, %30
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i32, i32* %19, i64 %32
  %34 = load i32, i32* %33, align 4
  %35 = add nsw i32 %9, 3
  %36 = mul nsw i32 %20, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %19, i64 %37
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %41 = load i32*, i32** %40, align 8
  %42 = getelementptr inbounds i32, i32* %41, i64 %16
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %45 = load i32*, i32** %44, align 8
  %46 = sext i32 %9 to i64
  %47 = getelementptr i32, i32* %45, i64 %46
  %48 = bitcast i32* %47 to i64*
  %49 = load i64, i64* %48, align 4
  %50 = getelementptr inbounds i32, i32* %47, i64 2
  %51 = bitcast i32* %50 to i64*
  %52 = load i64, i64* %51, align 4
  %53 = trunc i64 %49 to i32
  %54 = lshr i64 %49, 32
  %55 = trunc i64 %54 to i32
  %56 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = mul nsw i32 %59, %43
  %61 = add nsw i32 %60, %24
  %62 = add nsw i32 %60, %29
  %63 = add nsw i32 %60, %34
  %64 = add nsw i32 %60, %39
  %65 = mul nsw i32 %59, %7
  %66 = add nsw i32 %65, %53
  %67 = add nsw i32 %65, %55
  %68 = trunc i64 %52 to i32
  %69 = add nsw i32 %65, %68
  %70 = lshr i64 %52, 32
  %71 = trunc i64 %70 to i32
  %72 = add nsw i32 %65, %71
  %73 = mul nsw i32 %66, %57
  %74 = add nsw i32 %61, %73
  %75 = mul nsw i32 %67, %57
  %76 = add nsw i32 %62, %75
  %77 = mul nsw i32 %69, %57
  %78 = add nsw i32 %63, %77
  %79 = zext i32 %78 to i64
  %80 = mul nsw i32 %72, %57
  %81 = add nsw i32 %64, %80
  %82 = zext i32 %81 to i64
  %83 = shl nuw i64 %82, 32
  %84 = or i64 %83, %79
  %85 = zext i32 %76 to i64
  %86 = shl nuw i64 %85, 32
  %87 = zext i32 %74 to i64
  %88 = or i64 %86, %87
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %1, i64 0, i32 0, i32 0, i32 0
  %90 = load %"struct.gemmlowp::OutputStageBiasAddition.278"*, %"struct.gemmlowp::OutputStageBiasAddition.278"** %89, align 8
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.278", %"struct.gemmlowp::OutputStageBiasAddition.278"* %90, i64 0, i32 0, i32 0
  %92 = load i32*, i32** %91, align 8
  %93 = sext i32 %11 to i64
  %94 = getelementptr i32, i32* %92, i64 %93
  %95 = bitcast i32* %94 to i64*
  %96 = load i64, i64* %95, align 4
  %97 = getelementptr inbounds i32, i32* %94, i64 2
  %98 = bitcast i32* %97 to i64*
  %99 = load i64, i64* %98, align 4
  %100 = and i64 %96, -4294967296
  %101 = add i64 %96, %87
  %102 = add i64 %99, %79
  %103 = and i64 %102, 4294967295
  %104 = and i64 %99, -4294967296
  %105 = add i64 %104, %84
  %106 = and i64 %105, -4294967296
  %107 = or i64 %106, %103
  %108 = add i64 %100, %88
  %109 = and i64 %108, -4294967296
  %110 = and i64 %101, 4294967295
  %111 = or i64 %109, %110
  %112 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %1, i64 0, i32 0, i32 1, i32 0, i32 0
  %113 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %112, i64 %111, i64 %107) #18
  %114 = extractvalue { i64, i64 } %113, 0
  %115 = extractvalue { i64, i64 } %113, 1
  %116 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.336", %"struct.gemmlowp::OutputPipelineExecutor.336"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %117 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %116, align 8
  %118 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %117, i64 0, i32 0
  %119 = load i32, i32* %118, align 4
  %120 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %117, i64 0, i32 1
  %121 = load i32, i32* %120, align 4
  %122 = trunc i64 %114 to i32
  %123 = icmp sgt i32 %119, %122
  %124 = select i1 %123, i32 %119, i32 %122
  %125 = icmp slt i32 %121, %124
  %126 = select i1 %125, i32 %121, i32 %124
  %127 = lshr i64 %114, 32
  %128 = trunc i64 %127 to i32
  %129 = icmp sgt i32 %119, %128
  %130 = select i1 %129, i32 %119, i32 %128
  %131 = icmp slt i32 %121, %130
  %132 = select i1 %131, i32 %121, i32 %130
  %133 = trunc i64 %115 to i32
  %134 = icmp sgt i32 %119, %133
  %135 = select i1 %134, i32 %119, i32 %133
  %136 = icmp slt i32 %121, %135
  %137 = select i1 %136, i32 %121, i32 %135
  %138 = lshr i64 %115, 32
  %139 = trunc i64 %138 to i32
  %140 = icmp sgt i32 %119, %139
  %141 = select i1 %140, i32 %119, i32 %139
  %142 = icmp slt i32 %121, %141
  %143 = select i1 %142, i32 %121, i32 %141
  %144 = icmp sgt i32 %126, -32768
  %145 = select i1 %144, i32 %126, i32 -32768
  %146 = icmp slt i32 %145, 32767
  %147 = select i1 %146, i32 %145, i32 32767
  %148 = icmp sgt i32 %132, -32768
  %149 = select i1 %148, i32 %132, i32 -32768
  %150 = icmp slt i32 %149, 32767
  %151 = select i1 %150, i32 %149, i32 32767
  %152 = icmp sgt i32 %137, -32768
  %153 = select i1 %152, i32 %137, i32 -32768
  %154 = icmp slt i32 %153, 32767
  %155 = select i1 %154, i32 %153, i32 32767
  %156 = icmp sgt i32 %143, -32768
  %157 = select i1 %156, i32 %143, i32 -32768
  %158 = icmp slt i32 %157, 32767
  %159 = select i1 %158, i32 %157, i32 32767
  %160 = trunc i32 %147 to i16
  %161 = trunc i32 %151 to i16
  %162 = trunc i32 %155 to i16
  %163 = trunc i32 %159 to i16
  %164 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %165 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %166 = sext i32 %13 to i64
  %167 = sext i32 %12 to i64
  %168 = load i16*, i16** %164, align 8
  %169 = load i32, i32* %165, align 8
  %170 = sext i32 %169 to i64
  %171 = mul nsw i64 %170, %167
  %172 = getelementptr inbounds i16, i16* %168, i64 %171
  %173 = getelementptr inbounds i16, i16* %172, i64 %166
  store i16 %160, i16* %173, align 2
  %174 = add nsw i64 %166, 1
  %175 = load i16*, i16** %164, align 8
  %176 = load i32, i32* %165, align 8
  %177 = sext i32 %176 to i64
  %178 = mul nsw i64 %177, %167
  %179 = getelementptr inbounds i16, i16* %175, i64 %178
  %180 = getelementptr inbounds i16, i16* %179, i64 %174
  store i16 %161, i16* %180, align 2
  %181 = add nsw i64 %166, 2
  %182 = load i16*, i16** %164, align 8
  %183 = load i32, i32* %165, align 8
  %184 = sext i32 %183 to i64
  %185 = mul nsw i64 %184, %167
  %186 = getelementptr inbounds i16, i16* %182, i64 %185
  %187 = getelementptr inbounds i16, i16* %186, i64 %181
  store i16 %162, i16* %187, align 2
  %188 = add nsw i64 %166, 3
  %189 = load i16*, i16** %164, align 8
  %190 = load i32, i32* %165, align 8
  %191 = sext i32 %190 to i64
  %192 = mul nsw i64 %191, %167
  %193 = getelementptr inbounds i16, i16* %189, i64 %192
  %194 = getelementptr inbounds i16, i16* %193, i64 %188
  store i16 %163, i16* %194, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.364"* dereferenceable(40), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #18
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !484
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !484
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !484
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !484
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !484
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !484
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !484
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !484
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !484
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !484
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !484
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !484
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !484
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !484
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !484
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !484
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !484
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !484
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !484
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !484
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !484
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !484
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !484
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !484
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !484
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !484
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !484
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !484
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !484
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !484
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !484
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !484
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !484
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !484
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !487
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.364"* %1, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %15, %"class.gemmlowp::MatrixMap.273"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.320"* dereferenceable(40), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.382", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !492
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !492
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !492
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !492
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !492
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !492
  %37 = load i32, i32* %35, align 4, !noalias !492
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !497
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = mul nsw <4 x i32> %56, %45
  %59 = mul nsw i32 %54, %7
  %60 = add nsw i32 %59, %50
  %61 = mul nsw i32 %60, %52
  %62 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %62) #18
  %63 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.320", %"struct.gemmlowp::OutputPipelineExecutor.320"* %1, i64 0, i32 0, i32 0, i32 0
  %64 = load %"struct.gemmlowp::OutputStageBiasAddition.278"*, %"struct.gemmlowp::OutputStageBiasAddition.278"** %63, align 8, !noalias !502
  %65 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.278", %"struct.gemmlowp::OutputStageBiasAddition.278"* %64, i64 0, i32 0, i32 0
  %66 = load i32*, i32** %65, align 8, !noalias !502
  %67 = sext i32 %11 to i64
  %68 = getelementptr inbounds i32, i32* %66, i64 %67
  %69 = load i32, i32* %68, align 4, !noalias !502
  %70 = add i32 %69, %61
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = add <4 x i32> %72, %30
  %74 = add <4 x i32> %73, %57
  %75 = insertelement <4 x i32> undef, i32 %32, i32 0
  %76 = insertelement <4 x i32> %75, i32 %34, i32 1
  %77 = insertelement <4 x i32> %76, i32 %36, i32 2
  %78 = insertelement <4 x i32> %77, i32 %37, i32 3
  %79 = add <4 x i32> %72, %78
  %80 = add <4 x i32> %79, %58
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.320", %"struct.gemmlowp::OutputPipelineExecutor.320"* %1, i64 0, i32 0, i32 1
  %82 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %15 to <4 x i32>*
  store <4 x i32> %74, <4 x i32>* %82, align 16
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %15, i64 0, i32 0, i32 0, i64 4
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %80, <4 x i32>* %84, align 16
  %85 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.323"* %81, %"struct.gemmlowp::RegisterBlock.382"* nonnull byval(%"struct.gemmlowp::RegisterBlock.382") align 8 %15, i32 %10, i32 %11) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %62) #18
  %86 = extractvalue { i64, i64 } %85, 0
  %87 = extractvalue { i64, i64 } %85, 1
  %88 = trunc i64 %86 to i16
  %89 = lshr i64 %86, 16
  %90 = trunc i64 %89 to i16
  %91 = lshr i64 %86, 32
  %92 = trunc i64 %91 to i16
  %93 = lshr i64 %86, 48
  %94 = trunc i64 %93 to i16
  %95 = trunc i64 %87 to i16
  %96 = lshr i64 %87, 16
  %97 = trunc i64 %96 to i16
  %98 = lshr i64 %87, 32
  %99 = trunc i64 %98 to i16
  %100 = lshr i64 %87, 48
  %101 = trunc i64 %100 to i16
  %102 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %103 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %104 = sext i32 %12 to i64
  %105 = load i16*, i16** %102, align 8
  %106 = load i32, i32* %103, align 8
  %107 = sext i32 %106 to i64
  %108 = mul nsw i64 %107, %104
  %109 = getelementptr inbounds i16, i16* %105, i64 %108
  %110 = sext i32 %13 to i64
  %111 = getelementptr inbounds i16, i16* %109, i64 %110
  store i16 %88, i16* %111, align 2
  %112 = add nsw i64 %104, 1
  %113 = load i16*, i16** %102, align 8
  %114 = load i32, i32* %103, align 8
  %115 = sext i32 %114 to i64
  %116 = mul nsw i64 %112, %115
  %117 = getelementptr inbounds i16, i16* %113, i64 %116
  %118 = getelementptr inbounds i16, i16* %117, i64 %110
  store i16 %90, i16* %118, align 2
  %119 = add nsw i64 %104, 2
  %120 = load i16*, i16** %102, align 8
  %121 = load i32, i32* %103, align 8
  %122 = sext i32 %121 to i64
  %123 = mul nsw i64 %119, %122
  %124 = getelementptr inbounds i16, i16* %120, i64 %123
  %125 = getelementptr inbounds i16, i16* %124, i64 %110
  store i16 %92, i16* %125, align 2
  %126 = add nsw i64 %104, 3
  %127 = load i16*, i16** %102, align 8
  %128 = load i32, i32* %103, align 8
  %129 = sext i32 %128 to i64
  %130 = mul nsw i64 %126, %129
  %131 = getelementptr inbounds i16, i16* %127, i64 %130
  %132 = getelementptr inbounds i16, i16* %131, i64 %110
  store i16 %94, i16* %132, align 2
  %133 = add nsw i64 %104, 4
  %134 = load i16*, i16** %102, align 8
  %135 = load i32, i32* %103, align 8
  %136 = sext i32 %135 to i64
  %137 = mul nsw i64 %133, %136
  %138 = getelementptr inbounds i16, i16* %134, i64 %137
  %139 = getelementptr inbounds i16, i16* %138, i64 %110
  store i16 %95, i16* %139, align 2
  %140 = add nsw i64 %104, 5
  %141 = load i16*, i16** %102, align 8
  %142 = load i32, i32* %103, align 8
  %143 = sext i32 %142 to i64
  %144 = mul nsw i64 %140, %143
  %145 = getelementptr inbounds i16, i16* %141, i64 %144
  %146 = getelementptr inbounds i16, i16* %145, i64 %110
  store i16 %97, i16* %146, align 2
  %147 = add nsw i64 %104, 6
  %148 = load i16*, i16** %102, align 8
  %149 = load i32, i32* %103, align 8
  %150 = sext i32 %149 to i64
  %151 = mul nsw i64 %147, %150
  %152 = getelementptr inbounds i16, i16* %148, i64 %151
  %153 = getelementptr inbounds i16, i16* %152, i64 %110
  store i16 %99, i16* %153, align 2
  %154 = add nsw i64 %104, 7
  %155 = load i16*, i16** %102, align 8
  %156 = load i32, i32* %103, align 8
  %157 = sext i32 %156 to i64
  %158 = mul nsw i64 %154, %157
  %159 = getelementptr inbounds i16, i16* %155, i64 %158
  %160 = getelementptr inbounds i16, i16* %159, i64 %110
  store i16 %101, i16* %160, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor"* dereferenceable(40), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %16 = load i32*, i32** %15, align 8
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %19 = load i32, i32* %18, align 8
  %20 = getelementptr inbounds i32, i32* %16, i64 %17
  %21 = mul nsw i32 %19, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %20, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %26 = load i32*, i32** %25, align 8
  %27 = getelementptr inbounds i32, i32* %26, i64 %17
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %30 = load i32*, i32** %29, align 8
  %31 = sext i32 %9 to i64
  %32 = getelementptr inbounds i32, i32* %30, i64 %31
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = mul nsw i32 %37, %28
  %39 = add nsw i32 %38, %24
  %40 = mul nsw i32 %37, %7
  %41 = add nsw i32 %40, %33
  %42 = mul nsw i32 %41, %35
  %43 = add nsw i32 %39, %42
  %44 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 0, i32 0
  %45 = load %"struct.gemmlowp::OutputStageBiasAddition.278"*, %"struct.gemmlowp::OutputStageBiasAddition.278"** %44, align 8
  %46 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.278", %"struct.gemmlowp::OutputStageBiasAddition.278"* %45, i64 0, i32 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %11 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = add nsw i32 %43, %50
  %52 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %53 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %52, align 8
  %54 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 2
  %55 = load i32, i32* %54, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %57 = load i32, i32* %56, align 8
  %58 = sext i32 %51 to i64
  %59 = shl i32 1, %57
  %60 = sext i32 %59 to i64
  %61 = mul nsw i64 %60, %58
  %62 = icmp slt i64 %61, 2147483647
  %63 = select i1 %62, i64 %61, i64 2147483647
  %64 = icmp sgt i64 %63, -2147483648
  %65 = select i1 %64, i64 %63, i64 -2147483648
  %66 = trunc i64 %65 to i32
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = icmp ne i32 %68, %66
  %70 = icmp ne i32 %66, -2147483648
  %71 = or i1 %69, %70
  br i1 %71, label %72, label %81

72:                                               ; preds = %14
  %73 = sext i32 %68 to i64
  %74 = select i1 %69, i64 %73, i64 %65
  %75 = mul nsw i64 %74, %65
  %76 = icmp sgt i64 %75, -1
  %77 = select i1 %76, i64 1073741824, i64 -1073741823
  %78 = add nsw i64 %77, %75
  %79 = sdiv i64 %78, 2147483648
  %80 = trunc i64 %79 to i32
  br label %81

81:                                               ; preds = %14, %72
  %82 = phi i32 [ %80, %72 ], [ 2147483647, %14 ]
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  %84 = load i32, i32* %83, align 4
  %85 = zext i32 %84 to i64
  %86 = shl nsw i64 -1, %85
  %87 = trunc i64 %86 to i32
  %88 = xor i32 %87, -1
  %89 = and i32 %82, %88
  %90 = ashr i32 %88, 1
  %91 = lshr i32 %82, 31
  %92 = add nsw i32 %90, %91
  %93 = ashr i32 %82, %84
  %94 = icmp sgt i32 %89, %92
  %95 = zext i1 %94 to i32
  %96 = add i32 %93, %55
  %97 = add i32 %96, %95
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %99 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 0
  %101 = load i32, i32* %100, align 4
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 1
  %103 = load i32, i32* %102, align 4
  %104 = icmp sgt i32 %101, %97
  %105 = select i1 %104, i32 %101, i32 %97
  %106 = icmp slt i32 %103, %105
  %107 = select i1 %106, i32 %103, i32 %105
  %108 = icmp sgt i32 %107, -32768
  %109 = select i1 %108, i32 %107, i32 -32768
  %110 = icmp slt i32 %109, 32767
  %111 = select i1 %110, i32 %109, i32 32767
  %112 = trunc i32 %111 to i16
  %113 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %114 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %115 = load i16*, i16** %113, align 8
  %116 = load i32, i32* %114, align 8
  %117 = mul nsw i32 %116, %12
  %118 = sext i32 %117 to i64
  %119 = getelementptr inbounds i16, i16* %115, i64 %118
  %120 = sext i32 %13 to i64
  %121 = getelementptr inbounds i16, i16* %119, i64 %120
  store i16 %112, i16* %121, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.364"*, %"struct.gemmlowp::RegisterBlock.380"* byval(%"struct.gemmlowp::RegisterBlock.380") align 8, %"class.gemmlowp::MatrixMap.260"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.388", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBlock.388", align 2
  %11 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %11) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %11, i8 -86, i64 64, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition.278"*, %"struct.gemmlowp::OutputStageBiasAddition.278"** %36, align 8, !noalias !505
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.278", %"struct.gemmlowp::OutputStageBiasAddition.278"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !505
  %40 = sext i32 %4 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to i64*
  %43 = load i64, i64* %42, align 4, !noalias !505
  %44 = getelementptr inbounds i32, i32* %41, i64 2
  %45 = bitcast i32* %44 to i64*
  %46 = load i64, i64* %45, align 4, !noalias !505
  %47 = trunc i64 %43 to i32
  %48 = lshr i64 %43, 32
  %49 = trunc i64 %48 to i32
  %50 = insertelement <4 x i32> undef, i32 %47, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = add nsw <4 x i32> %13, %51
  %53 = add nsw <4 x i32> %16, %51
  %54 = insertelement <4 x i32> undef, i32 %49, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add nsw <4 x i32> %19, %55
  %57 = add nsw <4 x i32> %22, %55
  %58 = trunc i64 %46 to i32
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = add nsw <4 x i32> %25, %60
  %62 = add nsw <4 x i32> %28, %60
  %63 = lshr i64 %46, 32
  %64 = trunc i64 %63 to i32
  %65 = insertelement <4 x i32> undef, i32 %64, i32 0
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> zeroinitializer
  %67 = add nsw <4 x i32> %31, %66
  %68 = add nsw <4 x i32> %34, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %0, i64 0, i32 0, i32 1
  %70 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %9 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %70, align 16, !noalias !510
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 4
  %72 = bitcast i32* %71 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %72, align 16, !noalias !510
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 8
  %74 = bitcast i32* %73 to <4 x i32>*
  store <4 x i32> %56, <4 x i32>* %74, align 16, !noalias !510
  %75 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 12
  %76 = bitcast i32* %75 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %76, align 16, !noalias !510
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 16
  %78 = bitcast i32* %77 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %78, align 16, !noalias !510
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 20
  %80 = bitcast i32* %79 to <4 x i32>*
  store <4 x i32> %62, <4 x i32>* %80, align 16, !noalias !510
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 24
  %82 = bitcast i32* %81 to <4 x i32>*
  store <4 x i32> %67, <4 x i32>* %82, align 16, !noalias !510
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 28
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %84, align 16, !noalias !510
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.388"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.367"* %69, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %9, i32 %3, i32 %4) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %85 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %85)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %85, i8* nonnull align 2 %11, i64 64, i1 false)
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = sext i32 %5 to i64
  %90 = add nsw i64 %88, 1
  %91 = add nsw i64 %88, 2
  %92 = add nsw i64 %88, 3
  br label %93

93:                                               ; preds = %93, %7
  %94 = phi i64 [ 0, %7 ], [ %131, %93 ]
  %95 = add nsw i64 %94, %89
  %96 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %94
  %97 = load i16, i16* %96, align 2
  %98 = load i16*, i16** %86, align 8
  %99 = getelementptr inbounds i16, i16* %98, i64 %95
  %100 = load i32, i32* %87, align 8
  %101 = sext i32 %100 to i64
  %102 = mul nsw i64 %101, %88
  %103 = getelementptr inbounds i16, i16* %99, i64 %102
  store i16 %97, i16* %103, align 2
  %104 = add nuw nsw i64 %94, 8
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %104
  %106 = load i16, i16* %105, align 2
  %107 = load i16*, i16** %86, align 8
  %108 = getelementptr inbounds i16, i16* %107, i64 %95
  %109 = load i32, i32* %87, align 8
  %110 = sext i32 %109 to i64
  %111 = mul nsw i64 %90, %110
  %112 = getelementptr inbounds i16, i16* %108, i64 %111
  store i16 %106, i16* %112, align 2
  %113 = add nuw nsw i64 %94, 16
  %114 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = load i16*, i16** %86, align 8
  %117 = getelementptr inbounds i16, i16* %116, i64 %95
  %118 = load i32, i32* %87, align 8
  %119 = sext i32 %118 to i64
  %120 = mul nsw i64 %91, %119
  %121 = getelementptr inbounds i16, i16* %117, i64 %120
  store i16 %115, i16* %121, align 2
  %122 = add nuw nsw i64 %94, 24
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %122
  %124 = load i16, i16* %123, align 2
  %125 = load i16*, i16** %86, align 8
  %126 = getelementptr inbounds i16, i16* %125, i64 %95
  %127 = load i32, i32* %87, align 8
  %128 = sext i32 %127 to i64
  %129 = mul nsw i64 %92, %128
  %130 = getelementptr inbounds i16, i16* %126, i64 %129
  store i16 %124, i16* %130, align 2
  %131 = add nuw nsw i64 %94, 1
  %132 = icmp eq i64 %131, 8
  br i1 %132, label %133, label %93

133:                                              ; preds = %93
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %85)
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %11) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.388"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.367"*, %"struct.gemmlowp::RegisterBlock.380"* byval(%"struct.gemmlowp::RegisterBlock.380") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.389", align 8
  %8 = alloca [32 x i16], align 2
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %11 = alloca [32 x i32], align 4
  %12 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 8
  %13 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 4
  %14 = alloca [32 x i32], align 4
  %15 = bitcast [32 x i32]* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15)
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %15, i8 -86, i64 128, i1 false), !alias.scope !511
  %17 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %17) #18, !noalias !511
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #18, !noalias !511
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %18, i8* nonnull align 8 %16, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %17, i8 -86, i64 128, i1 false) #18, !alias.scope !514, !noalias !511
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.367", %"struct.gemmlowp::OutputPipelineEvalImpl.367"* %1, i64 0, i32 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %19, align 8, !noalias !517
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !517
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.367", %"struct.gemmlowp::OutputPipelineEvalImpl.367"* %1, i64 0, i32 0, i32 0, i32 1
  %24 = load i32, i32* %23, align 8, !noalias !517
  %25 = shl i32 1, %24
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 0
  %28 = load i32, i32* %27, align 4, !noalias !517
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.367", %"struct.gemmlowp::OutputPipelineEvalImpl.367"* %1, i64 0, i32 0, i32 0, i32 2
  %31 = load i32, i32* %30, align 4, !noalias !517
  %32 = zext i32 %31 to i64
  %33 = shl nsw i64 -1, %32
  %34 = trunc i64 %33 to i32
  %35 = xor i32 %34, -1
  %36 = ashr i32 %35, 1
  %37 = icmp ne i32 %28, -2147483648
  br label %38

38:                                               ; preds = %59, %5
  %39 = phi i64 [ 0, %5 ], [ %70, %59 ]
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %12, i64 0, i32 0, i64 %39
  %41 = load i32, i32* %40, align 4, !noalias !517
  %42 = sext i32 %41 to i64
  %43 = mul nsw i64 %42, %26
  %44 = icmp slt i64 %43, 2147483647
  %45 = select i1 %44, i64 %43, i64 2147483647
  %46 = icmp sgt i64 %45, -2147483648
  %47 = select i1 %46, i64 %45, i64 -2147483648
  %48 = trunc i64 %47 to i32
  %49 = icmp ne i32 %28, %48
  %50 = or i1 %37, %49
  br i1 %50, label %51, label %59

51:                                               ; preds = %38
  %52 = select i1 %49, i64 %29, i64 %47
  %53 = mul nsw i64 %52, %47
  %54 = icmp sgt i64 %53, -1
  %55 = select i1 %54, i64 1073741824, i64 -1073741823
  %56 = add nsw i64 %55, %53
  %57 = sdiv i64 %56, 2147483648
  %58 = trunc i64 %57 to i32
  br label %59

59:                                               ; preds = %51, %38
  %60 = phi i32 [ %58, %51 ], [ 2147483647, %38 ]
  %61 = and i32 %60, %35
  %62 = lshr i32 %60, 31
  %63 = add nsw i32 %62, %36
  %64 = ashr i32 %60, %31
  %65 = icmp sgt i32 %61, %63
  %66 = zext i1 %65 to i32
  %67 = add i32 %64, %22
  %68 = add i32 %67, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %13, i64 0, i32 0, i64 %39
  store i32 %68, i32* %69, align 4, !alias.scope !514, !noalias !511
  %70 = add nuw nsw i64 %39, 1
  %71 = icmp eq i64 %70, 32
  br i1 %71, label %72, label %38

72:                                               ; preds = %59
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #18, !noalias !511
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %15, i8* nonnull align 4 %17, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %17) #18, !noalias !511
  %73 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %73, i8 -86, i64 128, i1 false), !alias.scope !518, !noalias !521
  %74 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %74) #18, !noalias !524
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %75) #18, !noalias !524
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %75, i8* nonnull align 4 %15, i64 128, i1 false)
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.367", %"struct.gemmlowp::OutputPipelineEvalImpl.367"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %77 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %76, align 8, !noalias !525
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !525
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 1
  %81 = load i32, i32* %80, align 4, !noalias !525
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %74, i8 -86, i64 128, i1 false) #18, !alias.scope !528, !noalias !524
  %82 = insertelement <4 x i32> undef, i32 %79, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = insertelement <4 x i32> undef, i32 %81, i32 0
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> zeroinitializer
  %86 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %9 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16, !noalias !525
  %88 = icmp slt <4 x i32> %87, %83
  %89 = select <4 x i1> %88, <4 x i32> %83, <4 x i32> %87
  %90 = icmp slt <4 x i32> %85, %89
  %91 = select <4 x i1> %90, <4 x i32> %85, <4 x i32> %89
  %92 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %10 to <4 x i32>*
  store <4 x i32> %91, <4 x i32>* %92, align 16, !alias.scope !528, !noalias !524
  %93 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 4
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16, !noalias !525
  %96 = icmp slt <4 x i32> %95, %83
  %97 = select <4 x i1> %96, <4 x i32> %83, <4 x i32> %95
  %98 = icmp slt <4 x i32> %85, %97
  %99 = select <4 x i1> %98, <4 x i32> %85, <4 x i32> %97
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 4
  %101 = bitcast i32* %100 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %101, align 16, !alias.scope !528, !noalias !524
  %102 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 8
  %103 = bitcast i32* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16, !noalias !525
  %105 = icmp slt <4 x i32> %104, %83
  %106 = select <4 x i1> %105, <4 x i32> %83, <4 x i32> %104
  %107 = icmp slt <4 x i32> %85, %106
  %108 = select <4 x i1> %107, <4 x i32> %85, <4 x i32> %106
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 8
  %110 = bitcast i32* %109 to <4 x i32>*
  store <4 x i32> %108, <4 x i32>* %110, align 16, !alias.scope !528, !noalias !524
  %111 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 12
  %112 = bitcast i32* %111 to <4 x i32>*
  %113 = load <4 x i32>, <4 x i32>* %112, align 16, !noalias !525
  %114 = icmp slt <4 x i32> %113, %83
  %115 = select <4 x i1> %114, <4 x i32> %83, <4 x i32> %113
  %116 = icmp slt <4 x i32> %85, %115
  %117 = select <4 x i1> %116, <4 x i32> %85, <4 x i32> %115
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 12
  %119 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %117, <4 x i32>* %119, align 16, !alias.scope !528, !noalias !524
  %120 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 16
  %121 = bitcast i32* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16, !noalias !525
  %123 = icmp slt <4 x i32> %122, %83
  %124 = select <4 x i1> %123, <4 x i32> %83, <4 x i32> %122
  %125 = icmp slt <4 x i32> %85, %124
  %126 = select <4 x i1> %125, <4 x i32> %85, <4 x i32> %124
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 16
  %128 = bitcast i32* %127 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %128, align 16, !alias.scope !528, !noalias !524
  %129 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 20
  %130 = bitcast i32* %129 to <4 x i32>*
  %131 = load <4 x i32>, <4 x i32>* %130, align 16, !noalias !525
  %132 = icmp slt <4 x i32> %131, %83
  %133 = select <4 x i1> %132, <4 x i32> %83, <4 x i32> %131
  %134 = icmp slt <4 x i32> %85, %133
  %135 = select <4 x i1> %134, <4 x i32> %85, <4 x i32> %133
  %136 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 20
  %137 = bitcast i32* %136 to <4 x i32>*
  store <4 x i32> %135, <4 x i32>* %137, align 16, !alias.scope !528, !noalias !524
  %138 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 24
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16, !noalias !525
  %141 = icmp slt <4 x i32> %140, %83
  %142 = select <4 x i1> %141, <4 x i32> %83, <4 x i32> %140
  %143 = icmp slt <4 x i32> %85, %142
  %144 = select <4 x i1> %143, <4 x i32> %85, <4 x i32> %142
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 24
  %146 = bitcast i32* %145 to <4 x i32>*
  store <4 x i32> %144, <4 x i32>* %146, align 16, !alias.scope !528, !noalias !524
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 28
  %148 = bitcast i32* %147 to <4 x i32>*
  %149 = load <4 x i32>, <4 x i32>* %148, align 16, !noalias !525
  %150 = icmp slt <4 x i32> %149, %83
  %151 = select <4 x i1> %150, <4 x i32> %83, <4 x i32> %149
  %152 = icmp slt <4 x i32> %85, %151
  %153 = select <4 x i1> %152, <4 x i32> %85, <4 x i32> %151
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 28
  %155 = bitcast i32* %154 to <4 x i32>*
  store <4 x i32> %153, <4 x i32>* %155, align 16, !alias.scope !528, !noalias !524
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %75) #18, !noalias !524
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %73, i8* nonnull align 16 %74, i64 128, i1 false) #18, !noalias !521
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %74) #18, !noalias !524
  %156 = bitcast [32 x i16]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %156, i8 -86, i64 64, i1 false), !alias.scope !529, !noalias !532
  %157 = bitcast %"struct.gemmlowp::RegisterBuffer.389"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %157) #18, !noalias !535
  %158 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %158) #18, !noalias !535
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %158, i8* nonnull align 4 %73, i64 128, i1 false) #18, !noalias !521
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %157, i8 -86, i64 64, i1 false) #18, !alias.scope !536, !noalias !535
  %159 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %6 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16, !noalias !539
  %161 = icmp sgt <4 x i32> %160, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %162 = select <4 x i1> %161, <4 x i32> %160, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %163 = icmp slt <4 x i32> %162, <i32 32767, i32 32767, i32 32767, i32 32767>
  %164 = select <4 x i1> %163, <4 x i32> %162, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %165 = trunc <4 x i32> %164 to <4 x i16>
  %166 = bitcast %"struct.gemmlowp::RegisterBuffer.389"* %7 to <4 x i16>*
  store <4 x i16> %165, <4 x i16>* %166, align 8, !alias.scope !536, !noalias !535
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 4
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16, !noalias !539
  %170 = icmp sgt <4 x i32> %169, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %172 = icmp slt <4 x i32> %171, <i32 32767, i32 32767, i32 32767, i32 32767>
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %174 = trunc <4 x i32> %173 to <4 x i16>
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 4
  %176 = bitcast i16* %175 to <4 x i16>*
  store <4 x i16> %174, <4 x i16>* %176, align 8, !alias.scope !536, !noalias !535
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 8
  %178 = bitcast i32* %177 to <4 x i32>*
  %179 = load <4 x i32>, <4 x i32>* %178, align 16, !noalias !539
  %180 = icmp sgt <4 x i32> %179, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %182 = icmp slt <4 x i32> %181, <i32 32767, i32 32767, i32 32767, i32 32767>
  %183 = select <4 x i1> %182, <4 x i32> %181, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %184 = trunc <4 x i32> %183 to <4 x i16>
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 8
  %186 = bitcast i16* %185 to <4 x i16>*
  store <4 x i16> %184, <4 x i16>* %186, align 8, !alias.scope !536, !noalias !535
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 12
  %188 = bitcast i32* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16, !noalias !539
  %190 = icmp sgt <4 x i32> %189, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %192 = icmp slt <4 x i32> %191, <i32 32767, i32 32767, i32 32767, i32 32767>
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %194 = trunc <4 x i32> %193 to <4 x i16>
  %195 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 12
  %196 = bitcast i16* %195 to <4 x i16>*
  store <4 x i16> %194, <4 x i16>* %196, align 8, !alias.scope !536, !noalias !535
  %197 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 16
  %198 = bitcast i32* %197 to <4 x i32>*
  %199 = load <4 x i32>, <4 x i32>* %198, align 16, !noalias !539
  %200 = icmp sgt <4 x i32> %199, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %202 = icmp slt <4 x i32> %201, <i32 32767, i32 32767, i32 32767, i32 32767>
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %204 = trunc <4 x i32> %203 to <4 x i16>
  %205 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 16
  %206 = bitcast i16* %205 to <4 x i16>*
  store <4 x i16> %204, <4 x i16>* %206, align 8, !alias.scope !536, !noalias !535
  %207 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 20
  %208 = bitcast i32* %207 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16, !noalias !539
  %210 = icmp sgt <4 x i32> %209, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %212 = icmp slt <4 x i32> %211, <i32 32767, i32 32767, i32 32767, i32 32767>
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %214 = trunc <4 x i32> %213 to <4 x i16>
  %215 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 20
  %216 = bitcast i16* %215 to <4 x i16>*
  store <4 x i16> %214, <4 x i16>* %216, align 8, !alias.scope !536, !noalias !535
  %217 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 24
  %218 = bitcast i32* %217 to <4 x i32>*
  %219 = load <4 x i32>, <4 x i32>* %218, align 16, !noalias !539
  %220 = icmp sgt <4 x i32> %219, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %222 = icmp slt <4 x i32> %221, <i32 32767, i32 32767, i32 32767, i32 32767>
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %224 = trunc <4 x i32> %223 to <4 x i16>
  %225 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 24
  %226 = bitcast i16* %225 to <4 x i16>*
  store <4 x i16> %224, <4 x i16>* %226, align 8, !alias.scope !536, !noalias !535
  %227 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 28
  %228 = bitcast i32* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16, !noalias !539
  %230 = icmp sgt <4 x i32> %229, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %232 = icmp slt <4 x i32> %231, <i32 32767, i32 32767, i32 32767, i32 32767>
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %234 = trunc <4 x i32> %233 to <4 x i16>
  %235 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 28
  %236 = bitcast i16* %235 to <4 x i16>*
  store <4 x i16> %234, <4 x i16>* %236, align 8, !alias.scope !536, !noalias !535
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %158) #18, !noalias !535
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 2 %156, i8* nonnull align 8 %157, i64 64, i1 false) #18, !noalias !532
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %157) #18, !noalias !535
  %237 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %237, i8* nonnull align 2 %156, i64 64, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIsLi8ELi8EEENS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock"* dereferenceable(128), %"class.gemmlowp::MatrixMap.273"*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %1, i64 0, i32 0
  %6 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %1, i64 0, i32 3
  %7 = sext i32 %3 to i64
  %8 = sext i32 %2 to i64
  %9 = add nsw i64 %7, 1
  %10 = add nsw i64 %7, 2
  %11 = add nsw i64 %7, 3
  %12 = add nsw i64 %7, 4
  %13 = add nsw i64 %7, 5
  %14 = add nsw i64 %7, 6
  %15 = add nsw i64 %7, 7
  br label %16

16:                                               ; preds = %16, %4
  %17 = phi i64 [ 0, %4 ], [ %90, %16 ]
  %18 = add nsw i64 %17, %8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %17
  %20 = load i16, i16* %19, align 2
  %21 = load i16*, i16** %5, align 8
  %22 = load i32, i32* %6, align 8
  %23 = sext i32 %22 to i64
  %24 = mul nsw i64 %18, %23
  %25 = getelementptr inbounds i16, i16* %21, i64 %7
  %26 = getelementptr inbounds i16, i16* %25, i64 %24
  store i16 %20, i16* %26, align 2
  %27 = add nuw nsw i64 %17, 8
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = load i16*, i16** %5, align 8
  %31 = load i32, i32* %6, align 8
  %32 = sext i32 %31 to i64
  %33 = mul nsw i64 %18, %32
  %34 = getelementptr inbounds i16, i16* %30, i64 %9
  %35 = getelementptr inbounds i16, i16* %34, i64 %33
  store i16 %29, i16* %35, align 2
  %36 = add nuw nsw i64 %17, 16
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %36
  %38 = load i16, i16* %37, align 2
  %39 = load i16*, i16** %5, align 8
  %40 = load i32, i32* %6, align 8
  %41 = sext i32 %40 to i64
  %42 = mul nsw i64 %18, %41
  %43 = getelementptr inbounds i16, i16* %39, i64 %10
  %44 = getelementptr inbounds i16, i16* %43, i64 %42
  store i16 %38, i16* %44, align 2
  %45 = add nuw nsw i64 %17, 24
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = load i16*, i16** %5, align 8
  %49 = load i32, i32* %6, align 8
  %50 = sext i32 %49 to i64
  %51 = mul nsw i64 %18, %50
  %52 = getelementptr inbounds i16, i16* %48, i64 %11
  %53 = getelementptr inbounds i16, i16* %52, i64 %51
  store i16 %47, i16* %53, align 2
  %54 = add nuw nsw i64 %17, 32
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = load i16*, i16** %5, align 8
  %58 = load i32, i32* %6, align 8
  %59 = sext i32 %58 to i64
  %60 = mul nsw i64 %18, %59
  %61 = getelementptr inbounds i16, i16* %57, i64 %12
  %62 = getelementptr inbounds i16, i16* %61, i64 %60
  store i16 %56, i16* %62, align 2
  %63 = add nuw nsw i64 %17, 40
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = load i16*, i16** %5, align 8
  %67 = load i32, i32* %6, align 8
  %68 = sext i32 %67 to i64
  %69 = mul nsw i64 %18, %68
  %70 = getelementptr inbounds i16, i16* %66, i64 %13
  %71 = getelementptr inbounds i16, i16* %70, i64 %69
  store i16 %65, i16* %71, align 2
  %72 = add nuw nsw i64 %17, 48
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %72
  %74 = load i16, i16* %73, align 2
  %75 = load i16*, i16** %5, align 8
  %76 = load i32, i32* %6, align 8
  %77 = sext i32 %76 to i64
  %78 = mul nsw i64 %18, %77
  %79 = getelementptr inbounds i16, i16* %75, i64 %14
  %80 = getelementptr inbounds i16, i16* %79, i64 %78
  store i16 %74, i16* %80, align 2
  %81 = add nuw nsw i64 %17, 56
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = load i16*, i16** %5, align 8
  %85 = load i32, i32* %6, align 8
  %86 = sext i32 %85 to i64
  %87 = mul nsw i64 %18, %86
  %88 = getelementptr inbounds i16, i16* %84, i64 %15
  %89 = getelementptr inbounds i16, i16* %88, i64 %87
  store i16 %83, i16* %89, align 2
  %90 = add nuw nsw i64 %17, 1
  %91 = icmp eq i64 %90, 8
  br i1 %91, label %92, label %16

92:                                               ; preds = %16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.393"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.349"*, %"struct.gemmlowp::RegisterBlock.390"* byval(%"struct.gemmlowp::RegisterBlock.390") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.391", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.391", align 8
  %8 = alloca [16 x i32], align 8
  %9 = bitcast %"struct.gemmlowp::RegisterBlock.390"* %2 to <4 x i32>*
  %10 = load <4 x i32>, <4 x i32>* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 4
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 8
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 12
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.349", %"struct.gemmlowp::OutputPipelineEvalImpl.349"* %1, i64 0, i32 0, i32 0
  %21 = load %"struct.gemmlowp::OutputStageBiasAddition.278"*, %"struct.gemmlowp::OutputStageBiasAddition.278"** %20, align 8, !noalias !540
  %22 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.278", %"struct.gemmlowp::OutputStageBiasAddition.278"* %21, i64 0, i32 0, i32 0
  %23 = load i32*, i32** %22, align 8, !noalias !540
  %24 = sext i32 %4 to i64
  %25 = getelementptr i32, i32* %23, i64 %24
  %26 = bitcast i32* %25 to i64*
  %27 = load i64, i64* %26, align 4, !noalias !540
  %28 = getelementptr inbounds i32, i32* %25, i64 2
  %29 = bitcast i32* %28 to i64*
  %30 = load i64, i64* %29, align 4, !noalias !540
  %31 = trunc i64 %27 to i32
  %32 = lshr i64 %27, 32
  %33 = trunc i64 %32 to i32
  %34 = insertelement <4 x i32> undef, i32 %31, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = add nsw <4 x i32> %10, %35
  %37 = insertelement <4 x i32> undef, i32 %33, i32 0
  %38 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> zeroinitializer
  %39 = add nsw <4 x i32> %13, %38
  %40 = trunc i64 %30 to i32
  %41 = insertelement <4 x i32> undef, i32 %40, i32 0
  %42 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> zeroinitializer
  %43 = add nsw <4 x i32> %16, %42
  %44 = lshr i64 %30, 32
  %45 = trunc i64 %44 to i32
  %46 = insertelement <4 x i32> undef, i32 %45, i32 0
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> zeroinitializer
  %48 = add nsw <4 x i32> %19, %47
  %49 = bitcast [16 x i32]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %49) #18, !noalias !543
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 64, i1 false) #18, !alias.scope !546, !noalias !543
  %50 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %50) #18, !noalias !549
  %51 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %51) #18, !noalias !549
  %52 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %6 to <4 x i32>*
  store <4 x i32> %36, <4 x i32>* %52, align 16, !noalias !543
  %53 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 4
  %54 = bitcast i32* %53 to <4 x i32>*
  store <4 x i32> %39, <4 x i32>* %54, align 16, !noalias !543
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 8
  %56 = bitcast i32* %55 to <4 x i32>*
  store <4 x i32> %43, <4 x i32>* %56, align 16, !noalias !543
  %57 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 12
  %58 = bitcast i32* %57 to <4 x i32>*
  store <4 x i32> %48, <4 x i32>* %58, align 16, !noalias !543
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %50, i8 -86, i64 64, i1 false) #18, !alias.scope !550, !noalias !549
  %59 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.349", %"struct.gemmlowp::OutputPipelineEvalImpl.349"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %60 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %59, align 8, !noalias !553
  %61 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, i64 0, i32 2
  %62 = load i32, i32* %61, align 4, !noalias !553
  %63 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.349", %"struct.gemmlowp::OutputPipelineEvalImpl.349"* %1, i64 0, i32 1, i32 0, i32 0, i32 1
  %64 = load i32, i32* %63, align 8, !noalias !553
  %65 = shl i32 1, %64
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, i64 0, i32 0
  %68 = load i32, i32* %67, align 4, !noalias !553
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.349", %"struct.gemmlowp::OutputPipelineEvalImpl.349"* %1, i64 0, i32 1, i32 0, i32 0, i32 2
  %71 = load i32, i32* %70, align 4, !noalias !553
  %72 = zext i32 %71 to i64
  %73 = shl nsw i64 -1, %72
  %74 = trunc i64 %73 to i32
  %75 = xor i32 %74, -1
  %76 = ashr i32 %75, 1
  %77 = icmp ne i32 %68, -2147483648
  %78 = extractelement <4 x i32> %36, i32 0
  br label %79

79:                                               ; preds = %112, %5
  %80 = phi i32 [ %78, %5 ], [ %114, %112 ]
  %81 = phi i64 [ 0, %5 ], [ %110, %112 ]
  %82 = sext i32 %80 to i64
  %83 = mul nsw i64 %82, %66
  %84 = icmp slt i64 %83, 2147483647
  %85 = select i1 %84, i64 %83, i64 2147483647
  %86 = icmp sgt i64 %85, -2147483648
  %87 = select i1 %86, i64 %85, i64 -2147483648
  %88 = trunc i64 %87 to i32
  %89 = icmp ne i32 %68, %88
  %90 = or i1 %77, %89
  br i1 %90, label %91, label %99

91:                                               ; preds = %79
  %92 = select i1 %89, i64 %69, i64 %87
  %93 = mul nsw i64 %92, %87
  %94 = icmp sgt i64 %93, -1
  %95 = select i1 %94, i64 1073741824, i64 -1073741823
  %96 = add nsw i64 %95, %93
  %97 = sdiv i64 %96, 2147483648
  %98 = trunc i64 %97 to i32
  br label %99

99:                                               ; preds = %91, %79
  %100 = phi i32 [ %98, %91 ], [ 2147483647, %79 ]
  %101 = and i32 %100, %75
  %102 = lshr i32 %100, 31
  %103 = add nsw i32 %102, %76
  %104 = ashr i32 %100, %71
  %105 = icmp sgt i32 %101, %103
  %106 = zext i1 %105 to i32
  %107 = add i32 %104, %62
  %108 = add i32 %107, %106
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %7, i64 0, i32 0, i64 %81
  store i32 %108, i32* %109, align 4, !alias.scope !550, !noalias !549
  %110 = add nuw nsw i64 %81, 1
  %111 = icmp eq i64 %110, 16
  br i1 %111, label %115, label %112

112:                                              ; preds = %99
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 %110
  %114 = load i32, i32* %113, align 4, !noalias !553
  br label %79

115:                                              ; preds = %99
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %51) #18, !noalias !549
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %49, i8* nonnull align 8 %50, i64 64, i1 false) #18, !noalias !543
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %50) #18, !noalias !549
  %116 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.349", %"struct.gemmlowp::OutputPipelineEvalImpl.349"* %1, i64 0, i32 1, i32 1
  %117 = bitcast [16 x i32]* %8 to %"struct.gemmlowp::RegisterBlock.390"*
  tail call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.393"* sret %0, %"struct.gemmlowp::OutputPipelineEvalImpl.354"* %116, %"struct.gemmlowp::RegisterBlock.390"* nonnull byval(%"struct.gemmlowp::RegisterBlock.390") align 8 %117, i32 %3, i32 %4) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %49) #18, !noalias !543
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.393"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.354"*, %"struct.gemmlowp::RegisterBlock.390"* byval(%"struct.gemmlowp::RegisterBlock.390") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.390"* %2 to <8 x i32>*
  %7 = load <8 x i32>, <8 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 8
  %9 = load i32, i32* %8, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 9
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 10
  %13 = load i32, i32* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 11
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 12
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 13
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 14
  %21 = load i32, i32* %20, align 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 15
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.354", %"struct.gemmlowp::OutputPipelineEvalImpl.354"* %1, i64 0, i32 0, i32 0, i32 0
  %25 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %24, align 8, !noalias !554
  %26 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 0
  %27 = load i32, i32* %26, align 4, !noalias !554
  %28 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 1
  %29 = load i32, i32* %28, align 4, !noalias !554
  %30 = insertelement <8 x i32> undef, i32 %27, i32 0
  %31 = shufflevector <8 x i32> %30, <8 x i32> undef, <8 x i32> zeroinitializer
  %32 = icmp slt <8 x i32> %7, %31
  %33 = select <8 x i1> %32, <8 x i32> %31, <8 x i32> %7
  %34 = insertelement <8 x i32> undef, i32 %29, i32 0
  %35 = shufflevector <8 x i32> %34, <8 x i32> undef, <8 x i32> zeroinitializer
  %36 = icmp slt <8 x i32> %35, %33
  %37 = select <8 x i1> %36, <8 x i32> %35, <8 x i32> %33
  %38 = icmp slt i32 %9, %27
  %39 = select i1 %38, i32 %27, i32 %9
  %40 = icmp slt i32 %29, %39
  %41 = select i1 %40, i32 %29, i32 %39
  %42 = icmp slt i32 %11, %27
  %43 = select i1 %42, i32 %27, i32 %11
  %44 = icmp slt i32 %29, %43
  %45 = select i1 %44, i32 %29, i32 %43
  %46 = icmp slt i32 %13, %27
  %47 = select i1 %46, i32 %27, i32 %13
  %48 = icmp slt i32 %29, %47
  %49 = select i1 %48, i32 %29, i32 %47
  %50 = icmp slt i32 %15, %27
  %51 = select i1 %50, i32 %27, i32 %15
  %52 = icmp slt i32 %29, %51
  %53 = select i1 %52, i32 %29, i32 %51
  %54 = icmp slt i32 %17, %27
  %55 = select i1 %54, i32 %27, i32 %17
  %56 = icmp slt i32 %29, %55
  %57 = select i1 %56, i32 %29, i32 %55
  %58 = icmp slt i32 %19, %27
  %59 = select i1 %58, i32 %27, i32 %19
  %60 = icmp slt i32 %29, %59
  %61 = select i1 %60, i32 %29, i32 %59
  %62 = icmp slt i32 %21, %27
  %63 = select i1 %62, i32 %27, i32 %21
  %64 = icmp slt i32 %29, %63
  %65 = select i1 %64, i32 %29, i32 %63
  %66 = icmp slt i32 %23, %27
  %67 = select i1 %66, i32 %27, i32 %23
  %68 = icmp slt i32 %29, %67
  %69 = select i1 %68, i32 %29, i32 %67
  %70 = icmp sgt <8 x i32> %37, <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %71 = select <8 x i1> %70, <8 x i32> %37, <8 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %72 = icmp slt <8 x i32> %71, <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %73 = select <8 x i1> %72, <8 x i32> %71, <8 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %74 = trunc <8 x i32> %73 to <8 x i16>
  %75 = icmp sgt i32 %41, -32768
  %76 = select i1 %75, i32 %41, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = trunc i32 %78 to i16
  %80 = icmp sgt i32 %45, -32768
  %81 = select i1 %80, i32 %45, i32 -32768
  %82 = icmp slt i32 %81, 32767
  %83 = select i1 %82, i32 %81, i32 32767
  %84 = trunc i32 %83 to i16
  %85 = icmp sgt i32 %49, -32768
  %86 = select i1 %85, i32 %49, i32 -32768
  %87 = icmp slt i32 %86, 32767
  %88 = select i1 %87, i32 %86, i32 32767
  %89 = trunc i32 %88 to i16
  %90 = icmp sgt i32 %53, -32768
  %91 = select i1 %90, i32 %53, i32 -32768
  %92 = icmp slt i32 %91, 32767
  %93 = select i1 %92, i32 %91, i32 32767
  %94 = trunc i32 %93 to i16
  %95 = icmp sgt i32 %57, -32768
  %96 = select i1 %95, i32 %57, i32 -32768
  %97 = icmp slt i32 %96, 32767
  %98 = select i1 %97, i32 %96, i32 32767
  %99 = icmp sgt i32 %61, -32768
  %100 = select i1 %99, i32 %61, i32 -32768
  %101 = icmp slt i32 %100, 32767
  %102 = select i1 %101, i32 %100, i32 32767
  %103 = shl nsw i32 %102, 16
  %104 = and i32 %98, 65535
  %105 = or i32 %103, %104
  %106 = zext i32 %105 to i64
  %107 = icmp sgt i32 %65, -32768
  %108 = select i1 %107, i32 %65, i32 -32768
  %109 = icmp slt i32 %108, 32767
  %110 = select i1 %109, i32 %108, i32 32767
  %111 = and i32 %110, 65535
  %112 = zext i32 %111 to i64
  %113 = shl nuw nsw i64 %112, 32
  %114 = icmp sgt i32 %69, -32768
  %115 = select i1 %114, i32 %69, i32 -32768
  %116 = icmp slt i32 %115, 32767
  %117 = select i1 %116, i32 %115, i32 32767
  %118 = zext i32 %117 to i64
  %119 = shl i64 %118, 48
  %120 = or i64 %119, %106
  %121 = or i64 %120, %113
  %122 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %0 to <8 x i16>*
  store <8 x i16> %74, <8 x i16>* %122, align 2, !alias.scope !559
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 8
  store i16 %79, i16* %123, align 2, !alias.scope !559
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 9
  store i16 %84, i16* %124, align 2, !alias.scope !559
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 10
  store i16 %89, i16* %125, align 2, !alias.scope !559
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 11
  store i16 %94, i16* %126, align 2, !alias.scope !559
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 12
  %128 = bitcast i16* %127 to i64*
  store i64 %121, i64* %128, align 2, !alias.scope !559
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"*, i64, i64) local_unnamed_addr #1 comdat align 2 {
  %4 = alloca { i64, i64 }, align 8
  %5 = bitcast { i64, i64 }* %4 to [4 x i32]*
  %6 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 1
  %7 = getelementptr inbounds %"struct.gemmlowp::OutputStageEvalBufferImpl.309", %"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %0, i64 0, i32 0
  %8 = bitcast { i64, i64 }* %4 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %8, i8 -86, i64 16, i1 false)
  %9 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %7, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %9, i64 0, i32 2
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::OutputStageEvalBufferImpl.309", %"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %0, i64 0, i32 1
  %13 = load i32, i32* %12, align 8
  %14 = shl i32 1, %13
  %15 = sext i32 %14 to i64
  %16 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %9, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageEvalBufferImpl.309", %"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %0, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = zext i32 %20 to i64
  %22 = shl nsw i64 -1, %21
  %23 = trunc i64 %22 to i32
  %24 = xor i32 %23, -1
  %25 = ashr i32 %24, 1
  %26 = shl i64 %1, 32
  %27 = ashr exact i64 %26, 32
  %28 = mul nsw i64 %27, %15
  %29 = icmp slt i64 %28, 2147483647
  %30 = select i1 %29, i64 %28, i64 2147483647
  %31 = icmp sgt i64 %30, -2147483648
  %32 = select i1 %31, i64 %30, i64 -2147483648
  %33 = trunc i64 %32 to i32
  %34 = icmp eq i32 %17, %33
  br i1 %34, label %35, label %37

35:                                               ; preds = %3
  %36 = icmp eq i32 %17, -2147483648
  br i1 %36, label %45, label %37

37:                                               ; preds = %3, %35
  %38 = phi i64 [ %32, %35 ], [ %18, %3 ]
  %39 = mul nsw i64 %38, %32
  %40 = icmp sgt i64 %39, -1
  %41 = select i1 %40, i64 1073741824, i64 -1073741823
  %42 = add nsw i64 %41, %39
  %43 = sdiv i64 %42, 2147483648
  %44 = trunc i64 %43 to i32
  br label %45

45:                                               ; preds = %35, %37
  %46 = phi i32 [ %44, %37 ], [ 2147483647, %35 ]
  %47 = and i32 %46, %24
  %48 = lshr i32 %46, 31
  %49 = add nsw i32 %25, %48
  %50 = ashr i32 %46, %20
  %51 = icmp sgt i32 %47, %49
  %52 = zext i1 %51 to i32
  %53 = add i32 %50, %11
  %54 = add i32 %53, %52
  %55 = bitcast { i64, i64 }* %4 to i32*
  store i32 %54, i32* %55, align 8
  %56 = ashr i64 %1, 32
  %57 = mul nsw i64 %56, %15
  %58 = icmp slt i64 %57, 2147483647
  %59 = select i1 %58, i64 %57, i64 2147483647
  %60 = icmp sgt i64 %59, -2147483648
  %61 = select i1 %60, i64 %59, i64 -2147483648
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %17, %62
  br i1 %63, label %64, label %66

64:                                               ; preds = %45
  %65 = icmp eq i32 %17, -2147483648
  br i1 %65, label %74, label %66

66:                                               ; preds = %64, %45
  %67 = phi i64 [ %61, %64 ], [ %18, %45 ]
  %68 = mul nsw i64 %67, %61
  %69 = icmp sgt i64 %68, -1
  %70 = select i1 %69, i64 1073741824, i64 -1073741823
  %71 = add nsw i64 %70, %68
  %72 = sdiv i64 %71, 2147483648
  %73 = trunc i64 %72 to i32
  br label %74

74:                                               ; preds = %66, %64
  %75 = phi i32 [ %73, %66 ], [ 2147483647, %64 ]
  %76 = and i32 %75, %24
  %77 = lshr i32 %75, 31
  %78 = add nsw i32 %25, %77
  %79 = ashr i32 %75, %20
  %80 = icmp sgt i32 %76, %78
  %81 = zext i1 %80 to i32
  %82 = add i32 %79, %11
  %83 = add i32 %82, %81
  %84 = getelementptr inbounds [4 x i32], [4 x i32]* %5, i64 0, i64 1
  store i32 %83, i32* %84, align 4
  %85 = shl i64 %2, 32
  %86 = ashr exact i64 %85, 32
  %87 = mul nsw i64 %86, %15
  %88 = icmp slt i64 %87, 2147483647
  %89 = select i1 %88, i64 %87, i64 2147483647
  %90 = icmp sgt i64 %89, -2147483648
  %91 = select i1 %90, i64 %89, i64 -2147483648
  %92 = trunc i64 %91 to i32
  %93 = icmp eq i32 %17, %92
  br i1 %93, label %94, label %96

94:                                               ; preds = %74
  %95 = icmp eq i32 %17, -2147483648
  br i1 %95, label %104, label %96

96:                                               ; preds = %94, %74
  %97 = phi i64 [ %91, %94 ], [ %18, %74 ]
  %98 = mul nsw i64 %97, %91
  %99 = icmp sgt i64 %98, -1
  %100 = select i1 %99, i64 1073741824, i64 -1073741823
  %101 = add nsw i64 %100, %98
  %102 = sdiv i64 %101, 2147483648
  %103 = trunc i64 %102 to i32
  br label %104

104:                                              ; preds = %96, %94
  %105 = phi i32 [ %103, %96 ], [ 2147483647, %94 ]
  %106 = and i32 %105, %24
  %107 = lshr i32 %105, 31
  %108 = add nsw i32 %25, %107
  %109 = ashr i32 %105, %20
  %110 = icmp sgt i32 %106, %108
  %111 = zext i1 %110 to i32
  %112 = add i32 %109, %11
  %113 = add i32 %112, %111
  %114 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 1
  %115 = bitcast i64* %114 to i32*
  store i32 %113, i32* %115, align 8
  %116 = ashr i64 %2, 32
  %117 = mul nsw i64 %116, %15
  %118 = icmp slt i64 %117, 2147483647
  %119 = select i1 %118, i64 %117, i64 2147483647
  %120 = icmp sgt i64 %119, -2147483648
  %121 = select i1 %120, i64 %119, i64 -2147483648
  %122 = trunc i64 %121 to i32
  %123 = icmp eq i32 %17, %122
  br i1 %123, label %124, label %126

124:                                              ; preds = %104
  %125 = icmp eq i32 %17, -2147483648
  br i1 %125, label %134, label %126

126:                                              ; preds = %124, %104
  %127 = phi i64 [ %121, %124 ], [ %18, %104 ]
  %128 = mul nsw i64 %127, %121
  %129 = icmp sgt i64 %128, -1
  %130 = select i1 %129, i64 1073741824, i64 -1073741823
  %131 = add nsw i64 %130, %128
  %132 = sdiv i64 %131, 2147483648
  %133 = trunc i64 %132 to i32
  br label %134

134:                                              ; preds = %126, %124
  %135 = phi i32 [ %133, %126 ], [ 2147483647, %124 ]
  %136 = and i32 %135, %24
  %137 = lshr i32 %135, 31
  %138 = add nsw i32 %25, %137
  %139 = ashr i32 %135, %20
  %140 = icmp sgt i32 %136, %138
  %141 = zext i1 %140 to i32
  %142 = add i32 %139, %11
  %143 = add i32 %142, %141
  %144 = getelementptr inbounds [4 x i32], [4 x i32]* %5, i64 0, i64 3
  store i32 %143, i32* %144, align 4
  %145 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 0
  %146 = load i64, i64* %145, align 8
  %147 = insertvalue { i64, i64 } undef, i64 %146, 0
  %148 = load i64, i64* %6, align 8
  %149 = insertvalue { i64, i64 } %147, i64 %148, 1
  ret { i64, i64 } %149
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.364"*, %"struct.gemmlowp::RegisterBlock.380"* byval(%"struct.gemmlowp::RegisterBlock.380") align 8, %"class.gemmlowp::MatrixMap.273"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.388", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBlock.388", align 2
  %11 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %11) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %11, i8 -86, i64 64, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition.278"*, %"struct.gemmlowp::OutputStageBiasAddition.278"** %36, align 8, !noalias !562
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.278", %"struct.gemmlowp::OutputStageBiasAddition.278"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !562
  %40 = sext i32 %4 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to i64*
  %43 = load i64, i64* %42, align 4, !noalias !562
  %44 = getelementptr inbounds i32, i32* %41, i64 2
  %45 = bitcast i32* %44 to i64*
  %46 = load i64, i64* %45, align 4, !noalias !562
  %47 = trunc i64 %43 to i32
  %48 = lshr i64 %43, 32
  %49 = trunc i64 %48 to i32
  %50 = insertelement <4 x i32> undef, i32 %47, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = add nsw <4 x i32> %13, %51
  %53 = add nsw <4 x i32> %16, %51
  %54 = insertelement <4 x i32> undef, i32 %49, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add nsw <4 x i32> %19, %55
  %57 = add nsw <4 x i32> %22, %55
  %58 = trunc i64 %46 to i32
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = add nsw <4 x i32> %25, %60
  %62 = add nsw <4 x i32> %28, %60
  %63 = lshr i64 %46, 32
  %64 = trunc i64 %63 to i32
  %65 = insertelement <4 x i32> undef, i32 %64, i32 0
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> zeroinitializer
  %67 = add nsw <4 x i32> %31, %66
  %68 = add nsw <4 x i32> %34, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.364", %"struct.gemmlowp::OutputPipelineExecutor.364"* %0, i64 0, i32 0, i32 1
  %70 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %9 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %70, align 16, !noalias !567
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 4
  %72 = bitcast i32* %71 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %72, align 16, !noalias !567
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 8
  %74 = bitcast i32* %73 to <4 x i32>*
  store <4 x i32> %56, <4 x i32>* %74, align 16, !noalias !567
  %75 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 12
  %76 = bitcast i32* %75 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %76, align 16, !noalias !567
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 16
  %78 = bitcast i32* %77 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %78, align 16, !noalias !567
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 20
  %80 = bitcast i32* %79 to <4 x i32>*
  store <4 x i32> %62, <4 x i32>* %80, align 16, !noalias !567
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 24
  %82 = bitcast i32* %81 to <4 x i32>*
  store <4 x i32> %67, <4 x i32>* %82, align 16, !noalias !567
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 28
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %84, align 16, !noalias !567
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.388"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.367"* %69, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %9, i32 %3, i32 %4) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %85 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %85)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %85, i8* nonnull align 2 %11, i64 64, i1 false)
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = sext i32 %5 to i64
  %90 = add nsw i64 %88, 1
  %91 = add nsw i64 %88, 2
  %92 = add nsw i64 %88, 3
  br label %93

93:                                               ; preds = %93, %7
  %94 = phi i64 [ 0, %7 ], [ %131, %93 ]
  %95 = add nsw i64 %94, %89
  %96 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %94
  %97 = load i16, i16* %96, align 2
  %98 = load i16*, i16** %86, align 8
  %99 = load i32, i32* %87, align 8
  %100 = sext i32 %99 to i64
  %101 = mul nsw i64 %95, %100
  %102 = getelementptr inbounds i16, i16* %98, i64 %88
  %103 = getelementptr inbounds i16, i16* %102, i64 %101
  store i16 %97, i16* %103, align 2
  %104 = add nuw nsw i64 %94, 8
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %104
  %106 = load i16, i16* %105, align 2
  %107 = load i16*, i16** %86, align 8
  %108 = load i32, i32* %87, align 8
  %109 = sext i32 %108 to i64
  %110 = mul nsw i64 %95, %109
  %111 = getelementptr inbounds i16, i16* %107, i64 %90
  %112 = getelementptr inbounds i16, i16* %111, i64 %110
  store i16 %106, i16* %112, align 2
  %113 = add nuw nsw i64 %94, 16
  %114 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = load i16*, i16** %86, align 8
  %117 = load i32, i32* %87, align 8
  %118 = sext i32 %117 to i64
  %119 = mul nsw i64 %95, %118
  %120 = getelementptr inbounds i16, i16* %116, i64 %91
  %121 = getelementptr inbounds i16, i16* %120, i64 %119
  store i16 %115, i16* %121, align 2
  %122 = add nuw nsw i64 %94, 24
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %122
  %124 = load i16, i16* %123, align 2
  %125 = load i16*, i16** %86, align 8
  %126 = load i32, i32* %87, align 8
  %127 = sext i32 %126 to i64
  %128 = mul nsw i64 %95, %127
  %129 = getelementptr inbounds i16, i16* %125, i64 %92
  %130 = getelementptr inbounds i16, i16* %129, i64 %128
  store i16 %124, i16* %130, align 2
  %131 = add nuw nsw i64 %94, 1
  %132 = icmp eq i64 %131, 8
  br i1 %132, label %133, label %93

133:                                              ; preds = %93
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %85)
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %11) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.323"*, %"struct.gemmlowp::RegisterBlock.382"* byval(%"struct.gemmlowp::RegisterBlock.382") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.383", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.383", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBlock.382", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %1 to i8*
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #18, !noalias !568
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #18, !noalias !568
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* nonnull align 8 %8, i64 32, i1 false)
  %11 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.323", %"struct.gemmlowp::OutputPipelineEvalImpl.323"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #18, !alias.scope !571, !noalias !568
  %12 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %11, align 8, !noalias !574
  %13 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 2
  %14 = load i32, i32* %13, align 4, !noalias !574
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.323", %"struct.gemmlowp::OutputPipelineEvalImpl.323"* %0, i64 0, i32 0, i32 0, i32 1
  %16 = load i32, i32* %15, align 8, !noalias !574
  %17 = shl i32 1, %16
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !574
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.323", %"struct.gemmlowp::OutputPipelineEvalImpl.323"* %0, i64 0, i32 0, i32 0, i32 2
  %23 = load i32, i32* %22, align 4, !noalias !574
  %24 = zext i32 %23 to i64
  %25 = shl nsw i64 -1, %24
  %26 = trunc i64 %25 to i32
  %27 = xor i32 %26, -1
  %28 = ashr i32 %27, 1
  %29 = icmp ne i32 %20, -2147483648
  br label %30

30:                                               ; preds = %51, %4
  %31 = phi i64 [ 0, %4 ], [ %62, %51 ]
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %5, i64 0, i32 0, i64 %31
  %33 = load i32, i32* %32, align 4, !noalias !574
  %34 = sext i32 %33 to i64
  %35 = mul nsw i64 %34, %18
  %36 = icmp slt i64 %35, 2147483647
  %37 = select i1 %36, i64 %35, i64 2147483647
  %38 = icmp sgt i64 %37, -2147483648
  %39 = select i1 %38, i64 %37, i64 -2147483648
  %40 = trunc i64 %39 to i32
  %41 = icmp ne i32 %20, %40
  %42 = or i1 %29, %41
  br i1 %42, label %43, label %51

43:                                               ; preds = %30
  %44 = select i1 %41, i64 %21, i64 %39
  %45 = mul nsw i64 %44, %39
  %46 = icmp sgt i64 %45, -1
  %47 = select i1 %46, i64 1073741824, i64 -1073741823
  %48 = add nsw i64 %47, %45
  %49 = sdiv i64 %48, 2147483648
  %50 = trunc i64 %49 to i32
  br label %51

51:                                               ; preds = %43, %30
  %52 = phi i32 [ %50, %43 ], [ 2147483647, %30 ]
  %53 = and i32 %52, %27
  %54 = lshr i32 %52, 31
  %55 = add nsw i32 %54, %28
  %56 = ashr i32 %52, %23
  %57 = icmp sgt i32 %53, %55
  %58 = zext i1 %57 to i32
  %59 = add i32 %56, %14
  %60 = add i32 %59, %58
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %6, i64 0, i32 0, i64 %31
  store i32 %60, i32* %61, align 4, !alias.scope !571, !noalias !568
  %62 = add nuw nsw i64 %31, 1
  %63 = icmp eq i64 %62, 8
  br i1 %63, label %64, label %30

64:                                               ; preds = %51
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #18, !noalias !568
  %65 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %6 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %6, i64 0, i32 0, i64 4
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #18, !noalias !568
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.323", %"struct.gemmlowp::OutputPipelineEvalImpl.323"* %0, i64 0, i32 1
  %71 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %7 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %71, align 16
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %7, i64 0, i32 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  store <4 x i32> %69, <4 x i32>* %73, align 16
  %74 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.326"* %70, %"struct.gemmlowp::RegisterBlock.382"* nonnull byval(%"struct.gemmlowp::RegisterBlock.382") align 8 %7, i32 %2, i32 %3)
  ret { i64, i64 } %74
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.326"*, %"struct.gemmlowp::RegisterBlock.382"* byval(%"struct.gemmlowp::RegisterBlock.382") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 0
  %6 = load i32, i32* %5, align 8
  %7 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 3
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 4
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 5
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 6
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 7
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.326", %"struct.gemmlowp::OutputPipelineEvalImpl.326"* %0, i64 0, i32 0, i32 0, i32 0
  %22 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %21, align 8, !noalias !575
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 0
  %24 = load i32, i32* %23, align 4, !noalias !575
  %25 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 1
  %26 = load i32, i32* %25, align 4, !noalias !575
  %27 = icmp slt i32 %6, %24
  %28 = select i1 %27, i32 %24, i32 %6
  %29 = icmp slt i32 %26, %28
  %30 = select i1 %29, i32 %26, i32 %28
  %31 = icmp slt i32 %8, %24
  %32 = select i1 %31, i32 %24, i32 %8
  %33 = icmp slt i32 %26, %32
  %34 = select i1 %33, i32 %26, i32 %32
  %35 = icmp slt i32 %10, %24
  %36 = select i1 %35, i32 %24, i32 %10
  %37 = icmp slt i32 %26, %36
  %38 = select i1 %37, i32 %26, i32 %36
  %39 = icmp slt i32 %12, %24
  %40 = select i1 %39, i32 %24, i32 %12
  %41 = icmp slt i32 %26, %40
  %42 = select i1 %41, i32 %26, i32 %40
  %43 = icmp slt i32 %14, %24
  %44 = select i1 %43, i32 %24, i32 %14
  %45 = icmp slt i32 %26, %44
  %46 = select i1 %45, i32 %26, i32 %44
  %47 = icmp slt i32 %16, %24
  %48 = select i1 %47, i32 %24, i32 %16
  %49 = icmp slt i32 %26, %48
  %50 = select i1 %49, i32 %26, i32 %48
  %51 = icmp slt i32 %18, %24
  %52 = select i1 %51, i32 %24, i32 %18
  %53 = icmp slt i32 %26, %52
  %54 = select i1 %53, i32 %26, i32 %52
  %55 = icmp slt i32 %20, %24
  %56 = select i1 %55, i32 %24, i32 %20
  %57 = icmp slt i32 %26, %56
  %58 = select i1 %57, i32 %26, i32 %56
  %59 = icmp sgt i32 %30, -32768
  %60 = select i1 %59, i32 %30, i32 -32768
  %61 = icmp slt i32 %60, 32767
  %62 = select i1 %61, i32 %60, i32 32767
  %63 = icmp sgt i32 %34, -32768
  %64 = select i1 %63, i32 %34, i32 -32768
  %65 = icmp slt i32 %64, 32767
  %66 = select i1 %65, i32 %64, i32 32767
  %67 = icmp sgt i32 %38, -32768
  %68 = select i1 %67, i32 %38, i32 -32768
  %69 = icmp slt i32 %68, 32767
  %70 = select i1 %69, i32 %68, i32 32767
  %71 = icmp sgt i32 %42, -32768
  %72 = select i1 %71, i32 %42, i32 -32768
  %73 = icmp slt i32 %72, 32767
  %74 = select i1 %73, i32 %72, i32 32767
  %75 = icmp sgt i32 %46, -32768
  %76 = select i1 %75, i32 %46, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = icmp sgt i32 %50, -32768
  %80 = select i1 %79, i32 %50, i32 -32768
  %81 = icmp slt i32 %80, 32767
  %82 = select i1 %81, i32 %80, i32 32767
  %83 = shl nsw i32 %82, 16
  %84 = and i32 %78, 65535
  %85 = or i32 %83, %84
  %86 = zext i32 %85 to i64
  %87 = icmp sgt i32 %54, -32768
  %88 = select i1 %87, i32 %54, i32 -32768
  %89 = icmp slt i32 %88, 32767
  %90 = select i1 %89, i32 %88, i32 32767
  %91 = and i32 %90, 65535
  %92 = zext i32 %91 to i64
  %93 = shl nuw nsw i64 %92, 32
  %94 = icmp sgt i32 %58, -32768
  %95 = select i1 %94, i32 %58, i32 -32768
  %96 = icmp slt i32 %95, 32767
  %97 = select i1 %96, i32 %95, i32 32767
  %98 = zext i32 %97 to i64
  %99 = shl i64 %98, 48
  %100 = or i64 %99, %86
  %101 = or i64 %100, %93
  %102 = zext i32 %74 to i64
  %103 = shl i64 %102, 48
  %104 = and i32 %70, 65535
  %105 = zext i32 %104 to i64
  %106 = shl nuw nsw i64 %105, 32
  %107 = shl nsw i32 %66, 16
  %108 = and i32 %62, 65535
  %109 = or i32 %107, %108
  %110 = zext i32 %109 to i64
  %111 = or i64 %103, %110
  %112 = or i64 %111, %106
  %113 = insertvalue { i64, i64 } undef, i64 %112, 0
  %114 = insertvalue { i64, i64 } %113, i64 %101, 1
  ret { i64, i64 } %114
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.304"*, i64, i64, %"class.gemmlowp::MatrixMap.273"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %9 = trunc i64 %1 to i32
  %10 = lshr i64 %1, 32
  %11 = trunc i64 %10 to i32
  %12 = trunc i64 %2 to i32
  %13 = lshr i64 %2, 32
  %14 = trunc i64 %13 to i32
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %0, i64 0, i32 0, i32 0, i32 0
  %16 = load %"struct.gemmlowp::OutputStageBiasAddition.278"*, %"struct.gemmlowp::OutputStageBiasAddition.278"** %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.278", %"struct.gemmlowp::OutputStageBiasAddition.278"* %16, i64 0, i32 0, i32 0
  %18 = load i32*, i32** %17, align 8
  %19 = sext i32 %5 to i64
  %20 = getelementptr inbounds i32, i32* %18, i64 %19
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, %9
  %23 = add nsw i32 %21, %11
  %24 = add nsw i32 %21, %12
  %25 = zext i32 %24 to i64
  %26 = add nsw i32 %21, %14
  %27 = zext i32 %26 to i64
  %28 = shl nuw i64 %27, 32
  %29 = or i64 %28, %25
  %30 = zext i32 %23 to i64
  %31 = shl nuw i64 %30, 32
  %32 = zext i32 %22 to i64
  %33 = or i64 %31, %32
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %35 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %34, i64 %33, i64 %29) #18
  %36 = extractvalue { i64, i64 } %35, 0
  %37 = extractvalue { i64, i64 } %35, 1
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.304", %"struct.gemmlowp::OutputPipelineExecutor.304"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %39 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %38, align 8
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 0
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 1
  %43 = load i32, i32* %42, align 4
  %44 = trunc i64 %36 to i32
  %45 = icmp sgt i32 %41, %44
  %46 = select i1 %45, i32 %41, i32 %44
  %47 = icmp slt i32 %43, %46
  %48 = select i1 %47, i32 %43, i32 %46
  %49 = lshr i64 %36, 32
  %50 = trunc i64 %49 to i32
  %51 = icmp sgt i32 %41, %50
  %52 = select i1 %51, i32 %41, i32 %50
  %53 = icmp slt i32 %43, %52
  %54 = select i1 %53, i32 %43, i32 %52
  %55 = trunc i64 %37 to i32
  %56 = icmp sgt i32 %41, %55
  %57 = select i1 %56, i32 %41, i32 %55
  %58 = icmp slt i32 %43, %57
  %59 = select i1 %58, i32 %43, i32 %57
  %60 = lshr i64 %37, 32
  %61 = trunc i64 %60 to i32
  %62 = icmp sgt i32 %41, %61
  %63 = select i1 %62, i32 %41, i32 %61
  %64 = icmp slt i32 %43, %63
  %65 = select i1 %64, i32 %43, i32 %63
  %66 = icmp sgt i32 %48, -32768
  %67 = select i1 %66, i32 %48, i32 -32768
  %68 = icmp slt i32 %67, 32767
  %69 = select i1 %68, i32 %67, i32 32767
  %70 = icmp sgt i32 %54, -32768
  %71 = select i1 %70, i32 %54, i32 -32768
  %72 = icmp slt i32 %71, 32767
  %73 = select i1 %72, i32 %71, i32 32767
  %74 = icmp sgt i32 %59, -32768
  %75 = select i1 %74, i32 %59, i32 -32768
  %76 = icmp slt i32 %75, 32767
  %77 = select i1 %76, i32 %75, i32 32767
  %78 = icmp sgt i32 %65, -32768
  %79 = select i1 %78, i32 %65, i32 -32768
  %80 = icmp slt i32 %79, 32767
  %81 = select i1 %80, i32 %79, i32 32767
  %82 = trunc i32 %69 to i16
  %83 = trunc i32 %73 to i16
  %84 = trunc i32 %77 to i16
  %85 = trunc i32 %81 to i16
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %3, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %3, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = load i16*, i16** %86, align 8
  %90 = load i32, i32* %87, align 8
  %91 = sext i32 %90 to i64
  %92 = mul nsw i64 %91, %88
  %93 = getelementptr inbounds i16, i16* %89, i64 %92
  %94 = sext i32 %7 to i64
  %95 = getelementptr inbounds i16, i16* %93, i64 %94
  store i16 %82, i16* %95, align 2
  %96 = add nsw i64 %88, 1
  %97 = load i16*, i16** %86, align 8
  %98 = load i32, i32* %87, align 8
  %99 = sext i32 %98 to i64
  %100 = mul nsw i64 %96, %99
  %101 = getelementptr inbounds i16, i16* %97, i64 %100
  %102 = getelementptr inbounds i16, i16* %101, i64 %94
  store i16 %83, i16* %102, align 2
  %103 = add nsw i64 %88, 2
  %104 = load i16*, i16** %86, align 8
  %105 = load i32, i32* %87, align 8
  %106 = sext i32 %105 to i64
  %107 = mul nsw i64 %103, %106
  %108 = getelementptr inbounds i16, i16* %104, i64 %107
  %109 = getelementptr inbounds i16, i16* %108, i64 %94
  store i16 %84, i16* %109, align 2
  %110 = add nsw i64 %88, 3
  %111 = load i16*, i16** %86, align 8
  %112 = load i32, i32* %87, align 8
  %113 = sext i32 %112 to i64
  %114 = mul nsw i64 %110, %113
  %115 = getelementptr inbounds i16, i16* %111, i64 %114
  %116 = getelementptr inbounds i16, i16* %115, i64 %94
  store i16 %85, i16* %116, align 2
  ret void
}

; Function Attrs: nounwind
declare void @free(i8* nocapture) local_unnamed_addr #10

; Function Attrs: nofree nounwind
declare i32 @posix_memalign(i8**, i64, i64) local_unnamed_addr #12

; Function Attrs: nofree nounwind
declare i32 @fprintf(%struct._IO_FILE* nocapture, i8* nocapture readonly, ...) local_unnamed_addr #12

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask"*) unnamed_addr #5 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask"*) unnamed_addr #5 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #17
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !580
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !580
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !580
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !580
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !580
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !580
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #18
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !583
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !583
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !583
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !583
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !583
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !583
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #18
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !586
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !586
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !586
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !586
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !586
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !586
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #18
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup.272"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #18
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !589
  %190 = load i32, i32* %115, align 8, !noalias !589
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #18
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #18
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #18
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #18
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #18
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #18
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #18
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #18
  %280 = load %"class.gemmlowp::VectorDup.272"*, %"class.gemmlowp::VectorDup.272"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !592
  store i32 %282, i32* %148, align 4, !alias.scope !592
  store i32 %188, i32* %149, align 4, !alias.scope !592
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #18
  %283 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !595
  store i32 %285, i32* %152, align 4, !alias.scope !595
  store i32 %171, i32* %153, align 4, !alias.scope !595
  %286 = load %"class.std::__1::tuple.275"*, %"class.std::__1::tuple.275"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.273"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.275"* dereferenceable(40) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #18
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"*, %"class.std::__1::vector.283"* dereferenceable(24)) local_unnamed_addr #1 comdat align 2 {
  %3 = alloca %"class.std::__1::chrono::duration.170", align 8
  %4 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %1, i64 0, i32 0, i32 1
  %5 = bitcast %"struct.gemmlowp::Task"*** %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = bitcast %"class.std::__1::vector.283"* %1 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = sub i64 %6, %8
  %10 = ashr exact i64 %9, 3
  %11 = add nsw i64 %10, -1
  tail call void @_ZN8gemmlowp11WorkersPool13CreateWorkersEm(%"class.gemmlowp::WorkersPool"* %0, i64 %11)
  %12 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %13 = load atomic i64, i64* %12 monotonic, align 8
  store atomic i64 %11, i64* %12 release, align 8
  %14 = icmp eq i64 %11, 0
  br i1 %14, label %18, label %15

15:                                               ; preds = %2
  %16 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 0
  %17 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %1, i64 0, i32 0, i32 0
  br label %60

18:                                               ; preds = %74, %2
  %19 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %1, i64 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %19, align 8
  %21 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %20, i64 %11
  %22 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %21, align 8
  %23 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 2
  %24 = getelementptr inbounds %"struct.gemmlowp::Task", %"struct.gemmlowp::Task"* %22, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %23, %"class.gemmlowp::Allocator"** %24, align 8
  %25 = bitcast %"struct.gemmlowp::Task"* %22 to void (%"struct.gemmlowp::Task"*)***
  %26 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %25, align 8
  %27 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %26, i64 2
  %28 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %27, align 8
  tail call void %28(%"struct.gemmlowp::Task"* %22) #18
  %29 = load atomic i64, i64* %12 acquire, align 8
  %30 = icmp eq i64 %29, 0
  br i1 %30, label %43, label %31

31:                                               ; preds = %18
  %32 = bitcast %"class.std::__1::chrono::duration.170"* %3 to i8*
  %33 = getelementptr inbounds %"class.std::__1::chrono::duration.170", %"class.std::__1::chrono::duration.170"* %3, i64 0, i32 0
  br label %34

34:                                               ; preds = %39, %31
  %35 = phi i32 [ 0, %31 ], [ %40, %39 ]
  call void asm sideeffect "nop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0A", "~{dirflag},~{fpsr},~{flags}"() #18, !srcloc !246
  %36 = add nsw i32 %35, 64
  %37 = icmp sgt i32 %36, 4000000
  br i1 %37, label %38, label %39

38:                                               ; preds = %34
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %32) #18
  store i64 1000000, i64* %33, align 8
  call void @_ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE(%"class.std::__1::chrono::duration.170"* nonnull dereferenceable(8) %3) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %32) #18
  br label %39

39:                                               ; preds = %38, %34
  %40 = phi i32 [ 0, %38 ], [ %36, %34 ]
  %41 = load atomic i64, i64* %12 acquire, align 8
  %42 = icmp eq i64 %41, 0
  br i1 %42, label %43, label %34

43:                                               ; preds = %39, %18
  %44 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %19, align 8
  %45 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %4, align 8
  %46 = icmp eq %"struct.gemmlowp::Task"** %44, %45
  br i1 %46, label %59, label %47

47:                                               ; preds = %43, %56
  %48 = phi %"struct.gemmlowp::Task"** [ %57, %56 ], [ %44, %43 ]
  %49 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %48, align 8
  %50 = icmp eq %"struct.gemmlowp::Task"* %49, null
  br i1 %50, label %56, label %51

51:                                               ; preds = %47
  %52 = bitcast %"struct.gemmlowp::Task"* %49 to void (%"struct.gemmlowp::Task"*)***
  %53 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %52, align 8
  %54 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %53, i64 1
  %55 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %54, align 8
  call void %55(%"struct.gemmlowp::Task"* nonnull %49) #18
  br label %56

56:                                               ; preds = %51, %47
  %57 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %48, i64 1
  %58 = icmp eq %"struct.gemmlowp::Task"** %57, %45
  br i1 %58, label %59, label %47

59:                                               ; preds = %56, %43
  ret void

60:                                               ; preds = %74, %15
  %61 = phi i64 [ 0, %15 ], [ %81, %74 ]
  %62 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %16, align 8
  %63 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %62, i64 %61
  %64 = load %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %63, align 8
  %65 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %17, align 8
  %66 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %65, i64 %61
  %67 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %66, align 8
  %68 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 3
  %69 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %68) #18
  %70 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0
  %71 = load atomic i32, i32* %70 monotonic, align 4
  %72 = icmp ult i32 %71, 3
  br i1 %72, label %74, label %73

73:                                               ; preds = %60
  tail call void @abort() #19
  unreachable

74:                                               ; preds = %60
  %75 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 5
  %76 = getelementptr inbounds %"struct.gemmlowp::Task", %"struct.gemmlowp::Task"* %67, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %75, %"class.gemmlowp::Allocator"** %76, align 8
  %77 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 1
  store %"struct.gemmlowp::Task"* %67, %"struct.gemmlowp::Task"** %77, align 8
  store atomic i32 2, i32* %70 monotonic, align 4
  %78 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 2
  %79 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %78) #18
  %80 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %68) #18
  %81 = add nuw i64 %61, 1
  %82 = icmp eq i64 %81, %11
  br i1 %82, label %18, label %60
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.std::__1::tuple"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup", align 4
  %22 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #18
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !598
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !598
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !598
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !598
  %67 = load i64, i64* %61, align 8, !noalias !598
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !598
  %69 = load i64, i64* %59, align 8, !noalias !598
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !598
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #18
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !601
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !601
  %82 = load i64, i64* %61, align 8, !noalias !601
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !601
  %84 = load i64, i64* %59, align 8, !noalias !601
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !601
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #18
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !604
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !604
  %106 = load i64, i64* %61, align 8, !noalias !604
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !604
  %108 = load i64, i64* %59, align 8, !noalias !604
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !604
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #18
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !607
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !607
  %121 = load i64, i64* %61, align 8, !noalias !607
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !607
  %123 = load i64, i64* %59, align 8, !noalias !607
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !607
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #18
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !610
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !610
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !610
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !610
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #18
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #18
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.258"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #18
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #18
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #18
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup.272"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #18
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !613
  %228 = load i32, i32* %173, align 8, !noalias !613
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #18
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #18
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #18
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !616
  %247 = load i32, i32* %184, align 8, !noalias !616
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #18
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #18
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #18
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #18
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #18
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #18
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #18
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #18
  %332 = load i32, i32* %208, align 4, !noalias !619
  store i32 %332, i32* %209, align 4, !alias.scope !619
  store i32 %226, i32* %210, align 4, !alias.scope !619
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #18
  %333 = load i32, i32* %212, align 4, !noalias !622
  store i32 %333, i32* %213, align 4, !alias.scope !622
  store i32 %244, i32* %214, align 4, !alias.scope !622
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.260"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple"* dereferenceable(40) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #18
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.260"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.std::__1::tuple"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.gemmlowp::RegisterBlock.382", align 16
  %11 = alloca %"class.gemmlowp::MatrixMap.292", align 8
  %12 = alloca %"class.gemmlowp::VectorMap", align 8
  %13 = alloca %"class.gemmlowp::VectorMap.279", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.407", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.416", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.425", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.434", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.443", align 8
  %19 = alloca %"struct.gemmlowp::OutputPipelineExecutor.452", align 8
  %20 = bitcast %"class.gemmlowp::MatrixMap.292"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %20) #18
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 0
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 1
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 2
  %24 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 3
  %25 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %26 = bitcast %"class.gemmlowp::MatrixMap.292"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %26, i8 -86, i64 24, i1 false)
  %27 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %25, align 8, !noalias !625
  %28 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %29 = load i8, i8* %28, align 8, !noalias !625
  %30 = zext i8 %29 to i64
  %31 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %27, i64 0, i32 5, i64 %30
  %32 = load i64, i64* %31, align 8, !noalias !625
  %33 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %27, i64 0, i32 2
  %34 = bitcast i8** %33 to i64*
  %35 = load i64, i64* %34, align 8, !noalias !625
  %36 = add i64 %35, %32
  %37 = inttoptr i64 %36 to i32*
  %38 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %39 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %38, align 8, !noalias !625
  %40 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %39, i64 0, i32 3
  %41 = load i32, i32* %40, align 4, !noalias !625
  %42 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %39, i64 0, i32 4
  %43 = load i32, i32* %42, align 4, !noalias !625
  store i32* %37, i32** %21, align 8, !alias.scope !625
  store i32 %41, i32* %22, align 8, !alias.scope !625
  store i32 %43, i32* %23, align 4, !alias.scope !625
  store i32 %41, i32* %24, align 8, !alias.scope !625
  %44 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %44) #18
  %45 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 0
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 1
  %47 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %48 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %48, i8 -86, i64 16, i1 false)
  %49 = load i32, i32* %47, align 4
  store i32* %4, i32** %45, align 8
  store i32 %49, i32* %46, align 8
  %50 = bitcast %"class.gemmlowp::VectorMap.279"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %50) #18
  %51 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %13, i64 0, i32 0
  %52 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %13, i64 0, i32 1
  %53 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %54 = bitcast %"class.gemmlowp::VectorMap.279"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %54, i8 -86, i64 16, i1 false)
  %55 = load i32, i32* %53, align 4
  store i32* %5, i32** %51, align 8
  store i32 %55, i32* %52, align 8
  %56 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.407"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %56) #18
  %57 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %14, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %58 = bitcast i8* %57 to i64*
  store i64 -6148914691236517206, i64* %58, align 8
  %59 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %8, i64 0, i32 0, i32 0, i32 0
  %60 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %14, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %60, align 8
  %61 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %8, i64 0, i32 0, i32 1, i32 0
  %62 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %62, align 8
  %63 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %64 = load i32, i32* %63, align 4
  %65 = icmp sgt i32 %64, 0
  %66 = select i1 %65, i32 %64, i32 0
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %67, align 8
  %68 = sub nsw i32 0, %64
  %69 = icmp sgt i32 %68, 0
  %70 = select i1 %69, i32 %68, i32 0
  %71 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %8, i64 0, i32 0, i32 2, i32 0
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %73, align 8
  %74 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.416"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %74) #18
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %15, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %76 = bitcast i8* %75 to i64*
  store i64 -6148914691236517206, i64* %76, align 8
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %15, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %77, align 8
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %78, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %79, align 8
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %80, align 4
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %82 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.425"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %82) #18
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.425", %"struct.gemmlowp::OutputPipelineExecutor.425"* %16, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %84 = bitcast i8* %83 to i64*
  store i64 -6148914691236517206, i64* %84, align 8
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.425", %"struct.gemmlowp::OutputPipelineExecutor.425"* %16, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %85, align 8
  %86 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.425", %"struct.gemmlowp::OutputPipelineExecutor.425"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %86, align 8
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.425", %"struct.gemmlowp::OutputPipelineExecutor.425"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %87, align 8
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.425", %"struct.gemmlowp::OutputPipelineExecutor.425"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %88, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.425", %"struct.gemmlowp::OutputPipelineExecutor.425"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %89, align 8
  %90 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.434"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %90) #18
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %17, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %92 = bitcast i8* %91 to i64*
  store i64 -6148914691236517206, i64* %92, align 8
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %17, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %93, align 8
  %94 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %94, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %95, align 8
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %96, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %97, align 8
  %98 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.443"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %98) #18
  %99 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.443", %"struct.gemmlowp::OutputPipelineExecutor.443"* %18, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %100 = bitcast i8* %99 to i64*
  store i64 -6148914691236517206, i64* %100, align 8
  %101 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.443", %"struct.gemmlowp::OutputPipelineExecutor.443"* %18, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %101, align 8
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.443", %"struct.gemmlowp::OutputPipelineExecutor.443"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %102, align 8
  %103 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.443", %"struct.gemmlowp::OutputPipelineExecutor.443"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %103, align 8
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.443", %"struct.gemmlowp::OutputPipelineExecutor.443"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %104, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.443", %"struct.gemmlowp::OutputPipelineExecutor.443"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %105, align 8
  %106 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.452"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %106) #18
  %107 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.452", %"struct.gemmlowp::OutputPipelineExecutor.452"* %19, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %108 = bitcast i8* %107 to i64*
  store i64 -6148914691236517206, i64* %108, align 8
  %109 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.452", %"struct.gemmlowp::OutputPipelineExecutor.452"* %19, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %109, align 8
  %110 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.452", %"struct.gemmlowp::OutputPipelineExecutor.452"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %110, align 8
  %111 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.452", %"struct.gemmlowp::OutputPipelineExecutor.452"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %111, align 8
  %112 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.452", %"struct.gemmlowp::OutputPipelineExecutor.452"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %112, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.452", %"struct.gemmlowp::OutputPipelineExecutor.452"* %19, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %113, align 8
  %114 = icmp slt i32 %55, 4
  br i1 %114, label %123, label %115

115:                                              ; preds = %9
  %116 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %117 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %118 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %119 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %7, i64 0, i32 0
  %120 = load i32, i32* %47, align 4
  br label %138

121:                                              ; preds = %309
  %122 = trunc i64 %311 to i32
  br label %123

123:                                              ; preds = %121, %9
  %124 = phi i32 [ %55, %9 ], [ %312, %121 ]
  %125 = phi i32 [ 0, %9 ], [ %122, %121 ]
  %126 = icmp slt i32 %125, %124
  br i1 %126, label %127, label %438

127:                                              ; preds = %123
  %128 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %129 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %130 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %10 to i8*
  %131 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %132 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %7, i64 0, i32 0
  %133 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %10, i64 0, i32 0, i32 0, i64 4
  %134 = zext i32 %125 to i64
  %135 = load i32, i32* %47, align 4
  %136 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %10 to <4 x i32>*
  %137 = bitcast i32* %133 to <4 x i32>*
  br label %316

138:                                              ; preds = %115, %309
  %139 = phi i32 [ %120, %115 ], [ %310, %309 ]
  %140 = phi i64 [ 0, %115 ], [ %311, %309 ]
  %141 = load i32, i32* %116, align 4
  %142 = trunc i64 %140 to i32
  %143 = add nsw i32 %141, %142
  %144 = load i32*, i32** %21, align 8
  %145 = load i32, i32* %24, align 8
  %146 = mul nsw i32 %145, %142
  %147 = sext i32 %146 to i64
  %148 = load i32*, i32** %45, align 8
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #18
  %150 = getelementptr inbounds i32, i32* %148, i64 4
  %151 = bitcast i32* %150 to i8*
  call void @llvm.prefetch(i8* %151, i32 0, i32 3, i32 1) #18
  %152 = getelementptr inbounds i32, i32* %144, i64 %147
  %153 = sext i32 %145 to i64
  %154 = bitcast i32* %152 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #18
  %155 = getelementptr inbounds i32, i32* %152, i64 4
  %156 = bitcast i32* %155 to i8*
  call void @llvm.prefetch(i8* %156, i32 0, i32 3, i32 1) #18
  %157 = getelementptr inbounds i32, i32* %152, i64 %153
  %158 = bitcast i32* %157 to i8*
  call void @llvm.prefetch(i8* %158, i32 0, i32 3, i32 1) #18
  %159 = getelementptr inbounds i32, i32* %157, i64 4
  %160 = bitcast i32* %159 to i8*
  call void @llvm.prefetch(i8* %160, i32 0, i32 3, i32 1) #18
  %161 = shl nsw i64 %153, 1
  %162 = getelementptr inbounds i32, i32* %152, i64 %161
  %163 = bitcast i32* %162 to i8*
  call void @llvm.prefetch(i8* %163, i32 0, i32 3, i32 1) #18
  %164 = getelementptr inbounds i32, i32* %162, i64 4
  %165 = bitcast i32* %164 to i8*
  call void @llvm.prefetch(i8* %165, i32 0, i32 3, i32 1) #18
  %166 = mul nsw i64 %153, 3
  %167 = getelementptr inbounds i32, i32* %152, i64 %166
  %168 = bitcast i32* %167 to i8*
  call void @llvm.prefetch(i8* %168, i32 0, i32 3, i32 1) #18
  %169 = getelementptr inbounds i32, i32* %167, i64 4
  %170 = bitcast i32* %169 to i8*
  call void @llvm.prefetch(i8* %170, i32 0, i32 3, i32 1) #18
  %171 = icmp slt i32 %139, 8
  br i1 %171, label %174, label %179

172:                                              ; preds = %179
  %173 = trunc i64 %187 to i32
  br label %174

174:                                              ; preds = %172, %138
  %175 = phi i32 [ %139, %138 ], [ %214, %172 ]
  %176 = phi i32 [ 0, %138 ], [ %173, %172 ]
  %177 = add nsw i32 %175, -4
  %178 = icmp sgt i32 %176, %177
  br i1 %178, label %222, label %231

179:                                              ; preds = %138, %218
  %180 = phi i32* [ %221, %218 ], [ %148, %138 ]
  %181 = phi i32 [ %220, %218 ], [ %145, %138 ]
  %182 = phi i32* [ %219, %218 ], [ %144, %138 ]
  %183 = phi i64 [ %187, %218 ], [ 0, %138 ]
  %184 = load i32, i32* %117, align 4
  %185 = trunc i64 %183 to i32
  %186 = add nsw i32 %184, %185
  %187 = add nuw i64 %183, 8
  %188 = mul nsw i32 %181, %142
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i32, i32* %180, i64 %187
  %191 = bitcast i32* %190 to i8*
  call void @llvm.prefetch(i8* %191, i32 0, i32 3, i32 1) #18
  %192 = getelementptr inbounds i32, i32* %190, i64 4
  %193 = bitcast i32* %192 to i8*
  call void @llvm.prefetch(i8* %193, i32 0, i32 3, i32 1) #18
  %194 = getelementptr inbounds i32, i32* %182, i64 %187
  %195 = getelementptr inbounds i32, i32* %194, i64 %189
  %196 = sext i32 %181 to i64
  %197 = bitcast i32* %195 to i8*
  call void @llvm.prefetch(i8* %197, i32 0, i32 3, i32 1) #18
  %198 = getelementptr inbounds i32, i32* %195, i64 4
  %199 = bitcast i32* %198 to i8*
  call void @llvm.prefetch(i8* %199, i32 0, i32 3, i32 1) #18
  %200 = getelementptr inbounds i32, i32* %195, i64 %196
  %201 = bitcast i32* %200 to i8*
  call void @llvm.prefetch(i8* %201, i32 0, i32 3, i32 1) #18
  %202 = getelementptr inbounds i32, i32* %200, i64 4
  %203 = bitcast i32* %202 to i8*
  call void @llvm.prefetch(i8* %203, i32 0, i32 3, i32 1) #18
  %204 = shl nsw i64 %196, 1
  %205 = getelementptr inbounds i32, i32* %195, i64 %204
  %206 = bitcast i32* %205 to i8*
  call void @llvm.prefetch(i8* %206, i32 0, i32 3, i32 1) #18
  %207 = getelementptr inbounds i32, i32* %205, i64 4
  %208 = bitcast i32* %207 to i8*
  call void @llvm.prefetch(i8* %208, i32 0, i32 3, i32 1) #18
  %209 = mul nsw i64 %196, 3
  %210 = getelementptr inbounds i32, i32* %195, i64 %209
  %211 = bitcast i32* %210 to i8*
  call void @llvm.prefetch(i8* %211, i32 0, i32 3, i32 1) #18
  %212 = getelementptr inbounds i32, i32* %210, i64 4
  %213 = bitcast i32* %212 to i8*
  call void @llvm.prefetch(i8* %213, i32 0, i32 3, i32 1) #18
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.452"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %185, i32 %142, i32 %186, i32 %143, i32 %186, i32 %143)
  %214 = load i32, i32* %47, align 4
  %215 = add nsw i32 %214, -8
  %216 = trunc i64 %187 to i32
  %217 = icmp slt i32 %215, %216
  br i1 %217, label %172, label %218

218:                                              ; preds = %179
  %219 = load i32*, i32** %21, align 8
  %220 = load i32, i32* %24, align 8
  %221 = load i32*, i32** %45, align 8
  br label %179

222:                                              ; preds = %231, %174
  %223 = phi i32 [ %175, %174 ], [ %236, %231 ]
  %224 = phi i32 [ %176, %174 ], [ %235, %231 ]
  %225 = icmp slt i32 %224, %223
  br i1 %225, label %226, label %309

226:                                              ; preds = %222
  %227 = or i64 %140, 1
  %228 = or i64 %140, 2
  %229 = or i64 %140, 3
  %230 = zext i32 %224 to i64
  br label %239

231:                                              ; preds = %174, %231
  %232 = phi i32 [ %235, %231 ], [ %176, %174 ]
  %233 = load i32, i32* %117, align 4
  %234 = add nsw i32 %233, %232
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.443"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %232, i32 %142, i32 %234, i32 %143, i32 %234, i32 %143)
  %235 = add nuw nsw i32 %232, 4
  %236 = load i32, i32* %47, align 4
  %237 = add nsw i32 %236, -4
  %238 = icmp sgt i32 %235, %237
  br i1 %238, label %222, label %231

239:                                              ; preds = %226, %239
  %240 = phi i64 [ %230, %226 ], [ %305, %239 ]
  %241 = load i32, i32* %117, align 4
  %242 = trunc i64 %240 to i32
  %243 = add nsw i32 %241, %242
  %244 = load i32*, i32** %21, align 8
  %245 = getelementptr inbounds i32, i32* %244, i64 %240
  %246 = load i32, i32* %24, align 8
  %247 = mul nsw i32 %246, %142
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds i32, i32* %245, i64 %248
  %250 = load i32, i32* %249, align 4
  %251 = sext i32 %246 to i64
  %252 = mul nsw i64 %227, %251
  %253 = getelementptr inbounds i32, i32* %245, i64 %252
  %254 = load i32, i32* %253, align 4
  %255 = mul nsw i64 %228, %251
  %256 = getelementptr inbounds i32, i32* %245, i64 %255
  %257 = load i32, i32* %256, align 4
  %258 = mul nsw i64 %229, %251
  %259 = getelementptr inbounds i32, i32* %245, i64 %258
  %260 = load i32, i32* %259, align 4
  %261 = load i32*, i32** %45, align 8
  %262 = getelementptr inbounds i32, i32* %261, i64 %240
  %263 = load i32, i32* %262, align 4
  %264 = load i32*, i32** %51, align 8
  %265 = getelementptr i32, i32* %264, i64 %140
  %266 = bitcast i32* %265 to i64*
  %267 = load i64, i64* %266, align 4
  %268 = getelementptr inbounds i32, i32* %265, i64 2
  %269 = bitcast i32* %268 to i64*
  %270 = load i64, i64* %269, align 4
  %271 = trunc i64 %267 to i32
  %272 = lshr i64 %267, 32
  %273 = trunc i64 %272 to i32
  %274 = load i32, i32* %118, align 4
  %275 = load i32, i32* %119, align 4
  %276 = mul nsw i32 %275, %263
  %277 = add nsw i32 %276, %250
  %278 = add nsw i32 %276, %254
  %279 = add nsw i32 %276, %257
  %280 = add nsw i32 %276, %260
  %281 = mul nsw i32 %275, %3
  %282 = add nsw i32 %281, %271
  %283 = add nsw i32 %281, %273
  %284 = trunc i64 %270 to i32
  %285 = add nsw i32 %281, %284
  %286 = lshr i64 %270, 32
  %287 = trunc i64 %286 to i32
  %288 = add nsw i32 %281, %287
  %289 = mul nsw i32 %282, %274
  %290 = add nsw i32 %277, %289
  %291 = mul nsw i32 %283, %274
  %292 = add nsw i32 %278, %291
  %293 = mul nsw i32 %285, %274
  %294 = add nsw i32 %279, %293
  %295 = zext i32 %294 to i64
  %296 = mul nsw i32 %288, %274
  %297 = add nsw i32 %280, %296
  %298 = zext i32 %297 to i64
  %299 = shl nuw i64 %298, 32
  %300 = or i64 %299, %295
  %301 = zext i32 %292 to i64
  %302 = shl nuw i64 %301, 32
  %303 = zext i32 %290 to i64
  %304 = or i64 %302, %303
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.434"* nonnull %17, i64 %304, i64 %300, %"class.gemmlowp::MatrixMap.260"* %0, i32 %243, i32 %143, i32 %243, i32 %143) #18
  %305 = add nuw nsw i64 %240, 1
  %306 = load i32, i32* %47, align 4
  %307 = trunc i64 %305 to i32
  %308 = icmp sgt i32 %306, %307
  br i1 %308, label %239, label %309

309:                                              ; preds = %239, %222
  %310 = phi i32 [ %223, %222 ], [ %306, %239 ]
  %311 = add nuw i64 %140, 4
  %312 = load i32, i32* %53, align 4
  %313 = add nsw i32 %312, -4
  %314 = trunc i64 %311 to i32
  %315 = icmp slt i32 %313, %314
  br i1 %315, label %121, label %138

316:                                              ; preds = %127, %432
  %317 = phi i32 [ %135, %127 ], [ %433, %432 ]
  %318 = phi i64 [ %134, %127 ], [ %434, %432 ]
  %319 = load i32, i32* %128, align 4
  %320 = trunc i64 %318 to i32
  %321 = add nsw i32 %319, %320
  %322 = load i32*, i32** %21, align 8
  %323 = load i32, i32* %24, align 8
  %324 = mul nsw i32 %323, %320
  %325 = sext i32 %324 to i64
  %326 = load i32*, i32** %45, align 8
  %327 = bitcast i32* %326 to i8*
  call void @llvm.prefetch(i8* %327, i32 0, i32 3, i32 1) #18
  %328 = getelementptr inbounds i32, i32* %326, i64 4
  %329 = bitcast i32* %328 to i8*
  call void @llvm.prefetch(i8* %329, i32 0, i32 3, i32 1) #18
  %330 = getelementptr inbounds i32, i32* %322, i64 %325
  %331 = bitcast i32* %330 to i8*
  call void @llvm.prefetch(i8* %331, i32 0, i32 3, i32 1) #18
  %332 = getelementptr inbounds i32, i32* %330, i64 4
  %333 = bitcast i32* %332 to i8*
  call void @llvm.prefetch(i8* %333, i32 0, i32 3, i32 1) #18
  %334 = icmp slt i32 %317, 8
  br i1 %334, label %337, label %342

335:                                              ; preds = %342
  %336 = trunc i64 %350 to i32
  br label %337

337:                                              ; preds = %335, %316
  %338 = phi i32 [ %317, %316 ], [ %405, %335 ]
  %339 = phi i32 [ 0, %316 ], [ %336, %335 ]
  %340 = add nsw i32 %338, -4
  %341 = icmp sgt i32 %339, %340
  br i1 %341, label %413, label %417

342:                                              ; preds = %316, %409
  %343 = phi i32* [ %412, %409 ], [ %326, %316 ]
  %344 = phi i32 [ %411, %409 ], [ %323, %316 ]
  %345 = phi i32* [ %410, %409 ], [ %322, %316 ]
  %346 = phi i64 [ %350, %409 ], [ 0, %316 ]
  %347 = load i32, i32* %129, align 4
  %348 = trunc i64 %346 to i32
  %349 = add nsw i32 %347, %348
  %350 = add nuw i64 %346, 8
  %351 = mul nsw i32 %344, %320
  %352 = sext i32 %351 to i64
  %353 = getelementptr inbounds i32, i32* %343, i64 %350
  %354 = bitcast i32* %353 to i8*
  call void @llvm.prefetch(i8* %354, i32 0, i32 3, i32 1) #18
  %355 = getelementptr inbounds i32, i32* %353, i64 4
  %356 = bitcast i32* %355 to i8*
  call void @llvm.prefetch(i8* %356, i32 0, i32 3, i32 1) #18
  %357 = getelementptr inbounds i32, i32* %345, i64 %350
  %358 = getelementptr inbounds i32, i32* %357, i64 %352
  %359 = bitcast i32* %358 to i8*
  call void @llvm.prefetch(i8* %359, i32 0, i32 3, i32 1) #18
  %360 = getelementptr inbounds i32, i32* %358, i64 4
  %361 = bitcast i32* %360 to i8*
  call void @llvm.prefetch(i8* %361, i32 0, i32 3, i32 1) #18
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %130)
  %362 = getelementptr inbounds i32, i32* %345, i64 %346
  %363 = getelementptr inbounds i32, i32* %362, i64 %352
  %364 = getelementptr inbounds i32, i32* %363, i64 1
  %365 = getelementptr inbounds i32, i32* %364, i64 1
  %366 = getelementptr inbounds i32, i32* %365, i64 1
  %367 = getelementptr inbounds i32, i32* %366, i64 1
  %368 = bitcast i32* %363 to <4 x i32>*
  %369 = load <4 x i32>, <4 x i32>* %368, align 4, !noalias !628
  %370 = getelementptr inbounds i32, i32* %367, i64 1
  %371 = load i32, i32* %367, align 4, !noalias !628
  %372 = getelementptr inbounds i32, i32* %370, i64 1
  %373 = load i32, i32* %370, align 4, !noalias !628
  %374 = getelementptr inbounds i32, i32* %372, i64 1
  %375 = load i32, i32* %372, align 4, !noalias !628
  %376 = load i32, i32* %374, align 4, !noalias !628
  %377 = getelementptr i32, i32* %343, i64 %346
  %378 = bitcast i32* %377 to <4 x i32>*
  %379 = load <4 x i32>, <4 x i32>* %378, align 4
  %380 = getelementptr inbounds i32, i32* %377, i64 4
  %381 = bitcast i32* %380 to <4 x i32>*
  %382 = load <4 x i32>, <4 x i32>* %381, align 4
  %383 = load i32*, i32** %51, align 8
  %384 = getelementptr inbounds i32, i32* %383, i64 %318
  %385 = load i32, i32* %384, align 4
  %386 = load i32, i32* %131, align 4
  %387 = load i32, i32* %132, align 4
  %388 = insertelement <4 x i32> undef, i32 %387, i32 0
  %389 = shufflevector <4 x i32> %388, <4 x i32> undef, <4 x i32> zeroinitializer
  %390 = mul nsw <4 x i32> %389, %379
  %391 = add nsw <4 x i32> %390, %369
  %392 = mul nsw <4 x i32> %389, %382
  %393 = insertelement <4 x i32> undef, i32 %371, i32 0
  %394 = insertelement <4 x i32> %393, i32 %373, i32 1
  %395 = insertelement <4 x i32> %394, i32 %375, i32 2
  %396 = insertelement <4 x i32> %395, i32 %376, i32 3
  %397 = add nsw <4 x i32> %392, %396
  %398 = mul nsw i32 %387, %3
  %399 = add nsw i32 %398, %385
  %400 = mul nsw i32 %399, %386
  %401 = insertelement <4 x i32> undef, i32 %400, i32 0
  %402 = shufflevector <4 x i32> %401, <4 x i32> undef, <4 x i32> zeroinitializer
  %403 = add nsw <4 x i32> %391, %402
  %404 = add nsw <4 x i32> %397, %402
  store <4 x i32> %403, <4 x i32>* %136, align 16
  store <4 x i32> %404, <4 x i32>* %137, align 16
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.425"* nonnull %16, %"struct.gemmlowp::RegisterBlock.382"* nonnull byval(%"struct.gemmlowp::RegisterBlock.382") align 8 %10, %"class.gemmlowp::MatrixMap.260"* %0, i32 %349, i32 %321, i32 %349, i32 %321) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %130)
  %405 = load i32, i32* %47, align 4
  %406 = add nsw i32 %405, -8
  %407 = trunc i64 %350 to i32
  %408 = icmp slt i32 %406, %407
  br i1 %408, label %335, label %409

409:                                              ; preds = %342
  %410 = load i32*, i32** %21, align 8
  %411 = load i32, i32* %24, align 8
  %412 = load i32*, i32** %45, align 8
  br label %342

413:                                              ; preds = %417, %337
  %414 = phi i32 [ %338, %337 ], [ %422, %417 ]
  %415 = phi i32 [ %339, %337 ], [ %421, %417 ]
  %416 = icmp slt i32 %415, %414
  br i1 %416, label %425, label %432

417:                                              ; preds = %337, %417
  %418 = phi i32 [ %421, %417 ], [ %339, %337 ]
  %419 = load i32, i32* %129, align 4
  %420 = add nsw i32 %419, %418
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.416"* nonnull dereferenceable(40) %15, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %418, i32 %320, i32 %420, i32 %321, i32 %420, i32 %321)
  %421 = add nuw nsw i32 %418, 4
  %422 = load i32, i32* %47, align 4
  %423 = add nsw i32 %422, -4
  %424 = icmp sgt i32 %421, %423
  br i1 %424, label %413, label %417

425:                                              ; preds = %413, %425
  %426 = phi i32 [ %429, %425 ], [ %415, %413 ]
  %427 = load i32, i32* %129, align 4
  %428 = add nsw i32 %427, %426
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.407"* nonnull dereferenceable(40) %14, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %426, i32 %320, i32 %428, i32 %321, i32 %428, i32 %321)
  %429 = add nuw nsw i32 %426, 1
  %430 = load i32, i32* %47, align 4
  %431 = icmp slt i32 %429, %430
  br i1 %431, label %425, label %432

432:                                              ; preds = %425, %413
  %433 = phi i32 [ %414, %413 ], [ %430, %425 ]
  %434 = add nuw nsw i64 %318, 1
  %435 = load i32, i32* %53, align 4
  %436 = trunc i64 %434 to i32
  %437 = icmp sgt i32 %435, %436
  br i1 %437, label %316, label %438

438:                                              ; preds = %432, %123
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %106) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %98) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %90) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %82) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %74) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %56) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %50) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %44) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %20) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.452"* dereferenceable(40), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #18
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !633
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !633
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !633
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !633
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !633
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !633
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !633
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !633
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !633
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !633
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !633
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !633
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !633
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !633
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !633
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !633
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !633
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !633
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !633
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !633
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !633
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !633
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !633
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !633
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !633
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !633
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !633
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !633
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !633
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !633
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !633
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !633
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !633
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !633
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !636
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.452"* %1, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %15, %"class.gemmlowp::MatrixMap.260"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.443"* dereferenceable(40), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.393", align 2
  %16 = alloca %"struct.gemmlowp::RegisterBlock.390", align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %20 = load i32*, i32** %17, align 8, !noalias !641
  %21 = getelementptr inbounds i32, i32* %20, i64 %18
  %22 = load i32, i32* %19, align 8, !noalias !641
  %23 = mul nsw i32 %22, %9
  %24 = sext i32 %23 to i64
  %25 = getelementptr inbounds i32, i32* %21, i64 %24
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = load i32, i32* %25, align 4, !noalias !641
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4, !noalias !641
  %30 = getelementptr inbounds i32, i32* %28, i64 1
  %31 = load i32, i32* %28, align 4, !noalias !641
  %32 = load i32, i32* %30, align 4, !noalias !641
  %33 = add nsw i32 %9, 1
  %34 = mul nsw i32 %22, %33
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds i32, i32* %21, i64 %35
  %37 = getelementptr inbounds i32, i32* %36, i64 1
  %38 = load i32, i32* %36, align 4, !noalias !641
  %39 = getelementptr inbounds i32, i32* %37, i64 1
  %40 = load i32, i32* %37, align 4, !noalias !641
  %41 = getelementptr inbounds i32, i32* %39, i64 1
  %42 = load i32, i32* %39, align 4, !noalias !641
  %43 = load i32, i32* %41, align 4, !noalias !641
  %44 = add nsw i32 %9, 2
  %45 = mul nsw i32 %22, %44
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i32, i32* %21, i64 %46
  %48 = getelementptr inbounds i32, i32* %47, i64 1
  %49 = load i32, i32* %47, align 4, !noalias !641
  %50 = getelementptr inbounds i32, i32* %48, i64 1
  %51 = load i32, i32* %48, align 4, !noalias !641
  %52 = getelementptr inbounds i32, i32* %50, i64 1
  %53 = load i32, i32* %50, align 4, !noalias !641
  %54 = load i32, i32* %52, align 4, !noalias !641
  %55 = add nsw i32 %9, 3
  %56 = mul nsw i32 %22, %55
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i32, i32* %21, i64 %57
  %59 = getelementptr inbounds i32, i32* %58, i64 1
  %60 = load i32, i32* %58, align 4, !noalias !641
  %61 = getelementptr inbounds i32, i32* %59, i64 1
  %62 = load i32, i32* %59, align 4, !noalias !641
  %63 = getelementptr inbounds i32, i32* %61, i64 1
  %64 = load i32, i32* %61, align 4, !noalias !641
  %65 = load i32, i32* %63, align 4, !noalias !641
  %66 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %67 = load i32*, i32** %66, align 8
  %68 = getelementptr i32, i32* %67, i64 %18
  %69 = bitcast i32* %68 to i64*
  %70 = load i64, i64* %69, align 4
  %71 = getelementptr inbounds i32, i32* %68, i64 2
  %72 = bitcast i32* %71 to i64*
  %73 = load i64, i64* %72, align 4
  %74 = trunc i64 %70 to i32
  %75 = lshr i64 %70, 32
  %76 = trunc i64 %75 to i32
  %77 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %78 = load i32*, i32** %77, align 8
  %79 = sext i32 %9 to i64
  %80 = getelementptr i32, i32* %78, i64 %79
  %81 = bitcast i32* %80 to i64*
  %82 = load i64, i64* %81, align 4
  %83 = getelementptr inbounds i32, i32* %80, i64 2
  %84 = bitcast i32* %83 to i64*
  %85 = load i64, i64* %84, align 4
  %86 = trunc i64 %82 to i32
  %87 = lshr i64 %82, 32
  %88 = trunc i64 %87 to i32
  %89 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %90 = load i32, i32* %89, align 4
  %91 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %92 = load i32, i32* %91, align 4
  %93 = mul nsw i32 %92, %74
  %94 = add nsw i32 %93, %27
  %95 = mul nsw i32 %92, %76
  %96 = add nsw i32 %95, %29
  %97 = trunc i64 %73 to i32
  %98 = mul nsw i32 %92, %97
  %99 = add nsw i32 %98, %31
  %100 = lshr i64 %73, 32
  %101 = trunc i64 %100 to i32
  %102 = mul nsw i32 %92, %101
  %103 = add nsw i32 %102, %32
  %104 = add nsw i32 %93, %38
  %105 = add nsw i32 %95, %40
  %106 = add nsw i32 %98, %42
  %107 = add nsw i32 %102, %43
  %108 = add nsw i32 %93, %49
  %109 = add nsw i32 %95, %51
  %110 = add nsw i32 %98, %53
  %111 = add nsw i32 %102, %54
  %112 = add nsw i32 %93, %60
  %113 = add nsw i32 %95, %62
  %114 = add nsw i32 %98, %64
  %115 = add nsw i32 %102, %65
  %116 = mul nsw i32 %92, %7
  %117 = add nsw i32 %116, %86
  %118 = add nsw i32 %116, %88
  %119 = trunc i64 %85 to i32
  %120 = add nsw i32 %116, %119
  %121 = lshr i64 %85, 32
  %122 = trunc i64 %121 to i32
  %123 = add nsw i32 %116, %122
  %124 = mul nsw i32 %117, %90
  %125 = add nsw i32 %94, %124
  %126 = add nsw i32 %96, %124
  %127 = add nsw i32 %99, %124
  %128 = add nsw i32 %103, %124
  %129 = mul nsw i32 %118, %90
  %130 = add nsw i32 %104, %129
  %131 = add nsw i32 %105, %129
  %132 = add nsw i32 %106, %129
  %133 = add nsw i32 %107, %129
  %134 = mul nsw i32 %120, %90
  %135 = add nsw i32 %108, %134
  %136 = add nsw i32 %109, %134
  %137 = add nsw i32 %110, %134
  %138 = add nsw i32 %111, %134
  %139 = mul nsw i32 %123, %90
  %140 = add nsw i32 %112, %139
  %141 = add nsw i32 %113, %139
  %142 = add nsw i32 %114, %139
  %143 = add nsw i32 %115, %139
  %144 = bitcast %"struct.gemmlowp::RegisterBlock.390"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %144)
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 0
  store i32 %125, i32* %145, align 8
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 1
  store i32 %126, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 2
  store i32 %127, i32* %147, align 8
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 3
  store i32 %128, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 4
  store i32 %130, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 5
  store i32 %131, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 6
  store i32 %132, i32* %151, align 8
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 7
  store i32 %133, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 8
  store i32 %135, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 9
  store i32 %136, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 10
  store i32 %137, i32* %155, align 8
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 11
  store i32 %138, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 12
  store i32 %140, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 13
  store i32 %141, i32* %158, align 4
  %159 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 14
  store i32 %142, i32* %159, align 8
  %160 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %16, i64 0, i32 0, i32 0, i64 15
  store i32 %143, i32* %160, align 4
  %161 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %161) #18
  %162 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.443", %"struct.gemmlowp::OutputPipelineExecutor.443"* %1, i64 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %161, i8 -86, i64 32, i1 false) #18
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.393"* nonnull sret %15, %"struct.gemmlowp::OutputPipelineEvalImpl.444"* %162, %"struct.gemmlowp::RegisterBlock.390"* nonnull byval(%"struct.gemmlowp::RegisterBlock.390") align 8 %16, i32 %10, i32 %11) #18
  %163 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 0
  %164 = load i16, i16* %163, align 2
  %165 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 1
  %166 = load i16, i16* %165, align 2
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 2
  %168 = load i16, i16* %167, align 2
  %169 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 3
  %170 = load i16, i16* %169, align 2
  %171 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 4
  %172 = load i16, i16* %171, align 2
  %173 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 5
  %174 = load i16, i16* %173, align 2
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 6
  %176 = load i16, i16* %175, align 2
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 7
  %178 = load i16, i16* %177, align 2
  %179 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 8
  %180 = load i16, i16* %179, align 2
  %181 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 9
  %182 = load i16, i16* %181, align 2
  %183 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 10
  %184 = load i16, i16* %183, align 2
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 11
  %186 = load i16, i16* %185, align 2
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 12
  %188 = load i16, i16* %187, align 2
  %189 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 13
  %190 = load i16, i16* %189, align 2
  %191 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 14
  %192 = load i16, i16* %191, align 2
  %193 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %15, i64 0, i32 0, i32 0, i64 15
  %194 = load i16, i16* %193, align 2
  %195 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %196 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %197 = sext i32 %13 to i64
  %198 = sext i32 %12 to i64
  %199 = load i16*, i16** %195, align 8
  %200 = getelementptr inbounds i16, i16* %199, i64 %198
  %201 = load i32, i32* %196, align 8
  %202 = sext i32 %201 to i64
  %203 = mul nsw i64 %202, %197
  %204 = getelementptr inbounds i16, i16* %200, i64 %203
  store i16 %164, i16* %204, align 2
  %205 = add nsw i64 %197, 1
  %206 = load i16*, i16** %195, align 8
  %207 = getelementptr inbounds i16, i16* %206, i64 %198
  %208 = load i32, i32* %196, align 8
  %209 = sext i32 %208 to i64
  %210 = mul nsw i64 %205, %209
  %211 = getelementptr inbounds i16, i16* %207, i64 %210
  store i16 %172, i16* %211, align 2
  %212 = add nsw i64 %197, 2
  %213 = load i16*, i16** %195, align 8
  %214 = getelementptr inbounds i16, i16* %213, i64 %198
  %215 = load i32, i32* %196, align 8
  %216 = sext i32 %215 to i64
  %217 = mul nsw i64 %212, %216
  %218 = getelementptr inbounds i16, i16* %214, i64 %217
  store i16 %180, i16* %218, align 2
  %219 = add nsw i64 %197, 3
  %220 = load i16*, i16** %195, align 8
  %221 = getelementptr inbounds i16, i16* %220, i64 %198
  %222 = load i32, i32* %196, align 8
  %223 = sext i32 %222 to i64
  %224 = mul nsw i64 %219, %223
  %225 = getelementptr inbounds i16, i16* %221, i64 %224
  store i16 %188, i16* %225, align 2
  %226 = add nsw i64 %198, 1
  %227 = load i16*, i16** %195, align 8
  %228 = getelementptr inbounds i16, i16* %227, i64 %226
  %229 = load i32, i32* %196, align 8
  %230 = sext i32 %229 to i64
  %231 = mul nsw i64 %230, %197
  %232 = getelementptr inbounds i16, i16* %228, i64 %231
  store i16 %166, i16* %232, align 2
  %233 = load i16*, i16** %195, align 8
  %234 = getelementptr inbounds i16, i16* %233, i64 %226
  %235 = load i32, i32* %196, align 8
  %236 = sext i32 %235 to i64
  %237 = mul nsw i64 %205, %236
  %238 = getelementptr inbounds i16, i16* %234, i64 %237
  store i16 %174, i16* %238, align 2
  %239 = load i16*, i16** %195, align 8
  %240 = getelementptr inbounds i16, i16* %239, i64 %226
  %241 = load i32, i32* %196, align 8
  %242 = sext i32 %241 to i64
  %243 = mul nsw i64 %212, %242
  %244 = getelementptr inbounds i16, i16* %240, i64 %243
  store i16 %182, i16* %244, align 2
  %245 = load i16*, i16** %195, align 8
  %246 = getelementptr inbounds i16, i16* %245, i64 %226
  %247 = load i32, i32* %196, align 8
  %248 = sext i32 %247 to i64
  %249 = mul nsw i64 %219, %248
  %250 = getelementptr inbounds i16, i16* %246, i64 %249
  store i16 %190, i16* %250, align 2
  %251 = add nsw i64 %198, 2
  %252 = load i16*, i16** %195, align 8
  %253 = getelementptr inbounds i16, i16* %252, i64 %251
  %254 = load i32, i32* %196, align 8
  %255 = sext i32 %254 to i64
  %256 = mul nsw i64 %255, %197
  %257 = getelementptr inbounds i16, i16* %253, i64 %256
  store i16 %168, i16* %257, align 2
  %258 = load i16*, i16** %195, align 8
  %259 = getelementptr inbounds i16, i16* %258, i64 %251
  %260 = load i32, i32* %196, align 8
  %261 = sext i32 %260 to i64
  %262 = mul nsw i64 %205, %261
  %263 = getelementptr inbounds i16, i16* %259, i64 %262
  store i16 %176, i16* %263, align 2
  %264 = load i16*, i16** %195, align 8
  %265 = getelementptr inbounds i16, i16* %264, i64 %251
  %266 = load i32, i32* %196, align 8
  %267 = sext i32 %266 to i64
  %268 = mul nsw i64 %212, %267
  %269 = getelementptr inbounds i16, i16* %265, i64 %268
  store i16 %184, i16* %269, align 2
  %270 = load i16*, i16** %195, align 8
  %271 = getelementptr inbounds i16, i16* %270, i64 %251
  %272 = load i32, i32* %196, align 8
  %273 = sext i32 %272 to i64
  %274 = mul nsw i64 %219, %273
  %275 = getelementptr inbounds i16, i16* %271, i64 %274
  store i16 %192, i16* %275, align 2
  %276 = add nsw i64 %198, 3
  %277 = load i16*, i16** %195, align 8
  %278 = getelementptr inbounds i16, i16* %277, i64 %276
  %279 = load i32, i32* %196, align 8
  %280 = sext i32 %279 to i64
  %281 = mul nsw i64 %280, %197
  %282 = getelementptr inbounds i16, i16* %278, i64 %281
  store i16 %170, i16* %282, align 2
  %283 = load i16*, i16** %195, align 8
  %284 = getelementptr inbounds i16, i16* %283, i64 %276
  %285 = load i32, i32* %196, align 8
  %286 = sext i32 %285 to i64
  %287 = mul nsw i64 %205, %286
  %288 = getelementptr inbounds i16, i16* %284, i64 %287
  store i16 %178, i16* %288, align 2
  %289 = load i16*, i16** %195, align 8
  %290 = getelementptr inbounds i16, i16* %289, i64 %276
  %291 = load i32, i32* %196, align 8
  %292 = sext i32 %291 to i64
  %293 = mul nsw i64 %212, %292
  %294 = getelementptr inbounds i16, i16* %290, i64 %293
  store i16 %186, i16* %294, align 2
  %295 = load i16*, i16** %195, align 8
  %296 = getelementptr inbounds i16, i16* %295, i64 %276
  %297 = load i32, i32* %196, align 8
  %298 = sext i32 %297 to i64
  %299 = mul nsw i64 %219, %298
  %300 = getelementptr inbounds i16, i16* %296, i64 %299
  store i16 %194, i16* %300, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %161) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %144)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.416"* dereferenceable(40), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = getelementptr inbounds i32, i32* %23, i64 1
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds i32, i32* %24, i64 1
  %27 = load i32, i32* %24, align 4
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = getelementptr i32, i32* %32, i64 %16
  %34 = bitcast i32* %33 to i64*
  %35 = load i64, i64* %34, align 4
  %36 = getelementptr inbounds i32, i32* %33, i64 2
  %37 = bitcast i32* %36 to i64*
  %38 = load i64, i64* %37, align 4
  %39 = trunc i64 %35 to i32
  %40 = lshr i64 %35, 32
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %9 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = load i32, i32* %45, align 4
  %47 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %50 = load i32, i32* %49, align 4
  %51 = mul nsw i32 %50, %39
  %52 = add nsw i32 %51, %25
  %53 = mul nsw i32 %50, %41
  %54 = add nsw i32 %53, %27
  %55 = trunc i64 %38 to i32
  %56 = mul nsw i32 %50, %55
  %57 = add nsw i32 %56, %29
  %58 = lshr i64 %38, 32
  %59 = trunc i64 %58 to i32
  %60 = mul nsw i32 %50, %59
  %61 = add nsw i32 %60, %30
  %62 = mul nsw i32 %50, %7
  %63 = add nsw i32 %62, %46
  %64 = mul nsw i32 %63, %48
  %65 = add nsw i32 %52, %64
  %66 = add nsw i32 %54, %64
  %67 = add nsw i32 %57, %64
  %68 = zext i32 %67 to i64
  %69 = add nsw i32 %61, %64
  %70 = zext i32 %69 to i64
  %71 = shl nuw i64 %70, 32
  %72 = or i64 %71, %68
  %73 = zext i32 %66 to i64
  %74 = shl nuw i64 %73, 32
  %75 = zext i32 %65 to i64
  %76 = or i64 %74, %75
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %1, i64 0, i32 0, i32 0, i32 0
  %78 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %77, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %78, i64 0, i32 0, i32 0
  %80 = load i32*, i32** %79, align 8
  %81 = sext i32 %10 to i64
  %82 = getelementptr i32, i32* %80, i64 %81
  %83 = bitcast i32* %82 to i64*
  %84 = load i64, i64* %83, align 4
  %85 = getelementptr inbounds i32, i32* %82, i64 2
  %86 = bitcast i32* %85 to i64*
  %87 = load i64, i64* %86, align 4
  %88 = and i64 %84, -4294967296
  %89 = add i64 %84, %75
  %90 = add i64 %87, %68
  %91 = and i64 %90, 4294967295
  %92 = and i64 %87, -4294967296
  %93 = add i64 %92, %72
  %94 = and i64 %93, -4294967296
  %95 = or i64 %94, %91
  %96 = add i64 %88, %76
  %97 = and i64 %96, -4294967296
  %98 = and i64 %89, 4294967295
  %99 = or i64 %97, %98
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %1, i64 0, i32 0, i32 1, i32 0, i32 0
  %101 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %100, i64 %99, i64 %95) #18
  %102 = extractvalue { i64, i64 } %101, 0
  %103 = extractvalue { i64, i64 } %101, 1
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.416", %"struct.gemmlowp::OutputPipelineExecutor.416"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %105 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %104, align 8
  %106 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %105, i64 0, i32 0
  %107 = load i32, i32* %106, align 4
  %108 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %105, i64 0, i32 1
  %109 = load i32, i32* %108, align 4
  %110 = trunc i64 %102 to i32
  %111 = icmp sgt i32 %107, %110
  %112 = select i1 %111, i32 %107, i32 %110
  %113 = icmp slt i32 %109, %112
  %114 = select i1 %113, i32 %109, i32 %112
  %115 = lshr i64 %102, 32
  %116 = trunc i64 %115 to i32
  %117 = icmp sgt i32 %107, %116
  %118 = select i1 %117, i32 %107, i32 %116
  %119 = icmp slt i32 %109, %118
  %120 = select i1 %119, i32 %109, i32 %118
  %121 = trunc i64 %103 to i32
  %122 = icmp sgt i32 %107, %121
  %123 = select i1 %122, i32 %107, i32 %121
  %124 = icmp slt i32 %109, %123
  %125 = select i1 %124, i32 %109, i32 %123
  %126 = lshr i64 %103, 32
  %127 = trunc i64 %126 to i32
  %128 = icmp sgt i32 %107, %127
  %129 = select i1 %128, i32 %107, i32 %127
  %130 = icmp slt i32 %109, %129
  %131 = select i1 %130, i32 %109, i32 %129
  %132 = icmp sgt i32 %114, -32768
  %133 = select i1 %132, i32 %114, i32 -32768
  %134 = icmp slt i32 %133, 32767
  %135 = select i1 %134, i32 %133, i32 32767
  %136 = icmp sgt i32 %120, -32768
  %137 = select i1 %136, i32 %120, i32 -32768
  %138 = icmp slt i32 %137, 32767
  %139 = select i1 %138, i32 %137, i32 32767
  %140 = icmp sgt i32 %125, -32768
  %141 = select i1 %140, i32 %125, i32 -32768
  %142 = icmp slt i32 %141, 32767
  %143 = select i1 %142, i32 %141, i32 32767
  %144 = icmp sgt i32 %131, -32768
  %145 = select i1 %144, i32 %131, i32 -32768
  %146 = icmp slt i32 %145, 32767
  %147 = select i1 %146, i32 %145, i32 32767
  %148 = trunc i32 %135 to i16
  %149 = trunc i32 %139 to i16
  %150 = trunc i32 %143 to i16
  %151 = trunc i32 %147 to i16
  %152 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %154 = sext i32 %12 to i64
  %155 = load i16*, i16** %152, align 8
  %156 = getelementptr inbounds i16, i16* %155, i64 %154
  %157 = load i32, i32* %153, align 8
  %158 = mul nsw i32 %157, %13
  %159 = sext i32 %158 to i64
  %160 = getelementptr inbounds i16, i16* %156, i64 %159
  store i16 %148, i16* %160, align 2
  %161 = add nsw i64 %154, 1
  %162 = load i16*, i16** %152, align 8
  %163 = getelementptr inbounds i16, i16* %162, i64 %161
  %164 = load i32, i32* %153, align 8
  %165 = mul nsw i32 %164, %13
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds i16, i16* %163, i64 %166
  store i16 %149, i16* %167, align 2
  %168 = add nsw i64 %154, 2
  %169 = load i16*, i16** %152, align 8
  %170 = getelementptr inbounds i16, i16* %169, i64 %168
  %171 = load i32, i32* %153, align 8
  %172 = mul nsw i32 %171, %13
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds i16, i16* %170, i64 %173
  store i16 %150, i16* %174, align 2
  %175 = add nsw i64 %154, 3
  %176 = load i16*, i16** %152, align 8
  %177 = getelementptr inbounds i16, i16* %176, i64 %175
  %178 = load i32, i32* %153, align 8
  %179 = mul nsw i32 %178, %13
  %180 = sext i32 %179 to i64
  %181 = getelementptr inbounds i16, i16* %177, i64 %180
  store i16 %151, i16* %181, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.407"* dereferenceable(40), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %16 = load i32*, i32** %15, align 8
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %19 = load i32, i32* %18, align 8
  %20 = getelementptr inbounds i32, i32* %16, i64 %17
  %21 = mul nsw i32 %19, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %20, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %26 = load i32*, i32** %25, align 8
  %27 = getelementptr inbounds i32, i32* %26, i64 %17
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %30 = load i32*, i32** %29, align 8
  %31 = sext i32 %9 to i64
  %32 = getelementptr inbounds i32, i32* %30, i64 %31
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = mul nsw i32 %37, %28
  %39 = add nsw i32 %38, %24
  %40 = mul nsw i32 %37, %7
  %41 = add nsw i32 %40, %33
  %42 = mul nsw i32 %41, %35
  %43 = add nsw i32 %39, %42
  %44 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 0, i32 0
  %45 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %44, align 8
  %46 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %45, i64 0, i32 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %10 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = add nsw i32 %43, %50
  %52 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %53 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %52, align 8
  %54 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 2
  %55 = load i32, i32* %54, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %57 = load i32, i32* %56, align 8
  %58 = sext i32 %51 to i64
  %59 = shl i32 1, %57
  %60 = sext i32 %59 to i64
  %61 = mul nsw i64 %60, %58
  %62 = icmp slt i64 %61, 2147483647
  %63 = select i1 %62, i64 %61, i64 2147483647
  %64 = icmp sgt i64 %63, -2147483648
  %65 = select i1 %64, i64 %63, i64 -2147483648
  %66 = trunc i64 %65 to i32
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = icmp ne i32 %68, %66
  %70 = icmp ne i32 %66, -2147483648
  %71 = or i1 %69, %70
  br i1 %71, label %72, label %81

72:                                               ; preds = %14
  %73 = sext i32 %68 to i64
  %74 = select i1 %69, i64 %73, i64 %65
  %75 = mul nsw i64 %74, %65
  %76 = icmp sgt i64 %75, -1
  %77 = select i1 %76, i64 1073741824, i64 -1073741823
  %78 = add nsw i64 %77, %75
  %79 = sdiv i64 %78, 2147483648
  %80 = trunc i64 %79 to i32
  br label %81

81:                                               ; preds = %14, %72
  %82 = phi i32 [ %80, %72 ], [ 2147483647, %14 ]
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  %84 = load i32, i32* %83, align 4
  %85 = zext i32 %84 to i64
  %86 = shl nsw i64 -1, %85
  %87 = trunc i64 %86 to i32
  %88 = xor i32 %87, -1
  %89 = and i32 %82, %88
  %90 = ashr i32 %88, 1
  %91 = lshr i32 %82, 31
  %92 = add nsw i32 %90, %91
  %93 = ashr i32 %82, %84
  %94 = icmp sgt i32 %89, %92
  %95 = zext i1 %94 to i32
  %96 = add i32 %93, %55
  %97 = add i32 %96, %95
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %99 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 0
  %101 = load i32, i32* %100, align 4
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 1
  %103 = load i32, i32* %102, align 4
  %104 = icmp sgt i32 %101, %97
  %105 = select i1 %104, i32 %101, i32 %97
  %106 = icmp slt i32 %103, %105
  %107 = select i1 %106, i32 %103, i32 %105
  %108 = icmp sgt i32 %107, -32768
  %109 = select i1 %108, i32 %107, i32 -32768
  %110 = icmp slt i32 %109, 32767
  %111 = select i1 %110, i32 %109, i32 32767
  %112 = trunc i32 %111 to i16
  %113 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %114 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %115 = sext i32 %12 to i64
  %116 = load i16*, i16** %113, align 8
  %117 = getelementptr inbounds i16, i16* %116, i64 %115
  %118 = load i32, i32* %114, align 8
  %119 = mul nsw i32 %118, %13
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds i16, i16* %117, i64 %120
  store i16 %112, i16* %121, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.452"*, %"struct.gemmlowp::RegisterBlock.380"* byval(%"struct.gemmlowp::RegisterBlock.380") align 8, %"class.gemmlowp::MatrixMap.260"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.388", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBlock.388", align 2
  %11 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %11) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %11, i8 -86, i64 64, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.452", %"struct.gemmlowp::OutputPipelineExecutor.452"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %36, align 8, !noalias !646
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !651
  %40 = sext i32 %3 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 4, !noalias !646
  %44 = getelementptr inbounds i32, i32* %41, i64 4
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 4, !noalias !646
  %47 = add nsw <4 x i32> %43, %13
  %48 = add nsw <4 x i32> %46, %16
  %49 = add nsw <4 x i32> %43, %19
  %50 = add nsw <4 x i32> %46, %22
  %51 = add nsw <4 x i32> %43, %25
  %52 = add nsw <4 x i32> %46, %28
  %53 = add nsw <4 x i32> %43, %31
  %54 = add nsw <4 x i32> %46, %34
  %55 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.452", %"struct.gemmlowp::OutputPipelineExecutor.452"* %0, i64 0, i32 0, i32 1
  %56 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %9 to <4 x i32>*
  store <4 x i32> %47, <4 x i32>* %56, align 16, !noalias !656
  %57 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 4
  %58 = bitcast i32* %57 to <4 x i32>*
  store <4 x i32> %48, <4 x i32>* %58, align 16, !noalias !656
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 8
  %60 = bitcast i32* %59 to <4 x i32>*
  store <4 x i32> %49, <4 x i32>* %60, align 16, !noalias !656
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 12
  %62 = bitcast i32* %61 to <4 x i32>*
  store <4 x i32> %50, <4 x i32>* %62, align 16, !noalias !656
  %63 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 16
  %64 = bitcast i32* %63 to <4 x i32>*
  store <4 x i32> %51, <4 x i32>* %64, align 16, !noalias !656
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 20
  %66 = bitcast i32* %65 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %66, align 16, !noalias !656
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 24
  %68 = bitcast i32* %67 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %68, align 16, !noalias !656
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %9, i64 0, i32 0, i32 0, i64 28
  %70 = bitcast i32* %69 to <4 x i32>*
  store <4 x i32> %54, <4 x i32>* %70, align 16, !noalias !656
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.388"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.455"* %55, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %9, i32 %3, i32 %4) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %71 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %71)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %71, i8* nonnull align 2 %11, i64 64, i1 false)
  %72 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %73 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %74 = sext i32 %6 to i64
  %75 = sext i32 %5 to i64
  %76 = add nsw i64 %74, 1
  %77 = add nsw i64 %74, 2
  %78 = add nsw i64 %74, 3
  br label %79

79:                                               ; preds = %79, %7
  %80 = phi i64 [ 0, %7 ], [ %117, %79 ]
  %81 = add nsw i64 %80, %75
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %80
  %83 = load i16, i16* %82, align 2
  %84 = load i16*, i16** %72, align 8
  %85 = getelementptr inbounds i16, i16* %84, i64 %81
  %86 = load i32, i32* %73, align 8
  %87 = sext i32 %86 to i64
  %88 = mul nsw i64 %87, %74
  %89 = getelementptr inbounds i16, i16* %85, i64 %88
  store i16 %83, i16* %89, align 2
  %90 = add nuw nsw i64 %80, 8
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %90
  %92 = load i16, i16* %91, align 2
  %93 = load i16*, i16** %72, align 8
  %94 = getelementptr inbounds i16, i16* %93, i64 %81
  %95 = load i32, i32* %73, align 8
  %96 = sext i32 %95 to i64
  %97 = mul nsw i64 %76, %96
  %98 = getelementptr inbounds i16, i16* %94, i64 %97
  store i16 %92, i16* %98, align 2
  %99 = add nuw nsw i64 %80, 16
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = load i16*, i16** %72, align 8
  %103 = getelementptr inbounds i16, i16* %102, i64 %81
  %104 = load i32, i32* %73, align 8
  %105 = sext i32 %104 to i64
  %106 = mul nsw i64 %77, %105
  %107 = getelementptr inbounds i16, i16* %103, i64 %106
  store i16 %101, i16* %107, align 2
  %108 = add nuw nsw i64 %80, 24
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %8, i64 0, i32 0, i32 0, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = load i16*, i16** %72, align 8
  %112 = getelementptr inbounds i16, i16* %111, i64 %81
  %113 = load i32, i32* %73, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %78, %114
  %116 = getelementptr inbounds i16, i16* %112, i64 %115
  store i16 %110, i16* %116, align 2
  %117 = add nuw nsw i64 %80, 1
  %118 = icmp eq i64 %117, 8
  br i1 %118, label %119, label %79

119:                                              ; preds = %79
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %71)
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %11) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.388"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.455"*, %"struct.gemmlowp::RegisterBlock.380"* byval(%"struct.gemmlowp::RegisterBlock.380") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.389", align 8
  %8 = alloca [32 x i16], align 2
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %11 = alloca [32 x i32], align 4
  %12 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 8
  %13 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 4
  %14 = alloca [32 x i32], align 4
  %15 = bitcast [32 x i32]* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15)
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %15, i8 -86, i64 128, i1 false), !alias.scope !657
  %17 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %17) #18, !noalias !657
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #18, !noalias !657
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %18, i8* nonnull align 8 %16, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %17, i8 -86, i64 128, i1 false) #18, !alias.scope !660, !noalias !657
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.455", %"struct.gemmlowp::OutputPipelineEvalImpl.455"* %1, i64 0, i32 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %19, align 8, !noalias !663
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !663
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.455", %"struct.gemmlowp::OutputPipelineEvalImpl.455"* %1, i64 0, i32 0, i32 0, i32 1
  %24 = load i32, i32* %23, align 8, !noalias !663
  %25 = shl i32 1, %24
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 0
  %28 = load i32, i32* %27, align 4, !noalias !663
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.455", %"struct.gemmlowp::OutputPipelineEvalImpl.455"* %1, i64 0, i32 0, i32 0, i32 2
  %31 = load i32, i32* %30, align 4, !noalias !663
  %32 = zext i32 %31 to i64
  %33 = shl nsw i64 -1, %32
  %34 = trunc i64 %33 to i32
  %35 = xor i32 %34, -1
  %36 = ashr i32 %35, 1
  %37 = icmp ne i32 %28, -2147483648
  br label %38

38:                                               ; preds = %59, %5
  %39 = phi i64 [ 0, %5 ], [ %70, %59 ]
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %12, i64 0, i32 0, i64 %39
  %41 = load i32, i32* %40, align 4, !noalias !663
  %42 = sext i32 %41 to i64
  %43 = mul nsw i64 %42, %26
  %44 = icmp slt i64 %43, 2147483647
  %45 = select i1 %44, i64 %43, i64 2147483647
  %46 = icmp sgt i64 %45, -2147483648
  %47 = select i1 %46, i64 %45, i64 -2147483648
  %48 = trunc i64 %47 to i32
  %49 = icmp ne i32 %28, %48
  %50 = or i1 %37, %49
  br i1 %50, label %51, label %59

51:                                               ; preds = %38
  %52 = select i1 %49, i64 %29, i64 %47
  %53 = mul nsw i64 %52, %47
  %54 = icmp sgt i64 %53, -1
  %55 = select i1 %54, i64 1073741824, i64 -1073741823
  %56 = add nsw i64 %55, %53
  %57 = sdiv i64 %56, 2147483648
  %58 = trunc i64 %57 to i32
  br label %59

59:                                               ; preds = %51, %38
  %60 = phi i32 [ %58, %51 ], [ 2147483647, %38 ]
  %61 = and i32 %60, %35
  %62 = lshr i32 %60, 31
  %63 = add nsw i32 %62, %36
  %64 = ashr i32 %60, %31
  %65 = icmp sgt i32 %61, %63
  %66 = zext i1 %65 to i32
  %67 = add i32 %64, %22
  %68 = add i32 %67, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %13, i64 0, i32 0, i64 %39
  store i32 %68, i32* %69, align 4, !alias.scope !660, !noalias !657
  %70 = add nuw nsw i64 %39, 1
  %71 = icmp eq i64 %70, 32
  br i1 %71, label %72, label %38

72:                                               ; preds = %59
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #18, !noalias !657
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %15, i8* nonnull align 4 %17, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %17) #18, !noalias !657
  %73 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %73, i8 -86, i64 128, i1 false), !alias.scope !664, !noalias !667
  %74 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %74) #18, !noalias !670
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %75) #18, !noalias !670
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %75, i8* nonnull align 4 %15, i64 128, i1 false)
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.455", %"struct.gemmlowp::OutputPipelineEvalImpl.455"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %77 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %76, align 8, !noalias !671
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !671
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 1
  %81 = load i32, i32* %80, align 4, !noalias !671
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %74, i8 -86, i64 128, i1 false) #18, !alias.scope !674, !noalias !670
  %82 = insertelement <4 x i32> undef, i32 %79, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = insertelement <4 x i32> undef, i32 %81, i32 0
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> zeroinitializer
  %86 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %9 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16, !noalias !671
  %88 = icmp slt <4 x i32> %87, %83
  %89 = select <4 x i1> %88, <4 x i32> %83, <4 x i32> %87
  %90 = icmp slt <4 x i32> %85, %89
  %91 = select <4 x i1> %90, <4 x i32> %85, <4 x i32> %89
  %92 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %10 to <4 x i32>*
  store <4 x i32> %91, <4 x i32>* %92, align 16, !alias.scope !674, !noalias !670
  %93 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 4
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16, !noalias !671
  %96 = icmp slt <4 x i32> %95, %83
  %97 = select <4 x i1> %96, <4 x i32> %83, <4 x i32> %95
  %98 = icmp slt <4 x i32> %85, %97
  %99 = select <4 x i1> %98, <4 x i32> %85, <4 x i32> %97
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 4
  %101 = bitcast i32* %100 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %101, align 16, !alias.scope !674, !noalias !670
  %102 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 8
  %103 = bitcast i32* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16, !noalias !671
  %105 = icmp slt <4 x i32> %104, %83
  %106 = select <4 x i1> %105, <4 x i32> %83, <4 x i32> %104
  %107 = icmp slt <4 x i32> %85, %106
  %108 = select <4 x i1> %107, <4 x i32> %85, <4 x i32> %106
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 8
  %110 = bitcast i32* %109 to <4 x i32>*
  store <4 x i32> %108, <4 x i32>* %110, align 16, !alias.scope !674, !noalias !670
  %111 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 12
  %112 = bitcast i32* %111 to <4 x i32>*
  %113 = load <4 x i32>, <4 x i32>* %112, align 16, !noalias !671
  %114 = icmp slt <4 x i32> %113, %83
  %115 = select <4 x i1> %114, <4 x i32> %83, <4 x i32> %113
  %116 = icmp slt <4 x i32> %85, %115
  %117 = select <4 x i1> %116, <4 x i32> %85, <4 x i32> %115
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 12
  %119 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %117, <4 x i32>* %119, align 16, !alias.scope !674, !noalias !670
  %120 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 16
  %121 = bitcast i32* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16, !noalias !671
  %123 = icmp slt <4 x i32> %122, %83
  %124 = select <4 x i1> %123, <4 x i32> %83, <4 x i32> %122
  %125 = icmp slt <4 x i32> %85, %124
  %126 = select <4 x i1> %125, <4 x i32> %85, <4 x i32> %124
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 16
  %128 = bitcast i32* %127 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %128, align 16, !alias.scope !674, !noalias !670
  %129 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 20
  %130 = bitcast i32* %129 to <4 x i32>*
  %131 = load <4 x i32>, <4 x i32>* %130, align 16, !noalias !671
  %132 = icmp slt <4 x i32> %131, %83
  %133 = select <4 x i1> %132, <4 x i32> %83, <4 x i32> %131
  %134 = icmp slt <4 x i32> %85, %133
  %135 = select <4 x i1> %134, <4 x i32> %85, <4 x i32> %133
  %136 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 20
  %137 = bitcast i32* %136 to <4 x i32>*
  store <4 x i32> %135, <4 x i32>* %137, align 16, !alias.scope !674, !noalias !670
  %138 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 24
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16, !noalias !671
  %141 = icmp slt <4 x i32> %140, %83
  %142 = select <4 x i1> %141, <4 x i32> %83, <4 x i32> %140
  %143 = icmp slt <4 x i32> %85, %142
  %144 = select <4 x i1> %143, <4 x i32> %85, <4 x i32> %142
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 24
  %146 = bitcast i32* %145 to <4 x i32>*
  store <4 x i32> %144, <4 x i32>* %146, align 16, !alias.scope !674, !noalias !670
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 28
  %148 = bitcast i32* %147 to <4 x i32>*
  %149 = load <4 x i32>, <4 x i32>* %148, align 16, !noalias !671
  %150 = icmp slt <4 x i32> %149, %83
  %151 = select <4 x i1> %150, <4 x i32> %83, <4 x i32> %149
  %152 = icmp slt <4 x i32> %85, %151
  %153 = select <4 x i1> %152, <4 x i32> %85, <4 x i32> %151
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 28
  %155 = bitcast i32* %154 to <4 x i32>*
  store <4 x i32> %153, <4 x i32>* %155, align 16, !alias.scope !674, !noalias !670
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %75) #18, !noalias !670
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %73, i8* nonnull align 16 %74, i64 128, i1 false) #18, !noalias !667
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %74) #18, !noalias !670
  %156 = bitcast [32 x i16]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %156, i8 -86, i64 64, i1 false), !alias.scope !675, !noalias !678
  %157 = bitcast %"struct.gemmlowp::RegisterBuffer.389"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %157) #18, !noalias !681
  %158 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %158) #18, !noalias !681
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %158, i8* nonnull align 4 %73, i64 128, i1 false) #18, !noalias !667
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %157, i8 -86, i64 64, i1 false) #18, !alias.scope !682, !noalias !681
  %159 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %6 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16, !noalias !685
  %161 = icmp sgt <4 x i32> %160, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %162 = select <4 x i1> %161, <4 x i32> %160, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %163 = icmp slt <4 x i32> %162, <i32 32767, i32 32767, i32 32767, i32 32767>
  %164 = select <4 x i1> %163, <4 x i32> %162, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %165 = trunc <4 x i32> %164 to <4 x i16>
  %166 = bitcast %"struct.gemmlowp::RegisterBuffer.389"* %7 to <4 x i16>*
  store <4 x i16> %165, <4 x i16>* %166, align 8, !alias.scope !682, !noalias !681
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 4
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16, !noalias !685
  %170 = icmp sgt <4 x i32> %169, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %172 = icmp slt <4 x i32> %171, <i32 32767, i32 32767, i32 32767, i32 32767>
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %174 = trunc <4 x i32> %173 to <4 x i16>
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 4
  %176 = bitcast i16* %175 to <4 x i16>*
  store <4 x i16> %174, <4 x i16>* %176, align 8, !alias.scope !682, !noalias !681
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 8
  %178 = bitcast i32* %177 to <4 x i32>*
  %179 = load <4 x i32>, <4 x i32>* %178, align 16, !noalias !685
  %180 = icmp sgt <4 x i32> %179, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %182 = icmp slt <4 x i32> %181, <i32 32767, i32 32767, i32 32767, i32 32767>
  %183 = select <4 x i1> %182, <4 x i32> %181, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %184 = trunc <4 x i32> %183 to <4 x i16>
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 8
  %186 = bitcast i16* %185 to <4 x i16>*
  store <4 x i16> %184, <4 x i16>* %186, align 8, !alias.scope !682, !noalias !681
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 12
  %188 = bitcast i32* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16, !noalias !685
  %190 = icmp sgt <4 x i32> %189, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %192 = icmp slt <4 x i32> %191, <i32 32767, i32 32767, i32 32767, i32 32767>
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %194 = trunc <4 x i32> %193 to <4 x i16>
  %195 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 12
  %196 = bitcast i16* %195 to <4 x i16>*
  store <4 x i16> %194, <4 x i16>* %196, align 8, !alias.scope !682, !noalias !681
  %197 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 16
  %198 = bitcast i32* %197 to <4 x i32>*
  %199 = load <4 x i32>, <4 x i32>* %198, align 16, !noalias !685
  %200 = icmp sgt <4 x i32> %199, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %202 = icmp slt <4 x i32> %201, <i32 32767, i32 32767, i32 32767, i32 32767>
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %204 = trunc <4 x i32> %203 to <4 x i16>
  %205 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 16
  %206 = bitcast i16* %205 to <4 x i16>*
  store <4 x i16> %204, <4 x i16>* %206, align 8, !alias.scope !682, !noalias !681
  %207 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 20
  %208 = bitcast i32* %207 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16, !noalias !685
  %210 = icmp sgt <4 x i32> %209, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %212 = icmp slt <4 x i32> %211, <i32 32767, i32 32767, i32 32767, i32 32767>
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %214 = trunc <4 x i32> %213 to <4 x i16>
  %215 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 20
  %216 = bitcast i16* %215 to <4 x i16>*
  store <4 x i16> %214, <4 x i16>* %216, align 8, !alias.scope !682, !noalias !681
  %217 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 24
  %218 = bitcast i32* %217 to <4 x i32>*
  %219 = load <4 x i32>, <4 x i32>* %218, align 16, !noalias !685
  %220 = icmp sgt <4 x i32> %219, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %222 = icmp slt <4 x i32> %221, <i32 32767, i32 32767, i32 32767, i32 32767>
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %224 = trunc <4 x i32> %223 to <4 x i16>
  %225 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 24
  %226 = bitcast i16* %225 to <4 x i16>*
  store <4 x i16> %224, <4 x i16>* %226, align 8, !alias.scope !682, !noalias !681
  %227 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 28
  %228 = bitcast i32* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16, !noalias !685
  %230 = icmp sgt <4 x i32> %229, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %232 = icmp slt <4 x i32> %231, <i32 32767, i32 32767, i32 32767, i32 32767>
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %234 = trunc <4 x i32> %233 to <4 x i16>
  %235 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 28
  %236 = bitcast i16* %235 to <4 x i16>*
  store <4 x i16> %234, <4 x i16>* %236, align 8, !alias.scope !682, !noalias !681
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %158) #18, !noalias !681
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 2 %156, i8* nonnull align 8 %157, i64 64, i1 false) #18, !noalias !678
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %157) #18, !noalias !681
  %237 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %237, i8* nonnull align 2 %156, i64 64, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.393"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.444"*, %"struct.gemmlowp::RegisterBlock.390"* byval(%"struct.gemmlowp::RegisterBlock.390") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.391", align 8
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.391", align 8
  %8 = alloca [16 x i32], align 8
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 0
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 1
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 2
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 3
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 4
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 5
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 6
  %22 = load i32, i32* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 7
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 8
  %26 = load i32, i32* %25, align 8
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 9
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 10
  %30 = load i32, i32* %29, align 8
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 11
  %32 = load i32, i32* %31, align 4
  %33 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 12
  %34 = load i32, i32* %33, align 8
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 13
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 14
  %38 = load i32, i32* %37, align 8
  %39 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 15
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.444", %"struct.gemmlowp::OutputPipelineEvalImpl.444"* %1, i64 0, i32 0, i32 0
  %42 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %41, align 8, !noalias !686
  %43 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %42, i64 0, i32 0, i32 0
  %44 = load i32*, i32** %43, align 8, !noalias !686
  %45 = sext i32 %3 to i64
  %46 = getelementptr i32, i32* %44, i64 %45
  %47 = bitcast i32* %46 to i64*
  %48 = load i64, i64* %47, align 4, !noalias !686
  %49 = getelementptr inbounds i32, i32* %46, i64 2
  %50 = bitcast i32* %49 to i64*
  %51 = load i64, i64* %50, align 4, !noalias !686
  %52 = trunc i64 %48 to i32
  %53 = lshr i64 %48, 32
  %54 = trunc i64 %53 to i32
  %55 = add nsw i32 %10, %52
  %56 = add nsw i32 %12, %54
  %57 = trunc i64 %51 to i32
  %58 = add nsw i32 %14, %57
  %59 = lshr i64 %51, 32
  %60 = trunc i64 %59 to i32
  %61 = add nsw i32 %16, %60
  %62 = add nsw i32 %18, %52
  %63 = add nsw i32 %20, %54
  %64 = add nsw i32 %22, %57
  %65 = add nsw i32 %24, %60
  %66 = add nsw i32 %26, %52
  %67 = add nsw i32 %28, %54
  %68 = add nsw i32 %30, %57
  %69 = add nsw i32 %32, %60
  %70 = add nsw i32 %34, %52
  %71 = add nsw i32 %36, %54
  %72 = add nsw i32 %38, %57
  %73 = add nsw i32 %40, %60
  %74 = bitcast [16 x i32]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %74) #18, !noalias !689
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %74, i8 -86, i64 64, i1 false) #18, !alias.scope !692, !noalias !689
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %75) #18, !noalias !695
  %76 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %76) #18, !noalias !695
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 0
  store i32 %55, i32* %77, align 8, !noalias !689
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 1
  store i32 %56, i32* %78, align 4, !noalias !689
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 2
  store i32 %58, i32* %79, align 8, !noalias !689
  %80 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 3
  store i32 %61, i32* %80, align 4, !noalias !689
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 4
  store i32 %62, i32* %81, align 8, !noalias !689
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 5
  store i32 %63, i32* %82, align 4, !noalias !689
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 6
  store i32 %64, i32* %83, align 8, !noalias !689
  %84 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 7
  store i32 %65, i32* %84, align 4, !noalias !689
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 8
  store i32 %66, i32* %85, align 8, !noalias !689
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 9
  store i32 %67, i32* %86, align 4, !noalias !689
  %87 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 10
  store i32 %68, i32* %87, align 8, !noalias !689
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 11
  store i32 %69, i32* %88, align 4, !noalias !689
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 12
  store i32 %70, i32* %89, align 8, !noalias !689
  %90 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 13
  store i32 %71, i32* %90, align 4, !noalias !689
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 14
  store i32 %72, i32* %91, align 8, !noalias !689
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 15
  store i32 %73, i32* %92, align 4, !noalias !689
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %75, i8 -86, i64 64, i1 false) #18, !alias.scope !696, !noalias !695
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.444", %"struct.gemmlowp::OutputPipelineEvalImpl.444"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %94 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %93, align 8, !noalias !699
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %94, i64 0, i32 2
  %96 = load i32, i32* %95, align 4, !noalias !699
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.444", %"struct.gemmlowp::OutputPipelineEvalImpl.444"* %1, i64 0, i32 1, i32 0, i32 0, i32 1
  %98 = load i32, i32* %97, align 8, !noalias !699
  %99 = shl i32 1, %98
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %94, i64 0, i32 0
  %102 = load i32, i32* %101, align 4, !noalias !699
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.444", %"struct.gemmlowp::OutputPipelineEvalImpl.444"* %1, i64 0, i32 1, i32 0, i32 0, i32 2
  %105 = load i32, i32* %104, align 4, !noalias !699
  %106 = zext i32 %105 to i64
  %107 = shl nsw i64 -1, %106
  %108 = trunc i64 %107 to i32
  %109 = xor i32 %108, -1
  %110 = ashr i32 %109, 1
  %111 = icmp ne i32 %102, -2147483648
  br label %112

112:                                              ; preds = %145, %5
  %113 = phi i32 [ %55, %5 ], [ %147, %145 ]
  %114 = phi i64 [ 0, %5 ], [ %143, %145 ]
  %115 = sext i32 %113 to i64
  %116 = mul nsw i64 %115, %100
  %117 = icmp slt i64 %116, 2147483647
  %118 = select i1 %117, i64 %116, i64 2147483647
  %119 = icmp sgt i64 %118, -2147483648
  %120 = select i1 %119, i64 %118, i64 -2147483648
  %121 = trunc i64 %120 to i32
  %122 = icmp ne i32 %102, %121
  %123 = or i1 %111, %122
  br i1 %123, label %124, label %132

124:                                              ; preds = %112
  %125 = select i1 %122, i64 %103, i64 %120
  %126 = mul nsw i64 %125, %120
  %127 = icmp sgt i64 %126, -1
  %128 = select i1 %127, i64 1073741824, i64 -1073741823
  %129 = add nsw i64 %128, %126
  %130 = sdiv i64 %129, 2147483648
  %131 = trunc i64 %130 to i32
  br label %132

132:                                              ; preds = %124, %112
  %133 = phi i32 [ %131, %124 ], [ 2147483647, %112 ]
  %134 = and i32 %133, %109
  %135 = lshr i32 %133, 31
  %136 = add nsw i32 %135, %110
  %137 = ashr i32 %133, %105
  %138 = icmp sgt i32 %134, %136
  %139 = zext i1 %138 to i32
  %140 = add i32 %137, %96
  %141 = add i32 %140, %139
  %142 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %7, i64 0, i32 0, i64 %114
  store i32 %141, i32* %142, align 4, !alias.scope !696, !noalias !695
  %143 = add nuw nsw i64 %114, 1
  %144 = icmp eq i64 %143, 16
  br i1 %144, label %148, label %145

145:                                              ; preds = %132
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %6, i64 0, i32 0, i64 %143
  %147 = load i32, i32* %146, align 4, !noalias !699
  br label %112

148:                                              ; preds = %132
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %76) #18, !noalias !695
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %74, i8* nonnull align 8 %75, i64 64, i1 false) #18, !noalias !689
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %75) #18, !noalias !695
  %149 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.444", %"struct.gemmlowp::OutputPipelineEvalImpl.444"* %1, i64 0, i32 1, i32 1
  %150 = bitcast [16 x i32]* %8 to %"struct.gemmlowp::RegisterBlock.390"*
  tail call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.393"* sret %0, %"struct.gemmlowp::OutputPipelineEvalImpl.447"* %149, %"struct.gemmlowp::RegisterBlock.390"* nonnull byval(%"struct.gemmlowp::RegisterBlock.390") align 8 %150, i32 %3, i32 %4) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %74) #18, !noalias !689
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.393"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.447"*, %"struct.gemmlowp::RegisterBlock.390"* byval(%"struct.gemmlowp::RegisterBlock.390") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.390"* %2 to <8 x i32>*
  %7 = load <8 x i32>, <8 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 8
  %9 = load i32, i32* %8, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 9
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 10
  %13 = load i32, i32* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 11
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 12
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 13
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 14
  %21 = load i32, i32* %20, align 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 15
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.447", %"struct.gemmlowp::OutputPipelineEvalImpl.447"* %1, i64 0, i32 0, i32 0, i32 0
  %25 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %24, align 8, !noalias !700
  %26 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 0
  %27 = load i32, i32* %26, align 4, !noalias !700
  %28 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 1
  %29 = load i32, i32* %28, align 4, !noalias !700
  %30 = insertelement <8 x i32> undef, i32 %27, i32 0
  %31 = shufflevector <8 x i32> %30, <8 x i32> undef, <8 x i32> zeroinitializer
  %32 = icmp slt <8 x i32> %7, %31
  %33 = select <8 x i1> %32, <8 x i32> %31, <8 x i32> %7
  %34 = insertelement <8 x i32> undef, i32 %29, i32 0
  %35 = shufflevector <8 x i32> %34, <8 x i32> undef, <8 x i32> zeroinitializer
  %36 = icmp slt <8 x i32> %35, %33
  %37 = select <8 x i1> %36, <8 x i32> %35, <8 x i32> %33
  %38 = icmp slt i32 %9, %27
  %39 = select i1 %38, i32 %27, i32 %9
  %40 = icmp slt i32 %29, %39
  %41 = select i1 %40, i32 %29, i32 %39
  %42 = icmp slt i32 %11, %27
  %43 = select i1 %42, i32 %27, i32 %11
  %44 = icmp slt i32 %29, %43
  %45 = select i1 %44, i32 %29, i32 %43
  %46 = icmp slt i32 %13, %27
  %47 = select i1 %46, i32 %27, i32 %13
  %48 = icmp slt i32 %29, %47
  %49 = select i1 %48, i32 %29, i32 %47
  %50 = icmp slt i32 %15, %27
  %51 = select i1 %50, i32 %27, i32 %15
  %52 = icmp slt i32 %29, %51
  %53 = select i1 %52, i32 %29, i32 %51
  %54 = icmp slt i32 %17, %27
  %55 = select i1 %54, i32 %27, i32 %17
  %56 = icmp slt i32 %29, %55
  %57 = select i1 %56, i32 %29, i32 %55
  %58 = icmp slt i32 %19, %27
  %59 = select i1 %58, i32 %27, i32 %19
  %60 = icmp slt i32 %29, %59
  %61 = select i1 %60, i32 %29, i32 %59
  %62 = icmp slt i32 %21, %27
  %63 = select i1 %62, i32 %27, i32 %21
  %64 = icmp slt i32 %29, %63
  %65 = select i1 %64, i32 %29, i32 %63
  %66 = icmp slt i32 %23, %27
  %67 = select i1 %66, i32 %27, i32 %23
  %68 = icmp slt i32 %29, %67
  %69 = select i1 %68, i32 %29, i32 %67
  %70 = icmp sgt <8 x i32> %37, <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %71 = select <8 x i1> %70, <8 x i32> %37, <8 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %72 = icmp slt <8 x i32> %71, <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %73 = select <8 x i1> %72, <8 x i32> %71, <8 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %74 = trunc <8 x i32> %73 to <8 x i16>
  %75 = icmp sgt i32 %41, -32768
  %76 = select i1 %75, i32 %41, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = trunc i32 %78 to i16
  %80 = icmp sgt i32 %45, -32768
  %81 = select i1 %80, i32 %45, i32 -32768
  %82 = icmp slt i32 %81, 32767
  %83 = select i1 %82, i32 %81, i32 32767
  %84 = trunc i32 %83 to i16
  %85 = icmp sgt i32 %49, -32768
  %86 = select i1 %85, i32 %49, i32 -32768
  %87 = icmp slt i32 %86, 32767
  %88 = select i1 %87, i32 %86, i32 32767
  %89 = trunc i32 %88 to i16
  %90 = icmp sgt i32 %53, -32768
  %91 = select i1 %90, i32 %53, i32 -32768
  %92 = icmp slt i32 %91, 32767
  %93 = select i1 %92, i32 %91, i32 32767
  %94 = trunc i32 %93 to i16
  %95 = icmp sgt i32 %57, -32768
  %96 = select i1 %95, i32 %57, i32 -32768
  %97 = icmp slt i32 %96, 32767
  %98 = select i1 %97, i32 %96, i32 32767
  %99 = icmp sgt i32 %61, -32768
  %100 = select i1 %99, i32 %61, i32 -32768
  %101 = icmp slt i32 %100, 32767
  %102 = select i1 %101, i32 %100, i32 32767
  %103 = shl nsw i32 %102, 16
  %104 = and i32 %98, 65535
  %105 = or i32 %103, %104
  %106 = zext i32 %105 to i64
  %107 = icmp sgt i32 %65, -32768
  %108 = select i1 %107, i32 %65, i32 -32768
  %109 = icmp slt i32 %108, 32767
  %110 = select i1 %109, i32 %108, i32 32767
  %111 = and i32 %110, 65535
  %112 = zext i32 %111 to i64
  %113 = shl nuw nsw i64 %112, 32
  %114 = icmp sgt i32 %69, -32768
  %115 = select i1 %114, i32 %69, i32 -32768
  %116 = icmp slt i32 %115, 32767
  %117 = select i1 %116, i32 %115, i32 32767
  %118 = zext i32 %117 to i64
  %119 = shl i64 %118, 48
  %120 = or i64 %119, %106
  %121 = or i64 %120, %113
  %122 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %0 to <8 x i16>*
  store <8 x i16> %74, <8 x i16>* %122, align 2, !alias.scope !705
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 8
  store i16 %79, i16* %123, align 2, !alias.scope !705
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 9
  store i16 %84, i16* %124, align 2, !alias.scope !705
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 10
  store i16 %89, i16* %125, align 2, !alias.scope !705
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 11
  store i16 %94, i16* %126, align 2, !alias.scope !705
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 12
  %128 = bitcast i16* %127 to i64*
  store i64 %121, i64* %128, align 2, !alias.scope !705
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.434"*, i64, i64, %"class.gemmlowp::MatrixMap.260"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %9 = trunc i64 %1 to i32
  %10 = lshr i64 %1, 32
  %11 = trunc i64 %10 to i32
  %12 = trunc i64 %2 to i32
  %13 = lshr i64 %2, 32
  %14 = trunc i64 %13 to i32
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %0, i64 0, i32 0, i32 0, i32 0
  %16 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %16, i64 0, i32 0, i32 0
  %18 = load i32*, i32** %17, align 8
  %19 = sext i32 %4 to i64
  %20 = getelementptr inbounds i32, i32* %18, i64 %19
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, %9
  %23 = add nsw i32 %21, %11
  %24 = add nsw i32 %21, %12
  %25 = zext i32 %24 to i64
  %26 = add nsw i32 %21, %14
  %27 = zext i32 %26 to i64
  %28 = shl nuw i64 %27, 32
  %29 = or i64 %28, %25
  %30 = zext i32 %23 to i64
  %31 = shl nuw i64 %30, 32
  %32 = zext i32 %22 to i64
  %33 = or i64 %31, %32
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %35 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %34, i64 %33, i64 %29) #18
  %36 = extractvalue { i64, i64 } %35, 0
  %37 = extractvalue { i64, i64 } %35, 1
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.434", %"struct.gemmlowp::OutputPipelineExecutor.434"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %39 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %38, align 8
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 0
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 1
  %43 = load i32, i32* %42, align 4
  %44 = trunc i64 %36 to i32
  %45 = icmp sgt i32 %41, %44
  %46 = select i1 %45, i32 %41, i32 %44
  %47 = icmp slt i32 %43, %46
  %48 = select i1 %47, i32 %43, i32 %46
  %49 = lshr i64 %36, 32
  %50 = trunc i64 %49 to i32
  %51 = icmp sgt i32 %41, %50
  %52 = select i1 %51, i32 %41, i32 %50
  %53 = icmp slt i32 %43, %52
  %54 = select i1 %53, i32 %43, i32 %52
  %55 = trunc i64 %37 to i32
  %56 = icmp sgt i32 %41, %55
  %57 = select i1 %56, i32 %41, i32 %55
  %58 = icmp slt i32 %43, %57
  %59 = select i1 %58, i32 %43, i32 %57
  %60 = lshr i64 %37, 32
  %61 = trunc i64 %60 to i32
  %62 = icmp sgt i32 %41, %61
  %63 = select i1 %62, i32 %41, i32 %61
  %64 = icmp slt i32 %43, %63
  %65 = select i1 %64, i32 %43, i32 %63
  %66 = icmp sgt i32 %48, -32768
  %67 = select i1 %66, i32 %48, i32 -32768
  %68 = icmp slt i32 %67, 32767
  %69 = select i1 %68, i32 %67, i32 32767
  %70 = icmp sgt i32 %54, -32768
  %71 = select i1 %70, i32 %54, i32 -32768
  %72 = icmp slt i32 %71, 32767
  %73 = select i1 %72, i32 %71, i32 32767
  %74 = icmp sgt i32 %59, -32768
  %75 = select i1 %74, i32 %59, i32 -32768
  %76 = icmp slt i32 %75, 32767
  %77 = select i1 %76, i32 %75, i32 32767
  %78 = icmp sgt i32 %65, -32768
  %79 = select i1 %78, i32 %65, i32 -32768
  %80 = icmp slt i32 %79, 32767
  %81 = select i1 %80, i32 %79, i32 32767
  %82 = trunc i32 %69 to i16
  %83 = trunc i32 %73 to i16
  %84 = trunc i32 %77 to i16
  %85 = trunc i32 %81 to i16
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %3, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %3, i64 0, i32 3
  %88 = sext i32 %7 to i64
  %89 = sext i32 %6 to i64
  %90 = load i16*, i16** %86, align 8
  %91 = getelementptr inbounds i16, i16* %90, i64 %89
  %92 = load i32, i32* %87, align 8
  %93 = sext i32 %92 to i64
  %94 = mul nsw i64 %93, %88
  %95 = getelementptr inbounds i16, i16* %91, i64 %94
  store i16 %82, i16* %95, align 2
  %96 = add nsw i64 %88, 1
  %97 = load i16*, i16** %86, align 8
  %98 = getelementptr inbounds i16, i16* %97, i64 %89
  %99 = load i32, i32* %87, align 8
  %100 = sext i32 %99 to i64
  %101 = mul nsw i64 %96, %100
  %102 = getelementptr inbounds i16, i16* %98, i64 %101
  store i16 %83, i16* %102, align 2
  %103 = add nsw i64 %88, 2
  %104 = load i16*, i16** %86, align 8
  %105 = getelementptr inbounds i16, i16* %104, i64 %89
  %106 = load i32, i32* %87, align 8
  %107 = sext i32 %106 to i64
  %108 = mul nsw i64 %103, %107
  %109 = getelementptr inbounds i16, i16* %105, i64 %108
  store i16 %84, i16* %109, align 2
  %110 = add nsw i64 %88, 3
  %111 = load i16*, i16** %86, align 8
  %112 = getelementptr inbounds i16, i16* %111, i64 %89
  %113 = load i32, i32* %87, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %110, %114
  %116 = getelementptr inbounds i16, i16* %112, i64 %115
  store i16 %85, i16* %116, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.425"*, %"struct.gemmlowp::RegisterBlock.382"* byval(%"struct.gemmlowp::RegisterBlock.382") align 8, %"class.gemmlowp::MatrixMap.260"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.382", align 16
  %9 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %1 to <4 x i32>*
  %10 = load <4 x i32>, <4 x i32>* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 4
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %14)
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.425", %"struct.gemmlowp::OutputPipelineExecutor.425"* %0, i64 0, i32 0, i32 0, i32 0
  %16 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %15, align 8, !noalias !708
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %16, i64 0, i32 0, i32 0
  %18 = load i32*, i32** %17, align 8, !noalias !711
  %19 = sext i32 %3 to i64
  %20 = getelementptr i32, i32* %18, i64 %19
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 4, !noalias !708
  %23 = getelementptr inbounds i32, i32* %20, i64 4
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 4, !noalias !708
  %26 = add nsw <4 x i32> %22, %10
  %27 = add nsw <4 x i32> %25, %13
  %28 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.425", %"struct.gemmlowp::OutputPipelineExecutor.425"* %0, i64 0, i32 0, i32 1
  %29 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %8 to <4 x i32>*
  store <4 x i32> %26, <4 x i32>* %29, align 16
  %30 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %8, i64 0, i32 0, i32 0, i64 4
  %31 = bitcast i32* %30 to <4 x i32>*
  store <4 x i32> %27, <4 x i32>* %31, align 16
  %32 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.428"* %28, %"struct.gemmlowp::RegisterBlock.382"* nonnull byval(%"struct.gemmlowp::RegisterBlock.382") align 8 %8, i32 %3, i32 %4) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %14)
  %33 = extractvalue { i64, i64 } %32, 0
  %34 = extractvalue { i64, i64 } %32, 1
  %35 = trunc i64 %33 to i16
  %36 = lshr i64 %33, 16
  %37 = trunc i64 %36 to i16
  %38 = lshr i64 %33, 32
  %39 = trunc i64 %38 to i16
  %40 = lshr i64 %33, 48
  %41 = trunc i64 %40 to i16
  %42 = trunc i64 %34 to i16
  %43 = lshr i64 %34, 16
  %44 = trunc i64 %43 to i16
  %45 = lshr i64 %34, 32
  %46 = trunc i64 %45 to i16
  %47 = lshr i64 %34, 48
  %48 = trunc i64 %47 to i16
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %51 = sext i32 %5 to i64
  %52 = load i16*, i16** %49, align 8
  %53 = getelementptr inbounds i16, i16* %52, i64 %51
  %54 = load i32, i32* %50, align 8
  %55 = mul nsw i32 %54, %6
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i16, i16* %53, i64 %56
  store i16 %35, i16* %57, align 2
  %58 = add nsw i64 %51, 1
  %59 = load i16*, i16** %49, align 8
  %60 = getelementptr inbounds i16, i16* %59, i64 %58
  %61 = load i32, i32* %50, align 8
  %62 = mul nsw i32 %61, %6
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds i16, i16* %60, i64 %63
  store i16 %37, i16* %64, align 2
  %65 = add nsw i64 %51, 2
  %66 = load i16*, i16** %49, align 8
  %67 = getelementptr inbounds i16, i16* %66, i64 %65
  %68 = load i32, i32* %50, align 8
  %69 = mul nsw i32 %68, %6
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds i16, i16* %67, i64 %70
  store i16 %39, i16* %71, align 2
  %72 = add nsw i64 %51, 3
  %73 = load i16*, i16** %49, align 8
  %74 = getelementptr inbounds i16, i16* %73, i64 %72
  %75 = load i32, i32* %50, align 8
  %76 = mul nsw i32 %75, %6
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds i16, i16* %74, i64 %77
  store i16 %41, i16* %78, align 2
  %79 = add nsw i64 %51, 4
  %80 = load i16*, i16** %49, align 8
  %81 = getelementptr inbounds i16, i16* %80, i64 %79
  %82 = load i32, i32* %50, align 8
  %83 = mul nsw i32 %82, %6
  %84 = sext i32 %83 to i64
  %85 = getelementptr inbounds i16, i16* %81, i64 %84
  store i16 %42, i16* %85, align 2
  %86 = add nsw i64 %51, 5
  %87 = load i16*, i16** %49, align 8
  %88 = getelementptr inbounds i16, i16* %87, i64 %86
  %89 = load i32, i32* %50, align 8
  %90 = mul nsw i32 %89, %6
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds i16, i16* %88, i64 %91
  store i16 %44, i16* %92, align 2
  %93 = add nsw i64 %51, 6
  %94 = load i16*, i16** %49, align 8
  %95 = getelementptr inbounds i16, i16* %94, i64 %93
  %96 = load i32, i32* %50, align 8
  %97 = mul nsw i32 %96, %6
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %95, i64 %98
  store i16 %46, i16* %99, align 2
  %100 = add nsw i64 %51, 7
  %101 = load i16*, i16** %49, align 8
  %102 = getelementptr inbounds i16, i16* %101, i64 %100
  %103 = load i32, i32* %50, align 8
  %104 = mul nsw i32 %103, %6
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds i16, i16* %102, i64 %105
  store i16 %48, i16* %106, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.428"*, %"struct.gemmlowp::RegisterBlock.382"* byval(%"struct.gemmlowp::RegisterBlock.382") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.383", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.383", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBlock.382", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %1 to i8*
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #18, !noalias !716
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #18, !noalias !716
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* nonnull align 8 %8, i64 32, i1 false)
  %11 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.428", %"struct.gemmlowp::OutputPipelineEvalImpl.428"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #18, !alias.scope !719, !noalias !716
  %12 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %11, align 8, !noalias !722
  %13 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 2
  %14 = load i32, i32* %13, align 4, !noalias !722
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.428", %"struct.gemmlowp::OutputPipelineEvalImpl.428"* %0, i64 0, i32 0, i32 0, i32 1
  %16 = load i32, i32* %15, align 8, !noalias !722
  %17 = shl i32 1, %16
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !722
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.428", %"struct.gemmlowp::OutputPipelineEvalImpl.428"* %0, i64 0, i32 0, i32 0, i32 2
  %23 = load i32, i32* %22, align 4, !noalias !722
  %24 = zext i32 %23 to i64
  %25 = shl nsw i64 -1, %24
  %26 = trunc i64 %25 to i32
  %27 = xor i32 %26, -1
  %28 = ashr i32 %27, 1
  %29 = icmp ne i32 %20, -2147483648
  br label %30

30:                                               ; preds = %51, %4
  %31 = phi i64 [ 0, %4 ], [ %62, %51 ]
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %5, i64 0, i32 0, i64 %31
  %33 = load i32, i32* %32, align 4, !noalias !722
  %34 = sext i32 %33 to i64
  %35 = mul nsw i64 %34, %18
  %36 = icmp slt i64 %35, 2147483647
  %37 = select i1 %36, i64 %35, i64 2147483647
  %38 = icmp sgt i64 %37, -2147483648
  %39 = select i1 %38, i64 %37, i64 -2147483648
  %40 = trunc i64 %39 to i32
  %41 = icmp ne i32 %20, %40
  %42 = or i1 %29, %41
  br i1 %42, label %43, label %51

43:                                               ; preds = %30
  %44 = select i1 %41, i64 %21, i64 %39
  %45 = mul nsw i64 %44, %39
  %46 = icmp sgt i64 %45, -1
  %47 = select i1 %46, i64 1073741824, i64 -1073741823
  %48 = add nsw i64 %47, %45
  %49 = sdiv i64 %48, 2147483648
  %50 = trunc i64 %49 to i32
  br label %51

51:                                               ; preds = %43, %30
  %52 = phi i32 [ %50, %43 ], [ 2147483647, %30 ]
  %53 = and i32 %52, %27
  %54 = lshr i32 %52, 31
  %55 = add nsw i32 %54, %28
  %56 = ashr i32 %52, %23
  %57 = icmp sgt i32 %53, %55
  %58 = zext i1 %57 to i32
  %59 = add i32 %56, %14
  %60 = add i32 %59, %58
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %6, i64 0, i32 0, i64 %31
  store i32 %60, i32* %61, align 4, !alias.scope !719, !noalias !716
  %62 = add nuw nsw i64 %31, 1
  %63 = icmp eq i64 %62, 8
  br i1 %63, label %64, label %30

64:                                               ; preds = %51
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #18, !noalias !716
  %65 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %6 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %6, i64 0, i32 0, i64 4
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #18, !noalias !716
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.428", %"struct.gemmlowp::OutputPipelineEvalImpl.428"* %0, i64 0, i32 1
  %71 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %7 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %71, align 16
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %7, i64 0, i32 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  store <4 x i32> %69, <4 x i32>* %73, align 16
  %74 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.429"* %70, %"struct.gemmlowp::RegisterBlock.382"* nonnull byval(%"struct.gemmlowp::RegisterBlock.382") align 8 %7, i32 %2, i32 %3)
  ret { i64, i64 } %74
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.429"*, %"struct.gemmlowp::RegisterBlock.382"* byval(%"struct.gemmlowp::RegisterBlock.382") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 0
  %6 = load i32, i32* %5, align 8
  %7 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 3
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 4
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 5
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 6
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 7
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.429", %"struct.gemmlowp::OutputPipelineEvalImpl.429"* %0, i64 0, i32 0, i32 0, i32 0
  %22 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %21, align 8, !noalias !723
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 0
  %24 = load i32, i32* %23, align 4, !noalias !723
  %25 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 1
  %26 = load i32, i32* %25, align 4, !noalias !723
  %27 = icmp slt i32 %6, %24
  %28 = select i1 %27, i32 %24, i32 %6
  %29 = icmp slt i32 %26, %28
  %30 = select i1 %29, i32 %26, i32 %28
  %31 = icmp slt i32 %8, %24
  %32 = select i1 %31, i32 %24, i32 %8
  %33 = icmp slt i32 %26, %32
  %34 = select i1 %33, i32 %26, i32 %32
  %35 = icmp slt i32 %10, %24
  %36 = select i1 %35, i32 %24, i32 %10
  %37 = icmp slt i32 %26, %36
  %38 = select i1 %37, i32 %26, i32 %36
  %39 = icmp slt i32 %12, %24
  %40 = select i1 %39, i32 %24, i32 %12
  %41 = icmp slt i32 %26, %40
  %42 = select i1 %41, i32 %26, i32 %40
  %43 = icmp slt i32 %14, %24
  %44 = select i1 %43, i32 %24, i32 %14
  %45 = icmp slt i32 %26, %44
  %46 = select i1 %45, i32 %26, i32 %44
  %47 = icmp slt i32 %16, %24
  %48 = select i1 %47, i32 %24, i32 %16
  %49 = icmp slt i32 %26, %48
  %50 = select i1 %49, i32 %26, i32 %48
  %51 = icmp slt i32 %18, %24
  %52 = select i1 %51, i32 %24, i32 %18
  %53 = icmp slt i32 %26, %52
  %54 = select i1 %53, i32 %26, i32 %52
  %55 = icmp slt i32 %20, %24
  %56 = select i1 %55, i32 %24, i32 %20
  %57 = icmp slt i32 %26, %56
  %58 = select i1 %57, i32 %26, i32 %56
  %59 = icmp sgt i32 %30, -32768
  %60 = select i1 %59, i32 %30, i32 -32768
  %61 = icmp slt i32 %60, 32767
  %62 = select i1 %61, i32 %60, i32 32767
  %63 = icmp sgt i32 %34, -32768
  %64 = select i1 %63, i32 %34, i32 -32768
  %65 = icmp slt i32 %64, 32767
  %66 = select i1 %65, i32 %64, i32 32767
  %67 = icmp sgt i32 %38, -32768
  %68 = select i1 %67, i32 %38, i32 -32768
  %69 = icmp slt i32 %68, 32767
  %70 = select i1 %69, i32 %68, i32 32767
  %71 = icmp sgt i32 %42, -32768
  %72 = select i1 %71, i32 %42, i32 -32768
  %73 = icmp slt i32 %72, 32767
  %74 = select i1 %73, i32 %72, i32 32767
  %75 = icmp sgt i32 %46, -32768
  %76 = select i1 %75, i32 %46, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = icmp sgt i32 %50, -32768
  %80 = select i1 %79, i32 %50, i32 -32768
  %81 = icmp slt i32 %80, 32767
  %82 = select i1 %81, i32 %80, i32 32767
  %83 = shl nsw i32 %82, 16
  %84 = and i32 %78, 65535
  %85 = or i32 %83, %84
  %86 = zext i32 %85 to i64
  %87 = icmp sgt i32 %54, -32768
  %88 = select i1 %87, i32 %54, i32 -32768
  %89 = icmp slt i32 %88, 32767
  %90 = select i1 %89, i32 %88, i32 32767
  %91 = and i32 %90, 65535
  %92 = zext i32 %91 to i64
  %93 = shl nuw nsw i64 %92, 32
  %94 = icmp sgt i32 %58, -32768
  %95 = select i1 %94, i32 %58, i32 -32768
  %96 = icmp slt i32 %95, 32767
  %97 = select i1 %96, i32 %95, i32 32767
  %98 = zext i32 %97 to i64
  %99 = shl i64 %98, 48
  %100 = or i64 %99, %86
  %101 = or i64 %100, %93
  %102 = zext i32 %74 to i64
  %103 = shl i64 %102, 48
  %104 = and i32 %70, 65535
  %105 = zext i32 %104 to i64
  %106 = shl nuw nsw i64 %105, 32
  %107 = shl nsw i32 %66, 16
  %108 = and i32 %62, 65535
  %109 = or i32 %107, %108
  %110 = zext i32 %109 to i64
  %111 = or i64 %103, %110
  %112 = or i64 %111, %106
  %113 = insertvalue { i64, i64 } undef, i64 %112, 0
  %114 = insertvalue { i64, i64 } %113, i64 %101, 1
  ret { i64, i64 } %114
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.406"*) unnamed_addr #5 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.406"*) unnamed_addr #5 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #17
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.406"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup", align 4
  %9 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !728
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !728
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !728
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !728
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !728
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !728
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #18
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !731
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !731
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !731
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !731
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !731
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !731
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #18
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !734
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !734
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !734
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !734
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !734
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !734
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #18
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup.272"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.406", %"struct.gemmlowp::GemmWithPackedRhsTask.406"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #18
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !737
  %190 = load i32, i32* %115, align 8, !noalias !737
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #18
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #18
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #18
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #18
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #18
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #18
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #18
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #18
  %280 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !740
  store i32 %282, i32* %148, align 4, !alias.scope !740
  store i32 %188, i32* %149, align 4, !alias.scope !740
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #18
  %283 = load %"class.gemmlowp::VectorDup.272"*, %"class.gemmlowp::VectorDup.272"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !743
  store i32 %285, i32* %152, align 4, !alias.scope !743
  store i32 %171, i32* %153, align 4, !alias.scope !743
  %286 = load %"class.std::__1::tuple"*, %"class.std::__1::tuple"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.260"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple"* dereferenceable(40) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #18
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i8* @_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEv(%"struct.gemmlowp::ReferenceKernel"*) unnamed_addr #1 comdat align 2 {
  %2 = tail call i32 (i8*, i64, i8*, ...) @snprintf(i8* getelementptr inbounds ([256 x i8], [256 x i8]* @_ZZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEvE3buf, i64 0, i64 0), i64 256, i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.163, i64 0, i64 0), i32 1, i32 4, i32 16, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.165, i64 0, i64 0), i32 1, i32 16, i32 4, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.165, i64 0, i64 0)) #18
  ret i8* getelementptr inbounds ([256 x i8], [256 x i8]* @_ZZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEvE3buf, i64 0, i64 0)
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE3RunEPimmPKhSB_mm(%"struct.gemmlowp::ReferenceKernel"*, i32*, i64, i64, i8*, i8*, i64, i64) unnamed_addr #1 comdat align 2 {
  %9 = alloca [16 x i32], align 16
  %10 = bitcast [16 x i32]* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %10) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 0, i64 64, i1 false)
  %11 = lshr i64 %7, 4
  %12 = trunc i64 %11 to i32
  %13 = icmp sgt i32 %12, 0
  br i1 %13, label %14, label %48

14:                                               ; preds = %8
  %15 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 3
  %16 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 0
  %17 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 4
  %18 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 8
  %19 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 12
  %20 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 1
  %21 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 5
  %22 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 9
  %23 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 13
  %24 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 2
  %25 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 6
  %26 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 10
  %27 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 14
  %28 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 7
  %29 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 11
  %30 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 15
  %31 = load i32, i32* %16, align 16
  %32 = load i32, i32* %17, align 16
  %33 = load i32, i32* %18, align 16
  %34 = load i32, i32* %19, align 16
  %35 = load i32, i32* %20, align 4
  %36 = load i32, i32* %21, align 4
  %37 = load i32, i32* %22, align 4
  %38 = load i32, i32* %23, align 4
  %39 = load i32, i32* %24, align 8
  %40 = load i32, i32* %25, align 8
  %41 = load i32, i32* %26, align 8
  %42 = load i32, i32* %27, align 8
  %43 = load i32, i32* %15, align 4
  %44 = load i32, i32* %28, align 4
  %45 = load i32, i32* %29, align 4
  %46 = load i32, i32* %30, align 4
  br label %201

47:                                               ; preds = %326
  store i32 %331, i32* %16, align 16
  store i32 %336, i32* %17, align 16
  store i32 %341, i32* %18, align 16
  store i32 %346, i32* %19, align 16
  store i32 %351, i32* %20, align 4
  store i32 %356, i32* %21, align 4
  store i32 %361, i32* %22, align 4
  store i32 %366, i32* %23, align 4
  store i32 %371, i32* %24, align 8
  store i32 %376, i32* %25, align 8
  store i32 %381, i32* %26, align 8
  store i32 %386, i32* %27, align 8
  store i32 %391, i32* %15, align 4
  store i32 %396, i32* %28, align 4
  store i32 %401, i32* %29, align 4
  store i32 %406, i32* %30, align 4
  br label %48

48:                                               ; preds = %47, %8
  %49 = phi i32 [ 0, %8 ], [ %406, %47 ]
  %50 = icmp eq i64 %6, 0
  %51 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 0
  %52 = load i32, i32* %51, align 16
  br i1 %50, label %144, label %53

53:                                               ; preds = %48
  %54 = load i32, i32* %1, align 4
  %55 = add nsw i32 %54, %52
  store i32 %55, i32* %1, align 4
  %56 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 4
  %57 = load i32, i32* %56, align 16
  %58 = getelementptr inbounds i32, i32* %1, i64 %3
  %59 = load i32, i32* %58, align 4
  %60 = add nsw i32 %59, %57
  store i32 %60, i32* %58, align 4
  %61 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 8
  %62 = load i32, i32* %61, align 16
  %63 = shl i64 %3, 1
  %64 = getelementptr inbounds i32, i32* %1, i64 %63
  %65 = load i32, i32* %64, align 4
  %66 = add nsw i32 %65, %62
  store i32 %66, i32* %64, align 4
  %67 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 12
  %68 = load i32, i32* %67, align 16
  %69 = mul i64 %3, 3
  %70 = getelementptr inbounds i32, i32* %1, i64 %69
  %71 = load i32, i32* %70, align 4
  %72 = add nsw i32 %71, %68
  store i32 %72, i32* %70, align 4
  %73 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 1
  %74 = load i32, i32* %73, align 4
  %75 = getelementptr inbounds i32, i32* %1, i64 %2
  %76 = load i32, i32* %75, align 4
  %77 = add nsw i32 %76, %74
  store i32 %77, i32* %75, align 4
  %78 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 5
  %79 = load i32, i32* %78, align 4
  %80 = add i64 %3, %2
  %81 = getelementptr inbounds i32, i32* %1, i64 %80
  %82 = load i32, i32* %81, align 4
  %83 = add nsw i32 %82, %79
  store i32 %83, i32* %81, align 4
  %84 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 9
  %85 = load i32, i32* %84, align 4
  %86 = add i64 %63, %2
  %87 = getelementptr inbounds i32, i32* %1, i64 %86
  %88 = load i32, i32* %87, align 4
  %89 = add nsw i32 %88, %85
  store i32 %89, i32* %87, align 4
  %90 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 13
  %91 = load i32, i32* %90, align 4
  %92 = add i64 %69, %2
  %93 = getelementptr inbounds i32, i32* %1, i64 %92
  %94 = load i32, i32* %93, align 4
  %95 = add nsw i32 %94, %91
  store i32 %95, i32* %93, align 4
  %96 = shl i64 %2, 1
  %97 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 2
  %98 = load i32, i32* %97, align 8
  %99 = getelementptr inbounds i32, i32* %1, i64 %96
  %100 = load i32, i32* %99, align 4
  %101 = add nsw i32 %100, %98
  store i32 %101, i32* %99, align 4
  %102 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 6
  %103 = load i32, i32* %102, align 8
  %104 = add i64 %96, %3
  %105 = getelementptr inbounds i32, i32* %1, i64 %104
  %106 = load i32, i32* %105, align 4
  %107 = add nsw i32 %106, %103
  store i32 %107, i32* %105, align 4
  %108 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 10
  %109 = load i32, i32* %108, align 8
  %110 = add i64 %63, %96
  %111 = getelementptr inbounds i32, i32* %1, i64 %110
  %112 = load i32, i32* %111, align 4
  %113 = add nsw i32 %112, %109
  store i32 %113, i32* %111, align 4
  %114 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 14
  %115 = load i32, i32* %114, align 8
  %116 = add i64 %69, %96
  %117 = getelementptr inbounds i32, i32* %1, i64 %116
  %118 = load i32, i32* %117, align 4
  %119 = add nsw i32 %118, %115
  store i32 %119, i32* %117, align 4
  %120 = mul i64 %2, 3
  %121 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 3
  %122 = load i32, i32* %121, align 4
  %123 = getelementptr inbounds i32, i32* %1, i64 %120
  %124 = load i32, i32* %123, align 4
  %125 = add nsw i32 %124, %122
  store i32 %125, i32* %123, align 4
  %126 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 7
  %127 = load i32, i32* %126, align 4
  %128 = add i64 %120, %3
  %129 = getelementptr inbounds i32, i32* %1, i64 %128
  %130 = load i32, i32* %129, align 4
  %131 = add nsw i32 %130, %127
  store i32 %131, i32* %129, align 4
  %132 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 11
  %133 = load i32, i32* %132, align 4
  %134 = add i64 %63, %120
  %135 = getelementptr inbounds i32, i32* %1, i64 %134
  %136 = load i32, i32* %135, align 4
  %137 = add nsw i32 %136, %133
  store i32 %137, i32* %135, align 4
  %138 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 15
  %139 = load i32, i32* %138, align 4
  %140 = add i64 %69, %120
  %141 = getelementptr inbounds i32, i32* %1, i64 %140
  %142 = load i32, i32* %141, align 4
  %143 = add nsw i32 %142, %139
  store i32 %143, i32* %141, align 4
  br label %409

144:                                              ; preds = %48
  store i32 %52, i32* %1, align 4
  %145 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 4
  %146 = load i32, i32* %145, align 16
  %147 = getelementptr inbounds i32, i32* %1, i64 %3
  store i32 %146, i32* %147, align 4
  %148 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 8
  %149 = load i32, i32* %148, align 16
  %150 = shl i64 %3, 1
  %151 = getelementptr inbounds i32, i32* %1, i64 %150
  store i32 %149, i32* %151, align 4
  %152 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 12
  %153 = load i32, i32* %152, align 16
  %154 = mul i64 %3, 3
  %155 = getelementptr inbounds i32, i32* %1, i64 %154
  store i32 %153, i32* %155, align 4
  %156 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 1
  %157 = load i32, i32* %156, align 4
  %158 = getelementptr inbounds i32, i32* %1, i64 %2
  store i32 %157, i32* %158, align 4
  %159 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 5
  %160 = load i32, i32* %159, align 4
  %161 = add i64 %3, %2
  %162 = getelementptr inbounds i32, i32* %1, i64 %161
  store i32 %160, i32* %162, align 4
  %163 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 9
  %164 = load i32, i32* %163, align 4
  %165 = add i64 %150, %2
  %166 = getelementptr inbounds i32, i32* %1, i64 %165
  store i32 %164, i32* %166, align 4
  %167 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 13
  %168 = load i32, i32* %167, align 4
  %169 = add i64 %154, %2
  %170 = getelementptr inbounds i32, i32* %1, i64 %169
  store i32 %168, i32* %170, align 4
  %171 = shl i64 %2, 1
  %172 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 2
  %173 = load i32, i32* %172, align 8
  %174 = getelementptr inbounds i32, i32* %1, i64 %171
  store i32 %173, i32* %174, align 4
  %175 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 6
  %176 = load i32, i32* %175, align 8
  %177 = add i64 %171, %3
  %178 = getelementptr inbounds i32, i32* %1, i64 %177
  store i32 %176, i32* %178, align 4
  %179 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 10
  %180 = load i32, i32* %179, align 8
  %181 = add i64 %150, %171
  %182 = getelementptr inbounds i32, i32* %1, i64 %181
  store i32 %180, i32* %182, align 4
  %183 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 14
  %184 = load i32, i32* %183, align 8
  %185 = add i64 %154, %171
  %186 = getelementptr inbounds i32, i32* %1, i64 %185
  store i32 %184, i32* %186, align 4
  %187 = mul i64 %2, 3
  %188 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 3
  %189 = load i32, i32* %188, align 4
  %190 = getelementptr inbounds i32, i32* %1, i64 %187
  store i32 %189, i32* %190, align 4
  %191 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 7
  %192 = load i32, i32* %191, align 4
  %193 = add i64 %187, %3
  %194 = getelementptr inbounds i32, i32* %1, i64 %193
  store i32 %192, i32* %194, align 4
  %195 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 11
  %196 = load i32, i32* %195, align 4
  %197 = add i64 %150, %187
  %198 = getelementptr inbounds i32, i32* %1, i64 %197
  store i32 %196, i32* %198, align 4
  %199 = add i64 %154, %187
  %200 = getelementptr inbounds i32, i32* %1, i64 %199
  store i32 %49, i32* %200, align 4
  br label %409

201:                                              ; preds = %326, %14
  %202 = phi i32 [ %406, %326 ], [ %46, %14 ]
  %203 = phi i32 [ %401, %326 ], [ %45, %14 ]
  %204 = phi i32 [ %396, %326 ], [ %44, %14 ]
  %205 = phi i32 [ %391, %326 ], [ %43, %14 ]
  %206 = phi i32 [ %386, %326 ], [ %42, %14 ]
  %207 = phi i32 [ %381, %326 ], [ %41, %14 ]
  %208 = phi i32 [ %376, %326 ], [ %40, %14 ]
  %209 = phi i32 [ %371, %326 ], [ %39, %14 ]
  %210 = phi i32 [ %366, %326 ], [ %38, %14 ]
  %211 = phi i32 [ %361, %326 ], [ %37, %14 ]
  %212 = phi i32 [ %356, %326 ], [ %36, %14 ]
  %213 = phi i32 [ %351, %326 ], [ %35, %14 ]
  %214 = phi i32 [ %346, %326 ], [ %34, %14 ]
  %215 = phi i32 [ %341, %326 ], [ %33, %14 ]
  %216 = phi i32 [ %336, %326 ], [ %32, %14 ]
  %217 = phi i32 [ %331, %326 ], [ %31, %14 ]
  %218 = phi i32 [ %407, %326 ], [ 0, %14 ]
  %219 = shl nsw i32 %218, 6
  %220 = zext i32 %219 to i64
  %221 = getelementptr inbounds i8, i8* %4, i64 %220
  %222 = getelementptr inbounds i8, i8* %5, i64 %220
  %223 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %202, i32 0
  %224 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %203, i32 0
  %225 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %204, i32 0
  %226 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %205, i32 0
  %227 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %206, i32 0
  %228 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %207, i32 0
  %229 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %208, i32 0
  %230 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %209, i32 0
  %231 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %210, i32 0
  %232 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %211, i32 0
  %233 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %212, i32 0
  %234 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %213, i32 0
  %235 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %214, i32 0
  %236 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %215, i32 0
  %237 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %216, i32 0
  %238 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %217, i32 0
  br label %239

239:                                              ; preds = %239, %201
  %240 = phi i64 [ 0, %201 ], [ %324, %239 ]
  %241 = phi <4 x i32> [ %223, %201 ], [ %323, %239 ]
  %242 = phi <4 x i32> [ %224, %201 ], [ %321, %239 ]
  %243 = phi <4 x i32> [ %225, %201 ], [ %319, %239 ]
  %244 = phi <4 x i32> [ %226, %201 ], [ %317, %239 ]
  %245 = phi <4 x i32> [ %227, %201 ], [ %311, %239 ]
  %246 = phi <4 x i32> [ %228, %201 ], [ %309, %239 ]
  %247 = phi <4 x i32> [ %229, %201 ], [ %307, %239 ]
  %248 = phi <4 x i32> [ %230, %201 ], [ %305, %239 ]
  %249 = phi <4 x i32> [ %231, %201 ], [ %299, %239 ]
  %250 = phi <4 x i32> [ %232, %201 ], [ %297, %239 ]
  %251 = phi <4 x i32> [ %233, %201 ], [ %295, %239 ]
  %252 = phi <4 x i32> [ %234, %201 ], [ %293, %239 ]
  %253 = phi <4 x i32> [ %235, %201 ], [ %287, %239 ]
  %254 = phi <4 x i32> [ %236, %201 ], [ %280, %239 ]
  %255 = phi <4 x i32> [ %237, %201 ], [ %273, %239 ]
  %256 = phi <4 x i32> [ %238, %201 ], [ %266, %239 ]
  %257 = getelementptr inbounds i8, i8* %222, i64 %240
  %258 = getelementptr inbounds i8, i8* %221, i64 %240
  %259 = bitcast i8* %258 to <4 x i8>*
  %260 = load <4 x i8>, <4 x i8>* %259, align 1
  %261 = zext <4 x i8> %260 to <4 x i32>
  %262 = bitcast i8* %257 to <4 x i8>*
  %263 = load <4 x i8>, <4 x i8>* %262, align 1
  %264 = zext <4 x i8> %263 to <4 x i32>
  %265 = mul nuw nsw <4 x i32> %264, %261
  %266 = add nsw <4 x i32> %265, %256
  %267 = add nuw nsw i64 %240, 16
  %268 = getelementptr inbounds i8, i8* %222, i64 %267
  %269 = bitcast i8* %268 to <4 x i8>*
  %270 = load <4 x i8>, <4 x i8>* %269, align 1
  %271 = zext <4 x i8> %270 to <4 x i32>
  %272 = mul nuw nsw <4 x i32> %271, %261
  %273 = add nsw <4 x i32> %272, %255
  %274 = add nuw nsw i64 %240, 32
  %275 = getelementptr inbounds i8, i8* %222, i64 %274
  %276 = bitcast i8* %275 to <4 x i8>*
  %277 = load <4 x i8>, <4 x i8>* %276, align 1
  %278 = zext <4 x i8> %277 to <4 x i32>
  %279 = mul nuw nsw <4 x i32> %278, %261
  %280 = add nsw <4 x i32> %279, %254
  %281 = add nuw nsw i64 %240, 48
  %282 = getelementptr inbounds i8, i8* %222, i64 %281
  %283 = bitcast i8* %282 to <4 x i8>*
  %284 = load <4 x i8>, <4 x i8>* %283, align 1
  %285 = zext <4 x i8> %284 to <4 x i32>
  %286 = mul nuw nsw <4 x i32> %285, %261
  %287 = add nsw <4 x i32> %286, %253
  %288 = getelementptr inbounds i8, i8* %221, i64 %267
  %289 = bitcast i8* %288 to <4 x i8>*
  %290 = load <4 x i8>, <4 x i8>* %289, align 1
  %291 = zext <4 x i8> %290 to <4 x i32>
  %292 = mul nuw nsw <4 x i32> %264, %291
  %293 = add nsw <4 x i32> %292, %252
  %294 = mul nuw nsw <4 x i32> %271, %291
  %295 = add nsw <4 x i32> %294, %251
  %296 = mul nuw nsw <4 x i32> %278, %291
  %297 = add nsw <4 x i32> %296, %250
  %298 = mul nuw nsw <4 x i32> %285, %291
  %299 = add nsw <4 x i32> %298, %249
  %300 = getelementptr inbounds i8, i8* %221, i64 %274
  %301 = bitcast i8* %300 to <4 x i8>*
  %302 = load <4 x i8>, <4 x i8>* %301, align 1
  %303 = zext <4 x i8> %302 to <4 x i32>
  %304 = mul nuw nsw <4 x i32> %264, %303
  %305 = add nsw <4 x i32> %304, %248
  %306 = mul nuw nsw <4 x i32> %271, %303
  %307 = add nsw <4 x i32> %306, %247
  %308 = mul nuw nsw <4 x i32> %278, %303
  %309 = add nsw <4 x i32> %308, %246
  %310 = mul nuw nsw <4 x i32> %285, %303
  %311 = add nsw <4 x i32> %310, %245
  %312 = getelementptr inbounds i8, i8* %221, i64 %281
  %313 = bitcast i8* %312 to <4 x i8>*
  %314 = load <4 x i8>, <4 x i8>* %313, align 1
  %315 = zext <4 x i8> %314 to <4 x i32>
  %316 = mul nuw nsw <4 x i32> %264, %315
  %317 = add nsw <4 x i32> %316, %244
  %318 = mul nuw nsw <4 x i32> %271, %315
  %319 = add nsw <4 x i32> %318, %243
  %320 = mul nuw nsw <4 x i32> %278, %315
  %321 = add nsw <4 x i32> %320, %242
  %322 = mul nuw nsw <4 x i32> %285, %315
  %323 = add nsw <4 x i32> %322, %241
  %324 = add i64 %240, 4
  %325 = icmp eq i64 %324, 16
  br i1 %325, label %326, label %239, !llvm.loop !746

326:                                              ; preds = %239
  %327 = shufflevector <4 x i32> %266, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %328 = add <4 x i32> %266, %327
  %329 = shufflevector <4 x i32> %328, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %330 = add <4 x i32> %328, %329
  %331 = extractelement <4 x i32> %330, i32 0
  %332 = shufflevector <4 x i32> %273, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %333 = add <4 x i32> %273, %332
  %334 = shufflevector <4 x i32> %333, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %335 = add <4 x i32> %333, %334
  %336 = extractelement <4 x i32> %335, i32 0
  %337 = shufflevector <4 x i32> %280, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %338 = add <4 x i32> %280, %337
  %339 = shufflevector <4 x i32> %338, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %340 = add <4 x i32> %338, %339
  %341 = extractelement <4 x i32> %340, i32 0
  %342 = shufflevector <4 x i32> %287, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %343 = add <4 x i32> %287, %342
  %344 = shufflevector <4 x i32> %343, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %345 = add <4 x i32> %343, %344
  %346 = extractelement <4 x i32> %345, i32 0
  %347 = shufflevector <4 x i32> %293, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %348 = add <4 x i32> %293, %347
  %349 = shufflevector <4 x i32> %348, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %350 = add <4 x i32> %348, %349
  %351 = extractelement <4 x i32> %350, i32 0
  %352 = shufflevector <4 x i32> %295, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %353 = add <4 x i32> %295, %352
  %354 = shufflevector <4 x i32> %353, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %355 = add <4 x i32> %353, %354
  %356 = extractelement <4 x i32> %355, i32 0
  %357 = shufflevector <4 x i32> %297, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %358 = add <4 x i32> %297, %357
  %359 = shufflevector <4 x i32> %358, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %360 = add <4 x i32> %358, %359
  %361 = extractelement <4 x i32> %360, i32 0
  %362 = shufflevector <4 x i32> %299, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %363 = add <4 x i32> %299, %362
  %364 = shufflevector <4 x i32> %363, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %365 = add <4 x i32> %363, %364
  %366 = extractelement <4 x i32> %365, i32 0
  %367 = shufflevector <4 x i32> %305, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %368 = add <4 x i32> %305, %367
  %369 = shufflevector <4 x i32> %368, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %370 = add <4 x i32> %368, %369
  %371 = extractelement <4 x i32> %370, i32 0
  %372 = shufflevector <4 x i32> %307, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %373 = add <4 x i32> %307, %372
  %374 = shufflevector <4 x i32> %373, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %375 = add <4 x i32> %373, %374
  %376 = extractelement <4 x i32> %375, i32 0
  %377 = shufflevector <4 x i32> %309, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %378 = add <4 x i32> %309, %377
  %379 = shufflevector <4 x i32> %378, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %380 = add <4 x i32> %378, %379
  %381 = extractelement <4 x i32> %380, i32 0
  %382 = shufflevector <4 x i32> %311, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %383 = add <4 x i32> %311, %382
  %384 = shufflevector <4 x i32> %383, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %385 = add <4 x i32> %383, %384
  %386 = extractelement <4 x i32> %385, i32 0
  %387 = shufflevector <4 x i32> %317, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %388 = add <4 x i32> %317, %387
  %389 = shufflevector <4 x i32> %388, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %390 = add <4 x i32> %388, %389
  %391 = extractelement <4 x i32> %390, i32 0
  %392 = shufflevector <4 x i32> %319, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %393 = add <4 x i32> %319, %392
  %394 = shufflevector <4 x i32> %393, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %395 = add <4 x i32> %393, %394
  %396 = extractelement <4 x i32> %395, i32 0
  %397 = shufflevector <4 x i32> %321, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %398 = add <4 x i32> %321, %397
  %399 = shufflevector <4 x i32> %398, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %400 = add <4 x i32> %398, %399
  %401 = extractelement <4 x i32> %400, i32 0
  %402 = shufflevector <4 x i32> %323, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %403 = add <4 x i32> %323, %402
  %404 = shufflevector <4 x i32> %403, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %405 = add <4 x i32> %403, %404
  %406 = extractelement <4 x i32> %405, i32 0
  %407 = add nuw nsw i32 %218, 1
  %408 = icmp eq i32 %407, %12
  br i1 %408, label %47, label %201

409:                                              ; preds = %53, %144
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %10) #18
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEED0Ev(%"struct.gemmlowp::DefaultKernel"*) unnamed_addr #5 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::DefaultKernel"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #17
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp10KernelBaseD2Ev(%"struct.gemmlowp::KernelBase"*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nofree nounwind
declare i32 @snprintf(i8* nocapture, i64, i8* nocapture readonly, ...) local_unnamed_addr #12

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.std::__1::tuple.265"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.273", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.258", align 8
  %11 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %12 = alloca %"class.gemmlowp::VectorDup", align 4
  %13 = alloca %"class.std::__1::tuple.265", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %93, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %89

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.273"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #18
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.260"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.273"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !747
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !747
  %38 = bitcast %"class.gemmlowp::MatrixMap.273"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !747
  store i32 %18, i32* %30, align 8, !alias.scope !747
  store i32 %16, i32* %31, align 4, !alias.scope !747
  store i32 %37, i32* %32, align 8, !alias.scope !747
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #18
  %40 = bitcast %"class.gemmlowp::MatrixMap.258"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !752
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !752
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !752
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !752
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !752
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !752
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !752
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !752
  %52 = bitcast %"class.gemmlowp::MatrixMap.258"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #18
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !757
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !757
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !757
  %59 = bitcast %"class.gemmlowp::MatrixMap.258"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !757
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !757
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !757
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !757
  %63 = bitcast %"class.gemmlowp::VectorDup.272"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #18
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !762
  store i32 %66, i32* %64, align 4, !alias.scope !762
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !762
  store i32 %69, i32* %67, align 4, !alias.scope !762
  %70 = bitcast %"class.gemmlowp::VectorDup"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #18
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !767
  store i32 %73, i32* %71, align 4, !alias.scope !767
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !767
  store i32 %76, i32* %74, align 4, !alias.scope !767
  %77 = bitcast %"class.std::__1::tuple.265"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %77) #18
  %78 = bitcast %"class.std::__1::tuple.265"* %6 to i64*
  %79 = load i64, i64* %78, align 4, !noalias !772
  %80 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %6, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = load i32, i32* %80, align 4, !noalias !772
  %82 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageClamp"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !772
  %85 = bitcast %"class.std::__1::tuple.265"* %13 to i64*
  store i64 %79, i64* %85, align 8, !alias.scope !772
  %86 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %81, i32* %86, align 8, !alias.scope !772
  %87 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %13, i64 0, i32 0, i32 1
  %88 = bitcast %"class.std::__1::__tuple_leaf.268"* %87 to i64*
  store i64 %84, i64* %88, align 4, !alias.scope !775
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.258"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.273"* nonnull %8, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.265"* nonnull dereferenceable(20) %13)
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %77) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #18
  br label %93

89:                                               ; preds = %26
  %90 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %90) #18
  %91 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %91, align 8
  %92 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %92, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.258"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.260"* %3, %"class.gemmlowp::VectorDup"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %5, %"class.std::__1::tuple.265"* dereferenceable(20) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %90) #18
  br label %93

93:                                               ; preds = %7, %89, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.265"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.260", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.258", align 8
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %13 = alloca %"class.std::__1::tuple.265", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %93, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %89

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.260"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #18
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.273"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.260"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !778
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !778
  %38 = bitcast %"class.gemmlowp::MatrixMap.260"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !778
  store i32 %18, i32* %30, align 8, !alias.scope !778
  store i32 %16, i32* %31, align 4, !alias.scope !778
  store i32 %37, i32* %32, align 8, !alias.scope !778
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #18
  %40 = bitcast %"class.gemmlowp::MatrixMap.258"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !783
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !783
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !783
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !783
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !783
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !783
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !783
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !783
  %52 = bitcast %"class.gemmlowp::MatrixMap.258"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #18
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !788
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !788
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !788
  %59 = bitcast %"class.gemmlowp::MatrixMap.258"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !788
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !788
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !788
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !788
  %63 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #18
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !793
  store i32 %66, i32* %64, align 4, !alias.scope !793
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !793
  store i32 %69, i32* %67, align 4, !alias.scope !793
  %70 = bitcast %"class.gemmlowp::VectorDup.272"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #18
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !798
  store i32 %73, i32* %71, align 4, !alias.scope !798
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !798
  store i32 %76, i32* %74, align 4, !alias.scope !798
  %77 = bitcast %"class.std::__1::tuple.265"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %77) #18
  %78 = bitcast %"class.std::__1::tuple.265"* %6 to i64*
  %79 = load i64, i64* %78, align 4, !noalias !803
  %80 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %6, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = load i32, i32* %80, align 4, !noalias !803
  %82 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageClamp"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !803
  %85 = bitcast %"class.std::__1::tuple.265"* %13 to i64*
  store i64 %79, i64* %85, align 8, !alias.scope !803
  %86 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %81, i32* %86, align 8, !alias.scope !803
  %87 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %13, i64 0, i32 0, i32 1
  %88 = bitcast %"class.std::__1::__tuple_leaf.268"* %87 to i64*
  store i64 %84, i64* %88, align 4, !alias.scope !806
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.258"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.260"* nonnull %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.265"* nonnull dereferenceable(20) %13)
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %77) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #18
  br label %93

89:                                               ; preds = %26
  %90 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %90) #18
  %91 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %91, align 8
  %92 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %92, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.258"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.273"* %3, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.std::__1::tuple.265"* dereferenceable(20) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %90) #18
  br label %93

93:                                               ; preds = %7, %89, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.std::__1::tuple.265"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.283", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !400

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #18
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #18
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #18
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #18
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.258"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.260"* %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.std::__1::tuple.265"* dereferenceable(20) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #18
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !809
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !809
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !809
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !809
  %101 = load i64, i64* %95, align 8, !noalias !809
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !809
  %103 = load i64, i64* %93, align 8, !noalias !809
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !809
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #18
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !812
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !812
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !812
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !812
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #18
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.283"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.260"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.283"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #18
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !815
  %162 = load i32, i32* %128, align 8, !noalias !815
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #18
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #18
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #18
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #18
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.283"* nonnull dereferenceable(24) %13) #18
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #17
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #18
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !818
  %192 = load i32, i32* %143, align 8, !noalias !818
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #17
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #18
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %5, %"class.gemmlowp::VectorDup"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup.272"**
  store %"class.gemmlowp::VectorDup.272"* %6, %"class.gemmlowp::VectorDup.272"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.265"**
  store %"class.std::__1::tuple.265"* %7, %"class.std::__1::tuple.265"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.283"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #19
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #19
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #17
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #18
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #17
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.265"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.283", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !400

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #18
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #18
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #18
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #18
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.258"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.273"* %4, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.std::__1::tuple.265"* dereferenceable(20) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #18
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !821
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !821
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !821
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !821
  %101 = load i64, i64* %95, align 8, !noalias !821
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !821
  %103 = load i64, i64* %93, align 8, !noalias !821
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !821
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #18
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !824
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !824
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !824
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !824
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #18
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.283"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.283", %"class.std::__1::vector.283"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.273"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.283"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #18
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !827
  %162 = load i32, i32* %128, align 8, !noalias !827
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #18
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #18
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #18
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #18
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.283"* nonnull dereferenceable(24) %13) #18
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #17
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #18
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !830
  %192 = load i32, i32* %143, align 8, !noalias !830
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #17
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #18
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup.272"**
  store %"class.gemmlowp::VectorDup.272"* %5, %"class.gemmlowp::VectorDup.272"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %6, %"class.gemmlowp::VectorDup"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.265"**
  store %"class.std::__1::tuple.265"* %7, %"class.std::__1::tuple.265"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.283"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #19
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #19
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #17
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #18
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #17
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.265"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %22 = alloca %"class.gemmlowp::VectorDup", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #18
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !833
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !833
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !833
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !833
  %67 = load i64, i64* %61, align 8, !noalias !833
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !833
  %69 = load i64, i64* %59, align 8, !noalias !833
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !833
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #18
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !836
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !836
  %82 = load i64, i64* %61, align 8, !noalias !836
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !836
  %84 = load i64, i64* %59, align 8, !noalias !836
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !836
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #18
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !839
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !839
  %106 = load i64, i64* %61, align 8, !noalias !839
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !839
  %108 = load i64, i64* %59, align 8, !noalias !839
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !839
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #18
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !842
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !842
  %121 = load i64, i64* %61, align 8, !noalias !842
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !842
  %123 = load i64, i64* %59, align 8, !noalias !842
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !842
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #18
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !845
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !845
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !845
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !845
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #18
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #18
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.258"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #18
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #18
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #18
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup.272"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #18
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !848
  %228 = load i32, i32* %173, align 8, !noalias !848
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #18
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #18
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #18
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !851
  %247 = load i32, i32* %184, align 8, !noalias !851
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #18
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #18
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #18
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #18
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #18
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #18
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #18
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #18
  %332 = load i32, i32* %208, align 4, !noalias !854
  store i32 %332, i32* %209, align 4, !alias.scope !854
  store i32 %226, i32* %210, align 4, !alias.scope !854
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #18
  %333 = load i32, i32* %212, align 4, !noalias !857
  store i32 %333, i32* %213, align 4, !alias.scope !857
  store i32 %244, i32* %214, align 4, !alias.scope !857
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.273"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.265"* dereferenceable(20) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #18
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.273"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.265"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.gemmlowp::RegisterBlock", align 8
  %11 = alloca %"class.gemmlowp::MatrixMap.292", align 8
  %12 = alloca %"class.gemmlowp::VectorMap", align 8
  %13 = alloca %"class.gemmlowp::VectorMap.279", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.471", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.478", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.485", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.492", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.499", align 8
  %19 = alloca [64 x i16], align 16
  %20 = alloca %"class.gemmlowp::MatrixMap.260", align 8
  %21 = bitcast %"class.gemmlowp::MatrixMap.292"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %21) #18
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 0
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 1
  %24 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 2
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %11, i64 0, i32 3
  %26 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %27 = bitcast %"class.gemmlowp::MatrixMap.292"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %27, i8 -86, i64 24, i1 false)
  %28 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %26, align 8, !noalias !860
  %29 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %30 = load i8, i8* %29, align 8, !noalias !860
  %31 = zext i8 %30 to i64
  %32 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %28, i64 0, i32 5, i64 %31
  %33 = load i64, i64* %32, align 8, !noalias !860
  %34 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %28, i64 0, i32 2
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !860
  %37 = add i64 %36, %33
  %38 = inttoptr i64 %37 to i32*
  %39 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %40 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %39, align 8, !noalias !860
  %41 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %40, i64 0, i32 3
  %42 = load i32, i32* %41, align 4, !noalias !860
  %43 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %40, i64 0, i32 4
  %44 = load i32, i32* %43, align 4, !noalias !860
  store i32* %38, i32** %22, align 8, !alias.scope !860
  store i32 %42, i32* %23, align 8, !alias.scope !860
  store i32 %44, i32* %24, align 4, !alias.scope !860
  store i32 %42, i32* %25, align 8, !alias.scope !860
  %45 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %45) #18
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 0
  %47 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 1
  %48 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %49 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 16, i1 false)
  %50 = load i32, i32* %48, align 4
  store i32* %4, i32** %46, align 8
  store i32 %50, i32* %47, align 8
  %51 = bitcast %"class.gemmlowp::VectorMap.279"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %51) #18
  %52 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %13, i64 0, i32 0
  %53 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %13, i64 0, i32 1
  %54 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %55 = bitcast %"class.gemmlowp::VectorMap.279"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %55, i8 -86, i64 16, i1 false)
  %56 = load i32, i32* %54, align 4
  store i32* %5, i32** %52, align 8
  store i32 %56, i32* %53, align 8
  %57 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 0, i32 0
  %58 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 0, i32 0, i32 1
  %59 = load i32, i32* %58, align 4
  %60 = icmp sgt i32 %59, 0
  %61 = select i1 %60, i32 %59, i32 0
  %62 = sub nsw i32 0, %59
  %63 = icmp sgt i32 %62, 0
  %64 = select i1 %63, i32 %62, i32 0
  %65 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 1, i32 0
  %66 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.471"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %66) #18
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  %68 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %14, i64 0, i32 0, i32 0, i32 0, i32 1
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %14, i64 0, i32 0, i32 0, i32 0, i32 2
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %71 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %72 = bitcast i8* %71 to i64*
  store i64 -6148914691236517206, i64* %72, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %67, align 8
  store i32 %61, i32* %68, align 8
  store i32 %64, i32* %69, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %70, align 8
  %73 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.478"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %73) #18
  %74 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %15, i64 0, i32 0, i32 0, i32 0, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %15, i64 0, i32 0, i32 0, i32 0, i32 1
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %15, i64 0, i32 0, i32 0, i32 0, i32 2
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %79 = bitcast i8* %78 to i64*
  store i64 -6148914691236517206, i64* %79, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %74, align 8
  store i32 %61, i32* %75, align 8
  store i32 %64, i32* %76, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %77, align 8
  %80 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.485"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %80) #18
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %16, i64 0, i32 0, i32 0, i32 0, i32 0
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %16, i64 0, i32 0, i32 0, i32 0, i32 1
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %16, i64 0, i32 0, i32 0, i32 0, i32 2
  %84 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %86 = bitcast i8* %85 to i64*
  store i64 -6148914691236517206, i64* %86, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %81, align 8
  store i32 %61, i32* %82, align 8
  store i32 %64, i32* %83, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %84, align 8
  %87 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.492"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %87) #18
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %90 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %92 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %93 = bitcast i8* %92 to i64*
  store i64 -6148914691236517206, i64* %93, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %88, align 8
  store i32 %61, i32* %89, align 8
  store i32 %64, i32* %90, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %91, align 8
  %94 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.499"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %94) #18
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %18, i64 0, i32 0, i32 0, i32 0, i32 0
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %18, i64 0, i32 0, i32 0, i32 0, i32 1
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %18, i64 0, i32 0, i32 0, i32 0, i32 2
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %99 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %100 = bitcast i8* %99 to i64*
  store i64 -6148914691236517206, i64* %100, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %95, align 8
  store i32 %61, i32* %96, align 8
  store i32 %64, i32* %97, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %101 = load i32, i32* %54, align 4
  %102 = icmp slt i32 %101, 8
  br i1 %102, label %116, label %103

103:                                              ; preds = %9
  %104 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %105 = bitcast [64 x i16]* %19 to i8*
  %106 = bitcast %"class.gemmlowp::MatrixMap.260"* %20 to i8*
  %107 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %20, i64 0, i32 0
  %108 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %20, i64 0, i32 1
  %109 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %20, i64 0, i32 2
  %110 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %20, i64 0, i32 3
  %111 = getelementptr inbounds [64 x i16], [64 x i16]* %19, i64 0, i64 0
  %112 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %113 = bitcast %"struct.gemmlowp::RegisterBlock"* %10 to i8*
  %114 = load i32, i32* %48, align 4
  %115 = bitcast %"class.gemmlowp::MatrixMap.260"* %20 to i8*
  br label %125

116:                                              ; preds = %287, %9
  %117 = phi i32 [ %101, %9 ], [ %290, %287 ]
  %118 = phi i32 [ 0, %9 ], [ %289, %287 ]
  %119 = add nsw i32 %117, -4
  %120 = icmp sgt i32 %118, %119
  br i1 %120, label %293, label %121

121:                                              ; preds = %116
  %122 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %123 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %124 = load i32, i32* %48, align 4
  br label %317

125:                                              ; preds = %103, %287
  %126 = phi i32 [ %114, %103 ], [ %288, %287 ]
  %127 = phi i32 [ 0, %103 ], [ %289, %287 ]
  %128 = load i32*, i32** %22, align 8
  %129 = load i32, i32* %25, align 8
  %130 = mul nsw i32 %129, %127
  %131 = sext i32 %130 to i64
  %132 = load i32*, i32** %46, align 8
  %133 = bitcast i32* %132 to i8*
  call void @llvm.prefetch(i8* %133, i32 0, i32 3, i32 1) #18
  %134 = getelementptr inbounds i32, i32* %132, i64 4
  %135 = bitcast i32* %134 to i8*
  call void @llvm.prefetch(i8* %135, i32 0, i32 3, i32 1) #18
  %136 = getelementptr inbounds i32, i32* %128, i64 %131
  %137 = sext i32 %129 to i64
  %138 = bitcast i32* %136 to i8*
  call void @llvm.prefetch(i8* %138, i32 0, i32 3, i32 1) #18
  %139 = getelementptr inbounds i32, i32* %136, i64 4
  %140 = bitcast i32* %139 to i8*
  call void @llvm.prefetch(i8* %140, i32 0, i32 3, i32 1) #18
  %141 = getelementptr inbounds i32, i32* %136, i64 %137
  %142 = bitcast i32* %141 to i8*
  call void @llvm.prefetch(i8* %142, i32 0, i32 3, i32 1) #18
  %143 = getelementptr inbounds i32, i32* %141, i64 4
  %144 = bitcast i32* %143 to i8*
  call void @llvm.prefetch(i8* %144, i32 0, i32 3, i32 1) #18
  %145 = shl nsw i64 %137, 1
  %146 = getelementptr inbounds i32, i32* %136, i64 %145
  %147 = bitcast i32* %146 to i8*
  call void @llvm.prefetch(i8* %147, i32 0, i32 3, i32 1) #18
  %148 = getelementptr inbounds i32, i32* %146, i64 4
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #18
  %150 = mul nsw i64 %137, 3
  %151 = getelementptr inbounds i32, i32* %136, i64 %150
  %152 = bitcast i32* %151 to i8*
  call void @llvm.prefetch(i8* %152, i32 0, i32 3, i32 1) #18
  %153 = getelementptr inbounds i32, i32* %151, i64 4
  %154 = bitcast i32* %153 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #18
  %155 = shl nsw i64 %137, 2
  %156 = getelementptr inbounds i32, i32* %136, i64 %155
  %157 = bitcast i32* %156 to i8*
  call void @llvm.prefetch(i8* %157, i32 0, i32 3, i32 1) #18
  %158 = getelementptr inbounds i32, i32* %156, i64 4
  %159 = bitcast i32* %158 to i8*
  call void @llvm.prefetch(i8* %159, i32 0, i32 3, i32 1) #18
  %160 = mul nsw i64 %137, 5
  %161 = getelementptr inbounds i32, i32* %136, i64 %160
  %162 = bitcast i32* %161 to i8*
  call void @llvm.prefetch(i8* %162, i32 0, i32 3, i32 1) #18
  %163 = getelementptr inbounds i32, i32* %161, i64 4
  %164 = bitcast i32* %163 to i8*
  call void @llvm.prefetch(i8* %164, i32 0, i32 3, i32 1) #18
  %165 = mul nsw i64 %137, 6
  %166 = getelementptr inbounds i32, i32* %136, i64 %165
  %167 = bitcast i32* %166 to i8*
  call void @llvm.prefetch(i8* %167, i32 0, i32 3, i32 1) #18
  %168 = getelementptr inbounds i32, i32* %166, i64 4
  %169 = bitcast i32* %168 to i8*
  call void @llvm.prefetch(i8* %169, i32 0, i32 3, i32 1) #18
  %170 = mul nsw i64 %137, 7
  %171 = getelementptr inbounds i32, i32* %136, i64 %170
  %172 = bitcast i32* %171 to i8*
  call void @llvm.prefetch(i8* %172, i32 0, i32 3, i32 1) #18
  %173 = getelementptr inbounds i32, i32* %171, i64 4
  %174 = bitcast i32* %173 to i8*
  call void @llvm.prefetch(i8* %174, i32 0, i32 3, i32 1) #18
  %175 = icmp slt i32 %126, 8
  br i1 %175, label %180, label %176

176:                                              ; preds = %125
  %177 = or i32 %127, 4
  br label %187

178:                                              ; preds = %187
  %179 = trunc i64 %195 to i32
  br label %180

180:                                              ; preds = %178, %125
  %181 = phi i32 [ %126, %125 ], [ %250, %178 ]
  %182 = phi i32 [ 0, %125 ], [ %179, %178 ]
  %183 = add nsw i32 %181, -4
  %184 = icmp sgt i32 %182, %183
  br i1 %184, label %258, label %185

185:                                              ; preds = %180
  %186 = or i32 %127, 4
  br label %264

187:                                              ; preds = %254, %176
  %188 = phi i32* [ %132, %176 ], [ %257, %254 ]
  %189 = phi i32 [ %129, %176 ], [ %256, %254 ]
  %190 = phi i32* [ %128, %176 ], [ %255, %254 ]
  %191 = phi i64 [ 0, %176 ], [ %195, %254 ]
  %192 = load i32, i32* %104, align 4
  %193 = trunc i64 %191 to i32
  %194 = add nsw i32 %192, %193
  %195 = add nuw i64 %191, 8
  %196 = mul nsw i32 %189, %127
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds i32, i32* %188, i64 %195
  %199 = bitcast i32* %198 to i8*
  call void @llvm.prefetch(i8* %199, i32 0, i32 3, i32 1) #18
  %200 = getelementptr inbounds i32, i32* %198, i64 4
  %201 = bitcast i32* %200 to i8*
  call void @llvm.prefetch(i8* %201, i32 0, i32 3, i32 1) #18
  %202 = getelementptr inbounds i32, i32* %190, i64 %195
  %203 = getelementptr inbounds i32, i32* %202, i64 %197
  %204 = sext i32 %189 to i64
  %205 = bitcast i32* %203 to i8*
  call void @llvm.prefetch(i8* %205, i32 0, i32 3, i32 1) #18
  %206 = getelementptr inbounds i32, i32* %203, i64 4
  %207 = bitcast i32* %206 to i8*
  call void @llvm.prefetch(i8* %207, i32 0, i32 3, i32 1) #18
  %208 = getelementptr inbounds i32, i32* %203, i64 %204
  %209 = bitcast i32* %208 to i8*
  call void @llvm.prefetch(i8* %209, i32 0, i32 3, i32 1) #18
  %210 = getelementptr inbounds i32, i32* %208, i64 4
  %211 = bitcast i32* %210 to i8*
  call void @llvm.prefetch(i8* %211, i32 0, i32 3, i32 1) #18
  %212 = shl nsw i64 %204, 1
  %213 = getelementptr inbounds i32, i32* %203, i64 %212
  %214 = bitcast i32* %213 to i8*
  call void @llvm.prefetch(i8* %214, i32 0, i32 3, i32 1) #18
  %215 = getelementptr inbounds i32, i32* %213, i64 4
  %216 = bitcast i32* %215 to i8*
  call void @llvm.prefetch(i8* %216, i32 0, i32 3, i32 1) #18
  %217 = mul nsw i64 %204, 3
  %218 = getelementptr inbounds i32, i32* %203, i64 %217
  %219 = bitcast i32* %218 to i8*
  call void @llvm.prefetch(i8* %219, i32 0, i32 3, i32 1) #18
  %220 = getelementptr inbounds i32, i32* %218, i64 4
  %221 = bitcast i32* %220 to i8*
  call void @llvm.prefetch(i8* %221, i32 0, i32 3, i32 1) #18
  %222 = shl nsw i64 %204, 2
  %223 = getelementptr inbounds i32, i32* %203, i64 %222
  %224 = bitcast i32* %223 to i8*
  call void @llvm.prefetch(i8* %224, i32 0, i32 3, i32 1) #18
  %225 = getelementptr inbounds i32, i32* %223, i64 4
  %226 = bitcast i32* %225 to i8*
  call void @llvm.prefetch(i8* %226, i32 0, i32 3, i32 1) #18
  %227 = mul nsw i64 %204, 5
  %228 = getelementptr inbounds i32, i32* %203, i64 %227
  %229 = bitcast i32* %228 to i8*
  call void @llvm.prefetch(i8* %229, i32 0, i32 3, i32 1) #18
  %230 = getelementptr inbounds i32, i32* %228, i64 4
  %231 = bitcast i32* %230 to i8*
  call void @llvm.prefetch(i8* %231, i32 0, i32 3, i32 1) #18
  %232 = mul nsw i64 %204, 6
  %233 = getelementptr inbounds i32, i32* %203, i64 %232
  %234 = bitcast i32* %233 to i8*
  call void @llvm.prefetch(i8* %234, i32 0, i32 3, i32 1) #18
  %235 = getelementptr inbounds i32, i32* %233, i64 4
  %236 = bitcast i32* %235 to i8*
  call void @llvm.prefetch(i8* %236, i32 0, i32 3, i32 1) #18
  %237 = mul nsw i64 %204, 7
  %238 = getelementptr inbounds i32, i32* %203, i64 %237
  %239 = bitcast i32* %238 to i8*
  call void @llvm.prefetch(i8* %239, i32 0, i32 3, i32 1) #18
  %240 = getelementptr inbounds i32, i32* %238, i64 4
  %241 = bitcast i32* %240 to i8*
  call void @llvm.prefetch(i8* %241, i32 0, i32 3, i32 1) #18
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %105) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %105, i8 -86, i64 128, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %106) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %115, i8 -86, i64 24, i1 false)
  store i16* %111, i16** %107, align 8
  store i32 8, i32* %108, align 8
  store i32 8, i32* %109, align 4
  store i32 8, i32* %110, align 8
  %242 = load i32, i32* %112, align 4
  %243 = add nsw i32 %242, %127
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.499"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.260"* nonnull %20, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %193, i32 %127, i32 %194, i32 %243, i32 0, i32 0)
  %244 = load i32, i32* %112, align 4
  %245 = add nsw i32 %244, %177
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.499"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.260"* nonnull %20, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %193, i32 %177, i32 %194, i32 %245, i32 0, i32 4)
  %246 = load i32, i32* %104, align 4
  %247 = add nsw i32 %246, %193
  %248 = load i32, i32* %112, align 4
  %249 = add nsw i32 %248, %127
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %113)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %113, i8* nonnull align 16 %105, i64 128, i1 false)
  call void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIsLi8ELi8EEENS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock"* nonnull dereferenceable(128) %10, %"class.gemmlowp::MatrixMap.273"* %0, i32 %247, i32 %249) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %113)
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %106) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %105) #18
  %250 = load i32, i32* %48, align 4
  %251 = add nsw i32 %250, -8
  %252 = trunc i64 %195 to i32
  %253 = icmp slt i32 %251, %252
  br i1 %253, label %178, label %254

254:                                              ; preds = %187
  %255 = load i32*, i32** %22, align 8
  %256 = load i32, i32* %25, align 8
  %257 = load i32*, i32** %46, align 8
  br label %187

258:                                              ; preds = %264, %180
  %259 = phi i32 [ %181, %180 ], [ %273, %264 ]
  %260 = phi i32 [ %182, %180 ], [ %272, %264 ]
  %261 = icmp slt i32 %260, %259
  br i1 %261, label %262, label %287

262:                                              ; preds = %258
  %263 = or i32 %127, 4
  br label %276

264:                                              ; preds = %185, %264
  %265 = phi i32 [ %272, %264 ], [ %182, %185 ]
  %266 = load i32, i32* %104, align 4
  %267 = add nsw i32 %266, %265
  %268 = load i32, i32* %112, align 4
  %269 = add nsw i32 %268, %127
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.492"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %265, i32 %127, i32 %267, i32 %269, i32 %267, i32 %269)
  %270 = load i32, i32* %112, align 4
  %271 = add nsw i32 %270, %186
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.492"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %265, i32 %186, i32 %267, i32 %271, i32 %267, i32 %271)
  %272 = add nuw nsw i32 %265, 4
  %273 = load i32, i32* %48, align 4
  %274 = add nsw i32 %273, -4
  %275 = icmp sgt i32 %272, %274
  br i1 %275, label %258, label %264

276:                                              ; preds = %262, %276
  %277 = phi i32 [ %284, %276 ], [ %260, %262 ]
  %278 = load i32, i32* %104, align 4
  %279 = add nsw i32 %278, %277
  %280 = load i32, i32* %112, align 4
  %281 = add nsw i32 %280, %127
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.485"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %277, i32 %127, i32 %279, i32 %281, i32 %279, i32 %281)
  %282 = load i32, i32* %112, align 4
  %283 = add nsw i32 %282, %263
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.485"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %277, i32 %263, i32 %279, i32 %283, i32 %279, i32 %283)
  %284 = add nuw nsw i32 %277, 1
  %285 = load i32, i32* %48, align 4
  %286 = icmp slt i32 %284, %285
  br i1 %286, label %276, label %287

287:                                              ; preds = %276, %258
  %288 = phi i32 [ %259, %258 ], [ %285, %276 ]
  %289 = add nuw nsw i32 %127, 8
  %290 = load i32, i32* %54, align 4
  %291 = add nsw i32 %290, -8
  %292 = icmp sgt i32 %289, %291
  br i1 %292, label %116, label %125

293:                                              ; preds = %419, %116
  %294 = phi i32 [ %117, %116 ], [ %422, %419 ]
  %295 = phi i32 [ %118, %116 ], [ %421, %419 ]
  %296 = icmp slt i32 %295, %294
  br i1 %296, label %297, label %578

297:                                              ; preds = %293
  %298 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %299 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %300 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %301 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %7, i64 0, i32 0
  %302 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 0, i32 0, i32 2
  %303 = shl i32 1, %61
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 0, i32 0, i32 0
  %306 = zext i32 %64 to i64
  %307 = shl nsw i64 -1, %306
  %308 = trunc i64 %307 to i32
  %309 = xor i32 %308, -1
  %310 = ashr i32 %309, 1
  %311 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %65, i64 0, i32 0
  %312 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %313 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %0, i64 0, i32 0
  %314 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %0, i64 0, i32 3
  %315 = zext i32 %295 to i64
  %316 = load i32, i32* %48, align 4
  br label %425

317:                                              ; preds = %121, %419
  %318 = phi i32 [ %124, %121 ], [ %420, %419 ]
  %319 = phi i32 [ %118, %121 ], [ %421, %419 ]
  %320 = load i32, i32* %122, align 4
  %321 = add nsw i32 %320, %319
  %322 = load i32*, i32** %22, align 8
  %323 = load i32, i32* %25, align 8
  %324 = mul nsw i32 %323, %319
  %325 = sext i32 %324 to i64
  %326 = load i32*, i32** %46, align 8
  %327 = bitcast i32* %326 to i8*
  call void @llvm.prefetch(i8* %327, i32 0, i32 3, i32 1) #18
  %328 = getelementptr inbounds i32, i32* %326, i64 4
  %329 = bitcast i32* %328 to i8*
  call void @llvm.prefetch(i8* %329, i32 0, i32 3, i32 1) #18
  %330 = getelementptr inbounds i32, i32* %322, i64 %325
  %331 = sext i32 %323 to i64
  %332 = bitcast i32* %330 to i8*
  call void @llvm.prefetch(i8* %332, i32 0, i32 3, i32 1) #18
  %333 = getelementptr inbounds i32, i32* %330, i64 4
  %334 = bitcast i32* %333 to i8*
  call void @llvm.prefetch(i8* %334, i32 0, i32 3, i32 1) #18
  %335 = getelementptr inbounds i32, i32* %330, i64 %331
  %336 = bitcast i32* %335 to i8*
  call void @llvm.prefetch(i8* %336, i32 0, i32 3, i32 1) #18
  %337 = getelementptr inbounds i32, i32* %335, i64 4
  %338 = bitcast i32* %337 to i8*
  call void @llvm.prefetch(i8* %338, i32 0, i32 3, i32 1) #18
  %339 = shl nsw i64 %331, 1
  %340 = getelementptr inbounds i32, i32* %330, i64 %339
  %341 = bitcast i32* %340 to i8*
  call void @llvm.prefetch(i8* %341, i32 0, i32 3, i32 1) #18
  %342 = getelementptr inbounds i32, i32* %340, i64 4
  %343 = bitcast i32* %342 to i8*
  call void @llvm.prefetch(i8* %343, i32 0, i32 3, i32 1) #18
  %344 = mul nsw i64 %331, 3
  %345 = getelementptr inbounds i32, i32* %330, i64 %344
  %346 = bitcast i32* %345 to i8*
  call void @llvm.prefetch(i8* %346, i32 0, i32 3, i32 1) #18
  %347 = getelementptr inbounds i32, i32* %345, i64 4
  %348 = bitcast i32* %347 to i8*
  call void @llvm.prefetch(i8* %348, i32 0, i32 3, i32 1) #18
  %349 = icmp slt i32 %318, 8
  br i1 %349, label %352, label %357

350:                                              ; preds = %357
  %351 = trunc i64 %365 to i32
  br label %352

352:                                              ; preds = %350, %317
  %353 = phi i32 [ %318, %317 ], [ %392, %350 ]
  %354 = phi i32 [ 0, %317 ], [ %351, %350 ]
  %355 = add nsw i32 %353, -4
  %356 = icmp sgt i32 %354, %355
  br i1 %356, label %400, label %404

357:                                              ; preds = %317, %396
  %358 = phi i32* [ %399, %396 ], [ %326, %317 ]
  %359 = phi i32 [ %398, %396 ], [ %323, %317 ]
  %360 = phi i32* [ %397, %396 ], [ %322, %317 ]
  %361 = phi i64 [ %365, %396 ], [ 0, %317 ]
  %362 = load i32, i32* %123, align 4
  %363 = trunc i64 %361 to i32
  %364 = add nsw i32 %362, %363
  %365 = add nuw i64 %361, 8
  %366 = mul nsw i32 %359, %319
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds i32, i32* %358, i64 %365
  %369 = bitcast i32* %368 to i8*
  call void @llvm.prefetch(i8* %369, i32 0, i32 3, i32 1) #18
  %370 = getelementptr inbounds i32, i32* %368, i64 4
  %371 = bitcast i32* %370 to i8*
  call void @llvm.prefetch(i8* %371, i32 0, i32 3, i32 1) #18
  %372 = getelementptr inbounds i32, i32* %360, i64 %365
  %373 = getelementptr inbounds i32, i32* %372, i64 %367
  %374 = sext i32 %359 to i64
  %375 = bitcast i32* %373 to i8*
  call void @llvm.prefetch(i8* %375, i32 0, i32 3, i32 1) #18
  %376 = getelementptr inbounds i32, i32* %373, i64 4
  %377 = bitcast i32* %376 to i8*
  call void @llvm.prefetch(i8* %377, i32 0, i32 3, i32 1) #18
  %378 = getelementptr inbounds i32, i32* %373, i64 %374
  %379 = bitcast i32* %378 to i8*
  call void @llvm.prefetch(i8* %379, i32 0, i32 3, i32 1) #18
  %380 = getelementptr inbounds i32, i32* %378, i64 4
  %381 = bitcast i32* %380 to i8*
  call void @llvm.prefetch(i8* %381, i32 0, i32 3, i32 1) #18
  %382 = shl nsw i64 %374, 1
  %383 = getelementptr inbounds i32, i32* %373, i64 %382
  %384 = bitcast i32* %383 to i8*
  call void @llvm.prefetch(i8* %384, i32 0, i32 3, i32 1) #18
  %385 = getelementptr inbounds i32, i32* %383, i64 4
  %386 = bitcast i32* %385 to i8*
  call void @llvm.prefetch(i8* %386, i32 0, i32 3, i32 1) #18
  %387 = mul nsw i64 %374, 3
  %388 = getelementptr inbounds i32, i32* %373, i64 %387
  %389 = bitcast i32* %388 to i8*
  call void @llvm.prefetch(i8* %389, i32 0, i32 3, i32 1) #18
  %390 = getelementptr inbounds i32, i32* %388, i64 4
  %391 = bitcast i32* %390 to i8*
  call void @llvm.prefetch(i8* %391, i32 0, i32 3, i32 1) #18
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.499"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %363, i32 %319, i32 %364, i32 %321, i32 %364, i32 %321)
  %392 = load i32, i32* %48, align 4
  %393 = add nsw i32 %392, -8
  %394 = trunc i64 %365 to i32
  %395 = icmp slt i32 %393, %394
  br i1 %395, label %350, label %396

396:                                              ; preds = %357
  %397 = load i32*, i32** %22, align 8
  %398 = load i32, i32* %25, align 8
  %399 = load i32*, i32** %46, align 8
  br label %357

400:                                              ; preds = %404, %352
  %401 = phi i32 [ %353, %352 ], [ %409, %404 ]
  %402 = phi i32 [ %354, %352 ], [ %408, %404 ]
  %403 = icmp slt i32 %402, %401
  br i1 %403, label %412, label %419

404:                                              ; preds = %352, %404
  %405 = phi i32 [ %408, %404 ], [ %354, %352 ]
  %406 = load i32, i32* %123, align 4
  %407 = add nsw i32 %406, %405
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.492"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %405, i32 %319, i32 %407, i32 %321, i32 %407, i32 %321)
  %408 = add nuw nsw i32 %405, 4
  %409 = load i32, i32* %48, align 4
  %410 = add nsw i32 %409, -4
  %411 = icmp sgt i32 %408, %410
  br i1 %411, label %400, label %404

412:                                              ; preds = %400, %412
  %413 = phi i32 [ %416, %412 ], [ %402, %400 ]
  %414 = load i32, i32* %123, align 4
  %415 = add nsw i32 %414, %413
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.485"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %413, i32 %319, i32 %415, i32 %321, i32 %415, i32 %321)
  %416 = add nuw nsw i32 %413, 1
  %417 = load i32, i32* %48, align 4
  %418 = icmp slt i32 %416, %417
  br i1 %418, label %412, label %419

419:                                              ; preds = %412, %400
  %420 = phi i32 [ %401, %400 ], [ %417, %412 ]
  %421 = add nuw nsw i32 %319, 4
  %422 = load i32, i32* %54, align 4
  %423 = add nsw i32 %422, -4
  %424 = icmp sgt i32 %421, %423
  br i1 %424, label %293, label %317

425:                                              ; preds = %297, %572
  %426 = phi i32 [ %316, %297 ], [ %573, %572 ]
  %427 = phi i64 [ %315, %297 ], [ %574, %572 ]
  %428 = load i32, i32* %298, align 4
  %429 = trunc i64 %427 to i32
  %430 = add nsw i32 %428, %429
  %431 = load i32*, i32** %22, align 8
  %432 = load i32, i32* %25, align 8
  %433 = mul nsw i32 %432, %429
  %434 = sext i32 %433 to i64
  %435 = load i32*, i32** %46, align 8
  %436 = bitcast i32* %435 to i8*
  call void @llvm.prefetch(i8* %436, i32 0, i32 3, i32 1) #18
  %437 = getelementptr inbounds i32, i32* %435, i64 4
  %438 = bitcast i32* %437 to i8*
  call void @llvm.prefetch(i8* %438, i32 0, i32 3, i32 1) #18
  %439 = getelementptr inbounds i32, i32* %431, i64 %434
  %440 = bitcast i32* %439 to i8*
  call void @llvm.prefetch(i8* %440, i32 0, i32 3, i32 1) #18
  %441 = getelementptr inbounds i32, i32* %439, i64 4
  %442 = bitcast i32* %441 to i8*
  call void @llvm.prefetch(i8* %442, i32 0, i32 3, i32 1) #18
  %443 = icmp slt i32 %426, 8
  br i1 %443, label %446, label %451

444:                                              ; preds = %451
  %445 = trunc i64 %459 to i32
  br label %446

446:                                              ; preds = %444, %425
  %447 = phi i32 [ %426, %425 ], [ %471, %444 ]
  %448 = phi i32 [ 0, %425 ], [ %445, %444 ]
  %449 = add nsw i32 %447, -4
  %450 = icmp sgt i32 %448, %449
  br i1 %450, label %479, label %486

451:                                              ; preds = %425, %475
  %452 = phi i32* [ %478, %475 ], [ %435, %425 ]
  %453 = phi i32 [ %477, %475 ], [ %432, %425 ]
  %454 = phi i32* [ %476, %475 ], [ %431, %425 ]
  %455 = phi i64 [ %459, %475 ], [ 0, %425 ]
  %456 = load i32, i32* %299, align 4
  %457 = trunc i64 %455 to i32
  %458 = add nsw i32 %456, %457
  %459 = add nuw i64 %455, 8
  %460 = mul nsw i32 %453, %429
  %461 = sext i32 %460 to i64
  %462 = getelementptr inbounds i32, i32* %452, i64 %459
  %463 = bitcast i32* %462 to i8*
  call void @llvm.prefetch(i8* %463, i32 0, i32 3, i32 1) #18
  %464 = getelementptr inbounds i32, i32* %462, i64 4
  %465 = bitcast i32* %464 to i8*
  call void @llvm.prefetch(i8* %465, i32 0, i32 3, i32 1) #18
  %466 = getelementptr inbounds i32, i32* %454, i64 %459
  %467 = getelementptr inbounds i32, i32* %466, i64 %461
  %468 = bitcast i32* %467 to i8*
  call void @llvm.prefetch(i8* %468, i32 0, i32 3, i32 1) #18
  %469 = getelementptr inbounds i32, i32* %467, i64 4
  %470 = bitcast i32* %469 to i8*
  call void @llvm.prefetch(i8* %470, i32 0, i32 3, i32 1) #18
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.478"* nonnull dereferenceable(32) %15, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %457, i32 %429, i32 %458, i32 %430, i32 %458, i32 %430)
  %471 = load i32, i32* %48, align 4
  %472 = add nsw i32 %471, -8
  %473 = trunc i64 %459 to i32
  %474 = icmp slt i32 %472, %473
  br i1 %474, label %444, label %475

475:                                              ; preds = %451
  %476 = load i32*, i32** %22, align 8
  %477 = load i32, i32* %25, align 8
  %478 = load i32*, i32** %46, align 8
  br label %451

479:                                              ; preds = %486, %446
  %480 = phi i32 [ %447, %446 ], [ %491, %486 ]
  %481 = phi i32 [ %448, %446 ], [ %490, %486 ]
  %482 = icmp slt i32 %481, %480
  br i1 %482, label %483, label %572

483:                                              ; preds = %479
  %484 = sext i32 %430 to i64
  %485 = zext i32 %481 to i64
  br label %494

486:                                              ; preds = %446, %486
  %487 = phi i32 [ %490, %486 ], [ %448, %446 ]
  %488 = load i32, i32* %299, align 4
  %489 = add nsw i32 %488, %487
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.471"* nonnull dereferenceable(32) %14, %"class.gemmlowp::MatrixMap.273"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %487, i32 %429, i32 %489, i32 %430, i32 %489, i32 %430)
  %490 = add nuw nsw i32 %487, 4
  %491 = load i32, i32* %48, align 4
  %492 = add nsw i32 %491, -4
  %493 = icmp sgt i32 %490, %492
  br i1 %493, label %479, label %486

494:                                              ; preds = %483, %541
  %495 = phi i64 [ %485, %483 ], [ %568, %541 ]
  %496 = load i32, i32* %299, align 4
  %497 = trunc i64 %495 to i32
  %498 = add nsw i32 %496, %497
  %499 = load i32*, i32** %22, align 8
  %500 = load i32, i32* %25, align 8
  %501 = getelementptr inbounds i32, i32* %499, i64 %495
  %502 = mul nsw i32 %500, %429
  %503 = sext i32 %502 to i64
  %504 = getelementptr inbounds i32, i32* %501, i64 %503
  %505 = load i32, i32* %504, align 4
  %506 = load i32*, i32** %46, align 8
  %507 = getelementptr inbounds i32, i32* %506, i64 %495
  %508 = load i32, i32* %507, align 4
  %509 = load i32*, i32** %52, align 8
  %510 = getelementptr inbounds i32, i32* %509, i64 %427
  %511 = load i32, i32* %510, align 4
  %512 = load i32, i32* %300, align 4
  %513 = load i32, i32* %301, align 4
  %514 = mul nsw i32 %513, %508
  %515 = add nsw i32 %514, %505
  %516 = mul nsw i32 %513, %3
  %517 = add nsw i32 %516, %511
  %518 = mul nsw i32 %517, %512
  %519 = add nsw i32 %515, %518
  %520 = load i32, i32* %302, align 4
  %521 = sext i32 %519 to i64
  %522 = mul nsw i64 %521, %304
  %523 = icmp slt i64 %522, 2147483647
  %524 = select i1 %523, i64 %522, i64 2147483647
  %525 = icmp sgt i64 %524, -2147483648
  %526 = select i1 %525, i64 %524, i64 -2147483648
  %527 = trunc i64 %526 to i32
  %528 = load i32, i32* %305, align 4
  %529 = icmp ne i32 %528, %527
  %530 = icmp ne i32 %527, -2147483648
  %531 = or i1 %529, %530
  br i1 %531, label %532, label %541

532:                                              ; preds = %494
  %533 = sext i32 %528 to i64
  %534 = select i1 %529, i64 %533, i64 %526
  %535 = mul nsw i64 %534, %526
  %536 = icmp sgt i64 %535, -1
  %537 = select i1 %536, i64 1073741824, i64 -1073741823
  %538 = add nsw i64 %537, %535
  %539 = sdiv i64 %538, 2147483648
  %540 = trunc i64 %539 to i32
  br label %541

541:                                              ; preds = %494, %532
  %542 = phi i32 [ %540, %532 ], [ 2147483647, %494 ]
  %543 = and i32 %542, %309
  %544 = lshr i32 %542, 31
  %545 = add nsw i32 %544, %310
  %546 = ashr i32 %542, %64
  %547 = icmp sgt i32 %543, %545
  %548 = zext i1 %547 to i32
  %549 = add i32 %546, %520
  %550 = add i32 %549, %548
  %551 = load i32, i32* %311, align 4
  %552 = load i32, i32* %312, align 4
  %553 = icmp sgt i32 %551, %550
  %554 = select i1 %553, i32 %551, i32 %550
  %555 = icmp slt i32 %552, %554
  %556 = select i1 %555, i32 %552, i32 %554
  %557 = icmp sgt i32 %556, -32768
  %558 = select i1 %557, i32 %556, i32 -32768
  %559 = icmp slt i32 %558, 32767
  %560 = select i1 %559, i32 %558, i32 32767
  %561 = trunc i32 %560 to i16
  %562 = load i16*, i16** %313, align 8
  %563 = load i32, i32* %314, align 8
  %564 = mul nsw i32 %563, %498
  %565 = sext i32 %564 to i64
  %566 = getelementptr inbounds i16, i16* %562, i64 %484
  %567 = getelementptr inbounds i16, i16* %566, i64 %565
  store i16 %561, i16* %567, align 2
  %568 = add nuw nsw i64 %495, 1
  %569 = load i32, i32* %48, align 4
  %570 = trunc i64 %568 to i32
  %571 = icmp sgt i32 %569, %570
  br i1 %571, label %494, label %572

572:                                              ; preds = %541, %479
  %573 = phi i32 [ %480, %479 ], [ %569, %541 ]
  %574 = add nuw nsw i64 %427, 1
  %575 = load i32, i32* %54, align 4
  %576 = trunc i64 %574 to i32
  %577 = icmp sgt i32 %575, %576
  br i1 %577, label %425, label %578

578:                                              ; preds = %572, %293
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %94) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %87) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %80) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %73) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %66) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %51) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %45) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %21) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.499"* dereferenceable(32), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.388", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.388", align 2
  %17 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #18
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !863
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !863
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !863
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !863
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !863
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !863
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !863
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !863
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !863
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !863
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !863
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !863
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !863
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !863
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !863
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !863
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !863
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !863
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !863
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !863
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !863
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !863
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !863
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !863
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !863
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !863
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !863
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !863
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !863
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !863
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !863
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !863
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !863
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !863
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !866
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %245) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %245, i8 -86, i64 64, i1 false) #18
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %1, i64 0, i32 0
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.388"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.500"* %246, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %17, i32 %10, i32 %11) #18
  %247 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %247) #18
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 2 %245, i64 64, i1 false) #18
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i16, i16* %258, align 2
  %260 = load i16*, i16** %248, align 8
  %261 = getelementptr inbounds i16, i16* %260, i64 %257
  %262 = load i32, i32* %249, align 8
  %263 = sext i32 %262 to i64
  %264 = mul nsw i64 %263, %250
  %265 = getelementptr inbounds i16, i16* %261, i64 %264
  store i16 %259, i16* %265, align 2
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i16, i16* %267, align 2
  %269 = load i16*, i16** %248, align 8
  %270 = getelementptr inbounds i16, i16* %269, i64 %257
  %271 = load i32, i32* %249, align 8
  %272 = sext i32 %271 to i64
  %273 = mul nsw i64 %252, %272
  %274 = getelementptr inbounds i16, i16* %270, i64 %273
  store i16 %268, i16* %274, align 2
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i16, i16* %276, align 2
  %278 = load i16*, i16** %248, align 8
  %279 = getelementptr inbounds i16, i16* %278, i64 %257
  %280 = load i32, i32* %249, align 8
  %281 = sext i32 %280 to i64
  %282 = mul nsw i64 %253, %281
  %283 = getelementptr inbounds i16, i16* %279, i64 %282
  store i16 %277, i16* %283, align 2
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i16, i16* %285, align 2
  %287 = load i16*, i16** %248, align 8
  %288 = getelementptr inbounds i16, i16* %287, i64 %257
  %289 = load i32, i32* %249, align 8
  %290 = sext i32 %289 to i64
  %291 = mul nsw i64 %254, %290
  %292 = getelementptr inbounds i16, i16* %288, i64 %291
  store i16 %286, i16* %292, align 2
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %247) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %245) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.492"* dereferenceable(32), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.390", align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !871
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !871
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = load i32, i32* %24, align 4, !noalias !871
  %27 = getelementptr inbounds i32, i32* %25, i64 1
  %28 = load i32, i32* %25, align 4, !noalias !871
  %29 = getelementptr inbounds i32, i32* %27, i64 1
  %30 = load i32, i32* %27, align 4, !noalias !871
  %31 = load i32, i32* %29, align 4, !noalias !871
  %32 = add nsw i32 %9, 1
  %33 = mul nsw i32 %21, %32
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds i32, i32* %20, i64 %34
  %36 = getelementptr inbounds i32, i32* %35, i64 1
  %37 = load i32, i32* %35, align 4, !noalias !871
  %38 = getelementptr inbounds i32, i32* %36, i64 1
  %39 = load i32, i32* %36, align 4, !noalias !871
  %40 = getelementptr inbounds i32, i32* %38, i64 1
  %41 = load i32, i32* %38, align 4, !noalias !871
  %42 = load i32, i32* %40, align 4, !noalias !871
  %43 = add nsw i32 %9, 2
  %44 = mul nsw i32 %21, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i32, i32* %20, i64 %45
  %47 = getelementptr inbounds i32, i32* %46, i64 1
  %48 = load i32, i32* %46, align 4, !noalias !871
  %49 = getelementptr inbounds i32, i32* %47, i64 1
  %50 = load i32, i32* %47, align 4, !noalias !871
  %51 = getelementptr inbounds i32, i32* %49, i64 1
  %52 = load i32, i32* %49, align 4, !noalias !871
  %53 = load i32, i32* %51, align 4, !noalias !871
  %54 = add nsw i32 %9, 3
  %55 = mul nsw i32 %21, %54
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i32, i32* %20, i64 %56
  %58 = getelementptr inbounds i32, i32* %57, i64 1
  %59 = load i32, i32* %57, align 4, !noalias !871
  %60 = getelementptr inbounds i32, i32* %58, i64 1
  %61 = load i32, i32* %58, align 4, !noalias !871
  %62 = getelementptr inbounds i32, i32* %60, i64 1
  %63 = load i32, i32* %60, align 4, !noalias !871
  %64 = load i32, i32* %62, align 4, !noalias !871
  %65 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %66 = load i32*, i32** %65, align 8
  %67 = getelementptr i32, i32* %66, i64 %17
  %68 = bitcast i32* %67 to i64*
  %69 = load i64, i64* %68, align 4
  %70 = getelementptr inbounds i32, i32* %67, i64 2
  %71 = bitcast i32* %70 to i64*
  %72 = load i64, i64* %71, align 4
  %73 = trunc i64 %69 to i32
  %74 = lshr i64 %69, 32
  %75 = trunc i64 %74 to i32
  %76 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %77 = load i32*, i32** %76, align 8
  %78 = sext i32 %9 to i64
  %79 = getelementptr i32, i32* %77, i64 %78
  %80 = bitcast i32* %79 to i64*
  %81 = load i64, i64* %80, align 4
  %82 = getelementptr inbounds i32, i32* %79, i64 2
  %83 = bitcast i32* %82 to i64*
  %84 = load i64, i64* %83, align 4
  %85 = trunc i64 %81 to i32
  %86 = lshr i64 %81, 32
  %87 = trunc i64 %86 to i32
  %88 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %89 = load i32, i32* %88, align 4
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %91 = load i32, i32* %90, align 4
  %92 = mul nsw i32 %91, %73
  %93 = add nsw i32 %92, %26
  %94 = mul nsw i32 %91, %75
  %95 = add nsw i32 %94, %28
  %96 = trunc i64 %72 to i32
  %97 = mul nsw i32 %91, %96
  %98 = add nsw i32 %97, %30
  %99 = lshr i64 %72, 32
  %100 = trunc i64 %99 to i32
  %101 = mul nsw i32 %91, %100
  %102 = add nsw i32 %101, %31
  %103 = add nsw i32 %92, %37
  %104 = add nsw i32 %94, %39
  %105 = add nsw i32 %97, %41
  %106 = add nsw i32 %101, %42
  %107 = add nsw i32 %92, %48
  %108 = add nsw i32 %94, %50
  %109 = add nsw i32 %97, %52
  %110 = add nsw i32 %101, %53
  %111 = add nsw i32 %92, %59
  %112 = add nsw i32 %94, %61
  %113 = add nsw i32 %97, %63
  %114 = add nsw i32 %101, %64
  %115 = mul nsw i32 %91, %7
  %116 = add nsw i32 %115, %85
  %117 = add nsw i32 %115, %87
  %118 = trunc i64 %84 to i32
  %119 = add nsw i32 %115, %118
  %120 = lshr i64 %84, 32
  %121 = trunc i64 %120 to i32
  %122 = add nsw i32 %115, %121
  %123 = mul nsw i32 %116, %89
  %124 = add nsw i32 %93, %123
  %125 = add nsw i32 %95, %123
  %126 = add nsw i32 %98, %123
  %127 = add nsw i32 %102, %123
  %128 = mul nsw i32 %117, %89
  %129 = add nsw i32 %103, %128
  %130 = add nsw i32 %104, %128
  %131 = add nsw i32 %105, %128
  %132 = add nsw i32 %106, %128
  %133 = mul nsw i32 %119, %89
  %134 = add nsw i32 %107, %133
  %135 = add nsw i32 %108, %133
  %136 = add nsw i32 %109, %133
  %137 = add nsw i32 %110, %133
  %138 = mul nsw i32 %122, %89
  %139 = add nsw i32 %111, %138
  %140 = add nsw i32 %112, %138
  %141 = add nsw i32 %113, %138
  %142 = add nsw i32 %114, %138
  %143 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %124, i32* %143, align 8
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %125, i32* %144, align 4
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %126, i32* %145, align 8
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %127, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %129, i32* %147, align 8
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %130, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %131, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %132, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %134, i32* %151, align 8
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %135, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %136, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %137, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %139, i32* %155, align 8
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %140, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %141, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %142, i32* %158, align 4
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvS8_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.492"* %1, %"struct.gemmlowp::RegisterBlock.390"* nonnull byval(%"struct.gemmlowp::RegisterBlock.390") align 8 %15, %"class.gemmlowp::MatrixMap.273"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.485"* dereferenceable(32), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %9, 1
  %26 = mul nsw i32 %20, %25
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %19, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %9, 2
  %31 = mul nsw i32 %20, %30
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i32, i32* %19, i64 %32
  %34 = load i32, i32* %33, align 4
  %35 = add nsw i32 %9, 3
  %36 = mul nsw i32 %20, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %19, i64 %37
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %41 = load i32*, i32** %40, align 8
  %42 = getelementptr inbounds i32, i32* %41, i64 %16
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %45 = load i32*, i32** %44, align 8
  %46 = sext i32 %9 to i64
  %47 = getelementptr i32, i32* %45, i64 %46
  %48 = bitcast i32* %47 to i64*
  %49 = load i64, i64* %48, align 4
  %50 = getelementptr inbounds i32, i32* %47, i64 2
  %51 = bitcast i32* %50 to i64*
  %52 = load i64, i64* %51, align 4
  %53 = trunc i64 %49 to i32
  %54 = lshr i64 %49, 32
  %55 = trunc i64 %54 to i32
  %56 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = mul nsw i32 %59, %43
  %61 = add nsw i32 %60, %24
  %62 = add nsw i32 %60, %29
  %63 = add nsw i32 %60, %34
  %64 = add nsw i32 %60, %39
  %65 = mul nsw i32 %59, %7
  %66 = add nsw i32 %65, %53
  %67 = add nsw i32 %65, %55
  %68 = trunc i64 %52 to i32
  %69 = add nsw i32 %65, %68
  %70 = lshr i64 %52, 32
  %71 = trunc i64 %70 to i32
  %72 = add nsw i32 %65, %71
  %73 = mul nsw i32 %66, %57
  %74 = add nsw i32 %61, %73
  %75 = mul nsw i32 %67, %57
  %76 = add nsw i32 %62, %75
  %77 = mul nsw i32 %69, %57
  %78 = add nsw i32 %63, %77
  %79 = zext i32 %78 to i64
  %80 = mul nsw i32 %72, %57
  %81 = add nsw i32 %64, %80
  %82 = zext i32 %81 to i64
  %83 = shl nuw i64 %82, 32
  %84 = or i64 %83, %79
  %85 = zext i32 %76 to i64
  %86 = shl nuw i64 %85, 32
  %87 = zext i32 %74 to i64
  %88 = or i64 %86, %87
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %1, i64 0, i32 0, i32 0, i32 0
  %90 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %89, i64 %88, i64 %84) #18
  %91 = extractvalue { i64, i64 } %90, 0
  %92 = extractvalue { i64, i64 } %90, 1
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %94 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %93, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 0
  %96 = load i32, i32* %95, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 1
  %98 = load i32, i32* %97, align 4
  %99 = trunc i64 %91 to i32
  %100 = icmp sgt i32 %96, %99
  %101 = select i1 %100, i32 %96, i32 %99
  %102 = icmp slt i32 %98, %101
  %103 = select i1 %102, i32 %98, i32 %101
  %104 = lshr i64 %91, 32
  %105 = trunc i64 %104 to i32
  %106 = icmp sgt i32 %96, %105
  %107 = select i1 %106, i32 %96, i32 %105
  %108 = icmp slt i32 %98, %107
  %109 = select i1 %108, i32 %98, i32 %107
  %110 = trunc i64 %92 to i32
  %111 = icmp sgt i32 %96, %110
  %112 = select i1 %111, i32 %96, i32 %110
  %113 = icmp slt i32 %98, %112
  %114 = select i1 %113, i32 %98, i32 %112
  %115 = lshr i64 %92, 32
  %116 = trunc i64 %115 to i32
  %117 = icmp sgt i32 %96, %116
  %118 = select i1 %117, i32 %96, i32 %116
  %119 = icmp slt i32 %98, %118
  %120 = select i1 %119, i32 %98, i32 %118
  %121 = icmp sgt i32 %103, -32768
  %122 = select i1 %121, i32 %103, i32 -32768
  %123 = icmp slt i32 %122, 32767
  %124 = select i1 %123, i32 %122, i32 32767
  %125 = icmp sgt i32 %109, -32768
  %126 = select i1 %125, i32 %109, i32 -32768
  %127 = icmp slt i32 %126, 32767
  %128 = select i1 %127, i32 %126, i32 32767
  %129 = icmp sgt i32 %114, -32768
  %130 = select i1 %129, i32 %114, i32 -32768
  %131 = icmp slt i32 %130, 32767
  %132 = select i1 %131, i32 %130, i32 32767
  %133 = icmp sgt i32 %120, -32768
  %134 = select i1 %133, i32 %120, i32 -32768
  %135 = icmp slt i32 %134, 32767
  %136 = select i1 %135, i32 %134, i32 32767
  %137 = trunc i32 %124 to i16
  %138 = trunc i32 %128 to i16
  %139 = trunc i32 %132 to i16
  %140 = trunc i32 %136 to i16
  %141 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %143 = sext i32 %13 to i64
  %144 = sext i32 %12 to i64
  %145 = load i16*, i16** %141, align 8
  %146 = load i32, i32* %142, align 8
  %147 = sext i32 %146 to i64
  %148 = mul nsw i64 %147, %144
  %149 = getelementptr inbounds i16, i16* %145, i64 %148
  %150 = getelementptr inbounds i16, i16* %149, i64 %143
  store i16 %137, i16* %150, align 2
  %151 = add nsw i64 %143, 1
  %152 = load i16*, i16** %141, align 8
  %153 = load i32, i32* %142, align 8
  %154 = sext i32 %153 to i64
  %155 = mul nsw i64 %154, %144
  %156 = getelementptr inbounds i16, i16* %152, i64 %155
  %157 = getelementptr inbounds i16, i16* %156, i64 %151
  store i16 %138, i16* %157, align 2
  %158 = add nsw i64 %143, 2
  %159 = load i16*, i16** %141, align 8
  %160 = load i32, i32* %142, align 8
  %161 = sext i32 %160 to i64
  %162 = mul nsw i64 %161, %144
  %163 = getelementptr inbounds i16, i16* %159, i64 %162
  %164 = getelementptr inbounds i16, i16* %163, i64 %158
  store i16 %139, i16* %164, align 2
  %165 = add nsw i64 %143, 3
  %166 = load i16*, i16** %141, align 8
  %167 = load i32, i32* %142, align 8
  %168 = sext i32 %167 to i64
  %169 = mul nsw i64 %168, %144
  %170 = getelementptr inbounds i16, i16* %166, i64 %169
  %171 = getelementptr inbounds i16, i16* %170, i64 %165
  store i16 %140, i16* %171, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.499"* dereferenceable(32), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.388", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.388", align 2
  %17 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #18
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !876
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !876
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !876
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !876
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !876
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !876
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !876
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !876
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !876
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !876
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !876
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !876
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !876
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !876
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !876
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !876
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !876
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !876
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !876
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !876
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !876
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !876
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !876
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !876
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !876
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !876
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !876
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !876
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !876
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !876
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !876
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !876
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !876
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !876
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !879
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %245) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %245, i8 -86, i64 64, i1 false) #18
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %1, i64 0, i32 0
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.388"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.500"* %246, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %17, i32 %10, i32 %11) #18
  %247 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %247) #18
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 2 %245, i64 64, i1 false) #18
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i16, i16* %258, align 2
  %260 = load i16*, i16** %248, align 8
  %261 = load i32, i32* %249, align 8
  %262 = sext i32 %261 to i64
  %263 = mul nsw i64 %257, %262
  %264 = getelementptr inbounds i16, i16* %260, i64 %250
  %265 = getelementptr inbounds i16, i16* %264, i64 %263
  store i16 %259, i16* %265, align 2
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i16, i16* %267, align 2
  %269 = load i16*, i16** %248, align 8
  %270 = load i32, i32* %249, align 8
  %271 = sext i32 %270 to i64
  %272 = mul nsw i64 %257, %271
  %273 = getelementptr inbounds i16, i16* %269, i64 %252
  %274 = getelementptr inbounds i16, i16* %273, i64 %272
  store i16 %268, i16* %274, align 2
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i16, i16* %276, align 2
  %278 = load i16*, i16** %248, align 8
  %279 = load i32, i32* %249, align 8
  %280 = sext i32 %279 to i64
  %281 = mul nsw i64 %257, %280
  %282 = getelementptr inbounds i16, i16* %278, i64 %253
  %283 = getelementptr inbounds i16, i16* %282, i64 %281
  store i16 %277, i16* %283, align 2
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i16, i16* %285, align 2
  %287 = load i16*, i16** %248, align 8
  %288 = load i32, i32* %249, align 8
  %289 = sext i32 %288 to i64
  %290 = mul nsw i64 %257, %289
  %291 = getelementptr inbounds i16, i16* %287, i64 %254
  %292 = getelementptr inbounds i16, i16* %291, i64 %290
  store i16 %286, i16* %292, align 2
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %247) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %245) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.478"* dereferenceable(32), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.382", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !884
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !884
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !884
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !884
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !884
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !884
  %37 = load i32, i32* %35, align 4, !noalias !884
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !889
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = add nsw <4 x i32> %57, %30
  %59 = mul nsw <4 x i32> %56, %45
  %60 = insertelement <4 x i32> undef, i32 %32, i32 0
  %61 = insertelement <4 x i32> %60, i32 %34, i32 1
  %62 = insertelement <4 x i32> %61, i32 %36, i32 2
  %63 = insertelement <4 x i32> %62, i32 %37, i32 3
  %64 = add nsw <4 x i32> %59, %63
  %65 = mul nsw i32 %54, %7
  %66 = add nsw i32 %65, %50
  %67 = mul nsw i32 %66, %52
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw <4 x i32> %58, %69
  %71 = add nsw <4 x i32> %64, %69
  %72 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %72)
  %73 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %15 to <4 x i32>*
  store <4 x i32> %70, <4 x i32>* %73, align 16
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %15, i64 0, i32 0, i32 0, i64 4
  %75 = bitcast i32* %74 to <4 x i32>*
  store <4 x i32> %71, <4 x i32>* %75, align 16
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %1, i64 0, i32 0
  %77 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.479"* %76, %"struct.gemmlowp::RegisterBlock.382"* nonnull byval(%"struct.gemmlowp::RegisterBlock.382") align 8 %15, i32 %10, i32 %11) #18
  %78 = extractvalue { i64, i64 } %77, 0
  %79 = extractvalue { i64, i64 } %77, 1
  %80 = trunc i64 %78 to i16
  %81 = lshr i64 %78, 16
  %82 = trunc i64 %81 to i16
  %83 = lshr i64 %78, 32
  %84 = trunc i64 %83 to i16
  %85 = lshr i64 %78, 48
  %86 = trunc i64 %85 to i16
  %87 = trunc i64 %79 to i16
  %88 = lshr i64 %79, 16
  %89 = trunc i64 %88 to i16
  %90 = lshr i64 %79, 32
  %91 = trunc i64 %90 to i16
  %92 = lshr i64 %79, 48
  %93 = trunc i64 %92 to i16
  %94 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %95 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %96 = sext i32 %12 to i64
  %97 = load i16*, i16** %94, align 8
  %98 = load i32, i32* %95, align 8
  %99 = sext i32 %98 to i64
  %100 = mul nsw i64 %99, %96
  %101 = getelementptr inbounds i16, i16* %97, i64 %100
  %102 = sext i32 %13 to i64
  %103 = getelementptr inbounds i16, i16* %101, i64 %102
  store i16 %80, i16* %103, align 2
  %104 = add nsw i64 %96, 1
  %105 = load i16*, i16** %94, align 8
  %106 = load i32, i32* %95, align 8
  %107 = sext i32 %106 to i64
  %108 = mul nsw i64 %104, %107
  %109 = getelementptr inbounds i16, i16* %105, i64 %108
  %110 = getelementptr inbounds i16, i16* %109, i64 %102
  store i16 %82, i16* %110, align 2
  %111 = add nsw i64 %96, 2
  %112 = load i16*, i16** %94, align 8
  %113 = load i32, i32* %95, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %111, %114
  %116 = getelementptr inbounds i16, i16* %112, i64 %115
  %117 = getelementptr inbounds i16, i16* %116, i64 %102
  store i16 %84, i16* %117, align 2
  %118 = add nsw i64 %96, 3
  %119 = load i16*, i16** %94, align 8
  %120 = load i32, i32* %95, align 8
  %121 = sext i32 %120 to i64
  %122 = mul nsw i64 %118, %121
  %123 = getelementptr inbounds i16, i16* %119, i64 %122
  %124 = getelementptr inbounds i16, i16* %123, i64 %102
  store i16 %86, i16* %124, align 2
  %125 = add nsw i64 %96, 4
  %126 = load i16*, i16** %94, align 8
  %127 = load i32, i32* %95, align 8
  %128 = sext i32 %127 to i64
  %129 = mul nsw i64 %125, %128
  %130 = getelementptr inbounds i16, i16* %126, i64 %129
  %131 = getelementptr inbounds i16, i16* %130, i64 %102
  store i16 %87, i16* %131, align 2
  %132 = add nsw i64 %96, 5
  %133 = load i16*, i16** %94, align 8
  %134 = load i32, i32* %95, align 8
  %135 = sext i32 %134 to i64
  %136 = mul nsw i64 %132, %135
  %137 = getelementptr inbounds i16, i16* %133, i64 %136
  %138 = getelementptr inbounds i16, i16* %137, i64 %102
  store i16 %89, i16* %138, align 2
  %139 = add nsw i64 %96, 6
  %140 = load i16*, i16** %94, align 8
  %141 = load i32, i32* %95, align 8
  %142 = sext i32 %141 to i64
  %143 = mul nsw i64 %139, %142
  %144 = getelementptr inbounds i16, i16* %140, i64 %143
  %145 = getelementptr inbounds i16, i16* %144, i64 %102
  store i16 %91, i16* %145, align 2
  %146 = add nsw i64 %96, 7
  %147 = load i16*, i16** %94, align 8
  %148 = load i32, i32* %95, align 8
  %149 = sext i32 %148 to i64
  %150 = mul nsw i64 %146, %149
  %151 = getelementptr inbounds i16, i16* %147, i64 %150
  %152 = getelementptr inbounds i16, i16* %151, i64 %102
  store i16 %93, i16* %152, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %72)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.471"* dereferenceable(32), %"class.gemmlowp::MatrixMap.273"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = getelementptr inbounds i32, i32* %23, i64 1
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds i32, i32* %24, i64 1
  %27 = load i32, i32* %24, align 4
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = getelementptr i32, i32* %32, i64 %16
  %34 = bitcast i32* %33 to i64*
  %35 = load i64, i64* %34, align 4
  %36 = getelementptr inbounds i32, i32* %33, i64 2
  %37 = bitcast i32* %36 to i64*
  %38 = load i64, i64* %37, align 4
  %39 = trunc i64 %35 to i32
  %40 = lshr i64 %35, 32
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %9 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = load i32, i32* %45, align 4
  %47 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %5, i64 0, i32 0
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %50 = load i32, i32* %49, align 4
  %51 = mul nsw i32 %50, %39
  %52 = add nsw i32 %51, %25
  %53 = mul nsw i32 %50, %41
  %54 = add nsw i32 %53, %27
  %55 = trunc i64 %38 to i32
  %56 = mul nsw i32 %50, %55
  %57 = add nsw i32 %56, %29
  %58 = lshr i64 %38, 32
  %59 = trunc i64 %58 to i32
  %60 = mul nsw i32 %50, %59
  %61 = add nsw i32 %60, %30
  %62 = mul nsw i32 %50, %7
  %63 = add nsw i32 %62, %46
  %64 = mul nsw i32 %63, %48
  %65 = add nsw i32 %52, %64
  %66 = add nsw i32 %54, %64
  %67 = add nsw i32 %57, %64
  %68 = zext i32 %67 to i64
  %69 = add nsw i32 %61, %64
  %70 = zext i32 %69 to i64
  %71 = shl nuw i64 %70, 32
  %72 = or i64 %71, %68
  %73 = zext i32 %66 to i64
  %74 = shl nuw i64 %73, 32
  %75 = zext i32 %65 to i64
  %76 = or i64 %74, %75
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %1, i64 0, i32 0, i32 0, i32 0
  %78 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %77, i64 %76, i64 %72) #18
  %79 = extractvalue { i64, i64 } %78, 0
  %80 = extractvalue { i64, i64 } %78, 1
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 0
  %84 = load i32, i32* %83, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 1
  %86 = load i32, i32* %85, align 4
  %87 = trunc i64 %79 to i32
  %88 = icmp sgt i32 %84, %87
  %89 = select i1 %88, i32 %84, i32 %87
  %90 = icmp slt i32 %86, %89
  %91 = select i1 %90, i32 %86, i32 %89
  %92 = lshr i64 %79, 32
  %93 = trunc i64 %92 to i32
  %94 = icmp sgt i32 %84, %93
  %95 = select i1 %94, i32 %84, i32 %93
  %96 = icmp slt i32 %86, %95
  %97 = select i1 %96, i32 %86, i32 %95
  %98 = trunc i64 %80 to i32
  %99 = icmp sgt i32 %84, %98
  %100 = select i1 %99, i32 %84, i32 %98
  %101 = icmp slt i32 %86, %100
  %102 = select i1 %101, i32 %86, i32 %100
  %103 = lshr i64 %80, 32
  %104 = trunc i64 %103 to i32
  %105 = icmp sgt i32 %84, %104
  %106 = select i1 %105, i32 %84, i32 %104
  %107 = icmp slt i32 %86, %106
  %108 = select i1 %107, i32 %86, i32 %106
  %109 = icmp sgt i32 %91, -32768
  %110 = select i1 %109, i32 %91, i32 -32768
  %111 = icmp slt i32 %110, 32767
  %112 = select i1 %111, i32 %110, i32 32767
  %113 = icmp sgt i32 %97, -32768
  %114 = select i1 %113, i32 %97, i32 -32768
  %115 = icmp slt i32 %114, 32767
  %116 = select i1 %115, i32 %114, i32 32767
  %117 = icmp sgt i32 %102, -32768
  %118 = select i1 %117, i32 %102, i32 -32768
  %119 = icmp slt i32 %118, 32767
  %120 = select i1 %119, i32 %118, i32 32767
  %121 = icmp sgt i32 %108, -32768
  %122 = select i1 %121, i32 %108, i32 -32768
  %123 = icmp slt i32 %122, 32767
  %124 = select i1 %123, i32 %122, i32 32767
  %125 = trunc i32 %112 to i16
  %126 = trunc i32 %116 to i16
  %127 = trunc i32 %120 to i16
  %128 = trunc i32 %124 to i16
  %129 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %130 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %131 = sext i32 %12 to i64
  %132 = load i16*, i16** %129, align 8
  %133 = load i32, i32* %130, align 8
  %134 = sext i32 %133 to i64
  %135 = mul nsw i64 %134, %131
  %136 = getelementptr inbounds i16, i16* %132, i64 %135
  %137 = sext i32 %13 to i64
  %138 = getelementptr inbounds i16, i16* %136, i64 %137
  store i16 %125, i16* %138, align 2
  %139 = add nsw i64 %131, 1
  %140 = load i16*, i16** %129, align 8
  %141 = load i32, i32* %130, align 8
  %142 = sext i32 %141 to i64
  %143 = mul nsw i64 %139, %142
  %144 = getelementptr inbounds i16, i16* %140, i64 %143
  %145 = getelementptr inbounds i16, i16* %144, i64 %137
  store i16 %126, i16* %145, align 2
  %146 = add nsw i64 %131, 2
  %147 = load i16*, i16** %129, align 8
  %148 = load i32, i32* %130, align 8
  %149 = sext i32 %148 to i64
  %150 = mul nsw i64 %146, %149
  %151 = getelementptr inbounds i16, i16* %147, i64 %150
  %152 = getelementptr inbounds i16, i16* %151, i64 %137
  store i16 %127, i16* %152, align 2
  %153 = add nsw i64 %131, 3
  %154 = load i16*, i16** %129, align 8
  %155 = load i32, i32* %130, align 8
  %156 = sext i32 %155 to i64
  %157 = mul nsw i64 %153, %156
  %158 = getelementptr inbounds i16, i16* %154, i64 %157
  %159 = getelementptr inbounds i16, i16* %158, i64 %137
  store i16 %128, i16* %159, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.388"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.500"*, %"struct.gemmlowp::RegisterBlock.380"* byval(%"struct.gemmlowp::RegisterBlock.380") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.389", align 8
  %8 = alloca [32 x i16], align 2
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 16
  %11 = alloca [32 x i32], align 4
  %12 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 8
  %13 = alloca %"struct.gemmlowp::RegisterBuffer.381", align 4
  %14 = alloca [32 x i32], align 4
  %15 = bitcast [32 x i32]* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15)
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %15, i8 -86, i64 128, i1 false), !alias.scope !894
  %17 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %17) #18, !noalias !894
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #18, !noalias !894
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %18, i8* nonnull align 8 %16, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %17, i8 -86, i64 128, i1 false) #18, !alias.scope !897, !noalias !894
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.500", %"struct.gemmlowp::OutputPipelineEvalImpl.500"* %1, i64 0, i32 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %19, align 8, !noalias !900
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !900
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.500", %"struct.gemmlowp::OutputPipelineEvalImpl.500"* %1, i64 0, i32 0, i32 0, i32 1
  %24 = load i32, i32* %23, align 8, !noalias !900
  %25 = shl i32 1, %24
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 0
  %28 = load i32, i32* %27, align 4, !noalias !900
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.500", %"struct.gemmlowp::OutputPipelineEvalImpl.500"* %1, i64 0, i32 0, i32 0, i32 2
  %31 = load i32, i32* %30, align 4, !noalias !900
  %32 = zext i32 %31 to i64
  %33 = shl nsw i64 -1, %32
  %34 = trunc i64 %33 to i32
  %35 = xor i32 %34, -1
  %36 = ashr i32 %35, 1
  %37 = icmp ne i32 %28, -2147483648
  br label %38

38:                                               ; preds = %59, %5
  %39 = phi i64 [ 0, %5 ], [ %70, %59 ]
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %12, i64 0, i32 0, i64 %39
  %41 = load i32, i32* %40, align 4, !noalias !900
  %42 = sext i32 %41 to i64
  %43 = mul nsw i64 %42, %26
  %44 = icmp slt i64 %43, 2147483647
  %45 = select i1 %44, i64 %43, i64 2147483647
  %46 = icmp sgt i64 %45, -2147483648
  %47 = select i1 %46, i64 %45, i64 -2147483648
  %48 = trunc i64 %47 to i32
  %49 = icmp ne i32 %28, %48
  %50 = or i1 %37, %49
  br i1 %50, label %51, label %59

51:                                               ; preds = %38
  %52 = select i1 %49, i64 %29, i64 %47
  %53 = mul nsw i64 %52, %47
  %54 = icmp sgt i64 %53, -1
  %55 = select i1 %54, i64 1073741824, i64 -1073741823
  %56 = add nsw i64 %55, %53
  %57 = sdiv i64 %56, 2147483648
  %58 = trunc i64 %57 to i32
  br label %59

59:                                               ; preds = %51, %38
  %60 = phi i32 [ %58, %51 ], [ 2147483647, %38 ]
  %61 = and i32 %60, %35
  %62 = lshr i32 %60, 31
  %63 = add nsw i32 %62, %36
  %64 = ashr i32 %60, %31
  %65 = icmp sgt i32 %61, %63
  %66 = zext i1 %65 to i32
  %67 = add i32 %64, %22
  %68 = add i32 %67, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %13, i64 0, i32 0, i64 %39
  store i32 %68, i32* %69, align 4, !alias.scope !897, !noalias !894
  %70 = add nuw nsw i64 %39, 1
  %71 = icmp eq i64 %70, 32
  br i1 %71, label %72, label %38

72:                                               ; preds = %59
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #18, !noalias !894
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %15, i8* nonnull align 4 %17, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %17) #18, !noalias !894
  %73 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %73, i8 -86, i64 128, i1 false), !alias.scope !901, !noalias !904
  %74 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %74) #18, !noalias !907
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %75) #18, !noalias !907
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %75, i8* nonnull align 4 %15, i64 128, i1 false)
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.500", %"struct.gemmlowp::OutputPipelineEvalImpl.500"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %77 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %76, align 8, !noalias !908
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !908
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 1
  %81 = load i32, i32* %80, align 4, !noalias !908
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %74, i8 -86, i64 128, i1 false) #18, !alias.scope !911, !noalias !907
  %82 = insertelement <4 x i32> undef, i32 %79, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = insertelement <4 x i32> undef, i32 %81, i32 0
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> zeroinitializer
  %86 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %9 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16, !noalias !908
  %88 = icmp slt <4 x i32> %87, %83
  %89 = select <4 x i1> %88, <4 x i32> %83, <4 x i32> %87
  %90 = icmp slt <4 x i32> %85, %89
  %91 = select <4 x i1> %90, <4 x i32> %85, <4 x i32> %89
  %92 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %10 to <4 x i32>*
  store <4 x i32> %91, <4 x i32>* %92, align 16, !alias.scope !911, !noalias !907
  %93 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 4
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16, !noalias !908
  %96 = icmp slt <4 x i32> %95, %83
  %97 = select <4 x i1> %96, <4 x i32> %83, <4 x i32> %95
  %98 = icmp slt <4 x i32> %85, %97
  %99 = select <4 x i1> %98, <4 x i32> %85, <4 x i32> %97
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 4
  %101 = bitcast i32* %100 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %101, align 16, !alias.scope !911, !noalias !907
  %102 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 8
  %103 = bitcast i32* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16, !noalias !908
  %105 = icmp slt <4 x i32> %104, %83
  %106 = select <4 x i1> %105, <4 x i32> %83, <4 x i32> %104
  %107 = icmp slt <4 x i32> %85, %106
  %108 = select <4 x i1> %107, <4 x i32> %85, <4 x i32> %106
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 8
  %110 = bitcast i32* %109 to <4 x i32>*
  store <4 x i32> %108, <4 x i32>* %110, align 16, !alias.scope !911, !noalias !907
  %111 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 12
  %112 = bitcast i32* %111 to <4 x i32>*
  %113 = load <4 x i32>, <4 x i32>* %112, align 16, !noalias !908
  %114 = icmp slt <4 x i32> %113, %83
  %115 = select <4 x i1> %114, <4 x i32> %83, <4 x i32> %113
  %116 = icmp slt <4 x i32> %85, %115
  %117 = select <4 x i1> %116, <4 x i32> %85, <4 x i32> %115
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 12
  %119 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %117, <4 x i32>* %119, align 16, !alias.scope !911, !noalias !907
  %120 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 16
  %121 = bitcast i32* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16, !noalias !908
  %123 = icmp slt <4 x i32> %122, %83
  %124 = select <4 x i1> %123, <4 x i32> %83, <4 x i32> %122
  %125 = icmp slt <4 x i32> %85, %124
  %126 = select <4 x i1> %125, <4 x i32> %85, <4 x i32> %124
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 16
  %128 = bitcast i32* %127 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %128, align 16, !alias.scope !911, !noalias !907
  %129 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 20
  %130 = bitcast i32* %129 to <4 x i32>*
  %131 = load <4 x i32>, <4 x i32>* %130, align 16, !noalias !908
  %132 = icmp slt <4 x i32> %131, %83
  %133 = select <4 x i1> %132, <4 x i32> %83, <4 x i32> %131
  %134 = icmp slt <4 x i32> %85, %133
  %135 = select <4 x i1> %134, <4 x i32> %85, <4 x i32> %133
  %136 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 20
  %137 = bitcast i32* %136 to <4 x i32>*
  store <4 x i32> %135, <4 x i32>* %137, align 16, !alias.scope !911, !noalias !907
  %138 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 24
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16, !noalias !908
  %141 = icmp slt <4 x i32> %140, %83
  %142 = select <4 x i1> %141, <4 x i32> %83, <4 x i32> %140
  %143 = icmp slt <4 x i32> %85, %142
  %144 = select <4 x i1> %143, <4 x i32> %85, <4 x i32> %142
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 24
  %146 = bitcast i32* %145 to <4 x i32>*
  store <4 x i32> %144, <4 x i32>* %146, align 16, !alias.scope !911, !noalias !907
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %9, i64 0, i32 0, i64 28
  %148 = bitcast i32* %147 to <4 x i32>*
  %149 = load <4 x i32>, <4 x i32>* %148, align 16, !noalias !908
  %150 = icmp slt <4 x i32> %149, %83
  %151 = select <4 x i1> %150, <4 x i32> %83, <4 x i32> %149
  %152 = icmp slt <4 x i32> %85, %151
  %153 = select <4 x i1> %152, <4 x i32> %85, <4 x i32> %151
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %10, i64 0, i32 0, i64 28
  %155 = bitcast i32* %154 to <4 x i32>*
  store <4 x i32> %153, <4 x i32>* %155, align 16, !alias.scope !911, !noalias !907
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %75) #18, !noalias !907
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %73, i8* nonnull align 16 %74, i64 128, i1 false) #18, !noalias !904
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %74) #18, !noalias !907
  %156 = bitcast [32 x i16]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %156, i8 -86, i64 64, i1 false), !alias.scope !912, !noalias !915
  %157 = bitcast %"struct.gemmlowp::RegisterBuffer.389"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %157) #18, !noalias !918
  %158 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %158) #18, !noalias !918
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %158, i8* nonnull align 4 %73, i64 128, i1 false) #18, !noalias !904
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %157, i8 -86, i64 64, i1 false) #18, !alias.scope !919, !noalias !918
  %159 = bitcast %"struct.gemmlowp::RegisterBuffer.381"* %6 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16, !noalias !922
  %161 = icmp sgt <4 x i32> %160, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %162 = select <4 x i1> %161, <4 x i32> %160, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %163 = icmp slt <4 x i32> %162, <i32 32767, i32 32767, i32 32767, i32 32767>
  %164 = select <4 x i1> %163, <4 x i32> %162, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %165 = trunc <4 x i32> %164 to <4 x i16>
  %166 = bitcast %"struct.gemmlowp::RegisterBuffer.389"* %7 to <4 x i16>*
  store <4 x i16> %165, <4 x i16>* %166, align 8, !alias.scope !919, !noalias !918
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 4
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16, !noalias !922
  %170 = icmp sgt <4 x i32> %169, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %172 = icmp slt <4 x i32> %171, <i32 32767, i32 32767, i32 32767, i32 32767>
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %174 = trunc <4 x i32> %173 to <4 x i16>
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 4
  %176 = bitcast i16* %175 to <4 x i16>*
  store <4 x i16> %174, <4 x i16>* %176, align 8, !alias.scope !919, !noalias !918
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 8
  %178 = bitcast i32* %177 to <4 x i32>*
  %179 = load <4 x i32>, <4 x i32>* %178, align 16, !noalias !922
  %180 = icmp sgt <4 x i32> %179, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %182 = icmp slt <4 x i32> %181, <i32 32767, i32 32767, i32 32767, i32 32767>
  %183 = select <4 x i1> %182, <4 x i32> %181, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %184 = trunc <4 x i32> %183 to <4 x i16>
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 8
  %186 = bitcast i16* %185 to <4 x i16>*
  store <4 x i16> %184, <4 x i16>* %186, align 8, !alias.scope !919, !noalias !918
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 12
  %188 = bitcast i32* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16, !noalias !922
  %190 = icmp sgt <4 x i32> %189, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %192 = icmp slt <4 x i32> %191, <i32 32767, i32 32767, i32 32767, i32 32767>
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %194 = trunc <4 x i32> %193 to <4 x i16>
  %195 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 12
  %196 = bitcast i16* %195 to <4 x i16>*
  store <4 x i16> %194, <4 x i16>* %196, align 8, !alias.scope !919, !noalias !918
  %197 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 16
  %198 = bitcast i32* %197 to <4 x i32>*
  %199 = load <4 x i32>, <4 x i32>* %198, align 16, !noalias !922
  %200 = icmp sgt <4 x i32> %199, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %202 = icmp slt <4 x i32> %201, <i32 32767, i32 32767, i32 32767, i32 32767>
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %204 = trunc <4 x i32> %203 to <4 x i16>
  %205 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 16
  %206 = bitcast i16* %205 to <4 x i16>*
  store <4 x i16> %204, <4 x i16>* %206, align 8, !alias.scope !919, !noalias !918
  %207 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 20
  %208 = bitcast i32* %207 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16, !noalias !922
  %210 = icmp sgt <4 x i32> %209, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %212 = icmp slt <4 x i32> %211, <i32 32767, i32 32767, i32 32767, i32 32767>
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %214 = trunc <4 x i32> %213 to <4 x i16>
  %215 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 20
  %216 = bitcast i16* %215 to <4 x i16>*
  store <4 x i16> %214, <4 x i16>* %216, align 8, !alias.scope !919, !noalias !918
  %217 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 24
  %218 = bitcast i32* %217 to <4 x i32>*
  %219 = load <4 x i32>, <4 x i32>* %218, align 16, !noalias !922
  %220 = icmp sgt <4 x i32> %219, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %222 = icmp slt <4 x i32> %221, <i32 32767, i32 32767, i32 32767, i32 32767>
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %224 = trunc <4 x i32> %223 to <4 x i16>
  %225 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 24
  %226 = bitcast i16* %225 to <4 x i16>*
  store <4 x i16> %224, <4 x i16>* %226, align 8, !alias.scope !919, !noalias !918
  %227 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.381", %"struct.gemmlowp::RegisterBuffer.381"* %6, i64 0, i32 0, i64 28
  %228 = bitcast i32* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16, !noalias !922
  %230 = icmp sgt <4 x i32> %229, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %232 = icmp slt <4 x i32> %231, <i32 32767, i32 32767, i32 32767, i32 32767>
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %234 = trunc <4 x i32> %233 to <4 x i16>
  %235 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.389", %"struct.gemmlowp::RegisterBuffer.389"* %7, i64 0, i32 0, i64 28
  %236 = bitcast i16* %235 to <4 x i16>*
  store <4 x i16> %234, <4 x i16>* %236, align 8, !alias.scope !919, !noalias !918
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %158) #18, !noalias !918
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 2 %156, i8* nonnull align 8 %157, i64 64, i1 false) #18, !noalias !915
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %157) #18, !noalias !918
  %237 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %237, i8* nonnull align 2 %156, i64 64, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvS8_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.492"*, %"struct.gemmlowp::RegisterBlock.390"* byval(%"struct.gemmlowp::RegisterBlock.390") align 8, %"class.gemmlowp::MatrixMap.273"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBuffer.391", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.391", align 8
  %10 = alloca [16 x i32], align 8
  %11 = alloca %"struct.gemmlowp::RegisterBlock.393", align 2
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %12) #18
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 0
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 1
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 2
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 3
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 4
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 5
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 6
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 7
  %21 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 9
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 10
  %24 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 11
  %25 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 12
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 13
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 14
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 15
  %29 = bitcast %"struct.gemmlowp::RegisterBlock.390"* %1 to i8*
  %30 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %30, i8 -86, i64 32, i1 false)
  %31 = bitcast [16 x i32]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %31) #18, !noalias !923
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %31, i8 -86, i64 64, i1 false) #18, !alias.scope !926, !noalias !923
  %32 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %32) #18, !noalias !929
  %33 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %33) #18, !noalias !929
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %33, i8* nonnull align 8 %29, i64 64, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %32, i8 -86, i64 64, i1 false) #18, !alias.scope !930, !noalias !929
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %35 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %34, align 8, !noalias !933
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %35, i64 0, i32 2
  %37 = load i32, i32* %36, align 4, !noalias !933
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %39 = load i32, i32* %38, align 8, !noalias !933
  %40 = shl i32 1, %39
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %35, i64 0, i32 0
  %43 = load i32, i32* %42, align 4, !noalias !933
  %44 = sext i32 %43 to i64
  %45 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %46 = load i32, i32* %45, align 4, !noalias !933
  %47 = zext i32 %46 to i64
  %48 = shl nsw i64 -1, %47
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %49, -1
  %51 = ashr i32 %50, 1
  %52 = icmp ne i32 %43, -2147483648
  br label %53

53:                                               ; preds = %74, %7
  %54 = phi i64 [ 0, %7 ], [ %85, %74 ]
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %8, i64 0, i32 0, i64 %54
  %56 = load i32, i32* %55, align 4, !noalias !933
  %57 = sext i32 %56 to i64
  %58 = mul nsw i64 %57, %41
  %59 = icmp slt i64 %58, 2147483647
  %60 = select i1 %59, i64 %58, i64 2147483647
  %61 = icmp sgt i64 %60, -2147483648
  %62 = select i1 %61, i64 %60, i64 -2147483648
  %63 = trunc i64 %62 to i32
  %64 = icmp ne i32 %43, %63
  %65 = or i1 %52, %64
  br i1 %65, label %66, label %74

66:                                               ; preds = %53
  %67 = select i1 %64, i64 %44, i64 %62
  %68 = mul nsw i64 %67, %62
  %69 = icmp sgt i64 %68, -1
  %70 = select i1 %69, i64 1073741824, i64 -1073741823
  %71 = add nsw i64 %70, %68
  %72 = sdiv i64 %71, 2147483648
  %73 = trunc i64 %72 to i32
  br label %74

74:                                               ; preds = %66, %53
  %75 = phi i32 [ %73, %66 ], [ 2147483647, %53 ]
  %76 = and i32 %75, %50
  %77 = lshr i32 %75, 31
  %78 = add nsw i32 %77, %51
  %79 = ashr i32 %75, %46
  %80 = icmp sgt i32 %76, %78
  %81 = zext i1 %80 to i32
  %82 = add i32 %79, %37
  %83 = add i32 %82, %81
  %84 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %9, i64 0, i32 0, i64 %54
  store i32 %83, i32* %84, align 4, !alias.scope !930, !noalias !929
  %85 = add nuw nsw i64 %54, 1
  %86 = icmp eq i64 %85, 16
  br i1 %86, label %87, label %53

87:                                               ; preds = %74
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %33) #18, !noalias !929
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %31, i8* nonnull align 8 %32, i64 64, i1 false) #18, !noalias !923
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %32) #18, !noalias !929
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %0, i64 0, i32 0, i32 1
  %89 = bitcast [16 x i32]* %10 to %"struct.gemmlowp::RegisterBlock.390"*
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.393"* nonnull sret %11, %"struct.gemmlowp::OutputPipelineEvalImpl.494"* %88, %"struct.gemmlowp::RegisterBlock.390"* nonnull byval(%"struct.gemmlowp::RegisterBlock.390") align 8 %89, i32 %3, i32 %4) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %31) #18, !noalias !923
  %90 = load i16, i16* %13, align 2
  %91 = load i16, i16* %14, align 2
  %92 = load i16, i16* %15, align 2
  %93 = load i16, i16* %16, align 2
  %94 = load i16, i16* %17, align 2
  %95 = load i16, i16* %18, align 2
  %96 = load i16, i16* %19, align 2
  %97 = load i16, i16* %20, align 2
  %98 = load i16, i16* %21, align 2
  %99 = load i16, i16* %22, align 2
  %100 = load i16, i16* %23, align 2
  %101 = load i16, i16* %24, align 2
  %102 = load i16, i16* %25, align 2
  %103 = load i16, i16* %26, align 2
  %104 = load i16, i16* %27, align 2
  %105 = load i16, i16* %28, align 2
  %106 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 0
  %107 = getelementptr inbounds %"class.gemmlowp::MatrixMap.273", %"class.gemmlowp::MatrixMap.273"* %2, i64 0, i32 3
  %108 = sext i32 %6 to i64
  %109 = sext i32 %5 to i64
  %110 = load i16*, i16** %106, align 8
  %111 = load i32, i32* %107, align 8
  %112 = sext i32 %111 to i64
  %113 = mul nsw i64 %112, %109
  %114 = getelementptr inbounds i16, i16* %110, i64 %113
  %115 = getelementptr inbounds i16, i16* %114, i64 %108
  store i16 %90, i16* %115, align 2
  %116 = add nsw i64 %108, 1
  %117 = load i16*, i16** %106, align 8
  %118 = load i32, i32* %107, align 8
  %119 = sext i32 %118 to i64
  %120 = mul nsw i64 %119, %109
  %121 = getelementptr inbounds i16, i16* %117, i64 %120
  %122 = getelementptr inbounds i16, i16* %121, i64 %116
  store i16 %94, i16* %122, align 2
  %123 = add nsw i64 %108, 2
  %124 = load i16*, i16** %106, align 8
  %125 = load i32, i32* %107, align 8
  %126 = sext i32 %125 to i64
  %127 = mul nsw i64 %126, %109
  %128 = getelementptr inbounds i16, i16* %124, i64 %127
  %129 = getelementptr inbounds i16, i16* %128, i64 %123
  store i16 %98, i16* %129, align 2
  %130 = add nsw i64 %108, 3
  %131 = load i16*, i16** %106, align 8
  %132 = load i32, i32* %107, align 8
  %133 = sext i32 %132 to i64
  %134 = mul nsw i64 %133, %109
  %135 = getelementptr inbounds i16, i16* %131, i64 %134
  %136 = getelementptr inbounds i16, i16* %135, i64 %130
  store i16 %102, i16* %136, align 2
  %137 = add nsw i64 %109, 1
  %138 = load i16*, i16** %106, align 8
  %139 = load i32, i32* %107, align 8
  %140 = sext i32 %139 to i64
  %141 = mul nsw i64 %137, %140
  %142 = getelementptr inbounds i16, i16* %138, i64 %141
  %143 = getelementptr inbounds i16, i16* %142, i64 %108
  store i16 %91, i16* %143, align 2
  %144 = load i16*, i16** %106, align 8
  %145 = load i32, i32* %107, align 8
  %146 = sext i32 %145 to i64
  %147 = mul nsw i64 %137, %146
  %148 = getelementptr inbounds i16, i16* %144, i64 %147
  %149 = getelementptr inbounds i16, i16* %148, i64 %116
  store i16 %95, i16* %149, align 2
  %150 = load i16*, i16** %106, align 8
  %151 = load i32, i32* %107, align 8
  %152 = sext i32 %151 to i64
  %153 = mul nsw i64 %137, %152
  %154 = getelementptr inbounds i16, i16* %150, i64 %153
  %155 = getelementptr inbounds i16, i16* %154, i64 %123
  store i16 %99, i16* %155, align 2
  %156 = load i16*, i16** %106, align 8
  %157 = load i32, i32* %107, align 8
  %158 = sext i32 %157 to i64
  %159 = mul nsw i64 %137, %158
  %160 = getelementptr inbounds i16, i16* %156, i64 %159
  %161 = getelementptr inbounds i16, i16* %160, i64 %130
  store i16 %103, i16* %161, align 2
  %162 = add nsw i64 %109, 2
  %163 = load i16*, i16** %106, align 8
  %164 = load i32, i32* %107, align 8
  %165 = sext i32 %164 to i64
  %166 = mul nsw i64 %162, %165
  %167 = getelementptr inbounds i16, i16* %163, i64 %166
  %168 = getelementptr inbounds i16, i16* %167, i64 %108
  store i16 %92, i16* %168, align 2
  %169 = load i16*, i16** %106, align 8
  %170 = load i32, i32* %107, align 8
  %171 = sext i32 %170 to i64
  %172 = mul nsw i64 %162, %171
  %173 = getelementptr inbounds i16, i16* %169, i64 %172
  %174 = getelementptr inbounds i16, i16* %173, i64 %116
  store i16 %96, i16* %174, align 2
  %175 = load i16*, i16** %106, align 8
  %176 = load i32, i32* %107, align 8
  %177 = sext i32 %176 to i64
  %178 = mul nsw i64 %162, %177
  %179 = getelementptr inbounds i16, i16* %175, i64 %178
  %180 = getelementptr inbounds i16, i16* %179, i64 %123
  store i16 %100, i16* %180, align 2
  %181 = load i16*, i16** %106, align 8
  %182 = load i32, i32* %107, align 8
  %183 = sext i32 %182 to i64
  %184 = mul nsw i64 %162, %183
  %185 = getelementptr inbounds i16, i16* %181, i64 %184
  %186 = getelementptr inbounds i16, i16* %185, i64 %130
  store i16 %104, i16* %186, align 2
  %187 = add nsw i64 %109, 3
  %188 = load i16*, i16** %106, align 8
  %189 = load i32, i32* %107, align 8
  %190 = sext i32 %189 to i64
  %191 = mul nsw i64 %187, %190
  %192 = getelementptr inbounds i16, i16* %188, i64 %191
  %193 = getelementptr inbounds i16, i16* %192, i64 %108
  store i16 %93, i16* %193, align 2
  %194 = load i16*, i16** %106, align 8
  %195 = load i32, i32* %107, align 8
  %196 = sext i32 %195 to i64
  %197 = mul nsw i64 %187, %196
  %198 = getelementptr inbounds i16, i16* %194, i64 %197
  %199 = getelementptr inbounds i16, i16* %198, i64 %116
  store i16 %97, i16* %199, align 2
  %200 = load i16*, i16** %106, align 8
  %201 = load i32, i32* %107, align 8
  %202 = sext i32 %201 to i64
  %203 = mul nsw i64 %187, %202
  %204 = getelementptr inbounds i16, i16* %200, i64 %203
  %205 = getelementptr inbounds i16, i16* %204, i64 %123
  store i16 %101, i16* %205, align 2
  %206 = load i16*, i16** %106, align 8
  %207 = load i32, i32* %107, align 8
  %208 = sext i32 %207 to i64
  %209 = mul nsw i64 %187, %208
  %210 = getelementptr inbounds i16, i16* %206, i64 %209
  %211 = getelementptr inbounds i16, i16* %210, i64 %130
  store i16 %105, i16* %211, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %12) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.393"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.494"*, %"struct.gemmlowp::RegisterBlock.390"* byval(%"struct.gemmlowp::RegisterBlock.390") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.390"* %2 to <8 x i32>*
  %7 = load <8 x i32>, <8 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 8
  %9 = load i32, i32* %8, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 9
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 10
  %13 = load i32, i32* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 11
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 12
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 13
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 14
  %21 = load i32, i32* %20, align 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %2, i64 0, i32 0, i32 0, i64 15
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.494", %"struct.gemmlowp::OutputPipelineEvalImpl.494"* %1, i64 0, i32 0, i32 0, i32 0
  %25 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %24, align 8, !noalias !934
  %26 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 0
  %27 = load i32, i32* %26, align 4, !noalias !934
  %28 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 1
  %29 = load i32, i32* %28, align 4, !noalias !934
  %30 = insertelement <8 x i32> undef, i32 %27, i32 0
  %31 = shufflevector <8 x i32> %30, <8 x i32> undef, <8 x i32> zeroinitializer
  %32 = icmp slt <8 x i32> %7, %31
  %33 = select <8 x i1> %32, <8 x i32> %31, <8 x i32> %7
  %34 = insertelement <8 x i32> undef, i32 %29, i32 0
  %35 = shufflevector <8 x i32> %34, <8 x i32> undef, <8 x i32> zeroinitializer
  %36 = icmp slt <8 x i32> %35, %33
  %37 = select <8 x i1> %36, <8 x i32> %35, <8 x i32> %33
  %38 = icmp slt i32 %9, %27
  %39 = select i1 %38, i32 %27, i32 %9
  %40 = icmp slt i32 %29, %39
  %41 = select i1 %40, i32 %29, i32 %39
  %42 = icmp slt i32 %11, %27
  %43 = select i1 %42, i32 %27, i32 %11
  %44 = icmp slt i32 %29, %43
  %45 = select i1 %44, i32 %29, i32 %43
  %46 = icmp slt i32 %13, %27
  %47 = select i1 %46, i32 %27, i32 %13
  %48 = icmp slt i32 %29, %47
  %49 = select i1 %48, i32 %29, i32 %47
  %50 = icmp slt i32 %15, %27
  %51 = select i1 %50, i32 %27, i32 %15
  %52 = icmp slt i32 %29, %51
  %53 = select i1 %52, i32 %29, i32 %51
  %54 = icmp slt i32 %17, %27
  %55 = select i1 %54, i32 %27, i32 %17
  %56 = icmp slt i32 %29, %55
  %57 = select i1 %56, i32 %29, i32 %55
  %58 = icmp slt i32 %19, %27
  %59 = select i1 %58, i32 %27, i32 %19
  %60 = icmp slt i32 %29, %59
  %61 = select i1 %60, i32 %29, i32 %59
  %62 = icmp slt i32 %21, %27
  %63 = select i1 %62, i32 %27, i32 %21
  %64 = icmp slt i32 %29, %63
  %65 = select i1 %64, i32 %29, i32 %63
  %66 = icmp slt i32 %23, %27
  %67 = select i1 %66, i32 %27, i32 %23
  %68 = icmp slt i32 %29, %67
  %69 = select i1 %68, i32 %29, i32 %67
  %70 = icmp sgt <8 x i32> %37, <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %71 = select <8 x i1> %70, <8 x i32> %37, <8 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %72 = icmp slt <8 x i32> %71, <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %73 = select <8 x i1> %72, <8 x i32> %71, <8 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %74 = trunc <8 x i32> %73 to <8 x i16>
  %75 = icmp sgt i32 %41, -32768
  %76 = select i1 %75, i32 %41, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = trunc i32 %78 to i16
  %80 = icmp sgt i32 %45, -32768
  %81 = select i1 %80, i32 %45, i32 -32768
  %82 = icmp slt i32 %81, 32767
  %83 = select i1 %82, i32 %81, i32 32767
  %84 = trunc i32 %83 to i16
  %85 = icmp sgt i32 %49, -32768
  %86 = select i1 %85, i32 %49, i32 -32768
  %87 = icmp slt i32 %86, 32767
  %88 = select i1 %87, i32 %86, i32 32767
  %89 = trunc i32 %88 to i16
  %90 = icmp sgt i32 %53, -32768
  %91 = select i1 %90, i32 %53, i32 -32768
  %92 = icmp slt i32 %91, 32767
  %93 = select i1 %92, i32 %91, i32 32767
  %94 = trunc i32 %93 to i16
  %95 = icmp sgt i32 %57, -32768
  %96 = select i1 %95, i32 %57, i32 -32768
  %97 = icmp slt i32 %96, 32767
  %98 = select i1 %97, i32 %96, i32 32767
  %99 = icmp sgt i32 %61, -32768
  %100 = select i1 %99, i32 %61, i32 -32768
  %101 = icmp slt i32 %100, 32767
  %102 = select i1 %101, i32 %100, i32 32767
  %103 = shl nsw i32 %102, 16
  %104 = and i32 %98, 65535
  %105 = or i32 %103, %104
  %106 = zext i32 %105 to i64
  %107 = icmp sgt i32 %65, -32768
  %108 = select i1 %107, i32 %65, i32 -32768
  %109 = icmp slt i32 %108, 32767
  %110 = select i1 %109, i32 %108, i32 32767
  %111 = and i32 %110, 65535
  %112 = zext i32 %111 to i64
  %113 = shl nuw nsw i64 %112, 32
  %114 = icmp sgt i32 %69, -32768
  %115 = select i1 %114, i32 %69, i32 -32768
  %116 = icmp slt i32 %115, 32767
  %117 = select i1 %116, i32 %115, i32 32767
  %118 = zext i32 %117 to i64
  %119 = shl i64 %118, 48
  %120 = or i64 %119, %106
  %121 = or i64 %120, %113
  %122 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %0 to <8 x i16>*
  store <8 x i16> %74, <8 x i16>* %122, align 2, !alias.scope !939
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 8
  store i16 %79, i16* %123, align 2, !alias.scope !939
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 9
  store i16 %84, i16* %124, align 2, !alias.scope !939
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 10
  store i16 %89, i16* %125, align 2, !alias.scope !939
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 11
  store i16 %94, i16* %126, align 2, !alias.scope !939
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %0, i64 0, i32 0, i32 0, i64 12
  %128 = bitcast i16* %127 to i64*
  store i64 %121, i64* %128, align 2, !alias.scope !939
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.479"*, %"struct.gemmlowp::RegisterBlock.382"* byval(%"struct.gemmlowp::RegisterBlock.382") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.383", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.383", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBlock.382", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %1 to i8*
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #18, !noalias !942
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #18, !noalias !942
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* nonnull align 8 %8, i64 32, i1 false)
  %11 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.479", %"struct.gemmlowp::OutputPipelineEvalImpl.479"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #18, !alias.scope !945, !noalias !942
  %12 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %11, align 8, !noalias !948
  %13 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 2
  %14 = load i32, i32* %13, align 4, !noalias !948
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.479", %"struct.gemmlowp::OutputPipelineEvalImpl.479"* %0, i64 0, i32 0, i32 0, i32 1
  %16 = load i32, i32* %15, align 8, !noalias !948
  %17 = shl i32 1, %16
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !948
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.479", %"struct.gemmlowp::OutputPipelineEvalImpl.479"* %0, i64 0, i32 0, i32 0, i32 2
  %23 = load i32, i32* %22, align 4, !noalias !948
  %24 = zext i32 %23 to i64
  %25 = shl nsw i64 -1, %24
  %26 = trunc i64 %25 to i32
  %27 = xor i32 %26, -1
  %28 = ashr i32 %27, 1
  %29 = icmp ne i32 %20, -2147483648
  br label %30

30:                                               ; preds = %51, %4
  %31 = phi i64 [ 0, %4 ], [ %62, %51 ]
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %5, i64 0, i32 0, i64 %31
  %33 = load i32, i32* %32, align 4, !noalias !948
  %34 = sext i32 %33 to i64
  %35 = mul nsw i64 %34, %18
  %36 = icmp slt i64 %35, 2147483647
  %37 = select i1 %36, i64 %35, i64 2147483647
  %38 = icmp sgt i64 %37, -2147483648
  %39 = select i1 %38, i64 %37, i64 -2147483648
  %40 = trunc i64 %39 to i32
  %41 = icmp ne i32 %20, %40
  %42 = or i1 %29, %41
  br i1 %42, label %43, label %51

43:                                               ; preds = %30
  %44 = select i1 %41, i64 %21, i64 %39
  %45 = mul nsw i64 %44, %39
  %46 = icmp sgt i64 %45, -1
  %47 = select i1 %46, i64 1073741824, i64 -1073741823
  %48 = add nsw i64 %47, %45
  %49 = sdiv i64 %48, 2147483648
  %50 = trunc i64 %49 to i32
  br label %51

51:                                               ; preds = %43, %30
  %52 = phi i32 [ %50, %43 ], [ 2147483647, %30 ]
  %53 = and i32 %52, %27
  %54 = lshr i32 %52, 31
  %55 = add nsw i32 %54, %28
  %56 = ashr i32 %52, %23
  %57 = icmp sgt i32 %53, %55
  %58 = zext i1 %57 to i32
  %59 = add i32 %56, %14
  %60 = add i32 %59, %58
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %6, i64 0, i32 0, i64 %31
  store i32 %60, i32* %61, align 4, !alias.scope !945, !noalias !942
  %62 = add nuw nsw i64 %31, 1
  %63 = icmp eq i64 %62, 8
  br i1 %63, label %64, label %30

64:                                               ; preds = %51
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #18, !noalias !942
  %65 = bitcast %"struct.gemmlowp::RegisterBuffer.383"* %6 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.383", %"struct.gemmlowp::RegisterBuffer.383"* %6, i64 0, i32 0, i64 4
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #18, !noalias !942
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.479", %"struct.gemmlowp::OutputPipelineEvalImpl.479"* %0, i64 0, i32 1
  %71 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %7 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %71, align 16
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %7, i64 0, i32 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  store <4 x i32> %69, <4 x i32>* %73, align 16
  %74 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.480"* %70, %"struct.gemmlowp::RegisterBlock.382"* nonnull byval(%"struct.gemmlowp::RegisterBlock.382") align 8 %7, i32 %2, i32 %3)
  ret { i64, i64 } %74
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.480"*, %"struct.gemmlowp::RegisterBlock.382"* byval(%"struct.gemmlowp::RegisterBlock.382") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 0
  %6 = load i32, i32* %5, align 8
  %7 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 3
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 4
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 5
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 6
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %1, i64 0, i32 0, i32 0, i64 7
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.480", %"struct.gemmlowp::OutputPipelineEvalImpl.480"* %0, i64 0, i32 0, i32 0, i32 0
  %22 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %21, align 8, !noalias !949
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 0
  %24 = load i32, i32* %23, align 4, !noalias !949
  %25 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 1
  %26 = load i32, i32* %25, align 4, !noalias !949
  %27 = icmp slt i32 %6, %24
  %28 = select i1 %27, i32 %24, i32 %6
  %29 = icmp slt i32 %26, %28
  %30 = select i1 %29, i32 %26, i32 %28
  %31 = icmp slt i32 %8, %24
  %32 = select i1 %31, i32 %24, i32 %8
  %33 = icmp slt i32 %26, %32
  %34 = select i1 %33, i32 %26, i32 %32
  %35 = icmp slt i32 %10, %24
  %36 = select i1 %35, i32 %24, i32 %10
  %37 = icmp slt i32 %26, %36
  %38 = select i1 %37, i32 %26, i32 %36
  %39 = icmp slt i32 %12, %24
  %40 = select i1 %39, i32 %24, i32 %12
  %41 = icmp slt i32 %26, %40
  %42 = select i1 %41, i32 %26, i32 %40
  %43 = icmp slt i32 %14, %24
  %44 = select i1 %43, i32 %24, i32 %14
  %45 = icmp slt i32 %26, %44
  %46 = select i1 %45, i32 %26, i32 %44
  %47 = icmp slt i32 %16, %24
  %48 = select i1 %47, i32 %24, i32 %16
  %49 = icmp slt i32 %26, %48
  %50 = select i1 %49, i32 %26, i32 %48
  %51 = icmp slt i32 %18, %24
  %52 = select i1 %51, i32 %24, i32 %18
  %53 = icmp slt i32 %26, %52
  %54 = select i1 %53, i32 %26, i32 %52
  %55 = icmp slt i32 %20, %24
  %56 = select i1 %55, i32 %24, i32 %20
  %57 = icmp slt i32 %26, %56
  %58 = select i1 %57, i32 %26, i32 %56
  %59 = icmp sgt i32 %30, -32768
  %60 = select i1 %59, i32 %30, i32 -32768
  %61 = icmp slt i32 %60, 32767
  %62 = select i1 %61, i32 %60, i32 32767
  %63 = icmp sgt i32 %34, -32768
  %64 = select i1 %63, i32 %34, i32 -32768
  %65 = icmp slt i32 %64, 32767
  %66 = select i1 %65, i32 %64, i32 32767
  %67 = icmp sgt i32 %38, -32768
  %68 = select i1 %67, i32 %38, i32 -32768
  %69 = icmp slt i32 %68, 32767
  %70 = select i1 %69, i32 %68, i32 32767
  %71 = icmp sgt i32 %42, -32768
  %72 = select i1 %71, i32 %42, i32 -32768
  %73 = icmp slt i32 %72, 32767
  %74 = select i1 %73, i32 %72, i32 32767
  %75 = icmp sgt i32 %46, -32768
  %76 = select i1 %75, i32 %46, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = icmp sgt i32 %50, -32768
  %80 = select i1 %79, i32 %50, i32 -32768
  %81 = icmp slt i32 %80, 32767
  %82 = select i1 %81, i32 %80, i32 32767
  %83 = shl nsw i32 %82, 16
  %84 = and i32 %78, 65535
  %85 = or i32 %83, %84
  %86 = zext i32 %85 to i64
  %87 = icmp sgt i32 %54, -32768
  %88 = select i1 %87, i32 %54, i32 -32768
  %89 = icmp slt i32 %88, 32767
  %90 = select i1 %89, i32 %88, i32 32767
  %91 = and i32 %90, 65535
  %92 = zext i32 %91 to i64
  %93 = shl nuw nsw i64 %92, 32
  %94 = icmp sgt i32 %58, -32768
  %95 = select i1 %94, i32 %58, i32 -32768
  %96 = icmp slt i32 %95, 32767
  %97 = select i1 %96, i32 %95, i32 32767
  %98 = zext i32 %97 to i64
  %99 = shl i64 %98, 48
  %100 = or i64 %99, %86
  %101 = or i64 %100, %93
  %102 = zext i32 %74 to i64
  %103 = shl i64 %102, 48
  %104 = and i32 %70, 65535
  %105 = zext i32 %104 to i64
  %106 = shl nuw nsw i64 %105, 32
  %107 = shl nsw i32 %66, 16
  %108 = and i32 %62, 65535
  %109 = or i32 %107, %108
  %110 = zext i32 %109 to i64
  %111 = or i64 %103, %110
  %112 = or i64 %111, %106
  %113 = insertvalue { i64, i64 } undef, i64 %112, 0
  %114 = insertvalue { i64, i64 } %113, i64 %101, 1
  ret { i64, i64 } %114
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.463"*) unnamed_addr #5 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.463"*) unnamed_addr #5 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #17
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.463"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !954
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !954
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !954
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !954
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !954
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !954
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #18
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !957
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !957
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !957
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !957
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !957
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !957
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #18
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !960
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !960
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !960
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !960
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !960
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !960
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #18
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup.272"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.463", %"struct.gemmlowp::GemmWithPackedRhsTask.463"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #18
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !963
  %190 = load i32, i32* %115, align 8, !noalias !963
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #18
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #18
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #18
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #18
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #18
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #18
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #18
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #18
  %280 = load %"class.gemmlowp::VectorDup.272"*, %"class.gemmlowp::VectorDup.272"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !966
  store i32 %282, i32* %148, align 4, !alias.scope !966
  store i32 %188, i32* %149, align 4, !alias.scope !966
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #18
  %283 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !969
  store i32 %285, i32* %152, align 4, !alias.scope !969
  store i32 %171, i32* %153, align 4, !alias.scope !969
  %286 = load %"class.std::__1::tuple.265"*, %"class.std::__1::tuple.265"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.273"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.265"* dereferenceable(20) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #18
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.258"* dereferenceable(24), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.std::__1::tuple.265"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup", align 4
  %22 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #18
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !972
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !972
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !972
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !972
  %67 = load i64, i64* %61, align 8, !noalias !972
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !972
  %69 = load i64, i64* %59, align 8, !noalias !972
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !972
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #18
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !975
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !975
  %82 = load i64, i64* %61, align 8, !noalias !975
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !975
  %84 = load i64, i64* %59, align 8, !noalias !975
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !975
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #18
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !978
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !978
  %106 = load i64, i64* %61, align 8, !noalias !978
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !978
  %108 = load i64, i64* %59, align 8, !noalias !978
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !978
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #18
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !981
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !981
  %121 = load i64, i64* %61, align 8, !noalias !981
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !981
  %123 = load i64, i64* %59, align 8, !noalias !981
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !981
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #18
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !984
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !984
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !984
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !984
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #18
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #18
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.258"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #18
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #18
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #18
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.258", %"class.gemmlowp::MatrixMap.258"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup.272"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #18
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !987
  %228 = load i32, i32* %173, align 8, !noalias !987
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #18
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #18
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #18
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !990
  %247 = load i32, i32* %184, align 8, !noalias !990
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #18
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #18
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #18
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #18
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #18
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #18
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #18
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #18
  %332 = load i32, i32* %208, align 4, !noalias !993
  store i32 %332, i32* %209, align 4, !alias.scope !993
  store i32 %226, i32* %210, align 4, !alias.scope !993
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #18
  %333 = load i32, i32* %212, align 4, !noalias !996
  store i32 %333, i32* %213, align 4, !alias.scope !996
  store i32 %244, i32* %214, align 4, !alias.scope !996
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.260"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.265"* dereferenceable(20) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #18
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.260"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), %"class.std::__1::tuple.265"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %10 = alloca %"class.gemmlowp::MatrixMap.292", align 8
  %11 = alloca %"class.gemmlowp::VectorMap", align 8
  %12 = alloca %"class.gemmlowp::VectorMap.279", align 8
  %13 = alloca %"struct.gemmlowp::OutputPipelineExecutor.471", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.478", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.485", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.492", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.499", align 8
  %18 = bitcast %"class.gemmlowp::MatrixMap.292"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %18) #18
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %10, i64 0, i32 0
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %10, i64 0, i32 1
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %10, i64 0, i32 2
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %10, i64 0, i32 3
  %23 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %24 = bitcast %"class.gemmlowp::MatrixMap.292"* %10 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %24, i8 -86, i64 24, i1 false)
  %25 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %23, align 8, !noalias !999
  %26 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %27 = load i8, i8* %26, align 8, !noalias !999
  %28 = zext i8 %27 to i64
  %29 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %25, i64 0, i32 5, i64 %28
  %30 = load i64, i64* %29, align 8, !noalias !999
  %31 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %25, i64 0, i32 2
  %32 = bitcast i8** %31 to i64*
  %33 = load i64, i64* %32, align 8, !noalias !999
  %34 = add i64 %33, %30
  %35 = inttoptr i64 %34 to i32*
  %36 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %37 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %36, align 8, !noalias !999
  %38 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %37, i64 0, i32 3
  %39 = load i32, i32* %38, align 4, !noalias !999
  %40 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %37, i64 0, i32 4
  %41 = load i32, i32* %40, align 4, !noalias !999
  store i32* %35, i32** %19, align 8, !alias.scope !999
  store i32 %39, i32* %20, align 8, !alias.scope !999
  store i32 %41, i32* %21, align 4, !alias.scope !999
  store i32 %39, i32* %22, align 8, !alias.scope !999
  %42 = bitcast %"class.gemmlowp::VectorMap"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %42) #18
  %43 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %11, i64 0, i32 0
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %11, i64 0, i32 1
  %45 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %46 = bitcast %"class.gemmlowp::VectorMap"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %46, i8 -86, i64 16, i1 false)
  %47 = load i32, i32* %45, align 4
  store i32* %4, i32** %43, align 8
  store i32 %47, i32* %44, align 8
  %48 = bitcast %"class.gemmlowp::VectorMap.279"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %48) #18
  %49 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %12, i64 0, i32 0
  %50 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %12, i64 0, i32 1
  %51 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %52 = bitcast %"class.gemmlowp::VectorMap.279"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %52, i8 -86, i64 16, i1 false)
  %53 = load i32, i32* %51, align 4
  store i32* %5, i32** %49, align 8
  store i32 %53, i32* %50, align 8
  %54 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 0, i32 0
  %55 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 0, i32 0, i32 1
  %56 = load i32, i32* %55, align 4
  %57 = icmp sgt i32 %56, 0
  %58 = select i1 %57, i32 %56, i32 0
  %59 = sub nsw i32 0, %56
  %60 = icmp sgt i32 %59, 0
  %61 = select i1 %60, i32 %59, i32 0
  %62 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 1, i32 0
  %63 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.471"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %63) #18
  %64 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %13, i64 0, i32 0, i32 0, i32 0, i32 0
  %65 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %13, i64 0, i32 0, i32 0, i32 0, i32 1
  %66 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %13, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %68 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %13, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %69 = bitcast i8* %68 to i64*
  store i64 -6148914691236517206, i64* %69, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %64, align 8
  store i32 %58, i32* %65, align 8
  store i32 %61, i32* %66, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %67, align 8
  %70 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.478"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %70) #18
  %71 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  %72 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %14, i64 0, i32 0, i32 0, i32 0, i32 1
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %14, i64 0, i32 0, i32 0, i32 0, i32 2
  %74 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %76 = bitcast i8* %75 to i64*
  store i64 -6148914691236517206, i64* %76, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %71, align 8
  store i32 %58, i32* %72, align 8
  store i32 %61, i32* %73, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %74, align 8
  %77 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.485"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %77) #18
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %15, i64 0, i32 0, i32 0, i32 0, i32 0
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %15, i64 0, i32 0, i32 0, i32 0, i32 1
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %15, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %83 = bitcast i8* %82 to i64*
  store i64 -6148914691236517206, i64* %83, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %78, align 8
  store i32 %58, i32* %79, align 8
  store i32 %61, i32* %80, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %84 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.492"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %84) #18
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %16, i64 0, i32 0, i32 0, i32 0, i32 0
  %86 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %16, i64 0, i32 0, i32 0, i32 0, i32 1
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %16, i64 0, i32 0, i32 0, i32 0, i32 2
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %90 = bitcast i8* %89 to i64*
  store i64 -6148914691236517206, i64* %90, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %85, align 8
  store i32 %58, i32* %86, align 8
  store i32 %61, i32* %87, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %88, align 8
  %91 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.499"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %91) #18
  %92 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %94 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %97 = bitcast i8* %96 to i64*
  store i64 -6148914691236517206, i64* %97, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %92, align 8
  store i32 %58, i32* %93, align 8
  store i32 %61, i32* %94, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %95, align 8
  %98 = load i32, i32* %51, align 4
  %99 = icmp slt i32 %98, 4
  br i1 %99, label %104, label %100

100:                                              ; preds = %9
  %101 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %102 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %103 = load i32, i32* %45, align 4
  br label %128

104:                                              ; preds = %230, %9
  %105 = phi i32 [ %98, %9 ], [ %233, %230 ]
  %106 = phi i32 [ 0, %9 ], [ %232, %230 ]
  %107 = icmp slt i32 %106, %105
  br i1 %107, label %108, label %389

108:                                              ; preds = %104
  %109 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %110 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %111 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %112 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %7, i64 0, i32 0
  %113 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 0, i32 0, i32 2
  %114 = shl i32 1, %58
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 0, i32 0, i32 0
  %117 = zext i32 %61 to i64
  %118 = shl nsw i64 -1, %117
  %119 = trunc i64 %118 to i32
  %120 = xor i32 %119, -1
  %121 = ashr i32 %120, 1
  %122 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %62, i64 0, i32 0
  %123 = getelementptr inbounds %"class.std::__1::tuple.265", %"class.std::__1::tuple.265"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %124 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %0, i64 0, i32 0
  %125 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %0, i64 0, i32 3
  %126 = zext i32 %106 to i64
  %127 = load i32, i32* %45, align 4
  br label %236

128:                                              ; preds = %100, %230
  %129 = phi i32 [ %103, %100 ], [ %231, %230 ]
  %130 = phi i32 [ 0, %100 ], [ %232, %230 ]
  %131 = load i32, i32* %101, align 4
  %132 = add nsw i32 %131, %130
  %133 = load i32*, i32** %19, align 8
  %134 = load i32, i32* %22, align 8
  %135 = mul nsw i32 %134, %130
  %136 = sext i32 %135 to i64
  %137 = load i32*, i32** %43, align 8
  %138 = bitcast i32* %137 to i8*
  call void @llvm.prefetch(i8* %138, i32 0, i32 3, i32 1) #18
  %139 = getelementptr inbounds i32, i32* %137, i64 4
  %140 = bitcast i32* %139 to i8*
  call void @llvm.prefetch(i8* %140, i32 0, i32 3, i32 1) #18
  %141 = getelementptr inbounds i32, i32* %133, i64 %136
  %142 = sext i32 %134 to i64
  %143 = bitcast i32* %141 to i8*
  call void @llvm.prefetch(i8* %143, i32 0, i32 3, i32 1) #18
  %144 = getelementptr inbounds i32, i32* %141, i64 4
  %145 = bitcast i32* %144 to i8*
  call void @llvm.prefetch(i8* %145, i32 0, i32 3, i32 1) #18
  %146 = getelementptr inbounds i32, i32* %141, i64 %142
  %147 = bitcast i32* %146 to i8*
  call void @llvm.prefetch(i8* %147, i32 0, i32 3, i32 1) #18
  %148 = getelementptr inbounds i32, i32* %146, i64 4
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #18
  %150 = shl nsw i64 %142, 1
  %151 = getelementptr inbounds i32, i32* %141, i64 %150
  %152 = bitcast i32* %151 to i8*
  call void @llvm.prefetch(i8* %152, i32 0, i32 3, i32 1) #18
  %153 = getelementptr inbounds i32, i32* %151, i64 4
  %154 = bitcast i32* %153 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #18
  %155 = mul nsw i64 %142, 3
  %156 = getelementptr inbounds i32, i32* %141, i64 %155
  %157 = bitcast i32* %156 to i8*
  call void @llvm.prefetch(i8* %157, i32 0, i32 3, i32 1) #18
  %158 = getelementptr inbounds i32, i32* %156, i64 4
  %159 = bitcast i32* %158 to i8*
  call void @llvm.prefetch(i8* %159, i32 0, i32 3, i32 1) #18
  %160 = icmp slt i32 %129, 8
  br i1 %160, label %163, label %168

161:                                              ; preds = %168
  %162 = trunc i64 %176 to i32
  br label %163

163:                                              ; preds = %161, %128
  %164 = phi i32 [ %129, %128 ], [ %203, %161 ]
  %165 = phi i32 [ 0, %128 ], [ %162, %161 ]
  %166 = add nsw i32 %164, -4
  %167 = icmp sgt i32 %165, %166
  br i1 %167, label %211, label %215

168:                                              ; preds = %128, %207
  %169 = phi i32* [ %210, %207 ], [ %137, %128 ]
  %170 = phi i32 [ %209, %207 ], [ %134, %128 ]
  %171 = phi i32* [ %208, %207 ], [ %133, %128 ]
  %172 = phi i64 [ %176, %207 ], [ 0, %128 ]
  %173 = load i32, i32* %102, align 4
  %174 = trunc i64 %172 to i32
  %175 = add nsw i32 %173, %174
  %176 = add nuw i64 %172, 8
  %177 = mul nsw i32 %170, %130
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i32, i32* %169, i64 %176
  %180 = bitcast i32* %179 to i8*
  call void @llvm.prefetch(i8* %180, i32 0, i32 3, i32 1) #18
  %181 = getelementptr inbounds i32, i32* %179, i64 4
  %182 = bitcast i32* %181 to i8*
  call void @llvm.prefetch(i8* %182, i32 0, i32 3, i32 1) #18
  %183 = getelementptr inbounds i32, i32* %171, i64 %176
  %184 = getelementptr inbounds i32, i32* %183, i64 %178
  %185 = sext i32 %170 to i64
  %186 = bitcast i32* %184 to i8*
  call void @llvm.prefetch(i8* %186, i32 0, i32 3, i32 1) #18
  %187 = getelementptr inbounds i32, i32* %184, i64 4
  %188 = bitcast i32* %187 to i8*
  call void @llvm.prefetch(i8* %188, i32 0, i32 3, i32 1) #18
  %189 = getelementptr inbounds i32, i32* %184, i64 %185
  %190 = bitcast i32* %189 to i8*
  call void @llvm.prefetch(i8* %190, i32 0, i32 3, i32 1) #18
  %191 = getelementptr inbounds i32, i32* %189, i64 4
  %192 = bitcast i32* %191 to i8*
  call void @llvm.prefetch(i8* %192, i32 0, i32 3, i32 1) #18
  %193 = shl nsw i64 %185, 1
  %194 = getelementptr inbounds i32, i32* %184, i64 %193
  %195 = bitcast i32* %194 to i8*
  call void @llvm.prefetch(i8* %195, i32 0, i32 3, i32 1) #18
  %196 = getelementptr inbounds i32, i32* %194, i64 4
  %197 = bitcast i32* %196 to i8*
  call void @llvm.prefetch(i8* %197, i32 0, i32 3, i32 1) #18
  %198 = mul nsw i64 %185, 3
  %199 = getelementptr inbounds i32, i32* %184, i64 %198
  %200 = bitcast i32* %199 to i8*
  call void @llvm.prefetch(i8* %200, i32 0, i32 3, i32 1) #18
  %201 = getelementptr inbounds i32, i32* %199, i64 4
  %202 = bitcast i32* %201 to i8*
  call void @llvm.prefetch(i8* %202, i32 0, i32 3, i32 1) #18
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.499"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %174, i32 %130, i32 %175, i32 %132, i32 %175, i32 %132)
  %203 = load i32, i32* %45, align 4
  %204 = add nsw i32 %203, -8
  %205 = trunc i64 %176 to i32
  %206 = icmp slt i32 %204, %205
  br i1 %206, label %161, label %207

207:                                              ; preds = %168
  %208 = load i32*, i32** %19, align 8
  %209 = load i32, i32* %22, align 8
  %210 = load i32*, i32** %43, align 8
  br label %168

211:                                              ; preds = %215, %163
  %212 = phi i32 [ %164, %163 ], [ %220, %215 ]
  %213 = phi i32 [ %165, %163 ], [ %219, %215 ]
  %214 = icmp slt i32 %213, %212
  br i1 %214, label %223, label %230

215:                                              ; preds = %163, %215
  %216 = phi i32 [ %219, %215 ], [ %165, %163 ]
  %217 = load i32, i32* %102, align 4
  %218 = add nsw i32 %217, %216
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.492"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %216, i32 %130, i32 %218, i32 %132, i32 %218, i32 %132)
  %219 = add nuw nsw i32 %216, 4
  %220 = load i32, i32* %45, align 4
  %221 = add nsw i32 %220, -4
  %222 = icmp sgt i32 %219, %221
  br i1 %222, label %211, label %215

223:                                              ; preds = %211, %223
  %224 = phi i32 [ %227, %223 ], [ %213, %211 ]
  %225 = load i32, i32* %102, align 4
  %226 = add nsw i32 %225, %224
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.485"* nonnull dereferenceable(32) %15, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %224, i32 %130, i32 %226, i32 %132, i32 %226, i32 %132)
  %227 = add nuw nsw i32 %224, 1
  %228 = load i32, i32* %45, align 4
  %229 = icmp slt i32 %227, %228
  br i1 %229, label %223, label %230

230:                                              ; preds = %223, %211
  %231 = phi i32 [ %212, %211 ], [ %228, %223 ]
  %232 = add nuw nsw i32 %130, 4
  %233 = load i32, i32* %51, align 4
  %234 = add nsw i32 %233, -4
  %235 = icmp sgt i32 %232, %234
  br i1 %235, label %104, label %128

236:                                              ; preds = %108, %383
  %237 = phi i32 [ %127, %108 ], [ %384, %383 ]
  %238 = phi i64 [ %126, %108 ], [ %385, %383 ]
  %239 = load i32, i32* %109, align 4
  %240 = trunc i64 %238 to i32
  %241 = add nsw i32 %239, %240
  %242 = load i32*, i32** %19, align 8
  %243 = load i32, i32* %22, align 8
  %244 = mul nsw i32 %243, %240
  %245 = sext i32 %244 to i64
  %246 = load i32*, i32** %43, align 8
  %247 = bitcast i32* %246 to i8*
  call void @llvm.prefetch(i8* %247, i32 0, i32 3, i32 1) #18
  %248 = getelementptr inbounds i32, i32* %246, i64 4
  %249 = bitcast i32* %248 to i8*
  call void @llvm.prefetch(i8* %249, i32 0, i32 3, i32 1) #18
  %250 = getelementptr inbounds i32, i32* %242, i64 %245
  %251 = bitcast i32* %250 to i8*
  call void @llvm.prefetch(i8* %251, i32 0, i32 3, i32 1) #18
  %252 = getelementptr inbounds i32, i32* %250, i64 4
  %253 = bitcast i32* %252 to i8*
  call void @llvm.prefetch(i8* %253, i32 0, i32 3, i32 1) #18
  %254 = icmp slt i32 %237, 8
  br i1 %254, label %257, label %262

255:                                              ; preds = %262
  %256 = trunc i64 %270 to i32
  br label %257

257:                                              ; preds = %255, %236
  %258 = phi i32 [ %237, %236 ], [ %282, %255 ]
  %259 = phi i32 [ 0, %236 ], [ %256, %255 ]
  %260 = add nsw i32 %258, -4
  %261 = icmp sgt i32 %259, %260
  br i1 %261, label %290, label %296

262:                                              ; preds = %236, %286
  %263 = phi i32* [ %289, %286 ], [ %246, %236 ]
  %264 = phi i32 [ %288, %286 ], [ %243, %236 ]
  %265 = phi i32* [ %287, %286 ], [ %242, %236 ]
  %266 = phi i64 [ %270, %286 ], [ 0, %236 ]
  %267 = load i32, i32* %110, align 4
  %268 = trunc i64 %266 to i32
  %269 = add nsw i32 %267, %268
  %270 = add nuw i64 %266, 8
  %271 = mul nsw i32 %264, %240
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds i32, i32* %263, i64 %270
  %274 = bitcast i32* %273 to i8*
  call void @llvm.prefetch(i8* %274, i32 0, i32 3, i32 1) #18
  %275 = getelementptr inbounds i32, i32* %273, i64 4
  %276 = bitcast i32* %275 to i8*
  call void @llvm.prefetch(i8* %276, i32 0, i32 3, i32 1) #18
  %277 = getelementptr inbounds i32, i32* %265, i64 %270
  %278 = getelementptr inbounds i32, i32* %277, i64 %272
  %279 = bitcast i32* %278 to i8*
  call void @llvm.prefetch(i8* %279, i32 0, i32 3, i32 1) #18
  %280 = getelementptr inbounds i32, i32* %278, i64 4
  %281 = bitcast i32* %280 to i8*
  call void @llvm.prefetch(i8* %281, i32 0, i32 3, i32 1) #18
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.478"* nonnull dereferenceable(32) %14, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %268, i32 %240, i32 %269, i32 %241, i32 %269, i32 %241)
  %282 = load i32, i32* %45, align 4
  %283 = add nsw i32 %282, -8
  %284 = trunc i64 %270 to i32
  %285 = icmp slt i32 %283, %284
  br i1 %285, label %255, label %286

286:                                              ; preds = %262
  %287 = load i32*, i32** %19, align 8
  %288 = load i32, i32* %22, align 8
  %289 = load i32*, i32** %43, align 8
  br label %262

290:                                              ; preds = %296, %257
  %291 = phi i32 [ %258, %257 ], [ %301, %296 ]
  %292 = phi i32 [ %259, %257 ], [ %300, %296 ]
  %293 = icmp slt i32 %292, %291
  br i1 %293, label %294, label %383

294:                                              ; preds = %290
  %295 = zext i32 %292 to i64
  br label %304

296:                                              ; preds = %257, %296
  %297 = phi i32 [ %300, %296 ], [ %259, %257 ]
  %298 = load i32, i32* %110, align 4
  %299 = add nsw i32 %298, %297
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.471"* nonnull dereferenceable(32) %13, %"class.gemmlowp::MatrixMap.260"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.279"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.272"* dereferenceable(8) %7, i32 %3, i32 %297, i32 %240, i32 %299, i32 %241, i32 %299, i32 %241)
  %300 = add nuw nsw i32 %297, 4
  %301 = load i32, i32* %45, align 4
  %302 = add nsw i32 %301, -4
  %303 = icmp sgt i32 %300, %302
  br i1 %303, label %290, label %296

304:                                              ; preds = %294, %351
  %305 = phi i64 [ %295, %294 ], [ %379, %351 ]
  %306 = load i32, i32* %110, align 4
  %307 = trunc i64 %305 to i32
  %308 = add nsw i32 %306, %307
  %309 = load i32*, i32** %19, align 8
  %310 = load i32, i32* %22, align 8
  %311 = getelementptr inbounds i32, i32* %309, i64 %305
  %312 = mul nsw i32 %310, %240
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i32, i32* %311, i64 %313
  %315 = load i32, i32* %314, align 4
  %316 = load i32*, i32** %43, align 8
  %317 = getelementptr inbounds i32, i32* %316, i64 %305
  %318 = load i32, i32* %317, align 4
  %319 = load i32*, i32** %49, align 8
  %320 = getelementptr inbounds i32, i32* %319, i64 %238
  %321 = load i32, i32* %320, align 4
  %322 = load i32, i32* %111, align 4
  %323 = load i32, i32* %112, align 4
  %324 = mul nsw i32 %323, %318
  %325 = add nsw i32 %324, %315
  %326 = mul nsw i32 %323, %3
  %327 = add nsw i32 %326, %321
  %328 = mul nsw i32 %327, %322
  %329 = add nsw i32 %325, %328
  %330 = load i32, i32* %113, align 4
  %331 = sext i32 %329 to i64
  %332 = mul nsw i64 %331, %115
  %333 = icmp slt i64 %332, 2147483647
  %334 = select i1 %333, i64 %332, i64 2147483647
  %335 = icmp sgt i64 %334, -2147483648
  %336 = select i1 %335, i64 %334, i64 -2147483648
  %337 = trunc i64 %336 to i32
  %338 = load i32, i32* %116, align 4
  %339 = icmp ne i32 %338, %337
  %340 = icmp ne i32 %337, -2147483648
  %341 = or i1 %339, %340
  br i1 %341, label %342, label %351

342:                                              ; preds = %304
  %343 = sext i32 %338 to i64
  %344 = select i1 %339, i64 %343, i64 %336
  %345 = mul nsw i64 %344, %336
  %346 = icmp sgt i64 %345, -1
  %347 = select i1 %346, i64 1073741824, i64 -1073741823
  %348 = add nsw i64 %347, %345
  %349 = sdiv i64 %348, 2147483648
  %350 = trunc i64 %349 to i32
  br label %351

351:                                              ; preds = %304, %342
  %352 = phi i32 [ %350, %342 ], [ 2147483647, %304 ]
  %353 = and i32 %352, %120
  %354 = lshr i32 %352, 31
  %355 = add nsw i32 %354, %121
  %356 = ashr i32 %352, %61
  %357 = icmp sgt i32 %353, %355
  %358 = zext i1 %357 to i32
  %359 = add i32 %356, %330
  %360 = add i32 %359, %358
  %361 = load i32, i32* %122, align 4
  %362 = load i32, i32* %123, align 4
  %363 = icmp sgt i32 %361, %360
  %364 = select i1 %363, i32 %361, i32 %360
  %365 = icmp slt i32 %362, %364
  %366 = select i1 %365, i32 %362, i32 %364
  %367 = icmp sgt i32 %366, -32768
  %368 = select i1 %367, i32 %366, i32 -32768
  %369 = icmp slt i32 %368, 32767
  %370 = select i1 %369, i32 %368, i32 32767
  %371 = trunc i32 %370 to i16
  %372 = sext i32 %308 to i64
  %373 = load i16*, i16** %124, align 8
  %374 = getelementptr inbounds i16, i16* %373, i64 %372
  %375 = load i32, i32* %125, align 8
  %376 = mul nsw i32 %375, %241
  %377 = sext i32 %376 to i64
  %378 = getelementptr inbounds i16, i16* %374, i64 %377
  store i16 %371, i16* %378, align 2
  %379 = add nuw nsw i64 %305, 1
  %380 = load i32, i32* %45, align 4
  %381 = trunc i64 %379 to i32
  %382 = icmp sgt i32 %380, %381
  br i1 %382, label %304, label %383

383:                                              ; preds = %351, %290
  %384 = phi i32 [ %291, %290 ], [ %380, %351 ]
  %385 = add nuw nsw i64 %238, 1
  %386 = load i32, i32* %51, align 4
  %387 = trunc i64 %385 to i32
  %388 = icmp sgt i32 %386, %387
  br i1 %388, label %236, label %389

389:                                              ; preds = %383, %104
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %91) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %84) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %77) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %70) #18
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %63) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %48) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %42) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.499"* dereferenceable(32), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.388", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.388", align 2
  %17 = alloca %"struct.gemmlowp::RegisterBlock.380", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #18
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !1002
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !1002
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !1002
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !1002
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !1002
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !1002
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !1002
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !1002
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !1002
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !1002
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !1002
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !1002
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !1002
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !1002
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !1002
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !1002
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !1002
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !1002
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !1002
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !1002
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !1002
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !1002
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !1002
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !1002
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !1002
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !1002
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !1002
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !1002
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !1002
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !1002
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !1002
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !1002
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !1002
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.380", %"struct.gemmlowp::RegisterBlock.380"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !1002
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !1005
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.380"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %245) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %245, i8 -86, i64 64, i1 false) #18
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.499", %"struct.gemmlowp::OutputPipelineExecutor.499"* %1, i64 0, i32 0
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.388"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.500"* %246, %"struct.gemmlowp::RegisterBlock.380"* nonnull byval(%"struct.gemmlowp::RegisterBlock.380") align 8 %17, i32 %10, i32 %11) #18
  %247 = bitcast %"struct.gemmlowp::RegisterBlock.388"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %247) #18
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 2 %245, i64 64, i1 false) #18
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i16, i16* %258, align 2
  %260 = load i16*, i16** %248, align 8
  %261 = getelementptr inbounds i16, i16* %260, i64 %257
  %262 = load i32, i32* %249, align 8
  %263 = sext i32 %262 to i64
  %264 = mul nsw i64 %263, %250
  %265 = getelementptr inbounds i16, i16* %261, i64 %264
  store i16 %259, i16* %265, align 2
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i16, i16* %267, align 2
  %269 = load i16*, i16** %248, align 8
  %270 = getelementptr inbounds i16, i16* %269, i64 %257
  %271 = load i32, i32* %249, align 8
  %272 = sext i32 %271 to i64
  %273 = mul nsw i64 %252, %272
  %274 = getelementptr inbounds i16, i16* %270, i64 %273
  store i16 %268, i16* %274, align 2
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i16, i16* %276, align 2
  %278 = load i16*, i16** %248, align 8
  %279 = getelementptr inbounds i16, i16* %278, i64 %257
  %280 = load i32, i32* %249, align 8
  %281 = sext i32 %280 to i64
  %282 = mul nsw i64 %253, %281
  %283 = getelementptr inbounds i16, i16* %279, i64 %282
  store i16 %277, i16* %283, align 2
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.388", %"struct.gemmlowp::RegisterBlock.388"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i16, i16* %285, align 2
  %287 = load i16*, i16** %248, align 8
  %288 = getelementptr inbounds i16, i16* %287, i64 %257
  %289 = load i32, i32* %249, align 8
  %290 = sext i32 %289 to i64
  %291 = mul nsw i64 %254, %290
  %292 = getelementptr inbounds i16, i16* %288, i64 %291
  store i16 %286, i16* %292, align 2
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %247) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %245) #18
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.492"* dereferenceable(32), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.390", align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !1010
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !1010
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = load i32, i32* %24, align 4, !noalias !1010
  %27 = getelementptr inbounds i32, i32* %25, i64 1
  %28 = load i32, i32* %25, align 4, !noalias !1010
  %29 = getelementptr inbounds i32, i32* %27, i64 1
  %30 = load i32, i32* %27, align 4, !noalias !1010
  %31 = load i32, i32* %29, align 4, !noalias !1010
  %32 = add nsw i32 %9, 1
  %33 = mul nsw i32 %21, %32
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds i32, i32* %20, i64 %34
  %36 = getelementptr inbounds i32, i32* %35, i64 1
  %37 = load i32, i32* %35, align 4, !noalias !1010
  %38 = getelementptr inbounds i32, i32* %36, i64 1
  %39 = load i32, i32* %36, align 4, !noalias !1010
  %40 = getelementptr inbounds i32, i32* %38, i64 1
  %41 = load i32, i32* %38, align 4, !noalias !1010
  %42 = load i32, i32* %40, align 4, !noalias !1010
  %43 = add nsw i32 %9, 2
  %44 = mul nsw i32 %21, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i32, i32* %20, i64 %45
  %47 = getelementptr inbounds i32, i32* %46, i64 1
  %48 = load i32, i32* %46, align 4, !noalias !1010
  %49 = getelementptr inbounds i32, i32* %47, i64 1
  %50 = load i32, i32* %47, align 4, !noalias !1010
  %51 = getelementptr inbounds i32, i32* %49, i64 1
  %52 = load i32, i32* %49, align 4, !noalias !1010
  %53 = load i32, i32* %51, align 4, !noalias !1010
  %54 = add nsw i32 %9, 3
  %55 = mul nsw i32 %21, %54
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i32, i32* %20, i64 %56
  %58 = getelementptr inbounds i32, i32* %57, i64 1
  %59 = load i32, i32* %57, align 4, !noalias !1010
  %60 = getelementptr inbounds i32, i32* %58, i64 1
  %61 = load i32, i32* %58, align 4, !noalias !1010
  %62 = getelementptr inbounds i32, i32* %60, i64 1
  %63 = load i32, i32* %60, align 4, !noalias !1010
  %64 = load i32, i32* %62, align 4, !noalias !1010
  %65 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %66 = load i32*, i32** %65, align 8
  %67 = getelementptr i32, i32* %66, i64 %17
  %68 = bitcast i32* %67 to i64*
  %69 = load i64, i64* %68, align 4
  %70 = getelementptr inbounds i32, i32* %67, i64 2
  %71 = bitcast i32* %70 to i64*
  %72 = load i64, i64* %71, align 4
  %73 = trunc i64 %69 to i32
  %74 = lshr i64 %69, 32
  %75 = trunc i64 %74 to i32
  %76 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %77 = load i32*, i32** %76, align 8
  %78 = sext i32 %9 to i64
  %79 = getelementptr i32, i32* %77, i64 %78
  %80 = bitcast i32* %79 to i64*
  %81 = load i64, i64* %80, align 4
  %82 = getelementptr inbounds i32, i32* %79, i64 2
  %83 = bitcast i32* %82 to i64*
  %84 = load i64, i64* %83, align 4
  %85 = trunc i64 %81 to i32
  %86 = lshr i64 %81, 32
  %87 = trunc i64 %86 to i32
  %88 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %89 = load i32, i32* %88, align 4
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %91 = load i32, i32* %90, align 4
  %92 = mul nsw i32 %91, %73
  %93 = add nsw i32 %92, %26
  %94 = mul nsw i32 %91, %75
  %95 = add nsw i32 %94, %28
  %96 = trunc i64 %72 to i32
  %97 = mul nsw i32 %91, %96
  %98 = add nsw i32 %97, %30
  %99 = lshr i64 %72, 32
  %100 = trunc i64 %99 to i32
  %101 = mul nsw i32 %91, %100
  %102 = add nsw i32 %101, %31
  %103 = add nsw i32 %92, %37
  %104 = add nsw i32 %94, %39
  %105 = add nsw i32 %97, %41
  %106 = add nsw i32 %101, %42
  %107 = add nsw i32 %92, %48
  %108 = add nsw i32 %94, %50
  %109 = add nsw i32 %97, %52
  %110 = add nsw i32 %101, %53
  %111 = add nsw i32 %92, %59
  %112 = add nsw i32 %94, %61
  %113 = add nsw i32 %97, %63
  %114 = add nsw i32 %101, %64
  %115 = mul nsw i32 %91, %7
  %116 = add nsw i32 %115, %85
  %117 = add nsw i32 %115, %87
  %118 = trunc i64 %84 to i32
  %119 = add nsw i32 %115, %118
  %120 = lshr i64 %84, 32
  %121 = trunc i64 %120 to i32
  %122 = add nsw i32 %115, %121
  %123 = mul nsw i32 %116, %89
  %124 = add nsw i32 %93, %123
  %125 = add nsw i32 %95, %123
  %126 = add nsw i32 %98, %123
  %127 = add nsw i32 %102, %123
  %128 = mul nsw i32 %117, %89
  %129 = add nsw i32 %103, %128
  %130 = add nsw i32 %104, %128
  %131 = add nsw i32 %105, %128
  %132 = add nsw i32 %106, %128
  %133 = mul nsw i32 %119, %89
  %134 = add nsw i32 %107, %133
  %135 = add nsw i32 %108, %133
  %136 = add nsw i32 %109, %133
  %137 = add nsw i32 %110, %133
  %138 = mul nsw i32 %122, %89
  %139 = add nsw i32 %111, %138
  %140 = add nsw i32 %112, %138
  %141 = add nsw i32 %113, %138
  %142 = add nsw i32 %114, %138
  %143 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %124, i32* %143, align 8
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %125, i32* %144, align 4
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %126, i32* %145, align 8
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %127, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %129, i32* %147, align 8
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %130, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %131, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %132, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %134, i32* %151, align 8
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %135, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %136, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %137, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %139, i32* %155, align 8
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %140, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %141, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.390", %"struct.gemmlowp::RegisterBlock.390"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %142, i32* %158, align 4
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvS8_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.492"* %1, %"struct.gemmlowp::RegisterBlock.390"* nonnull byval(%"struct.gemmlowp::RegisterBlock.390") align 8 %15, %"class.gemmlowp::MatrixMap.260"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.485"* dereferenceable(32), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %9, 1
  %26 = mul nsw i32 %20, %25
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %19, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %9, 2
  %31 = mul nsw i32 %20, %30
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i32, i32* %19, i64 %32
  %34 = load i32, i32* %33, align 4
  %35 = add nsw i32 %9, 3
  %36 = mul nsw i32 %20, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %19, i64 %37
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %41 = load i32*, i32** %40, align 8
  %42 = getelementptr inbounds i32, i32* %41, i64 %16
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %45 = load i32*, i32** %44, align 8
  %46 = sext i32 %9 to i64
  %47 = getelementptr i32, i32* %45, i64 %46
  %48 = bitcast i32* %47 to i64*
  %49 = load i64, i64* %48, align 4
  %50 = getelementptr inbounds i32, i32* %47, i64 2
  %51 = bitcast i32* %50 to i64*
  %52 = load i64, i64* %51, align 4
  %53 = trunc i64 %49 to i32
  %54 = lshr i64 %49, 32
  %55 = trunc i64 %54 to i32
  %56 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = mul nsw i32 %59, %43
  %61 = add nsw i32 %60, %24
  %62 = add nsw i32 %60, %29
  %63 = add nsw i32 %60, %34
  %64 = add nsw i32 %60, %39
  %65 = mul nsw i32 %59, %7
  %66 = add nsw i32 %65, %53
  %67 = add nsw i32 %65, %55
  %68 = trunc i64 %52 to i32
  %69 = add nsw i32 %65, %68
  %70 = lshr i64 %52, 32
  %71 = trunc i64 %70 to i32
  %72 = add nsw i32 %65, %71
  %73 = mul nsw i32 %66, %57
  %74 = add nsw i32 %61, %73
  %75 = mul nsw i32 %67, %57
  %76 = add nsw i32 %62, %75
  %77 = mul nsw i32 %69, %57
  %78 = add nsw i32 %63, %77
  %79 = zext i32 %78 to i64
  %80 = mul nsw i32 %72, %57
  %81 = add nsw i32 %64, %80
  %82 = zext i32 %81 to i64
  %83 = shl nuw i64 %82, 32
  %84 = or i64 %83, %79
  %85 = zext i32 %76 to i64
  %86 = shl nuw i64 %85, 32
  %87 = zext i32 %74 to i64
  %88 = or i64 %86, %87
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %1, i64 0, i32 0, i32 0, i32 0
  %90 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %89, i64 %88, i64 %84) #18
  %91 = extractvalue { i64, i64 } %90, 0
  %92 = extractvalue { i64, i64 } %90, 1
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.485", %"struct.gemmlowp::OutputPipelineExecutor.485"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %94 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %93, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 0
  %96 = load i32, i32* %95, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 1
  %98 = load i32, i32* %97, align 4
  %99 = trunc i64 %91 to i32
  %100 = icmp sgt i32 %96, %99
  %101 = select i1 %100, i32 %96, i32 %99
  %102 = icmp slt i32 %98, %101
  %103 = select i1 %102, i32 %98, i32 %101
  %104 = lshr i64 %91, 32
  %105 = trunc i64 %104 to i32
  %106 = icmp sgt i32 %96, %105
  %107 = select i1 %106, i32 %96, i32 %105
  %108 = icmp slt i32 %98, %107
  %109 = select i1 %108, i32 %98, i32 %107
  %110 = trunc i64 %92 to i32
  %111 = icmp sgt i32 %96, %110
  %112 = select i1 %111, i32 %96, i32 %110
  %113 = icmp slt i32 %98, %112
  %114 = select i1 %113, i32 %98, i32 %112
  %115 = lshr i64 %92, 32
  %116 = trunc i64 %115 to i32
  %117 = icmp sgt i32 %96, %116
  %118 = select i1 %117, i32 %96, i32 %116
  %119 = icmp slt i32 %98, %118
  %120 = select i1 %119, i32 %98, i32 %118
  %121 = icmp sgt i32 %103, -32768
  %122 = select i1 %121, i32 %103, i32 -32768
  %123 = icmp slt i32 %122, 32767
  %124 = select i1 %123, i32 %122, i32 32767
  %125 = icmp sgt i32 %109, -32768
  %126 = select i1 %125, i32 %109, i32 -32768
  %127 = icmp slt i32 %126, 32767
  %128 = select i1 %127, i32 %126, i32 32767
  %129 = icmp sgt i32 %114, -32768
  %130 = select i1 %129, i32 %114, i32 -32768
  %131 = icmp slt i32 %130, 32767
  %132 = select i1 %131, i32 %130, i32 32767
  %133 = icmp sgt i32 %120, -32768
  %134 = select i1 %133, i32 %120, i32 -32768
  %135 = icmp slt i32 %134, 32767
  %136 = select i1 %135, i32 %134, i32 32767
  %137 = trunc i32 %124 to i16
  %138 = trunc i32 %128 to i16
  %139 = trunc i32 %132 to i16
  %140 = trunc i32 %136 to i16
  %141 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %143 = sext i32 %13 to i64
  %144 = sext i32 %12 to i64
  %145 = load i16*, i16** %141, align 8
  %146 = getelementptr inbounds i16, i16* %145, i64 %144
  %147 = load i32, i32* %142, align 8
  %148 = sext i32 %147 to i64
  %149 = mul nsw i64 %148, %143
  %150 = getelementptr inbounds i16, i16* %146, i64 %149
  store i16 %137, i16* %150, align 2
  %151 = add nsw i64 %143, 1
  %152 = load i16*, i16** %141, align 8
  %153 = getelementptr inbounds i16, i16* %152, i64 %144
  %154 = load i32, i32* %142, align 8
  %155 = sext i32 %154 to i64
  %156 = mul nsw i64 %151, %155
  %157 = getelementptr inbounds i16, i16* %153, i64 %156
  store i16 %138, i16* %157, align 2
  %158 = add nsw i64 %143, 2
  %159 = load i16*, i16** %141, align 8
  %160 = getelementptr inbounds i16, i16* %159, i64 %144
  %161 = load i32, i32* %142, align 8
  %162 = sext i32 %161 to i64
  %163 = mul nsw i64 %158, %162
  %164 = getelementptr inbounds i16, i16* %160, i64 %163
  store i16 %139, i16* %164, align 2
  %165 = add nsw i64 %143, 3
  %166 = load i16*, i16** %141, align 8
  %167 = getelementptr inbounds i16, i16* %166, i64 %144
  %168 = load i32, i32* %142, align 8
  %169 = sext i32 %168 to i64
  %170 = mul nsw i64 %165, %169
  %171 = getelementptr inbounds i16, i16* %167, i64 %170
  store i16 %140, i16* %171, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.478"* dereferenceable(32), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.382", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !1015
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !1015
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !1015
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !1015
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !1015
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !1015
  %37 = load i32, i32* %35, align 4, !noalias !1015
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !1020
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = add nsw <4 x i32> %57, %30
  %59 = mul nsw <4 x i32> %56, %45
  %60 = insertelement <4 x i32> undef, i32 %32, i32 0
  %61 = insertelement <4 x i32> %60, i32 %34, i32 1
  %62 = insertelement <4 x i32> %61, i32 %36, i32 2
  %63 = insertelement <4 x i32> %62, i32 %37, i32 3
  %64 = add nsw <4 x i32> %59, %63
  %65 = mul nsw i32 %54, %7
  %66 = add nsw i32 %65, %50
  %67 = mul nsw i32 %66, %52
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw <4 x i32> %58, %69
  %71 = add nsw <4 x i32> %64, %69
  %72 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %72)
  %73 = bitcast %"struct.gemmlowp::RegisterBlock.382"* %15 to <4 x i32>*
  store <4 x i32> %70, <4 x i32>* %73, align 16
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.382", %"struct.gemmlowp::RegisterBlock.382"* %15, i64 0, i32 0, i32 0, i64 4
  %75 = bitcast i32* %74 to <4 x i32>*
  store <4 x i32> %71, <4 x i32>* %75, align 16
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.478", %"struct.gemmlowp::OutputPipelineExecutor.478"* %1, i64 0, i32 0
  %77 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.479"* %76, %"struct.gemmlowp::RegisterBlock.382"* nonnull byval(%"struct.gemmlowp::RegisterBlock.382") align 8 %15, i32 %10, i32 %11) #18
  %78 = extractvalue { i64, i64 } %77, 0
  %79 = extractvalue { i64, i64 } %77, 1
  %80 = trunc i64 %78 to i16
  %81 = lshr i64 %78, 16
  %82 = trunc i64 %81 to i16
  %83 = lshr i64 %78, 32
  %84 = trunc i64 %83 to i16
  %85 = lshr i64 %78, 48
  %86 = trunc i64 %85 to i16
  %87 = trunc i64 %79 to i16
  %88 = lshr i64 %79, 16
  %89 = trunc i64 %88 to i16
  %90 = lshr i64 %79, 32
  %91 = trunc i64 %90 to i16
  %92 = lshr i64 %79, 48
  %93 = trunc i64 %92 to i16
  %94 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %95 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %96 = sext i32 %12 to i64
  %97 = load i16*, i16** %94, align 8
  %98 = getelementptr inbounds i16, i16* %97, i64 %96
  %99 = load i32, i32* %95, align 8
  %100 = mul nsw i32 %99, %13
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds i16, i16* %98, i64 %101
  store i16 %80, i16* %102, align 2
  %103 = add nsw i64 %96, 1
  %104 = load i16*, i16** %94, align 8
  %105 = getelementptr inbounds i16, i16* %104, i64 %103
  %106 = load i32, i32* %95, align 8
  %107 = mul nsw i32 %106, %13
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i16, i16* %105, i64 %108
  store i16 %82, i16* %109, align 2
  %110 = add nsw i64 %96, 2
  %111 = load i16*, i16** %94, align 8
  %112 = getelementptr inbounds i16, i16* %111, i64 %110
  %113 = load i32, i32* %95, align 8
  %114 = mul nsw i32 %113, %13
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %112, i64 %115
  store i16 %84, i16* %116, align 2
  %117 = add nsw i64 %96, 3
  %118 = load i16*, i16** %94, align 8
  %119 = getelementptr inbounds i16, i16* %118, i64 %117
  %120 = load i32, i32* %95, align 8
  %121 = mul nsw i32 %120, %13
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds i16, i16* %119, i64 %122
  store i16 %86, i16* %123, align 2
  %124 = add nsw i64 %96, 4
  %125 = load i16*, i16** %94, align 8
  %126 = getelementptr inbounds i16, i16* %125, i64 %124
  %127 = load i32, i32* %95, align 8
  %128 = mul nsw i32 %127, %13
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i16, i16* %126, i64 %129
  store i16 %87, i16* %130, align 2
  %131 = add nsw i64 %96, 5
  %132 = load i16*, i16** %94, align 8
  %133 = getelementptr inbounds i16, i16* %132, i64 %131
  %134 = load i32, i32* %95, align 8
  %135 = mul nsw i32 %134, %13
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i16, i16* %133, i64 %136
  store i16 %89, i16* %137, align 2
  %138 = add nsw i64 %96, 6
  %139 = load i16*, i16** %94, align 8
  %140 = getelementptr inbounds i16, i16* %139, i64 %138
  %141 = load i32, i32* %95, align 8
  %142 = mul nsw i32 %141, %13
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds i16, i16* %140, i64 %143
  store i16 %91, i16* %144, align 2
  %145 = add nsw i64 %96, 7
  %146 = load i16*, i16** %94, align 8
  %147 = getelementptr inbounds i16, i16* %146, i64 %145
  %148 = load i32, i32* %95, align 8
  %149 = mul nsw i32 %148, %13
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds i16, i16* %147, i64 %150
  store i16 %93, i16* %151, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %72)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.292"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.471"* dereferenceable(32), %"class.gemmlowp::MatrixMap.260"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.279"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.272"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.292", %"class.gemmlowp::MatrixMap.292"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = getelementptr inbounds i32, i32* %23, i64 1
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds i32, i32* %24, i64 1
  %27 = load i32, i32* %24, align 4
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = getelementptr i32, i32* %32, i64 %16
  %34 = bitcast i32* %33 to i64*
  %35 = load i64, i64* %34, align 4
  %36 = getelementptr inbounds i32, i32* %33, i64 2
  %37 = bitcast i32* %36 to i64*
  %38 = load i64, i64* %37, align 4
  %39 = trunc i64 %35 to i32
  %40 = lshr i64 %35, 32
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds %"class.gemmlowp::VectorMap.279", %"class.gemmlowp::VectorMap.279"* %4, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %9 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = load i32, i32* %45, align 4
  %47 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %6, i64 0, i32 0
  %50 = load i32, i32* %49, align 4
  %51 = mul nsw i32 %50, %39
  %52 = add nsw i32 %51, %25
  %53 = mul nsw i32 %50, %41
  %54 = add nsw i32 %53, %27
  %55 = trunc i64 %38 to i32
  %56 = mul nsw i32 %50, %55
  %57 = add nsw i32 %56, %29
  %58 = lshr i64 %38, 32
  %59 = trunc i64 %58 to i32
  %60 = mul nsw i32 %50, %59
  %61 = add nsw i32 %60, %30
  %62 = mul nsw i32 %50, %7
  %63 = add nsw i32 %62, %46
  %64 = mul nsw i32 %63, %48
  %65 = add nsw i32 %52, %64
  %66 = add nsw i32 %54, %64
  %67 = add nsw i32 %57, %64
  %68 = zext i32 %67 to i64
  %69 = add nsw i32 %61, %64
  %70 = zext i32 %69 to i64
  %71 = shl nuw i64 %70, 32
  %72 = or i64 %71, %68
  %73 = zext i32 %66 to i64
  %74 = shl nuw i64 %73, 32
  %75 = zext i32 %65 to i64
  %76 = or i64 %74, %75
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %1, i64 0, i32 0, i32 0, i32 0
  %78 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.309"* %77, i64 %76, i64 %72) #18
  %79 = extractvalue { i64, i64 } %78, 0
  %80 = extractvalue { i64, i64 } %78, 1
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.471", %"struct.gemmlowp::OutputPipelineExecutor.471"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 0
  %84 = load i32, i32* %83, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 1
  %86 = load i32, i32* %85, align 4
  %87 = trunc i64 %79 to i32
  %88 = icmp sgt i32 %84, %87
  %89 = select i1 %88, i32 %84, i32 %87
  %90 = icmp slt i32 %86, %89
  %91 = select i1 %90, i32 %86, i32 %89
  %92 = lshr i64 %79, 32
  %93 = trunc i64 %92 to i32
  %94 = icmp sgt i32 %84, %93
  %95 = select i1 %94, i32 %84, i32 %93
  %96 = icmp slt i32 %86, %95
  %97 = select i1 %96, i32 %86, i32 %95
  %98 = trunc i64 %80 to i32
  %99 = icmp sgt i32 %84, %98
  %100 = select i1 %99, i32 %84, i32 %98
  %101 = icmp slt i32 %86, %100
  %102 = select i1 %101, i32 %86, i32 %100
  %103 = lshr i64 %80, 32
  %104 = trunc i64 %103 to i32
  %105 = icmp sgt i32 %84, %104
  %106 = select i1 %105, i32 %84, i32 %104
  %107 = icmp slt i32 %86, %106
  %108 = select i1 %107, i32 %86, i32 %106
  %109 = icmp sgt i32 %91, -32768
  %110 = select i1 %109, i32 %91, i32 -32768
  %111 = icmp slt i32 %110, 32767
  %112 = select i1 %111, i32 %110, i32 32767
  %113 = icmp sgt i32 %97, -32768
  %114 = select i1 %113, i32 %97, i32 -32768
  %115 = icmp slt i32 %114, 32767
  %116 = select i1 %115, i32 %114, i32 32767
  %117 = icmp sgt i32 %102, -32768
  %118 = select i1 %117, i32 %102, i32 -32768
  %119 = icmp slt i32 %118, 32767
  %120 = select i1 %119, i32 %118, i32 32767
  %121 = icmp sgt i32 %108, -32768
  %122 = select i1 %121, i32 %108, i32 -32768
  %123 = icmp slt i32 %122, 32767
  %124 = select i1 %123, i32 %122, i32 32767
  %125 = trunc i32 %112 to i16
  %126 = trunc i32 %116 to i16
  %127 = trunc i32 %120 to i16
  %128 = trunc i32 %124 to i16
  %129 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %130 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %131 = sext i32 %12 to i64
  %132 = load i16*, i16** %129, align 8
  %133 = getelementptr inbounds i16, i16* %132, i64 %131
  %134 = load i32, i32* %130, align 8
  %135 = mul nsw i32 %134, %13
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i16, i16* %133, i64 %136
  store i16 %125, i16* %137, align 2
  %138 = add nsw i64 %131, 1
  %139 = load i16*, i16** %129, align 8
  %140 = getelementptr inbounds i16, i16* %139, i64 %138
  %141 = load i32, i32* %130, align 8
  %142 = mul nsw i32 %141, %13
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds i16, i16* %140, i64 %143
  store i16 %126, i16* %144, align 2
  %145 = add nsw i64 %131, 2
  %146 = load i16*, i16** %129, align 8
  %147 = getelementptr inbounds i16, i16* %146, i64 %145
  %148 = load i32, i32* %130, align 8
  %149 = mul nsw i32 %148, %13
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds i16, i16* %147, i64 %150
  store i16 %127, i16* %151, align 2
  %152 = add nsw i64 %131, 3
  %153 = load i16*, i16** %129, align 8
  %154 = getelementptr inbounds i16, i16* %153, i64 %152
  %155 = load i32, i32* %130, align 8
  %156 = mul nsw i32 %155, %13
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds i16, i16* %154, i64 %157
  store i16 %128, i16* %158, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvS8_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.492"*, %"struct.gemmlowp::RegisterBlock.390"* byval(%"struct.gemmlowp::RegisterBlock.390") align 8, %"class.gemmlowp::MatrixMap.260"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBuffer.391", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.391", align 8
  %10 = alloca [16 x i32], align 8
  %11 = alloca %"struct.gemmlowp::RegisterBlock.393", align 2
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %12) #18
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 0
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 1
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 2
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 3
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 4
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 5
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 6
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 7
  %21 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 9
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 10
  %24 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 11
  %25 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 12
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 13
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 14
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.393", %"struct.gemmlowp::RegisterBlock.393"* %11, i64 0, i32 0, i32 0, i64 15
  %29 = bitcast %"struct.gemmlowp::RegisterBlock.390"* %1 to i8*
  %30 = bitcast %"struct.gemmlowp::RegisterBlock.393"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %30, i8 -86, i64 32, i1 false)
  %31 = bitcast [16 x i32]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %31) #18, !noalias !1025
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %31, i8 -86, i64 64, i1 false) #18, !alias.scope !1028, !noalias !1025
  %32 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %32) #18, !noalias !1031
  %33 = bitcast %"struct.gemmlowp::RegisterBuffer.391"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %33) #18, !noalias !1031
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %33, i8* nonnull align 8 %29, i64 64, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %32, i8 -86, i64 64, i1 false) #18, !alias.scope !1032, !noalias !1031
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %35 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %34, align 8, !noalias !1035
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %35, i64 0, i32 2
  %37 = load i32, i32* %36, align 4, !noalias !1035
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %39 = load i32, i32* %38, align 8, !noalias !1035
  %40 = shl i32 1, %39
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %35, i64 0, i32 0
  %43 = load i32, i32* %42, align 4, !noalias !1035
  %44 = sext i32 %43 to i64
  %45 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %46 = load i32, i32* %45, align 4, !noalias !1035
  %47 = zext i32 %46 to i64
  %48 = shl nsw i64 -1, %47
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %49, -1
  %51 = ashr i32 %50, 1
  %52 = icmp ne i32 %43, -2147483648
  br label %53

53:                                               ; preds = %74, %7
  %54 = phi i64 [ 0, %7 ], [ %85, %74 ]
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %8, i64 0, i32 0, i64 %54
  %56 = load i32, i32* %55, align 4, !noalias !1035
  %57 = sext i32 %56 to i64
  %58 = mul nsw i64 %57, %41
  %59 = icmp slt i64 %58, 2147483647
  %60 = select i1 %59, i64 %58, i64 2147483647
  %61 = icmp sgt i64 %60, -2147483648
  %62 = select i1 %61, i64 %60, i64 -2147483648
  %63 = trunc i64 %62 to i32
  %64 = icmp ne i32 %43, %63
  %65 = or i1 %52, %64
  br i1 %65, label %66, label %74

66:                                               ; preds = %53
  %67 = select i1 %64, i64 %44, i64 %62
  %68 = mul nsw i64 %67, %62
  %69 = icmp sgt i64 %68, -1
  %70 = select i1 %69, i64 1073741824, i64 -1073741823
  %71 = add nsw i64 %70, %68
  %72 = sdiv i64 %71, 2147483648
  %73 = trunc i64 %72 to i32
  br label %74

74:                                               ; preds = %66, %53
  %75 = phi i32 [ %73, %66 ], [ 2147483647, %53 ]
  %76 = and i32 %75, %50
  %77 = lshr i32 %75, 31
  %78 = add nsw i32 %77, %51
  %79 = ashr i32 %75, %46
  %80 = icmp sgt i32 %76, %78
  %81 = zext i1 %80 to i32
  %82 = add i32 %79, %37
  %83 = add i32 %82, %81
  %84 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.391", %"struct.gemmlowp::RegisterBuffer.391"* %9, i64 0, i32 0, i64 %54
  store i32 %83, i32* %84, align 4, !alias.scope !1032, !noalias !1031
  %85 = add nuw nsw i64 %54, 1
  %86 = icmp eq i64 %85, 16
  br i1 %86, label %87, label %53

87:                                               ; preds = %74
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %33) #18, !noalias !1031
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %31, i8* nonnull align 8 %32, i64 64, i1 false) #18, !noalias !1025
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %32) #18, !noalias !1031
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.492", %"struct.gemmlowp::OutputPipelineExecutor.492"* %0, i64 0, i32 0, i32 1
  %89 = bitcast [16 x i32]* %10 to %"struct.gemmlowp::RegisterBlock.390"*
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.393"* nonnull sret %11, %"struct.gemmlowp::OutputPipelineEvalImpl.494"* %88, %"struct.gemmlowp::RegisterBlock.390"* nonnull byval(%"struct.gemmlowp::RegisterBlock.390") align 8 %89, i32 %3, i32 %4) #18
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %31) #18, !noalias !1025
  %90 = load i16, i16* %13, align 2
  %91 = load i16, i16* %14, align 2
  %92 = load i16, i16* %15, align 2
  %93 = load i16, i16* %16, align 2
  %94 = load i16, i16* %17, align 2
  %95 = load i16, i16* %18, align 2
  %96 = load i16, i16* %19, align 2
  %97 = load i16, i16* %20, align 2
  %98 = load i16, i16* %21, align 2
  %99 = load i16, i16* %22, align 2
  %100 = load i16, i16* %23, align 2
  %101 = load i16, i16* %24, align 2
  %102 = load i16, i16* %25, align 2
  %103 = load i16, i16* %26, align 2
  %104 = load i16, i16* %27, align 2
  %105 = load i16, i16* %28, align 2
  %106 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 0
  %107 = getelementptr inbounds %"class.gemmlowp::MatrixMap.260", %"class.gemmlowp::MatrixMap.260"* %2, i64 0, i32 3
  %108 = sext i32 %6 to i64
  %109 = sext i32 %5 to i64
  %110 = load i16*, i16** %106, align 8
  %111 = getelementptr inbounds i16, i16* %110, i64 %109
  %112 = load i32, i32* %107, align 8
  %113 = sext i32 %112 to i64
  %114 = mul nsw i64 %113, %108
  %115 = getelementptr inbounds i16, i16* %111, i64 %114
  store i16 %90, i16* %115, align 2
  %116 = add nsw i64 %108, 1
  %117 = load i16*, i16** %106, align 8
  %118 = getelementptr inbounds i16, i16* %117, i64 %109
  %119 = load i32, i32* %107, align 8
  %120 = sext i32 %119 to i64
  %121 = mul nsw i64 %116, %120
  %122 = getelementptr inbounds i16, i16* %118, i64 %121
  store i16 %94, i16* %122, align 2
  %123 = add nsw i64 %108, 2
  %124 = load i16*, i16** %106, align 8
  %125 = getelementptr inbounds i16, i16* %124, i64 %109
  %126 = load i32, i32* %107, align 8
  %127 = sext i32 %126 to i64
  %128 = mul nsw i64 %123, %127
  %129 = getelementptr inbounds i16, i16* %125, i64 %128
  store i16 %98, i16* %129, align 2
  %130 = add nsw i64 %108, 3
  %131 = load i16*, i16** %106, align 8
  %132 = getelementptr inbounds i16, i16* %131, i64 %109
  %133 = load i32, i32* %107, align 8
  %134 = sext i32 %133 to i64
  %135 = mul nsw i64 %130, %134
  %136 = getelementptr inbounds i16, i16* %132, i64 %135
  store i16 %102, i16* %136, align 2
  %137 = add nsw i64 %109, 1
  %138 = load i16*, i16** %106, align 8
  %139 = getelementptr inbounds i16, i16* %138, i64 %137
  %140 = load i32, i32* %107, align 8
  %141 = sext i32 %140 to i64
  %142 = mul nsw i64 %141, %108
  %143 = getelementptr inbounds i16, i16* %139, i64 %142
  store i16 %91, i16* %143, align 2
  %144 = load i16*, i16** %106, align 8
  %145 = getelementptr inbounds i16, i16* %144, i64 %137
  %146 = load i32, i32* %107, align 8
  %147 = sext i32 %146 to i64
  %148 = mul nsw i64 %116, %147
  %149 = getelementptr inbounds i16, i16* %145, i64 %148
  store i16 %95, i16* %149, align 2
  %150 = load i16*, i16** %106, align 8
  %151 = getelementptr inbounds i16, i16* %150, i64 %137
  %152 = load i32, i32* %107, align 8
  %153 = sext i32 %152 to i64
  %154 = mul nsw i64 %123, %153
  %155 = getelementptr inbounds i16, i16* %151, i64 %154
  store i16 %99, i16* %155, align 2
  %156 = load i16*, i16** %106, align 8
  %157 = getelementptr inbounds i16, i16* %156, i64 %137
  %158 = load i32, i32* %107, align 8
  %159 = sext i32 %158 to i64
  %160 = mul nsw i64 %130, %159
  %161 = getelementptr inbounds i16, i16* %157, i64 %160
  store i16 %103, i16* %161, align 2
  %162 = add nsw i64 %109, 2
  %163 = load i16*, i16** %106, align 8
  %164 = getelementptr inbounds i16, i16* %163, i64 %162
  %165 = load i32, i32* %107, align 8
  %166 = sext i32 %165 to i64
  %167 = mul nsw i64 %166, %108
  %168 = getelementptr inbounds i16, i16* %164, i64 %167
  store i16 %92, i16* %168, align 2
  %169 = load i16*, i16** %106, align 8
  %170 = getelementptr inbounds i16, i16* %169, i64 %162
  %171 = load i32, i32* %107, align 8
  %172 = sext i32 %171 to i64
  %173 = mul nsw i64 %116, %172
  %174 = getelementptr inbounds i16, i16* %170, i64 %173
  store i16 %96, i16* %174, align 2
  %175 = load i16*, i16** %106, align 8
  %176 = getelementptr inbounds i16, i16* %175, i64 %162
  %177 = load i32, i32* %107, align 8
  %178 = sext i32 %177 to i64
  %179 = mul nsw i64 %123, %178
  %180 = getelementptr inbounds i16, i16* %176, i64 %179
  store i16 %100, i16* %180, align 2
  %181 = load i16*, i16** %106, align 8
  %182 = getelementptr inbounds i16, i16* %181, i64 %162
  %183 = load i32, i32* %107, align 8
  %184 = sext i32 %183 to i64
  %185 = mul nsw i64 %130, %184
  %186 = getelementptr inbounds i16, i16* %182, i64 %185
  store i16 %104, i16* %186, align 2
  %187 = add nsw i64 %109, 3
  %188 = load i16*, i16** %106, align 8
  %189 = getelementptr inbounds i16, i16* %188, i64 %187
  %190 = load i32, i32* %107, align 8
  %191 = sext i32 %190 to i64
  %192 = mul nsw i64 %191, %108
  %193 = getelementptr inbounds i16, i16* %189, i64 %192
  store i16 %93, i16* %193, align 2
  %194 = load i16*, i16** %106, align 8
  %195 = getelementptr inbounds i16, i16* %194, i64 %187
  %196 = load i32, i32* %107, align 8
  %197 = sext i32 %196 to i64
  %198 = mul nsw i64 %116, %197
  %199 = getelementptr inbounds i16, i16* %195, i64 %198
  store i16 %97, i16* %199, align 2
  %200 = load i16*, i16** %106, align 8
  %201 = getelementptr inbounds i16, i16* %200, i64 %187
  %202 = load i32, i32* %107, align 8
  %203 = sext i32 %202 to i64
  %204 = mul nsw i64 %123, %203
  %205 = getelementptr inbounds i16, i16* %201, i64 %204
  store i16 %101, i16* %205, align 2
  %206 = load i16*, i16** %106, align 8
  %207 = getelementptr inbounds i16, i16* %206, i64 %187
  %208 = load i32, i32* %107, align 8
  %209 = sext i32 %208 to i64
  %210 = mul nsw i64 %130, %209
  %211 = getelementptr inbounds i16, i16* %207, i64 %210
  store i16 %105, i16* %211, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %12) #18
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.506"*) unnamed_addr #5 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.506"*) unnamed_addr #5 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #17
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.506"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup", align 4
  %9 = alloca %"class.gemmlowp::VectorDup.272", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !1036
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !1036
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !1036
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !1036
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !1036
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !1036
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #18
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !1039
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !1039
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !1039
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !1039
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !1039
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !1039
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #18
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1042
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1042
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1042
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1042
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !1042
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !1042
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #18
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup.272"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.506", %"struct.gemmlowp::GemmWithPackedRhsTask.506"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #18
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #18
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #18
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !1045
  %190 = load i32, i32* %115, align 8, !noalias !1045
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #18
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #18
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #18
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #18
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #18
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #18
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #18
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #18
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #18
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #18
  %280 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !1048
  store i32 %282, i32* %148, align 4, !alias.scope !1048
  store i32 %188, i32* %149, align 4, !alias.scope !1048
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #18
  %283 = load %"class.gemmlowp::VectorDup.272"*, %"class.gemmlowp::VectorDup.272"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup.272", %"class.gemmlowp::VectorDup.272"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !1051
  store i32 %285, i32* %152, align 4, !alias.scope !1051
  store i32 %171, i32* %153, align 4, !alias.scope !1051
  %286 = load %"class.std::__1::tuple.265"*, %"class.std::__1::tuple.265"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.260"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup.272"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.265"* dereferenceable(20) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #18
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #18
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #18
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i16 @_ZN8gemmlowp32one_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_(i16) local_unnamed_addr #1 comdat {
  %2 = sext i16 %0 to i32
  %3 = add nsw i32 %2, 32767
  %4 = icmp sgt i32 %3, -1
  %5 = select i1 %4, i32 1, i32 -1
  %6 = add nsw i32 %5, %3
  %7 = sdiv i32 %6, 2
  %8 = trunc i32 %7 to i16
  %9 = icmp eq i16 %8, -32768
  %10 = shl i32 %7, 16
  %11 = ashr exact i32 %10, 16
  %12 = mul nsw i32 %11, -15420
  %13 = icmp slt i32 %10, 65536
  %14 = select i1 %13, i32 16384, i32 -16383
  %15 = add nsw i32 %14, %12
  %16 = sdiv i32 %15, 32768
  %17 = trunc i32 %16 to i16
  %18 = add nsw i16 %17, 23130
  %19 = icmp eq i16 %18, %8
  %20 = and i1 %9, %19
  br i1 %20, label %31, label %21

21:                                               ; preds = %1
  %22 = sext i16 %18 to i32
  %23 = mul nsw i32 %11, %22
  %24 = icmp sgt i32 %23, -1
  %25 = select i1 %24, i32 16384, i32 -16383
  %26 = add nsw i32 %25, %23
  %27 = sdiv i32 %26, 32768
  %28 = shl i32 %27, 16
  %29 = sub i32 536870912, %28
  %30 = ashr exact i32 %29, 16
  br label %31

31:                                               ; preds = %1, %21
  %32 = phi i32 [ %30, %21 ], [ -24575, %1 ]
  %33 = sext i16 %18 to i32
  %34 = mul nsw i32 %32, %33
  %35 = icmp sgt i32 %34, -1
  %36 = select i1 %35, i32 16384, i32 -16383
  %37 = add nsw i32 %36, %34
  %38 = sdiv i32 %37, 32768
  %39 = trunc i32 %38 to i16
  %40 = icmp slt i16 %39, 8192
  %41 = icmp sgt i16 %39, -8192
  %42 = sext i16 %39 to i64
  %43 = shl nsw i64 %42, 2
  %44 = icmp slt i64 %43, 32767
  %45 = select i1 %44, i64 %43, i64 32767
  %46 = icmp sgt i64 %45, -32768
  %47 = select i1 %46, i64 %45, i64 -32768
  %48 = trunc i64 %47 to i16
  %49 = select i1 %40, i16 %48, i16 32767
  %50 = select i1 %41, i16 %49, i16 -32768
  %51 = add i16 %50, %18
  %52 = icmp eq i16 %51, %8
  %53 = and i1 %9, %52
  br i1 %53, label %63, label %54

54:                                               ; preds = %31
  %55 = sext i16 %51 to i32
  %56 = mul nsw i32 %11, %55
  %57 = icmp sgt i32 %56, -1
  %58 = select i1 %57, i32 16384, i32 -16383
  %59 = add nsw i32 %58, %56
  %60 = sdiv i32 %59, 32768
  %61 = trunc i32 %60 to i16
  %62 = sub i16 8192, %61
  br label %63

63:                                               ; preds = %54, %31
  %64 = phi i16 [ %62, %54 ], [ -24575, %31 ]
  %65 = icmp eq i16 %51, %64
  %66 = icmp eq i16 %51, -32768
  %67 = and i1 %66, %65
  br i1 %67, label %77, label %68

68:                                               ; preds = %63
  %69 = sext i16 %64 to i32
  %70 = sext i16 %51 to i32
  %71 = mul nsw i32 %69, %70
  %72 = icmp sgt i32 %71, -1
  %73 = select i1 %72, i32 16384, i32 -16383
  %74 = add nsw i32 %73, %71
  %75 = sdiv i32 %74, 32768
  %76 = trunc i32 %75 to i16
  br label %77

77:                                               ; preds = %68, %63
  %78 = phi i16 [ %76, %68 ], [ 32767, %63 ]
  %79 = icmp slt i16 %78, 8192
  %80 = icmp sgt i16 %78, -8192
  %81 = sext i16 %78 to i64
  %82 = shl nsw i64 %81, 2
  %83 = icmp slt i64 %82, 32767
  %84 = select i1 %83, i64 %82, i64 32767
  %85 = icmp sgt i64 %84, -32768
  %86 = select i1 %85, i64 %84, i64 -32768
  %87 = trunc i64 %86 to i16
  %88 = select i1 %79, i16 %87, i16 32767
  %89 = select i1 %80, i16 %88, i16 -32768
  %90 = add i16 %89, %51
  %91 = icmp eq i16 %90, %8
  %92 = and i1 %9, %91
  br i1 %92, label %102, label %93

93:                                               ; preds = %77
  %94 = sext i16 %90 to i32
  %95 = mul nsw i32 %11, %94
  %96 = icmp sgt i32 %95, -1
  %97 = select i1 %96, i32 16384, i32 -16383
  %98 = add nsw i32 %97, %95
  %99 = sdiv i32 %98, 32768
  %100 = trunc i32 %99 to i16
  %101 = sub i16 8192, %100
  br label %102

102:                                              ; preds = %93, %77
  %103 = phi i16 [ %101, %93 ], [ -24575, %77 ]
  %104 = icmp eq i16 %90, %103
  %105 = icmp eq i16 %90, -32768
  %106 = and i1 %105, %104
  br i1 %106, label %116, label %107

107:                                              ; preds = %102
  %108 = sext i16 %103 to i32
  %109 = sext i16 %90 to i32
  %110 = mul nsw i32 %108, %109
  %111 = icmp sgt i32 %110, -1
  %112 = select i1 %111, i32 16384, i32 -16383
  %113 = add nsw i32 %112, %110
  %114 = sdiv i32 %113, 32768
  %115 = trunc i32 %114 to i16
  br label %116

116:                                              ; preds = %107, %102
  %117 = phi i16 [ %115, %107 ], [ 32767, %102 ]
  %118 = icmp slt i16 %117, 8192
  %119 = icmp sgt i16 %117, -8192
  %120 = sext i16 %117 to i64
  %121 = shl nsw i64 %120, 2
  %122 = icmp slt i64 %121, 32767
  %123 = select i1 %122, i64 %121, i64 32767
  %124 = icmp sgt i64 %123, -32768
  %125 = select i1 %124, i64 %123, i64 -32768
  %126 = trunc i64 %125 to i16
  %127 = select i1 %118, i16 %126, i16 32767
  %128 = select i1 %119, i16 %127, i16 -32768
  %129 = add i16 %128, %90
  %130 = icmp slt i16 %129, 16384
  %131 = icmp sgt i16 %129, -16384
  %132 = sext i16 %129 to i64
  %133 = shl nsw i64 %132, 1
  %134 = icmp slt i64 %133, 32767
  %135 = select i1 %134, i64 %133, i64 32767
  %136 = icmp sgt i64 %135, -32768
  %137 = select i1 %136, i64 %135, i64 -32768
  %138 = trunc i64 %137 to i16
  %139 = select i1 %130, i16 %138, i16 32767
  %140 = select i1 %131, i16 %139, i16 -32768
  ret i16 %140
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i16 @_ZN8gemmlowp22exp_on_negative_valuesIsLi3EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE(i16) local_unnamed_addr #1 comdat {
  %2 = or i16 %0, -1024
  %3 = shl nsw i16 %2, 3
  %4 = add nsw i16 %3, 4096
  %5 = sext i16 %4 to i32
  %6 = mul nsw i32 %5, %5
  %7 = add nuw nsw i32 %6, 16384
  %8 = lshr i32 %7, 15
  %9 = trunc i32 %8 to i16
  %10 = shl nuw i32 %8, 16
  %11 = ashr exact i32 %10, 16
  %12 = mul nsw i32 %11, %5
  %13 = icmp sgt i32 %12, -1
  %14 = select i1 %13, i32 16384, i32 -16383
  %15 = add nsw i32 %14, %12
  %16 = sdiv i32 %15, 32768
  %17 = trunc i32 %16 to i16
  %18 = mul nsw i32 %11, %11
  %19 = add nuw nsw i32 %18, 16384
  %20 = lshr i32 %19, 15
  %21 = trunc i32 %20 to i16
  %22 = and i16 %21, 3
  %23 = lshr i32 %19, 30
  %24 = trunc i32 %23 to i16
  %25 = add nuw nsw i16 %24, 1
  %26 = ashr i16 %21, 2
  %27 = icmp ugt i16 %22, %25
  %28 = zext i1 %27 to i16
  %29 = add i16 %26, %17
  %30 = add i16 %29, %28
  %31 = sext i16 %30 to i32
  %32 = mul nsw i32 %31, 10923
  %33 = icmp sgt i16 %30, -1
  %34 = select i1 %33, i32 16384, i32 -16383
  %35 = add nsw i32 %34, %32
  %36 = sdiv i32 %35, 32768
  %37 = trunc i32 %36 to i16
  %38 = add i16 %37, %9
  %39 = and i16 %38, 1
  %40 = lshr i16 %38, 15
  %41 = ashr i16 %38, 1
  %42 = icmp ugt i16 %39, %40
  %43 = zext i1 %42 to i16
  %44 = add nsw i16 %41, %4
  %45 = add i16 %44, %43
  %46 = sext i16 %45 to i32
  %47 = mul nsw i32 %46, 28918
  %48 = icmp sgt i16 %45, -1
  %49 = select i1 %48, i32 16384, i32 -16383
  %50 = add nsw i32 %49, %47
  %51 = sdiv i32 %50, 32768
  %52 = shl i32 %51, 16
  %53 = ashr exact i32 %52, 16
  %54 = icmp slt i32 %53, 3849
  %55 = select i1 %54, i32 %53, i32 3849
  %56 = trunc i32 %55 to i16
  %57 = add nsw i16 %56, 28918
  %58 = sub i16 %2, %0
  %59 = sext i16 %57 to i32
  %60 = mul nsw i32 %59, 25520
  %61 = icmp sgt i16 %57, -1
  %62 = select i1 %61, i32 16384, i32 -16383
  %63 = add nsw i32 %62, %60
  %64 = sdiv i32 %63, 32768
  %65 = trunc i32 %64 to i16
  %66 = and i16 %58, 1024
  %67 = icmp eq i16 %66, 0
  %68 = select i1 %67, i16 %57, i16 %65
  %69 = sext i16 %68 to i32
  %70 = mul nsw i32 %69, 19875
  %71 = icmp sgt i16 %68, -1
  %72 = select i1 %71, i32 16384, i32 -16383
  %73 = add nsw i32 %72, %70
  %74 = sdiv i32 %73, 32768
  %75 = trunc i32 %74 to i16
  %76 = and i16 %58, 2048
  %77 = icmp eq i16 %76, 0
  %78 = select i1 %77, i16 %68, i16 %75
  %79 = sext i16 %78 to i32
  %80 = mul nsw i32 %79, 12055
  %81 = icmp sgt i16 %78, -1
  %82 = select i1 %81, i32 16384, i32 -16383
  %83 = add nsw i32 %82, %80
  %84 = sdiv i32 %83, 32768
  %85 = trunc i32 %84 to i16
  %86 = and i16 %58, 4096
  %87 = icmp eq i16 %86, 0
  %88 = select i1 %87, i16 %78, i16 %85
  %89 = sext i16 %88 to i32
  %90 = mul nsw i32 %89, 4435
  %91 = icmp sgt i16 %88, -1
  %92 = select i1 %91, i32 16384, i32 -16383
  %93 = add nsw i32 %92, %90
  %94 = sdiv i32 %93, 32768
  %95 = trunc i32 %94 to i16
  %96 = and i16 %58, 8192
  %97 = icmp eq i16 %96, 0
  %98 = select i1 %97, i16 %88, i16 %95
  %99 = sext i16 %98 to i32
  %100 = mul nsw i32 %99, 600
  %101 = icmp sgt i16 %98, -1
  %102 = select i1 %101, i32 16384, i32 -16383
  %103 = add nsw i32 %102, %100
  %104 = sdiv i32 %103, 32768
  %105 = trunc i32 %104 to i16
  %106 = and i16 %58, 16384
  %107 = icmp eq i16 %106, 0
  %108 = select i1 %107, i16 %98, i16 %105
  %109 = icmp eq i16 %0, 0
  %110 = select i1 %109, i16 32767, i16 %108
  ret i16 %110
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i16 @_ZN8gemmlowp40one_minus_x_over_one_plus_x_for_x_in_0_1IsEENS_10FixedPointIT_Li0EEES3_(i16) local_unnamed_addr #1 comdat {
  %2 = sext i16 %0 to i32
  %3 = add nsw i32 %2, 32767
  %4 = icmp sgt i32 %3, -1
  %5 = select i1 %4, i32 1, i32 -1
  %6 = add nsw i32 %5, %3
  %7 = sdiv i32 %6, 2
  %8 = trunc i32 %7 to i16
  %9 = icmp eq i16 %8, -32768
  %10 = shl i32 %7, 16
  %11 = ashr exact i32 %10, 16
  %12 = mul nsw i32 %11, -15420
  %13 = icmp slt i32 %10, 65536
  %14 = select i1 %13, i32 16384, i32 -16383
  %15 = add nsw i32 %14, %12
  %16 = sdiv i32 %15, 32768
  %17 = trunc i32 %16 to i16
  %18 = add nsw i16 %17, 23130
  %19 = icmp eq i16 %18, %8
  %20 = and i1 %9, %19
  br i1 %20, label %31, label %21

21:                                               ; preds = %1
  %22 = sext i16 %18 to i32
  %23 = mul nsw i32 %11, %22
  %24 = icmp sgt i32 %23, -1
  %25 = select i1 %24, i32 16384, i32 -16383
  %26 = add nsw i32 %25, %23
  %27 = sdiv i32 %26, 32768
  %28 = shl i32 %27, 16
  %29 = sub i32 536870912, %28
  %30 = ashr exact i32 %29, 16
  br label %31

31:                                               ; preds = %1, %21
  %32 = phi i32 [ %30, %21 ], [ -24575, %1 ]
  %33 = sext i16 %18 to i32
  %34 = mul nsw i32 %32, %33
  %35 = icmp sgt i32 %34, -1
  %36 = select i1 %35, i32 16384, i32 -16383
  %37 = add nsw i32 %36, %34
  %38 = sdiv i32 %37, 32768
  %39 = trunc i32 %38 to i16
  %40 = icmp slt i16 %39, 8192
  %41 = icmp sgt i16 %39, -8192
  %42 = sext i16 %39 to i64
  %43 = shl nsw i64 %42, 2
  %44 = icmp slt i64 %43, 32767
  %45 = select i1 %44, i64 %43, i64 32767
  %46 = icmp sgt i64 %45, -32768
  %47 = select i1 %46, i64 %45, i64 -32768
  %48 = trunc i64 %47 to i16
  %49 = select i1 %40, i16 %48, i16 32767
  %50 = select i1 %41, i16 %49, i16 -32768
  %51 = add i16 %50, %18
  %52 = icmp eq i16 %51, %8
  %53 = and i1 %9, %52
  br i1 %53, label %63, label %54

54:                                               ; preds = %31
  %55 = sext i16 %51 to i32
  %56 = mul nsw i32 %11, %55
  %57 = icmp sgt i32 %56, -1
  %58 = select i1 %57, i32 16384, i32 -16383
  %59 = add nsw i32 %58, %56
  %60 = sdiv i32 %59, 32768
  %61 = trunc i32 %60 to i16
  %62 = sub i16 8192, %61
  br label %63

63:                                               ; preds = %54, %31
  %64 = phi i16 [ %62, %54 ], [ -24575, %31 ]
  %65 = icmp eq i16 %51, %64
  %66 = icmp eq i16 %51, -32768
  %67 = and i1 %66, %65
  br i1 %67, label %77, label %68

68:                                               ; preds = %63
  %69 = sext i16 %64 to i32
  %70 = sext i16 %51 to i32
  %71 = mul nsw i32 %69, %70
  %72 = icmp sgt i32 %71, -1
  %73 = select i1 %72, i32 16384, i32 -16383
  %74 = add nsw i32 %73, %71
  %75 = sdiv i32 %74, 32768
  %76 = trunc i32 %75 to i16
  br label %77

77:                                               ; preds = %68, %63
  %78 = phi i16 [ %76, %68 ], [ 32767, %63 ]
  %79 = icmp slt i16 %78, 8192
  %80 = icmp sgt i16 %78, -8192
  %81 = sext i16 %78 to i64
  %82 = shl nsw i64 %81, 2
  %83 = icmp slt i64 %82, 32767
  %84 = select i1 %83, i64 %82, i64 32767
  %85 = icmp sgt i64 %84, -32768
  %86 = select i1 %85, i64 %84, i64 -32768
  %87 = trunc i64 %86 to i16
  %88 = select i1 %79, i16 %87, i16 32767
  %89 = select i1 %80, i16 %88, i16 -32768
  %90 = add i16 %89, %51
  %91 = icmp eq i16 %90, %8
  %92 = and i1 %9, %91
  br i1 %92, label %102, label %93

93:                                               ; preds = %77
  %94 = sext i16 %90 to i32
  %95 = mul nsw i32 %11, %94
  %96 = icmp sgt i32 %95, -1
  %97 = select i1 %96, i32 16384, i32 -16383
  %98 = add nsw i32 %97, %95
  %99 = sdiv i32 %98, 32768
  %100 = trunc i32 %99 to i16
  %101 = sub i16 8192, %100
  br label %102

102:                                              ; preds = %93, %77
  %103 = phi i16 [ %101, %93 ], [ -24575, %77 ]
  %104 = icmp eq i16 %90, %103
  %105 = icmp eq i16 %90, -32768
  %106 = and i1 %105, %104
  br i1 %106, label %116, label %107

107:                                              ; preds = %102
  %108 = sext i16 %103 to i32
  %109 = sext i16 %90 to i32
  %110 = mul nsw i32 %108, %109
  %111 = icmp sgt i32 %110, -1
  %112 = select i1 %111, i32 16384, i32 -16383
  %113 = add nsw i32 %112, %110
  %114 = sdiv i32 %113, 32768
  %115 = trunc i32 %114 to i16
  br label %116

116:                                              ; preds = %107, %102
  %117 = phi i16 [ %115, %107 ], [ 32767, %102 ]
  %118 = icmp slt i16 %117, 8192
  %119 = icmp sgt i16 %117, -8192
  %120 = sext i16 %117 to i64
  %121 = shl nsw i64 %120, 2
  %122 = icmp slt i64 %121, 32767
  %123 = select i1 %122, i64 %121, i64 32767
  %124 = icmp sgt i64 %123, -32768
  %125 = select i1 %124, i64 %123, i64 -32768
  %126 = trunc i64 %125 to i16
  %127 = select i1 %118, i16 %126, i16 32767
  %128 = select i1 %119, i16 %127, i16 -32768
  %129 = add i16 %128, %90
  %130 = add i16 %129, -8192
  %131 = icmp slt i16 %130, 8192
  %132 = icmp sgt i16 %130, -8192
  %133 = sext i16 %130 to i64
  %134 = shl nsw i64 %133, 2
  %135 = icmp slt i64 %134, 32767
  %136 = select i1 %135, i64 %134, i64 32767
  %137 = icmp sgt i64 %136, -32768
  %138 = select i1 %137, i64 %136, i64 -32768
  %139 = trunc i64 %138 to i16
  %140 = select i1 %131, i16 %139, i16 32767
  %141 = select i1 %132, i16 %140, i16 -32768
  ret i16 %141
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i16 @_ZN8gemmlowp22exp_on_negative_valuesIsLi4EEENS_10FixedPointIT_Li0EEENS1_IS2_XT0_EEE(i16) local_unnamed_addr #1 comdat {
  %2 = or i16 %0, -512
  %3 = shl nsw i16 %2, 4
  %4 = add nsw i16 %3, 4096
  %5 = sext i16 %4 to i32
  %6 = mul nsw i32 %5, %5
  %7 = add nuw nsw i32 %6, 16384
  %8 = lshr i32 %7, 15
  %9 = trunc i32 %8 to i16
  %10 = shl nuw i32 %8, 16
  %11 = ashr exact i32 %10, 16
  %12 = mul nsw i32 %11, %5
  %13 = icmp sgt i32 %12, -1
  %14 = select i1 %13, i32 16384, i32 -16383
  %15 = add nsw i32 %14, %12
  %16 = sdiv i32 %15, 32768
  %17 = trunc i32 %16 to i16
  %18 = mul nsw i32 %11, %11
  %19 = add nuw nsw i32 %18, 16384
  %20 = lshr i32 %19, 15
  %21 = trunc i32 %20 to i16
  %22 = and i16 %21, 3
  %23 = lshr i32 %19, 30
  %24 = trunc i32 %23 to i16
  %25 = add nuw nsw i16 %24, 1
  %26 = ashr i16 %21, 2
  %27 = icmp ugt i16 %22, %25
  %28 = zext i1 %27 to i16
  %29 = add i16 %26, %17
  %30 = add i16 %29, %28
  %31 = sext i16 %30 to i32
  %32 = mul nsw i32 %31, 10923
  %33 = icmp sgt i16 %30, -1
  %34 = select i1 %33, i32 16384, i32 -16383
  %35 = add nsw i32 %34, %32
  %36 = sdiv i32 %35, 32768
  %37 = trunc i32 %36 to i16
  %38 = add i16 %37, %9
  %39 = and i16 %38, 1
  %40 = lshr i16 %38, 15
  %41 = ashr i16 %38, 1
  %42 = icmp ugt i16 %39, %40
  %43 = zext i1 %42 to i16
  %44 = add nsw i16 %41, %4
  %45 = add i16 %44, %43
  %46 = sext i16 %45 to i32
  %47 = mul nsw i32 %46, 28918
  %48 = icmp sgt i16 %45, -1
  %49 = select i1 %48, i32 16384, i32 -16383
  %50 = add nsw i32 %49, %47
  %51 = sdiv i32 %50, 32768
  %52 = shl i32 %51, 16
  %53 = ashr exact i32 %52, 16
  %54 = icmp slt i32 %53, 3849
  %55 = select i1 %54, i32 %53, i32 3849
  %56 = trunc i32 %55 to i16
  %57 = add nsw i16 %56, 28918
  %58 = sub i16 %2, %0
  %59 = sext i16 %57 to i32
  %60 = mul nsw i32 %59, 25520
  %61 = icmp sgt i16 %57, -1
  %62 = select i1 %61, i32 16384, i32 -16383
  %63 = add nsw i32 %62, %60
  %64 = sdiv i32 %63, 32768
  %65 = trunc i32 %64 to i16
  %66 = and i16 %58, 512
  %67 = icmp eq i16 %66, 0
  %68 = select i1 %67, i16 %57, i16 %65
  %69 = sext i16 %68 to i32
  %70 = mul nsw i32 %69, 19875
  %71 = icmp sgt i16 %68, -1
  %72 = select i1 %71, i32 16384, i32 -16383
  %73 = add nsw i32 %72, %70
  %74 = sdiv i32 %73, 32768
  %75 = trunc i32 %74 to i16
  %76 = and i16 %58, 1024
  %77 = icmp eq i16 %76, 0
  %78 = select i1 %77, i16 %68, i16 %75
  %79 = sext i16 %78 to i32
  %80 = mul nsw i32 %79, 12055
  %81 = icmp sgt i16 %78, -1
  %82 = select i1 %81, i32 16384, i32 -16383
  %83 = add nsw i32 %82, %80
  %84 = sdiv i32 %83, 32768
  %85 = trunc i32 %84 to i16
  %86 = and i16 %58, 2048
  %87 = icmp eq i16 %86, 0
  %88 = select i1 %87, i16 %78, i16 %85
  %89 = sext i16 %88 to i32
  %90 = mul nsw i32 %89, 4435
  %91 = icmp sgt i16 %88, -1
  %92 = select i1 %91, i32 16384, i32 -16383
  %93 = add nsw i32 %92, %90
  %94 = sdiv i32 %93, 32768
  %95 = trunc i32 %94 to i16
  %96 = and i16 %58, 4096
  %97 = icmp eq i16 %96, 0
  %98 = select i1 %97, i16 %88, i16 %95
  %99 = sext i16 %98 to i32
  %100 = mul nsw i32 %99, 600
  %101 = icmp sgt i16 %98, -1
  %102 = select i1 %101, i32 16384, i32 -16383
  %103 = add nsw i32 %102, %100
  %104 = sdiv i32 %103, 32768
  %105 = trunc i32 %104 to i16
  %106 = and i16 %58, 8192
  %107 = icmp eq i16 %106, 0
  %108 = select i1 %107, i16 %98, i16 %105
  %109 = sext i16 %108 to i32
  %110 = mul nsw i32 %109, 11
  %111 = icmp sgt i16 %108, -1
  %112 = select i1 %111, i32 16384, i32 -16383
  %113 = add nsw i32 %112, %110
  %114 = sdiv i32 %113, 32768
  %115 = trunc i32 %114 to i16
  %116 = and i16 %58, 16384
  %117 = icmp eq i16 %116, 0
  %118 = select i1 %117, i16 %108, i16 %115
  %119 = icmp eq i16 %0, 0
  %120 = select i1 %119, i16 32767, i16 %118
  ret i16 %120
}

declare double @ldexp(double, i32) local_unnamed_addr

attributes #0 = { argmemonly nounwind }
attributes #1 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nobuiltin nofree "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone speculatable }
attributes #5 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { norecurse nounwind readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { noreturn nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { nofree nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #13 = { nounwind readnone }
attributes #14 = { nofree nounwind }
attributes #15 = { inaccessiblemem_or_argmemonly nounwind }
attributes #16 = { noinline nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #17 = { builtin nounwind }
attributes #18 = { nounwind }
attributes #19 = { noreturn nounwind }
attributes #20 = { cold nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!3}
!3 = distinct !{!3, !4, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!4 = distinct !{!4, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!5 = !{i8 0, i8 2}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.unroll.disable"}
!8 = distinct !{!8, !7}
!9 = distinct !{!9, !7}
!10 = distinct !{!10, !7}
!11 = !{!12}
!12 = distinct !{!12, !13, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!13 = distinct !{!13, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!14 = !{!15}
!15 = distinct !{!15, !16, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!16 = distinct !{!16, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!17 = !{!18}
!18 = distinct !{!18, !19, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!19 = distinct !{!19, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!20 = !{!21}
!21 = distinct !{!21, !22, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!22 = distinct !{!22, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!23 = !{!24}
!24 = distinct !{!24, !25, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!25 = distinct !{!25, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!26 = !{!27}
!27 = distinct !{!27, !28, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!28 = distinct !{!28, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!29 = !{!30}
!30 = distinct !{!30, !31, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!31 = distinct !{!31, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!32 = !{!33}
!33 = distinct !{!33, !34, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!34 = distinct !{!34, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!35 = !{!36}
!36 = distinct !{!36, !37, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!37 = distinct !{!37, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!38 = !{!39}
!39 = distinct !{!39, !40, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!40 = distinct !{!40, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!41 = !{!42}
!42 = distinct !{!42, !43, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!43 = distinct !{!43, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!44 = !{!45}
!45 = distinct !{!45, !46, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!46 = distinct !{!46, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!47 = !{!48}
!48 = distinct !{!48, !49, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!49 = distinct !{!49, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!50 = !{!51}
!51 = distinct !{!51, !52, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!52 = distinct !{!52, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!53 = !{!54}
!54 = distinct !{!54, !55, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!55 = distinct !{!55, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!56 = !{!57}
!57 = distinct !{!57, !58, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!58 = distinct !{!58, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!59 = !{!60}
!60 = distinct !{!60, !61, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!61 = distinct !{!61, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!62 = !{!63}
!63 = distinct !{!63, !64, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!64 = distinct !{!64, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!65 = !{!66}
!66 = distinct !{!66, !67, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!67 = distinct !{!67, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!68 = distinct !{!68, !69}
!69 = !{!"llvm.loop.isvectorized", i32 1}
!70 = distinct !{!70, !7}
!71 = distinct !{!71, !72, !69}
!72 = !{!"llvm.loop.unroll.runtime.disable"}
!73 = !{!74}
!74 = distinct !{!74, !75, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!75 = distinct !{!75, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!76 = distinct !{!76, !69}
!77 = distinct !{!77, !7}
!78 = distinct !{!78, !72, !69}
!79 = !{!80}
!80 = distinct !{!80, !81, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!81 = distinct !{!81, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!82 = distinct !{!82, !69}
!83 = distinct !{!83, !7}
!84 = distinct !{!84, !72, !69}
!85 = !{!86}
!86 = distinct !{!86, !87, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!87 = distinct !{!87, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!88 = distinct !{!88, !69}
!89 = distinct !{!89, !7}
!90 = distinct !{!90, !72, !69}
!91 = !{!92}
!92 = distinct !{!92, !93, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!93 = distinct !{!93, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!94 = distinct !{!94, !69}
!95 = distinct !{!95, !7}
!96 = distinct !{!96, !72, !69}
!97 = !{!98}
!98 = distinct !{!98, !99, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!99 = distinct !{!99, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!100 = distinct !{!100, !69}
!101 = distinct !{!101, !7}
!102 = distinct !{!102, !72, !69}
!103 = !{!104}
!104 = distinct !{!104, !105, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!105 = distinct !{!105, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!106 = distinct !{!106, !69}
!107 = distinct !{!107, !7}
!108 = distinct !{!108, !72, !69}
!109 = !{!110}
!110 = distinct !{!110, !111, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!111 = distinct !{!111, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!112 = distinct !{!112, !69}
!113 = distinct !{!113, !7}
!114 = distinct !{!114, !72, !69}
!115 = distinct !{!115, !7}
!116 = !{!117}
!117 = distinct !{!117, !118, !"_ZN6tflite13optimized_ops27MapAsArrayWithLastDimAsRowsIfEENSt3__111conditionalIXsr3std8is_constIT_EE5valueEN5Eigen3MapIKNS5_5ArrayINS2_12remove_constIS4_E4typeELin1ELin1ELi0ELin1ELin1EEELi0ENS5_6StrideILi0ELi0EEEEENS6_INS7_IS4_Lin1ELin1ELi0ELin1ELin1EEELi0ESE_EEE4typeEPS4_RKNS_12RuntimeShapeE: argument 0"}
!118 = distinct !{!118, !"_ZN6tflite13optimized_ops27MapAsArrayWithLastDimAsRowsIfEENSt3__111conditionalIXsr3std8is_constIT_EE5valueEN5Eigen3MapIKNS5_5ArrayINS2_12remove_constIS4_E4typeELin1ELin1ELi0ELin1ELin1EEELi0ENS5_6StrideILi0ELi0EEEEENS6_INS7_IS4_Lin1ELin1ELi0ELin1ELin1EEELi0ESE_EEE4typeEPS4_RKNS_12RuntimeShapeE"}
!119 = !{!120}
!120 = distinct !{!120, !121, !"_ZN6tflite13optimized_ops27MapAsArrayWithLastDimAsRowsIKfEENSt3__111conditionalIXsr3std8is_constIT_EE5valueEN5Eigen3MapIKNS6_5ArrayINS3_12remove_constIS5_E4typeELin1ELin1ELi0ELin1ELin1EEELi0ENS6_6StrideILi0ELi0EEEEENS7_INS8_IS5_Lin1ELin1ELi0ELin1ELin1EEELi0ESF_EEE4typeEPS5_RKNS_12RuntimeShapeE: argument 0"}
!121 = distinct !{!121, !"_ZN6tflite13optimized_ops27MapAsArrayWithLastDimAsRowsIKfEENSt3__111conditionalIXsr3std8is_constIT_EE5valueEN5Eigen3MapIKNS6_5ArrayINS3_12remove_constIS5_E4typeELin1ELin1ELi0ELin1ELin1EEELi0ENS6_6StrideILi0ELi0EEEEENS7_INS8_IS5_Lin1ELin1ELi0ELin1ELin1EEELi0ESF_EEE4typeEPS5_RKNS_12RuntimeShapeE"}
!122 = !{!123}
!123 = distinct !{!123, !124, !"_ZN6tflite13optimized_ops27MapAsArrayWithLastDimAsRowsIfEENSt3__111conditionalIXsr3std8is_constIT_EE5valueEN5Eigen3MapIKNS5_5ArrayINS2_12remove_constIS4_E4typeELin1ELin1ELi0ELin1ELin1EEELi0ENS5_6StrideILi0ELi0EEEEENS6_INS7_IS4_Lin1ELin1ELi0ELin1ELin1EEELi0ESE_EEE4typeEPS4_RKNS_12RuntimeShapeE: argument 0"}
!124 = distinct !{!124, !"_ZN6tflite13optimized_ops27MapAsArrayWithLastDimAsRowsIfEENSt3__111conditionalIXsr3std8is_constIT_EE5valueEN5Eigen3MapIKNS5_5ArrayINS2_12remove_constIS4_E4typeELin1ELin1ELi0ELin1ELin1EEELi0ENS5_6StrideILi0ELi0EEEEENS6_INS7_IS4_Lin1ELin1ELi0ELin1ELin1EEELi0ESE_EEE4typeEPS4_RKNS_12RuntimeShapeE"}
!125 = distinct !{!125, !7}
!126 = !{!127}
!127 = distinct !{!127, !128, !"_ZN6tflite13optimized_ops27MapAsArrayWithLastDimAsRowsIfEENSt3__111conditionalIXsr3std8is_constIT_EE5valueEN5Eigen3MapIKNS5_5ArrayINS2_12remove_constIS4_E4typeELin1ELin1ELi0ELin1ELin1EEELi0ENS5_6StrideILi0ELi0EEEEENS6_INS7_IS4_Lin1ELin1ELi0ELin1ELin1EEELi0ESE_EEE4typeEPS4_RKNS_12RuntimeShapeE: argument 0"}
!128 = distinct !{!128, !"_ZN6tflite13optimized_ops27MapAsArrayWithLastDimAsRowsIfEENSt3__111conditionalIXsr3std8is_constIT_EE5valueEN5Eigen3MapIKNS5_5ArrayINS2_12remove_constIS4_E4typeELin1ELin1ELi0ELin1ELin1EEELi0ENS5_6StrideILi0ELi0EEEEENS6_INS7_IS4_Lin1ELin1ELi0ELin1ELin1EEELi0ESE_EEE4typeEPS4_RKNS_12RuntimeShapeE"}
!129 = distinct !{!129, !7}
!130 = !{!131}
!131 = distinct !{!131, !132, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!132 = distinct !{!132, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!133 = distinct !{!133, !69}
!134 = distinct !{!134, !7}
!135 = distinct !{!135, !72, !69}
!136 = !{!137}
!137 = distinct !{!137, !138, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!138 = distinct !{!138, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!139 = distinct !{!139, !69}
!140 = distinct !{!140, !7}
!141 = distinct !{!141, !72, !69}
!142 = !{!143}
!143 = distinct !{!143, !144, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!144 = distinct !{!144, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!145 = distinct !{!145, !69}
!146 = distinct !{!146, !7}
!147 = distinct !{!147, !72, !69}
!148 = !{!149}
!149 = distinct !{!149, !150, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!150 = distinct !{!150, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!151 = distinct !{!151, !69}
!152 = distinct !{!152, !7}
!153 = distinct !{!153, !72, !69}
!154 = !{!155}
!155 = distinct !{!155, !156, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!156 = distinct !{!156, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!157 = distinct !{!157, !69}
!158 = distinct !{!158, !7}
!159 = distinct !{!159, !72, !69}
!160 = !{!161}
!161 = distinct !{!161, !162, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!162 = distinct !{!162, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!163 = distinct !{!163, !69}
!164 = distinct !{!164, !7}
!165 = distinct !{!165, !72, !69}
!166 = !{!167}
!167 = distinct !{!167, !168, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!168 = distinct !{!168, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!169 = distinct !{!169, !69}
!170 = distinct !{!170, !7}
!171 = distinct !{!171, !72, !69}
!172 = !{!173}
!173 = distinct !{!173, !174, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_: argument 0"}
!174 = distinct !{!174, !"_ZN6tflite12RuntimeShape13ExtendedShapeEiRKS0_"}
!175 = distinct !{!175, !69}
!176 = distinct !{!176, !7}
!177 = distinct !{!177, !72, !69}
!178 = distinct !{!178, !7}
!179 = distinct !{!179, !7}
!180 = distinct !{!180, !7}
!181 = distinct !{!181, !69}
!182 = distinct !{!182, !7}
!183 = distinct !{!183, !72, !69}
!184 = distinct !{!184, !7}
!185 = distinct !{!185, !7}
!186 = !{!187}
!187 = distinct !{!187, !188, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!188 = distinct !{!188, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!189 = !{!190}
!190 = distinct !{!190, !191, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!191 = distinct !{!191, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!192 = !{!193}
!193 = distinct !{!193, !194, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERNS_6MatrixIS2_EE: argument 0"}
!194 = distinct !{!194, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERNS_6MatrixIS2_EE"}
!195 = !{!196}
!196 = distinct !{!196, !197, !"_ZN3ruy9EraseTypeIfEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!197 = distinct !{!197, !"_ZN3ruy9EraseTypeIfEENS_4EMatERKNS_3MatIT_EE"}
!198 = !{!199}
!199 = distinct !{!199, !200, !"_ZN3ruy9EraseTypeIfEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!200 = distinct !{!200, !"_ZN3ruy9EraseTypeIfEENS_4EMatERKNS_3MatIT_EE"}
!201 = !{!202}
!202 = distinct !{!202, !203, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!203 = distinct !{!203, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!204 = !{!205}
!205 = distinct !{!205, !206, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!206 = distinct !{!206, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!207 = !{!208}
!208 = distinct !{!208, !209, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!209 = distinct !{!209, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!210 = !{!211}
!211 = distinct !{!211, !212, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!212 = distinct !{!212, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!213 = !{!214}
!214 = distinct !{!214, !215, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!215 = distinct !{!215, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!216 = !{!217}
!217 = distinct !{!217, !218, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!218 = distinct !{!218, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!219 = !{!220}
!220 = distinct !{!220, !221, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!221 = distinct !{!221, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!222 = !{!223}
!223 = distinct !{!223, !224, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!224 = distinct !{!224, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!225 = !{!226}
!226 = distinct !{!226, !227, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!227 = distinct !{!227, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!228 = !{!229}
!229 = distinct !{!229, !230, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!230 = distinct !{!230, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!231 = !{!232}
!232 = distinct !{!232, !233, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!233 = distinct !{!233, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!234 = !{!235}
!235 = distinct !{!235, !236, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!236 = distinct !{!236, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!237 = !{!238}
!238 = distinct !{!238, !239, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!239 = distinct !{!239, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!240 = !{!241}
!241 = distinct !{!241, !242, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!242 = distinct !{!242, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!243 = !{!244}
!244 = distinct !{!244, !245, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!245 = distinct !{!245, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!246 = !{i32 -2143120969, i32 -2143120960, i32 -2143120952, i32 -2143120944, i32 -2143120936, i32 -2143120928, i32 -2143120920, i32 -2143120912, i32 -2143120904, i32 -2143120896, i32 -2143120888, i32 -2143120880, i32 -2143120872, i32 -2143120864, i32 -2143120856, i32 -2143120848, i32 -2143120840, i32 -2143120832, i32 -2143120824, i32 -2143120816, i32 -2143120808, i32 -2143120800, i32 -2143120792, i32 -2143120784, i32 -2143120776, i32 -2143120768, i32 -2143120760, i32 -2143120752, i32 -2143120744, i32 -2143120736, i32 -2143120728, i32 -2143120720, i32 -2143120712, i32 -2143120704, i32 -2143120696, i32 -2143120688, i32 -2143120680, i32 -2143120672, i32 -2143120664, i32 -2143120656, i32 -2143120648, i32 -2143120640, i32 -2143120632, i32 -2143120624, i32 -2143120616, i32 -2143120608, i32 -2143120600, i32 -2143120592, i32 -2143120584, i32 -2143120576, i32 -2143120568, i32 -2143120560, i32 -2143120552, i32 -2143120544, i32 -2143120536, i32 -2143120528, i32 -2143120520, i32 -2143120512, i32 -2143120504, i32 -2143120496, i32 -2143120488, i32 -2143120480, i32 -2143120472, i32 -2143120464}
!247 = !{i32 6580053}
!248 = !{!"branch_weights", i32 2000, i32 1}
!249 = !{i32 6581946}
!250 = !{!"branch_weights", i32 1, i32 2000}
!251 = !{!252}
!252 = distinct !{!252, !253, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!253 = distinct !{!253, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!254 = !{!255}
!255 = distinct !{!255, !256, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!256 = distinct !{!256, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!257 = !{!258}
!258 = distinct !{!258, !259, !"_ZN3ruy10ToInternalIsEENS_3MatIT_EERNS_6MatrixIS2_EE: argument 0"}
!259 = distinct !{!259, !"_ZN3ruy10ToInternalIsEENS_3MatIT_EERNS_6MatrixIS2_EE"}
!260 = !{!261}
!261 = distinct !{!261, !262, !"_ZNSt3__110make_tupleIJRN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEERNS1_44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSH_: argument 0"}
!262 = distinct !{!262, !"_ZNSt3__110make_tupleIJRN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEERNS1_44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSH_"}
!263 = !{!264}
!264 = distinct !{!264, !265, !"_ZNSt3__110make_tupleIJRN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSA_: argument 0"}
!265 = distinct !{!265, !"_ZNSt3__110make_tupleIJRN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSA_"}
!266 = !{!267}
!267 = distinct !{!267, !268, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!268 = distinct !{!268, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE"}
!269 = !{!270}
!270 = distinct !{!270, !271, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!271 = distinct !{!271, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE"}
!272 = !{!273}
!273 = distinct !{!273, !274, !"_ZN3ruy9EraseTypeIsEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!274 = distinct !{!274, !"_ZN3ruy9EraseTypeIsEENS_4EMatERKNS_3MatIT_EE"}
!275 = !{!276}
!276 = distinct !{!276, !277, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!277 = distinct !{!277, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!278 = !{!279}
!279 = distinct !{!279, !280, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!280 = distinct !{!280, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!281 = !{!282}
!282 = distinct !{!282, !283, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!283 = distinct !{!283, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE"}
!284 = !{!285}
!285 = distinct !{!285, !286, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!286 = distinct !{!286, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!287 = !{!288}
!288 = distinct !{!288, !289, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!289 = distinct !{!289, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!290 = !{!291}
!291 = distinct !{!291, !292, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!292 = distinct !{!292, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!293 = !{!294}
!294 = distinct !{!294, !295, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!295 = distinct !{!295, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE"}
!296 = !{!297}
!297 = distinct !{!297, !298, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!298 = distinct !{!298, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE"}
!299 = !{!300}
!300 = distinct !{!300, !301, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!301 = distinct !{!301, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE"}
!302 = !{!303}
!303 = distinct !{!303, !304, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!304 = distinct !{!304, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE"}
!305 = !{!306}
!306 = distinct !{!306, !307, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!307 = distinct !{!307, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!308 = !{!309}
!309 = distinct !{!309, !310, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!310 = distinct !{!310, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!311 = !{!312}
!312 = distinct !{!312, !313, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!313 = distinct !{!313, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE"}
!314 = !{!315}
!315 = distinct !{!315, !316, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!316 = distinct !{!316, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!317 = !{!318}
!318 = distinct !{!318, !319, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!319 = distinct !{!319, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!320 = !{!321, !323}
!321 = distinct !{!321, !322, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE0EEEE3RunERKS3_: argument 0"}
!322 = distinct !{!322, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE0EEEE3RunERKS3_"}
!323 = distinct !{!323, !324, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!324 = distinct !{!324, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!325 = !{!326, !328}
!326 = distinct !{!326, !327, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!327 = distinct !{!327, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!328 = distinct !{!328, !329, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!329 = distinct !{!329, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!330 = !{!331, !333}
!331 = distinct !{!331, !332, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!332 = distinct !{!332, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!333 = distinct !{!333, !334, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!334 = distinct !{!334, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!335 = !{!336, !338}
!336 = distinct !{!336, !337, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!337 = distinct !{!337, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!338 = distinct !{!338, !339, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!339 = distinct !{!339, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!340 = !{!341, !343}
!341 = distinct !{!341, !342, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!342 = distinct !{!342, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!343 = distinct !{!343, !344, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!344 = distinct !{!344, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!345 = !{!346, !348, !350, !352, !354}
!346 = distinct !{!346, !347, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!347 = distinct !{!347, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!348 = distinct !{!348, !349, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!349 = distinct !{!349, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!350 = distinct !{!350, !351, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEE3RunERKS6_: argument 0"}
!351 = distinct !{!351, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEE3RunERKS6_"}
!352 = distinct !{!352, !353, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_: argument 0"}
!353 = distinct !{!353, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_"}
!354 = distinct !{!354, !355, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE: argument 0"}
!355 = distinct !{!355, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE"}
!356 = !{!354}
!357 = !{!358, !354}
!358 = distinct !{!358, !359, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE1EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_: argument 0"}
!359 = distinct !{!359, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE1EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_"}
!360 = !{!361, !363}
!361 = distinct !{!361, !362, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS3_: argument 0"}
!362 = distinct !{!362, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS3_"}
!363 = distinct !{!363, !364, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!364 = distinct !{!364, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!365 = !{!366, !368}
!366 = distinct !{!366, !367, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!367 = distinct !{!367, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!368 = distinct !{!368, !369, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!369 = distinct !{!369, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!370 = !{!371, !373}
!371 = distinct !{!371, !372, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!372 = distinct !{!372, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!373 = distinct !{!373, !374, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!374 = distinct !{!374, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!375 = !{!376, !378}
!376 = distinct !{!376, !377, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!377 = distinct !{!377, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!378 = distinct !{!378, !379, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!379 = distinct !{!379, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!380 = !{!381, !383}
!381 = distinct !{!381, !382, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!382 = distinct !{!382, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!383 = distinct !{!383, !384, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!384 = distinct !{!384, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!385 = !{!386, !388, !390, !392, !394}
!386 = distinct !{!386, !387, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!387 = distinct !{!387, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!388 = distinct !{!388, !389, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!389 = distinct !{!389, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!390 = distinct !{!390, !391, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEE3RunERKS6_: argument 0"}
!391 = distinct !{!391, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEE3RunERKS6_"}
!392 = distinct !{!392, !393, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_: argument 0"}
!393 = distinct !{!393, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_"}
!394 = distinct !{!394, !395, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE: argument 0"}
!395 = distinct !{!395, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE"}
!396 = !{!394}
!397 = !{!398, !394}
!398 = distinct !{!398, !399, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_: argument 0"}
!399 = distinct !{!399, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_"}
!400 = !{!"branch_weights", i32 1, i32 1048575}
!401 = !{!402}
!402 = distinct !{!402, !403, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!403 = distinct !{!403, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!404 = !{!405}
!405 = distinct !{!405, !406, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!406 = distinct !{!406, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!407 = !{!408}
!408 = distinct !{!408, !409, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!409 = distinct !{!409, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!410 = !{!411}
!411 = distinct !{!411, !412, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!412 = distinct !{!412, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!413 = !{!414}
!414 = distinct !{!414, !415, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!415 = distinct !{!415, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!416 = !{!417}
!417 = distinct !{!417, !418, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!418 = distinct !{!418, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!419 = !{!420}
!420 = distinct !{!420, !421, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!421 = distinct !{!421, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!422 = !{!423}
!423 = distinct !{!423, !424, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!424 = distinct !{!424, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!425 = !{!426}
!426 = distinct !{!426, !427, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!427 = distinct !{!427, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!428 = !{!429}
!429 = distinct !{!429, !430, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!430 = distinct !{!430, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!431 = !{!432}
!432 = distinct !{!432, !433, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!433 = distinct !{!433, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!434 = !{!435}
!435 = distinct !{!435, !436, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!436 = distinct !{!436, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!437 = !{!438}
!438 = distinct !{!438, !439, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!439 = distinct !{!439, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!440 = !{!441}
!441 = distinct !{!441, !442, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!442 = distinct !{!442, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!443 = !{!444}
!444 = distinct !{!444, !445, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!445 = distinct !{!445, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!446 = !{!447}
!447 = distinct !{!447, !448, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!448 = distinct !{!448, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!449 = !{!450}
!450 = distinct !{!450, !451, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!451 = distinct !{!451, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!452 = !{!453}
!453 = distinct !{!453, !454, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!454 = distinct !{!454, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!455 = distinct !{!455, !7}
!456 = !{!457}
!457 = distinct !{!457, !458, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii: argument 0"}
!458 = distinct !{!458, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii"}
!459 = !{!460}
!460 = distinct !{!460, !461, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii: argument 0"}
!461 = distinct !{!461, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii"}
!462 = !{!463}
!463 = distinct !{!463, !464, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii: argument 0"}
!464 = distinct !{!464, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii"}
!465 = !{!466}
!466 = distinct !{!466, !467, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii: argument 0"}
!467 = distinct !{!467, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii"}
!468 = !{!469}
!469 = distinct !{!469, !470, !"_ZN8gemmlowp12PackedResult3MapEv: argument 0"}
!470 = distinct !{!470, !"_ZN8gemmlowp12PackedResult3MapEv"}
!471 = !{!472}
!472 = distinct !{!472, !473, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!473 = distinct !{!473, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!474 = !{!475, !477}
!475 = distinct !{!475, !476, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!476 = distinct !{!476, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!477 = distinct !{!477, !478, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!478 = distinct !{!478, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!479 = !{!480, !482}
!480 = distinct !{!480, !481, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!481 = distinct !{!481, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!482 = distinct !{!482, !483, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!483 = distinct !{!483, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!484 = !{!485}
!485 = distinct !{!485, !486, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!486 = distinct !{!486, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!487 = !{!488, !490}
!488 = distinct !{!488, !489, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!489 = distinct !{!489, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!490 = distinct !{!490, !491, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!491 = distinct !{!491, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!492 = !{!493, !495}
!493 = distinct !{!493, !494, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!494 = distinct !{!494, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!495 = distinct !{!495, !496, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!496 = distinct !{!496, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!497 = !{!498, !500}
!498 = distinct !{!498, !499, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!499 = distinct !{!499, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!500 = distinct !{!500, !501, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!501 = distinct !{!501, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!502 = !{!503}
!503 = distinct !{!503, !504, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii: argument 0"}
!504 = distinct !{!504, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii"}
!505 = !{!506, !508}
!506 = distinct !{!506, !507, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!507 = distinct !{!507, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!508 = distinct !{!508, !509, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!509 = distinct !{!509, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!510 = !{!508}
!511 = !{!512}
!512 = distinct !{!512, !513, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!513 = distinct !{!513, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!514 = !{!515}
!515 = distinct !{!515, !516, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!516 = distinct !{!516, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!517 = !{!515, !512}
!518 = !{!519}
!519 = distinct !{!519, !520, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!520 = distinct !{!520, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!521 = !{!522}
!522 = distinct !{!522, !523, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!523 = distinct !{!523, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!524 = !{!519, !522}
!525 = !{!526, !519, !522}
!526 = distinct !{!526, !527, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!527 = distinct !{!527, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!528 = !{!526}
!529 = !{!530}
!530 = distinct !{!530, !531, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!531 = distinct !{!531, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!532 = !{!533, !522}
!533 = distinct !{!533, !534, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!534 = distinct !{!534, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!535 = !{!530, !533, !522}
!536 = !{!537}
!537 = distinct !{!537, !538, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!538 = distinct !{!538, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!539 = !{!537, !530, !533, !522}
!540 = !{!541}
!541 = distinct !{!541, !542, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii: argument 0"}
!542 = distinct !{!542, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii"}
!543 = !{!544}
!544 = distinct !{!544, !545, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii: argument 0"}
!545 = distinct !{!545, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii"}
!546 = !{!547}
!547 = distinct !{!547, !548, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!548 = distinct !{!548, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!549 = !{!547, !544}
!550 = !{!551}
!551 = distinct !{!551, !552, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!552 = distinct !{!552, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!553 = !{!551, !547, !544}
!554 = !{!555, !557}
!555 = distinct !{!555, !556, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!556 = distinct !{!556, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!557 = distinct !{!557, !558, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!558 = distinct !{!558, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!559 = !{!560}
!560 = distinct !{!560, !561, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii: argument 0"}
!561 = distinct !{!561, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii"}
!562 = !{!563, !565}
!563 = distinct !{!563, !564, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!564 = distinct !{!564, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!565 = distinct !{!565, !566, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!566 = distinct !{!566, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!567 = !{!565}
!568 = !{!569}
!569 = distinct !{!569, !570, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!570 = distinct !{!570, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!571 = !{!572}
!572 = distinct !{!572, !573, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!573 = distinct !{!573, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!574 = !{!572, !569}
!575 = !{!576, !578}
!576 = distinct !{!576, !577, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!577 = distinct !{!577, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!578 = distinct !{!578, !579, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!579 = distinct !{!579, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!580 = !{!581}
!581 = distinct !{!581, !582, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!582 = distinct !{!582, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!583 = !{!584}
!584 = distinct !{!584, !585, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!585 = distinct !{!585, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!586 = !{!587}
!587 = distinct !{!587, !588, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!588 = distinct !{!588, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!589 = !{!590}
!590 = distinct !{!590, !591, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!591 = distinct !{!591, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!592 = !{!593}
!593 = distinct !{!593, !594, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!594 = distinct !{!594, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!595 = !{!596}
!596 = distinct !{!596, !597, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!597 = distinct !{!597, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!598 = !{!599}
!599 = distinct !{!599, !600, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!600 = distinct !{!600, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!601 = !{!602}
!602 = distinct !{!602, !603, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!603 = distinct !{!603, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!604 = !{!605}
!605 = distinct !{!605, !606, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!606 = distinct !{!606, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!607 = !{!608}
!608 = distinct !{!608, !609, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!609 = distinct !{!609, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!610 = !{!611}
!611 = distinct !{!611, !612, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!612 = distinct !{!612, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!613 = !{!614}
!614 = distinct !{!614, !615, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!615 = distinct !{!615, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!616 = !{!617}
!617 = distinct !{!617, !618, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!618 = distinct !{!618, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!619 = !{!620}
!620 = distinct !{!620, !621, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!621 = distinct !{!621, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!622 = !{!623}
!623 = distinct !{!623, !624, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!624 = distinct !{!624, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!625 = !{!626}
!626 = distinct !{!626, !627, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!627 = distinct !{!627, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!628 = !{!629, !631}
!629 = distinct !{!629, !630, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!630 = distinct !{!630, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!631 = distinct !{!631, !632, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!632 = distinct !{!632, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!633 = !{!634}
!634 = distinct !{!634, !635, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!635 = distinct !{!635, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!636 = !{!637, !639}
!637 = distinct !{!637, !638, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!638 = distinct !{!638, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!639 = distinct !{!639, !640, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!640 = distinct !{!640, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!641 = !{!642, !644}
!642 = distinct !{!642, !643, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!643 = distinct !{!643, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!644 = distinct !{!644, !645, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!645 = distinct !{!645, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!646 = !{!647, !649}
!647 = distinct !{!647, !648, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!648 = distinct !{!648, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!649 = distinct !{!649, !650, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!650 = distinct !{!650, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!651 = !{!652, !654, !647, !649}
!652 = distinct !{!652, !653, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!653 = distinct !{!653, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!654 = distinct !{!654, !655, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!655 = distinct !{!655, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!656 = !{!649}
!657 = !{!658}
!658 = distinct !{!658, !659, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!659 = distinct !{!659, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!660 = !{!661}
!661 = distinct !{!661, !662, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!662 = distinct !{!662, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!663 = !{!661, !658}
!664 = !{!665}
!665 = distinct !{!665, !666, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!666 = distinct !{!666, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!667 = !{!668}
!668 = distinct !{!668, !669, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!669 = distinct !{!669, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!670 = !{!665, !668}
!671 = !{!672, !665, !668}
!672 = distinct !{!672, !673, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!673 = distinct !{!673, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!674 = !{!672}
!675 = !{!676}
!676 = distinct !{!676, !677, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!677 = distinct !{!677, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!678 = !{!679, !668}
!679 = distinct !{!679, !680, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!680 = distinct !{!680, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!681 = !{!676, !679, !668}
!682 = !{!683}
!683 = distinct !{!683, !684, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!684 = distinct !{!684, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!685 = !{!683, !676, !679, !668}
!686 = !{!687}
!687 = distinct !{!687, !688, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii: argument 0"}
!688 = distinct !{!688, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii"}
!689 = !{!690}
!690 = distinct !{!690, !691, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii: argument 0"}
!691 = distinct !{!691, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii"}
!692 = !{!693}
!693 = distinct !{!693, !694, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!694 = distinct !{!694, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!695 = !{!693, !690}
!696 = !{!697}
!697 = distinct !{!697, !698, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!698 = distinct !{!698, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!699 = !{!697, !693, !690}
!700 = !{!701, !703}
!701 = distinct !{!701, !702, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!702 = distinct !{!702, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!703 = distinct !{!703, !704, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!704 = distinct !{!704, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!705 = !{!706}
!706 = distinct !{!706, !707, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii: argument 0"}
!707 = distinct !{!707, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii"}
!708 = !{!709}
!709 = distinct !{!709, !710, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii: argument 0"}
!710 = distinct !{!710, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii"}
!711 = !{!712, !714, !709}
!712 = distinct !{!712, !713, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!713 = distinct !{!713, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!714 = distinct !{!714, !715, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!715 = distinct !{!715, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!716 = !{!717}
!717 = distinct !{!717, !718, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!718 = distinct !{!718, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!719 = !{!720}
!720 = distinct !{!720, !721, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!721 = distinct !{!721, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!722 = !{!720, !717}
!723 = !{!724, !726}
!724 = distinct !{!724, !725, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!725 = distinct !{!725, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!726 = distinct !{!726, !727, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!727 = distinct !{!727, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!728 = !{!729}
!729 = distinct !{!729, !730, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!730 = distinct !{!730, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!731 = !{!732}
!732 = distinct !{!732, !733, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!733 = distinct !{!733, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!734 = !{!735}
!735 = distinct !{!735, !736, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!736 = distinct !{!736, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!737 = !{!738}
!738 = distinct !{!738, !739, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!739 = distinct !{!739, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!740 = !{!741}
!741 = distinct !{!741, !742, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!742 = distinct !{!742, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!743 = !{!744}
!744 = distinct !{!744, !745, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!745 = distinct !{!745, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!746 = distinct !{!746, !69}
!747 = !{!748, !750}
!748 = distinct !{!748, !749, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE0EEEE3RunERKS3_: argument 0"}
!749 = distinct !{!749, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE0EEEE3RunERKS3_"}
!750 = distinct !{!750, !751, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!751 = distinct !{!751, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!752 = !{!753, !755}
!753 = distinct !{!753, !754, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!754 = distinct !{!754, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!755 = distinct !{!755, !756, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!756 = distinct !{!756, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!757 = !{!758, !760}
!758 = distinct !{!758, !759, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!759 = distinct !{!759, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!760 = distinct !{!760, !761, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!761 = distinct !{!761, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!762 = !{!763, !765}
!763 = distinct !{!763, !764, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!764 = distinct !{!764, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!765 = distinct !{!765, !766, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!766 = distinct !{!766, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!767 = !{!768, !770}
!768 = distinct !{!768, !769, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!769 = distinct !{!769, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!770 = distinct !{!770, !771, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!771 = distinct !{!771, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!772 = !{!773}
!773 = distinct !{!773, !774, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE: argument 0"}
!774 = distinct !{!774, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE"}
!775 = !{!776, !773}
!776 = distinct !{!776, !777, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_: argument 0"}
!777 = distinct !{!777, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_"}
!778 = !{!779, !781}
!779 = distinct !{!779, !780, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS3_: argument 0"}
!780 = distinct !{!780, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS3_"}
!781 = distinct !{!781, !782, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!782 = distinct !{!782, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!783 = !{!784, !786}
!784 = distinct !{!784, !785, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!785 = distinct !{!785, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!786 = distinct !{!786, !787, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!787 = distinct !{!787, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!788 = !{!789, !791}
!789 = distinct !{!789, !790, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!790 = distinct !{!790, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!791 = distinct !{!791, !792, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!792 = distinct !{!792, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!793 = !{!794, !796}
!794 = distinct !{!794, !795, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!795 = distinct !{!795, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!796 = distinct !{!796, !797, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!797 = distinct !{!797, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!798 = !{!799, !801}
!799 = distinct !{!799, !800, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!800 = distinct !{!800, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!801 = distinct !{!801, !802, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!802 = distinct !{!802, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!803 = !{!804}
!804 = distinct !{!804, !805, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE: argument 0"}
!805 = distinct !{!805, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE"}
!806 = !{!807, !804}
!807 = distinct !{!807, !808, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_: argument 0"}
!808 = distinct !{!808, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_"}
!809 = !{!810}
!810 = distinct !{!810, !811, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!811 = distinct !{!811, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!812 = !{!813}
!813 = distinct !{!813, !814, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!814 = distinct !{!814, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!815 = !{!816}
!816 = distinct !{!816, !817, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!817 = distinct !{!817, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!818 = !{!819}
!819 = distinct !{!819, !820, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!820 = distinct !{!820, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!821 = !{!822}
!822 = distinct !{!822, !823, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!823 = distinct !{!823, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!824 = !{!825}
!825 = distinct !{!825, !826, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!826 = distinct !{!826, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!827 = !{!828}
!828 = distinct !{!828, !829, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!829 = distinct !{!829, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!830 = !{!831}
!831 = distinct !{!831, !832, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!832 = distinct !{!832, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!833 = !{!834}
!834 = distinct !{!834, !835, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!835 = distinct !{!835, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!836 = !{!837}
!837 = distinct !{!837, !838, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!838 = distinct !{!838, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!839 = !{!840}
!840 = distinct !{!840, !841, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!841 = distinct !{!841, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!842 = !{!843}
!843 = distinct !{!843, !844, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!844 = distinct !{!844, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!845 = !{!846}
!846 = distinct !{!846, !847, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!847 = distinct !{!847, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!848 = !{!849}
!849 = distinct !{!849, !850, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!850 = distinct !{!850, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!851 = !{!852}
!852 = distinct !{!852, !853, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!853 = distinct !{!853, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!854 = !{!855}
!855 = distinct !{!855, !856, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!856 = distinct !{!856, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!857 = !{!858}
!858 = distinct !{!858, !859, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!859 = distinct !{!859, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!860 = !{!861}
!861 = distinct !{!861, !862, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!862 = distinct !{!862, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!863 = !{!864}
!864 = distinct !{!864, !865, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!865 = distinct !{!865, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!866 = !{!867, !869}
!867 = distinct !{!867, !868, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!868 = distinct !{!868, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!869 = distinct !{!869, !870, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!870 = distinct !{!870, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!871 = !{!872, !874}
!872 = distinct !{!872, !873, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!873 = distinct !{!873, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!874 = distinct !{!874, !875, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!875 = distinct !{!875, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!876 = !{!877}
!877 = distinct !{!877, !878, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!878 = distinct !{!878, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!879 = !{!880, !882}
!880 = distinct !{!880, !881, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!881 = distinct !{!881, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!882 = distinct !{!882, !883, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!883 = distinct !{!883, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!884 = !{!885, !887}
!885 = distinct !{!885, !886, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!886 = distinct !{!886, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!887 = distinct !{!887, !888, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!888 = distinct !{!888, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!889 = !{!890, !892}
!890 = distinct !{!890, !891, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!891 = distinct !{!891, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!892 = distinct !{!892, !893, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!893 = distinct !{!893, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!894 = !{!895}
!895 = distinct !{!895, !896, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!896 = distinct !{!896, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!897 = !{!898}
!898 = distinct !{!898, !899, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!899 = distinct !{!899, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!900 = !{!898, !895}
!901 = !{!902}
!902 = distinct !{!902, !903, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!903 = distinct !{!903, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!904 = !{!905}
!905 = distinct !{!905, !906, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii: argument 0"}
!906 = distinct !{!906, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii"}
!907 = !{!902, !905}
!908 = !{!909, !902, !905}
!909 = distinct !{!909, !910, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!910 = distinct !{!910, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!911 = !{!909}
!912 = !{!913}
!913 = distinct !{!913, !914, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!914 = distinct !{!914, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!915 = !{!916, !905}
!916 = distinct !{!916, !917, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii: argument 0"}
!917 = distinct !{!917, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii"}
!918 = !{!913, !916, !905}
!919 = !{!920}
!920 = distinct !{!920, !921, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!921 = distinct !{!921, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!922 = !{!920, !913, !916, !905}
!923 = !{!924}
!924 = distinct !{!924, !925, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii: argument 0"}
!925 = distinct !{!925, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii"}
!926 = !{!927}
!927 = distinct !{!927, !928, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!928 = distinct !{!928, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!929 = !{!927, !924}
!930 = !{!931}
!931 = distinct !{!931, !932, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!932 = distinct !{!932, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!933 = !{!931, !927, !924}
!934 = !{!935, !937}
!935 = distinct !{!935, !936, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!936 = distinct !{!936, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!937 = distinct !{!937, !938, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!938 = distinct !{!938, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!939 = !{!940}
!940 = distinct !{!940, !941, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii: argument 0"}
!941 = distinct !{!941, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii"}
!942 = !{!943}
!943 = distinct !{!943, !944, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!944 = distinct !{!944, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!945 = !{!946}
!946 = distinct !{!946, !947, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!947 = distinct !{!947, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!948 = !{!946, !943}
!949 = !{!950, !952}
!950 = distinct !{!950, !951, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!951 = distinct !{!951, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!952 = distinct !{!952, !953, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!953 = distinct !{!953, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!954 = !{!955}
!955 = distinct !{!955, !956, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!956 = distinct !{!956, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!957 = !{!958}
!958 = distinct !{!958, !959, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!959 = distinct !{!959, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!960 = !{!961}
!961 = distinct !{!961, !962, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!962 = distinct !{!962, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!963 = !{!964}
!964 = distinct !{!964, !965, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!965 = distinct !{!965, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!966 = !{!967}
!967 = distinct !{!967, !968, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!968 = distinct !{!968, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!969 = !{!970}
!970 = distinct !{!970, !971, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!971 = distinct !{!971, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!972 = !{!973}
!973 = distinct !{!973, !974, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!974 = distinct !{!974, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!975 = !{!976}
!976 = distinct !{!976, !977, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!977 = distinct !{!977, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!978 = !{!979}
!979 = distinct !{!979, !980, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!980 = distinct !{!980, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!981 = !{!982}
!982 = distinct !{!982, !983, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!983 = distinct !{!983, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!984 = !{!985}
!985 = distinct !{!985, !986, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!986 = distinct !{!986, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!987 = !{!988}
!988 = distinct !{!988, !989, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!989 = distinct !{!989, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!990 = !{!991}
!991 = distinct !{!991, !992, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!992 = distinct !{!992, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!993 = !{!994}
!994 = distinct !{!994, !995, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!995 = distinct !{!995, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!996 = !{!997}
!997 = distinct !{!997, !998, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!998 = distinct !{!998, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!999 = !{!1000}
!1000 = distinct !{!1000, !1001, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!1001 = distinct !{!1001, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!1002 = !{!1003}
!1003 = distinct !{!1003, !1004, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1004 = distinct !{!1004, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1005 = !{!1006, !1008}
!1006 = distinct !{!1006, !1007, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1007 = distinct !{!1007, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1008 = distinct !{!1008, !1009, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1009 = distinct !{!1009, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1010 = !{!1011, !1013}
!1011 = distinct !{!1011, !1012, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1012 = distinct !{!1012, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1013 = distinct !{!1013, !1014, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1014 = distinct !{!1014, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1015 = !{!1016, !1018}
!1016 = distinct !{!1016, !1017, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1017 = distinct !{!1017, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1018 = distinct !{!1018, !1019, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1019 = distinct !{!1019, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1020 = !{!1021, !1023}
!1021 = distinct !{!1021, !1022, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1022 = distinct !{!1022, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1023 = distinct !{!1023, !1024, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1024 = distinct !{!1024, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1025 = !{!1026}
!1026 = distinct !{!1026, !1027, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii: argument 0"}
!1027 = distinct !{!1027, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii"}
!1028 = !{!1029}
!1029 = distinct !{!1029, !1030, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1030 = distinct !{!1030, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1031 = !{!1029, !1026}
!1032 = !{!1033}
!1033 = distinct !{!1033, !1034, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1034 = distinct !{!1034, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1035 = !{!1033, !1029, !1026}
!1036 = !{!1037}
!1037 = distinct !{!1037, !1038, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1038 = distinct !{!1038, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1039 = !{!1040}
!1040 = distinct !{!1040, !1041, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1041 = distinct !{!1041, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1042 = !{!1043}
!1043 = distinct !{!1043, !1044, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1044 = distinct !{!1044, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1045 = !{!1046}
!1046 = distinct !{!1046, !1047, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1047 = distinct !{!1047, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1048 = !{!1049}
!1049 = distinct !{!1049, !1050, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1050 = distinct !{!1050, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1051 = !{!1052}
!1052 = distinct !{!1052, !1053, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1053 = distinct !{!1053, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
