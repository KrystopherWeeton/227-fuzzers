; ModuleID = '../../third_party/boringssl/src/crypto/hrss/hrss.c'
source_filename = "../../third_party/boringssl/src/crypto/hrss/hrss.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.poly3 = type { %struct.poly2, %struct.poly2 }
%struct.poly2 = type { [11 x i64] }
%struct.poly3_span = type { i64*, i64* }
%struct.HRSS_public_key = type { [1424 x i8] }
%struct.HRSS_private_key = type { [1808 x i8] }
%struct.poly = type { %union.anon }
%union.anon = type { [88 x <2 x i64>] }
%struct.private_key = type { %struct.poly3, %struct.poly3, %struct.poly, [32 x i8] }
%struct.public_key = type { %struct.poly }
%struct.sha256_state_st = type { [8 x i32], i32, i32, [64 x i8], i32, i32 }

@kSharedKey = internal constant [11 x i8] c"shared key\00", align 1

; Function Attrs: nounwind ssp uwtable
define hidden void @HRSS_poly3_mul(%struct.poly3*, %struct.poly3*, %struct.poly3*) local_unnamed_addr #0 {
  %4 = alloca [22 x i64], align 16
  %5 = alloca [22 x i64], align 16
  %6 = alloca [24 x i64], align 16
  %7 = alloca [24 x i64], align 16
  %8 = alloca %struct.poly3_span, align 8
  %9 = alloca %struct.poly3_span, align 8
  %10 = alloca %struct.poly3_span, align 8
  %11 = alloca %struct.poly3_span, align 8
  %12 = bitcast [22 x i64]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 176, i8* nonnull %12) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %12, i8 -86, i64 176, i1 false)
  %13 = bitcast [22 x i64]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 176, i8* nonnull %13) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 176, i1 false)
  %14 = bitcast [24 x i64]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 192, i8* nonnull %14) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 192, i1 false)
  %15 = bitcast [24 x i64]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 192, i8* nonnull %15) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 192, i1 false)
  %16 = bitcast %struct.poly3_span* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %16) #5
  %17 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %8, i64 0, i32 0
  %18 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %8, i64 0, i32 1
  %19 = getelementptr inbounds [22 x i64], [22 x i64]* %4, i64 0, i64 0
  store i64* %19, i64** %17, align 8
  %20 = getelementptr inbounds [22 x i64], [22 x i64]* %5, i64 0, i64 0
  store i64* %20, i64** %18, align 8
  %21 = bitcast %struct.poly3_span* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %21) #5
  %22 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %9, i64 0, i32 0
  %23 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %9, i64 0, i32 1
  %24 = getelementptr inbounds [24 x i64], [24 x i64]* %6, i64 0, i64 0
  store i64* %24, i64** %22, align 8
  %25 = getelementptr inbounds [24 x i64], [24 x i64]* %7, i64 0, i64 0
  store i64* %25, i64** %23, align 8
  %26 = bitcast %struct.poly3_span* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %26) #5
  %27 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %10, i64 0, i32 0
  %28 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %10, i64 0, i32 1
  %29 = getelementptr inbounds %struct.poly3, %struct.poly3* %1, i64 0, i32 0, i32 0, i64 0
  store i64* %29, i64** %27, align 8
  %30 = getelementptr inbounds %struct.poly3, %struct.poly3* %1, i64 0, i32 1, i32 0, i64 0
  store i64* %30, i64** %28, align 8
  %31 = bitcast %struct.poly3_span* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %31) #5
  %32 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %11, i64 0, i32 0
  %33 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %11, i64 0, i32 1
  %34 = getelementptr inbounds %struct.poly3, %struct.poly3* %2, i64 0, i32 0, i32 0, i64 0
  store i64* %34, i64** %32, align 8
  %35 = getelementptr inbounds %struct.poly3, %struct.poly3* %2, i64 0, i32 1, i32 0, i64 0
  store i64* %35, i64** %33, align 8
  call fastcc void @poly3_mul_aux(%struct.poly3_span* nonnull %8, %struct.poly3_span* nonnull %9, %struct.poly3_span* nonnull %10, %struct.poly3_span* nonnull %11, i64 11)
  %36 = getelementptr inbounds [22 x i64], [22 x i64]* %4, i64 0, i64 10
  %37 = load i64, i64* %36, align 16
  %38 = getelementptr inbounds [22 x i64], [22 x i64]* %5, i64 0, i64 10
  %39 = load i64, i64* %38, align 16
  br label %132

40:                                               ; preds = %132
  %41 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 10
  %42 = load i64, i64* %41, align 8
  %43 = lshr i64 %42, 60
  %44 = and i64 %43, 1
  %45 = sub nsw i64 0, %44
  %46 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 10
  %47 = load i64, i64* %46, align 8
  %48 = lshr i64 %47, 60
  %49 = and i64 %48, 1
  %50 = sub nsw i64 0, %49
  %51 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 0
  %52 = bitcast %struct.poly3* %0 to <2 x i64>*
  %53 = load <2 x i64>, <2 x i64>* %52, align 8
  %54 = bitcast i64* %51 to <2 x i64>*
  %55 = load <2 x i64>, <2 x i64>* %54, align 8
  %56 = insertelement <2 x i64> undef, i64 %50, i32 0
  %57 = shufflevector <2 x i64> %56, <2 x i64> undef, <2 x i32> zeroinitializer
  %58 = xor <2 x i64> %55, %57
  %59 = xor <2 x i64> %53, %57
  %60 = insertelement <2 x i64> undef, i64 %45, i32 0
  %61 = shufflevector <2 x i64> %60, <2 x i64> undef, <2 x i32> zeroinitializer
  %62 = xor <2 x i64> %58, %61
  %63 = and <2 x i64> %62, %59
  %64 = bitcast %struct.poly3* %0 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %64, align 8
  %65 = xor <2 x i64> %53, %61
  %66 = or <2 x i64> %58, %65
  %67 = bitcast i64* %51 to <2 x i64>*
  store <2 x i64> %66, <2 x i64>* %67, align 8
  %68 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 2
  %69 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 2
  %70 = bitcast i64* %68 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8
  %72 = bitcast i64* %69 to <2 x i64>*
  %73 = load <2 x i64>, <2 x i64>* %72, align 8
  %74 = xor <2 x i64> %73, %57
  %75 = xor <2 x i64> %71, %57
  %76 = xor <2 x i64> %74, %61
  %77 = and <2 x i64> %76, %75
  %78 = bitcast i64* %68 to <2 x i64>*
  store <2 x i64> %77, <2 x i64>* %78, align 8
  %79 = xor <2 x i64> %71, %61
  %80 = or <2 x i64> %74, %79
  %81 = bitcast i64* %69 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %81, align 8
  %82 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 4
  %83 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 4
  %84 = bitcast i64* %82 to <2 x i64>*
  %85 = load <2 x i64>, <2 x i64>* %84, align 8
  %86 = bitcast i64* %83 to <2 x i64>*
  %87 = load <2 x i64>, <2 x i64>* %86, align 8
  %88 = xor <2 x i64> %87, %57
  %89 = xor <2 x i64> %85, %57
  %90 = xor <2 x i64> %88, %61
  %91 = and <2 x i64> %90, %89
  %92 = bitcast i64* %82 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %92, align 8
  %93 = xor <2 x i64> %85, %61
  %94 = or <2 x i64> %88, %93
  %95 = bitcast i64* %83 to <2 x i64>*
  store <2 x i64> %94, <2 x i64>* %95, align 8
  %96 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 6
  %97 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 6
  %98 = bitcast i64* %96 to <2 x i64>*
  %99 = load <2 x i64>, <2 x i64>* %98, align 8
  %100 = bitcast i64* %97 to <2 x i64>*
  %101 = load <2 x i64>, <2 x i64>* %100, align 8
  %102 = xor <2 x i64> %101, %57
  %103 = xor <2 x i64> %99, %57
  %104 = xor <2 x i64> %102, %61
  %105 = and <2 x i64> %104, %103
  %106 = bitcast i64* %96 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %106, align 8
  %107 = xor <2 x i64> %99, %61
  %108 = or <2 x i64> %102, %107
  %109 = bitcast i64* %97 to <2 x i64>*
  store <2 x i64> %108, <2 x i64>* %109, align 8
  %110 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 8
  %111 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 8
  %112 = bitcast i64* %110 to <2 x i64>*
  %113 = load <2 x i64>, <2 x i64>* %112, align 8
  %114 = bitcast i64* %111 to <2 x i64>*
  %115 = load <2 x i64>, <2 x i64>* %114, align 8
  %116 = xor <2 x i64> %115, %57
  %117 = xor <2 x i64> %113, %57
  %118 = xor <2 x i64> %116, %61
  %119 = and <2 x i64> %118, %117
  %120 = bitcast i64* %110 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8
  %121 = xor <2 x i64> %113, %61
  %122 = or <2 x i64> %116, %121
  %123 = bitcast i64* %111 to <2 x i64>*
  store <2 x i64> %122, <2 x i64>* %123, align 8
  %124 = xor i64 %47, %50
  %125 = xor i64 %42, %50
  %126 = xor i64 %124, %45
  %127 = xor i64 %42, %45
  %128 = or i64 %124, %127
  %129 = and i64 %125, 2305843009213693951
  %130 = and i64 %129, %126
  store i64 %130, i64* %41, align 8
  %131 = and i64 %128, 2305843009213693951
  store i64 %131, i64* %46, align 8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %31) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %26) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %21) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %16) #5
  call void @llvm.lifetime.end.p0i8(i64 192, i8* nonnull %15) #5
  call void @llvm.lifetime.end.p0i8(i64 192, i8* nonnull %14) #5
  call void @llvm.lifetime.end.p0i8(i64 176, i8* nonnull %13) #5
  call void @llvm.lifetime.end.p0i8(i64 176, i8* nonnull %12) #5
  ret void

132:                                              ; preds = %132, %3
  %133 = phi i64 [ %39, %3 ], [ %144, %132 ]
  %134 = phi i64 [ %37, %3 ], [ %139, %132 ]
  %135 = phi i64 [ 0, %3 ], [ %159, %132 ]
  %136 = add nuw nsw i64 %135, 11
  %137 = lshr i64 %134, 61
  %138 = getelementptr inbounds [22 x i64], [22 x i64]* %4, i64 0, i64 %136
  %139 = load i64, i64* %138, align 8
  %140 = shl i64 %139, 3
  %141 = or i64 %140, %137
  %142 = lshr i64 %133, 61
  %143 = getelementptr inbounds [22 x i64], [22 x i64]* %5, i64 0, i64 %136
  %144 = load i64, i64* %143, align 8
  %145 = shl i64 %144, 3
  %146 = or i64 %145, %142
  %147 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 %135
  %148 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 %135
  %149 = getelementptr inbounds [22 x i64], [22 x i64]* %4, i64 0, i64 %135
  %150 = load i64, i64* %149, align 8
  %151 = getelementptr inbounds [22 x i64], [22 x i64]* %5, i64 0, i64 %135
  %152 = load i64, i64* %151, align 8
  %153 = xor i64 %146, %150
  %154 = xor i64 %152, %141
  %155 = and i64 %153, %154
  store i64 %155, i64* %147, align 8
  %156 = xor i64 %146, %152
  %157 = xor i64 %153, %141
  %158 = or i64 %157, %156
  store i64 %158, i64* %148, align 8
  %159 = add nuw nsw i64 %135, 1
  %160 = icmp eq i64 %159, 11
  br i1 %160, label %40, label %132
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @poly3_mul_aux(%struct.poly3_span* nocapture readonly, %struct.poly3_span*, %struct.poly3_span* nocapture readonly, %struct.poly3_span* nocapture readonly, i64) unnamed_addr #0 {
  %6 = alloca %struct.poly3_span, align 8
  %7 = alloca %struct.poly3_span, align 8
  %8 = alloca %struct.poly3_span, align 8
  %9 = alloca %struct.poly3_span, align 8
  %10 = alloca %struct.poly3_span, align 8
  %11 = alloca %struct.poly3_span, align 8
  %12 = icmp eq i64 %4, 1
  br i1 %12, label %13, label %78

13:                                               ; preds = %5
  %14 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %3, i64 0, i32 0
  %15 = load i64*, i64** %14, align 8
  %16 = load i64, i64* %15, align 8
  %17 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %3, i64 0, i32 1
  %18 = load i64*, i64** %17, align 8
  %19 = load i64, i64* %18, align 8
  %20 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %2, i64 0, i32 0
  %21 = load i64*, i64** %20, align 8
  %22 = load i64, i64* %21, align 8
  %23 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %2, i64 0, i32 1
  %24 = load i64*, i64** %23, align 8
  %25 = load i64, i64* %24, align 8
  br label %35

26:                                               ; preds = %71
  %27 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %0, i64 0, i32 0
  %28 = load i64*, i64** %27, align 8
  store i64 %75, i64* %28, align 8
  %29 = load i64*, i64** %27, align 8
  %30 = getelementptr inbounds i64, i64* %29, i64 1
  store i64 %72, i64* %30, align 8
  %31 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %0, i64 0, i32 1
  %32 = load i64*, i64** %31, align 8
  store i64 %73, i64* %32, align 8
  %33 = load i64*, i64** %31, align 8
  %34 = getelementptr inbounds i64, i64* %33, i64 1
  store i64 %74, i64* %34, align 8
  br label %267

35:                                               ; preds = %71, %13
  %36 = phi i64 [ %16, %13 ], [ %50, %71 ]
  %37 = phi i64 [ %19, %13 ], [ %51, %71 ]
  %38 = phi i64 [ 0, %13 ], [ %76, %71 ]
  %39 = phi i64 [ 0, %13 ], [ %75, %71 ]
  %40 = phi i64 [ 0, %13 ], [ %74, %71 ]
  %41 = phi i64 [ 0, %13 ], [ %73, %71 ]
  %42 = phi i64 [ 0, %13 ], [ %72, %71 ]
  %43 = and i64 %36, 1
  %44 = sub nsw i64 0, %43
  %45 = and i64 %37, 1
  %46 = sub nsw i64 0, %45
  %47 = and i64 %25, %46
  %48 = xor i64 %22, %44
  %49 = and i64 %48, %47
  %50 = lshr i64 %36, 1
  %51 = lshr i64 %37, 1
  %52 = icmp eq i64 %38, 0
  br i1 %52, label %71, label %53

53:                                               ; preds = %35
  %54 = shl i64 %49, %38
  %55 = sub nuw nsw i64 64, %38
  %56 = lshr i64 %49, %55
  %57 = shl i64 %47, %38
  %58 = lshr i64 %47, %55
  %59 = xor i64 %57, %39
  %60 = xor i64 %54, %41
  %61 = and i64 %60, %59
  %62 = xor i64 %57, %41
  %63 = xor i64 %54, %59
  %64 = or i64 %63, %62
  %65 = xor i64 %58, %42
  %66 = xor i64 %56, %40
  %67 = and i64 %66, %65
  %68 = xor i64 %58, %40
  %69 = xor i64 %56, %65
  %70 = or i64 %69, %68
  br label %71

71:                                               ; preds = %35, %53
  %72 = phi i64 [ %67, %53 ], [ %42, %35 ]
  %73 = phi i64 [ %64, %53 ], [ %47, %35 ]
  %74 = phi i64 [ %70, %53 ], [ %40, %35 ]
  %75 = phi i64 [ %61, %53 ], [ %49, %35 ]
  %76 = add nuw nsw i64 %38, 1
  %77 = icmp eq i64 %76, 64
  br i1 %77, label %26, label %35

78:                                               ; preds = %5
  %79 = lshr i64 %4, 1
  %80 = sub i64 %4, %79
  %81 = bitcast %struct.poly3_span* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %81) #5
  %82 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %6, i64 0, i32 0
  %83 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %6, i64 0, i32 1
  %84 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %2, i64 0, i32 0
  %85 = load i64*, i64** %84, align 8
  %86 = getelementptr inbounds i64, i64* %85, i64 %79
  store i64* %86, i64** %82, align 8
  %87 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %2, i64 0, i32 1
  %88 = load i64*, i64** %87, align 8
  %89 = getelementptr inbounds i64, i64* %88, i64 %79
  store i64* %89, i64** %83, align 8
  %90 = bitcast %struct.poly3_span* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %90) #5
  %91 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %7, i64 0, i32 0
  %92 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %7, i64 0, i32 1
  %93 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %3, i64 0, i32 0
  %94 = load i64*, i64** %93, align 8
  %95 = getelementptr inbounds i64, i64* %94, i64 %79
  store i64* %95, i64** %91, align 8
  %96 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %3, i64 0, i32 1
  %97 = load i64*, i64** %96, align 8
  %98 = getelementptr inbounds i64, i64* %97, i64 %79
  store i64* %98, i64** %92, align 8
  %99 = bitcast %struct.poly3_span* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %99) #5
  %100 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %8, i64 0, i32 0
  %101 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %8, i64 0, i32 1
  %102 = bitcast %struct.poly3_span* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %99, i8* align 8 %102, i64 16, i1 false)
  %103 = bitcast %struct.poly3_span* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %103) #5
  %104 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %9, i64 0, i32 0
  %105 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %9, i64 0, i32 1
  %106 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %0, i64 0, i32 0
  %107 = load i64*, i64** %106, align 8
  %108 = getelementptr inbounds i64, i64* %107, i64 %80
  store i64* %108, i64** %104, align 8
  %109 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %0, i64 0, i32 1
  %110 = load i64*, i64** %109, align 8
  %111 = getelementptr inbounds i64, i64* %110, i64 %80
  store i64* %111, i64** %105, align 8
  %112 = icmp eq i64 %79, 0
  br i1 %112, label %163, label %113

113:                                              ; preds = %78
  %114 = load i64*, i64** %100, align 8
  %115 = load i64*, i64** %101, align 8
  br label %116

116:                                              ; preds = %138, %113
  %117 = phi i64* [ %140, %138 ], [ %88, %113 ]
  %118 = phi i64* [ %139, %138 ], [ %85, %113 ]
  %119 = phi i64 [ %136, %138 ], [ 0, %113 ]
  %120 = getelementptr inbounds i64, i64* %114, i64 %119
  %121 = getelementptr inbounds i64, i64* %115, i64 %119
  %122 = getelementptr inbounds i64, i64* %118, i64 %119
  %123 = load i64, i64* %122, align 8
  %124 = getelementptr inbounds i64, i64* %117, i64 %119
  %125 = load i64, i64* %124, align 8
  %126 = getelementptr inbounds i64, i64* %86, i64 %119
  %127 = load i64, i64* %126, align 8
  %128 = getelementptr inbounds i64, i64* %89, i64 %119
  %129 = load i64, i64* %128, align 8
  %130 = xor i64 %129, %123
  %131 = xor i64 %127, %125
  %132 = and i64 %130, %131
  store i64 %132, i64* %120, align 8
  %133 = xor i64 %129, %125
  %134 = xor i64 %130, %127
  %135 = or i64 %134, %133
  store i64 %135, i64* %121, align 8
  %136 = add nuw nsw i64 %119, 1
  %137 = icmp eq i64 %136, %79
  br i1 %137, label %141, label %138

138:                                              ; preds = %116
  %139 = load i64*, i64** %84, align 8
  %140 = load i64*, i64** %87, align 8
  br label %116

141:                                              ; preds = %116, %141
  %142 = phi i64 [ %161, %141 ], [ 0, %116 ]
  %143 = getelementptr inbounds i64, i64* %108, i64 %142
  %144 = getelementptr inbounds i64, i64* %111, i64 %142
  %145 = load i64*, i64** %93, align 8
  %146 = getelementptr inbounds i64, i64* %145, i64 %142
  %147 = load i64, i64* %146, align 8
  %148 = load i64*, i64** %96, align 8
  %149 = getelementptr inbounds i64, i64* %148, i64 %142
  %150 = load i64, i64* %149, align 8
  %151 = getelementptr inbounds i64, i64* %95, i64 %142
  %152 = load i64, i64* %151, align 8
  %153 = getelementptr inbounds i64, i64* %98, i64 %142
  %154 = load i64, i64* %153, align 8
  %155 = xor i64 %154, %147
  %156 = xor i64 %152, %150
  %157 = and i64 %155, %156
  store i64 %157, i64* %143, align 8
  %158 = xor i64 %154, %150
  %159 = xor i64 %155, %152
  %160 = or i64 %159, %158
  store i64 %160, i64* %144, align 8
  %161 = add nuw nsw i64 %142, 1
  %162 = icmp eq i64 %161, %79
  br i1 %162, label %163, label %141

163:                                              ; preds = %141, %78
  %164 = icmp eq i64 %80, %79
  br i1 %164, label %180, label %165

165:                                              ; preds = %163
  %166 = getelementptr inbounds i64, i64* %86, i64 %79
  %167 = load i64, i64* %166, align 8
  %168 = load i64*, i64** %100, align 8
  %169 = getelementptr inbounds i64, i64* %168, i64 %79
  store i64 %167, i64* %169, align 8
  %170 = getelementptr inbounds i64, i64* %89, i64 %79
  %171 = load i64, i64* %170, align 8
  %172 = load i64*, i64** %101, align 8
  %173 = getelementptr inbounds i64, i64* %172, i64 %79
  store i64 %171, i64* %173, align 8
  %174 = getelementptr inbounds i64, i64* %95, i64 %79
  %175 = load i64, i64* %174, align 8
  %176 = getelementptr inbounds i64, i64* %107, i64 %4
  store i64 %175, i64* %176, align 8
  %177 = getelementptr inbounds i64, i64* %98, i64 %79
  %178 = load i64, i64* %177, align 8
  %179 = getelementptr inbounds i64, i64* %110, i64 %4
  store i64 %178, i64* %179, align 8
  br label %180

180:                                              ; preds = %163, %165
  %181 = bitcast %struct.poly3_span* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %181) #5
  %182 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %10, i64 0, i32 0
  %183 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %10, i64 0, i32 1
  %184 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %1, i64 0, i32 0
  %185 = load i64*, i64** %184, align 8
  %186 = shl i64 %80, 1
  %187 = getelementptr inbounds i64, i64* %185, i64 %186
  store i64* %187, i64** %182, align 8
  %188 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %1, i64 0, i32 1
  %189 = load i64*, i64** %188, align 8
  %190 = getelementptr inbounds i64, i64* %189, i64 %186
  store i64* %190, i64** %183, align 8
  %191 = load i64*, i64** %106, align 8
  %192 = getelementptr inbounds i64, i64* %191, i64 %79
  %193 = load i64*, i64** %109, align 8
  %194 = getelementptr inbounds i64, i64* %193, i64 %79
  %195 = bitcast %struct.poly3_span* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %195) #5
  %196 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %11, i64 0, i32 0
  %197 = getelementptr inbounds %struct.poly3_span, %struct.poly3_span* %11, i64 0, i32 1
  %198 = and i64 %4, -2
  %199 = getelementptr inbounds i64, i64* %191, i64 %198
  store i64* %199, i64** %196, align 8
  %200 = getelementptr inbounds i64, i64* %193, i64 %198
  store i64* %200, i64** %197, align 8
  call fastcc void @poly3_mul_aux(%struct.poly3_span* %1, %struct.poly3_span* nonnull %10, %struct.poly3_span* nonnull %8, %struct.poly3_span* nonnull %9, i64 %80)
  call fastcc void @poly3_mul_aux(%struct.poly3_span* nonnull %11, %struct.poly3_span* nonnull %10, %struct.poly3_span* nonnull %6, %struct.poly3_span* nonnull %7, i64 %80)
  call fastcc void @poly3_mul_aux(%struct.poly3_span* %0, %struct.poly3_span* nonnull %10, %struct.poly3_span* %2, %struct.poly3_span* %3, i64 %79)
  %201 = icmp eq i64 %198, 0
  br i1 %201, label %224, label %202

202:                                              ; preds = %180, %202
  %203 = phi i64 [ %222, %202 ], [ 0, %180 ]
  %204 = load i64*, i64** %184, align 8
  %205 = getelementptr inbounds i64, i64* %204, i64 %203
  %206 = load i64*, i64** %188, align 8
  %207 = getelementptr inbounds i64, i64* %206, i64 %203
  %208 = load i64, i64* %205, align 8
  %209 = load i64, i64* %207, align 8
  %210 = load i64*, i64** %106, align 8
  %211 = getelementptr inbounds i64, i64* %210, i64 %203
  %212 = load i64, i64* %211, align 8
  %213 = load i64*, i64** %109, align 8
  %214 = getelementptr inbounds i64, i64* %213, i64 %203
  %215 = load i64, i64* %214, align 8
  %216 = xor i64 %215, %209
  %217 = xor i64 %215, %208
  %218 = xor i64 %216, %212
  %219 = and i64 %218, %217
  store i64 %219, i64* %205, align 8
  %220 = xor i64 %212, %208
  %221 = or i64 %216, %220
  store i64 %221, i64* %207, align 8
  %222 = add nuw i64 %203, 1
  %223 = icmp eq i64 %222, %198
  br i1 %223, label %224, label %202

224:                                              ; preds = %202, %180
  %225 = icmp eq i64 %186, 0
  br i1 %225, label %266, label %226

226:                                              ; preds = %224, %226
  %227 = phi i64 [ %244, %226 ], [ 0, %224 ]
  %228 = load i64*, i64** %184, align 8
  %229 = getelementptr inbounds i64, i64* %228, i64 %227
  %230 = load i64*, i64** %188, align 8
  %231 = getelementptr inbounds i64, i64* %230, i64 %227
  %232 = load i64, i64* %229, align 8
  %233 = load i64, i64* %231, align 8
  %234 = getelementptr inbounds i64, i64* %199, i64 %227
  %235 = load i64, i64* %234, align 8
  %236 = getelementptr inbounds i64, i64* %200, i64 %227
  %237 = load i64, i64* %236, align 8
  %238 = xor i64 %237, %233
  %239 = xor i64 %237, %232
  %240 = xor i64 %238, %235
  %241 = and i64 %240, %239
  store i64 %241, i64* %229, align 8
  %242 = xor i64 %235, %232
  %243 = or i64 %238, %242
  store i64 %243, i64* %231, align 8
  %244 = add nuw i64 %227, 1
  %245 = icmp eq i64 %244, %186
  br i1 %245, label %246, label %226

246:                                              ; preds = %226, %246
  %247 = phi i64 [ %264, %246 ], [ 0, %226 ]
  %248 = getelementptr inbounds i64, i64* %192, i64 %247
  %249 = getelementptr inbounds i64, i64* %194, i64 %247
  %250 = load i64, i64* %248, align 8
  %251 = load i64, i64* %249, align 8
  %252 = load i64*, i64** %184, align 8
  %253 = getelementptr inbounds i64, i64* %252, i64 %247
  %254 = load i64, i64* %253, align 8
  %255 = load i64*, i64** %188, align 8
  %256 = getelementptr inbounds i64, i64* %255, i64 %247
  %257 = load i64, i64* %256, align 8
  %258 = xor i64 %257, %250
  %259 = xor i64 %254, %251
  %260 = and i64 %258, %259
  store i64 %260, i64* %248, align 8
  %261 = xor i64 %257, %251
  %262 = xor i64 %258, %254
  %263 = or i64 %262, %261
  store i64 %263, i64* %249, align 8
  %264 = add nuw i64 %247, 1
  %265 = icmp eq i64 %264, %186
  br i1 %265, label %266, label %246

266:                                              ; preds = %246, %224
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %195) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %181) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %103) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %99) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %90) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %81) #5
  br label %267

267:                                              ; preds = %266, %26
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @HRSS_poly3_invert(%struct.poly3*, %struct.poly3* nocapture readonly) local_unnamed_addr #2 {
  %3 = alloca %struct.poly3, align 16
  %4 = bitcast %struct.poly3* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 176, i8* nonnull %4) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 -86, i64 176, i1 false) #5
  %5 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 1
  %6 = getelementptr inbounds %struct.poly3, %struct.poly3* %1, i64 0, i32 1
  call fastcc void @poly2_reverse_700(%struct.poly2* %5, %struct.poly2* %6) #5
  %7 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 0
  %8 = getelementptr inbounds %struct.poly3, %struct.poly3* %1, i64 0, i32 0
  call fastcc void @poly2_reverse_700(%struct.poly2* nonnull %7, %struct.poly2* %8) #5
  %9 = bitcast %struct.poly3* %3 to <2 x i64>*
  %10 = load <2 x i64>, <2 x i64>* %9, align 16
  %11 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 0, i32 0, i64 2
  %12 = bitcast i64* %11 to <2 x i64>*
  %13 = load <2 x i64>, <2 x i64>* %12, align 16
  %14 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i64* %14 to <2 x i64>*
  %16 = load <2 x i64>, <2 x i64>* %15, align 16
  %17 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 0, i32 0, i64 6
  %18 = bitcast i64* %17 to <2 x i64>*
  %19 = load <2 x i64>, <2 x i64>* %18, align 16
  %20 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 0, i32 0, i64 8
  %21 = bitcast i64* %20 to <2 x i64>*
  %22 = load <2 x i64>, <2 x i64>* %21, align 16
  %23 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 0, i32 0, i64 10
  %24 = load i64, i64* %23, align 16
  %25 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %24, i32 0
  %26 = bitcast %struct.poly2* %5 to <2 x i64>*
  %27 = load <2 x i64>, <2 x i64>* %26, align 8
  %28 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 1, i32 0, i64 2
  %29 = bitcast i64* %28 to <2 x i64>*
  %30 = load <2 x i64>, <2 x i64>* %29, align 8
  %31 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 1, i32 0, i64 4
  %32 = bitcast i64* %31 to <2 x i64>*
  %33 = load <2 x i64>, <2 x i64>* %32, align 8
  %34 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 1, i32 0, i64 6
  %35 = bitcast i64* %34 to <2 x i64>*
  %36 = load <2 x i64>, <2 x i64>* %35, align 8
  %37 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 1, i32 0, i64 8
  %38 = bitcast i64* %37 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 8
  %40 = getelementptr inbounds %struct.poly3, %struct.poly3* %3, i64 0, i32 1, i32 0, i64 10
  %41 = load i64, i64* %40, align 8
  %42 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %41, i32 0
  br label %43

43:                                               ; preds = %43, %2
  %44 = phi i32 [ 1, %2 ], [ %239, %43 ]
  %45 = phi i64 [ 0, %2 ], [ %545, %43 ]
  %46 = phi <2 x i64> [ %27, %2 ], [ %442, %43 ]
  %47 = phi <2 x i64> [ %30, %2 ], [ %426, %43 ]
  %48 = phi <2 x i64> [ %33, %2 ], [ %408, %43 ]
  %49 = phi <2 x i64> [ %36, %2 ], [ %390, %43 ]
  %50 = phi <2 x i64> [ %39, %2 ], [ %372, %43 ]
  %51 = phi <2 x i64> [ %42, %2 ], [ %354, %43 ]
  %52 = phi <2 x i64> [ %10, %2 ], [ %435, %43 ]
  %53 = phi <2 x i64> [ %13, %2 ], [ %417, %43 ]
  %54 = phi <2 x i64> [ %16, %2 ], [ %399, %43 ]
  %55 = phi <2 x i64> [ %19, %2 ], [ %381, %43 ]
  %56 = phi <2 x i64> [ %22, %2 ], [ %363, %43 ]
  %57 = phi <2 x i64> [ %25, %2 ], [ %346, %43 ]
  %58 = phi <2 x i64> [ <i64 -1, i64 -1>, %2 ], [ %245, %43 ]
  %59 = phi <2 x i64> [ <i64 -1, i64 -1>, %2 ], [ %253, %43 ]
  %60 = phi <2 x i64> [ <i64 -1, i64 -1>, %2 ], [ %261, %43 ]
  %61 = phi <2 x i64> [ <i64 -1, i64 -1>, %2 ], [ %269, %43 ]
  %62 = phi <2 x i64> [ <i64 -1, i64 -1>, %2 ], [ %277, %43 ]
  %63 = phi <2 x i64> [ <i64 2305843009213693951, i64 0>, %2 ], [ %285, %43 ]
  %64 = phi <2 x i64> [ zeroinitializer, %2 ], [ %241, %43 ]
  %65 = phi <2 x i64> [ zeroinitializer, %2 ], [ %249, %43 ]
  %66 = phi <2 x i64> [ zeroinitializer, %2 ], [ %257, %43 ]
  %67 = phi <2 x i64> [ zeroinitializer, %2 ], [ %265, %43 ]
  %68 = phi <2 x i64> [ zeroinitializer, %2 ], [ %273, %43 ]
  %69 = phi <2 x i64> [ zeroinitializer, %2 ], [ %281, %43 ]
  %70 = phi <2 x i64> [ <i64 1, i64 0>, %2 ], [ %499, %43 ]
  %71 = phi <2 x i64> [ zeroinitializer, %2 ], [ %508, %43 ]
  %72 = phi <2 x i64> [ zeroinitializer, %2 ], [ %517, %43 ]
  %73 = phi <2 x i64> [ zeroinitializer, %2 ], [ %526, %43 ]
  %74 = phi <2 x i64> [ zeroinitializer, %2 ], [ %535, %43 ]
  %75 = phi <2 x i64> [ zeroinitializer, %2 ], [ %544, %43 ]
  %76 = phi <2 x i64> [ zeroinitializer, %2 ], [ %497, %43 ]
  %77 = phi <2 x i64> [ zeroinitializer, %2 ], [ %506, %43 ]
  %78 = phi <2 x i64> [ zeroinitializer, %2 ], [ %515, %43 ]
  %79 = phi <2 x i64> [ zeroinitializer, %2 ], [ %524, %43 ]
  %80 = phi <2 x i64> [ zeroinitializer, %2 ], [ %533, %43 ]
  %81 = phi <2 x i64> [ zeroinitializer, %2 ], [ %542, %43 ]
  %82 = phi <2 x i64> [ zeroinitializer, %2 ], [ %449, %43 ]
  %83 = phi <2 x i64> [ zeroinitializer, %2 ], [ %457, %43 ]
  %84 = phi <2 x i64> [ zeroinitializer, %2 ], [ %465, %43 ]
  %85 = phi <2 x i64> [ zeroinitializer, %2 ], [ %473, %43 ]
  %86 = phi <2 x i64> [ zeroinitializer, %2 ], [ %481, %43 ]
  %87 = phi <2 x i64> [ zeroinitializer, %2 ], [ %489, %43 ]
  %88 = phi <2 x i64> [ zeroinitializer, %2 ], [ %445, %43 ]
  %89 = phi <2 x i64> [ zeroinitializer, %2 ], [ %453, %43 ]
  %90 = phi <2 x i64> [ zeroinitializer, %2 ], [ %461, %43 ]
  %91 = phi <2 x i64> [ zeroinitializer, %2 ], [ %469, %43 ]
  %92 = phi <2 x i64> [ zeroinitializer, %2 ], [ %477, %43 ]
  %93 = phi <2 x i64> [ zeroinitializer, %2 ], [ %485, %43 ]
  %94 = lshr <2 x i64> %88, <i64 63, i64 63>
  %95 = shl <2 x i64> %88, <i64 1, i64 1>
  %96 = bitcast <2 x i64> %94 to <16 x i8>
  %97 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %96, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %98 = bitcast <16 x i8> %97 to <2 x i64>
  %99 = or <2 x i64> %95, %98
  %100 = shufflevector <16 x i8> %96, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %101 = bitcast <16 x i8> %100 to <2 x i64>
  %102 = lshr <2 x i64> %82, <i64 63, i64 63>
  %103 = shl <2 x i64> %82, <i64 1, i64 1>
  %104 = bitcast <2 x i64> %102 to <16 x i8>
  %105 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %104, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %106 = bitcast <16 x i8> %105 to <2 x i64>
  %107 = or <2 x i64> %103, %106
  %108 = shufflevector <16 x i8> %104, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %109 = bitcast <16 x i8> %108 to <2 x i64>
  %110 = lshr <2 x i64> %89, <i64 63, i64 63>
  %111 = shl <2 x i64> %89, <i64 1, i64 1>
  %112 = bitcast <2 x i64> %110 to <16 x i8>
  %113 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %112, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %114 = bitcast <16 x i8> %113 to <2 x i64>
  %115 = or <2 x i64> %111, %101
  %116 = or <2 x i64> %115, %114
  %117 = shufflevector <16 x i8> %112, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %118 = bitcast <16 x i8> %117 to <2 x i64>
  %119 = lshr <2 x i64> %83, <i64 63, i64 63>
  %120 = shl <2 x i64> %83, <i64 1, i64 1>
  %121 = bitcast <2 x i64> %119 to <16 x i8>
  %122 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %121, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %123 = bitcast <16 x i8> %122 to <2 x i64>
  %124 = or <2 x i64> %120, %109
  %125 = or <2 x i64> %124, %123
  %126 = shufflevector <16 x i8> %121, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %127 = bitcast <16 x i8> %126 to <2 x i64>
  %128 = lshr <2 x i64> %90, <i64 63, i64 63>
  %129 = shl <2 x i64> %90, <i64 1, i64 1>
  %130 = bitcast <2 x i64> %128 to <16 x i8>
  %131 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %130, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %132 = bitcast <16 x i8> %131 to <2 x i64>
  %133 = or <2 x i64> %129, %118
  %134 = or <2 x i64> %133, %132
  %135 = shufflevector <16 x i8> %130, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %136 = bitcast <16 x i8> %135 to <2 x i64>
  %137 = lshr <2 x i64> %84, <i64 63, i64 63>
  %138 = shl <2 x i64> %84, <i64 1, i64 1>
  %139 = bitcast <2 x i64> %137 to <16 x i8>
  %140 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %139, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %141 = bitcast <16 x i8> %140 to <2 x i64>
  %142 = or <2 x i64> %138, %127
  %143 = or <2 x i64> %142, %141
  %144 = shufflevector <16 x i8> %139, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %145 = bitcast <16 x i8> %144 to <2 x i64>
  %146 = lshr <2 x i64> %91, <i64 63, i64 63>
  %147 = shl <2 x i64> %91, <i64 1, i64 1>
  %148 = bitcast <2 x i64> %146 to <16 x i8>
  %149 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %148, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %150 = bitcast <16 x i8> %149 to <2 x i64>
  %151 = or <2 x i64> %147, %136
  %152 = or <2 x i64> %151, %150
  %153 = shufflevector <16 x i8> %148, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %154 = bitcast <16 x i8> %153 to <2 x i64>
  %155 = lshr <2 x i64> %85, <i64 63, i64 63>
  %156 = shl <2 x i64> %85, <i64 1, i64 1>
  %157 = bitcast <2 x i64> %155 to <16 x i8>
  %158 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %157, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %159 = bitcast <16 x i8> %158 to <2 x i64>
  %160 = or <2 x i64> %156, %145
  %161 = or <2 x i64> %160, %159
  %162 = shufflevector <16 x i8> %157, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %163 = bitcast <16 x i8> %162 to <2 x i64>
  %164 = lshr <2 x i64> %92, <i64 63, i64 63>
  %165 = shl <2 x i64> %92, <i64 1, i64 1>
  %166 = bitcast <2 x i64> %164 to <16 x i8>
  %167 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %166, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %168 = bitcast <16 x i8> %167 to <2 x i64>
  %169 = or <2 x i64> %165, %154
  %170 = or <2 x i64> %169, %168
  %171 = shufflevector <16 x i8> %166, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %172 = bitcast <16 x i8> %171 to <2 x i64>
  %173 = lshr <2 x i64> %86, <i64 63, i64 63>
  %174 = shl <2 x i64> %86, <i64 1, i64 1>
  %175 = bitcast <2 x i64> %173 to <16 x i8>
  %176 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %175, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %177 = bitcast <16 x i8> %176 to <2 x i64>
  %178 = or <2 x i64> %174, %163
  %179 = or <2 x i64> %178, %177
  %180 = shufflevector <16 x i8> %175, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %181 = bitcast <16 x i8> %180 to <2 x i64>
  %182 = lshr <2 x i64> %93, <i64 63, i64 63>
  %183 = shl <2 x i64> %93, <i64 1, i64 1>
  %184 = bitcast <2 x i64> %182 to <16 x i8>
  %185 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %184, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %186 = bitcast <16 x i8> %185 to <2 x i64>
  %187 = or <2 x i64> %183, %172
  %188 = or <2 x i64> %187, %186
  %189 = lshr <2 x i64> %87, <i64 63, i64 63>
  %190 = shl <2 x i64> %87, <i64 1, i64 1>
  %191 = bitcast <2 x i64> %189 to <16 x i8>
  %192 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %191, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %193 = bitcast <16 x i8> %192 to <2 x i64>
  %194 = or <2 x i64> %190, %181
  %195 = or <2 x i64> %194, %193
  %196 = lshr i32 %44, 31
  %197 = zext i32 %196 to i64
  %198 = add nsw i64 %197, -1
  %199 = sext i32 %44 to i64
  %200 = xor i64 %199, -9223372036854775808
  %201 = add nsw i64 %199, -1
  %202 = and i64 %201, %200
  %203 = ashr i64 %202, 63
  %204 = xor i64 %203, -1
  %205 = and i64 %198, %204
  %206 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %205, i32 0
  %207 = and <2 x i64> %206, %46
  %208 = shl <2 x i64> %207, <i64 63, i64 63>
  %209 = bitcast <2 x i64> %208 to <4 x i32>
  %210 = ashr <4 x i32> %209, <i32 31, i32 31, i32 31, i32 31>
  %211 = shufflevector <4 x i32> %210, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %212 = bitcast <4 x i32> %211 to <2 x i64>
  %213 = and <2 x i64> %58, %46
  %214 = shl <2 x i64> %213, <i64 63, i64 63>
  %215 = bitcast <2 x i64> %214 to <4 x i32>
  %216 = ashr <4 x i32> %215, <i32 31, i32 31, i32 31, i32 31>
  %217 = shufflevector <4 x i32> %216, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %218 = bitcast <4 x i32> %217 to <2 x i64>
  %219 = xor <2 x i64> %64, %52
  %220 = and <2 x i64> %219, %218
  %221 = shl <2 x i64> %220, <i64 63, i64 63>
  %222 = bitcast <2 x i64> %221 to <4 x i32>
  %223 = ashr <4 x i32> %222, <i32 31, i32 31, i32 31, i32 31>
  %224 = shufflevector <4 x i32> %223, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %225 = bitcast <4 x i32> %224 to <2 x i64>
  %226 = extractelement <2 x i64> %212, i32 0
  %227 = and i64 %226, 1
  %228 = sub nsw i64 0, %227
  %229 = sub nsw i32 0, %44
  %230 = zext i32 %229 to i64
  %231 = zext i32 %44 to i64
  %232 = tail call i64 asm "", "=r,0,~{dirflag},~{fpsr},~{flags}"(i64 %228) #6, !srcloc !2
  %233 = and i64 %232, %230
  %234 = add nsw i64 %227, -1
  %235 = tail call i64 asm "", "=r,0,~{dirflag},~{fpsr},~{flags}"(i64 %234) #6, !srcloc !2
  %236 = and i64 %235, %231
  %237 = or i64 %236, %233
  %238 = trunc i64 %237 to i32
  %239 = add nsw i32 %238, 1
  %240 = and <2 x i64> %219, %212
  %241 = xor <2 x i64> %240, %64
  %242 = xor <2 x i64> %240, %52
  %243 = xor <2 x i64> %58, %46
  %244 = and <2 x i64> %243, %212
  %245 = xor <2 x i64> %244, %58
  %246 = xor <2 x i64> %244, %46
  %247 = xor <2 x i64> %65, %53
  %248 = and <2 x i64> %247, %212
  %249 = xor <2 x i64> %248, %65
  %250 = xor <2 x i64> %248, %53
  %251 = xor <2 x i64> %59, %47
  %252 = and <2 x i64> %251, %212
  %253 = xor <2 x i64> %252, %59
  %254 = xor <2 x i64> %252, %47
  %255 = xor <2 x i64> %66, %54
  %256 = and <2 x i64> %255, %212
  %257 = xor <2 x i64> %256, %66
  %258 = xor <2 x i64> %256, %54
  %259 = xor <2 x i64> %60, %48
  %260 = and <2 x i64> %259, %212
  %261 = xor <2 x i64> %260, %60
  %262 = xor <2 x i64> %260, %48
  %263 = xor <2 x i64> %67, %55
  %264 = and <2 x i64> %263, %212
  %265 = xor <2 x i64> %264, %67
  %266 = xor <2 x i64> %264, %55
  %267 = xor <2 x i64> %61, %49
  %268 = and <2 x i64> %267, %212
  %269 = xor <2 x i64> %268, %61
  %270 = xor <2 x i64> %268, %49
  %271 = xor <2 x i64> %68, %56
  %272 = and <2 x i64> %271, %212
  %273 = xor <2 x i64> %272, %68
  %274 = xor <2 x i64> %272, %56
  %275 = xor <2 x i64> %62, %50
  %276 = and <2 x i64> %275, %212
  %277 = xor <2 x i64> %276, %62
  %278 = xor <2 x i64> %276, %50
  %279 = xor <2 x i64> %69, %57
  %280 = and <2 x i64> %279, %212
  %281 = xor <2 x i64> %280, %69
  %282 = xor <2 x i64> %280, %57
  %283 = xor <2 x i64> %63, %51
  %284 = and <2 x i64> %283, %212
  %285 = xor <2 x i64> %284, %63
  %286 = xor <2 x i64> %284, %51
  %287 = and <2 x i64> %245, %218
  %288 = xor <2 x i64> %241, %225
  %289 = and <2 x i64> %288, %287
  %290 = xor <2 x i64> %246, %287
  %291 = xor <2 x i64> %242, %287
  %292 = xor <2 x i64> %289, %290
  %293 = and <2 x i64> %292, %291
  %294 = xor <2 x i64> %289, %242
  %295 = or <2 x i64> %294, %290
  %296 = and <2 x i64> %253, %218
  %297 = xor <2 x i64> %249, %225
  %298 = and <2 x i64> %297, %296
  %299 = xor <2 x i64> %254, %296
  %300 = xor <2 x i64> %250, %296
  %301 = xor <2 x i64> %298, %299
  %302 = and <2 x i64> %301, %300
  %303 = xor <2 x i64> %298, %250
  %304 = or <2 x i64> %303, %299
  %305 = and <2 x i64> %261, %218
  %306 = xor <2 x i64> %257, %225
  %307 = and <2 x i64> %306, %305
  %308 = xor <2 x i64> %262, %305
  %309 = xor <2 x i64> %258, %305
  %310 = xor <2 x i64> %307, %308
  %311 = and <2 x i64> %310, %309
  %312 = xor <2 x i64> %307, %258
  %313 = or <2 x i64> %312, %308
  %314 = and <2 x i64> %269, %218
  %315 = xor <2 x i64> %265, %225
  %316 = and <2 x i64> %315, %314
  %317 = xor <2 x i64> %270, %314
  %318 = xor <2 x i64> %266, %314
  %319 = xor <2 x i64> %316, %317
  %320 = and <2 x i64> %319, %318
  %321 = xor <2 x i64> %316, %266
  %322 = or <2 x i64> %321, %317
  %323 = and <2 x i64> %277, %218
  %324 = xor <2 x i64> %273, %225
  %325 = and <2 x i64> %324, %323
  %326 = xor <2 x i64> %278, %323
  %327 = xor <2 x i64> %274, %323
  %328 = xor <2 x i64> %325, %326
  %329 = and <2 x i64> %328, %327
  %330 = xor <2 x i64> %325, %274
  %331 = or <2 x i64> %330, %326
  %332 = and <2 x i64> %285, %218
  %333 = xor <2 x i64> %281, %225
  %334 = and <2 x i64> %333, %332
  %335 = xor <2 x i64> %286, %332
  %336 = xor <2 x i64> %282, %332
  %337 = xor <2 x i64> %334, %335
  %338 = and <2 x i64> %337, %336
  %339 = xor <2 x i64> %334, %282
  %340 = or <2 x i64> %339, %335
  %341 = shl <2 x i64> %338, <i64 63, i64 63>
  %342 = lshr <2 x i64> %338, <i64 1, i64 1>
  %343 = bitcast <2 x i64> %341 to <16 x i8>
  %344 = shufflevector <16 x i8> %343, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %345 = bitcast <16 x i8> %344 to <2 x i64>
  %346 = or <2 x i64> %342, %345
  %347 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %343, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %348 = bitcast <16 x i8> %347 to <2 x i64>
  %349 = shl <2 x i64> %340, <i64 63, i64 63>
  %350 = lshr <2 x i64> %340, <i64 1, i64 1>
  %351 = bitcast <2 x i64> %349 to <16 x i8>
  %352 = shufflevector <16 x i8> %351, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %353 = bitcast <16 x i8> %352 to <2 x i64>
  %354 = or <2 x i64> %350, %353
  %355 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %351, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %356 = bitcast <16 x i8> %355 to <2 x i64>
  %357 = shl <2 x i64> %329, <i64 63, i64 63>
  %358 = lshr <2 x i64> %329, <i64 1, i64 1>
  %359 = bitcast <2 x i64> %357 to <16 x i8>
  %360 = shufflevector <16 x i8> %359, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %361 = bitcast <16 x i8> %360 to <2 x i64>
  %362 = or <2 x i64> %358, %361
  %363 = or <2 x i64> %362, %348
  %364 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %359, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %365 = bitcast <16 x i8> %364 to <2 x i64>
  %366 = shl <2 x i64> %331, <i64 63, i64 63>
  %367 = lshr <2 x i64> %331, <i64 1, i64 1>
  %368 = bitcast <2 x i64> %366 to <16 x i8>
  %369 = shufflevector <16 x i8> %368, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %370 = bitcast <16 x i8> %369 to <2 x i64>
  %371 = or <2 x i64> %367, %370
  %372 = or <2 x i64> %371, %356
  %373 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %368, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %374 = bitcast <16 x i8> %373 to <2 x i64>
  %375 = shl <2 x i64> %320, <i64 63, i64 63>
  %376 = lshr <2 x i64> %320, <i64 1, i64 1>
  %377 = bitcast <2 x i64> %375 to <16 x i8>
  %378 = shufflevector <16 x i8> %377, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %379 = bitcast <16 x i8> %378 to <2 x i64>
  %380 = or <2 x i64> %376, %365
  %381 = or <2 x i64> %380, %379
  %382 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %377, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %383 = bitcast <16 x i8> %382 to <2 x i64>
  %384 = shl <2 x i64> %322, <i64 63, i64 63>
  %385 = lshr <2 x i64> %322, <i64 1, i64 1>
  %386 = bitcast <2 x i64> %384 to <16 x i8>
  %387 = shufflevector <16 x i8> %386, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %388 = bitcast <16 x i8> %387 to <2 x i64>
  %389 = or <2 x i64> %385, %374
  %390 = or <2 x i64> %389, %388
  %391 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %386, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %392 = bitcast <16 x i8> %391 to <2 x i64>
  %393 = shl <2 x i64> %311, <i64 63, i64 63>
  %394 = lshr <2 x i64> %311, <i64 1, i64 1>
  %395 = bitcast <2 x i64> %393 to <16 x i8>
  %396 = shufflevector <16 x i8> %395, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %397 = bitcast <16 x i8> %396 to <2 x i64>
  %398 = or <2 x i64> %394, %383
  %399 = or <2 x i64> %398, %397
  %400 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %395, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %401 = bitcast <16 x i8> %400 to <2 x i64>
  %402 = shl <2 x i64> %313, <i64 63, i64 63>
  %403 = lshr <2 x i64> %313, <i64 1, i64 1>
  %404 = bitcast <2 x i64> %402 to <16 x i8>
  %405 = shufflevector <16 x i8> %404, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %406 = bitcast <16 x i8> %405 to <2 x i64>
  %407 = or <2 x i64> %403, %392
  %408 = or <2 x i64> %407, %406
  %409 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %404, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %410 = bitcast <16 x i8> %409 to <2 x i64>
  %411 = shl <2 x i64> %302, <i64 63, i64 63>
  %412 = lshr <2 x i64> %302, <i64 1, i64 1>
  %413 = bitcast <2 x i64> %411 to <16 x i8>
  %414 = shufflevector <16 x i8> %413, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %415 = bitcast <16 x i8> %414 to <2 x i64>
  %416 = or <2 x i64> %412, %401
  %417 = or <2 x i64> %416, %415
  %418 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %413, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %419 = bitcast <16 x i8> %418 to <2 x i64>
  %420 = shl <2 x i64> %304, <i64 63, i64 63>
  %421 = lshr <2 x i64> %304, <i64 1, i64 1>
  %422 = bitcast <2 x i64> %420 to <16 x i8>
  %423 = shufflevector <16 x i8> %422, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %424 = bitcast <16 x i8> %423 to <2 x i64>
  %425 = or <2 x i64> %421, %410
  %426 = or <2 x i64> %425, %424
  %427 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %422, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %428 = bitcast <16 x i8> %427 to <2 x i64>
  %429 = shl <2 x i64> %293, <i64 63, i64 63>
  %430 = lshr <2 x i64> %293, <i64 1, i64 1>
  %431 = bitcast <2 x i64> %429 to <16 x i8>
  %432 = shufflevector <16 x i8> %431, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %433 = bitcast <16 x i8> %432 to <2 x i64>
  %434 = or <2 x i64> %430, %419
  %435 = or <2 x i64> %434, %433
  %436 = shl <2 x i64> %295, <i64 63, i64 63>
  %437 = lshr <2 x i64> %295, <i64 1, i64 1>
  %438 = bitcast <2 x i64> %436 to <16 x i8>
  %439 = shufflevector <16 x i8> %438, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %440 = bitcast <16 x i8> %439 to <2 x i64>
  %441 = or <2 x i64> %437, %428
  %442 = or <2 x i64> %441, %440
  %443 = xor <2 x i64> %99, %76
  %444 = and <2 x i64> %443, %212
  %445 = xor <2 x i64> %444, %99
  %446 = xor <2 x i64> %444, %76
  %447 = xor <2 x i64> %107, %70
  %448 = and <2 x i64> %447, %212
  %449 = xor <2 x i64> %448, %107
  %450 = xor <2 x i64> %448, %70
  %451 = xor <2 x i64> %116, %77
  %452 = and <2 x i64> %451, %212
  %453 = xor <2 x i64> %452, %116
  %454 = xor <2 x i64> %452, %77
  %455 = xor <2 x i64> %125, %71
  %456 = and <2 x i64> %455, %212
  %457 = xor <2 x i64> %456, %125
  %458 = xor <2 x i64> %456, %71
  %459 = xor <2 x i64> %134, %78
  %460 = and <2 x i64> %459, %212
  %461 = xor <2 x i64> %460, %134
  %462 = xor <2 x i64> %460, %78
  %463 = xor <2 x i64> %143, %72
  %464 = and <2 x i64> %463, %212
  %465 = xor <2 x i64> %464, %143
  %466 = xor <2 x i64> %464, %72
  %467 = xor <2 x i64> %152, %79
  %468 = and <2 x i64> %467, %212
  %469 = xor <2 x i64> %468, %152
  %470 = xor <2 x i64> %468, %79
  %471 = xor <2 x i64> %161, %73
  %472 = and <2 x i64> %471, %212
  %473 = xor <2 x i64> %472, %161
  %474 = xor <2 x i64> %472, %73
  %475 = xor <2 x i64> %170, %80
  %476 = and <2 x i64> %475, %212
  %477 = xor <2 x i64> %476, %170
  %478 = xor <2 x i64> %476, %80
  %479 = xor <2 x i64> %179, %74
  %480 = and <2 x i64> %479, %212
  %481 = xor <2 x i64> %480, %179
  %482 = xor <2 x i64> %480, %74
  %483 = xor <2 x i64> %188, %81
  %484 = and <2 x i64> %483, %212
  %485 = xor <2 x i64> %484, %188
  %486 = xor <2 x i64> %484, %81
  %487 = xor <2 x i64> %195, %75
  %488 = and <2 x i64> %487, %212
  %489 = xor <2 x i64> %488, %195
  %490 = xor <2 x i64> %488, %75
  %491 = and <2 x i64> %449, %218
  %492 = xor <2 x i64> %445, %225
  %493 = and <2 x i64> %492, %491
  %494 = xor <2 x i64> %450, %491
  %495 = xor <2 x i64> %446, %491
  %496 = xor <2 x i64> %493, %494
  %497 = and <2 x i64> %496, %495
  %498 = xor <2 x i64> %493, %446
  %499 = or <2 x i64> %498, %494
  %500 = and <2 x i64> %457, %218
  %501 = xor <2 x i64> %453, %225
  %502 = and <2 x i64> %501, %500
  %503 = xor <2 x i64> %458, %500
  %504 = xor <2 x i64> %454, %500
  %505 = xor <2 x i64> %502, %503
  %506 = and <2 x i64> %505, %504
  %507 = xor <2 x i64> %502, %454
  %508 = or <2 x i64> %507, %503
  %509 = and <2 x i64> %465, %218
  %510 = xor <2 x i64> %461, %225
  %511 = and <2 x i64> %510, %509
  %512 = xor <2 x i64> %466, %509
  %513 = xor <2 x i64> %462, %509
  %514 = xor <2 x i64> %511, %512
  %515 = and <2 x i64> %514, %513
  %516 = xor <2 x i64> %511, %462
  %517 = or <2 x i64> %516, %512
  %518 = and <2 x i64> %473, %218
  %519 = xor <2 x i64> %469, %225
  %520 = and <2 x i64> %519, %518
  %521 = xor <2 x i64> %474, %518
  %522 = xor <2 x i64> %470, %518
  %523 = xor <2 x i64> %520, %521
  %524 = and <2 x i64> %523, %522
  %525 = xor <2 x i64> %520, %470
  %526 = or <2 x i64> %525, %521
  %527 = and <2 x i64> %481, %218
  %528 = xor <2 x i64> %477, %225
  %529 = and <2 x i64> %528, %527
  %530 = xor <2 x i64> %482, %527
  %531 = xor <2 x i64> %478, %527
  %532 = xor <2 x i64> %529, %530
  %533 = and <2 x i64> %532, %531
  %534 = xor <2 x i64> %529, %478
  %535 = or <2 x i64> %534, %530
  %536 = and <2 x i64> %489, %218
  %537 = xor <2 x i64> %485, %225
  %538 = and <2 x i64> %537, %536
  %539 = xor <2 x i64> %490, %536
  %540 = xor <2 x i64> %486, %536
  %541 = xor <2 x i64> %538, %539
  %542 = and <2 x i64> %541, %540
  %543 = xor <2 x i64> %538, %486
  %544 = or <2 x i64> %543, %539
  %545 = add nuw nsw i64 %45, 1
  %546 = icmp eq i64 %545, 1399
  br i1 %546, label %547, label %43

547:                                              ; preds = %43
  %548 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 2
  %549 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 4
  %550 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 6
  %551 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 8
  %552 = bitcast i64* %551 to <2 x i64>*
  store <2 x i64> %477, <2 x i64>* %552, align 8
  %553 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 10
  %554 = extractelement <2 x i64> %485, i32 0
  store i64 %554, i64* %553, align 8
  %555 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1
  %556 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 2
  %557 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 4
  %558 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 6
  %559 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 8
  %560 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 10
  %561 = extractelement <2 x i64> %489, i32 0
  %562 = bitcast <2 x i64> %241 to <8 x i16>
  %563 = extractelement <8 x i16> %562, i64 0
  %564 = bitcast <2 x i64> %245 to <8 x i16>
  %565 = extractelement <8 x i16> %564, i64 0
  %566 = and i16 %563, 1
  %567 = zext i16 %566 to i64
  %568 = sub nsw i64 0, %567
  %569 = and i16 %565, 1
  %570 = zext i16 %569 to i64
  %571 = sub nsw i64 0, %570
  %572 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 1, i32 0, i64 0
  %573 = insertelement <2 x i64> undef, i64 %571, i32 0
  %574 = shufflevector <2 x i64> %573, <2 x i64> undef, <2 x i32> zeroinitializer
  %575 = and <2 x i64> %449, %574
  %576 = bitcast i64* %572 to <2 x i64>*
  store <2 x i64> %575, <2 x i64>* %576, align 8
  %577 = insertelement <2 x i64> undef, i64 %568, i32 0
  %578 = shufflevector <2 x i64> %577, <2 x i64> undef, <2 x i32> zeroinitializer
  %579 = xor <2 x i64> %445, %578
  %580 = and <2 x i64> %579, %575
  %581 = bitcast %struct.poly3* %0 to <2 x i64>*
  store <2 x i64> %580, <2 x i64>* %581, align 8
  %582 = and <2 x i64> %457, %574
  %583 = bitcast i64* %556 to <2 x i64>*
  store <2 x i64> %582, <2 x i64>* %583, align 8
  %584 = xor <2 x i64> %453, %578
  %585 = and <2 x i64> %584, %582
  %586 = bitcast i64* %548 to <2 x i64>*
  store <2 x i64> %585, <2 x i64>* %586, align 8
  %587 = and <2 x i64> %465, %574
  %588 = bitcast i64* %557 to <2 x i64>*
  store <2 x i64> %587, <2 x i64>* %588, align 8
  %589 = xor <2 x i64> %461, %578
  %590 = and <2 x i64> %589, %587
  %591 = bitcast i64* %549 to <2 x i64>*
  store <2 x i64> %590, <2 x i64>* %591, align 8
  %592 = extractelement <2 x i64> %469, i32 0
  %593 = xor i64 %592, %568
  %594 = and <2 x i64> %473, %574
  %595 = extractelement <2 x i64> %594, i32 0
  %596 = and i64 %593, %595
  store i64 %596, i64* %550, align 8
  %597 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 7
  %598 = bitcast i64* %558 to <2 x i64>*
  store <2 x i64> %594, <2 x i64>* %598, align 8
  %599 = shufflevector <2 x i64> %469, <2 x i64> %477, <2 x i32> <i32 1, i32 2>
  %600 = xor <2 x i64> %599, %578
  %601 = and <2 x i64> %481, %574
  %602 = shufflevector <2 x i64> %594, <2 x i64> %601, <2 x i32> <i32 1, i32 2>
  %603 = and <2 x i64> %600, %602
  %604 = bitcast i64* %597 to <2 x i64>*
  store <2 x i64> %603, <2 x i64>* %604, align 8
  %605 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0, i32 0, i64 9
  %606 = load i64, i64* %605, align 8
  %607 = bitcast i64* %559 to <2 x i64>*
  store <2 x i64> %601, <2 x i64>* %607, align 8
  %608 = xor i64 %606, %568
  %609 = extractelement <2 x i64> %601, i32 1
  %610 = and i64 %609, %608
  store i64 %610, i64* %605, align 8
  %611 = and i64 %561, %571
  store i64 %611, i64* %560, align 8
  %612 = xor i64 %554, %568
  %613 = and i64 %612, %611
  store i64 %613, i64* %553, align 8
  tail call fastcc void @poly2_reverse_700(%struct.poly2* %555, %struct.poly2* %555) #5
  %614 = getelementptr inbounds %struct.poly3, %struct.poly3* %0, i64 0, i32 0
  tail call fastcc void @poly2_reverse_700(%struct.poly2* %614, %struct.poly2* %614) #5
  call void @llvm.lifetime.end.p0i8(i64 176, i8* nonnull %4) #5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @HRSS_generate_key(%struct.HRSS_public_key*, %struct.HRSS_private_key*, i8* nocapture readonly) local_unnamed_addr #2 {
  %4 = alloca %struct.poly2, align 8
  %5 = alloca %struct.poly2, align 16
  %6 = alloca %struct.poly, align 16
  %7 = alloca %struct.poly, align 16
  %8 = alloca [176 x <2 x i64>], align 16
  %9 = alloca [172 x <2 x i64>], align 16
  %10 = alloca %struct.poly, align 16
  %11 = alloca %struct.poly, align 16
  %12 = alloca %struct.poly, align 16
  %13 = alloca %struct.poly, align 16
  %14 = ptrtoint %struct.HRSS_public_key* %0 to i64
  %15 = add i64 %14, 15
  %16 = and i64 %15, -16
  %17 = ptrtoint %struct.HRSS_private_key* %1 to i64
  %18 = add i64 %17, 15
  %19 = and i64 %18, -16
  %20 = inttoptr i64 %19 to %struct.private_key*
  %21 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 3, i64 0
  %22 = getelementptr inbounds i8, i8* %2, i64 1400
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %21, i8* align 1 %22, i64 32, i1 false) #5
  %23 = bitcast %struct.poly* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %23) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %23, i8 -86, i64 1408, i1 false)
  %24 = bitcast %struct.poly* %10 to [704 x i16]*
  br label %25

25:                                               ; preds = %25, %3
  %26 = phi i64 [ 0, %3 ], [ %47, %25 ]
  %27 = getelementptr inbounds i8, i8* %2, i64 %26
  %28 = bitcast i8* %27 to <8 x i8>*
  %29 = load <8 x i8>, <8 x i8>* %28, align 1
  %30 = zext <8 x i8> %29 to <8 x i16>
  %31 = zext <8 x i8> %29 to <8 x i32>
  %32 = mul nuw nsw <8 x i32> %31, <i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845>
  %33 = lshr <8 x i32> %32, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %34 = trunc <8 x i32> %33 to <8 x i16>
  %35 = mul nsw <8 x i16> %34, <i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3>
  %36 = add nsw <8 x i16> %35, %30
  %37 = ashr <8 x i16> %36, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %38 = and <8 x i16> %37, %36
  %39 = add <8 x i16> %38, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %40 = and <8 x i16> %39, %36
  %41 = lshr <8 x i16> %40, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %42 = xor <8 x i16> %41, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %43 = add nsw <8 x i16> %42, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %44 = or <8 x i16> %43, %40
  %45 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %26
  %46 = bitcast i16* %45 to <8 x i16>*
  store <8 x i16> %44, <8 x i16>* %46, align 16
  %47 = add i64 %26, 8
  %48 = icmp eq i64 %47, 696
  br i1 %48, label %49, label %25, !llvm.loop !3

49:                                               ; preds = %25
  %50 = getelementptr inbounds i8, i8* %2, i64 696
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i16
  %53 = zext i8 %51 to i32
  %54 = mul nuw nsw i32 %53, 21845
  %55 = lshr i32 %54, 16
  %56 = trunc i32 %55 to i16
  %57 = mul nsw i16 %56, -3
  %58 = add nsw i16 %57, %52
  %59 = ashr i16 %58, 1
  %60 = and i16 %59, %58
  %61 = add i16 %60, -1
  %62 = and i16 %61, %58
  %63 = lshr i16 %62, 1
  %64 = xor i16 %63, 1
  %65 = add nsw i16 %64, -1
  %66 = or i16 %65, %62
  %67 = getelementptr inbounds %struct.poly, %struct.poly* %10, i64 0, i32 0, i32 0, i64 87
  %68 = bitcast <2 x i64>* %67 to i16*
  store i16 %66, i16* %68, align 16
  %69 = getelementptr inbounds i8, i8* %2, i64 697
  %70 = load i8, i8* %69, align 1
  %71 = zext i8 %70 to i16
  %72 = zext i8 %70 to i32
  %73 = mul nuw nsw i32 %72, 21845
  %74 = lshr i32 %73, 16
  %75 = trunc i32 %74 to i16
  %76 = mul nsw i16 %75, -3
  %77 = add nsw i16 %76, %71
  %78 = ashr i16 %77, 1
  %79 = and i16 %78, %77
  %80 = add i16 %79, -1
  %81 = and i16 %80, %77
  %82 = lshr i16 %81, 1
  %83 = xor i16 %82, 1
  %84 = add nsw i16 %83, -1
  %85 = or i16 %84, %81
  %86 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 697
  store i16 %85, i16* %86, align 2
  %87 = getelementptr inbounds i8, i8* %2, i64 698
  %88 = load i8, i8* %87, align 1
  %89 = zext i8 %88 to i16
  %90 = zext i8 %88 to i32
  %91 = mul nuw nsw i32 %90, 21845
  %92 = lshr i32 %91, 16
  %93 = trunc i32 %92 to i16
  %94 = mul nsw i16 %93, -3
  %95 = add nsw i16 %94, %89
  %96 = ashr i16 %95, 1
  %97 = and i16 %96, %95
  %98 = add i16 %97, -1
  %99 = and i16 %98, %95
  %100 = lshr i16 %99, 1
  %101 = xor i16 %100, 1
  %102 = add nsw i16 %101, -1
  %103 = or i16 %102, %99
  %104 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 698
  store i16 %103, i16* %104, align 4
  %105 = getelementptr inbounds i8, i8* %2, i64 699
  %106 = load i8, i8* %105, align 1
  %107 = zext i8 %106 to i16
  %108 = zext i8 %106 to i32
  %109 = mul nuw nsw i32 %108, 21845
  %110 = lshr i32 %109, 16
  %111 = trunc i32 %110 to i16
  %112 = mul nsw i16 %111, -3
  %113 = add nsw i16 %112, %107
  %114 = ashr i16 %113, 1
  %115 = and i16 %114, %113
  %116 = add i16 %115, -1
  %117 = and i16 %116, %113
  %118 = lshr i16 %117, 1
  %119 = xor i16 %118, 1
  %120 = add nsw i16 %119, -1
  %121 = or i16 %120, %117
  %122 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 699
  store i16 %121, i16* %122, align 2
  %123 = inttoptr i64 %16 to %struct.public_key*
  %124 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 700
  store i16 0, i16* %124, align 8
  %125 = bitcast %struct.poly* %10 to i16*
  %126 = load i16, i16* %125, align 16
  %127 = insertelement <8 x i16> undef, i16 %126, i32 7
  br label %128

128:                                              ; preds = %1485, %49
  %129 = phi i64 [ 0, %49 ], [ %1499, %1485 ]
  %130 = phi <8 x i16> [ %127, %49 ], [ %1492, %1485 ]
  %131 = phi <8 x i16> [ zeroinitializer, %49 ], [ %1497, %1485 ]
  %132 = phi <8 x i16> [ zeroinitializer, %49 ], [ %1498, %1485 ]
  %133 = or i64 %129, 1
  %134 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %133
  %135 = bitcast i16* %134 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 2
  %137 = getelementptr inbounds i16, i16* %134, i64 8
  %138 = bitcast i16* %137 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 2
  %140 = shufflevector <8 x i16> %130, <8 x i16> %136, <8 x i32> <i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %141 = shufflevector <8 x i16> %136, <8 x i16> %139, <8 x i32> <i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %142 = mul <8 x i16> %136, %140
  %143 = mul <8 x i16> %139, %141
  %144 = add <8 x i16> %142, %131
  %145 = add <8 x i16> %143, %132
  %146 = or i64 %129, 16
  %147 = icmp eq i64 %146, 688
  br i1 %147, label %148, label %1485, !llvm.loop !5

148:                                              ; preds = %128
  %149 = add <8 x i16> %145, %144
  %150 = shufflevector <8 x i16> %149, <8 x i16> undef, <8 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef>
  %151 = add <8 x i16> %149, %150
  %152 = shufflevector <8 x i16> %151, <8 x i16> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %153 = add <8 x i16> %151, %152
  %154 = extractelement <8 x i16> %139, i32 7
  %155 = shufflevector <8 x i16> %153, <8 x i16> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %156 = add <8 x i16> %153, %155
  %157 = extractelement <8 x i16> %156, i32 0
  %158 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 689
  %159 = load i16, i16* %158, align 2
  %160 = mul i16 %159, %154
  %161 = add i16 %160, %157
  %162 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 690
  %163 = load i16, i16* %162, align 4
  %164 = mul i16 %163, %159
  %165 = add i16 %164, %161
  %166 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 691
  %167 = load i16, i16* %166, align 2
  %168 = mul i16 %167, %163
  %169 = add i16 %168, %165
  %170 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 692
  %171 = load i16, i16* %170, align 8
  %172 = mul i16 %171, %167
  %173 = add i16 %172, %169
  %174 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 693
  %175 = load i16, i16* %174, align 2
  %176 = mul i16 %175, %171
  %177 = add i16 %176, %173
  %178 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 694
  %179 = load i16, i16* %178, align 4
  %180 = mul i16 %179, %175
  %181 = add i16 %180, %177
  %182 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 695
  %183 = load i16, i16* %182, align 2
  %184 = mul i16 %183, %179
  %185 = add i16 %184, %181
  %186 = getelementptr inbounds %struct.poly, %struct.poly* %10, i64 0, i32 0, i32 0, i64 87
  %187 = bitcast <2 x i64>* %186 to i16*
  %188 = load i16, i16* %187, align 16
  %189 = mul i16 %188, %183
  %190 = add i16 %189, %185
  %191 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 697
  %192 = load i16, i16* %191, align 2
  %193 = mul i16 %192, %188
  %194 = add i16 %193, %190
  %195 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 698
  %196 = load i16, i16* %195, align 4
  %197 = mul i16 %196, %192
  %198 = add i16 %197, %194
  %199 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 699
  %200 = load i16, i16* %199, align 2
  %201 = mul i16 %200, %196
  %202 = add i16 %201, %198
  %203 = ashr i16 %202, 15
  %204 = and i16 %203, 1
  %205 = xor i16 %204, 1
  %206 = or i16 %205, %203
  %207 = mul i16 %126, %206
  store i16 %207, i16* %125, align 16
  br label %208

208:                                              ; preds = %208, %148
  %209 = phi i64 [ 2, %148 ], [ %229, %208 ]
  %210 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %209
  %211 = load i16, i16* %210, align 4
  %212 = mul i16 %211, %206
  store i16 %212, i16* %210, align 4
  %213 = add nuw nsw i64 %209, 2
  %214 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %213
  %215 = load i16, i16* %214, align 4
  %216 = mul i16 %215, %206
  store i16 %216, i16* %214, align 4
  %217 = add nuw nsw i64 %209, 4
  %218 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %217
  %219 = load i16, i16* %218, align 4
  %220 = mul i16 %219, %206
  store i16 %220, i16* %218, align 4
  %221 = add nuw nsw i64 %209, 6
  %222 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %221
  %223 = load i16, i16* %222, align 4
  %224 = mul i16 %223, %206
  store i16 %224, i16* %222, align 4
  %225 = add nuw nsw i64 %209, 8
  %226 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %225
  %227 = load i16, i16* %226, align 4
  %228 = mul i16 %227, %206
  store i16 %228, i16* %226, align 4
  %229 = add nuw nsw i64 %209, 10
  %230 = icmp ult i64 %229, 701
  br i1 %230, label %208, label %231

231:                                              ; preds = %208
  %232 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 0, i32 0, i32 0, i64 0
  %233 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 0, i32 1, i32 0, i64 0
  br label %234

234:                                              ; preds = %270, %231
  %235 = phi i64 [ 0, %231 ], [ %276, %270 ]
  %236 = phi i64* [ %232, %231 ], [ %275, %270 ]
  %237 = phi i64* [ %233, %231 ], [ %274, %270 ]
  %238 = phi i32 [ 0, %231 ], [ %273, %270 ]
  %239 = phi i64 [ 0, %231 ], [ %272, %270 ]
  %240 = phi i64 [ 0, %231 ], [ %271, %270 ]
  %241 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %235
  %242 = load i16, i16* %241, align 2
  %243 = shl i16 %242, 3
  %244 = ashr exact i16 %243, 3
  %245 = sext i16 %244 to i32
  %246 = mul nsw i32 %245, 21845
  %247 = lshr i32 %246, 16
  %248 = trunc i32 %247 to i16
  %249 = mul i16 %248, -3
  %250 = add i16 %249, %244
  %251 = ashr i16 %250, 1
  %252 = and i16 %251, %250
  %253 = add i16 %252, -1
  %254 = and i16 %253, %250
  %255 = lshr i64 %240, 1
  %256 = and i16 %254, 2
  %257 = zext i16 %256 to i64
  %258 = shl nuw i64 %257, 62
  %259 = or i64 %258, %255
  %260 = lshr i64 %239, 1
  %261 = zext i16 %254 to i64
  %262 = shl i64 %261, 63
  %263 = or i64 %262, %260
  %264 = or i64 %263, %258
  %265 = add i32 %238, 1
  %266 = icmp eq i32 %265, 64
  br i1 %266, label %267, label %270

267:                                              ; preds = %234
  store i64 %259, i64* %236, align 8
  %268 = getelementptr inbounds i64, i64* %236, i64 1
  store i64 %264, i64* %237, align 8
  %269 = getelementptr inbounds i64, i64* %237, i64 1
  br label %270

270:                                              ; preds = %267, %234
  %271 = phi i64 [ 0, %267 ], [ %259, %234 ]
  %272 = phi i64 [ 0, %267 ], [ %264, %234 ]
  %273 = phi i32 [ 0, %267 ], [ %265, %234 ]
  %274 = phi i64* [ %269, %267 ], [ %237, %234 ]
  %275 = phi i64* [ %268, %267 ], [ %236, %234 ]
  %276 = add nuw nsw i64 %235, 1
  %277 = icmp eq i64 %276, 701
  br i1 %277, label %278, label %234

278:                                              ; preds = %270
  %279 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 0
  %280 = zext i32 %273 to i64
  %281 = sub nsw i64 64, %280
  %282 = lshr i64 %271, %281
  %283 = lshr i64 %272, %281
  store i64 %282, i64* %275, align 8
  store i64 %283, i64* %274, align 8
  %284 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 1
  tail call void @HRSS_poly3_invert(%struct.poly3* %284, %struct.poly3* %279)
  %285 = bitcast %struct.poly* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %285) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %285, i8 -86, i64 1408, i1 false)
  %286 = getelementptr inbounds i8, i8* %2, i64 700
  %287 = bitcast %struct.poly* %11 to [704 x i16]*
  br label %288

288:                                              ; preds = %288, %278
  %289 = phi i64 [ 0, %278 ], [ %310, %288 ]
  %290 = getelementptr inbounds i8, i8* %286, i64 %289
  %291 = bitcast i8* %290 to <8 x i8>*
  %292 = load <8 x i8>, <8 x i8>* %291, align 1
  %293 = zext <8 x i8> %292 to <8 x i16>
  %294 = zext <8 x i8> %292 to <8 x i32>
  %295 = mul nuw nsw <8 x i32> %294, <i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845>
  %296 = lshr <8 x i32> %295, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %297 = trunc <8 x i32> %296 to <8 x i16>
  %298 = mul nsw <8 x i16> %297, <i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3>
  %299 = add nsw <8 x i16> %298, %293
  %300 = ashr <8 x i16> %299, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %301 = and <8 x i16> %300, %299
  %302 = add <8 x i16> %301, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %303 = and <8 x i16> %302, %299
  %304 = lshr <8 x i16> %303, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %305 = xor <8 x i16> %304, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %306 = add nsw <8 x i16> %305, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %307 = or <8 x i16> %306, %303
  %308 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %289
  %309 = bitcast i16* %308 to <8 x i16>*
  store <8 x i16> %307, <8 x i16>* %309, align 16
  %310 = add i64 %289, 8
  %311 = icmp eq i64 %310, 696
  br i1 %311, label %312, label %288, !llvm.loop !6

312:                                              ; preds = %288
  %313 = getelementptr inbounds i8, i8* %2, i64 1396
  %314 = load i8, i8* %313, align 1
  %315 = zext i8 %314 to i16
  %316 = zext i8 %314 to i32
  %317 = mul nuw nsw i32 %316, 21845
  %318 = lshr i32 %317, 16
  %319 = trunc i32 %318 to i16
  %320 = mul nsw i16 %319, -3
  %321 = add nsw i16 %320, %315
  %322 = ashr i16 %321, 1
  %323 = and i16 %322, %321
  %324 = add i16 %323, -1
  %325 = and i16 %324, %321
  %326 = lshr i16 %325, 1
  %327 = xor i16 %326, 1
  %328 = add nsw i16 %327, -1
  %329 = or i16 %328, %325
  %330 = getelementptr inbounds %struct.poly, %struct.poly* %11, i64 0, i32 0, i32 0, i64 87
  %331 = bitcast <2 x i64>* %330 to i16*
  store i16 %329, i16* %331, align 16
  %332 = getelementptr inbounds i8, i8* %2, i64 1397
  %333 = load i8, i8* %332, align 1
  %334 = zext i8 %333 to i16
  %335 = zext i8 %333 to i32
  %336 = mul nuw nsw i32 %335, 21845
  %337 = lshr i32 %336, 16
  %338 = trunc i32 %337 to i16
  %339 = mul nsw i16 %338, -3
  %340 = add nsw i16 %339, %334
  %341 = ashr i16 %340, 1
  %342 = and i16 %341, %340
  %343 = add i16 %342, -1
  %344 = and i16 %343, %340
  %345 = lshr i16 %344, 1
  %346 = xor i16 %345, 1
  %347 = add nsw i16 %346, -1
  %348 = or i16 %347, %344
  %349 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 697
  store i16 %348, i16* %349, align 2
  %350 = getelementptr inbounds i8, i8* %2, i64 1398
  %351 = load i8, i8* %350, align 1
  %352 = zext i8 %351 to i16
  %353 = zext i8 %351 to i32
  %354 = mul nuw nsw i32 %353, 21845
  %355 = lshr i32 %354, 16
  %356 = trunc i32 %355 to i16
  %357 = mul nsw i16 %356, -3
  %358 = add nsw i16 %357, %352
  %359 = ashr i16 %358, 1
  %360 = and i16 %359, %358
  %361 = add i16 %360, -1
  %362 = and i16 %361, %358
  %363 = lshr i16 %362, 1
  %364 = xor i16 %363, 1
  %365 = add nsw i16 %364, -1
  %366 = or i16 %365, %362
  %367 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 698
  store i16 %366, i16* %367, align 4
  %368 = getelementptr inbounds i8, i8* %2, i64 1399
  %369 = load i8, i8* %368, align 1
  %370 = zext i8 %369 to i16
  %371 = zext i8 %369 to i32
  %372 = mul nuw nsw i32 %371, 21845
  %373 = lshr i32 %372, 16
  %374 = trunc i32 %373 to i16
  %375 = mul nsw i16 %374, -3
  %376 = add nsw i16 %375, %370
  %377 = ashr i16 %376, 1
  %378 = and i16 %377, %376
  %379 = add i16 %378, -1
  %380 = and i16 %379, %376
  %381 = lshr i16 %380, 1
  %382 = xor i16 %381, 1
  %383 = add nsw i16 %382, -1
  %384 = or i16 %383, %380
  %385 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 699
  store i16 %384, i16* %385, align 2
  %386 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 700
  store i16 0, i16* %386, align 8
  %387 = bitcast %struct.poly* %11 to i16*
  %388 = load i16, i16* %387, align 16
  %389 = insertelement <8 x i16> undef, i16 %388, i32 7
  br label %390

390:                                              ; preds = %1470, %312
  %391 = phi i64 [ 0, %312 ], [ %1484, %1470 ]
  %392 = phi <8 x i16> [ %389, %312 ], [ %1477, %1470 ]
  %393 = phi <8 x i16> [ zeroinitializer, %312 ], [ %1482, %1470 ]
  %394 = phi <8 x i16> [ zeroinitializer, %312 ], [ %1483, %1470 ]
  %395 = or i64 %391, 1
  %396 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %395
  %397 = bitcast i16* %396 to <8 x i16>*
  %398 = load <8 x i16>, <8 x i16>* %397, align 2
  %399 = getelementptr inbounds i16, i16* %396, i64 8
  %400 = bitcast i16* %399 to <8 x i16>*
  %401 = load <8 x i16>, <8 x i16>* %400, align 2
  %402 = shufflevector <8 x i16> %392, <8 x i16> %398, <8 x i32> <i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %403 = shufflevector <8 x i16> %398, <8 x i16> %401, <8 x i32> <i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %404 = mul <8 x i16> %398, %402
  %405 = mul <8 x i16> %401, %403
  %406 = add <8 x i16> %404, %393
  %407 = add <8 x i16> %405, %394
  %408 = or i64 %391, 16
  %409 = icmp eq i64 %408, 688
  br i1 %409, label %410, label %1470, !llvm.loop !7

410:                                              ; preds = %390
  %411 = add <8 x i16> %407, %406
  %412 = shufflevector <8 x i16> %411, <8 x i16> undef, <8 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef>
  %413 = add <8 x i16> %411, %412
  %414 = shufflevector <8 x i16> %413, <8 x i16> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %415 = add <8 x i16> %413, %414
  %416 = extractelement <8 x i16> %401, i32 7
  %417 = shufflevector <8 x i16> %415, <8 x i16> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %418 = add <8 x i16> %415, %417
  %419 = extractelement <8 x i16> %418, i32 0
  %420 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 689
  %421 = load i16, i16* %420, align 2
  %422 = mul i16 %421, %416
  %423 = add i16 %422, %419
  %424 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 690
  %425 = load i16, i16* %424, align 4
  %426 = mul i16 %425, %421
  %427 = add i16 %426, %423
  %428 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 691
  %429 = load i16, i16* %428, align 2
  %430 = mul i16 %429, %425
  %431 = add i16 %430, %427
  %432 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 692
  %433 = load i16, i16* %432, align 8
  %434 = mul i16 %433, %429
  %435 = add i16 %434, %431
  %436 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 693
  %437 = load i16, i16* %436, align 2
  %438 = mul i16 %437, %433
  %439 = add i16 %438, %435
  %440 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 694
  %441 = load i16, i16* %440, align 4
  %442 = mul i16 %441, %437
  %443 = add i16 %442, %439
  %444 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 695
  %445 = load i16, i16* %444, align 2
  %446 = mul i16 %445, %441
  %447 = add i16 %446, %443
  %448 = getelementptr inbounds %struct.poly, %struct.poly* %11, i64 0, i32 0, i32 0, i64 87
  %449 = bitcast <2 x i64>* %448 to i16*
  %450 = load i16, i16* %449, align 16
  %451 = mul i16 %450, %445
  %452 = add i16 %451, %447
  %453 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 697
  %454 = load i16, i16* %453, align 2
  %455 = mul i16 %454, %450
  %456 = add i16 %455, %452
  %457 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 698
  %458 = load i16, i16* %457, align 4
  %459 = mul i16 %458, %454
  %460 = add i16 %459, %456
  %461 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 699
  %462 = load i16, i16* %461, align 2
  %463 = mul i16 %462, %458
  %464 = add i16 %463, %460
  %465 = ashr i16 %464, 15
  %466 = and i16 %465, 1
  %467 = xor i16 %466, 1
  %468 = or i16 %467, %465
  %469 = mul i16 %388, %468
  store i16 %469, i16* %387, align 16
  br label %470

470:                                              ; preds = %470, %410
  %471 = phi i64 [ 2, %410 ], [ %491, %470 ]
  %472 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %471
  %473 = load i16, i16* %472, align 4
  %474 = mul i16 %473, %468
  store i16 %474, i16* %472, align 4
  %475 = add nuw nsw i64 %471, 2
  %476 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %475
  %477 = load i16, i16* %476, align 4
  %478 = mul i16 %477, %468
  store i16 %478, i16* %476, align 4
  %479 = add nuw nsw i64 %471, 4
  %480 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %479
  %481 = load i16, i16* %480, align 4
  %482 = mul i16 %481, %468
  store i16 %482, i16* %480, align 4
  %483 = add nuw nsw i64 %471, 6
  %484 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %483
  %485 = load i16, i16* %484, align 4
  %486 = mul i16 %485, %468
  store i16 %486, i16* %484, align 4
  %487 = add nuw nsw i64 %471, 8
  %488 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %487
  %489 = load i16, i16* %488, align 4
  %490 = mul i16 %489, %468
  store i16 %490, i16* %488, align 4
  %491 = add nuw nsw i64 %471, 10
  %492 = icmp ult i64 %491, 701
  br i1 %492, label %470, label %493

493:                                              ; preds = %470, %1458
  %494 = phi i64 [ %1469, %1458 ], [ 0, %470 ]
  %495 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %494
  %496 = bitcast i16* %495 to <8 x i16>*
  %497 = load <8 x i16>, <8 x i16>* %496, align 16
  %498 = getelementptr inbounds i16, i16* %495, i64 8
  %499 = bitcast i16* %498 to <8 x i16>*
  %500 = load <8 x i16>, <8 x i16>* %499, align 16
  %501 = mul <8 x i16> %497, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %502 = mul <8 x i16> %500, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %503 = bitcast i16* %495 to <8 x i16>*
  store <8 x i16> %501, <8 x i16>* %503, align 16
  %504 = bitcast i16* %498 to <8 x i16>*
  store <8 x i16> %502, <8 x i16>* %504, align 16
  %505 = or i64 %494, 16
  %506 = icmp eq i64 %505, 688
  br i1 %506, label %1347, label %1458, !llvm.loop !8

507:                                              ; preds = %507, %1347
  %508 = phi i16 [ %1388, %1347 ], [ %532, %507 ]
  %509 = phi i64 [ 700, %1347 ], [ %530, %507 ]
  %510 = add nsw i64 %509, -1
  %511 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %510
  %512 = load i16, i16* %511, align 2
  %513 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %509
  %514 = sub i16 %512, %508
  store i16 %514, i16* %513, align 2
  %515 = add nsw i64 %509, -2
  %516 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %515
  %517 = load i16, i16* %516, align 2
  %518 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %510
  %519 = sub i16 %517, %512
  store i16 %519, i16* %518, align 2
  %520 = add nsw i64 %509, -3
  %521 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %520
  %522 = load i16, i16* %521, align 2
  %523 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %515
  %524 = sub i16 %522, %517
  store i16 %524, i16* %523, align 2
  %525 = add nsw i64 %509, -4
  %526 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %525
  %527 = load i16, i16* %526, align 2
  %528 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %520
  %529 = sub i16 %527, %522
  store i16 %529, i16* %528, align 2
  %530 = add nsw i64 %509, -5
  %531 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %530
  %532 = load i16, i16* %531, align 2
  %533 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %525
  %534 = sub i16 %532, %527
  store i16 %534, i16* %533, align 2
  %535 = icmp eq i64 %530, 0
  br i1 %535, label %536, label %507

536:                                              ; preds = %507
  %537 = load i16, i16* %387, align 16
  %538 = sub i16 %1388, %537
  store i16 %538, i16* %387, align 16
  %539 = bitcast %struct.poly* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %539) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %539, i8 -86, i64 1408, i1 false)
  %540 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 701
  %541 = bitcast i16* %540 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %541, i8 0, i64 6, i1 false) #5
  %542 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 701
  %543 = bitcast i16* %542 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %543, i8 0, i64 6, i1 false) #5
  %544 = bitcast [176 x <2 x i64>]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %544, i8 -86, i64 2816, i1 false) #5
  %545 = bitcast [172 x <2 x i64>]* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %545, i8 -86, i64 2752, i1 false) #5
  %546 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 0
  %547 = getelementptr inbounds [172 x <2 x i64>], [172 x <2 x i64>]* %9, i64 0, i64 0
  %548 = getelementptr inbounds %struct.poly, %struct.poly* %10, i64 0, i32 0, i32 0, i64 0
  %549 = getelementptr inbounds %struct.poly, %struct.poly* %11, i64 0, i32 0, i32 0, i64 0
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %546, <2 x i64>* nonnull %547, <2 x i64>* nonnull %548, <2 x i64>* nonnull %549, i64 88) #5
  %550 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 87
  %551 = bitcast <2 x i64>* %550 to <16 x i8>*
  %552 = load <16 x i8>, <16 x i8>* %551, align 16
  br label %553

553:                                              ; preds = %553, %536
  %554 = phi <16 x i8> [ %552, %536 ], [ %574, %553 ]
  %555 = phi i64 [ 0, %536 ], [ %585, %553 ]
  %556 = add nuw nsw i64 %555, 88
  %557 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %556
  %558 = bitcast <2 x i64>* %557 to <16 x i8>*
  %559 = load <16 x i8>, <16 x i8>* %558, align 16
  %560 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %555
  %561 = bitcast <2 x i64>* %560 to <8 x i16>*
  %562 = load <8 x i16>, <8 x i16>* %561, align 16
  %563 = shufflevector <16 x i8> %554, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %564 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %559, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %565 = or <16 x i8> %564, %563
  %566 = bitcast <16 x i8> %565 to <8 x i16>
  %567 = add <8 x i16> %562, %566
  %568 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 %555
  %569 = bitcast <2 x i64>* %568 to <8 x i16>*
  store <8 x i16> %567, <8 x i16>* %569, align 16
  %570 = or i64 %555, 1
  %571 = add nuw nsw i64 %555, 89
  %572 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %571
  %573 = bitcast <2 x i64>* %572 to <16 x i8>*
  %574 = load <16 x i8>, <16 x i8>* %573, align 16
  %575 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %570
  %576 = bitcast <2 x i64>* %575 to <8 x i16>*
  %577 = load <8 x i16>, <8 x i16>* %576, align 16
  %578 = shufflevector <16 x i8> %559, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %579 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %574, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %580 = or <16 x i8> %579, %578
  %581 = bitcast <16 x i8> %580 to <8 x i16>
  %582 = add <8 x i16> %577, %581
  %583 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 %570
  %584 = bitcast <2 x i64>* %583 to <8 x i16>*
  store <8 x i16> %582, <8 x i16>* %584, align 16
  %585 = add nuw nsw i64 %555, 2
  %586 = icmp eq i64 %585, 88
  br i1 %586, label %587, label %553

587:                                              ; preds = %553
  %588 = bitcast %struct.poly* %12 to [704 x i16]*
  %589 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 701
  %590 = bitcast i16* %589 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %590, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %544) #5
  %591 = bitcast %struct.poly* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %591) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %591, i8 -86, i64 1408, i1 false)
  %592 = bitcast %struct.poly* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %592) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %592, i8 -86, i64 1408, i1 false) #5
  %593 = bitcast %struct.poly* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %593) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %593, i8 -86, i64 1408, i1 false) #5
  %594 = bitcast %struct.poly* %6 to [704 x i16]*
  br label %595

595:                                              ; preds = %1444, %587
  %596 = phi i64 [ 0, %587 ], [ %1457, %1444 ]
  %597 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 %596
  %598 = bitcast i16* %597 to <8 x i16>*
  %599 = load <8 x i16>, <8 x i16>* %598, align 16
  %600 = getelementptr inbounds i16, i16* %597, i64 8
  %601 = bitcast i16* %600 to <8 x i16>*
  %602 = load <8 x i16>, <8 x i16>* %601, align 16
  %603 = sub <8 x i16> zeroinitializer, %599
  %604 = sub <8 x i16> zeroinitializer, %602
  %605 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 %596
  %606 = bitcast i16* %605 to <8 x i16>*
  store <8 x i16> %603, <8 x i16>* %606, align 16
  %607 = getelementptr inbounds i16, i16* %605, i64 8
  %608 = bitcast i16* %607 to <8 x i16>*
  store <8 x i16> %604, <8 x i16>* %608, align 16
  %609 = or i64 %596, 16
  %610 = icmp eq i64 %609, 688
  br i1 %610, label %945, label %1444, !llvm.loop !9

611:                                              ; preds = %1439, %945
  %612 = phi i64 [ 0, %945 ], [ %1443, %1439 ]
  %613 = phi i64 [ 0, %945 ], [ %1442, %1439 ]
  %614 = phi i32 [ 0, %945 ], [ %1441, %1439 ]
  %615 = phi i64* [ %1004, %945 ], [ %1440, %1439 ]
  %616 = lshr i64 %613, 1
  %617 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 %612
  %618 = load i16, i16* %617, align 4
  %619 = zext i16 %618 to i64
  %620 = shl i64 %619, 63
  %621 = or i64 %620, %616
  %622 = add i32 %614, 1
  %623 = icmp eq i32 %622, 64
  br i1 %623, label %624, label %626

624:                                              ; preds = %611
  store i64 %621, i64* %615, align 8
  %625 = getelementptr inbounds i64, i64* %615, i64 1
  br label %626

626:                                              ; preds = %624, %611
  %627 = phi i64* [ %625, %624 ], [ %615, %611 ]
  %628 = phi i32 [ 0, %624 ], [ %622, %611 ]
  %629 = phi i64 [ 0, %624 ], [ %621, %611 ]
  %630 = or i64 %612, 1
  %631 = icmp eq i64 %630, 701
  br i1 %631, label %632, label %1428

632:                                              ; preds = %626
  %633 = zext i32 %628 to i64
  %634 = sub nsw i64 64, %633
  %635 = lshr i64 %629, %634
  store i64 %635, i64* %627, align 8
  %636 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 10
  %637 = load i64, i64* %636, align 16
  %638 = lshr i64 %637, 60
  %639 = and i64 %638, 1
  %640 = sub nsw i64 0, %639
  %641 = bitcast %struct.poly2* %5 to <2 x i64>*
  %642 = load <2 x i64>, <2 x i64>* %641, align 16
  %643 = insertelement <2 x i64> undef, i64 %640, i32 0
  %644 = shufflevector <2 x i64> %643, <2 x i64> undef, <2 x i32> zeroinitializer
  %645 = xor <2 x i64> %642, %644
  %646 = bitcast %struct.poly2* %5 to <2 x i64>*
  store <2 x i64> %645, <2 x i64>* %646, align 16
  %647 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 2
  %648 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 3
  %649 = bitcast i64* %647 to <2 x i64>*
  %650 = load <2 x i64>, <2 x i64>* %649, align 16
  %651 = xor <2 x i64> %650, %644
  %652 = bitcast i64* %647 to <2 x i64>*
  store <2 x i64> %651, <2 x i64>* %652, align 16
  %653 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 4
  %654 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 5
  %655 = bitcast i64* %653 to <2 x i64>*
  %656 = load <2 x i64>, <2 x i64>* %655, align 16
  %657 = xor <2 x i64> %656, %644
  %658 = bitcast i64* %653 to <2 x i64>*
  store <2 x i64> %657, <2 x i64>* %658, align 16
  %659 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 6
  %660 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 7
  %661 = bitcast i64* %659 to <2 x i64>*
  %662 = load <2 x i64>, <2 x i64>* %661, align 16
  %663 = xor <2 x i64> %662, %644
  %664 = bitcast i64* %659 to <2 x i64>*
  store <2 x i64> %663, <2 x i64>* %664, align 16
  %665 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 8
  %666 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 9
  %667 = bitcast i64* %665 to <2 x i64>*
  %668 = load <2 x i64>, <2 x i64>* %667, align 16
  %669 = xor <2 x i64> %668, %644
  %670 = bitcast i64* %665 to <2 x i64>*
  store <2 x i64> %669, <2 x i64>* %670, align 16
  %671 = xor i64 %637, %640
  %672 = and i64 %671, 1152921504606846975
  store i64 %672, i64* %636, align 16
  call fastcc void @poly2_reverse_700(%struct.poly2* nonnull %5, %struct.poly2* nonnull %5) #5
  %673 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 2
  %674 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 3
  %675 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 4
  %676 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 5
  %677 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 6
  %678 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 7
  %679 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 8
  %680 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 9
  %681 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 10
  %682 = bitcast i64* %673 to <2 x i64>*
  %683 = load <2 x i64>, <2 x i64>* %682, align 8
  %684 = bitcast i64* %675 to <2 x i64>*
  %685 = load <2 x i64>, <2 x i64>* %684, align 8
  %686 = bitcast i64* %677 to <2 x i64>*
  %687 = load <2 x i64>, <2 x i64>* %686, align 8
  %688 = bitcast i64* %679 to <2 x i64>*
  %689 = load <2 x i64>, <2 x i64>* %688, align 8
  %690 = load i64, i64* %681, align 8
  %691 = bitcast %struct.poly2* %5 to <2 x i64>*
  %692 = load <2 x i64>, <2 x i64>* %691, align 16
  %693 = load i64, i64* %647, align 16
  %694 = bitcast i64* %648 to <2 x i64>*
  %695 = load <2 x i64>, <2 x i64>* %694, align 8
  %696 = bitcast i64* %654 to <2 x i64>*
  %697 = load <2 x i64>, <2 x i64>* %696, align 8
  %698 = bitcast i64* %660 to <2 x i64>*
  %699 = load <2 x i64>, <2 x i64>* %698, align 8
  %700 = bitcast i64* %666 to <2 x i64>*
  %701 = load <2 x i64>, <2 x i64>* %700, align 8
  br label %737

702:                                              ; preds = %737
  %703 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 0
  %704 = getelementptr inbounds %struct.poly2, %struct.poly2* %4, i64 0, i32 0, i64 1
  store i64 %883, i64* %703, align 8
  %705 = bitcast i64* %704 to <2 x i64>*
  store <2 x i64> %887, <2 x i64>* %705, align 8
  %706 = bitcast i64* %674 to <2 x i64>*
  store <2 x i64> %891, <2 x i64>* %706, align 8
  %707 = bitcast i64* %676 to <2 x i64>*
  store <2 x i64> %895, <2 x i64>* %707, align 8
  %708 = bitcast i64* %678 to <2 x i64>*
  store <2 x i64> %899, <2 x i64>* %708, align 8
  %709 = bitcast i64* %680 to <2 x i64>*
  store <2 x i64> %903, <2 x i64>* %709, align 8
  %710 = bitcast %struct.poly2* %5 to <2 x i64>*
  store <2 x i64> %880, <2 x i64>* %710, align 16
  %711 = bitcast i64* %647 to <2 x i64>*
  store <2 x i64> %874, <2 x i64>* %711, align 16
  %712 = bitcast i64* %653 to <2 x i64>*
  store <2 x i64> %869, <2 x i64>* %712, align 16
  %713 = bitcast i64* %659 to <2 x i64>*
  store <2 x i64> %865, <2 x i64>* %713, align 16
  %714 = bitcast i64* %665 to <2 x i64>*
  store <2 x i64> %861, <2 x i64>* %714, align 16
  store i64 %857, i64* %636, align 16
  call fastcc void @poly2_reverse_700(%struct.poly2* nonnull %4, %struct.poly2* nonnull %4) #5
  %715 = load i64, i64* %703, align 8
  %716 = bitcast %struct.poly* %13 to [704 x i16]*
  br label %717

717:                                              ; preds = %1423, %702
  %718 = phi i64 [ 0, %702 ], [ %1427, %1423 ]
  %719 = phi i64 [ %715, %702 ], [ %1426, %1423 ]
  %720 = phi i32 [ 0, %702 ], [ %1425, %1423 ]
  %721 = phi i64* [ %703, %702 ], [ %1424, %1423 ]
  %722 = trunc i64 %719 to i16
  %723 = and i16 %722, 1
  %724 = getelementptr inbounds [704 x i16], [704 x i16]* %716, i64 0, i64 %718
  store i16 %723, i16* %724, align 4
  %725 = lshr i64 %719, 1
  %726 = add i32 %720, 1
  %727 = icmp eq i32 %726, 64
  br i1 %727, label %728, label %731

728:                                              ; preds = %717
  %729 = getelementptr inbounds i64, i64* %721, i64 1
  %730 = load i64, i64* %729, align 8
  br label %731

731:                                              ; preds = %728, %717
  %732 = phi i64* [ %729, %728 ], [ %721, %717 ]
  %733 = phi i32 [ 0, %728 ], [ %726, %717 ]
  %734 = phi i64 [ %730, %728 ], [ %725, %717 ]
  %735 = or i64 %718, 1
  %736 = icmp eq i64 %735, 701
  br i1 %736, label %933, label %1413

737:                                              ; preds = %737, %632
  %738 = phi i64 [ %693, %632 ], [ %927, %737 ]
  %739 = phi i64 [ %690, %632 ], [ %925, %737 ]
  %740 = phi i32 [ 1, %632 ], [ %815, %737 ]
  %741 = phi i64 [ 0, %632 ], [ %917, %737 ]
  %742 = phi i64 [ -1, %632 ], [ %824, %737 ]
  %743 = phi i64 [ 1, %632 ], [ %906, %737 ]
  %744 = phi <2 x i64> [ zeroinitializer, %632 ], [ %908, %737 ]
  %745 = phi <2 x i64> [ zeroinitializer, %632 ], [ %920, %737 ]
  %746 = phi <2 x i64> [ zeroinitializer, %632 ], [ %910, %737 ]
  %747 = phi <2 x i64> [ %683, %632 ], [ %921, %737 ]
  %748 = phi <2 x i64> [ zeroinitializer, %632 ], [ %912, %737 ]
  %749 = phi <2 x i64> [ %685, %632 ], [ %922, %737 ]
  %750 = phi <2 x i64> [ zeroinitializer, %632 ], [ %914, %737 ]
  %751 = phi <2 x i64> [ %687, %632 ], [ %923, %737 ]
  %752 = phi <2 x i64> [ zeroinitializer, %632 ], [ %916, %737 ]
  %753 = phi <2 x i64> [ %689, %632 ], [ %924, %737 ]
  %754 = phi <2 x i64> [ <i64 -1, i64 -1>, %632 ], [ %820, %737 ]
  %755 = phi <2 x i64> [ %692, %632 ], [ %880, %737 ]
  %756 = phi <2 x i64> [ <i64 -1, i64 -1>, %632 ], [ %828, %737 ]
  %757 = phi <2 x i64> [ %695, %632 ], [ %926, %737 ]
  %758 = phi <2 x i64> [ <i64 -1, i64 -1>, %632 ], [ %832, %737 ]
  %759 = phi <2 x i64> [ %697, %632 ], [ %928, %737 ]
  %760 = phi <2 x i64> [ <i64 -1, i64 -1>, %632 ], [ %836, %737 ]
  %761 = phi <2 x i64> [ %699, %632 ], [ %929, %737 ]
  %762 = phi <2 x i64> [ <i64 -1, i64 2305843009213693951>, %632 ], [ %840, %737 ]
  %763 = phi <2 x i64> [ %701, %632 ], [ %932, %737 ]
  %764 = extractelement <2 x i64> %745, i32 0
  %765 = shl i64 %764, 1
  %766 = lshr <2 x i64> %745, <i64 63, i64 63>
  %767 = shufflevector <2 x i64> %745, <2 x i64> %747, <2 x i32> <i32 1, i32 2>
  %768 = shl <2 x i64> %767, <i64 1, i64 1>
  %769 = or <2 x i64> %766, %768
  %770 = lshr <2 x i64> %747, <i64 63, i64 63>
  %771 = shufflevector <2 x i64> %747, <2 x i64> %749, <2 x i32> <i32 1, i32 2>
  %772 = shl <2 x i64> %771, <i64 1, i64 1>
  %773 = or <2 x i64> %770, %772
  %774 = lshr <2 x i64> %749, <i64 63, i64 63>
  %775 = shufflevector <2 x i64> %749, <2 x i64> %751, <2 x i32> <i32 1, i32 2>
  %776 = shl <2 x i64> %775, <i64 1, i64 1>
  %777 = or <2 x i64> %774, %776
  %778 = lshr <2 x i64> %751, <i64 63, i64 63>
  %779 = shufflevector <2 x i64> %751, <2 x i64> %753, <2 x i32> <i32 1, i32 2>
  %780 = shl <2 x i64> %779, <i64 1, i64 1>
  %781 = or <2 x i64> %778, %780
  %782 = lshr <2 x i64> %753, <i64 63, i64 63>
  %783 = extractelement <2 x i64> %753, i32 1
  %784 = insertelement <2 x i64> undef, i64 %783, i32 0
  %785 = insertelement <2 x i64> %784, i64 %739, i32 1
  %786 = shl <2 x i64> %785, <i64 1, i64 1>
  %787 = or <2 x i64> %782, %786
  %788 = lshr i32 %740, 31
  %789 = zext i32 %788 to i64
  %790 = add nsw i64 %789, -1
  %791 = sext i32 %740 to i64
  %792 = xor i64 %791, -9223372036854775808
  %793 = add nsw i64 %791, -1
  %794 = and i64 %793, %792
  %795 = ashr i64 %794, 63
  %796 = xor i64 %795, -1
  %797 = extractelement <2 x i64> %755, i32 0
  %798 = and i64 %797, 1
  %799 = sub nsw i64 0, %798
  %800 = and i64 %790, %799
  %801 = and i64 %800, %796
  %802 = extractelement <2 x i64> %754, i32 0
  %803 = and i64 %802, %798
  %804 = sub nsw i64 0, %803
  %805 = sub nsw i32 0, %740
  %806 = zext i32 %805 to i64
  %807 = zext i32 %740 to i64
  %808 = call i64 asm "", "=r,0,~{dirflag},~{fpsr},~{flags}"(i64 %801) #6, !srcloc !2
  %809 = and i64 %808, %806
  %810 = xor i64 %801, -1
  %811 = call i64 asm "", "=r,0,~{dirflag},~{fpsr},~{flags}"(i64 %810) #6, !srcloc !2
  %812 = and i64 %811, %807
  %813 = or i64 %812, %809
  %814 = trunc i64 %813 to i32
  %815 = add nsw i32 %814, 1
  %816 = xor <2 x i64> %754, %755
  %817 = insertelement <2 x i64> undef, i64 %801, i32 0
  %818 = shufflevector <2 x i64> %817, <2 x i64> undef, <2 x i32> zeroinitializer
  %819 = and <2 x i64> %816, %818
  %820 = xor <2 x i64> %819, %754
  %821 = xor <2 x i64> %819, %755
  %822 = xor i64 %742, %738
  %823 = and i64 %822, %801
  %824 = xor i64 %823, %742
  %825 = xor i64 %823, %738
  %826 = xor <2 x i64> %756, %757
  %827 = and <2 x i64> %826, %818
  %828 = xor <2 x i64> %827, %756
  %829 = xor <2 x i64> %827, %757
  %830 = xor <2 x i64> %758, %759
  %831 = and <2 x i64> %830, %818
  %832 = xor <2 x i64> %831, %758
  %833 = xor <2 x i64> %831, %759
  %834 = xor <2 x i64> %760, %761
  %835 = and <2 x i64> %834, %818
  %836 = xor <2 x i64> %835, %760
  %837 = xor <2 x i64> %835, %761
  %838 = xor <2 x i64> %762, %763
  %839 = and <2 x i64> %818, %838
  %840 = xor <2 x i64> %839, %762
  %841 = xor <2 x i64> %839, %763
  %842 = insertelement <2 x i64> undef, i64 %804, i32 0
  %843 = shufflevector <2 x i64> %842, <2 x i64> undef, <2 x i32> zeroinitializer
  %844 = and <2 x i64> %820, %843
  %845 = xor <2 x i64> %821, %844
  %846 = and i64 %824, %804
  %847 = xor i64 %825, %846
  %848 = and <2 x i64> %828, %843
  %849 = xor <2 x i64> %829, %848
  %850 = and <2 x i64> %832, %843
  %851 = xor <2 x i64> %833, %850
  %852 = and <2 x i64> %836, %843
  %853 = xor <2 x i64> %837, %852
  %854 = and <2 x i64> %840, %843
  %855 = xor <2 x i64> %841, %854
  %856 = extractelement <2 x i64> %855, i32 1
  %857 = lshr i64 %856, 1
  %858 = shufflevector <2 x i64> %853, <2 x i64> %855, <2 x i32> <i32 1, i32 2>
  %859 = lshr <2 x i64> %858, <i64 1, i64 1>
  %860 = shl <2 x i64> %855, <i64 63, i64 63>
  %861 = or <2 x i64> %860, %859
  %862 = shufflevector <2 x i64> %851, <2 x i64> %853, <2 x i32> <i32 1, i32 2>
  %863 = lshr <2 x i64> %862, <i64 1, i64 1>
  %864 = shl <2 x i64> %853, <i64 63, i64 63>
  %865 = or <2 x i64> %864, %863
  %866 = shufflevector <2 x i64> %849, <2 x i64> %851, <2 x i32> <i32 1, i32 2>
  %867 = lshr <2 x i64> %866, <i64 1, i64 1>
  %868 = shl <2 x i64> %851, <i64 63, i64 63>
  %869 = or <2 x i64> %868, %867
  %870 = insertelement <2 x i64> undef, i64 %847, i32 0
  %871 = shufflevector <2 x i64> %870, <2 x i64> %849, <2 x i32> <i32 0, i32 2>
  %872 = lshr <2 x i64> %871, <i64 1, i64 1>
  %873 = shl <2 x i64> %849, <i64 63, i64 63>
  %874 = or <2 x i64> %873, %872
  %875 = lshr <2 x i64> %845, <i64 1, i64 1>
  %876 = extractelement <2 x i64> %845, i32 1
  %877 = insertelement <2 x i64> undef, i64 %876, i32 0
  %878 = insertelement <2 x i64> %877, i64 %847, i32 1
  %879 = shl <2 x i64> %878, <i64 63, i64 63>
  %880 = or <2 x i64> %875, %879
  %881 = xor i64 %743, %765
  %882 = and i64 %881, %801
  %883 = xor i64 %882, %765
  %884 = xor i64 %882, %743
  %885 = xor <2 x i64> %744, %769
  %886 = and <2 x i64> %885, %818
  %887 = xor <2 x i64> %886, %769
  %888 = xor <2 x i64> %886, %744
  %889 = xor <2 x i64> %746, %773
  %890 = and <2 x i64> %889, %818
  %891 = xor <2 x i64> %890, %773
  %892 = xor <2 x i64> %890, %746
  %893 = xor <2 x i64> %748, %777
  %894 = and <2 x i64> %893, %818
  %895 = xor <2 x i64> %894, %777
  %896 = xor <2 x i64> %894, %748
  %897 = xor <2 x i64> %750, %781
  %898 = and <2 x i64> %897, %818
  %899 = xor <2 x i64> %898, %781
  %900 = xor <2 x i64> %898, %750
  %901 = xor <2 x i64> %752, %787
  %902 = and <2 x i64> %901, %818
  %903 = xor <2 x i64> %902, %787
  %904 = xor <2 x i64> %902, %752
  %905 = and i64 %883, %804
  %906 = xor i64 %884, %905
  %907 = and <2 x i64> %887, %843
  %908 = xor <2 x i64> %888, %907
  %909 = and <2 x i64> %891, %843
  %910 = xor <2 x i64> %892, %909
  %911 = and <2 x i64> %895, %843
  %912 = xor <2 x i64> %896, %911
  %913 = and <2 x i64> %899, %843
  %914 = xor <2 x i64> %900, %913
  %915 = and <2 x i64> %903, %843
  %916 = xor <2 x i64> %904, %915
  %917 = add nuw nsw i64 %741, 1
  %918 = icmp eq i64 %917, 1399
  %919 = insertelement <2 x i64> undef, i64 %883, i32 0
  %920 = shufflevector <2 x i64> %919, <2 x i64> %887, <2 x i32> <i32 0, i32 2>
  %921 = shufflevector <2 x i64> %887, <2 x i64> %891, <2 x i32> <i32 1, i32 2>
  %922 = shufflevector <2 x i64> %891, <2 x i64> %895, <2 x i32> <i32 1, i32 2>
  %923 = shufflevector <2 x i64> %895, <2 x i64> %899, <2 x i32> <i32 1, i32 2>
  %924 = shufflevector <2 x i64> %899, <2 x i64> %903, <2 x i32> <i32 1, i32 2>
  %925 = extractelement <2 x i64> %903, i32 1
  %926 = shufflevector <2 x i64> %874, <2 x i64> %869, <2 x i32> <i32 1, i32 2>
  %927 = extractelement <2 x i64> %874, i32 0
  %928 = shufflevector <2 x i64> %869, <2 x i64> %865, <2 x i32> <i32 1, i32 2>
  %929 = shufflevector <2 x i64> %865, <2 x i64> %861, <2 x i32> <i32 1, i32 2>
  %930 = extractelement <2 x i64> %861, i32 1
  %931 = insertelement <2 x i64> undef, i64 %930, i32 0
  %932 = insertelement <2 x i64> %931, i64 %857, i32 1
  br i1 %918, label %702, label %737

933:                                              ; preds = %731
  call void @llvm.lifetime.end.p0i8(i64 88, i8* nonnull %1003) #5
  call void @llvm.lifetime.end.p0i8(i64 88, i8* nonnull %1002) #5
  %934 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 701
  %935 = bitcast i16* %934 to i8*
  %936 = getelementptr inbounds [704 x i16], [704 x i16]* %716, i64 0, i64 701
  %937 = bitcast i16* %936 to i8*
  %938 = getelementptr inbounds %struct.poly, %struct.poly* %6, i64 0, i32 0, i32 0, i64 0
  %939 = getelementptr inbounds %struct.poly, %struct.poly* %13, i64 0, i32 0, i32 0, i64 0
  %940 = bitcast %struct.poly* %7 to [704 x i16]*
  %941 = getelementptr inbounds [704 x i16], [704 x i16]* %940, i64 0, i64 701
  %942 = bitcast i16* %941 to i8*
  %943 = bitcast %struct.poly* %7 to i16*
  %944 = getelementptr inbounds %struct.poly, %struct.poly* %7, i64 0, i32 0, i32 0, i64 0
  br label %1005

945:                                              ; preds = %595
  %946 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 86
  %947 = bitcast <2 x i64>* %946 to i16*
  %948 = load i16, i16* %947, align 16
  %949 = sub i16 0, %948
  %950 = getelementptr inbounds %struct.poly, %struct.poly* %6, i64 0, i32 0, i32 0, i64 86
  %951 = bitcast <2 x i64>* %950 to i16*
  store i16 %949, i16* %951, align 16
  %952 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 689
  %953 = load i16, i16* %952, align 2
  %954 = sub i16 0, %953
  %955 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 689
  store i16 %954, i16* %955, align 2
  %956 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 690
  %957 = load i16, i16* %956, align 4
  %958 = sub i16 0, %957
  %959 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 690
  store i16 %958, i16* %959, align 4
  %960 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 691
  %961 = load i16, i16* %960, align 2
  %962 = sub i16 0, %961
  %963 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 691
  store i16 %962, i16* %963, align 2
  %964 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 692
  %965 = load i16, i16* %964, align 8
  %966 = sub i16 0, %965
  %967 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 692
  store i16 %966, i16* %967, align 8
  %968 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 693
  %969 = load i16, i16* %968, align 2
  %970 = sub i16 0, %969
  %971 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 693
  store i16 %970, i16* %971, align 2
  %972 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 694
  %973 = load i16, i16* %972, align 4
  %974 = sub i16 0, %973
  %975 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 694
  store i16 %974, i16* %975, align 4
  %976 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 695
  %977 = load i16, i16* %976, align 2
  %978 = sub i16 0, %977
  %979 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 695
  store i16 %978, i16* %979, align 2
  %980 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 87
  %981 = bitcast <2 x i64>* %980 to i16*
  %982 = load i16, i16* %981, align 16
  %983 = sub i16 0, %982
  %984 = getelementptr inbounds %struct.poly, %struct.poly* %6, i64 0, i32 0, i32 0, i64 87
  %985 = bitcast <2 x i64>* %984 to i16*
  store i16 %983, i16* %985, align 16
  %986 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 697
  %987 = load i16, i16* %986, align 2
  %988 = sub i16 0, %987
  %989 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 697
  store i16 %988, i16* %989, align 2
  %990 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 698
  %991 = load i16, i16* %990, align 4
  %992 = sub i16 0, %991
  %993 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 698
  store i16 %992, i16* %993, align 4
  %994 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 699
  %995 = load i16, i16* %994, align 2
  %996 = sub i16 0, %995
  %997 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 699
  store i16 %996, i16* %997, align 2
  %998 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 700
  %999 = load i16, i16* %998, align 8
  %1000 = sub i16 0, %999
  %1001 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 700
  store i16 %1000, i16* %1001, align 8
  %1002 = bitcast %struct.poly2* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 88, i8* nonnull %1002) #5
  %1003 = bitcast %struct.poly2* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 88, i8* nonnull %1003) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1003, i8 -86, i64 88, i1 false) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %1002, i8 0, i64 88, i1 false) #5
  %1004 = getelementptr inbounds %struct.poly2, %struct.poly2* %5, i64 0, i32 0, i64 0
  br label %611

1005:                                             ; preds = %1080, %933
  %1006 = phi i32 [ 0, %933 ], [ %1081, %1080 ]
  call void @llvm.memset.p0i8.i64(i8* align 2 %935, i8 0, i64 6, i1 false) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %937, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %544, i8 -86, i64 2816, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %545, i8 -86, i64 2752, i1 false) #5
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %546, <2 x i64>* nonnull %547, <2 x i64>* nonnull %938, <2 x i64>* nonnull %939, i64 88) #5
  %1007 = load <16 x i8>, <16 x i8>* %551, align 16
  br label %1008

1008:                                             ; preds = %1008, %1005
  %1009 = phi <16 x i8> [ %1007, %1005 ], [ %1029, %1008 ]
  %1010 = phi i64 [ 0, %1005 ], [ %1040, %1008 ]
  %1011 = add nuw nsw i64 %1010, 88
  %1012 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1011
  %1013 = bitcast <2 x i64>* %1012 to <16 x i8>*
  %1014 = load <16 x i8>, <16 x i8>* %1013, align 16
  %1015 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1010
  %1016 = bitcast <2 x i64>* %1015 to <8 x i16>*
  %1017 = load <8 x i16>, <8 x i16>* %1016, align 16
  %1018 = shufflevector <16 x i8> %1009, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1019 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1014, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1020 = or <16 x i8> %1019, %1018
  %1021 = bitcast <16 x i8> %1020 to <8 x i16>
  %1022 = add <8 x i16> %1017, %1021
  %1023 = getelementptr inbounds %struct.poly, %struct.poly* %7, i64 0, i32 0, i32 0, i64 %1010
  %1024 = bitcast <2 x i64>* %1023 to <8 x i16>*
  store <8 x i16> %1022, <8 x i16>* %1024, align 16
  %1025 = or i64 %1010, 1
  %1026 = add nuw nsw i64 %1010, 89
  %1027 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1026
  %1028 = bitcast <2 x i64>* %1027 to <16 x i8>*
  %1029 = load <16 x i8>, <16 x i8>* %1028, align 16
  %1030 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1025
  %1031 = bitcast <2 x i64>* %1030 to <8 x i16>*
  %1032 = load <8 x i16>, <8 x i16>* %1031, align 16
  %1033 = shufflevector <16 x i8> %1014, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1034 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1029, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1035 = or <16 x i8> %1034, %1033
  %1036 = bitcast <16 x i8> %1035 to <8 x i16>
  %1037 = add <8 x i16> %1032, %1036
  %1038 = getelementptr inbounds %struct.poly, %struct.poly* %7, i64 0, i32 0, i32 0, i64 %1025
  %1039 = bitcast <2 x i64>* %1038 to <8 x i16>*
  store <8 x i16> %1037, <8 x i16>* %1039, align 16
  %1040 = add nuw nsw i64 %1010, 2
  %1041 = icmp eq i64 %1040, 88
  br i1 %1041, label %1042, label %1008

1042:                                             ; preds = %1008
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %544) #5
  %1043 = load i16, i16* %943, align 16
  %1044 = add i16 %1043, 2
  store i16 %1044, i16* %943, align 16
  call void @llvm.memset.p0i8.i64(i8* align 2 %937, i8 0, i64 6, i1 false) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %942, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %544, i8 -86, i64 2816, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %545, i8 -86, i64 2752, i1 false) #5
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %546, <2 x i64>* nonnull %547, <2 x i64>* nonnull %939, <2 x i64>* nonnull %944, i64 88) #5
  %1045 = load <16 x i8>, <16 x i8>* %551, align 16
  br label %1046

1046:                                             ; preds = %1046, %1042
  %1047 = phi <16 x i8> [ %1045, %1042 ], [ %1067, %1046 ]
  %1048 = phi i64 [ 0, %1042 ], [ %1078, %1046 ]
  %1049 = add nuw nsw i64 %1048, 88
  %1050 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1049
  %1051 = bitcast <2 x i64>* %1050 to <16 x i8>*
  %1052 = load <16 x i8>, <16 x i8>* %1051, align 16
  %1053 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1048
  %1054 = bitcast <2 x i64>* %1053 to <8 x i16>*
  %1055 = load <8 x i16>, <8 x i16>* %1054, align 16
  %1056 = shufflevector <16 x i8> %1047, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1057 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1052, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1058 = or <16 x i8> %1057, %1056
  %1059 = bitcast <16 x i8> %1058 to <8 x i16>
  %1060 = add <8 x i16> %1055, %1059
  %1061 = getelementptr inbounds %struct.poly, %struct.poly* %13, i64 0, i32 0, i32 0, i64 %1048
  %1062 = bitcast <2 x i64>* %1061 to <8 x i16>*
  store <8 x i16> %1060, <8 x i16>* %1062, align 16
  %1063 = or i64 %1048, 1
  %1064 = add nuw nsw i64 %1048, 89
  %1065 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1064
  %1066 = bitcast <2 x i64>* %1065 to <16 x i8>*
  %1067 = load <16 x i8>, <16 x i8>* %1066, align 16
  %1068 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1063
  %1069 = bitcast <2 x i64>* %1068 to <8 x i16>*
  %1070 = load <8 x i16>, <8 x i16>* %1069, align 16
  %1071 = shufflevector <16 x i8> %1052, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1072 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1067, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1073 = or <16 x i8> %1072, %1071
  %1074 = bitcast <16 x i8> %1073 to <8 x i16>
  %1075 = add <8 x i16> %1070, %1074
  %1076 = getelementptr inbounds %struct.poly, %struct.poly* %13, i64 0, i32 0, i32 0, i64 %1063
  %1077 = bitcast <2 x i64>* %1076 to <8 x i16>*
  store <8 x i16> %1075, <8 x i16>* %1077, align 16
  %1078 = add nuw nsw i64 %1048, 2
  %1079 = icmp eq i64 %1078, 88
  br i1 %1079, label %1080, label %1046

1080:                                             ; preds = %1046
  call void @llvm.memset.p0i8.i64(i8* align 2 %937, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %544) #5
  %1081 = add nuw nsw i32 %1006, 1
  %1082 = icmp eq i32 %1081, 4
  br i1 %1082, label %1083, label %1005

1083:                                             ; preds = %1080
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %593) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %592) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %937, i8 0, i64 6, i1 false) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %543, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %544, i8 -86, i64 2816, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %545, i8 -86, i64 2752, i1 false) #5
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %546, <2 x i64>* nonnull %547, <2 x i64>* nonnull %939, <2 x i64>* nonnull %549, i64 88) #5
  %1084 = load <16 x i8>, <16 x i8>* %551, align 16
  br label %1085

1085:                                             ; preds = %1085, %1083
  %1086 = phi <16 x i8> [ %1084, %1083 ], [ %1106, %1085 ]
  %1087 = phi i64 [ 0, %1083 ], [ %1117, %1085 ]
  %1088 = add nuw nsw i64 %1087, 88
  %1089 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1088
  %1090 = bitcast <2 x i64>* %1089 to <16 x i8>*
  %1091 = load <16 x i8>, <16 x i8>* %1090, align 16
  %1092 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1087
  %1093 = bitcast <2 x i64>* %1092 to <8 x i16>*
  %1094 = load <8 x i16>, <8 x i16>* %1093, align 16
  %1095 = shufflevector <16 x i8> %1086, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1096 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1091, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1097 = or <16 x i8> %1096, %1095
  %1098 = bitcast <16 x i8> %1097 to <8 x i16>
  %1099 = add <8 x i16> %1094, %1098
  %1100 = getelementptr inbounds %struct.public_key, %struct.public_key* %123, i64 0, i32 0, i32 0, i32 0, i64 %1087
  %1101 = bitcast <2 x i64>* %1100 to <8 x i16>*
  store <8 x i16> %1099, <8 x i16>* %1101, align 16
  %1102 = or i64 %1087, 1
  %1103 = add nuw nsw i64 %1087, 89
  %1104 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1103
  %1105 = bitcast <2 x i64>* %1104 to <16 x i8>*
  %1106 = load <16 x i8>, <16 x i8>* %1105, align 16
  %1107 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1102
  %1108 = bitcast <2 x i64>* %1107 to <8 x i16>*
  %1109 = load <8 x i16>, <8 x i16>* %1108, align 16
  %1110 = shufflevector <16 x i8> %1091, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1111 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1106, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1112 = or <16 x i8> %1111, %1110
  %1113 = bitcast <16 x i8> %1112 to <8 x i16>
  %1114 = add <8 x i16> %1109, %1113
  %1115 = getelementptr inbounds %struct.public_key, %struct.public_key* %123, i64 0, i32 0, i32 0, i32 0, i64 %1102
  %1116 = bitcast <2 x i64>* %1115 to <8 x i16>*
  store <8 x i16> %1114, <8 x i16>* %1116, align 16
  %1117 = add nuw nsw i64 %1087, 2
  %1118 = icmp eq i64 %1117, 88
  br i1 %1118, label %1119, label %1085

1119:                                             ; preds = %1085
  %1120 = inttoptr i64 %16 to [704 x i16]*
  %1121 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 701
  %1122 = bitcast i16* %1121 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %1122, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %1122, i8 0, i64 6, i1 false) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %543, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %544, i8 -86, i64 2816, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %545, i8 -86, i64 2752, i1 false) #5
  %1123 = getelementptr inbounds %struct.public_key, %struct.public_key* %123, i64 0, i32 0, i32 0, i32 0, i64 0
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %546, <2 x i64>* nonnull %547, <2 x i64>* %1123, <2 x i64>* nonnull %549, i64 88) #5
  %1124 = load <16 x i8>, <16 x i8>* %551, align 16
  br label %1125

1125:                                             ; preds = %1125, %1119
  %1126 = phi <16 x i8> [ %1124, %1119 ], [ %1146, %1125 ]
  %1127 = phi i64 [ 0, %1119 ], [ %1157, %1125 ]
  %1128 = add nuw nsw i64 %1127, 88
  %1129 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1128
  %1130 = bitcast <2 x i64>* %1129 to <16 x i8>*
  %1131 = load <16 x i8>, <16 x i8>* %1130, align 16
  %1132 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1127
  %1133 = bitcast <2 x i64>* %1132 to <8 x i16>*
  %1134 = load <8 x i16>, <8 x i16>* %1133, align 16
  %1135 = shufflevector <16 x i8> %1126, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1136 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1131, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1137 = or <16 x i8> %1136, %1135
  %1138 = bitcast <16 x i8> %1137 to <8 x i16>
  %1139 = add <8 x i16> %1134, %1138
  %1140 = getelementptr inbounds %struct.public_key, %struct.public_key* %123, i64 0, i32 0, i32 0, i32 0, i64 %1127
  %1141 = bitcast <2 x i64>* %1140 to <8 x i16>*
  store <8 x i16> %1139, <8 x i16>* %1141, align 16
  %1142 = or i64 %1127, 1
  %1143 = add nuw nsw i64 %1127, 89
  %1144 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1143
  %1145 = bitcast <2 x i64>* %1144 to <16 x i8>*
  %1146 = load <16 x i8>, <16 x i8>* %1145, align 16
  %1147 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1142
  %1148 = bitcast <2 x i64>* %1147 to <8 x i16>*
  %1149 = load <8 x i16>, <8 x i16>* %1148, align 16
  %1150 = shufflevector <16 x i8> %1131, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1151 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1146, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1152 = or <16 x i8> %1151, %1150
  %1153 = bitcast <16 x i8> %1152 to <8 x i16>
  %1154 = add <8 x i16> %1149, %1153
  %1155 = getelementptr inbounds %struct.public_key, %struct.public_key* %123, i64 0, i32 0, i32 0, i32 0, i64 %1142
  %1156 = bitcast <2 x i64>* %1155 to <8 x i16>*
  store <8 x i16> %1154, <8 x i16>* %1156, align 16
  %1157 = add nuw nsw i64 %1127, 2
  %1158 = icmp eq i64 %1157, 88
  br i1 %1158, label %1159, label %1125

1159:                                             ; preds = %1125
  call void @llvm.memset.p0i8.i64(i8* align 2 %1122, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %544) #5
  br label %1160

1160:                                             ; preds = %1401, %1159
  %1161 = phi i64 [ 0, %1159 ], [ %1412, %1401 ]
  %1162 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 %1161
  %1163 = bitcast i16* %1162 to <8 x i16>*
  %1164 = load <8 x i16>, <8 x i16>* %1163, align 16
  %1165 = getelementptr inbounds i16, i16* %1162, i64 8
  %1166 = bitcast i16* %1165 to <8 x i16>*
  %1167 = load <8 x i16>, <8 x i16>* %1166, align 16
  %1168 = and <8 x i16> %1164, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %1169 = and <8 x i16> %1167, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %1170 = bitcast i16* %1162 to <8 x i16>*
  store <8 x i16> %1168, <8 x i16>* %1170, align 16
  %1171 = bitcast i16* %1165 to <8 x i16>*
  store <8 x i16> %1169, <8 x i16>* %1171, align 16
  %1172 = or i64 %1161, 16
  %1173 = icmp eq i64 %1172, 688
  br i1 %1173, label %1174, label %1401, !llvm.loop !10

1174:                                             ; preds = %1160
  %1175 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 688
  %1176 = load i16, i16* %1175, align 16
  %1177 = and i16 %1176, 8191
  store i16 %1177, i16* %1175, align 16
  %1178 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 689
  %1179 = load i16, i16* %1178, align 2
  %1180 = and i16 %1179, 8191
  store i16 %1180, i16* %1178, align 2
  %1181 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 690
  %1182 = load i16, i16* %1181, align 4
  %1183 = and i16 %1182, 8191
  store i16 %1183, i16* %1181, align 4
  %1184 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 691
  %1185 = load i16, i16* %1184, align 2
  %1186 = and i16 %1185, 8191
  store i16 %1186, i16* %1184, align 2
  %1187 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 692
  %1188 = load i16, i16* %1187, align 8
  %1189 = and i16 %1188, 8191
  store i16 %1189, i16* %1187, align 8
  %1190 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 693
  %1191 = load i16, i16* %1190, align 2
  %1192 = and i16 %1191, 8191
  store i16 %1192, i16* %1190, align 2
  %1193 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 694
  %1194 = load i16, i16* %1193, align 4
  %1195 = and i16 %1194, 8191
  store i16 %1195, i16* %1193, align 4
  %1196 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 695
  %1197 = load i16, i16* %1196, align 2
  %1198 = and i16 %1197, 8191
  store i16 %1198, i16* %1196, align 2
  %1199 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 696
  %1200 = load i16, i16* %1199, align 16
  %1201 = and i16 %1200, 8191
  store i16 %1201, i16* %1199, align 16
  %1202 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 697
  %1203 = load i16, i16* %1202, align 2
  %1204 = and i16 %1203, 8191
  store i16 %1204, i16* %1202, align 2
  %1205 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 698
  %1206 = load i16, i16* %1205, align 4
  %1207 = and i16 %1206, 8191
  store i16 %1207, i16* %1205, align 4
  %1208 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 699
  %1209 = load i16, i16* %1208, align 2
  %1210 = and i16 %1209, 8191
  store i16 %1210, i16* %1208, align 2
  %1211 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 700
  %1212 = load i16, i16* %1211, align 8
  %1213 = and i16 %1212, 8191
  store i16 %1213, i16* %1211, align 8
  call void @llvm.memset.p0i8.i64(i8* align 2 %937, i8 0, i64 6, i1 false) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %541, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %544, i8 -86, i64 2816, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %545, i8 -86, i64 2752, i1 false) #5
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %546, <2 x i64>* nonnull %547, <2 x i64>* nonnull %939, <2 x i64>* nonnull %548, i64 88) #5
  %1214 = load <16 x i8>, <16 x i8>* %551, align 16
  br label %1215

1215:                                             ; preds = %1215, %1174
  %1216 = phi <16 x i8> [ %1214, %1174 ], [ %1236, %1215 ]
  %1217 = phi i64 [ 0, %1174 ], [ %1247, %1215 ]
  %1218 = add nuw nsw i64 %1217, 88
  %1219 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1218
  %1220 = bitcast <2 x i64>* %1219 to <16 x i8>*
  %1221 = load <16 x i8>, <16 x i8>* %1220, align 16
  %1222 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1217
  %1223 = bitcast <2 x i64>* %1222 to <8 x i16>*
  %1224 = load <8 x i16>, <8 x i16>* %1223, align 16
  %1225 = shufflevector <16 x i8> %1216, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1226 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1221, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1227 = or <16 x i8> %1226, %1225
  %1228 = bitcast <16 x i8> %1227 to <8 x i16>
  %1229 = add <8 x i16> %1224, %1228
  %1230 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 2, i32 0, i32 0, i64 %1217
  %1231 = bitcast <2 x i64>* %1230 to <8 x i16>*
  store <8 x i16> %1229, <8 x i16>* %1231, align 16
  %1232 = or i64 %1217, 1
  %1233 = add nuw nsw i64 %1217, 89
  %1234 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1233
  %1235 = bitcast <2 x i64>* %1234 to <16 x i8>*
  %1236 = load <16 x i8>, <16 x i8>* %1235, align 16
  %1237 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1232
  %1238 = bitcast <2 x i64>* %1237 to <8 x i16>*
  %1239 = load <8 x i16>, <8 x i16>* %1238, align 16
  %1240 = shufflevector <16 x i8> %1221, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1241 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1236, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1242 = or <16 x i8> %1241, %1240
  %1243 = bitcast <16 x i8> %1242 to <8 x i16>
  %1244 = add <8 x i16> %1239, %1243
  %1245 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 2, i32 0, i32 0, i64 %1232
  %1246 = bitcast <2 x i64>* %1245 to <8 x i16>*
  store <8 x i16> %1244, <8 x i16>* %1246, align 16
  %1247 = add nuw nsw i64 %1217, 2
  %1248 = icmp eq i64 %1247, 88
  br i1 %1248, label %1249, label %1215

1249:                                             ; preds = %1215
  %1250 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 2
  %1251 = bitcast %struct.poly* %1250 to [704 x i16]*
  %1252 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 701
  %1253 = bitcast i16* %1252 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %1253, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %1253, i8 0, i64 6, i1 false) #5
  call void @llvm.memset.p0i8.i64(i8* align 2 %541, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %544) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %544, i8 -86, i64 2816, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %545, i8 -86, i64 2752, i1 false) #5
  %1254 = getelementptr inbounds %struct.poly, %struct.poly* %1250, i64 0, i32 0, i32 0, i64 0
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %546, <2 x i64>* nonnull %547, <2 x i64>* %1254, <2 x i64>* nonnull %548, i64 88) #5
  %1255 = load <16 x i8>, <16 x i8>* %551, align 16
  br label %1256

1256:                                             ; preds = %1256, %1249
  %1257 = phi <16 x i8> [ %1255, %1249 ], [ %1277, %1256 ]
  %1258 = phi i64 [ 0, %1249 ], [ %1288, %1256 ]
  %1259 = add nuw nsw i64 %1258, 88
  %1260 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1259
  %1261 = bitcast <2 x i64>* %1260 to <16 x i8>*
  %1262 = load <16 x i8>, <16 x i8>* %1261, align 16
  %1263 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1258
  %1264 = bitcast <2 x i64>* %1263 to <8 x i16>*
  %1265 = load <8 x i16>, <8 x i16>* %1264, align 16
  %1266 = shufflevector <16 x i8> %1257, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1267 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1262, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1268 = or <16 x i8> %1267, %1266
  %1269 = bitcast <16 x i8> %1268 to <8 x i16>
  %1270 = add <8 x i16> %1265, %1269
  %1271 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 2, i32 0, i32 0, i64 %1258
  %1272 = bitcast <2 x i64>* %1271 to <8 x i16>*
  store <8 x i16> %1270, <8 x i16>* %1272, align 16
  %1273 = or i64 %1258, 1
  %1274 = add nuw nsw i64 %1258, 89
  %1275 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1274
  %1276 = bitcast <2 x i64>* %1275 to <16 x i8>*
  %1277 = load <16 x i8>, <16 x i8>* %1276, align 16
  %1278 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %8, i64 0, i64 %1273
  %1279 = bitcast <2 x i64>* %1278 to <8 x i16>*
  %1280 = load <8 x i16>, <8 x i16>* %1279, align 16
  %1281 = shufflevector <16 x i8> %1262, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1282 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %1277, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %1283 = or <16 x i8> %1282, %1281
  %1284 = bitcast <16 x i8> %1283 to <8 x i16>
  %1285 = add <8 x i16> %1280, %1284
  %1286 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 2, i32 0, i32 0, i64 %1273
  %1287 = bitcast <2 x i64>* %1286 to <8 x i16>*
  store <8 x i16> %1285, <8 x i16>* %1287, align 16
  %1288 = add nuw nsw i64 %1258, 2
  %1289 = icmp eq i64 %1288, 88
  br i1 %1289, label %1290, label %1256

1290:                                             ; preds = %1256
  call void @llvm.memset.p0i8.i64(i8* align 2 %1253, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %545) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %544) #5
  br label %1291

1291:                                             ; preds = %1389, %1290
  %1292 = phi i64 [ 0, %1290 ], [ %1400, %1389 ]
  %1293 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 %1292
  %1294 = bitcast i16* %1293 to <8 x i16>*
  %1295 = load <8 x i16>, <8 x i16>* %1294, align 16
  %1296 = getelementptr inbounds i16, i16* %1293, i64 8
  %1297 = bitcast i16* %1296 to <8 x i16>*
  %1298 = load <8 x i16>, <8 x i16>* %1297, align 2
  %1299 = and <8 x i16> %1295, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %1300 = and <8 x i16> %1298, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %1301 = bitcast i16* %1293 to <8 x i16>*
  store <8 x i16> %1299, <8 x i16>* %1301, align 16
  %1302 = bitcast i16* %1296 to <8 x i16>*
  store <8 x i16> %1300, <8 x i16>* %1302, align 2
  %1303 = or i64 %1292, 16
  %1304 = icmp eq i64 %1303, 688
  br i1 %1304, label %1305, label %1389, !llvm.loop !11

1305:                                             ; preds = %1291
  %1306 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 2, i32 0, i32 0, i64 86
  %1307 = bitcast <2 x i64>* %1306 to i16*
  %1308 = load i16, i16* %1307, align 16
  %1309 = and i16 %1308, 8191
  store i16 %1309, i16* %1307, align 16
  %1310 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 689
  %1311 = load i16, i16* %1310, align 2
  %1312 = and i16 %1311, 8191
  store i16 %1312, i16* %1310, align 2
  %1313 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 690
  %1314 = load i16, i16* %1313, align 4
  %1315 = and i16 %1314, 8191
  store i16 %1315, i16* %1313, align 4
  %1316 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 691
  %1317 = load i16, i16* %1316, align 2
  %1318 = and i16 %1317, 8191
  store i16 %1318, i16* %1316, align 2
  %1319 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 692
  %1320 = load i16, i16* %1319, align 8
  %1321 = and i16 %1320, 8191
  store i16 %1321, i16* %1319, align 8
  %1322 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 693
  %1323 = load i16, i16* %1322, align 2
  %1324 = and i16 %1323, 8191
  store i16 %1324, i16* %1322, align 2
  %1325 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 694
  %1326 = load i16, i16* %1325, align 4
  %1327 = and i16 %1326, 8191
  store i16 %1327, i16* %1325, align 4
  %1328 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 695
  %1329 = load i16, i16* %1328, align 2
  %1330 = and i16 %1329, 8191
  store i16 %1330, i16* %1328, align 2
  %1331 = getelementptr inbounds %struct.private_key, %struct.private_key* %20, i64 0, i32 2, i32 0, i32 0, i64 87
  %1332 = bitcast <2 x i64>* %1331 to i16*
  %1333 = load i16, i16* %1332, align 16
  %1334 = and i16 %1333, 8191
  store i16 %1334, i16* %1332, align 16
  %1335 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 697
  %1336 = load i16, i16* %1335, align 2
  %1337 = and i16 %1336, 8191
  store i16 %1337, i16* %1335, align 2
  %1338 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 698
  %1339 = load i16, i16* %1338, align 4
  %1340 = and i16 %1339, 8191
  store i16 %1340, i16* %1338, align 4
  %1341 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 699
  %1342 = load i16, i16* %1341, align 2
  %1343 = and i16 %1342, 8191
  store i16 %1343, i16* %1341, align 2
  %1344 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 700
  %1345 = load i16, i16* %1344, align 8
  %1346 = and i16 %1345, 8191
  store i16 %1346, i16* %1344, align 8
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %591) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %539) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %285) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %23) #5
  ret void

1347:                                             ; preds = %493
  %1348 = getelementptr inbounds %struct.poly, %struct.poly* %11, i64 0, i32 0, i32 0, i64 86
  %1349 = bitcast <2 x i64>* %1348 to i16*
  %1350 = load i16, i16* %1349, align 16
  %1351 = mul i16 %1350, 3
  store i16 %1351, i16* %1349, align 16
  %1352 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 689
  %1353 = load i16, i16* %1352, align 2
  %1354 = mul i16 %1353, 3
  store i16 %1354, i16* %1352, align 2
  %1355 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 690
  %1356 = load i16, i16* %1355, align 4
  %1357 = mul i16 %1356, 3
  store i16 %1357, i16* %1355, align 4
  %1358 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 691
  %1359 = load i16, i16* %1358, align 2
  %1360 = mul i16 %1359, 3
  store i16 %1360, i16* %1358, align 2
  %1361 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 692
  %1362 = load i16, i16* %1361, align 8
  %1363 = mul i16 %1362, 3
  store i16 %1363, i16* %1361, align 8
  %1364 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 693
  %1365 = load i16, i16* %1364, align 2
  %1366 = mul i16 %1365, 3
  store i16 %1366, i16* %1364, align 2
  %1367 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 694
  %1368 = load i16, i16* %1367, align 4
  %1369 = mul i16 %1368, 3
  store i16 %1369, i16* %1367, align 4
  %1370 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 695
  %1371 = load i16, i16* %1370, align 2
  %1372 = mul i16 %1371, 3
  store i16 %1372, i16* %1370, align 2
  %1373 = getelementptr inbounds %struct.poly, %struct.poly* %11, i64 0, i32 0, i32 0, i64 87
  %1374 = bitcast <2 x i64>* %1373 to i16*
  %1375 = load i16, i16* %1374, align 16
  %1376 = mul i16 %1375, 3
  store i16 %1376, i16* %1374, align 16
  %1377 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 697
  %1378 = load i16, i16* %1377, align 2
  %1379 = mul i16 %1378, 3
  store i16 %1379, i16* %1377, align 2
  %1380 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 698
  %1381 = load i16, i16* %1380, align 4
  %1382 = mul i16 %1381, 3
  store i16 %1382, i16* %1380, align 4
  %1383 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 699
  %1384 = load i16, i16* %1383, align 2
  %1385 = mul i16 %1384, 3
  store i16 %1385, i16* %1383, align 2
  %1386 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 700
  %1387 = load i16, i16* %1386, align 8
  %1388 = mul i16 %1387, 3
  store i16 %1388, i16* %1386, align 8
  br label %507

1389:                                             ; preds = %1291
  %1390 = getelementptr inbounds [704 x i16], [704 x i16]* %1251, i64 0, i64 %1303
  %1391 = bitcast i16* %1390 to <8 x i16>*
  %1392 = load <8 x i16>, <8 x i16>* %1391, align 16
  %1393 = getelementptr inbounds i16, i16* %1390, i64 8
  %1394 = bitcast i16* %1393 to <8 x i16>*
  %1395 = load <8 x i16>, <8 x i16>* %1394, align 2
  %1396 = and <8 x i16> %1392, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %1397 = and <8 x i16> %1395, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %1398 = bitcast i16* %1390 to <8 x i16>*
  store <8 x i16> %1396, <8 x i16>* %1398, align 16
  %1399 = bitcast i16* %1393 to <8 x i16>*
  store <8 x i16> %1397, <8 x i16>* %1399, align 2
  %1400 = add nuw nsw i64 %1292, 32
  br label %1291

1401:                                             ; preds = %1160
  %1402 = getelementptr inbounds [704 x i16], [704 x i16]* %1120, i64 0, i64 %1172
  %1403 = bitcast i16* %1402 to <8 x i16>*
  %1404 = load <8 x i16>, <8 x i16>* %1403, align 16
  %1405 = getelementptr inbounds i16, i16* %1402, i64 8
  %1406 = bitcast i16* %1405 to <8 x i16>*
  %1407 = load <8 x i16>, <8 x i16>* %1406, align 16
  %1408 = and <8 x i16> %1404, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %1409 = and <8 x i16> %1407, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %1410 = bitcast i16* %1402 to <8 x i16>*
  store <8 x i16> %1408, <8 x i16>* %1410, align 16
  %1411 = bitcast i16* %1405 to <8 x i16>*
  store <8 x i16> %1409, <8 x i16>* %1411, align 16
  %1412 = add nuw nsw i64 %1161, 32
  br label %1160

1413:                                             ; preds = %731
  %1414 = trunc i64 %734 to i16
  %1415 = and i16 %1414, 1
  %1416 = getelementptr inbounds [704 x i16], [704 x i16]* %716, i64 0, i64 %735
  store i16 %1415, i16* %1416, align 2
  %1417 = lshr i64 %734, 1
  %1418 = add i32 %733, 1
  %1419 = icmp eq i32 %1418, 64
  br i1 %1419, label %1420, label %1423

1420:                                             ; preds = %1413
  %1421 = getelementptr inbounds i64, i64* %732, i64 1
  %1422 = load i64, i64* %1421, align 8
  br label %1423

1423:                                             ; preds = %1420, %1413
  %1424 = phi i64* [ %1421, %1420 ], [ %732, %1413 ]
  %1425 = phi i32 [ 0, %1420 ], [ %1418, %1413 ]
  %1426 = phi i64 [ %1422, %1420 ], [ %1417, %1413 ]
  %1427 = add nuw nsw i64 %718, 2
  br label %717

1428:                                             ; preds = %626
  %1429 = lshr i64 %629, 1
  %1430 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 %630
  %1431 = load i16, i16* %1430, align 2
  %1432 = zext i16 %1431 to i64
  %1433 = shl i64 %1432, 63
  %1434 = or i64 %1433, %1429
  %1435 = add i32 %628, 1
  %1436 = icmp eq i32 %1435, 64
  br i1 %1436, label %1437, label %1439

1437:                                             ; preds = %1428
  store i64 %1434, i64* %627, align 8
  %1438 = getelementptr inbounds i64, i64* %627, i64 1
  br label %1439

1439:                                             ; preds = %1437, %1428
  %1440 = phi i64* [ %1438, %1437 ], [ %627, %1428 ]
  %1441 = phi i32 [ 0, %1437 ], [ %1435, %1428 ]
  %1442 = phi i64 [ 0, %1437 ], [ %1434, %1428 ]
  %1443 = add nuw nsw i64 %612, 2
  br label %611

1444:                                             ; preds = %595
  %1445 = getelementptr inbounds [704 x i16], [704 x i16]* %588, i64 0, i64 %609
  %1446 = bitcast i16* %1445 to <8 x i16>*
  %1447 = load <8 x i16>, <8 x i16>* %1446, align 16
  %1448 = getelementptr inbounds i16, i16* %1445, i64 8
  %1449 = bitcast i16* %1448 to <8 x i16>*
  %1450 = load <8 x i16>, <8 x i16>* %1449, align 16
  %1451 = sub <8 x i16> zeroinitializer, %1447
  %1452 = sub <8 x i16> zeroinitializer, %1450
  %1453 = getelementptr inbounds [704 x i16], [704 x i16]* %594, i64 0, i64 %609
  %1454 = bitcast i16* %1453 to <8 x i16>*
  store <8 x i16> %1451, <8 x i16>* %1454, align 16
  %1455 = getelementptr inbounds i16, i16* %1453, i64 8
  %1456 = bitcast i16* %1455 to <8 x i16>*
  store <8 x i16> %1452, <8 x i16>* %1456, align 16
  %1457 = add nuw nsw i64 %596, 32
  br label %595

1458:                                             ; preds = %493
  %1459 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %505
  %1460 = bitcast i16* %1459 to <8 x i16>*
  %1461 = load <8 x i16>, <8 x i16>* %1460, align 16
  %1462 = getelementptr inbounds i16, i16* %1459, i64 8
  %1463 = bitcast i16* %1462 to <8 x i16>*
  %1464 = load <8 x i16>, <8 x i16>* %1463, align 16
  %1465 = mul <8 x i16> %1461, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1466 = mul <8 x i16> %1464, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1467 = bitcast i16* %1459 to <8 x i16>*
  store <8 x i16> %1465, <8 x i16>* %1467, align 16
  %1468 = bitcast i16* %1462 to <8 x i16>*
  store <8 x i16> %1466, <8 x i16>* %1468, align 16
  %1469 = add nuw nsw i64 %494, 32
  br label %493

1470:                                             ; preds = %390
  %1471 = or i64 %391, 17
  %1472 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %1471
  %1473 = bitcast i16* %1472 to <8 x i16>*
  %1474 = load <8 x i16>, <8 x i16>* %1473, align 2
  %1475 = getelementptr inbounds i16, i16* %1472, i64 8
  %1476 = bitcast i16* %1475 to <8 x i16>*
  %1477 = load <8 x i16>, <8 x i16>* %1476, align 2
  %1478 = shufflevector <8 x i16> %401, <8 x i16> %1474, <8 x i32> <i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %1479 = shufflevector <8 x i16> %1474, <8 x i16> %1477, <8 x i32> <i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %1480 = mul <8 x i16> %1474, %1478
  %1481 = mul <8 x i16> %1477, %1479
  %1482 = add <8 x i16> %1480, %406
  %1483 = add <8 x i16> %1481, %407
  %1484 = add nuw nsw i64 %391, 32
  br label %390

1485:                                             ; preds = %128
  %1486 = or i64 %129, 17
  %1487 = getelementptr inbounds [704 x i16], [704 x i16]* %24, i64 0, i64 %1486
  %1488 = bitcast i16* %1487 to <8 x i16>*
  %1489 = load <8 x i16>, <8 x i16>* %1488, align 2
  %1490 = getelementptr inbounds i16, i16* %1487, i64 8
  %1491 = bitcast i16* %1490 to <8 x i16>*
  %1492 = load <8 x i16>, <8 x i16>* %1491, align 2
  %1493 = shufflevector <8 x i16> %139, <8 x i16> %1489, <8 x i32> <i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %1494 = shufflevector <8 x i16> %1489, <8 x i16> %1492, <8 x i32> <i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %1495 = mul <8 x i16> %1489, %1493
  %1496 = mul <8 x i16> %1492, %1494
  %1497 = add <8 x i16> %1495, %144
  %1498 = add <8 x i16> %1496, %145
  %1499 = add nuw nsw i64 %129, 32
  br label %128
}

; Function Attrs: nounwind ssp uwtable
define hidden void @HRSS_encap(i8*, i8*, %struct.HRSS_public_key*, i8* nocapture readonly) local_unnamed_addr #2 {
  %5 = alloca [176 x <2 x i64>], align 16
  %6 = alloca [172 x <2 x i64>], align 16
  %7 = alloca %struct.poly, align 16
  %8 = bitcast %struct.poly* %7 to i8*
  %9 = alloca %struct.poly, align 16
  %10 = bitcast %struct.poly* %9 to i8*
  %11 = alloca %struct.poly, align 16
  %12 = alloca %struct.poly, align 16
  %13 = alloca [140 x i8], align 16
  %14 = getelementptr inbounds [140 x i8], [140 x i8]* %13, i64 0, i64 0
  %15 = alloca [140 x i8], align 16
  %16 = getelementptr inbounds [140 x i8], [140 x i8]* %15, i64 0, i64 0
  %17 = alloca %struct.sha256_state_st, align 4
  %18 = ptrtoint %struct.HRSS_public_key* %2 to i64
  %19 = add i64 %18, 15
  %20 = and i64 %19, -16
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %8) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 1408, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %10) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 -86, i64 1408, i1 false)
  %21 = bitcast %struct.poly* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %21) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %21, i8 -86, i64 1408, i1 false)
  %22 = bitcast %struct.poly* %7 to [704 x i16]*
  br label %23

23:                                               ; preds = %23, %4
  %24 = phi i64 [ 0, %4 ], [ %45, %23 ]
  %25 = getelementptr inbounds i8, i8* %3, i64 %24
  %26 = bitcast i8* %25 to <8 x i8>*
  %27 = load <8 x i8>, <8 x i8>* %26, align 1
  %28 = zext <8 x i8> %27 to <8 x i16>
  %29 = zext <8 x i8> %27 to <8 x i32>
  %30 = mul nuw nsw <8 x i32> %29, <i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845>
  %31 = lshr <8 x i32> %30, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %32 = trunc <8 x i32> %31 to <8 x i16>
  %33 = mul nsw <8 x i16> %32, <i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3>
  %34 = add nsw <8 x i16> %33, %28
  %35 = ashr <8 x i16> %34, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %36 = and <8 x i16> %35, %34
  %37 = add <8 x i16> %36, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %38 = and <8 x i16> %37, %34
  %39 = lshr <8 x i16> %38, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %40 = xor <8 x i16> %39, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %41 = add nsw <8 x i16> %40, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %42 = or <8 x i16> %41, %38
  %43 = getelementptr inbounds [704 x i16], [704 x i16]* %22, i64 0, i64 %24
  %44 = bitcast i16* %43 to <8 x i16>*
  store <8 x i16> %42, <8 x i16>* %44, align 16
  %45 = add i64 %24, 8
  %46 = icmp eq i64 %45, 696
  br i1 %46, label %47, label %23, !llvm.loop !12

47:                                               ; preds = %23
  %48 = getelementptr inbounds i8, i8* %3, i64 696
  %49 = load i8, i8* %48, align 1
  %50 = zext i8 %49 to i16
  %51 = zext i8 %49 to i32
  %52 = mul nuw nsw i32 %51, 21845
  %53 = lshr i32 %52, 16
  %54 = trunc i32 %53 to i16
  %55 = mul nsw i16 %54, -3
  %56 = add nsw i16 %55, %50
  %57 = ashr i16 %56, 1
  %58 = and i16 %57, %56
  %59 = add i16 %58, -1
  %60 = and i16 %59, %56
  %61 = lshr i16 %60, 1
  %62 = xor i16 %61, 1
  %63 = add nsw i16 %62, -1
  %64 = or i16 %63, %60
  %65 = getelementptr inbounds %struct.poly, %struct.poly* %7, i64 0, i32 0, i32 0, i64 87
  %66 = bitcast <2 x i64>* %65 to i16*
  store i16 %64, i16* %66, align 16
  %67 = getelementptr inbounds i8, i8* %3, i64 697
  %68 = load i8, i8* %67, align 1
  %69 = zext i8 %68 to i16
  %70 = zext i8 %68 to i32
  %71 = mul nuw nsw i32 %70, 21845
  %72 = lshr i32 %71, 16
  %73 = trunc i32 %72 to i16
  %74 = mul nsw i16 %73, -3
  %75 = add nsw i16 %74, %69
  %76 = ashr i16 %75, 1
  %77 = and i16 %76, %75
  %78 = add i16 %77, -1
  %79 = and i16 %78, %75
  %80 = lshr i16 %79, 1
  %81 = xor i16 %80, 1
  %82 = add nsw i16 %81, -1
  %83 = or i16 %82, %79
  %84 = getelementptr inbounds [704 x i16], [704 x i16]* %22, i64 0, i64 697
  store i16 %83, i16* %84, align 2
  %85 = getelementptr inbounds i8, i8* %3, i64 698
  %86 = load i8, i8* %85, align 1
  %87 = zext i8 %86 to i16
  %88 = zext i8 %86 to i32
  %89 = mul nuw nsw i32 %88, 21845
  %90 = lshr i32 %89, 16
  %91 = trunc i32 %90 to i16
  %92 = mul nsw i16 %91, -3
  %93 = add nsw i16 %92, %87
  %94 = ashr i16 %93, 1
  %95 = and i16 %94, %93
  %96 = add i16 %95, -1
  %97 = and i16 %96, %93
  %98 = lshr i16 %97, 1
  %99 = xor i16 %98, 1
  %100 = add nsw i16 %99, -1
  %101 = or i16 %100, %97
  %102 = getelementptr inbounds [704 x i16], [704 x i16]* %22, i64 0, i64 698
  store i16 %101, i16* %102, align 4
  %103 = getelementptr inbounds i8, i8* %3, i64 699
  %104 = load i8, i8* %103, align 1
  %105 = zext i8 %104 to i16
  %106 = zext i8 %104 to i32
  %107 = mul nuw nsw i32 %106, 21845
  %108 = lshr i32 %107, 16
  %109 = trunc i32 %108 to i16
  %110 = mul nsw i16 %109, -3
  %111 = add nsw i16 %110, %105
  %112 = ashr i16 %111, 1
  %113 = and i16 %112, %111
  %114 = add i16 %113, -1
  %115 = and i16 %114, %111
  %116 = lshr i16 %115, 1
  %117 = xor i16 %116, 1
  %118 = add nsw i16 %117, -1
  %119 = or i16 %118, %115
  %120 = getelementptr inbounds [704 x i16], [704 x i16]* %22, i64 0, i64 699
  store i16 %119, i16* %120, align 2
  %121 = inttoptr i64 %20 to %struct.public_key*
  %122 = getelementptr inbounds [704 x i16], [704 x i16]* %22, i64 0, i64 700
  store i16 0, i16* %122, align 8
  %123 = getelementptr inbounds i8, i8* %3, i64 700
  %124 = bitcast %struct.poly* %9 to [704 x i16]*
  br label %125

125:                                              ; preds = %125, %47
  %126 = phi i64 [ 0, %47 ], [ %147, %125 ]
  %127 = getelementptr inbounds i8, i8* %123, i64 %126
  %128 = bitcast i8* %127 to <8 x i8>*
  %129 = load <8 x i8>, <8 x i8>* %128, align 1
  %130 = zext <8 x i8> %129 to <8 x i16>
  %131 = zext <8 x i8> %129 to <8 x i32>
  %132 = mul nuw nsw <8 x i32> %131, <i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845>
  %133 = lshr <8 x i32> %132, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %134 = trunc <8 x i32> %133 to <8 x i16>
  %135 = mul nsw <8 x i16> %134, <i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3>
  %136 = add nsw <8 x i16> %135, %130
  %137 = ashr <8 x i16> %136, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %138 = and <8 x i16> %137, %136
  %139 = add <8 x i16> %138, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %140 = and <8 x i16> %139, %136
  %141 = lshr <8 x i16> %140, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %142 = xor <8 x i16> %141, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %143 = add nsw <8 x i16> %142, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %144 = or <8 x i16> %143, %140
  %145 = getelementptr inbounds [704 x i16], [704 x i16]* %124, i64 0, i64 %126
  %146 = bitcast i16* %145 to <8 x i16>*
  store <8 x i16> %144, <8 x i16>* %146, align 16
  %147 = add i64 %126, 8
  %148 = icmp eq i64 %147, 696
  br i1 %148, label %149, label %125, !llvm.loop !13

149:                                              ; preds = %125
  %150 = getelementptr inbounds i8, i8* %3, i64 1396
  %151 = load i8, i8* %150, align 1
  %152 = zext i8 %151 to i16
  %153 = zext i8 %151 to i32
  %154 = mul nuw nsw i32 %153, 21845
  %155 = lshr i32 %154, 16
  %156 = trunc i32 %155 to i16
  %157 = mul nsw i16 %156, -3
  %158 = add nsw i16 %157, %152
  %159 = ashr i16 %158, 1
  %160 = and i16 %159, %158
  %161 = add i16 %160, -1
  %162 = and i16 %161, %158
  %163 = lshr i16 %162, 1
  %164 = xor i16 %163, 1
  %165 = add nsw i16 %164, -1
  %166 = or i16 %165, %162
  %167 = getelementptr inbounds %struct.poly, %struct.poly* %9, i64 0, i32 0, i32 0, i64 87
  %168 = bitcast <2 x i64>* %167 to i16*
  store i16 %166, i16* %168, align 16
  %169 = getelementptr inbounds i8, i8* %3, i64 1397
  %170 = load i8, i8* %169, align 1
  %171 = zext i8 %170 to i16
  %172 = zext i8 %170 to i32
  %173 = mul nuw nsw i32 %172, 21845
  %174 = lshr i32 %173, 16
  %175 = trunc i32 %174 to i16
  %176 = mul nsw i16 %175, -3
  %177 = add nsw i16 %176, %171
  %178 = ashr i16 %177, 1
  %179 = and i16 %178, %177
  %180 = add i16 %179, -1
  %181 = and i16 %180, %177
  %182 = lshr i16 %181, 1
  %183 = xor i16 %182, 1
  %184 = add nsw i16 %183, -1
  %185 = or i16 %184, %181
  %186 = getelementptr inbounds [704 x i16], [704 x i16]* %124, i64 0, i64 697
  store i16 %185, i16* %186, align 2
  %187 = getelementptr inbounds i8, i8* %3, i64 1398
  %188 = load i8, i8* %187, align 1
  %189 = zext i8 %188 to i16
  %190 = zext i8 %188 to i32
  %191 = mul nuw nsw i32 %190, 21845
  %192 = lshr i32 %191, 16
  %193 = trunc i32 %192 to i16
  %194 = mul nsw i16 %193, -3
  %195 = add nsw i16 %194, %189
  %196 = ashr i16 %195, 1
  %197 = and i16 %196, %195
  %198 = add i16 %197, -1
  %199 = and i16 %198, %195
  %200 = lshr i16 %199, 1
  %201 = xor i16 %200, 1
  %202 = add nsw i16 %201, -1
  %203 = or i16 %202, %199
  %204 = getelementptr inbounds [704 x i16], [704 x i16]* %124, i64 0, i64 698
  store i16 %203, i16* %204, align 4
  %205 = getelementptr inbounds i8, i8* %3, i64 1399
  %206 = load i8, i8* %205, align 1
  %207 = zext i8 %206 to i16
  %208 = zext i8 %206 to i32
  %209 = mul nuw nsw i32 %208, 21845
  %210 = lshr i32 %209, 16
  %211 = trunc i32 %210 to i16
  %212 = mul nsw i16 %211, -3
  %213 = add nsw i16 %212, %207
  %214 = ashr i16 %213, 1
  %215 = and i16 %214, %213
  %216 = add i16 %215, -1
  %217 = and i16 %216, %213
  %218 = lshr i16 %217, 1
  %219 = xor i16 %218, 1
  %220 = add nsw i16 %219, -1
  %221 = or i16 %220, %217
  %222 = getelementptr inbounds [704 x i16], [704 x i16]* %124, i64 0, i64 699
  store i16 %221, i16* %222, align 2
  %223 = getelementptr inbounds [704 x i16], [704 x i16]* %124, i64 0, i64 700
  store i16 0, i16* %223, align 8
  call fastcc void @poly_lift(%struct.poly* nonnull %11, %struct.poly* nonnull %7)
  %224 = bitcast %struct.poly* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %224) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %224, i8 -86, i64 1408, i1 false)
  %225 = getelementptr inbounds [704 x i16], [704 x i16]* %124, i64 0, i64 701
  %226 = bitcast i16* %225 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %226, i8 0, i64 6, i1 false) #5
  %227 = inttoptr i64 %20 to [704 x i16]*
  %228 = getelementptr inbounds [704 x i16], [704 x i16]* %227, i64 0, i64 701
  %229 = bitcast i16* %228 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %229, i8 0, i64 6, i1 false) #5
  %230 = bitcast [176 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %230) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %230, i8 -86, i64 2816, i1 false) #5
  %231 = bitcast [172 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %231) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %231, i8 -86, i64 2752, i1 false) #5
  %232 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 0
  %233 = getelementptr inbounds [172 x <2 x i64>], [172 x <2 x i64>]* %6, i64 0, i64 0
  %234 = getelementptr inbounds %struct.poly, %struct.poly* %9, i64 0, i32 0, i32 0, i64 0
  %235 = getelementptr inbounds %struct.public_key, %struct.public_key* %121, i64 0, i32 0, i32 0, i32 0, i64 0
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %232, <2 x i64>* nonnull %233, <2 x i64>* nonnull %234, <2 x i64>* %235, i64 88) #5
  %236 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 87
  %237 = bitcast <2 x i64>* %236 to <16 x i8>*
  %238 = load <16 x i8>, <16 x i8>* %237, align 16
  br label %239

239:                                              ; preds = %239, %149
  %240 = phi <16 x i8> [ %238, %149 ], [ %260, %239 ]
  %241 = phi i64 [ 0, %149 ], [ %271, %239 ]
  %242 = add nuw nsw i64 %241, 88
  %243 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %242
  %244 = bitcast <2 x i64>* %243 to <16 x i8>*
  %245 = load <16 x i8>, <16 x i8>* %244, align 16
  %246 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %241
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = shufflevector <16 x i8> %240, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %250 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %245, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %251 = or <16 x i8> %250, %249
  %252 = bitcast <16 x i8> %251 to <8 x i16>
  %253 = add <8 x i16> %248, %252
  %254 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 %241
  %255 = bitcast <2 x i64>* %254 to <8 x i16>*
  store <8 x i16> %253, <8 x i16>* %255, align 16
  %256 = or i64 %241, 1
  %257 = add nuw nsw i64 %241, 89
  %258 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %257
  %259 = bitcast <2 x i64>* %258 to <16 x i8>*
  %260 = load <16 x i8>, <16 x i8>* %259, align 16
  %261 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %256
  %262 = bitcast <2 x i64>* %261 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <16 x i8> %245, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %265 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %260, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %266 = or <16 x i8> %265, %264
  %267 = bitcast <16 x i8> %266 to <8 x i16>
  %268 = add <8 x i16> %263, %267
  %269 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 %256
  %270 = bitcast <2 x i64>* %269 to <8 x i16>*
  store <8 x i16> %268, <8 x i16>* %270, align 16
  %271 = add nuw nsw i64 %241, 2
  %272 = icmp eq i64 %271, 88
  br i1 %272, label %273, label %239

273:                                              ; preds = %239
  %274 = bitcast %struct.poly* %12 to [704 x i16]*
  %275 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 701
  %276 = bitcast i16* %275 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %276, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %231) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %230) #5
  %277 = bitcast %struct.poly* %11 to [704 x i16]*
  br label %278

278:                                              ; preds = %581, %273
  %279 = phi i64 [ 0, %273 ], [ %598, %581 ]
  %280 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 %279
  %281 = bitcast i16* %280 to <8 x i16>*
  %282 = load <8 x i16>, <8 x i16>* %281, align 16
  %283 = getelementptr inbounds i16, i16* %280, i64 8
  %284 = bitcast i16* %283 to <8 x i16>*
  %285 = load <8 x i16>, <8 x i16>* %284, align 16
  %286 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 %279
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %286, i64 8
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = add <8 x i16> %288, %282
  %293 = add <8 x i16> %291, %285
  %294 = bitcast i16* %286 to <8 x i16>*
  store <8 x i16> %292, <8 x i16>* %294, align 16
  %295 = bitcast i16* %289 to <8 x i16>*
  store <8 x i16> %293, <8 x i16>* %295, align 16
  %296 = or i64 %279, 16
  %297 = icmp eq i64 %296, 688
  br i1 %297, label %501, label %581, !llvm.loop !14

298:                                              ; preds = %501
  %299 = getelementptr inbounds %struct.poly, %struct.poly* %7, i64 0, i32 0, i32 0, i64 85
  %300 = bitcast <2 x i64>* %299 to i16*
  br label %301

301:                                              ; preds = %301, %298
  %302 = phi i64 [ 0, %298 ], [ %342, %301 ]
  %303 = mul i64 %302, 5
  %304 = getelementptr i16, i16* %573, i64 %303
  %305 = bitcast i16* %304 to <40 x i16>*
  %306 = load <40 x i16>, <40 x i16>* %305, align 16
  %307 = shufflevector <40 x i16> %306, <40 x i16> undef, <8 x i32> <i32 0, i32 5, i32 10, i32 15, i32 20, i32 25, i32 30, i32 35>
  %308 = shufflevector <40 x i16> %306, <40 x i16> undef, <8 x i32> <i32 1, i32 6, i32 11, i32 16, i32 21, i32 26, i32 31, i32 36>
  %309 = shufflevector <40 x i16> %306, <40 x i16> undef, <8 x i32> <i32 2, i32 7, i32 12, i32 17, i32 22, i32 27, i32 32, i32 37>
  %310 = shufflevector <40 x i16> %306, <40 x i16> undef, <8 x i32> <i32 3, i32 8, i32 13, i32 18, i32 23, i32 28, i32 33, i32 38>
  %311 = shufflevector <40 x i16> %306, <40 x i16> undef, <8 x i32> <i32 4, i32 9, i32 14, i32 19, i32 24, i32 29, i32 34, i32 39>
  %312 = and <8 x i16> %307, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %313 = lshr <8 x i16> %312, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %314 = xor <8 x i16> %313, %312
  %315 = and <8 x i16> %308, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %316 = lshr <8 x i16> %315, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %317 = xor <8 x i16> %316, %315
  %318 = and <8 x i16> %309, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %319 = lshr <8 x i16> %318, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %320 = xor <8 x i16> %319, %318
  %321 = and <8 x i16> %310, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %322 = lshr <8 x i16> %321, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %323 = xor <8 x i16> %322, %321
  %324 = and <8 x i16> %311, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %325 = lshr <8 x i16> %324, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %326 = xor <8 x i16> %325, %324
  %327 = trunc <8 x i16> %314 to <8 x i8>
  %328 = trunc <8 x i16> %317 to <8 x i8>
  %329 = mul nuw nsw <8 x i8> %328, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %330 = add nuw nsw <8 x i8> %329, %327
  %331 = trunc <8 x i16> %320 to <8 x i8>
  %332 = mul nuw nsw <8 x i8> %331, <i8 9, i8 9, i8 9, i8 9, i8 9, i8 9, i8 9, i8 9>
  %333 = add nuw nsw <8 x i8> %330, %332
  %334 = trunc <8 x i16> %323 to <8 x i8>
  %335 = mul nuw nsw <8 x i8> %334, <i8 27, i8 27, i8 27, i8 27, i8 27, i8 27, i8 27, i8 27>
  %336 = add <8 x i8> %333, %335
  %337 = trunc <8 x i16> %326 to <8 x i8>
  %338 = mul nuw <8 x i8> %337, <i8 81, i8 81, i8 81, i8 81, i8 81, i8 81, i8 81, i8 81>
  %339 = add <8 x i8> %336, %338
  %340 = getelementptr inbounds [140 x i8], [140 x i8]* %13, i64 0, i64 %302
  %341 = bitcast i8* %340 to <8 x i8>*
  store <8 x i8> %339, <8 x i8>* %341, align 8, !alias.scope !15, !noalias !18
  %342 = add i64 %302, 8
  %343 = icmp eq i64 %342, 136
  br i1 %343, label %344, label %301, !llvm.loop !20

344:                                              ; preds = %301, %501
  %345 = phi i16* [ %573, %501 ], [ %300, %301 ]
  %346 = phi i64 [ 0, %501 ], [ 136, %301 ]
  br label %347

347:                                              ; preds = %344, %347
  %348 = phi i16* [ %388, %347 ], [ %345, %344 ]
  %349 = phi i64 [ %389, %347 ], [ %346, %344 ]
  %350 = load i16, i16* %348, align 2
  %351 = and i16 %350, 3
  %352 = lshr i16 %351, 1
  %353 = xor i16 %352, %351
  %354 = getelementptr inbounds i16, i16* %348, i64 1
  %355 = load i16, i16* %354, align 2
  %356 = and i16 %355, 3
  %357 = lshr i16 %356, 1
  %358 = xor i16 %357, %356
  %359 = getelementptr inbounds i16, i16* %348, i64 2
  %360 = load i16, i16* %359, align 2
  %361 = and i16 %360, 3
  %362 = lshr i16 %361, 1
  %363 = xor i16 %362, %361
  %364 = getelementptr inbounds i16, i16* %348, i64 3
  %365 = load i16, i16* %364, align 2
  %366 = and i16 %365, 3
  %367 = lshr i16 %366, 1
  %368 = xor i16 %367, %366
  %369 = getelementptr inbounds i16, i16* %348, i64 4
  %370 = load i16, i16* %369, align 2
  %371 = and i16 %370, 3
  %372 = lshr i16 %371, 1
  %373 = xor i16 %372, %371
  %374 = trunc i16 %353 to i8
  %375 = trunc i16 %358 to i8
  %376 = mul nuw nsw i8 %375, 3
  %377 = add nuw nsw i8 %376, %374
  %378 = trunc i16 %363 to i8
  %379 = mul nuw nsw i8 %378, 9
  %380 = add nuw nsw i8 %377, %379
  %381 = trunc i16 %368 to i8
  %382 = mul nuw nsw i8 %381, 27
  %383 = add i8 %380, %382
  %384 = trunc i16 %373 to i8
  %385 = mul nuw i8 %384, 81
  %386 = add i8 %383, %385
  %387 = getelementptr inbounds [140 x i8], [140 x i8]* %13, i64 0, i64 %349
  store i8 %386, i8* %387, align 1
  %388 = getelementptr inbounds i16, i16* %348, i64 5
  %389 = add nuw nsw i64 %349, 1
  %390 = icmp eq i64 %389, 140
  br i1 %390, label %391, label %347, !llvm.loop !21

391:                                              ; preds = %347
  %392 = bitcast %struct.poly* %9 to i16*
  %393 = getelementptr inbounds [140 x i8], [140 x i8]* %15, i64 1, i64 0
  %394 = getelementptr inbounds %struct.poly, %struct.poly* %9, i64 0, i32 0, i32 0, i64 87
  %395 = bitcast <2 x i64>* %394 to i8*
  %396 = getelementptr inbounds i8, i8* %395, i64 8
  %397 = icmp ult i8* %16, %396
  %398 = icmp ugt i8* %393, %10
  %399 = and i1 %397, %398
  br i1 %399, label %446, label %400

400:                                              ; preds = %391
  %401 = getelementptr inbounds %struct.poly, %struct.poly* %9, i64 0, i32 0, i32 0, i64 85
  %402 = bitcast <2 x i64>* %401 to i16*
  br label %403

403:                                              ; preds = %403, %400
  %404 = phi i64 [ 0, %400 ], [ %444, %403 ]
  %405 = mul i64 %404, 5
  %406 = getelementptr i16, i16* %392, i64 %405
  %407 = bitcast i16* %406 to <40 x i16>*
  %408 = load <40 x i16>, <40 x i16>* %407, align 16
  %409 = shufflevector <40 x i16> %408, <40 x i16> undef, <8 x i32> <i32 0, i32 5, i32 10, i32 15, i32 20, i32 25, i32 30, i32 35>
  %410 = shufflevector <40 x i16> %408, <40 x i16> undef, <8 x i32> <i32 1, i32 6, i32 11, i32 16, i32 21, i32 26, i32 31, i32 36>
  %411 = shufflevector <40 x i16> %408, <40 x i16> undef, <8 x i32> <i32 2, i32 7, i32 12, i32 17, i32 22, i32 27, i32 32, i32 37>
  %412 = shufflevector <40 x i16> %408, <40 x i16> undef, <8 x i32> <i32 3, i32 8, i32 13, i32 18, i32 23, i32 28, i32 33, i32 38>
  %413 = shufflevector <40 x i16> %408, <40 x i16> undef, <8 x i32> <i32 4, i32 9, i32 14, i32 19, i32 24, i32 29, i32 34, i32 39>
  %414 = and <8 x i16> %409, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %415 = lshr <8 x i16> %414, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %416 = xor <8 x i16> %415, %414
  %417 = and <8 x i16> %410, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %418 = lshr <8 x i16> %417, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %419 = xor <8 x i16> %418, %417
  %420 = and <8 x i16> %411, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %421 = lshr <8 x i16> %420, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %422 = xor <8 x i16> %421, %420
  %423 = and <8 x i16> %412, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %424 = lshr <8 x i16> %423, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %425 = xor <8 x i16> %424, %423
  %426 = and <8 x i16> %413, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %427 = lshr <8 x i16> %426, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %428 = xor <8 x i16> %427, %426
  %429 = trunc <8 x i16> %416 to <8 x i8>
  %430 = trunc <8 x i16> %419 to <8 x i8>
  %431 = mul nuw nsw <8 x i8> %430, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %432 = add nuw nsw <8 x i8> %431, %429
  %433 = trunc <8 x i16> %422 to <8 x i8>
  %434 = mul nuw nsw <8 x i8> %433, <i8 9, i8 9, i8 9, i8 9, i8 9, i8 9, i8 9, i8 9>
  %435 = add nuw nsw <8 x i8> %432, %434
  %436 = trunc <8 x i16> %425 to <8 x i8>
  %437 = mul nuw nsw <8 x i8> %436, <i8 27, i8 27, i8 27, i8 27, i8 27, i8 27, i8 27, i8 27>
  %438 = add <8 x i8> %435, %437
  %439 = trunc <8 x i16> %428 to <8 x i8>
  %440 = mul nuw <8 x i8> %439, <i8 81, i8 81, i8 81, i8 81, i8 81, i8 81, i8 81, i8 81>
  %441 = add <8 x i8> %438, %440
  %442 = getelementptr inbounds [140 x i8], [140 x i8]* %15, i64 0, i64 %404
  %443 = bitcast i8* %442 to <8 x i8>*
  store <8 x i8> %441, <8 x i8>* %443, align 8, !alias.scope !22, !noalias !25
  %444 = add i64 %404, 8
  %445 = icmp eq i64 %444, 136
  br i1 %445, label %446, label %403, !llvm.loop !27

446:                                              ; preds = %403, %391
  %447 = phi i16* [ %392, %391 ], [ %402, %403 ]
  %448 = phi i64 [ 0, %391 ], [ 136, %403 ]
  br label %449

449:                                              ; preds = %446, %449
  %450 = phi i16* [ %490, %449 ], [ %447, %446 ]
  %451 = phi i64 [ %491, %449 ], [ %448, %446 ]
  %452 = load i16, i16* %450, align 2
  %453 = and i16 %452, 3
  %454 = lshr i16 %453, 1
  %455 = xor i16 %454, %453
  %456 = getelementptr inbounds i16, i16* %450, i64 1
  %457 = load i16, i16* %456, align 2
  %458 = and i16 %457, 3
  %459 = lshr i16 %458, 1
  %460 = xor i16 %459, %458
  %461 = getelementptr inbounds i16, i16* %450, i64 2
  %462 = load i16, i16* %461, align 2
  %463 = and i16 %462, 3
  %464 = lshr i16 %463, 1
  %465 = xor i16 %464, %463
  %466 = getelementptr inbounds i16, i16* %450, i64 3
  %467 = load i16, i16* %466, align 2
  %468 = and i16 %467, 3
  %469 = lshr i16 %468, 1
  %470 = xor i16 %469, %468
  %471 = getelementptr inbounds i16, i16* %450, i64 4
  %472 = load i16, i16* %471, align 2
  %473 = and i16 %472, 3
  %474 = lshr i16 %473, 1
  %475 = xor i16 %474, %473
  %476 = trunc i16 %455 to i8
  %477 = trunc i16 %460 to i8
  %478 = mul nuw nsw i8 %477, 3
  %479 = add nuw nsw i8 %478, %476
  %480 = trunc i16 %465 to i8
  %481 = mul nuw nsw i8 %480, 9
  %482 = add nuw nsw i8 %479, %481
  %483 = trunc i16 %470 to i8
  %484 = mul nuw nsw i8 %483, 27
  %485 = add i8 %482, %484
  %486 = trunc i16 %475 to i8
  %487 = mul nuw i8 %486, 81
  %488 = add i8 %485, %487
  %489 = getelementptr inbounds [140 x i8], [140 x i8]* %15, i64 0, i64 %451
  store i8 %488, i8* %489, align 1
  %490 = getelementptr inbounds i16, i16* %450, i64 5
  %491 = add nuw nsw i64 %451, 1
  %492 = icmp eq i64 %491, 140
  br i1 %492, label %493, label %449, !llvm.loop !28

493:                                              ; preds = %449
  %494 = bitcast %struct.sha256_state_st* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 112, i8* nonnull %494) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %494, i8 -86, i64 112, i1 false)
  %495 = call i32 @SHA256_Init(%struct.sha256_state_st* nonnull %17) #5
  %496 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %17, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @kSharedKey, i64 0, i64 0), i64 11) #5
  %497 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %17, i8* nonnull %571, i64 140) #5
  %498 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %17, i8* nonnull %572, i64 140) #5
  %499 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %17, i8* %0, i64 1138) #5
  %500 = call i32 @SHA256_Final(i8* %1, %struct.sha256_state_st* nonnull %17) #5
  call void @llvm.lifetime.end.p0i8(i64 112, i8* nonnull %494) #5
  call void @llvm.lifetime.end.p0i8(i64 140, i8* nonnull %572) #5
  call void @llvm.lifetime.end.p0i8(i64 140, i8* nonnull %571) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %224) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %21) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %10) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %8) #5
  ret void

501:                                              ; preds = %278
  %502 = getelementptr inbounds %struct.poly, %struct.poly* %11, i64 0, i32 0, i32 0, i64 86
  %503 = bitcast <2 x i64>* %502 to i16*
  %504 = load i16, i16* %503, align 16
  %505 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 86
  %506 = bitcast <2 x i64>* %505 to i16*
  %507 = load i16, i16* %506, align 16
  %508 = add i16 %507, %504
  store i16 %508, i16* %506, align 16
  %509 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 689
  %510 = load i16, i16* %509, align 2
  %511 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 689
  %512 = load i16, i16* %511, align 2
  %513 = add i16 %512, %510
  store i16 %513, i16* %511, align 2
  %514 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 690
  %515 = load i16, i16* %514, align 4
  %516 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 690
  %517 = load i16, i16* %516, align 4
  %518 = add i16 %517, %515
  store i16 %518, i16* %516, align 4
  %519 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 691
  %520 = load i16, i16* %519, align 2
  %521 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 691
  %522 = load i16, i16* %521, align 2
  %523 = add i16 %522, %520
  store i16 %523, i16* %521, align 2
  %524 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 692
  %525 = load i16, i16* %524, align 8
  %526 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 692
  %527 = load i16, i16* %526, align 8
  %528 = add i16 %527, %525
  store i16 %528, i16* %526, align 8
  %529 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 693
  %530 = load i16, i16* %529, align 2
  %531 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 693
  %532 = load i16, i16* %531, align 2
  %533 = add i16 %532, %530
  store i16 %533, i16* %531, align 2
  %534 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 694
  %535 = load i16, i16* %534, align 4
  %536 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 694
  %537 = load i16, i16* %536, align 4
  %538 = add i16 %537, %535
  store i16 %538, i16* %536, align 4
  %539 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 695
  %540 = load i16, i16* %539, align 2
  %541 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 695
  %542 = load i16, i16* %541, align 2
  %543 = add i16 %542, %540
  store i16 %543, i16* %541, align 2
  %544 = getelementptr inbounds %struct.poly, %struct.poly* %11, i64 0, i32 0, i32 0, i64 87
  %545 = bitcast <2 x i64>* %544 to i16*
  %546 = load i16, i16* %545, align 16
  %547 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 87
  %548 = bitcast <2 x i64>* %547 to i16*
  %549 = load i16, i16* %548, align 16
  %550 = add i16 %549, %546
  store i16 %550, i16* %548, align 16
  %551 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 697
  %552 = load i16, i16* %551, align 2
  %553 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 697
  %554 = load i16, i16* %553, align 2
  %555 = add i16 %554, %552
  store i16 %555, i16* %553, align 2
  %556 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 698
  %557 = load i16, i16* %556, align 4
  %558 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 698
  %559 = load i16, i16* %558, align 4
  %560 = add i16 %559, %557
  store i16 %560, i16* %558, align 4
  %561 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 699
  %562 = load i16, i16* %561, align 2
  %563 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 699
  %564 = load i16, i16* %563, align 2
  %565 = add i16 %564, %562
  store i16 %565, i16* %563, align 2
  %566 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 700
  %567 = load i16, i16* %566, align 8
  %568 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 700
  %569 = load i16, i16* %568, align 8
  %570 = add i16 %569, %567
  store i16 %570, i16* %568, align 8
  call fastcc void @poly_marshal(i8* %0, %struct.poly* nonnull %12)
  %571 = getelementptr inbounds [140 x i8], [140 x i8]* %13, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 140, i8* nonnull %571) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %571, i8 -86, i64 140, i1 false)
  %572 = getelementptr inbounds [140 x i8], [140 x i8]* %15, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 140, i8* nonnull %572) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %572, i8 -86, i64 140, i1 false)
  %573 = bitcast %struct.poly* %7 to i16*
  %574 = getelementptr inbounds [140 x i8], [140 x i8]* %13, i64 1, i64 0
  %575 = getelementptr inbounds %struct.poly, %struct.poly* %7, i64 0, i32 0, i32 0, i64 87
  %576 = bitcast <2 x i64>* %575 to i8*
  %577 = getelementptr inbounds i8, i8* %576, i64 8
  %578 = icmp ult i8* %14, %577
  %579 = icmp ugt i8* %574, %8
  %580 = and i1 %578, %579
  br i1 %580, label %344, label %298

581:                                              ; preds = %278
  %582 = getelementptr inbounds [704 x i16], [704 x i16]* %277, i64 0, i64 %296
  %583 = bitcast i16* %582 to <8 x i16>*
  %584 = load <8 x i16>, <8 x i16>* %583, align 16
  %585 = getelementptr inbounds i16, i16* %582, i64 8
  %586 = bitcast i16* %585 to <8 x i16>*
  %587 = load <8 x i16>, <8 x i16>* %586, align 16
  %588 = getelementptr inbounds [704 x i16], [704 x i16]* %274, i64 0, i64 %296
  %589 = bitcast i16* %588 to <8 x i16>*
  %590 = load <8 x i16>, <8 x i16>* %589, align 16
  %591 = getelementptr inbounds i16, i16* %588, i64 8
  %592 = bitcast i16* %591 to <8 x i16>*
  %593 = load <8 x i16>, <8 x i16>* %592, align 16
  %594 = add <8 x i16> %590, %584
  %595 = add <8 x i16> %593, %587
  %596 = bitcast i16* %588 to <8 x i16>*
  store <8 x i16> %594, <8 x i16>* %596, align 16
  %597 = bitcast i16* %591 to <8 x i16>*
  store <8 x i16> %595, <8 x i16>* %597, align 16
  %598 = add nuw nsw i64 %279, 32
  br label %278
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal fastcc void @poly_lift(%struct.poly* nocapture, %struct.poly* nocapture readonly) unnamed_addr #3 {
  %3 = bitcast %struct.poly* %1 to [704 x i16]*
  %4 = bitcast %struct.poly* %1 to i16*
  %5 = load i16, i16* %4, align 16
  %6 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 2
  %7 = load i16, i16* %6, align 4
  %8 = add i16 %7, %5
  %9 = bitcast %struct.poly* %0 to [704 x i16]*
  %10 = bitcast %struct.poly* %0 to i16*
  store i16 %8, i16* %10, align 16
  %11 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 1
  %12 = load i16, i16* %11, align 2
  %13 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 1
  store i16 %12, i16* %13, align 2
  %14 = load i16, i16* %4, align 16
  %15 = load i16, i16* %6, align 4
  %16 = sub i16 %15, %14
  %17 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 2
  store i16 %16, i16* %17, align 4
  br label %31

18:                                               ; preds = %31
  %19 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 699
  %20 = load i16, i16* %19, align 2
  %21 = trunc i32 %61 to i16
  %22 = sub i16 %21, %20
  %23 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 700
  %24 = load i16, i16* %23, align 8
  %25 = trunc i32 %67 to i16
  %26 = add i16 %24, %25
  %27 = add i16 %22, %8
  store i16 %27, i16* %10, align 16
  %28 = sub i16 %12, %22
  %29 = sub i16 %28, %26
  store i16 %29, i16* %13, align 2
  %30 = add i16 %26, %16
  store i16 %30, i16* %17, align 4
  br label %99

31:                                               ; preds = %31, %2
  %32 = phi i32 [ 0, %2 ], [ %69, %31 ]
  %33 = phi i64 [ 3, %2 ], [ %68, %31 ]
  %34 = phi i32 [ 0, %2 ], [ %70, %31 ]
  %35 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %33
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = add nuw nsw i64 %33, 2
  %39 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = sub nsw i32 %32, %37
  %43 = add nsw i32 %42, %41
  %44 = add nuw nsw i64 %33, 1
  %45 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = sub nsw i32 %34, %41
  %49 = add nsw i32 %48, %47
  %50 = add nuw nsw i64 %33, 3
  %51 = and i32 %43, 65535
  %52 = and i32 %49, 65535
  %53 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %50
  %54 = load i16, i16* %53, align 2
  %55 = zext i16 %54 to i32
  %56 = add nuw nsw i64 %33, 5
  %57 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %56
  %58 = load i16, i16* %57, align 2
  %59 = zext i16 %58 to i32
  %60 = sub nsw i32 %51, %55
  %61 = add nsw i32 %60, %59
  %62 = add nuw nsw i64 %33, 4
  %63 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %62
  %64 = load i16, i16* %63, align 2
  %65 = zext i16 %64 to i32
  %66 = sub nsw i32 %52, %59
  %67 = add nsw i32 %66, %65
  %68 = add nuw nsw i64 %33, 6
  %69 = and i32 %61, 65535
  %70 = and i32 %67, 65535
  %71 = icmp ult i64 %68, 699
  br i1 %71, label %31, label %18

72:                                               ; preds = %99
  %73 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 700
  %74 = load i16, i16* %73, align 8
  %75 = insertelement <8 x i16> undef, i16 %74, i32 0
  %76 = shufflevector <8 x i16> %75, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %77

77:                                               ; preds = %77, %72
  %78 = phi i64 [ 0, %72 ], [ %97, %77 ]
  %79 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %78
  %80 = bitcast i16* %79 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 2
  %82 = sub <8 x i16> %81, %76
  %83 = sext <8 x i16> %82 to <8 x i32>
  %84 = mul nsw <8 x i32> %83, <i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845, i32 21845>
  %85 = lshr <8 x i32> %84, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %86 = trunc <8 x i32> %85 to <8 x i16>
  %87 = mul <8 x i16> %86, <i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3, i16 -3>
  %88 = add <8 x i16> %87, %82
  %89 = ashr <8 x i16> %88, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %90 = and <8 x i16> %89, %88
  %91 = add <8 x i16> %90, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %92 = and <8 x i16> %91, %88
  %93 = lshr <8 x i16> %92, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %94 = sub nsw <8 x i16> zeroinitializer, %93
  %95 = or <8 x i16> %92, %94
  %96 = bitcast i16* %79 to <8 x i16>*
  store <8 x i16> %95, <8 x i16>* %96, align 2
  %97 = add i64 %78, 8
  %98 = icmp eq i64 %97, 696
  br i1 %98, label %165, label %77, !llvm.loop !29

99:                                               ; preds = %99, %18
  %100 = phi i64 [ 3, %18 ], [ %131, %99 ]
  %101 = add nsw i64 %100, -3
  %102 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = add nsw i64 %100, -2
  %105 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %104
  %106 = load i16, i16* %105, align 2
  %107 = add nsw i64 %100, -1
  %108 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %107
  %109 = load i16, i16* %108, align 2
  %110 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %100
  %111 = load i16, i16* %110, align 2
  %112 = sub i16 %103, %106
  %113 = sub i16 %112, %109
  %114 = sub i16 %113, %111
  %115 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %100
  store i16 %114, i16* %115, align 2
  %116 = add nuw nsw i64 %100, 1
  %117 = add nsw i64 %100, -2
  %118 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %117
  %119 = load i16, i16* %118, align 2
  %120 = add nsw i64 %100, -1
  %121 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %120
  %122 = load i16, i16* %121, align 2
  %123 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %100
  %124 = load i16, i16* %123, align 2
  %125 = getelementptr inbounds [704 x i16], [704 x i16]* %3, i64 0, i64 %116
  %126 = load i16, i16* %125, align 2
  %127 = sub i16 %119, %122
  %128 = sub i16 %127, %124
  %129 = sub i16 %128, %126
  %130 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %116
  store i16 %129, i16* %130, align 2
  %131 = add nuw nsw i64 %100, 2
  %132 = icmp eq i64 %131, 701
  br i1 %132, label %72, label %99

133:                                              ; preds = %133, %165
  %134 = phi i16 [ %246, %165 ], [ %158, %133 ]
  %135 = phi i64 [ 700, %165 ], [ %156, %133 ]
  %136 = add nsw i64 %135, -1
  %137 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %136
  %138 = load i16, i16* %137, align 2
  %139 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %135
  %140 = sub i16 %138, %134
  store i16 %140, i16* %139, align 2
  %141 = add nsw i64 %135, -2
  %142 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %141
  %143 = load i16, i16* %142, align 2
  %144 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %136
  %145 = sub i16 %143, %138
  store i16 %145, i16* %144, align 2
  %146 = add nsw i64 %135, -3
  %147 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %141
  %150 = sub i16 %148, %143
  store i16 %150, i16* %149, align 2
  %151 = add nsw i64 %135, -4
  %152 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %151
  %153 = load i16, i16* %152, align 2
  %154 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %146
  %155 = sub i16 %153, %148
  store i16 %155, i16* %154, align 2
  %156 = add nsw i64 %135, -5
  %157 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 %151
  %160 = sub i16 %158, %153
  store i16 %160, i16* %159, align 2
  %161 = icmp eq i64 %156, 0
  br i1 %161, label %162, label %133

162:                                              ; preds = %133
  %163 = load i16, i16* %10, align 16
  %164 = sub i16 %246, %163
  store i16 %164, i16* %10, align 16
  ret void

165:                                              ; preds = %77
  %166 = getelementptr inbounds %struct.poly, %struct.poly* %0, i64 0, i32 0, i32 0, i64 87
  %167 = bitcast <2 x i64>* %166 to i16*
  %168 = load i16, i16* %167, align 2
  %169 = sub i16 %168, %74
  %170 = sext i16 %169 to i32
  %171 = mul nsw i32 %170, 21845
  %172 = lshr i32 %171, 16
  %173 = trunc i32 %172 to i16
  %174 = mul i16 %173, -3
  %175 = add i16 %174, %169
  %176 = ashr i16 %175, 1
  %177 = and i16 %176, %175
  %178 = add i16 %177, -1
  %179 = and i16 %178, %175
  %180 = lshr i16 %179, 1
  %181 = sub nsw i16 0, %180
  %182 = or i16 %179, %181
  store i16 %182, i16* %167, align 2
  %183 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 697
  %184 = load i16, i16* %183, align 2
  %185 = sub i16 %184, %74
  %186 = sext i16 %185 to i32
  %187 = mul nsw i32 %186, 21845
  %188 = lshr i32 %187, 16
  %189 = trunc i32 %188 to i16
  %190 = mul i16 %189, -3
  %191 = add i16 %190, %185
  %192 = ashr i16 %191, 1
  %193 = and i16 %192, %191
  %194 = add i16 %193, -1
  %195 = and i16 %194, %191
  %196 = lshr i16 %195, 1
  %197 = sub nsw i16 0, %196
  %198 = or i16 %195, %197
  store i16 %198, i16* %183, align 2
  %199 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 698
  %200 = load i16, i16* %199, align 2
  %201 = sub i16 %200, %74
  %202 = sext i16 %201 to i32
  %203 = mul nsw i32 %202, 21845
  %204 = lshr i32 %203, 16
  %205 = trunc i32 %204 to i16
  %206 = mul i16 %205, -3
  %207 = add i16 %206, %201
  %208 = ashr i16 %207, 1
  %209 = and i16 %208, %207
  %210 = add i16 %209, -1
  %211 = and i16 %210, %207
  %212 = lshr i16 %211, 1
  %213 = sub nsw i16 0, %212
  %214 = or i16 %211, %213
  store i16 %214, i16* %199, align 2
  %215 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 699
  %216 = load i16, i16* %215, align 2
  %217 = sub i16 %216, %74
  %218 = sext i16 %217 to i32
  %219 = mul nsw i32 %218, 21845
  %220 = lshr i32 %219, 16
  %221 = trunc i32 %220 to i16
  %222 = mul i16 %221, -3
  %223 = add i16 %222, %217
  %224 = ashr i16 %223, 1
  %225 = and i16 %224, %223
  %226 = add i16 %225, -1
  %227 = and i16 %226, %223
  %228 = lshr i16 %227, 1
  %229 = sub nsw i16 0, %228
  %230 = or i16 %227, %229
  store i16 %230, i16* %215, align 2
  %231 = getelementptr inbounds [704 x i16], [704 x i16]* %9, i64 0, i64 700
  %232 = load i16, i16* %231, align 2
  %233 = sub i16 %232, %74
  %234 = sext i16 %233 to i32
  %235 = mul nsw i32 %234, 21845
  %236 = lshr i32 %235, 16
  %237 = trunc i32 %236 to i16
  %238 = mul i16 %237, -3
  %239 = add i16 %238, %233
  %240 = ashr i16 %239, 1
  %241 = and i16 %240, %239
  %242 = add i16 %241, -1
  %243 = and i16 %242, %239
  %244 = lshr i16 %243, 1
  %245 = sub nsw i16 0, %244
  %246 = or i16 %243, %245
  store i16 %246, i16* %231, align 2
  br label %133
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal fastcc void @poly_marshal(i8* nocapture, %struct.poly* nocapture readonly) unnamed_addr #3 {
  %3 = bitcast %struct.poly* %1 to i16*
  br label %4

4:                                                ; preds = %52, %2
  %5 = phi i8* [ %0, %2 ], [ %100, %52 ]
  %6 = phi i16* [ %3, %2 ], [ %99, %52 ]
  %7 = phi i64 [ 0, %2 ], [ %101, %52 ]
  %8 = load i16, i16* %6, align 2
  %9 = trunc i16 %8 to i8
  store i8 %9, i8* %5, align 1
  %10 = load i16, i16* %6, align 2
  %11 = lshr i16 %10, 8
  %12 = and i16 %11, 31
  %13 = getelementptr inbounds i16, i16* %6, i64 1
  %14 = load i16, i16* %13, align 2
  %15 = shl i16 %14, 5
  %16 = or i16 %12, %15
  %17 = trunc i16 %16 to i8
  %18 = getelementptr inbounds i8, i8* %5, i64 1
  store i8 %17, i8* %18, align 1
  %19 = load i16, i16* %13, align 2
  %20 = lshr i16 %19, 3
  %21 = trunc i16 %20 to i8
  %22 = getelementptr inbounds i8, i8* %5, i64 2
  store i8 %21, i8* %22, align 1
  %23 = load i16, i16* %13, align 2
  %24 = lshr i16 %23, 11
  %25 = and i16 %24, 3
  %26 = getelementptr inbounds i16, i16* %6, i64 2
  %27 = load i16, i16* %26, align 2
  %28 = shl i16 %27, 2
  %29 = or i16 %25, %28
  %30 = trunc i16 %29 to i8
  %31 = getelementptr inbounds i8, i8* %5, i64 3
  store i8 %30, i8* %31, align 1
  %32 = load i16, i16* %26, align 2
  %33 = lshr i16 %32, 6
  %34 = and i16 %33, 127
  %35 = getelementptr inbounds i16, i16* %6, i64 3
  %36 = load i16, i16* %35, align 2
  %37 = shl i16 %36, 7
  %38 = or i16 %34, %37
  %39 = trunc i16 %38 to i8
  %40 = getelementptr inbounds i8, i8* %5, i64 4
  store i8 %39, i8* %40, align 1
  %41 = load i16, i16* %35, align 2
  %42 = lshr i16 %41, 1
  %43 = trunc i16 %42 to i8
  %44 = getelementptr inbounds i8, i8* %5, i64 5
  store i8 %43, i8* %44, align 1
  %45 = load i16, i16* %35, align 2
  %46 = lshr i16 %45, 9
  %47 = icmp eq i64 %7, 87
  br i1 %47, label %48, label %52

48:                                               ; preds = %4
  %49 = trunc i16 %46 to i8
  %50 = and i8 %49, 15
  %51 = getelementptr inbounds i8, i8* %5, i64 6
  store i8 %50, i8* %51, align 1
  ret void

52:                                               ; preds = %4
  %53 = and i16 %46, 15
  %54 = getelementptr inbounds i16, i16* %6, i64 4
  %55 = load i16, i16* %54, align 2
  %56 = shl i16 %55, 4
  %57 = or i16 %56, %53
  %58 = trunc i16 %57 to i8
  %59 = getelementptr inbounds i8, i8* %5, i64 6
  store i8 %58, i8* %59, align 1
  %60 = load i16, i16* %54, align 2
  %61 = lshr i16 %60, 4
  %62 = trunc i16 %61 to i8
  %63 = getelementptr inbounds i8, i8* %5, i64 7
  store i8 %62, i8* %63, align 1
  %64 = load i16, i16* %54, align 2
  %65 = lshr i16 %64, 12
  %66 = and i16 %65, 1
  %67 = getelementptr inbounds i16, i16* %6, i64 5
  %68 = load i16, i16* %67, align 2
  %69 = shl i16 %68, 1
  %70 = or i16 %66, %69
  %71 = trunc i16 %70 to i8
  %72 = getelementptr inbounds i8, i8* %5, i64 8
  store i8 %71, i8* %72, align 1
  %73 = load i16, i16* %67, align 2
  %74 = lshr i16 %73, 7
  %75 = and i16 %74, 63
  %76 = getelementptr inbounds i16, i16* %6, i64 6
  %77 = load i16, i16* %76, align 2
  %78 = shl i16 %77, 6
  %79 = or i16 %75, %78
  %80 = trunc i16 %79 to i8
  %81 = getelementptr inbounds i8, i8* %5, i64 9
  store i8 %80, i8* %81, align 1
  %82 = load i16, i16* %76, align 2
  %83 = lshr i16 %82, 2
  %84 = trunc i16 %83 to i8
  %85 = getelementptr inbounds i8, i8* %5, i64 10
  store i8 %84, i8* %85, align 1
  %86 = load i16, i16* %76, align 2
  %87 = lshr i16 %86, 10
  %88 = and i16 %87, 7
  %89 = getelementptr inbounds i16, i16* %6, i64 7
  %90 = load i16, i16* %89, align 2
  %91 = shl i16 %90, 3
  %92 = or i16 %88, %91
  %93 = trunc i16 %92 to i8
  %94 = getelementptr inbounds i8, i8* %5, i64 11
  store i8 %93, i8* %94, align 1
  %95 = load i16, i16* %89, align 2
  %96 = lshr i16 %95, 5
  %97 = trunc i16 %96 to i8
  %98 = getelementptr inbounds i8, i8* %5, i64 12
  store i8 %97, i8* %98, align 1
  %99 = getelementptr inbounds i16, i16* %6, i64 8
  %100 = getelementptr inbounds i8, i8* %5, i64 13
  %101 = add nuw nsw i64 %7, 1
  br label %4
}

declare i32 @SHA256_Init(%struct.sha256_state_st*) local_unnamed_addr #4

declare i32 @SHA256_Update(%struct.sha256_state_st*, i8*, i64) local_unnamed_addr #4

declare i32 @SHA256_Final(i8*, %struct.sha256_state_st*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @HRSS_decap(i8*, %struct.HRSS_private_key*, i8*, i64) local_unnamed_addr #2 {
  %5 = alloca [176 x <2 x i64>], align 16
  %6 = alloca [172 x <2 x i64>], align 16
  %7 = alloca [64 x i8], align 16
  %8 = alloca %struct.sha256_state_st, align 4
  %9 = alloca [32 x i8], align 16
  %10 = alloca %struct.poly, align 16
  %11 = alloca %struct.poly, align 16
  %12 = alloca %struct.poly, align 16
  %13 = alloca %struct.poly3, align 8
  %14 = alloca %struct.poly3, align 8
  %15 = alloca %struct.poly, align 16
  %16 = bitcast %struct.poly* %15 to i8*
  %17 = alloca %struct.poly, align 16
  %18 = alloca %struct.poly, align 16
  %19 = bitcast %struct.poly* %18 to i8*
  %20 = alloca %struct.poly3, align 8
  %21 = alloca [1138 x i8], align 16
  %22 = alloca [140 x i8], align 16
  %23 = getelementptr inbounds [140 x i8], [140 x i8]* %22, i64 0, i64 0
  %24 = alloca [140 x i8], align 16
  %25 = getelementptr inbounds [140 x i8], [140 x i8]* %24, i64 0, i64 0
  %26 = alloca [32 x i8], align 16
  %27 = ptrtoint %struct.HRSS_private_key* %1 to i64
  %28 = add i64 %27, 15
  %29 = and i64 %28, -16
  %30 = inttoptr i64 %29 to %struct.private_key*
  %31 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %31) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %31, i8 -86, i64 64, i1 false)
  %32 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 0
  %33 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 32
  %34 = getelementptr %struct.private_key, %struct.private_key* %30, i64 0, i32 3, i64 0
  %35 = getelementptr %struct.private_key, %struct.private_key* %30, i64 1
  %36 = bitcast %struct.private_key* %35 to i8*
  %37 = icmp ult i8* %32, %36
  %38 = icmp ult i8* %34, %33
  %39 = and i1 %37, %38
  br i1 %39, label %75, label %40

40:                                               ; preds = %4
  %41 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 3, i64 0
  %42 = bitcast i8* %41 to <16 x i8>*
  %43 = load <16 x i8>, <16 x i8>* %42, align 16, !alias.scope !30
  %44 = xor <16 x i8> %43, <i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54>
  %45 = bitcast [64 x i8]* %7 to <16 x i8>*
  store <16 x i8> %44, <16 x i8>* %45, align 16, !alias.scope !33, !noalias !30
  %46 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 3, i64 16
  %47 = bitcast i8* %46 to <16 x i8>*
  %48 = load <16 x i8>, <16 x i8>* %47, align 16, !alias.scope !30
  %49 = xor <16 x i8> %48, <i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54, i8 54>
  %50 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 16
  %51 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %49, <16 x i8>* %51, align 16, !alias.scope !33, !noalias !30
  br label %52

52:                                               ; preds = %75, %40
  %53 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 32
  call void @llvm.memset.p0i8.i64(i8* align 16 %53, i8 54, i64 32, i1 false) #5
  %54 = bitcast %struct.sha256_state_st* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 112, i8* nonnull %54) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %54, i8 -86, i64 112, i1 false)
  %55 = call i32 @SHA256_Init(%struct.sha256_state_st* nonnull %8) #5
  %56 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %8, i8* nonnull %31, i64 64) #5
  %57 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %8, i8* %2, i64 %3) #5
  %58 = getelementptr inbounds [32 x i8], [32 x i8]* %9, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %58) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %58, i8 -86, i64 32, i1 false)
  %59 = call i32 @SHA256_Final(i8* nonnull %58, %struct.sha256_state_st* nonnull %8) #5
  %60 = bitcast [64 x i8]* %7 to <16 x i8>*
  %61 = load <16 x i8>, <16 x i8>* %60, align 16
  %62 = xor <16 x i8> %61, <i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106>
  %63 = bitcast [64 x i8]* %7 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 16
  %64 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 16
  %65 = bitcast i8* %64 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 16
  %67 = xor <16 x i8> %66, <i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106, i8 106>
  %68 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %67, <16 x i8>* %68, align 16
  call void @llvm.memset.p0i8.i64(i8* align 16 %53, i8 92, i64 32, i1 false) #5
  %69 = call i32 @SHA256_Init(%struct.sha256_state_st* nonnull %8) #5
  %70 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %8, i8* nonnull %31, i64 64) #5
  %71 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %8, i8* nonnull %58, i64 32) #5
  %72 = call i32 @SHA256_Final(i8* %0, %struct.sha256_state_st* nonnull %8) #5
  %73 = bitcast %struct.poly* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %73) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %73, i8 -86, i64 1408, i1 false)
  %74 = icmp eq i64 %3, 1138
  br i1 %74, label %98, label %863

75:                                               ; preds = %4, %75
  %76 = phi i64 [ %96, %75 ], [ 0, %4 ]
  %77 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 3, i64 %76
  %78 = load i8, i8* %77, align 4
  %79 = xor i8 %78, 54
  %80 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 %76
  store i8 %79, i8* %80, align 4
  %81 = or i64 %76, 1
  %82 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 3, i64 %81
  %83 = load i8, i8* %82, align 1
  %84 = xor i8 %83, 54
  %85 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 %81
  store i8 %84, i8* %85, align 1
  %86 = or i64 %76, 2
  %87 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 3, i64 %86
  %88 = load i8, i8* %87, align 2
  %89 = xor i8 %88, 54
  %90 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 %86
  store i8 %89, i8* %90, align 2
  %91 = or i64 %76, 3
  %92 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 3, i64 %91
  %93 = load i8, i8* %92, align 1
  %94 = xor i8 %93, 54
  %95 = getelementptr inbounds [64 x i8], [64 x i8]* %7, i64 0, i64 %91
  store i8 %94, i8* %95, align 1
  %96 = add nuw nsw i64 %76, 4
  %97 = icmp eq i64 %96, 32
  br i1 %97, label %52, label %75, !llvm.loop !35

98:                                               ; preds = %52
  %99 = call fastcc i32 @poly_unmarshal(%struct.poly* nonnull %10, i8* %2)
  %100 = icmp eq i32 %99, 0
  br i1 %100, label %863, label %101

101:                                              ; preds = %98
  %102 = bitcast %struct.poly* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %102) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %102, i8 -86, i64 1408, i1 false)
  %103 = bitcast %struct.poly* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %103) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %103, i8 -86, i64 1408, i1 false)
  %104 = bitcast %struct.poly3* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 176, i8* nonnull %104) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %104, i8 -86, i64 176, i1 false)
  %105 = bitcast %struct.poly3* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 176, i8* nonnull %105) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %105, i8 -86, i64 176, i1 false)
  %106 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 0, i32 0, i32 0, i64 0
  %107 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 0, i32 1, i32 0, i64 0
  %108 = load i64, i64* %106, align 16
  %109 = xor i64 %108, -1
  %110 = load i64, i64* %107, align 8
  %111 = bitcast %struct.poly* %11 to [704 x i16]*
  br label %112

112:                                              ; preds = %135, %101
  %113 = phi i64 [ 0, %101 ], [ %141, %135 ]
  %114 = phi i32 [ 0, %101 ], [ %140, %135 ]
  %115 = phi i64 [ %110, %101 ], [ %139, %135 ]
  %116 = phi i64 [ %109, %101 ], [ %138, %135 ]
  %117 = phi i64* [ %107, %101 ], [ %137, %135 ]
  %118 = phi i64* [ %106, %101 ], [ %136, %135 ]
  %119 = and i64 %116, 1
  %120 = add nuw nsw i64 %119, 65535
  %121 = getelementptr inbounds [704 x i16], [704 x i16]* %111, i64 0, i64 %113
  %122 = and i64 %115, 1
  %123 = or i64 %120, %122
  %124 = trunc i64 %123 to i16
  store i16 %124, i16* %121, align 2
  %125 = lshr i64 %116, 1
  %126 = lshr i64 %115, 1
  %127 = add i32 %114, 1
  %128 = icmp eq i32 %127, 64
  br i1 %128, label %129, label %135

129:                                              ; preds = %112
  %130 = getelementptr inbounds i64, i64* %118, i64 1
  %131 = getelementptr inbounds i64, i64* %117, i64 1
  %132 = load i64, i64* %130, align 8
  %133 = xor i64 %132, -1
  %134 = load i64, i64* %131, align 8
  br label %135

135:                                              ; preds = %129, %112
  %136 = phi i64* [ %130, %129 ], [ %118, %112 ]
  %137 = phi i64* [ %131, %129 ], [ %117, %112 ]
  %138 = phi i64 [ %133, %129 ], [ %125, %112 ]
  %139 = phi i64 [ %134, %129 ], [ %126, %112 ]
  %140 = phi i32 [ 0, %129 ], [ %127, %112 ]
  %141 = add nuw nsw i64 %113, 1
  %142 = icmp eq i64 %141, 701
  br i1 %142, label %143, label %112

143:                                              ; preds = %135
  %144 = bitcast %struct.poly* %10 to [704 x i16]*
  %145 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 701
  %146 = bitcast i16* %145 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %146, i8 0, i64 6, i1 false) #5
  %147 = getelementptr inbounds [704 x i16], [704 x i16]* %111, i64 0, i64 701
  %148 = bitcast i16* %147 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %148, i8 0, i64 6, i1 false) #5
  %149 = bitcast [176 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %149) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %149, i8 -86, i64 2816, i1 false) #5
  %150 = bitcast [172 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %150) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %150, i8 -86, i64 2752, i1 false) #5
  %151 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 0
  %152 = getelementptr inbounds [172 x <2 x i64>], [172 x <2 x i64>]* %6, i64 0, i64 0
  %153 = getelementptr inbounds %struct.poly, %struct.poly* %10, i64 0, i32 0, i32 0, i64 0
  %154 = getelementptr inbounds %struct.poly, %struct.poly* %11, i64 0, i32 0, i32 0, i64 0
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %151, <2 x i64>* nonnull %152, <2 x i64>* nonnull %153, <2 x i64>* nonnull %154, i64 88) #5
  %155 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 87
  %156 = bitcast <2 x i64>* %155 to <16 x i8>*
  %157 = load <16 x i8>, <16 x i8>* %156, align 16
  br label %158

158:                                              ; preds = %158, %143
  %159 = phi <16 x i8> [ %157, %143 ], [ %179, %158 ]
  %160 = phi i64 [ 0, %143 ], [ %190, %158 ]
  %161 = add nuw nsw i64 %160, 88
  %162 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %161
  %163 = bitcast <2 x i64>* %162 to <16 x i8>*
  %164 = load <16 x i8>, <16 x i8>* %163, align 16
  %165 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %160
  %166 = bitcast <2 x i64>* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <16 x i8> %159, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %169 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %164, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %170 = or <16 x i8> %169, %168
  %171 = bitcast <16 x i8> %170 to <8 x i16>
  %172 = add <8 x i16> %167, %171
  %173 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 %160
  %174 = bitcast <2 x i64>* %173 to <8 x i16>*
  store <8 x i16> %172, <8 x i16>* %174, align 16
  %175 = or i64 %160, 1
  %176 = add nuw nsw i64 %160, 89
  %177 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %176
  %178 = bitcast <2 x i64>* %177 to <16 x i8>*
  %179 = load <16 x i8>, <16 x i8>* %178, align 16
  %180 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %175
  %181 = bitcast <2 x i64>* %180 to <8 x i16>*
  %182 = load <8 x i16>, <8 x i16>* %181, align 16
  %183 = shufflevector <16 x i8> %164, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %184 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %179, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %185 = or <16 x i8> %184, %183
  %186 = bitcast <16 x i8> %185 to <8 x i16>
  %187 = add <8 x i16> %182, %186
  %188 = getelementptr inbounds %struct.poly, %struct.poly* %12, i64 0, i32 0, i32 0, i64 %175
  %189 = bitcast <2 x i64>* %188 to <8 x i16>*
  store <8 x i16> %187, <8 x i16>* %189, align 16
  %190 = add nuw nsw i64 %160, 2
  %191 = icmp eq i64 %190, 88
  br i1 %191, label %192, label %158

192:                                              ; preds = %158
  %193 = bitcast %struct.poly* %12 to [704 x i16]*
  %194 = getelementptr inbounds [704 x i16], [704 x i16]* %193, i64 0, i64 701
  %195 = bitcast i16* %194 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %195, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %150) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %149) #5
  %196 = getelementptr inbounds %struct.poly3, %struct.poly3* %13, i64 0, i32 0, i32 0, i64 0
  %197 = getelementptr inbounds %struct.poly3, %struct.poly3* %13, i64 0, i32 1, i32 0, i64 0
  br label %198

198:                                              ; preds = %234, %192
  %199 = phi i64 [ 0, %192 ], [ %240, %234 ]
  %200 = phi i64* [ %196, %192 ], [ %239, %234 ]
  %201 = phi i64* [ %197, %192 ], [ %238, %234 ]
  %202 = phi i32 [ 0, %192 ], [ %237, %234 ]
  %203 = phi i64 [ 0, %192 ], [ %236, %234 ]
  %204 = phi i64 [ 0, %192 ], [ %235, %234 ]
  %205 = getelementptr inbounds [704 x i16], [704 x i16]* %193, i64 0, i64 %199
  %206 = load i16, i16* %205, align 2
  %207 = shl i16 %206, 3
  %208 = ashr exact i16 %207, 3
  %209 = sext i16 %208 to i32
  %210 = mul nsw i32 %209, 21845
  %211 = lshr i32 %210, 16
  %212 = trunc i32 %211 to i16
  %213 = mul i16 %212, -3
  %214 = add i16 %213, %208
  %215 = ashr i16 %214, 1
  %216 = and i16 %215, %214
  %217 = add i16 %216, -1
  %218 = and i16 %217, %214
  %219 = lshr i64 %204, 1
  %220 = and i16 %218, 2
  %221 = zext i16 %220 to i64
  %222 = shl nuw i64 %221, 62
  %223 = or i64 %222, %219
  %224 = lshr i64 %203, 1
  %225 = zext i16 %218 to i64
  %226 = shl i64 %225, 63
  %227 = or i64 %226, %224
  %228 = or i64 %227, %222
  %229 = add i32 %202, 1
  %230 = icmp eq i32 %229, 64
  br i1 %230, label %231, label %234

231:                                              ; preds = %198
  store i64 %223, i64* %200, align 8
  %232 = getelementptr inbounds i64, i64* %200, i64 1
  store i64 %228, i64* %201, align 8
  %233 = getelementptr inbounds i64, i64* %201, i64 1
  br label %234

234:                                              ; preds = %231, %198
  %235 = phi i64 [ 0, %231 ], [ %223, %198 ]
  %236 = phi i64 [ 0, %231 ], [ %228, %198 ]
  %237 = phi i32 [ 0, %231 ], [ %229, %198 ]
  %238 = phi i64* [ %233, %231 ], [ %201, %198 ]
  %239 = phi i64* [ %232, %231 ], [ %200, %198 ]
  %240 = add nuw nsw i64 %199, 1
  %241 = icmp eq i64 %240, 701
  br i1 %241, label %242, label %198

242:                                              ; preds = %234
  %243 = zext i32 %237 to i64
  %244 = sub nsw i64 64, %243
  %245 = lshr i64 %235, %244
  %246 = lshr i64 %236, %244
  store i64 %245, i64* %239, align 8
  store i64 %246, i64* %238, align 8
  %247 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 1
  call void @HRSS_poly3_mul(%struct.poly3* nonnull %14, %struct.poly3* nonnull %13, %struct.poly3* %247)
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %16) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 -86, i64 1408, i1 false)
  %248 = bitcast %struct.poly* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %248) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %248, i8 -86, i64 1408, i1 false)
  %249 = getelementptr inbounds %struct.poly3, %struct.poly3* %14, i64 0, i32 0, i32 0, i64 0
  %250 = getelementptr inbounds %struct.poly3, %struct.poly3* %14, i64 0, i32 1, i32 0, i64 0
  %251 = load i64, i64* %249, align 8
  %252 = xor i64 %251, -1
  %253 = load i64, i64* %250, align 8
  %254 = bitcast %struct.poly* %15 to [704 x i16]*
  br label %255

255:                                              ; preds = %278, %242
  %256 = phi i64 [ 0, %242 ], [ %284, %278 ]
  %257 = phi i32 [ 0, %242 ], [ %283, %278 ]
  %258 = phi i64 [ %253, %242 ], [ %282, %278 ]
  %259 = phi i64 [ %252, %242 ], [ %281, %278 ]
  %260 = phi i64* [ %250, %242 ], [ %280, %278 ]
  %261 = phi i64* [ %249, %242 ], [ %279, %278 ]
  %262 = and i64 %259, 1
  %263 = add nuw nsw i64 %262, 65535
  %264 = getelementptr inbounds [704 x i16], [704 x i16]* %254, i64 0, i64 %256
  %265 = and i64 %258, 1
  %266 = or i64 %263, %265
  %267 = trunc i64 %266 to i16
  store i16 %267, i16* %264, align 2
  %268 = lshr i64 %259, 1
  %269 = lshr i64 %258, 1
  %270 = add i32 %257, 1
  %271 = icmp eq i32 %270, 64
  br i1 %271, label %272, label %278

272:                                              ; preds = %255
  %273 = getelementptr inbounds i64, i64* %261, i64 1
  %274 = getelementptr inbounds i64, i64* %260, i64 1
  %275 = load i64, i64* %273, align 8
  %276 = xor i64 %275, -1
  %277 = load i64, i64* %274, align 8
  br label %278

278:                                              ; preds = %272, %255
  %279 = phi i64* [ %273, %272 ], [ %261, %255 ]
  %280 = phi i64* [ %274, %272 ], [ %260, %255 ]
  %281 = phi i64 [ %276, %272 ], [ %268, %255 ]
  %282 = phi i64 [ %277, %272 ], [ %269, %255 ]
  %283 = phi i32 [ 0, %272 ], [ %270, %255 ]
  %284 = add nuw nsw i64 %256, 1
  %285 = icmp eq i64 %284, 701
  br i1 %285, label %286, label %255

286:                                              ; preds = %278
  call fastcc void @poly_lift(%struct.poly* nonnull %17, %struct.poly* nonnull %15)
  call void @llvm.lifetime.start.p0i8(i64 1408, i8* nonnull %19) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %19, i8 -86, i64 1408, i1 false)
  %287 = bitcast %struct.poly* %17 to [704 x i16]*
  %288 = bitcast %struct.poly* %18 to [704 x i16]*
  br label %289

289:                                              ; preds = %888, %286
  %290 = phi i64 [ 0, %286 ], [ %907, %888 ]
  %291 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 %290
  %292 = bitcast i16* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = getelementptr inbounds i16, i16* %291, i64 8
  %295 = bitcast i16* %294 to <8 x i16>*
  %296 = load <8 x i16>, <8 x i16>* %295, align 16
  %297 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %290
  %298 = bitcast i16* %297 to <8 x i16>*
  %299 = load <8 x i16>, <8 x i16>* %298, align 16
  %300 = getelementptr inbounds i16, i16* %297, i64 8
  %301 = bitcast i16* %300 to <8 x i16>*
  %302 = load <8 x i16>, <8 x i16>* %301, align 16
  %303 = sub <8 x i16> %293, %299
  %304 = sub <8 x i16> %296, %302
  %305 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 %290
  %306 = bitcast i16* %305 to <8 x i16>*
  store <8 x i16> %303, <8 x i16>* %306, align 16
  %307 = getelementptr inbounds i16, i16* %305, i64 8
  %308 = bitcast i16* %307 to <8 x i16>*
  store <8 x i16> %304, <8 x i16>* %308, align 16
  %309 = or i64 %290, 16
  %310 = icmp eq i64 %309, 688
  br i1 %310, label %769, label %888, !llvm.loop !36

311:                                              ; preds = %311, %769
  %312 = phi <16 x i8> [ %862, %769 ], [ %332, %311 ]
  %313 = phi i64 [ 0, %769 ], [ %343, %311 ]
  %314 = add nuw nsw i64 %313, 88
  %315 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %314
  %316 = bitcast <2 x i64>* %315 to <16 x i8>*
  %317 = load <16 x i8>, <16 x i8>* %316, align 16
  %318 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %313
  %319 = bitcast <2 x i64>* %318 to <8 x i16>*
  %320 = load <8 x i16>, <8 x i16>* %319, align 16
  %321 = shufflevector <16 x i8> %312, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %322 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %317, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %323 = or <16 x i8> %322, %321
  %324 = bitcast <16 x i8> %323 to <8 x i16>
  %325 = add <8 x i16> %320, %324
  %326 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 %313
  %327 = bitcast <2 x i64>* %326 to <8 x i16>*
  store <8 x i16> %325, <8 x i16>* %327, align 16
  %328 = or i64 %313, 1
  %329 = add nuw nsw i64 %313, 89
  %330 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %329
  %331 = bitcast <2 x i64>* %330 to <16 x i8>*
  %332 = load <16 x i8>, <16 x i8>* %331, align 16
  %333 = getelementptr inbounds [176 x <2 x i64>], [176 x <2 x i64>]* %5, i64 0, i64 %328
  %334 = bitcast <2 x i64>* %333 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 16
  %336 = shufflevector <16 x i8> %317, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %337 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %332, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %338 = or <16 x i8> %337, %336
  %339 = bitcast <16 x i8> %338 to <8 x i16>
  %340 = add <8 x i16> %335, %339
  %341 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 %328
  %342 = bitcast <2 x i64>* %341 to <8 x i16>*
  store <8 x i16> %340, <8 x i16>* %342, align 16
  %343 = add nuw nsw i64 %313, 2
  %344 = icmp eq i64 %343, 88
  br i1 %344, label %345, label %311

345:                                              ; preds = %311
  call void @llvm.memset.p0i8.i64(i8* align 2 %856, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.end.p0i8(i64 2752, i8* nonnull %150) #5
  call void @llvm.lifetime.end.p0i8(i64 2816, i8* nonnull %149) #5
  %346 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 700
  %347 = load i16, i16* %346, align 8
  %348 = insertelement <8 x i16> undef, i16 %347, i32 0
  %349 = shufflevector <8 x i16> %348, <8 x i16> undef, <8 x i32> zeroinitializer
  %350 = insertelement <8 x i16> undef, i16 %347, i32 0
  %351 = shufflevector <8 x i16> %350, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %352

352:                                              ; preds = %876, %345
  %353 = phi i64 [ 0, %345 ], [ %887, %876 ]
  %354 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 %353
  %355 = bitcast i16* %354 to <8 x i16>*
  %356 = load <8 x i16>, <8 x i16>* %355, align 16
  %357 = getelementptr inbounds i16, i16* %354, i64 8
  %358 = bitcast i16* %357 to <8 x i16>*
  %359 = load <8 x i16>, <8 x i16>* %358, align 16
  %360 = sub <8 x i16> %356, %349
  %361 = sub <8 x i16> %359, %351
  %362 = bitcast i16* %354 to <8 x i16>*
  store <8 x i16> %360, <8 x i16>* %362, align 16
  %363 = bitcast i16* %357 to <8 x i16>*
  store <8 x i16> %361, <8 x i16>* %363, align 16
  %364 = or i64 %353, 16
  %365 = icmp eq i64 %364, 688
  br i1 %365, label %366, label %876, !llvm.loop !37

366:                                              ; preds = %352
  %367 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 86
  %368 = bitcast <2 x i64>* %367 to i16*
  %369 = load i16, i16* %368, align 16
  %370 = sub i16 %369, %347
  store i16 %370, i16* %368, align 16
  %371 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 689
  %372 = load i16, i16* %371, align 2
  %373 = sub i16 %372, %347
  store i16 %373, i16* %371, align 2
  %374 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 690
  %375 = load i16, i16* %374, align 4
  %376 = sub i16 %375, %347
  store i16 %376, i16* %374, align 4
  %377 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 691
  %378 = load i16, i16* %377, align 2
  %379 = sub i16 %378, %347
  store i16 %379, i16* %377, align 2
  %380 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 692
  %381 = load i16, i16* %380, align 8
  %382 = sub i16 %381, %347
  store i16 %382, i16* %380, align 8
  %383 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 693
  %384 = load i16, i16* %383, align 2
  %385 = sub i16 %384, %347
  store i16 %385, i16* %383, align 2
  %386 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 694
  %387 = load i16, i16* %386, align 4
  %388 = sub i16 %387, %347
  store i16 %388, i16* %386, align 4
  %389 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 695
  %390 = load i16, i16* %389, align 2
  %391 = sub i16 %390, %347
  store i16 %391, i16* %389, align 2
  %392 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 87
  %393 = bitcast <2 x i64>* %392 to i16*
  %394 = load i16, i16* %393, align 16
  %395 = sub i16 %394, %347
  store i16 %395, i16* %393, align 16
  %396 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 697
  %397 = load i16, i16* %396, align 2
  %398 = sub i16 %397, %347
  store i16 %398, i16* %396, align 2
  %399 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 698
  %400 = load i16, i16* %399, align 4
  %401 = sub i16 %400, %347
  store i16 %401, i16* %399, align 4
  %402 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 699
  %403 = load i16, i16* %402, align 2
  %404 = sub i16 %403, %347
  store i16 %404, i16* %402, align 2
  %405 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 700
  %406 = load i16, i16* %405, align 8
  %407 = sub i16 %406, %347
  store i16 %407, i16* %405, align 8
  br label %408

408:                                              ; preds = %864, %366
  %409 = phi i64 [ 0, %366 ], [ %875, %864 ]
  %410 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 %409
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %410, i64 8
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = and <8 x i16> %412, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %417 = and <8 x i16> %415, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %418 = bitcast i16* %410 to <8 x i16>*
  store <8 x i16> %416, <8 x i16>* %418, align 16
  %419 = bitcast i16* %413 to <8 x i16>*
  store <8 x i16> %417, <8 x i16>* %419, align 16
  %420 = or i64 %409, 16
  %421 = icmp eq i64 %420, 688
  br i1 %421, label %422, label %864, !llvm.loop !38

422:                                              ; preds = %408
  %423 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 86
  %424 = bitcast <2 x i64>* %423 to i16*
  %425 = load i16, i16* %424, align 16
  %426 = and i16 %425, 8191
  store i16 %426, i16* %424, align 16
  %427 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 689
  %428 = load i16, i16* %427, align 2
  %429 = and i16 %428, 8191
  store i16 %429, i16* %427, align 2
  %430 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 690
  %431 = load i16, i16* %430, align 4
  %432 = and i16 %431, 8191
  store i16 %432, i16* %430, align 4
  %433 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 691
  %434 = load i16, i16* %433, align 2
  %435 = and i16 %434, 8191
  store i16 %435, i16* %433, align 2
  %436 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 692
  %437 = load i16, i16* %436, align 8
  %438 = and i16 %437, 8191
  store i16 %438, i16* %436, align 8
  %439 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 693
  %440 = load i16, i16* %439, align 2
  %441 = and i16 %440, 8191
  store i16 %441, i16* %439, align 2
  %442 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 694
  %443 = load i16, i16* %442, align 4
  %444 = and i16 %443, 8191
  store i16 %444, i16* %442, align 4
  %445 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 695
  %446 = load i16, i16* %445, align 2
  %447 = and i16 %446, 8191
  store i16 %447, i16* %445, align 2
  %448 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 87
  %449 = bitcast <2 x i64>* %448 to i16*
  %450 = load i16, i16* %449, align 16
  %451 = and i16 %450, 8191
  store i16 %451, i16* %449, align 16
  %452 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 697
  %453 = load i16, i16* %452, align 2
  %454 = and i16 %453, 8191
  store i16 %454, i16* %452, align 2
  %455 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 698
  %456 = load i16, i16* %455, align 4
  %457 = and i16 %456, 8191
  store i16 %457, i16* %455, align 4
  %458 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 699
  %459 = load i16, i16* %458, align 2
  %460 = and i16 %459, 8191
  store i16 %460, i16* %458, align 2
  %461 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 700
  %462 = load i16, i16* %461, align 8
  %463 = and i16 %462, 8191
  store i16 %463, i16* %461, align 8
  %464 = bitcast %struct.poly3* %20 to i8*
  call void @llvm.lifetime.start.p0i8(i64 176, i8* nonnull %464) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %464, i8 -86, i64 176, i1 false)
  %465 = getelementptr inbounds %struct.poly3, %struct.poly3* %20, i64 0, i32 0, i32 0, i64 0
  %466 = getelementptr inbounds %struct.poly3, %struct.poly3* %20, i64 0, i32 1, i32 0, i64 0
  br label %467

467:                                              ; preds = %503, %422
  %468 = phi i64 [ 0, %422 ], [ %509, %503 ]
  %469 = phi i64* [ %465, %422 ], [ %508, %503 ]
  %470 = phi i64* [ %466, %422 ], [ %507, %503 ]
  %471 = phi i64 [ 0, %422 ], [ %506, %503 ]
  %472 = phi i64 [ 0, %422 ], [ %505, %503 ]
  %473 = phi i64 [ -1, %422 ], [ %487, %503 ]
  %474 = phi i32 [ 0, %422 ], [ %504, %503 ]
  %475 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 %468
  %476 = load i16, i16* %475, align 2
  %477 = and i16 %476, 3
  %478 = lshr i16 %477, 1
  %479 = xor i16 %478, %477
  %480 = sub nsw i16 0, %478
  %481 = and i16 %480, 8191
  %482 = or i16 %479, %481
  %483 = xor i16 %482, %476
  %484 = zext i16 %483 to i64
  %485 = add nsw i64 %484, -1
  %486 = ashr i64 %485, 63
  %487 = and i64 %486, %473
  %488 = lshr i64 %471, 1
  %489 = and i16 %476, 2
  %490 = zext i16 %489 to i64
  %491 = shl nuw i64 %490, 62
  %492 = or i64 %491, %488
  %493 = lshr i64 %472, 1
  %494 = zext i16 %479 to i64
  %495 = shl i64 %494, 63
  %496 = or i64 %491, %493
  %497 = or i64 %496, %495
  %498 = add i32 %474, 1
  %499 = icmp eq i32 %498, 64
  br i1 %499, label %500, label %503

500:                                              ; preds = %467
  store i64 %492, i64* %469, align 8
  %501 = getelementptr inbounds i64, i64* %469, i64 1
  store i64 %497, i64* %470, align 8
  %502 = getelementptr inbounds i64, i64* %470, i64 1
  br label %503

503:                                              ; preds = %500, %467
  %504 = phi i32 [ 0, %500 ], [ %498, %467 ]
  %505 = phi i64 [ 0, %500 ], [ %497, %467 ]
  %506 = phi i64 [ 0, %500 ], [ %492, %467 ]
  %507 = phi i64* [ %502, %500 ], [ %470, %467 ]
  %508 = phi i64* [ %501, %500 ], [ %469, %467 ]
  %509 = add nuw nsw i64 %468, 1
  %510 = icmp eq i64 %509, 701
  br i1 %510, label %511, label %467

511:                                              ; preds = %503
  %512 = zext i32 %504 to i64
  %513 = sub nsw i64 64, %512
  %514 = lshr i64 %506, %513
  %515 = lshr i64 %505, %513
  store i64 %514, i64* %508, align 8
  store i64 %515, i64* %507, align 8
  %516 = getelementptr inbounds [1138 x i8], [1138 x i8]* %21, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 1138, i8* nonnull %516) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %516, i8 -86, i64 1138, i1 false)
  call fastcc void @poly_marshal(i8* nonnull %516, %struct.poly* nonnull %10)
  %517 = getelementptr inbounds [140 x i8], [140 x i8]* %22, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 140, i8* nonnull %517) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %517, i8 -86, i64 140, i1 false)
  %518 = getelementptr inbounds [140 x i8], [140 x i8]* %24, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 140, i8* nonnull %518) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %518, i8 -86, i64 140, i1 false)
  %519 = bitcast %struct.poly* %15 to i16*
  %520 = getelementptr inbounds [140 x i8], [140 x i8]* %22, i64 1, i64 0
  %521 = getelementptr inbounds %struct.poly, %struct.poly* %15, i64 0, i32 0, i32 0, i64 87
  %522 = bitcast <2 x i64>* %521 to i8*
  %523 = getelementptr inbounds i8, i8* %522, i64 8
  %524 = icmp ult i8* %23, %523
  %525 = icmp ugt i8* %520, %16
  %526 = and i1 %524, %525
  br i1 %526, label %573, label %527

527:                                              ; preds = %511
  %528 = getelementptr inbounds %struct.poly, %struct.poly* %15, i64 0, i32 0, i32 0, i64 85
  %529 = bitcast <2 x i64>* %528 to i16*
  br label %530

530:                                              ; preds = %530, %527
  %531 = phi i64 [ 0, %527 ], [ %571, %530 ]
  %532 = mul i64 %531, 5
  %533 = getelementptr i16, i16* %519, i64 %532
  %534 = bitcast i16* %533 to <40 x i16>*
  %535 = load <40 x i16>, <40 x i16>* %534, align 16
  %536 = shufflevector <40 x i16> %535, <40 x i16> undef, <8 x i32> <i32 0, i32 5, i32 10, i32 15, i32 20, i32 25, i32 30, i32 35>
  %537 = shufflevector <40 x i16> %535, <40 x i16> undef, <8 x i32> <i32 1, i32 6, i32 11, i32 16, i32 21, i32 26, i32 31, i32 36>
  %538 = shufflevector <40 x i16> %535, <40 x i16> undef, <8 x i32> <i32 2, i32 7, i32 12, i32 17, i32 22, i32 27, i32 32, i32 37>
  %539 = shufflevector <40 x i16> %535, <40 x i16> undef, <8 x i32> <i32 3, i32 8, i32 13, i32 18, i32 23, i32 28, i32 33, i32 38>
  %540 = shufflevector <40 x i16> %535, <40 x i16> undef, <8 x i32> <i32 4, i32 9, i32 14, i32 19, i32 24, i32 29, i32 34, i32 39>
  %541 = and <8 x i16> %536, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %542 = lshr <8 x i16> %541, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %543 = xor <8 x i16> %542, %541
  %544 = and <8 x i16> %537, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %545 = lshr <8 x i16> %544, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %546 = xor <8 x i16> %545, %544
  %547 = and <8 x i16> %538, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %548 = lshr <8 x i16> %547, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %549 = xor <8 x i16> %548, %547
  %550 = and <8 x i16> %539, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %551 = lshr <8 x i16> %550, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %552 = xor <8 x i16> %551, %550
  %553 = and <8 x i16> %540, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %554 = lshr <8 x i16> %553, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %555 = xor <8 x i16> %554, %553
  %556 = trunc <8 x i16> %543 to <8 x i8>
  %557 = trunc <8 x i16> %546 to <8 x i8>
  %558 = mul nuw nsw <8 x i8> %557, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %559 = add nuw nsw <8 x i8> %558, %556
  %560 = trunc <8 x i16> %549 to <8 x i8>
  %561 = mul nuw nsw <8 x i8> %560, <i8 9, i8 9, i8 9, i8 9, i8 9, i8 9, i8 9, i8 9>
  %562 = add nuw nsw <8 x i8> %559, %561
  %563 = trunc <8 x i16> %552 to <8 x i8>
  %564 = mul nuw nsw <8 x i8> %563, <i8 27, i8 27, i8 27, i8 27, i8 27, i8 27, i8 27, i8 27>
  %565 = add <8 x i8> %562, %564
  %566 = trunc <8 x i16> %555 to <8 x i8>
  %567 = mul nuw <8 x i8> %566, <i8 81, i8 81, i8 81, i8 81, i8 81, i8 81, i8 81, i8 81>
  %568 = add <8 x i8> %565, %567
  %569 = getelementptr inbounds [140 x i8], [140 x i8]* %22, i64 0, i64 %531
  %570 = bitcast i8* %569 to <8 x i8>*
  store <8 x i8> %568, <8 x i8>* %570, align 8, !alias.scope !39, !noalias !42
  %571 = add i64 %531, 8
  %572 = icmp eq i64 %571, 136
  br i1 %572, label %573, label %530, !llvm.loop !44

573:                                              ; preds = %530, %511
  %574 = phi i16* [ %519, %511 ], [ %529, %530 ]
  %575 = phi i64 [ 0, %511 ], [ 136, %530 ]
  br label %576

576:                                              ; preds = %573, %576
  %577 = phi i16* [ %617, %576 ], [ %574, %573 ]
  %578 = phi i64 [ %618, %576 ], [ %575, %573 ]
  %579 = load i16, i16* %577, align 2
  %580 = and i16 %579, 3
  %581 = lshr i16 %580, 1
  %582 = xor i16 %581, %580
  %583 = getelementptr inbounds i16, i16* %577, i64 1
  %584 = load i16, i16* %583, align 2
  %585 = and i16 %584, 3
  %586 = lshr i16 %585, 1
  %587 = xor i16 %586, %585
  %588 = getelementptr inbounds i16, i16* %577, i64 2
  %589 = load i16, i16* %588, align 2
  %590 = and i16 %589, 3
  %591 = lshr i16 %590, 1
  %592 = xor i16 %591, %590
  %593 = getelementptr inbounds i16, i16* %577, i64 3
  %594 = load i16, i16* %593, align 2
  %595 = and i16 %594, 3
  %596 = lshr i16 %595, 1
  %597 = xor i16 %596, %595
  %598 = getelementptr inbounds i16, i16* %577, i64 4
  %599 = load i16, i16* %598, align 2
  %600 = and i16 %599, 3
  %601 = lshr i16 %600, 1
  %602 = xor i16 %601, %600
  %603 = trunc i16 %582 to i8
  %604 = trunc i16 %587 to i8
  %605 = mul nuw nsw i8 %604, 3
  %606 = add nuw nsw i8 %605, %603
  %607 = trunc i16 %592 to i8
  %608 = mul nuw nsw i8 %607, 9
  %609 = add nuw nsw i8 %606, %608
  %610 = trunc i16 %597 to i8
  %611 = mul nuw nsw i8 %610, 27
  %612 = add i8 %609, %611
  %613 = trunc i16 %602 to i8
  %614 = mul nuw i8 %613, 81
  %615 = add i8 %612, %614
  %616 = getelementptr inbounds [140 x i8], [140 x i8]* %22, i64 0, i64 %578
  store i8 %615, i8* %616, align 1
  %617 = getelementptr inbounds i16, i16* %577, i64 5
  %618 = add nuw nsw i64 %578, 1
  %619 = icmp eq i64 %618, 140
  br i1 %619, label %620, label %576, !llvm.loop !45

620:                                              ; preds = %576
  %621 = bitcast %struct.poly* %18 to i16*
  %622 = getelementptr inbounds [140 x i8], [140 x i8]* %24, i64 1, i64 0
  %623 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 87
  %624 = bitcast <2 x i64>* %623 to i8*
  %625 = getelementptr inbounds i8, i8* %624, i64 8
  %626 = icmp ult i8* %25, %625
  %627 = icmp ugt i8* %622, %19
  %628 = and i1 %626, %627
  br i1 %628, label %675, label %629

629:                                              ; preds = %620
  %630 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 85
  %631 = bitcast <2 x i64>* %630 to i16*
  br label %632

632:                                              ; preds = %632, %629
  %633 = phi i64 [ 0, %629 ], [ %673, %632 ]
  %634 = mul i64 %633, 5
  %635 = getelementptr i16, i16* %621, i64 %634
  %636 = bitcast i16* %635 to <40 x i16>*
  %637 = load <40 x i16>, <40 x i16>* %636, align 16
  %638 = shufflevector <40 x i16> %637, <40 x i16> undef, <8 x i32> <i32 0, i32 5, i32 10, i32 15, i32 20, i32 25, i32 30, i32 35>
  %639 = shufflevector <40 x i16> %637, <40 x i16> undef, <8 x i32> <i32 1, i32 6, i32 11, i32 16, i32 21, i32 26, i32 31, i32 36>
  %640 = shufflevector <40 x i16> %637, <40 x i16> undef, <8 x i32> <i32 2, i32 7, i32 12, i32 17, i32 22, i32 27, i32 32, i32 37>
  %641 = shufflevector <40 x i16> %637, <40 x i16> undef, <8 x i32> <i32 3, i32 8, i32 13, i32 18, i32 23, i32 28, i32 33, i32 38>
  %642 = shufflevector <40 x i16> %637, <40 x i16> undef, <8 x i32> <i32 4, i32 9, i32 14, i32 19, i32 24, i32 29, i32 34, i32 39>
  %643 = and <8 x i16> %638, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %644 = lshr <8 x i16> %643, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %645 = xor <8 x i16> %644, %643
  %646 = and <8 x i16> %639, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %647 = lshr <8 x i16> %646, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %648 = xor <8 x i16> %647, %646
  %649 = and <8 x i16> %640, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %650 = lshr <8 x i16> %649, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %651 = xor <8 x i16> %650, %649
  %652 = and <8 x i16> %641, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %653 = lshr <8 x i16> %652, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %654 = xor <8 x i16> %653, %652
  %655 = and <8 x i16> %642, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %656 = lshr <8 x i16> %655, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %657 = xor <8 x i16> %656, %655
  %658 = trunc <8 x i16> %645 to <8 x i8>
  %659 = trunc <8 x i16> %648 to <8 x i8>
  %660 = mul nuw nsw <8 x i8> %659, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %661 = add nuw nsw <8 x i8> %660, %658
  %662 = trunc <8 x i16> %651 to <8 x i8>
  %663 = mul nuw nsw <8 x i8> %662, <i8 9, i8 9, i8 9, i8 9, i8 9, i8 9, i8 9, i8 9>
  %664 = add nuw nsw <8 x i8> %661, %663
  %665 = trunc <8 x i16> %654 to <8 x i8>
  %666 = mul nuw nsw <8 x i8> %665, <i8 27, i8 27, i8 27, i8 27, i8 27, i8 27, i8 27, i8 27>
  %667 = add <8 x i8> %664, %666
  %668 = trunc <8 x i16> %657 to <8 x i8>
  %669 = mul nuw <8 x i8> %668, <i8 81, i8 81, i8 81, i8 81, i8 81, i8 81, i8 81, i8 81>
  %670 = add <8 x i8> %667, %669
  %671 = getelementptr inbounds [140 x i8], [140 x i8]* %24, i64 0, i64 %633
  %672 = bitcast i8* %671 to <8 x i8>*
  store <8 x i8> %670, <8 x i8>* %672, align 8, !alias.scope !46, !noalias !49
  %673 = add i64 %633, 8
  %674 = icmp eq i64 %673, 136
  br i1 %674, label %675, label %632, !llvm.loop !51

675:                                              ; preds = %632, %620
  %676 = phi i16* [ %621, %620 ], [ %631, %632 ]
  %677 = phi i64 [ 0, %620 ], [ 136, %632 ]
  br label %678

678:                                              ; preds = %675, %678
  %679 = phi i16* [ %719, %678 ], [ %676, %675 ]
  %680 = phi i64 [ %720, %678 ], [ %677, %675 ]
  %681 = load i16, i16* %679, align 2
  %682 = and i16 %681, 3
  %683 = lshr i16 %682, 1
  %684 = xor i16 %683, %682
  %685 = getelementptr inbounds i16, i16* %679, i64 1
  %686 = load i16, i16* %685, align 2
  %687 = and i16 %686, 3
  %688 = lshr i16 %687, 1
  %689 = xor i16 %688, %687
  %690 = getelementptr inbounds i16, i16* %679, i64 2
  %691 = load i16, i16* %690, align 2
  %692 = and i16 %691, 3
  %693 = lshr i16 %692, 1
  %694 = xor i16 %693, %692
  %695 = getelementptr inbounds i16, i16* %679, i64 3
  %696 = load i16, i16* %695, align 2
  %697 = and i16 %696, 3
  %698 = lshr i16 %697, 1
  %699 = xor i16 %698, %697
  %700 = getelementptr inbounds i16, i16* %679, i64 4
  %701 = load i16, i16* %700, align 2
  %702 = and i16 %701, 3
  %703 = lshr i16 %702, 1
  %704 = xor i16 %703, %702
  %705 = trunc i16 %684 to i8
  %706 = trunc i16 %689 to i8
  %707 = mul nuw nsw i8 %706, 3
  %708 = add nuw nsw i8 %707, %705
  %709 = trunc i16 %694 to i8
  %710 = mul nuw nsw i8 %709, 9
  %711 = add nuw nsw i8 %708, %710
  %712 = trunc i16 %699 to i8
  %713 = mul nuw nsw i8 %712, 27
  %714 = add i8 %711, %713
  %715 = trunc i16 %704 to i8
  %716 = mul nuw i8 %715, 81
  %717 = add i8 %714, %716
  %718 = getelementptr inbounds [140 x i8], [140 x i8]* %24, i64 0, i64 %680
  store i8 %717, i8* %718, align 1
  %719 = getelementptr inbounds i16, i16* %679, i64 5
  %720 = add nuw nsw i64 %680, 1
  %721 = icmp eq i64 %720, 140
  br i1 %721, label %722, label %678, !llvm.loop !52

722:                                              ; preds = %678
  %723 = call i32 @CRYPTO_memcmp(i8* %2, i8* nonnull %516, i64 1138) #5
  %724 = sext i32 %723 to i64
  %725 = xor i64 %724, -9223372036854775808
  %726 = add nsw i64 %724, -1
  %727 = and i64 %726, %725
  %728 = ashr i64 %727, 63
  %729 = getelementptr inbounds [32 x i8], [32 x i8]* %26, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %729) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %729, i8 -86, i64 32, i1 false)
  %730 = call i32 @SHA256_Init(%struct.sha256_state_st* nonnull %8) #5
  %731 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %8, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @kSharedKey, i64 0, i64 0), i64 11) #5
  %732 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %8, i8* nonnull %517, i64 140) #5
  %733 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %8, i8* nonnull %518, i64 140) #5
  %734 = call i32 @SHA256_Update(%struct.sha256_state_st* nonnull %8, i8* nonnull %516, i64 1138) #5
  %735 = call i32 @SHA256_Final(i8* nonnull %729, %struct.sha256_state_st* nonnull %8) #5
  %736 = and i64 %487, 255
  %737 = and i64 %736, %728
  %738 = xor i64 %737, -1
  %739 = call i64 asm "", "=r,0,~{dirflag},~{fpsr},~{flags}"(i64 %738) #6, !srcloc !2
  %740 = call i64 asm "", "=r,0,~{dirflag},~{fpsr},~{flags}"(i64 %737) #6, !srcloc !2
  %741 = insertelement <16 x i64> undef, i64 %740, i32 0
  %742 = shufflevector <16 x i64> %741, <16 x i64> undef, <16 x i32> zeroinitializer
  %743 = insertelement <16 x i64> undef, i64 %739, i32 0
  %744 = shufflevector <16 x i64> %743, <16 x i64> undef, <16 x i32> zeroinitializer
  %745 = bitcast [32 x i8]* %26 to <16 x i8>*
  %746 = load <16 x i8>, <16 x i8>* %745, align 16
  %747 = bitcast i8* %0 to <16 x i8>*
  %748 = load <16 x i8>, <16 x i8>* %747, align 1
  %749 = zext <16 x i8> %746 to <16 x i64>
  %750 = zext <16 x i8> %748 to <16 x i64>
  %751 = and <16 x i64> %742, %749
  %752 = and <16 x i64> %744, %750
  %753 = or <16 x i64> %752, %751
  %754 = trunc <16 x i64> %753 to <16 x i8>
  %755 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %754, <16 x i8>* %755, align 1
  %756 = getelementptr inbounds [32 x i8], [32 x i8]* %26, i64 0, i64 16
  %757 = bitcast i8* %756 to <16 x i8>*
  %758 = load <16 x i8>, <16 x i8>* %757, align 16
  %759 = getelementptr inbounds i8, i8* %0, i64 16
  %760 = bitcast i8* %759 to <16 x i8>*
  %761 = load <16 x i8>, <16 x i8>* %760, align 1
  %762 = zext <16 x i8> %758 to <16 x i64>
  %763 = zext <16 x i8> %761 to <16 x i64>
  %764 = and <16 x i64> %742, %762
  %765 = and <16 x i64> %744, %763
  %766 = or <16 x i64> %765, %764
  %767 = trunc <16 x i64> %766 to <16 x i8>
  %768 = bitcast i8* %759 to <16 x i8>*
  store <16 x i8> %767, <16 x i8>* %768, align 1
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %729) #5
  call void @llvm.lifetime.end.p0i8(i64 140, i8* nonnull %518) #5
  call void @llvm.lifetime.end.p0i8(i64 140, i8* nonnull %517) #5
  call void @llvm.lifetime.end.p0i8(i64 1138, i8* nonnull %516) #5
  call void @llvm.lifetime.end.p0i8(i64 176, i8* nonnull %464) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %19) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %248) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %16) #5
  call void @llvm.lifetime.end.p0i8(i64 176, i8* nonnull %105) #5
  call void @llvm.lifetime.end.p0i8(i64 176, i8* nonnull %104) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %103) #5
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %102) #5
  br label %863

769:                                              ; preds = %289
  %770 = getelementptr inbounds %struct.poly, %struct.poly* %10, i64 0, i32 0, i32 0, i64 86
  %771 = bitcast <2 x i64>* %770 to i16*
  %772 = load i16, i16* %771, align 16
  %773 = getelementptr inbounds %struct.poly, %struct.poly* %17, i64 0, i32 0, i32 0, i64 86
  %774 = bitcast <2 x i64>* %773 to i16*
  %775 = load i16, i16* %774, align 16
  %776 = sub i16 %772, %775
  %777 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 86
  %778 = bitcast <2 x i64>* %777 to i16*
  store i16 %776, i16* %778, align 16
  %779 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 689
  %780 = load i16, i16* %779, align 2
  %781 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 689
  %782 = load i16, i16* %781, align 2
  %783 = sub i16 %780, %782
  %784 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 689
  store i16 %783, i16* %784, align 2
  %785 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 690
  %786 = load i16, i16* %785, align 4
  %787 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 690
  %788 = load i16, i16* %787, align 4
  %789 = sub i16 %786, %788
  %790 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 690
  store i16 %789, i16* %790, align 4
  %791 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 691
  %792 = load i16, i16* %791, align 2
  %793 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 691
  %794 = load i16, i16* %793, align 2
  %795 = sub i16 %792, %794
  %796 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 691
  store i16 %795, i16* %796, align 2
  %797 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 692
  %798 = load i16, i16* %797, align 8
  %799 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 692
  %800 = load i16, i16* %799, align 8
  %801 = sub i16 %798, %800
  %802 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 692
  store i16 %801, i16* %802, align 8
  %803 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 693
  %804 = load i16, i16* %803, align 2
  %805 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 693
  %806 = load i16, i16* %805, align 2
  %807 = sub i16 %804, %806
  %808 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 693
  store i16 %807, i16* %808, align 2
  %809 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 694
  %810 = load i16, i16* %809, align 4
  %811 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 694
  %812 = load i16, i16* %811, align 4
  %813 = sub i16 %810, %812
  %814 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 694
  store i16 %813, i16* %814, align 4
  %815 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 695
  %816 = load i16, i16* %815, align 2
  %817 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 695
  %818 = load i16, i16* %817, align 2
  %819 = sub i16 %816, %818
  %820 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 695
  store i16 %819, i16* %820, align 2
  %821 = getelementptr inbounds %struct.poly, %struct.poly* %10, i64 0, i32 0, i32 0, i64 87
  %822 = bitcast <2 x i64>* %821 to i16*
  %823 = load i16, i16* %822, align 16
  %824 = getelementptr inbounds %struct.poly, %struct.poly* %17, i64 0, i32 0, i32 0, i64 87
  %825 = bitcast <2 x i64>* %824 to i16*
  %826 = load i16, i16* %825, align 16
  %827 = sub i16 %823, %826
  %828 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 87
  %829 = bitcast <2 x i64>* %828 to i16*
  store i16 %827, i16* %829, align 16
  %830 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 697
  %831 = load i16, i16* %830, align 2
  %832 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 697
  %833 = load i16, i16* %832, align 2
  %834 = sub i16 %831, %833
  %835 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 697
  store i16 %834, i16* %835, align 2
  %836 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 698
  %837 = load i16, i16* %836, align 4
  %838 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 698
  %839 = load i16, i16* %838, align 4
  %840 = sub i16 %837, %839
  %841 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 698
  store i16 %840, i16* %841, align 4
  %842 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 699
  %843 = load i16, i16* %842, align 2
  %844 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 699
  %845 = load i16, i16* %844, align 2
  %846 = sub i16 %843, %845
  %847 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 699
  store i16 %846, i16* %847, align 2
  %848 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 700
  %849 = load i16, i16* %848, align 8
  %850 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 700
  %851 = load i16, i16* %850, align 8
  %852 = sub i16 %849, %851
  %853 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 700
  store i16 %852, i16* %853, align 8
  %854 = getelementptr inbounds %struct.private_key, %struct.private_key* %30, i64 0, i32 2
  %855 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 701
  %856 = bitcast i16* %855 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %856, i8 0, i64 6, i1 false) #5
  %857 = bitcast %struct.poly* %854 to [704 x i16]*
  %858 = getelementptr inbounds [704 x i16], [704 x i16]* %857, i64 0, i64 701
  %859 = bitcast i16* %858 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %859, i8 0, i64 6, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2816, i8* nonnull %149) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %149, i8 -86, i64 2816, i1 false) #5
  call void @llvm.lifetime.start.p0i8(i64 2752, i8* nonnull %150) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %150, i8 -86, i64 2752, i1 false) #5
  %860 = getelementptr inbounds %struct.poly, %struct.poly* %18, i64 0, i32 0, i32 0, i64 0
  %861 = getelementptr inbounds %struct.poly, %struct.poly* %854, i64 0, i32 0, i32 0, i64 0
  call fastcc void @poly_mul_vec_aux(<2 x i64>* nonnull %151, <2 x i64>* nonnull %152, <2 x i64>* nonnull %860, <2 x i64>* %861, i64 88) #5
  %862 = load <16 x i8>, <16 x i8>* %156, align 16
  br label %311

863:                                              ; preds = %52, %98, %722
  call void @llvm.lifetime.end.p0i8(i64 1408, i8* nonnull %73) #5
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %58) #5
  call void @llvm.lifetime.end.p0i8(i64 112, i8* nonnull %54) #5
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %31) #5
  ret void

864:                                              ; preds = %408
  %865 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 %420
  %866 = bitcast i16* %865 to <8 x i16>*
  %867 = load <8 x i16>, <8 x i16>* %866, align 16
  %868 = getelementptr inbounds i16, i16* %865, i64 8
  %869 = bitcast i16* %868 to <8 x i16>*
  %870 = load <8 x i16>, <8 x i16>* %869, align 16
  %871 = and <8 x i16> %867, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %872 = and <8 x i16> %870, <i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191, i16 8191>
  %873 = bitcast i16* %865 to <8 x i16>*
  store <8 x i16> %871, <8 x i16>* %873, align 16
  %874 = bitcast i16* %868 to <8 x i16>*
  store <8 x i16> %872, <8 x i16>* %874, align 16
  %875 = add nuw nsw i64 %409, 32
  br label %408

876:                                              ; preds = %352
  %877 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 %364
  %878 = bitcast i16* %877 to <8 x i16>*
  %879 = load <8 x i16>, <8 x i16>* %878, align 16
  %880 = getelementptr inbounds i16, i16* %877, i64 8
  %881 = bitcast i16* %880 to <8 x i16>*
  %882 = load <8 x i16>, <8 x i16>* %881, align 16
  %883 = sub <8 x i16> %879, %349
  %884 = sub <8 x i16> %882, %351
  %885 = bitcast i16* %877 to <8 x i16>*
  store <8 x i16> %883, <8 x i16>* %885, align 16
  %886 = bitcast i16* %880 to <8 x i16>*
  store <8 x i16> %884, <8 x i16>* %886, align 16
  %887 = add nuw nsw i64 %353, 32
  br label %352

888:                                              ; preds = %289
  %889 = getelementptr inbounds [704 x i16], [704 x i16]* %144, i64 0, i64 %309
  %890 = bitcast i16* %889 to <8 x i16>*
  %891 = load <8 x i16>, <8 x i16>* %890, align 16
  %892 = getelementptr inbounds i16, i16* %889, i64 8
  %893 = bitcast i16* %892 to <8 x i16>*
  %894 = load <8 x i16>, <8 x i16>* %893, align 16
  %895 = getelementptr inbounds [704 x i16], [704 x i16]* %287, i64 0, i64 %309
  %896 = bitcast i16* %895 to <8 x i16>*
  %897 = load <8 x i16>, <8 x i16>* %896, align 16
  %898 = getelementptr inbounds i16, i16* %895, i64 8
  %899 = bitcast i16* %898 to <8 x i16>*
  %900 = load <8 x i16>, <8 x i16>* %899, align 16
  %901 = sub <8 x i16> %891, %897
  %902 = sub <8 x i16> %894, %900
  %903 = getelementptr inbounds [704 x i16], [704 x i16]* %288, i64 0, i64 %309
  %904 = bitcast i16* %903 to <8 x i16>*
  store <8 x i16> %901, <8 x i16>* %904, align 16
  %905 = getelementptr inbounds i16, i16* %903, i64 8
  %906 = bitcast i16* %905 to <8 x i16>*
  store <8 x i16> %902, <8 x i16>* %906, align 16
  %907 = add nuw nsw i64 %290, 32
  br label %289
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal fastcc i32 @poly_unmarshal(%struct.poly* nocapture, i8* nocapture readonly) unnamed_addr #3 {
  %3 = bitcast %struct.poly* %0 to i16*
  br label %4

4:                                                ; preds = %75, %2
  %5 = phi i8* [ %1, %2 ], [ %126, %75 ]
  %6 = phi i16* [ %3, %2 ], [ %125, %75 ]
  %7 = phi i64 [ 0, %2 ], [ %127, %75 ]
  %8 = load i8, i8* %5, align 1
  %9 = zext i8 %8 to i16
  %10 = getelementptr inbounds i8, i8* %5, i64 1
  %11 = load i8, i8* %10, align 1
  %12 = and i8 %11, 31
  %13 = zext i8 %12 to i16
  %14 = shl nuw nsw i16 %13, 8
  %15 = or i16 %14, %9
  store i16 %15, i16* %6, align 2
  %16 = load i8, i8* %10, align 1
  %17 = lshr i8 %16, 5
  %18 = zext i8 %17 to i16
  %19 = getelementptr inbounds i8, i8* %5, i64 2
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i16
  %22 = shl nuw nsw i16 %21, 3
  %23 = or i16 %22, %18
  %24 = getelementptr inbounds i8, i8* %5, i64 3
  %25 = load i8, i8* %24, align 1
  %26 = and i8 %25, 3
  %27 = zext i8 %26 to i16
  %28 = shl nuw nsw i16 %27, 11
  %29 = or i16 %23, %28
  %30 = getelementptr inbounds i16, i16* %6, i64 1
  store i16 %29, i16* %30, align 2
  %31 = load i8, i8* %24, align 1
  %32 = lshr i8 %31, 2
  %33 = zext i8 %32 to i16
  %34 = getelementptr inbounds i8, i8* %5, i64 4
  %35 = load i8, i8* %34, align 1
  %36 = and i8 %35, 127
  %37 = zext i8 %36 to i16
  %38 = shl nuw nsw i16 %37, 6
  %39 = or i16 %38, %33
  %40 = getelementptr inbounds i16, i16* %6, i64 2
  store i16 %39, i16* %40, align 2
  %41 = load i8, i8* %34, align 1
  %42 = lshr i8 %41, 7
  %43 = zext i8 %42 to i16
  %44 = getelementptr inbounds i8, i8* %5, i64 5
  %45 = load i8, i8* %44, align 1
  %46 = zext i8 %45 to i16
  %47 = shl nuw nsw i16 %46, 1
  %48 = or i16 %47, %43
  %49 = getelementptr inbounds i8, i8* %5, i64 6
  %50 = load i8, i8* %49, align 1
  %51 = and i8 %50, 15
  %52 = zext i8 %51 to i16
  %53 = shl nuw nsw i16 %52, 9
  %54 = or i16 %48, %53
  %55 = getelementptr inbounds i16, i16* %6, i64 3
  store i16 %54, i16* %55, align 2
  %56 = icmp eq i64 %7, 87
  br i1 %56, label %57, label %75

57:                                               ; preds = %4
  %58 = bitcast %struct.poly* %0 to [704 x i16]*
  br label %59

59:                                               ; preds = %244, %57
  %60 = phi i64 [ 0, %57 ], [ %257, %244 ]
  %61 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 %60
  %62 = bitcast i16* %61 to <8 x i16>*
  %63 = load <8 x i16>, <8 x i16>* %62, align 2
  %64 = getelementptr inbounds i16, i16* %61, i64 8
  %65 = bitcast i16* %64 to <8 x i16>*
  %66 = load <8 x i16>, <8 x i16>* %65, align 2
  %67 = shl <8 x i16> %63, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %68 = shl <8 x i16> %66, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %69 = ashr exact <8 x i16> %67, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %70 = ashr exact <8 x i16> %68, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %71 = bitcast i16* %61 to <8 x i16>*
  store <8 x i16> %69, <8 x i16>* %71, align 2
  %72 = bitcast i16* %64 to <8 x i16>*
  store <8 x i16> %70, <8 x i16>* %72, align 2
  %73 = or i64 %60, 16
  %74 = icmp eq i64 %73, 688
  br i1 %74, label %189, label %244, !llvm.loop !53

75:                                               ; preds = %4
  %76 = load i8, i8* %49, align 1
  %77 = lshr i8 %76, 4
  %78 = zext i8 %77 to i16
  %79 = getelementptr inbounds i8, i8* %5, i64 7
  %80 = load i8, i8* %79, align 1
  %81 = zext i8 %80 to i16
  %82 = shl nuw nsw i16 %81, 4
  %83 = or i16 %82, %78
  %84 = getelementptr inbounds i8, i8* %5, i64 8
  %85 = load i8, i8* %84, align 1
  %86 = and i8 %85, 1
  %87 = zext i8 %86 to i16
  %88 = shl nuw nsw i16 %87, 12
  %89 = or i16 %83, %88
  %90 = getelementptr inbounds i16, i16* %6, i64 4
  store i16 %89, i16* %90, align 2
  %91 = load i8, i8* %84, align 1
  %92 = lshr i8 %91, 1
  %93 = zext i8 %92 to i16
  %94 = getelementptr inbounds i8, i8* %5, i64 9
  %95 = load i8, i8* %94, align 1
  %96 = and i8 %95, 63
  %97 = zext i8 %96 to i16
  %98 = shl nuw nsw i16 %97, 7
  %99 = or i16 %98, %93
  %100 = getelementptr inbounds i16, i16* %6, i64 5
  store i16 %99, i16* %100, align 2
  %101 = load i8, i8* %94, align 1
  %102 = lshr i8 %101, 6
  %103 = zext i8 %102 to i16
  %104 = getelementptr inbounds i8, i8* %5, i64 10
  %105 = load i8, i8* %104, align 1
  %106 = zext i8 %105 to i16
  %107 = shl nuw nsw i16 %106, 2
  %108 = or i16 %107, %103
  %109 = getelementptr inbounds i8, i8* %5, i64 11
  %110 = load i8, i8* %109, align 1
  %111 = and i8 %110, 7
  %112 = zext i8 %111 to i16
  %113 = shl nuw nsw i16 %112, 10
  %114 = or i16 %108, %113
  %115 = getelementptr inbounds i16, i16* %6, i64 6
  store i16 %114, i16* %115, align 2
  %116 = load i8, i8* %109, align 1
  %117 = lshr i8 %116, 3
  %118 = zext i8 %117 to i16
  %119 = getelementptr inbounds i8, i8* %5, i64 12
  %120 = load i8, i8* %119, align 1
  %121 = zext i8 %120 to i16
  %122 = shl nuw nsw i16 %121, 5
  %123 = or i16 %122, %118
  %124 = getelementptr inbounds i16, i16* %6, i64 7
  store i16 %123, i16* %124, align 2
  %125 = getelementptr inbounds i16, i16* %6, i64 8
  %126 = getelementptr inbounds i8, i8* %5, i64 13
  %127 = add nuw nsw i64 %7, 1
  br label %4

128:                                              ; preds = %189, %128
  %129 = phi i64 [ %164, %128 ], [ 0, %189 ]
  %130 = phi <4 x i32> [ %162, %128 ], [ zeroinitializer, %189 ]
  %131 = phi <4 x i32> [ %163, %128 ], [ zeroinitializer, %189 ]
  %132 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 %129
  %133 = bitcast i16* %132 to <4 x i16>*
  %134 = load <4 x i16>, <4 x i16>* %133, align 2
  %135 = getelementptr inbounds i16, i16* %132, i64 4
  %136 = bitcast i16* %135 to <4 x i16>*
  %137 = load <4 x i16>, <4 x i16>* %136, align 2
  %138 = zext <4 x i16> %134 to <4 x i32>
  %139 = zext <4 x i16> %137 to <4 x i32>
  %140 = add <4 x i32> %130, %138
  %141 = add <4 x i32> %131, %139
  %142 = add nuw nsw i64 %129, 8
  %143 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 %142
  %144 = bitcast i16* %143 to <4 x i16>*
  %145 = load <4 x i16>, <4 x i16>* %144, align 2
  %146 = getelementptr inbounds i16, i16* %143, i64 4
  %147 = bitcast i16* %146 to <4 x i16>*
  %148 = load <4 x i16>, <4 x i16>* %147, align 2
  %149 = zext <4 x i16> %145 to <4 x i32>
  %150 = zext <4 x i16> %148 to <4 x i32>
  %151 = add <4 x i32> %140, %149
  %152 = add <4 x i32> %141, %150
  %153 = add nuw nsw i64 %129, 16
  %154 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 %153
  %155 = bitcast i16* %154 to <4 x i16>*
  %156 = load <4 x i16>, <4 x i16>* %155, align 2
  %157 = getelementptr inbounds i16, i16* %154, i64 4
  %158 = bitcast i16* %157 to <4 x i16>*
  %159 = load <4 x i16>, <4 x i16>* %158, align 2
  %160 = zext <4 x i16> %156 to <4 x i32>
  %161 = zext <4 x i16> %159 to <4 x i32>
  %162 = add <4 x i32> %151, %160
  %163 = add <4 x i32> %152, %161
  %164 = add nuw nsw i64 %129, 24
  %165 = icmp eq i64 %164, 696
  br i1 %165, label %166, label %128, !llvm.loop !54

166:                                              ; preds = %128
  %167 = add <4 x i32> %163, %162
  %168 = shufflevector <4 x i32> %167, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %169 = add <4 x i32> %167, %168
  %170 = shufflevector <4 x i32> %169, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %171 = add <4 x i32> %169, %170
  %172 = extractelement <4 x i32> %171, i32 0
  %173 = getelementptr inbounds %struct.poly, %struct.poly* %0, i64 0, i32 0, i32 0, i64 87
  %174 = bitcast <2 x i64>* %173 to i16*
  %175 = load i16, i16* %174, align 2
  %176 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 697
  %177 = load i16, i16* %176, align 2
  %178 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 698
  %179 = load i16, i16* %178, align 2
  %180 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 699
  %181 = load i16, i16* %180, align 2
  %182 = trunc i32 %172 to i16
  %183 = add i16 %175, %182
  %184 = add i16 %177, %183
  %185 = add i16 %179, %184
  %186 = add i16 %181, %185
  %187 = sub i16 0, %186
  %188 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 700
  store i16 %187, i16* %188, align 8
  br label %242

189:                                              ; preds = %59
  %190 = getelementptr inbounds %struct.poly, %struct.poly* %0, i64 0, i32 0, i32 0, i64 86
  %191 = bitcast <2 x i64>* %190 to i16*
  %192 = load i16, i16* %191, align 2
  %193 = shl i16 %192, 3
  %194 = ashr exact i16 %193, 3
  store i16 %194, i16* %191, align 2
  %195 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 689
  %196 = load i16, i16* %195, align 2
  %197 = shl i16 %196, 3
  %198 = ashr exact i16 %197, 3
  store i16 %198, i16* %195, align 2
  %199 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 690
  %200 = load i16, i16* %199, align 2
  %201 = shl i16 %200, 3
  %202 = ashr exact i16 %201, 3
  store i16 %202, i16* %199, align 2
  %203 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 691
  %204 = load i16, i16* %203, align 2
  %205 = shl i16 %204, 3
  %206 = ashr exact i16 %205, 3
  store i16 %206, i16* %203, align 2
  %207 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 692
  %208 = load i16, i16* %207, align 2
  %209 = shl i16 %208, 3
  %210 = ashr exact i16 %209, 3
  store i16 %210, i16* %207, align 2
  %211 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 693
  %212 = load i16, i16* %211, align 2
  %213 = shl i16 %212, 3
  %214 = ashr exact i16 %213, 3
  store i16 %214, i16* %211, align 2
  %215 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 694
  %216 = load i16, i16* %215, align 2
  %217 = shl i16 %216, 3
  %218 = ashr exact i16 %217, 3
  store i16 %218, i16* %215, align 2
  %219 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 695
  %220 = load i16, i16* %219, align 2
  %221 = shl i16 %220, 3
  %222 = ashr exact i16 %221, 3
  store i16 %222, i16* %219, align 2
  %223 = getelementptr inbounds %struct.poly, %struct.poly* %0, i64 0, i32 0, i32 0, i64 87
  %224 = bitcast <2 x i64>* %223 to i16*
  %225 = load i16, i16* %224, align 2
  %226 = shl i16 %225, 3
  %227 = ashr exact i16 %226, 3
  store i16 %227, i16* %224, align 2
  %228 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 697
  %229 = load i16, i16* %228, align 2
  %230 = shl i16 %229, 3
  %231 = ashr exact i16 %230, 3
  store i16 %231, i16* %228, align 2
  %232 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 698
  %233 = load i16, i16* %232, align 2
  %234 = shl i16 %233, 3
  %235 = ashr exact i16 %234, 3
  store i16 %235, i16* %232, align 2
  %236 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 699
  %237 = load i16, i16* %236, align 2
  %238 = shl i16 %237, 3
  %239 = ashr exact i16 %238, 3
  store i16 %239, i16* %236, align 2
  %240 = load i8, i8* %49, align 1
  %241 = icmp ugt i8 %240, 15
  br i1 %241, label %242, label %128

242:                                              ; preds = %189, %166
  %243 = phi i32 [ 1, %166 ], [ 0, %189 ]
  ret i32 %243

244:                                              ; preds = %59
  %245 = getelementptr inbounds [704 x i16], [704 x i16]* %58, i64 0, i64 %73
  %246 = bitcast i16* %245 to <8 x i16>*
  %247 = load <8 x i16>, <8 x i16>* %246, align 2
  %248 = getelementptr inbounds i16, i16* %245, i64 8
  %249 = bitcast i16* %248 to <8 x i16>*
  %250 = load <8 x i16>, <8 x i16>* %249, align 2
  %251 = shl <8 x i16> %247, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %252 = shl <8 x i16> %250, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %253 = ashr exact <8 x i16> %251, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %254 = ashr exact <8 x i16> %252, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %255 = bitcast i16* %245 to <8 x i16>*
  store <8 x i16> %253, <8 x i16>* %255, align 2
  %256 = bitcast i16* %248 to <8 x i16>*
  store <8 x i16> %254, <8 x i16>* %256, align 2
  %257 = add nuw nsw i64 %60, 32
  br label %59
}

declare i32 @CRYPTO_memcmp(i8*, i8*, i64) local_unnamed_addr #4

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @HRSS_marshal_public_key(i8* nocapture, %struct.HRSS_public_key*) local_unnamed_addr #3 {
  %3 = ptrtoint %struct.HRSS_public_key* %1 to i64
  %4 = add i64 %3, 15
  %5 = and i64 %4, -16
  %6 = inttoptr i64 %5 to %struct.public_key*
  %7 = getelementptr inbounds %struct.public_key, %struct.public_key* %6, i64 0, i32 0
  tail call fastcc void @poly_marshal(i8* %0, %struct.poly* %7)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @HRSS_parse_public_key(%struct.HRSS_public_key*, i8* nocapture readonly) local_unnamed_addr #0 {
  %3 = ptrtoint %struct.HRSS_public_key* %0 to i64
  %4 = add i64 %3, 15
  %5 = and i64 %4, -16
  %6 = inttoptr i64 %5 to %struct.public_key*
  %7 = getelementptr inbounds %struct.public_key, %struct.public_key* %6, i64 0, i32 0
  %8 = tail call fastcc i32 @poly_unmarshal(%struct.poly* %7, i8* %1)
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %14, label %10

10:                                               ; preds = %2
  %11 = inttoptr i64 %5 to [704 x i16]*
  %12 = getelementptr inbounds [704 x i16], [704 x i16]* %11, i64 0, i64 701
  %13 = bitcast i16* %12 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %13, i8 0, i64 6, i1 false) #5
  br label %14

14:                                               ; preds = %2, %10
  %15 = phi i32 [ 1, %10 ], [ 0, %2 ]
  ret i32 %15
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @poly2_reverse_700(%struct.poly2* nocapture, %struct.poly2* nocapture readonly) unnamed_addr #0 {
  %3 = alloca %struct.poly2, align 16
  %4 = bitcast %struct.poly2* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 88, i8* nonnull %4) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 -86, i64 88, i1 false)
  br label %5

5:                                                ; preds = %5, %2
  %6 = phi i64 [ 0, %2 ], [ %38, %5 ]
  %7 = getelementptr inbounds %struct.poly2, %struct.poly2* %1, i64 0, i32 0, i64 %6
  %8 = load i64, i64* %7, align 8
  %9 = lshr i64 %8, 1
  %10 = and i64 %9, 6148914691236517205
  %11 = shl i64 %8, 1
  %12 = and i64 %11, -6148914691236517206
  %13 = or i64 %12, %10
  %14 = lshr i64 %13, 2
  %15 = and i64 %14, 3689348814741910323
  %16 = shl i64 %13, 2
  %17 = and i64 %16, -3689348814741910324
  %18 = or i64 %17, %15
  %19 = lshr i64 %18, 4
  %20 = and i64 %19, 1085102592571150095
  %21 = shl i64 %18, 4
  %22 = and i64 %21, -1085102592571150096
  %23 = or i64 %22, %20
  %24 = lshr i64 %23, 8
  %25 = and i64 %24, 71777214294589695
  %26 = shl i64 %23, 8
  %27 = and i64 %26, -71777214294589696
  %28 = or i64 %27, %25
  %29 = lshr i64 %28, 16
  %30 = and i64 %29, 281470681808895
  %31 = shl i64 %28, 16
  %32 = and i64 %31, -281470681808896
  %33 = or i64 %32, %30
  %34 = lshr i64 %33, 32
  %35 = shl i64 %33, 32
  %36 = or i64 %35, %34
  %37 = getelementptr inbounds %struct.poly2, %struct.poly2* %3, i64 0, i32 0, i64 %6
  store i64 %36, i64* %37, align 8
  %38 = add nuw nsw i64 %6, 1
  %39 = icmp eq i64 %38, 11
  br i1 %39, label %40, label %5

40:                                               ; preds = %5
  %41 = getelementptr inbounds %struct.poly2, %struct.poly2* %3, i64 0, i32 0, i64 10
  %42 = load i64, i64* %41, align 16
  %43 = getelementptr inbounds %struct.poly2, %struct.poly2* %3, i64 0, i32 0, i64 8
  %44 = bitcast i64* %43 to <2 x i64>*
  %45 = load <2 x i64>, <2 x i64>* %44, align 16
  %46 = insertelement <2 x i64> %45, i64 %42, i32 0
  %47 = lshr <2 x i64> %46, <i64 4, i64 4>
  %48 = shl <2 x i64> %45, <i64 60, i64 60>
  %49 = shufflevector <2 x i64> %48, <2 x i64> undef, <2 x i32> <i32 1, i32 0>
  %50 = or <2 x i64> %49, %47
  %51 = bitcast %struct.poly2* %0 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8
  %52 = getelementptr inbounds %struct.poly2, %struct.poly2* %0, i64 0, i32 0, i64 2
  %53 = getelementptr inbounds %struct.poly2, %struct.poly2* %3, i64 0, i32 0, i64 6
  %54 = bitcast i64* %53 to <2 x i64>*
  %55 = load <2 x i64>, <2 x i64>* %54, align 16
  %56 = shufflevector <2 x i64> %45, <2 x i64> %55, <2 x i32> <i32 0, i32 3>
  %57 = lshr <2 x i64> %56, <i64 4, i64 4>
  %58 = shl <2 x i64> %55, <i64 60, i64 60>
  %59 = shufflevector <2 x i64> %58, <2 x i64> undef, <2 x i32> <i32 1, i32 0>
  %60 = or <2 x i64> %59, %57
  %61 = bitcast i64* %52 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %61, align 8
  %62 = getelementptr inbounds %struct.poly2, %struct.poly2* %0, i64 0, i32 0, i64 4
  %63 = getelementptr inbounds %struct.poly2, %struct.poly2* %3, i64 0, i32 0, i64 4
  %64 = bitcast i64* %63 to <2 x i64>*
  %65 = load <2 x i64>, <2 x i64>* %64, align 16
  %66 = shufflevector <2 x i64> %55, <2 x i64> %65, <2 x i32> <i32 0, i32 3>
  %67 = lshr <2 x i64> %66, <i64 4, i64 4>
  %68 = shl <2 x i64> %65, <i64 60, i64 60>
  %69 = shufflevector <2 x i64> %68, <2 x i64> undef, <2 x i32> <i32 1, i32 0>
  %70 = or <2 x i64> %69, %67
  %71 = bitcast i64* %62 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %71, align 8
  %72 = getelementptr inbounds %struct.poly2, %struct.poly2* %0, i64 0, i32 0, i64 6
  %73 = getelementptr inbounds %struct.poly2, %struct.poly2* %3, i64 0, i32 0, i64 2
  %74 = bitcast i64* %73 to <2 x i64>*
  %75 = load <2 x i64>, <2 x i64>* %74, align 16
  %76 = shufflevector <2 x i64> %65, <2 x i64> %75, <2 x i32> <i32 0, i32 3>
  %77 = lshr <2 x i64> %76, <i64 4, i64 4>
  %78 = shl <2 x i64> %75, <i64 60, i64 60>
  %79 = shufflevector <2 x i64> %78, <2 x i64> undef, <2 x i32> <i32 1, i32 0>
  %80 = or <2 x i64> %79, %77
  %81 = bitcast i64* %72 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %81, align 8
  %82 = getelementptr inbounds %struct.poly2, %struct.poly2* %0, i64 0, i32 0, i64 8
  %83 = bitcast %struct.poly2* %3 to <2 x i64>*
  %84 = load <2 x i64>, <2 x i64>* %83, align 16
  %85 = shufflevector <2 x i64> %75, <2 x i64> %84, <2 x i32> <i32 0, i32 3>
  %86 = lshr <2 x i64> %85, <i64 4, i64 4>
  %87 = shl <2 x i64> %84, <i64 60, i64 60>
  %88 = shufflevector <2 x i64> %87, <2 x i64> undef, <2 x i32> <i32 1, i32 0>
  %89 = or <2 x i64> %88, %86
  %90 = bitcast i64* %82 to <2 x i64>*
  store <2 x i64> %89, <2 x i64>* %90, align 8
  %91 = extractelement <2 x i64> %84, i32 0
  %92 = lshr i64 %91, 4
  %93 = getelementptr inbounds %struct.poly2, %struct.poly2* %0, i64 0, i32 0, i64 10
  store i64 %92, i64* %93, align 8
  call void @llvm.lifetime.end.p0i8(i64 88, i8* nonnull %4) #5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @poly_mul_vec_aux(<2 x i64>* noalias, <2 x i64>* noalias, <2 x i64>* noalias readonly, <2 x i64>* noalias readonly, i64) unnamed_addr #2 {
  switch i64 %4, label %529 [
    i64 2, label %6
    i64 3, label %198
  ]

6:                                                ; preds = %5
  %7 = load <2 x i64>, <2 x i64>* %2, align 16
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %2, i64 1
  %9 = load <2 x i64>, <2 x i64>* %8, align 16
  %10 = bitcast <2 x i64>* %3 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 16
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> zeroinitializer
  %13 = bitcast <2 x i64> %7 to <8 x i16>
  %14 = mul <8 x i16> %12, %13
  %15 = bitcast <2 x i64> %9 to <8 x i16>
  %16 = mul <8 x i16> %12, %15
  %17 = getelementptr inbounds <2 x i64>, <2 x i64>* %3, i64 1
  %18 = bitcast <2 x i64>* %17 to <8 x i16>*
  %19 = load <8 x i16>, <8 x i16>* %18, align 16
  %20 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> zeroinitializer
  %21 = mul <8 x i16> %20, %13
  %22 = add <8 x i16> %21, %16
  %23 = mul <8 x i16> %20, %15
  %24 = bitcast <2 x i64> %7 to <16 x i8>
  %25 = shufflevector <16 x i8> %24, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %26 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %24, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %27 = bitcast <2 x i64> %9 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %29 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %27, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %30 = or <16 x i8> %29, %25
  %31 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %32 = bitcast <16 x i8> %26 to <8 x i16>
  %33 = mul <8 x i16> %31, %32
  %34 = add <8 x i16> %33, %14
  %35 = bitcast <16 x i8> %30 to <8 x i16>
  %36 = mul <8 x i16> %31, %35
  %37 = bitcast <16 x i8> %28 to <8 x i16>
  %38 = mul <8 x i16> %31, %37
  %39 = add <8 x i16> %38, %23
  %40 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %41 = mul <8 x i16> %40, %32
  %42 = mul <8 x i16> %40, %35
  %43 = add <8 x i16> %39, %42
  %44 = mul <8 x i16> %40, %37
  %45 = shufflevector <16 x i8> %26, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %46 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %26, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %47 = shufflevector <16 x i8> %30, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %48 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %30, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %49 = or <16 x i8> %48, %45
  %50 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %28, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %51 = or <16 x i8> %47, %50
  %52 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %53 = bitcast <16 x i8> %46 to <8 x i16>
  %54 = mul <8 x i16> %52, %53
  %55 = add <8 x i16> %34, %54
  %56 = bitcast <16 x i8> %49 to <8 x i16>
  %57 = mul <8 x i16> %52, %56
  %58 = bitcast <16 x i8> %51 to <8 x i16>
  %59 = mul <8 x i16> %52, %58
  %60 = add <8 x i16> %43, %59
  %61 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %62 = mul <8 x i16> %61, %53
  %63 = mul <8 x i16> %61, %56
  %64 = add <8 x i16> %60, %63
  %65 = mul <8 x i16> %61, %58
  %66 = add <8 x i16> %65, %44
  %67 = shufflevector <16 x i8> %46, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %68 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %46, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %69 = shufflevector <16 x i8> %49, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %70 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %49, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %71 = or <16 x i8> %70, %67
  %72 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %51, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %73 = or <16 x i8> %72, %69
  %74 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %75 = bitcast <16 x i8> %68 to <8 x i16>
  %76 = mul <8 x i16> %74, %75
  %77 = add <8 x i16> %55, %76
  %78 = bitcast <16 x i8> %71 to <8 x i16>
  %79 = mul <8 x i16> %74, %78
  %80 = bitcast <16 x i8> %73 to <8 x i16>
  %81 = mul <8 x i16> %74, %80
  %82 = add <8 x i16> %64, %81
  %83 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %84 = mul <8 x i16> %83, %75
  %85 = mul <8 x i16> %83, %78
  %86 = add <8 x i16> %82, %85
  %87 = mul <8 x i16> %83, %80
  %88 = add <8 x i16> %66, %87
  %89 = shufflevector <16 x i8> %68, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %90 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %68, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %91 = shufflevector <16 x i8> %71, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %92 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %71, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %93 = or <16 x i8> %92, %89
  %94 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %73, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %95 = or <16 x i8> %94, %91
  %96 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %97 = bitcast <16 x i8> %90 to <8 x i16>
  %98 = mul <8 x i16> %96, %97
  %99 = add <8 x i16> %77, %98
  %100 = bitcast <16 x i8> %93 to <8 x i16>
  %101 = mul <8 x i16> %96, %100
  %102 = bitcast <16 x i8> %95 to <8 x i16>
  %103 = mul <8 x i16> %96, %102
  %104 = add <8 x i16> %86, %103
  %105 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %106 = mul <8 x i16> %105, %97
  %107 = mul <8 x i16> %105, %100
  %108 = add <8 x i16> %104, %107
  %109 = mul <8 x i16> %105, %102
  %110 = add <8 x i16> %88, %109
  %111 = shufflevector <16 x i8> %90, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %112 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %90, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %113 = shufflevector <16 x i8> %93, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %114 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %93, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %115 = or <16 x i8> %114, %111
  %116 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %95, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %117 = or <16 x i8> %116, %113
  %118 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %119 = bitcast <16 x i8> %112 to <8 x i16>
  %120 = mul <8 x i16> %118, %119
  %121 = add <8 x i16> %99, %120
  %122 = bitcast <16 x i8> %115 to <8 x i16>
  %123 = mul <8 x i16> %118, %122
  %124 = bitcast <16 x i8> %117 to <8 x i16>
  %125 = mul <8 x i16> %118, %124
  %126 = add <8 x i16> %108, %125
  %127 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %128 = mul <8 x i16> %127, %119
  %129 = mul <8 x i16> %127, %122
  %130 = add <8 x i16> %126, %129
  %131 = mul <8 x i16> %127, %124
  %132 = add <8 x i16> %110, %131
  %133 = shufflevector <16 x i8> %112, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %134 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %112, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %135 = shufflevector <16 x i8> %115, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %136 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %115, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %137 = or <16 x i8> %136, %133
  %138 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %117, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %139 = or <16 x i8> %138, %135
  %140 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %141 = bitcast <16 x i8> %134 to <8 x i16>
  %142 = mul <8 x i16> %140, %141
  %143 = add <8 x i16> %121, %142
  %144 = bitcast <16 x i8> %137 to <8 x i16>
  %145 = mul <8 x i16> %140, %144
  %146 = bitcast <16 x i8> %139 to <8 x i16>
  %147 = mul <8 x i16> %140, %146
  %148 = add <8 x i16> %130, %147
  %149 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %150 = mul <8 x i16> %149, %141
  %151 = mul <8 x i16> %149, %144
  %152 = add <8 x i16> %148, %151
  %153 = mul <8 x i16> %149, %146
  %154 = add <8 x i16> %132, %153
  %155 = shufflevector <16 x i8> %134, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %156 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %134, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %157 = shufflevector <16 x i8> %137, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %158 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %137, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %159 = or <16 x i8> %158, %155
  %160 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %139, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %161 = or <16 x i8> %160, %157
  %162 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %163 = bitcast <16 x i8> %156 to <8 x i16>
  %164 = mul <8 x i16> %162, %163
  %165 = add <8 x i16> %143, %164
  %166 = bitcast <16 x i8> %159 to <8 x i16>
  %167 = mul <8 x i16> %162, %166
  %168 = bitcast <16 x i8> %161 to <8 x i16>
  %169 = mul <8 x i16> %162, %168
  %170 = add <8 x i16> %152, %169
  %171 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %172 = mul <8 x i16> %171, %163
  %173 = add <8 x i16> %22, %41
  %174 = add <8 x i16> %173, %62
  %175 = add <8 x i16> %174, %36
  %176 = add <8 x i16> %175, %84
  %177 = add <8 x i16> %176, %106
  %178 = add <8 x i16> %177, %57
  %179 = add <8 x i16> %178, %128
  %180 = add <8 x i16> %179, %150
  %181 = add <8 x i16> %180, %79
  %182 = add <8 x i16> %181, %172
  %183 = add <8 x i16> %182, %101
  %184 = add <8 x i16> %183, %123
  %185 = add <8 x i16> %184, %145
  %186 = add <8 x i16> %185, %167
  %187 = mul <8 x i16> %171, %166
  %188 = add <8 x i16> %170, %187
  %189 = mul <8 x i16> %171, %168
  %190 = add <8 x i16> %154, %189
  %191 = bitcast <2 x i64>* %0 to <8 x i16>*
  store <8 x i16> %165, <8 x i16>* %191, align 16
  %192 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %193 = bitcast <2 x i64>* %192 to <8 x i16>*
  store <8 x i16> %186, <8 x i16>* %193, align 16
  %194 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %195 = bitcast <2 x i64>* %194 to <8 x i16>*
  store <8 x i16> %188, <8 x i16>* %195, align 16
  %196 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  store <8 x i16> %190, <8 x i16>* %197, align 16
  br label %645

198:                                              ; preds = %5
  %199 = load <2 x i64>, <2 x i64>* %2, align 16
  %200 = getelementptr inbounds <2 x i64>, <2 x i64>* %2, i64 1
  %201 = load <2 x i64>, <2 x i64>* %200, align 16
  %202 = getelementptr inbounds <2 x i64>, <2 x i64>* %2, i64 2
  %203 = load <2 x i64>, <2 x i64>* %202, align 16
  %204 = bitcast <2 x i64>* %3 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = shufflevector <8 x i16> %205, <8 x i16> undef, <8 x i32> zeroinitializer
  %207 = bitcast <2 x i64> %199 to <8 x i16>
  %208 = mul <8 x i16> %206, %207
  %209 = bitcast <2 x i64> %201 to <8 x i16>
  %210 = mul <8 x i16> %206, %209
  %211 = bitcast <2 x i64> %203 to <8 x i16>
  %212 = mul <8 x i16> %206, %211
  %213 = getelementptr inbounds <2 x i64>, <2 x i64>* %3, i64 1
  %214 = bitcast <2 x i64>* %213 to <8 x i16>*
  %215 = load <8 x i16>, <8 x i16>* %214, align 16
  %216 = shufflevector <8 x i16> %215, <8 x i16> undef, <8 x i32> zeroinitializer
  %217 = mul <8 x i16> %216, %207
  %218 = add <8 x i16> %217, %210
  %219 = mul <8 x i16> %216, %209
  %220 = add <8 x i16> %219, %212
  %221 = mul <8 x i16> %216, %211
  %222 = getelementptr inbounds <2 x i64>, <2 x i64>* %3, i64 2
  %223 = bitcast <2 x i64>* %222 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> zeroinitializer
  %226 = mul <8 x i16> %225, %207
  %227 = mul <8 x i16> %225, %209
  %228 = mul <8 x i16> %225, %211
  %229 = bitcast <2 x i64> %199 to <16 x i8>
  %230 = shufflevector <16 x i8> %229, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %231 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %229, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %232 = bitcast <2 x i64> %201 to <16 x i8>
  %233 = shufflevector <16 x i8> %232, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %234 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %232, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %235 = or <16 x i8> %234, %230
  %236 = bitcast <2 x i64> %203 to <16 x i8>
  %237 = shufflevector <16 x i8> %236, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %238 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %236, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %239 = or <16 x i8> %238, %233
  %240 = shufflevector <8 x i16> %205, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %241 = bitcast <16 x i8> %231 to <8 x i16>
  %242 = mul <8 x i16> %240, %241
  %243 = add <8 x i16> %242, %208
  %244 = bitcast <16 x i8> %235 to <8 x i16>
  %245 = mul <8 x i16> %240, %244
  %246 = add <8 x i16> %218, %245
  %247 = bitcast <16 x i8> %239 to <8 x i16>
  %248 = mul <8 x i16> %240, %247
  %249 = bitcast <16 x i8> %237 to <8 x i16>
  %250 = mul <8 x i16> %240, %249
  %251 = shufflevector <8 x i16> %215, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %252 = mul <8 x i16> %251, %241
  %253 = add <8 x i16> %246, %252
  %254 = mul <8 x i16> %251, %244
  %255 = mul <8 x i16> %251, %247
  %256 = mul <8 x i16> %251, %249
  %257 = add <8 x i16> %228, %256
  %258 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %259 = mul <8 x i16> %258, %241
  %260 = mul <8 x i16> %258, %244
  %261 = mul <8 x i16> %258, %247
  %262 = add <8 x i16> %257, %261
  %263 = mul <8 x i16> %258, %249
  %264 = shufflevector <16 x i8> %231, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %265 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %231, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %266 = shufflevector <16 x i8> %235, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %267 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %235, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %268 = or <16 x i8> %267, %264
  %269 = shufflevector <16 x i8> %239, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %270 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %239, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %271 = or <16 x i8> %270, %266
  %272 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %237, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %273 = or <16 x i8> %269, %272
  %274 = shufflevector <8 x i16> %205, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %275 = bitcast <16 x i8> %265 to <8 x i16>
  %276 = mul <8 x i16> %274, %275
  %277 = add <8 x i16> %243, %276
  %278 = bitcast <16 x i8> %268 to <8 x i16>
  %279 = mul <8 x i16> %274, %278
  %280 = bitcast <16 x i8> %271 to <8 x i16>
  %281 = mul <8 x i16> %274, %280
  %282 = bitcast <16 x i8> %273 to <8 x i16>
  %283 = mul <8 x i16> %274, %282
  %284 = shufflevector <8 x i16> %215, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %285 = mul <8 x i16> %284, %275
  %286 = mul <8 x i16> %284, %278
  %287 = mul <8 x i16> %284, %280
  %288 = mul <8 x i16> %284, %282
  %289 = add <8 x i16> %262, %288
  %290 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %291 = mul <8 x i16> %290, %275
  %292 = mul <8 x i16> %290, %278
  %293 = mul <8 x i16> %290, %280
  %294 = add <8 x i16> %289, %293
  %295 = mul <8 x i16> %290, %282
  %296 = add <8 x i16> %295, %263
  %297 = shufflevector <16 x i8> %265, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %298 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %265, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %299 = shufflevector <16 x i8> %268, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %300 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %268, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %301 = or <16 x i8> %300, %297
  %302 = shufflevector <16 x i8> %271, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %303 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %271, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %304 = or <16 x i8> %303, %299
  %305 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %273, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %306 = or <16 x i8> %305, %302
  %307 = shufflevector <8 x i16> %205, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %308 = bitcast <16 x i8> %298 to <8 x i16>
  %309 = mul <8 x i16> %307, %308
  %310 = add <8 x i16> %277, %309
  %311 = bitcast <16 x i8> %301 to <8 x i16>
  %312 = mul <8 x i16> %307, %311
  %313 = bitcast <16 x i8> %304 to <8 x i16>
  %314 = mul <8 x i16> %307, %313
  %315 = bitcast <16 x i8> %306 to <8 x i16>
  %316 = mul <8 x i16> %307, %315
  %317 = shufflevector <8 x i16> %215, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %318 = mul <8 x i16> %317, %308
  %319 = mul <8 x i16> %317, %311
  %320 = mul <8 x i16> %317, %313
  %321 = mul <8 x i16> %317, %315
  %322 = add <8 x i16> %294, %321
  %323 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %324 = mul <8 x i16> %323, %308
  %325 = mul <8 x i16> %323, %311
  %326 = mul <8 x i16> %323, %313
  %327 = add <8 x i16> %322, %326
  %328 = mul <8 x i16> %323, %315
  %329 = add <8 x i16> %296, %328
  %330 = shufflevector <16 x i8> %298, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %331 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %298, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %332 = shufflevector <16 x i8> %301, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %333 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %301, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %334 = or <16 x i8> %333, %330
  %335 = shufflevector <16 x i8> %304, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %336 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %304, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %337 = or <16 x i8> %336, %332
  %338 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %306, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %339 = or <16 x i8> %338, %335
  %340 = shufflevector <8 x i16> %205, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %341 = bitcast <16 x i8> %331 to <8 x i16>
  %342 = mul <8 x i16> %340, %341
  %343 = add <8 x i16> %310, %342
  %344 = bitcast <16 x i8> %334 to <8 x i16>
  %345 = mul <8 x i16> %340, %344
  %346 = bitcast <16 x i8> %337 to <8 x i16>
  %347 = mul <8 x i16> %340, %346
  %348 = bitcast <16 x i8> %339 to <8 x i16>
  %349 = mul <8 x i16> %340, %348
  %350 = shufflevector <8 x i16> %215, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %351 = mul <8 x i16> %350, %341
  %352 = mul <8 x i16> %350, %344
  %353 = mul <8 x i16> %350, %346
  %354 = mul <8 x i16> %350, %348
  %355 = add <8 x i16> %327, %354
  %356 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %357 = mul <8 x i16> %356, %341
  %358 = mul <8 x i16> %356, %344
  %359 = mul <8 x i16> %356, %346
  %360 = add <8 x i16> %355, %359
  %361 = mul <8 x i16> %356, %348
  %362 = add <8 x i16> %329, %361
  %363 = shufflevector <16 x i8> %331, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %364 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %331, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %365 = shufflevector <16 x i8> %334, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %366 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %334, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %367 = or <16 x i8> %366, %363
  %368 = shufflevector <16 x i8> %337, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %369 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %337, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %370 = or <16 x i8> %369, %365
  %371 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %339, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %372 = or <16 x i8> %371, %368
  %373 = shufflevector <8 x i16> %205, <8 x i16> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %374 = bitcast <16 x i8> %364 to <8 x i16>
  %375 = mul <8 x i16> %373, %374
  %376 = add <8 x i16> %343, %375
  %377 = bitcast <16 x i8> %367 to <8 x i16>
  %378 = mul <8 x i16> %373, %377
  %379 = bitcast <16 x i8> %370 to <8 x i16>
  %380 = mul <8 x i16> %373, %379
  %381 = bitcast <16 x i8> %372 to <8 x i16>
  %382 = mul <8 x i16> %373, %381
  %383 = shufflevector <8 x i16> %215, <8 x i16> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %384 = mul <8 x i16> %383, %374
  %385 = mul <8 x i16> %383, %377
  %386 = mul <8 x i16> %383, %379
  %387 = mul <8 x i16> %383, %381
  %388 = add <8 x i16> %360, %387
  %389 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %390 = mul <8 x i16> %389, %374
  %391 = mul <8 x i16> %389, %377
  %392 = mul <8 x i16> %389, %379
  %393 = add <8 x i16> %388, %392
  %394 = mul <8 x i16> %389, %381
  %395 = add <8 x i16> %362, %394
  %396 = shufflevector <16 x i8> %364, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %397 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %364, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %398 = shufflevector <16 x i8> %367, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %399 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %367, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %400 = or <16 x i8> %399, %396
  %401 = shufflevector <16 x i8> %370, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %402 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %370, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %403 = or <16 x i8> %402, %398
  %404 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %372, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %405 = or <16 x i8> %404, %401
  %406 = shufflevector <8 x i16> %205, <8 x i16> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %407 = bitcast <16 x i8> %397 to <8 x i16>
  %408 = mul <8 x i16> %406, %407
  %409 = add <8 x i16> %376, %408
  %410 = bitcast <16 x i8> %400 to <8 x i16>
  %411 = mul <8 x i16> %406, %410
  %412 = bitcast <16 x i8> %403 to <8 x i16>
  %413 = mul <8 x i16> %406, %412
  %414 = bitcast <16 x i8> %405 to <8 x i16>
  %415 = mul <8 x i16> %406, %414
  %416 = shufflevector <8 x i16> %215, <8 x i16> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %417 = mul <8 x i16> %416, %407
  %418 = mul <8 x i16> %416, %410
  %419 = mul <8 x i16> %416, %412
  %420 = mul <8 x i16> %416, %414
  %421 = add <8 x i16> %393, %420
  %422 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %423 = mul <8 x i16> %422, %407
  %424 = mul <8 x i16> %422, %410
  %425 = mul <8 x i16> %422, %412
  %426 = add <8 x i16> %421, %425
  %427 = mul <8 x i16> %422, %414
  %428 = add <8 x i16> %395, %427
  %429 = shufflevector <16 x i8> %397, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %430 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %397, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %431 = shufflevector <16 x i8> %400, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %432 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %400, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %433 = or <16 x i8> %432, %429
  %434 = shufflevector <16 x i8> %403, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %435 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %403, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %436 = or <16 x i8> %435, %431
  %437 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %405, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %438 = or <16 x i8> %437, %434
  %439 = shufflevector <8 x i16> %205, <8 x i16> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %440 = bitcast <16 x i8> %430 to <8 x i16>
  %441 = mul <8 x i16> %439, %440
  %442 = add <8 x i16> %409, %441
  %443 = bitcast <16 x i8> %433 to <8 x i16>
  %444 = mul <8 x i16> %439, %443
  %445 = bitcast <16 x i8> %436 to <8 x i16>
  %446 = mul <8 x i16> %439, %445
  %447 = bitcast <16 x i8> %438 to <8 x i16>
  %448 = mul <8 x i16> %439, %447
  %449 = shufflevector <8 x i16> %215, <8 x i16> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %450 = mul <8 x i16> %449, %440
  %451 = add <8 x i16> %253, %285
  %452 = add <8 x i16> %451, %318
  %453 = add <8 x i16> %452, %351
  %454 = add <8 x i16> %453, %279
  %455 = add <8 x i16> %454, %384
  %456 = add <8 x i16> %455, %417
  %457 = add <8 x i16> %456, %312
  %458 = add <8 x i16> %457, %450
  %459 = add <8 x i16> %458, %345
  %460 = add <8 x i16> %459, %378
  %461 = add <8 x i16> %460, %411
  %462 = add <8 x i16> %461, %444
  %463 = mul <8 x i16> %449, %443
  %464 = mul <8 x i16> %449, %445
  %465 = mul <8 x i16> %449, %447
  %466 = add <8 x i16> %426, %465
  %467 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %468 = mul <8 x i16> %467, %440
  %469 = add <8 x i16> %220, %254
  %470 = add <8 x i16> %469, %226
  %471 = add <8 x i16> %470, %248
  %472 = add <8 x i16> %471, %259
  %473 = add <8 x i16> %472, %291
  %474 = add <8 x i16> %473, %324
  %475 = add <8 x i16> %474, %357
  %476 = add <8 x i16> %475, %286
  %477 = add <8 x i16> %476, %390
  %478 = add <8 x i16> %477, %281
  %479 = add <8 x i16> %478, %423
  %480 = add <8 x i16> %479, %319
  %481 = add <8 x i16> %480, %468
  %482 = add <8 x i16> %481, %314
  %483 = add <8 x i16> %482, %352
  %484 = add <8 x i16> %483, %347
  %485 = add <8 x i16> %484, %385
  %486 = add <8 x i16> %485, %380
  %487 = add <8 x i16> %486, %418
  %488 = add <8 x i16> %487, %413
  %489 = add <8 x i16> %488, %463
  %490 = add <8 x i16> %489, %446
  %491 = mul <8 x i16> %467, %443
  %492 = add <8 x i16> %250, %221
  %493 = add <8 x i16> %492, %227
  %494 = add <8 x i16> %493, %255
  %495 = add <8 x i16> %494, %260
  %496 = add <8 x i16> %495, %292
  %497 = add <8 x i16> %496, %283
  %498 = add <8 x i16> %497, %287
  %499 = add <8 x i16> %498, %325
  %500 = add <8 x i16> %499, %316
  %501 = add <8 x i16> %500, %320
  %502 = add <8 x i16> %501, %358
  %503 = add <8 x i16> %502, %349
  %504 = add <8 x i16> %503, %353
  %505 = add <8 x i16> %504, %391
  %506 = add <8 x i16> %505, %382
  %507 = add <8 x i16> %506, %386
  %508 = add <8 x i16> %507, %424
  %509 = add <8 x i16> %508, %415
  %510 = add <8 x i16> %509, %419
  %511 = add <8 x i16> %510, %491
  %512 = add <8 x i16> %511, %448
  %513 = add <8 x i16> %512, %464
  %514 = mul <8 x i16> %467, %445
  %515 = add <8 x i16> %466, %514
  %516 = mul <8 x i16> %467, %447
  %517 = add <8 x i16> %428, %516
  %518 = bitcast <2 x i64>* %0 to <8 x i16>*
  store <8 x i16> %442, <8 x i16>* %518, align 16
  %519 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %520 = bitcast <2 x i64>* %519 to <8 x i16>*
  store <8 x i16> %462, <8 x i16>* %520, align 16
  %521 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %522 = bitcast <2 x i64>* %521 to <8 x i16>*
  store <8 x i16> %490, <8 x i16>* %522, align 16
  %523 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %524 = bitcast <2 x i64>* %523 to <8 x i16>*
  store <8 x i16> %513, <8 x i16>* %524, align 16
  %525 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %526 = bitcast <2 x i64>* %525 to <8 x i16>*
  store <8 x i16> %515, <8 x i16>* %526, align 16
  %527 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %528 = bitcast <2 x i64>* %527 to <8 x i16>*
  store <8 x i16> %517, <8 x i16>* %528, align 16
  br label %645

529:                                              ; preds = %5
  %530 = lshr i64 %4, 1
  %531 = sub i64 %4, %530
  %532 = getelementptr inbounds <2 x i64>, <2 x i64>* %2, i64 %530
  %533 = getelementptr inbounds <2 x i64>, <2 x i64>* %3, i64 %530
  %534 = icmp eq i64 %530, 0
  br i1 %534, label %535, label %537

535:                                              ; preds = %537, %529
  %536 = icmp ne i64 %531, %530
  br i1 %536, label %560, label %567

537:                                              ; preds = %529, %537
  %538 = phi i64 [ %558, %537 ], [ 0, %529 ]
  %539 = getelementptr inbounds <2 x i64>, <2 x i64>* %532, i64 %538
  %540 = bitcast <2 x i64>* %539 to <8 x i16>*
  %541 = load <8 x i16>, <8 x i16>* %540, align 16
  %542 = getelementptr inbounds <2 x i64>, <2 x i64>* %2, i64 %538
  %543 = bitcast <2 x i64>* %542 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = add <8 x i16> %544, %541
  %546 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %538
  %547 = bitcast <2 x i64>* %546 to <8 x i16>*
  store <8 x i16> %545, <8 x i16>* %547, align 16
  %548 = getelementptr inbounds <2 x i64>, <2 x i64>* %533, i64 %538
  %549 = bitcast <2 x i64>* %548 to <8 x i16>*
  %550 = load <8 x i16>, <8 x i16>* %549, align 16
  %551 = getelementptr inbounds <2 x i64>, <2 x i64>* %3, i64 %538
  %552 = bitcast <2 x i64>* %551 to <8 x i16>*
  %553 = load <8 x i16>, <8 x i16>* %552, align 16
  %554 = add <8 x i16> %553, %550
  %555 = add i64 %538, %531
  %556 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %555
  %557 = bitcast <2 x i64>* %556 to <8 x i16>*
  store <8 x i16> %554, <8 x i16>* %557, align 16
  %558 = add nuw nsw i64 %538, 1
  %559 = icmp eq i64 %558, %530
  br i1 %559, label %535, label %537

560:                                              ; preds = %535
  %561 = getelementptr inbounds <2 x i64>, <2 x i64>* %532, i64 %530
  %562 = load <2 x i64>, <2 x i64>* %561, align 16
  %563 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %530
  store <2 x i64> %562, <2 x i64>* %563, align 16
  %564 = getelementptr inbounds <2 x i64>, <2 x i64>* %533, i64 %530
  %565 = load <2 x i64>, <2 x i64>* %564, align 16
  %566 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %4
  store <2 x i64> %565, <2 x i64>* %566, align 16
  br label %567

567:                                              ; preds = %560, %535
  %568 = shl i64 %531, 1
  %569 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %568
  %570 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %531
  tail call fastcc void @poly_mul_vec_aux(<2 x i64>* %1, <2 x i64>* %569, <2 x i64>* %0, <2 x i64>* %570, i64 %531)
  %571 = and i64 %4, -2
  %572 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %571
  tail call fastcc void @poly_mul_vec_aux(<2 x i64>* %572, <2 x i64>* %569, <2 x i64>* %532, <2 x i64>* %533, i64 %531)
  tail call fastcc void @poly_mul_vec_aux(<2 x i64>* %0, <2 x i64>* %569, <2 x i64>* %2, <2 x i64>* %3, i64 %530)
  %573 = icmp eq i64 %571, 0
  br i1 %573, label %574, label %575

574:                                              ; preds = %575, %567
  br i1 %536, label %604, label %622

575:                                              ; preds = %567, %575
  %576 = phi i64 [ %602, %575 ], [ 0, %567 ]
  %577 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %576
  %578 = bitcast <2 x i64>* %577 to <8 x i16>*
  %579 = load <8 x i16>, <8 x i16>* %578, align 16
  %580 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %576
  %581 = bitcast <2 x i64>* %580 to <8 x i16>*
  %582 = load <8 x i16>, <8 x i16>* %581, align 16
  %583 = add i64 %576, %571
  %584 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %583
  %585 = bitcast <2 x i64>* %584 to <8 x i16>*
  %586 = load <8 x i16>, <8 x i16>* %585, align 16
  %587 = sub <8 x i16> %579, %582
  %588 = sub <8 x i16> %587, %586
  store <8 x i16> %588, <8 x i16>* %578, align 16
  %589 = or i64 %576, 1
  %590 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %589
  %591 = bitcast <2 x i64>* %590 to <8 x i16>*
  %592 = load <8 x i16>, <8 x i16>* %591, align 16
  %593 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %589
  %594 = bitcast <2 x i64>* %593 to <8 x i16>*
  %595 = load <8 x i16>, <8 x i16>* %594, align 16
  %596 = add i64 %589, %571
  %597 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %596
  %598 = bitcast <2 x i64>* %597 to <8 x i16>*
  %599 = load <8 x i16>, <8 x i16>* %598, align 16
  %600 = sub <8 x i16> %592, %595
  %601 = sub <8 x i16> %600, %599
  store <8 x i16> %601, <8 x i16>* %591, align 16
  %602 = add nuw i64 %576, 2
  %603 = icmp eq i64 %602, %571
  br i1 %603, label %574, label %575

604:                                              ; preds = %574
  %605 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %571
  %606 = bitcast <2 x i64>* %605 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = shl i64 %530, 2
  %609 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %608
  %610 = bitcast <2 x i64>* %609 to <8 x i16>*
  %611 = load <8 x i16>, <8 x i16>* %610, align 16
  %612 = sub <8 x i16> %607, %611
  store <8 x i16> %612, <8 x i16>* %606, align 16
  %613 = or i64 %4, 1
  %614 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %613
  %615 = bitcast <2 x i64>* %614 to <8 x i16>*
  %616 = load <8 x i16>, <8 x i16>* %615, align 16
  %617 = or i64 %608, 1
  %618 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %617
  %619 = bitcast <2 x i64>* %618 to <8 x i16>*
  %620 = load <8 x i16>, <8 x i16>* %619, align 16
  %621 = sub <8 x i16> %616, %620
  store <8 x i16> %621, <8 x i16>* %615, align 16
  br label %622

622:                                              ; preds = %604, %574
  %623 = icmp eq i64 %568, 0
  br i1 %623, label %645, label %624

624:                                              ; preds = %622, %624
  %625 = phi i64 [ %643, %624 ], [ 0, %622 ]
  %626 = add i64 %625, %530
  %627 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %626
  %628 = bitcast <2 x i64>* %627 to <8 x i16>*
  %629 = load <8 x i16>, <8 x i16>* %628, align 16
  %630 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %625
  %631 = bitcast <2 x i64>* %630 to <8 x i16>*
  %632 = load <8 x i16>, <8 x i16>* %631, align 16
  %633 = add <8 x i16> %632, %629
  store <8 x i16> %633, <8 x i16>* %628, align 16
  %634 = or i64 %625, 1
  %635 = add i64 %634, %530
  %636 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %635
  %637 = bitcast <2 x i64>* %636 to <8 x i16>*
  %638 = load <8 x i16>, <8 x i16>* %637, align 16
  %639 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %634
  %640 = bitcast <2 x i64>* %639 to <8 x i16>*
  %641 = load <8 x i16>, <8 x i16>* %640, align 16
  %642 = add <8 x i16> %641, %638
  store <8 x i16> %642, <8 x i16>* %637, align 16
  %643 = add nuw i64 %625, 2
  %644 = icmp eq i64 %643, %568
  br i1 %644, label %645, label %624

645:                                              ; preds = %624, %622, %198, %6
  ret void
}

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind }
attributes #6 = { nounwind readnone }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 543359}
!3 = distinct !{!3, !4}
!4 = !{!"llvm.loop.isvectorized", i32 1}
!5 = distinct !{!5, !4}
!6 = distinct !{!6, !4}
!7 = distinct !{!7, !4}
!8 = distinct !{!8, !4}
!9 = distinct !{!9, !4}
!10 = distinct !{!10, !4}
!11 = distinct !{!11, !4}
!12 = distinct !{!12, !4}
!13 = distinct !{!13, !4}
!14 = distinct !{!14, !4}
!15 = !{!16}
!16 = distinct !{!16, !17}
!17 = distinct !{!17, !"LVerDomain"}
!18 = !{!19}
!19 = distinct !{!19, !17}
!20 = distinct !{!20, !4}
!21 = distinct !{!21, !4}
!22 = !{!23}
!23 = distinct !{!23, !24}
!24 = distinct !{!24, !"LVerDomain"}
!25 = !{!26}
!26 = distinct !{!26, !24}
!27 = distinct !{!27, !4}
!28 = distinct !{!28, !4}
!29 = distinct !{!29, !4}
!30 = !{!31}
!31 = distinct !{!31, !32}
!32 = distinct !{!32, !"LVerDomain"}
!33 = !{!34}
!34 = distinct !{!34, !32}
!35 = distinct !{!35, !4}
!36 = distinct !{!36, !4}
!37 = distinct !{!37, !4}
!38 = distinct !{!38, !4}
!39 = !{!40}
!40 = distinct !{!40, !41}
!41 = distinct !{!41, !"LVerDomain"}
!42 = !{!43}
!43 = distinct !{!43, !41}
!44 = distinct !{!44, !4}
!45 = distinct !{!45, !4}
!46 = !{!47}
!47 = distinct !{!47, !48}
!48 = distinct !{!48, !"LVerDomain"}
!49 = !{!50}
!50 = distinct !{!50, !48}
!51 = distinct !{!51, !4}
!52 = distinct !{!52, !4}
!53 = distinct !{!53, !4}
!54 = distinct !{!54, !4}
