; ModuleID = '../../third_party/libgav1/src/src/dsp/x86/intrapred_smooth_sse4.cc'
source_filename = "../../third_party/libgav1/src/src/dsp/x86/intrapred_smooth_sse4.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.libgav1::dsp::Dsp" = type { void (i8*, i8*, i32, i32, i8*, i64)*, void (i8*, i64, i8*, i32*)*, [2 x [3 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*]], [19 x void (i8*, i64, [32 x i16]*, i32)*], [19 x [3 x void ([32 x i16]*, i32, i32, i8*, i64)*]], [2 x [2 x [2 x [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i8*, i64)*]]]], [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i64)*], void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)*, void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i8*, i8, i8, i32, i32, i8*, i64)*, %"struct.libgav1::dsp::FilmGrainFuncs", void (i8*, i64, i8*, i8*, i8, i32, i32)*, [3 x void (i8*, i8*, i64, i8*, i64, i32, i32)*], void (i8*, i32, i32)*, void (i8*, i32)*, [19 x [10 x void (i8*, i64, i8*, i8*)*]], [4 x [5 x [2 x void (i8, i8, i32, i8*, i32, i32, i8*)*]]], [4 x [2 x void (i8*, i64, i32, i32, i32)*]], [2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*], [3 x [2 x void (i8*, i8*, i64, i8*, i64, i32, i32, i8*, i64)*]], void (%"struct.libgav1::ReferenceInfo"*, i32, i32, i32, i32, i32, i32, %"struct.libgav1::TemporalMotionField"*)*, [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32*, i32, %"union.libgav1::CompoundMotionVector"*)*], [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32, i32, %"struct.libgav1::MotionVector"*)*], [2 x void (i8*, i64, i32, i32, i8*, i64)*], void (i32, i32, i32, i8*)*, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, [6 x [6 x [2 x void (i8*, i8*, i8*, i64)*]]] }
%"struct.libgav1::dsp::FilmGrainFuncs" = type { [3 x void (%"struct.libgav1::FilmGrainParams"*, i8*)*], [2 x [4 x void (%"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i8*, i8*)*]], [2 x void (i8*, i32, i32, i32, i32, i32, i8*)*], void (i8*, i32, i32, i32, i32, i8*)*, void (i32, i8*, i8*, i8*)*, void (i8*, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64)*, [2 x void (i8, %"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64, i8*, i64)*] }
%"struct.libgav1::FilmGrainParams" = type { i8, i8, i8, i8, i8, i8, i8, i8, [14 x i8], [14 x i8], [10 x i8], [10 x i8], [10 x i8], [10 x i8], i8, i8, [24 x i8], [25 x i8], [25 x i8], i8, i16, i32, i32, i8, i8, i16, i8, i8, i16 }
%"struct.libgav1::RestorationUnitInfo" = type { i8, %"struct.libgav1::SgrProjInfo", [16 x i8], %"struct.libgav1::WienerInfo" }
%"struct.libgav1::SgrProjInfo" = type { i32, [2 x i32] }
%"struct.libgav1::WienerInfo" = type { [2 x i16], [28 x i8], [2 x [4 x i16]], [16 x i8] }
%"union.libgav1::RestorationBuffer" = type { %"struct.libgav1::SgrBuffer", [5024 x i8] }
%"struct.libgav1::SgrBuffer" = type { [1152 x i16], [1440 x i16], [1152 x i32], [1440 x i32], [1024 x i16], [768 x i16], [512 x i16], [1024 x i32], [768 x i32], [512 x i32], [288 x i8], [288 x i32] }
%"struct.libgav1::ReferenceInfo" = type { %"struct.std::__1::array", %"struct.std::__1::array.0", %"struct.std::__1::array.0", %"struct.std::__1::array.1", %"struct.std::__1::array.2", %"class.libgav1::Array2D", %"class.libgav1::Array2D.4" }
%"struct.std::__1::array" = type { [8 x i8] }
%"struct.std::__1::array.0" = type { [8 x i8] }
%"struct.std::__1::array.1" = type { [8 x i8] }
%"struct.std::__1::array.2" = type { [8 x i16] }
%"class.libgav1::Array2D" = type { %"class.std::__1::unique_ptr", i64, i64, %"class.libgav1::Array2DView" }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i8* }
%"class.libgav1::Array2DView" = type { i32, i32, i8* }
%"class.libgav1::Array2D.4" = type { %"class.std::__1::unique_ptr.5", i64, i64, %"class.libgav1::Array2DView.11" }
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.libgav1::MotionVector"* }
%"struct.libgav1::MotionVector" = type { %union.anon }
%union.anon = type { i32 }
%"class.libgav1::Array2DView.11" = type { i32, i32, %"struct.libgav1::MotionVector"* }
%"struct.libgav1::TemporalMotionField" = type { %"class.libgav1::Array2D.4", %"class.libgav1::Array2D.12" }
%"class.libgav1::Array2D.12" = type { %"class.std::__1::unique_ptr.13", i64, i64, %"class.libgav1::Array2DView.19" }
%"class.std::__1::unique_ptr.13" = type { %"class.std::__1::__compressed_pair.14" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.15" }
%"struct.std::__1::__compressed_pair_elem.15" = type { i8* }
%"class.libgav1::Array2DView.19" = type { i32, i32, i8* }
%"union.libgav1::CompoundMotionVector" = type { i64 }

@_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE = internal unnamed_addr constant [124 x i8] c"\FF\95U@\FF\C5\92iI2% \FF\E1\C4\AA\91{fTD6+!\1A\14\11\10\FF\F0\E1\D2\C4\B6\A9\9D\91\85zoe\5CSJB;4-'\22\1D\19\15\11\0E\0C\0A\09\08\08\FF\F8\F0\E9\E1\DA\D2\CB\C4\BD\B6\B0\A9\A3\9C\96\90\8A\85\7Fytoje`[VRMIEA=962/,)&# \1D\1B\19\16\14\12\10\0F\0D\0C\0A\09\08\07\06\06\05\05\04\04\04", align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN7libgav13dsp26IntraPredSmoothInit_SSE4_1Ev() local_unnamed_addr #0 {
  %1 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 8) #5
  %2 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 0, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Smooth4x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %2, align 8
  %3 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 1, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Smooth4x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %3, align 8
  %4 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 2, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Smooth4x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %4, align 8
  %5 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 3, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Smooth8x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %5, align 8
  %6 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 4, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Smooth8x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %6, align 8
  %7 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 5, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Smooth8x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %7, align 8
  %8 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 6, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Smooth8x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %8, align 8
  %9 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 7, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi4EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %9, align 8
  %10 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 8, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi8EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %10, align 8
  %11 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 9, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi16EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %11, align 8
  %12 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 10, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi32EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %12, align 8
  %13 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 11, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi64EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %13, align 8
  %14 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 12, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi32ELi8EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %14, align 8
  %15 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 13, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi32ELi16EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %15, align 8
  %16 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 14, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi32ELi32EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %16, align 8
  %17 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 15, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi32ELi64EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %17, align 8
  %18 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 16, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi64ELi16EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %18, align 8
  %19 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 17, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi64ELi32EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %19, align 8
  %20 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 18, i64 7
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi64ELi64EEEvPvlPKvS6_, void (i8*, i64, i8*, i8*)** %20, align 8
  %21 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 0, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_124SmoothVertical4x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %21, align 8
  %22 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 1, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_124SmoothVertical4x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %22, align 8
  %23 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 2, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical4x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %23, align 8
  %24 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 3, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_124SmoothVertical8x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %24, align 8
  %25 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 4, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_124SmoothVertical8x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %25, align 8
  %26 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 5, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical8x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %26, align 8
  %27 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 6, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical8x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %27, align 8
  %28 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 7, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical16x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %28, align 8
  %29 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 8, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical16x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %29, align 8
  %30 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 9, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical16x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %30, align 8
  %31 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 10, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical16x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %31, align 8
  %32 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 11, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical16x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %32, align 8
  %33 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 12, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical32x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %33, align 8
  %34 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 13, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical32x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %34, align 8
  %35 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 14, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical32x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %35, align 8
  %36 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 15, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical32x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %36, align 8
  %37 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 16, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical64x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %37, align 8
  %38 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 17, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical64x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %38, align 8
  %39 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 18, i64 8
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical64x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %39, align 8
  %40 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 0, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothHorizontal4x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %40, align 8
  %41 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 1, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothHorizontal4x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %41, align 8
  %42 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 2, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal4x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %42, align 8
  %43 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 3, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothHorizontal8x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %43, align 8
  %44 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 4, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothHorizontal8x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %44, align 8
  %45 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 5, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal8x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %45, align 8
  %46 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 6, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal8x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %46, align 8
  %47 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 7, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal16x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %47, align 8
  %48 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 8, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal16x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %48, align 8
  %49 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 9, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal16x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %49, align 8
  %50 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 10, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal16x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %50, align 8
  %51 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 11, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal16x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %51, align 8
  %52 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 12, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal32x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %52, align 8
  %53 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 13, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal32x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %53, align 8
  %54 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 14, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal32x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %54, align 8
  %55 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 15, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal32x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %55, align 8
  %56 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 16, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal64x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %56, align 8
  %57 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 17, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal64x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %57, align 8
  %58 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 18, i64 9
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal64x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %58, align 8
  ret void
}

declare %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Smooth4x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> undef, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %10 = zext <4 x i8> %9 to <4 x i32>
  %11 = bitcast i8* %3 to i32*
  %12 = load i32, i32* %11, align 1
  %13 = insertelement <4 x i32> undef, i32 %12, i32 0
  %14 = bitcast <4 x i32> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %16 = zext <4 x i8> %15 to <4 x i32>
  %17 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %18 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %19 = bitcast <4 x i32> %17 to <8 x i16>
  %20 = mul <8 x i16> %19, <i16 1, i16 0, i16 107, i16 0, i16 171, i16 0, i16 192, i16 0>
  %21 = bitcast <4 x i32> %18 to <8 x i16>
  %22 = mul <8 x i16> %21, <i16 1, i16 0, i16 107, i16 0, i16 171, i16 0, i16 192, i16 0>
  %23 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %24 = mul nsw <4 x i32> %23, <i32 255, i32 149, i32 85, i32 64>
  %25 = mul nuw nsw <4 x i32> %10, <i32 255, i32 255, i32 255, i32 255>
  %26 = bitcast <8 x i16> %22 to <4 x i32>
  %27 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> zeroinitializer
  %28 = bitcast <8 x i16> %20 to <4 x i32>
  %29 = add <4 x i32> %28, <i32 256, i32 256, i32 256, i32 256>
  %30 = add <4 x i32> %29, %25
  %31 = add <4 x i32> %30, %24
  %32 = add <4 x i32> %31, %27
  %33 = lshr <4 x i32> %32, <i32 9, i32 9, i32 9, i32 9>
  %34 = bitcast <4 x i32> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %36 = bitcast <16 x i8> %35 to <4 x i32>
  %37 = extractelement <4 x i32> %36, i32 0
  %38 = bitcast i8* %0 to i32*
  store i32 %37, i32* %38, align 1
  %39 = getelementptr inbounds i8, i8* %0, i64 %1
  %40 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %41 = mul nsw <4 x i32> %40, <i32 255, i32 149, i32 85, i32 64>
  %42 = mul nuw nsw <4 x i32> %10, <i32 149, i32 149, i32 149, i32 149>
  %43 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %44 = add <4 x i32> %29, %42
  %45 = add <4 x i32> %44, %41
  %46 = add <4 x i32> %45, %43
  %47 = lshr <4 x i32> %46, <i32 9, i32 9, i32 9, i32 9>
  %48 = bitcast <4 x i32> %47 to <16 x i8>
  %49 = shufflevector <16 x i8> %48, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %50 = bitcast <16 x i8> %49 to <4 x i32>
  %51 = extractelement <4 x i32> %50, i32 0
  %52 = bitcast i8* %39 to i32*
  store i32 %51, i32* %52, align 1
  %53 = getelementptr inbounds i8, i8* %39, i64 %1
  %54 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %55 = mul nsw <4 x i32> %54, <i32 255, i32 149, i32 85, i32 64>
  %56 = mul nuw nsw <4 x i32> %10, <i32 85, i32 85, i32 85, i32 85>
  %57 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %58 = add <4 x i32> %29, %56
  %59 = add <4 x i32> %58, %55
  %60 = add <4 x i32> %59, %57
  %61 = lshr <4 x i32> %60, <i32 9, i32 9, i32 9, i32 9>
  %62 = bitcast <4 x i32> %61 to <16 x i8>
  %63 = shufflevector <16 x i8> %62, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %64 = bitcast <16 x i8> %63 to <4 x i32>
  %65 = extractelement <4 x i32> %64, i32 0
  %66 = bitcast i8* %53 to i32*
  store i32 %65, i32* %66, align 1
  %67 = getelementptr inbounds i8, i8* %53, i64 %1
  %68 = mul nsw <4 x i32> %18, <i32 255, i32 149, i32 85, i32 64>
  %69 = shl nuw nsw <4 x i32> %10, <i32 6, i32 6, i32 6, i32 6>
  %70 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %71 = add <4 x i32> %29, %69
  %72 = add <4 x i32> %71, %68
  %73 = add <4 x i32> %72, %70
  %74 = lshr <4 x i32> %73, <i32 9, i32 9, i32 9, i32 9>
  %75 = bitcast <4 x i32> %74 to <16 x i8>
  %76 = shufflevector <16 x i8> %75, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %77 = bitcast <16 x i8> %76 to <4 x i32>
  %78 = extractelement <4 x i32> %77, i32 0
  %79 = bitcast i8* %67 to i32*
  store i32 %78, i32* %79, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Smooth4x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> undef, i64 %6, i32 0
  %8 = getelementptr inbounds i8, i8* %3, i64 7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i16
  %11 = insertelement <8 x i16> undef, i16 %10, i32 0
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %13 = bitcast i8* %2 to i32*
  %14 = load i32, i32* %13, align 1
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %14, i32 0
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %18 = zext <8 x i8> %17 to <8 x i16>
  %19 = shufflevector <8 x i16> %18, <8 x i16> %12, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %20 = getelementptr inbounds i8, i8* %2, i64 3
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i16
  %23 = insertelement <8 x i16> undef, i16 %22, i32 0
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <8 x i32> zeroinitializer
  %25 = bitcast <2 x i64> %7 to <16 x i8>
  %26 = shufflevector <16 x i8> %25, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %27 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %19, <8 x i16> <i16 255, i16 1, i16 255, i16 1, i16 255, i16 1, i16 255, i16 1>) #5
  %28 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = shufflevector <8 x i16> %29, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %31 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %30, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %32 = add <4 x i32> %27, <i32 256, i32 256, i32 256, i32 256>
  %33 = add <4 x i32> %32, %31
  %34 = ashr <4 x i32> %33, <i32 9, i32 9, i32 9, i32 9>
  %35 = bitcast <4 x i32> %34 to <16 x i8>
  %36 = shufflevector <16 x i8> %35, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %37 = bitcast <16 x i8> %36 to <4 x i32>
  %38 = extractelement <4 x i32> %37, i32 0
  %39 = bitcast i8* %0 to i32*
  store i32 %38, i32* %39, align 1
  %40 = getelementptr inbounds i8, i8* %0, i64 %1
  %41 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %19, <8 x i16> <i16 197, i16 59, i16 197, i16 59, i16 197, i16 59, i16 197, i16 59>) #5
  %42 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %43 = bitcast <16 x i8> %42 to <8 x i16>
  %44 = shufflevector <8 x i16> %43, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %45 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %44, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %46 = add <4 x i32> %41, <i32 256, i32 256, i32 256, i32 256>
  %47 = add <4 x i32> %46, %45
  %48 = ashr <4 x i32> %47, <i32 9, i32 9, i32 9, i32 9>
  %49 = bitcast <4 x i32> %48 to <16 x i8>
  %50 = shufflevector <16 x i8> %49, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %51 = bitcast <16 x i8> %50 to <4 x i32>
  %52 = extractelement <4 x i32> %51, i32 0
  %53 = bitcast i8* %40 to i32*
  store i32 %52, i32* %53, align 1
  %54 = getelementptr inbounds i8, i8* %40, i64 %1
  %55 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %19, <8 x i16> <i16 146, i16 110, i16 146, i16 110, i16 146, i16 110, i16 146, i16 110>) #5
  %56 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %57 = bitcast <16 x i8> %56 to <8 x i16>
  %58 = shufflevector <8 x i16> %57, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %59 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %58, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %60 = add <4 x i32> %55, <i32 256, i32 256, i32 256, i32 256>
  %61 = add <4 x i32> %60, %59
  %62 = ashr <4 x i32> %61, <i32 9, i32 9, i32 9, i32 9>
  %63 = bitcast <4 x i32> %62 to <16 x i8>
  %64 = shufflevector <16 x i8> %63, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %65 = bitcast <16 x i8> %64 to <4 x i32>
  %66 = extractelement <4 x i32> %65, i32 0
  %67 = bitcast i8* %54 to i32*
  store i32 %66, i32* %67, align 1
  %68 = getelementptr inbounds i8, i8* %54, i64 %1
  %69 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %19, <8 x i16> <i16 105, i16 151, i16 105, i16 151, i16 105, i16 151, i16 105, i16 151>) #5
  %70 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %71 = bitcast <16 x i8> %70 to <8 x i16>
  %72 = shufflevector <8 x i16> %71, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %73 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %72, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %74 = add <4 x i32> %69, <i32 256, i32 256, i32 256, i32 256>
  %75 = add <4 x i32> %74, %73
  %76 = ashr <4 x i32> %75, <i32 9, i32 9, i32 9, i32 9>
  %77 = bitcast <4 x i32> %76 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %79 = bitcast <16 x i8> %78 to <4 x i32>
  %80 = extractelement <4 x i32> %79, i32 0
  %81 = bitcast i8* %68 to i32*
  store i32 %80, i32* %81, align 1
  %82 = getelementptr inbounds i8, i8* %68, i64 %1
  %83 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %19, <8 x i16> <i16 73, i16 183, i16 73, i16 183, i16 73, i16 183, i16 73, i16 183>) #5
  %84 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %85 = bitcast <16 x i8> %84 to <8 x i16>
  %86 = shufflevector <8 x i16> %85, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %87 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %86, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %88 = add <4 x i32> %83, <i32 256, i32 256, i32 256, i32 256>
  %89 = add <4 x i32> %88, %87
  %90 = ashr <4 x i32> %89, <i32 9, i32 9, i32 9, i32 9>
  %91 = bitcast <4 x i32> %90 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %93 = bitcast <16 x i8> %92 to <4 x i32>
  %94 = extractelement <4 x i32> %93, i32 0
  %95 = bitcast i8* %82 to i32*
  store i32 %94, i32* %95, align 1
  %96 = getelementptr inbounds i8, i8* %82, i64 %1
  %97 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %19, <8 x i16> <i16 50, i16 206, i16 50, i16 206, i16 50, i16 206, i16 50, i16 206>) #5
  %98 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %99 = bitcast <16 x i8> %98 to <8 x i16>
  %100 = shufflevector <8 x i16> %99, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %101 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %100, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %102 = add <4 x i32> %97, <i32 256, i32 256, i32 256, i32 256>
  %103 = add <4 x i32> %102, %101
  %104 = ashr <4 x i32> %103, <i32 9, i32 9, i32 9, i32 9>
  %105 = bitcast <4 x i32> %104 to <16 x i8>
  %106 = shufflevector <16 x i8> %105, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %107 = bitcast <16 x i8> %106 to <4 x i32>
  %108 = extractelement <4 x i32> %107, i32 0
  %109 = bitcast i8* %96 to i32*
  store i32 %108, i32* %109, align 1
  %110 = getelementptr inbounds i8, i8* %96, i64 %1
  %111 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %19, <8 x i16> <i16 37, i16 219, i16 37, i16 219, i16 37, i16 219, i16 37, i16 219>) #5
  %112 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %113 = bitcast <16 x i8> %112 to <8 x i16>
  %114 = shufflevector <8 x i16> %113, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %115 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %114, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %116 = add <4 x i32> %111, <i32 256, i32 256, i32 256, i32 256>
  %117 = add <4 x i32> %116, %115
  %118 = ashr <4 x i32> %117, <i32 9, i32 9, i32 9, i32 9>
  %119 = bitcast <4 x i32> %118 to <16 x i8>
  %120 = shufflevector <16 x i8> %119, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %121 = bitcast <16 x i8> %120 to <4 x i32>
  %122 = extractelement <4 x i32> %121, i32 0
  %123 = bitcast i8* %110 to i32*
  store i32 %122, i32* %123, align 1
  %124 = getelementptr inbounds i8, i8* %110, i64 %1
  %125 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %19, <8 x i16> <i16 32, i16 224, i16 32, i16 224, i16 32, i16 224, i16 32, i16 224>) #5
  %126 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %127 = bitcast <16 x i8> %126 to <8 x i16>
  %128 = shufflevector <8 x i16> %127, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %129 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %128, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %130 = add <4 x i32> %125, <i32 256, i32 256, i32 256, i32 256>
  %131 = add <4 x i32> %130, %129
  %132 = ashr <4 x i32> %131, <i32 9, i32 9, i32 9, i32 9>
  %133 = bitcast <4 x i32> %132 to <16 x i8>
  %134 = shufflevector <16 x i8> %133, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %135 = bitcast <16 x i8> %134 to <4 x i32>
  %136 = extractelement <4 x i32> %135, i32 0
  %137 = bitcast i8* %124 to i32*
  store i32 %136, i32* %137, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Smooth4x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 15
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i16
  %10 = insertelement <8 x i16> undef, i16 %9, i32 0
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %12 = bitcast i8* %2 to i32*
  %13 = load i32, i32* %12, align 1
  %14 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %13, i32 0
  %15 = bitcast <4 x i32> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %17 = zext <8 x i8> %16 to <8 x i16>
  %18 = shufflevector <8 x i16> %17, <8 x i16> %11, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %19 = getelementptr inbounds i8, i8* %2, i64 3
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i16
  %22 = insertelement <8 x i16> undef, i16 %21, i32 0
  %23 = shufflevector <8 x i16> %22, <8 x i16> undef, <8 x i32> zeroinitializer
  %24 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %25 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 255, i16 1, i16 255, i16 1, i16 255, i16 1, i16 255, i16 1>) #5
  %26 = shufflevector <16 x i8> %24, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %27 = bitcast <16 x i8> %26 to <8 x i16>
  %28 = shufflevector <8 x i16> %27, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %29 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %28, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %30 = add <4 x i32> %25, <i32 256, i32 256, i32 256, i32 256>
  %31 = add <4 x i32> %30, %29
  %32 = ashr <4 x i32> %31, <i32 9, i32 9, i32 9, i32 9>
  %33 = bitcast <4 x i32> %32 to <16 x i8>
  %34 = shufflevector <16 x i8> %33, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %35 = bitcast <16 x i8> %34 to <4 x i32>
  %36 = extractelement <4 x i32> %35, i32 0
  %37 = bitcast i8* %0 to i32*
  store i32 %36, i32* %37, align 1
  %38 = getelementptr inbounds i8, i8* %0, i64 %1
  %39 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 225, i16 31, i16 225, i16 31, i16 225, i16 31, i16 225, i16 31>) #5
  %40 = shufflevector <16 x i8> %24, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %41 = bitcast <16 x i8> %40 to <8 x i16>
  %42 = shufflevector <8 x i16> %41, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %43 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %42, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %44 = add <4 x i32> %39, <i32 256, i32 256, i32 256, i32 256>
  %45 = add <4 x i32> %44, %43
  %46 = ashr <4 x i32> %45, <i32 9, i32 9, i32 9, i32 9>
  %47 = bitcast <4 x i32> %46 to <16 x i8>
  %48 = shufflevector <16 x i8> %47, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %49 = bitcast <16 x i8> %48 to <4 x i32>
  %50 = extractelement <4 x i32> %49, i32 0
  %51 = bitcast i8* %38 to i32*
  store i32 %50, i32* %51, align 1
  %52 = getelementptr inbounds i8, i8* %38, i64 %1
  %53 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 196, i16 60, i16 196, i16 60, i16 196, i16 60, i16 196, i16 60>) #5
  %54 = shufflevector <16 x i8> %24, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %55 = bitcast <16 x i8> %54 to <8 x i16>
  %56 = shufflevector <8 x i16> %55, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %57 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %58 = add <4 x i32> %53, <i32 256, i32 256, i32 256, i32 256>
  %59 = add <4 x i32> %58, %57
  %60 = ashr <4 x i32> %59, <i32 9, i32 9, i32 9, i32 9>
  %61 = bitcast <4 x i32> %60 to <16 x i8>
  %62 = shufflevector <16 x i8> %61, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %63 = bitcast <16 x i8> %62 to <4 x i32>
  %64 = extractelement <4 x i32> %63, i32 0
  %65 = bitcast i8* %52 to i32*
  store i32 %64, i32* %65, align 1
  %66 = getelementptr inbounds i8, i8* %52, i64 %1
  %67 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 170, i16 86, i16 170, i16 86, i16 170, i16 86, i16 170, i16 86>) #5
  %68 = shufflevector <16 x i8> %24, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %69 = bitcast <16 x i8> %68 to <8 x i16>
  %70 = shufflevector <8 x i16> %69, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %71 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %70, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %72 = add <4 x i32> %67, <i32 256, i32 256, i32 256, i32 256>
  %73 = add <4 x i32> %72, %71
  %74 = ashr <4 x i32> %73, <i32 9, i32 9, i32 9, i32 9>
  %75 = bitcast <4 x i32> %74 to <16 x i8>
  %76 = shufflevector <16 x i8> %75, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %77 = bitcast <16 x i8> %76 to <4 x i32>
  %78 = extractelement <4 x i32> %77, i32 0
  %79 = bitcast i8* %66 to i32*
  store i32 %78, i32* %79, align 1
  %80 = getelementptr inbounds i8, i8* %66, i64 %1
  %81 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 145, i16 111, i16 145, i16 111, i16 145, i16 111, i16 145, i16 111>) #5
  %82 = shufflevector <16 x i8> %24, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %83 = bitcast <16 x i8> %82 to <8 x i16>
  %84 = shufflevector <8 x i16> %83, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %85 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %84, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %86 = add <4 x i32> %81, <i32 256, i32 256, i32 256, i32 256>
  %87 = add <4 x i32> %86, %85
  %88 = ashr <4 x i32> %87, <i32 9, i32 9, i32 9, i32 9>
  %89 = bitcast <4 x i32> %88 to <16 x i8>
  %90 = shufflevector <16 x i8> %89, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %91 = bitcast <16 x i8> %90 to <4 x i32>
  %92 = extractelement <4 x i32> %91, i32 0
  %93 = bitcast i8* %80 to i32*
  store i32 %92, i32* %93, align 1
  %94 = getelementptr inbounds i8, i8* %80, i64 %1
  %95 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 123, i16 133, i16 123, i16 133, i16 123, i16 133, i16 123, i16 133>) #5
  %96 = shufflevector <16 x i8> %24, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %97 = bitcast <16 x i8> %96 to <8 x i16>
  %98 = shufflevector <8 x i16> %97, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %99 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %100 = add <4 x i32> %95, <i32 256, i32 256, i32 256, i32 256>
  %101 = add <4 x i32> %100, %99
  %102 = ashr <4 x i32> %101, <i32 9, i32 9, i32 9, i32 9>
  %103 = bitcast <4 x i32> %102 to <16 x i8>
  %104 = shufflevector <16 x i8> %103, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %105 = bitcast <16 x i8> %104 to <4 x i32>
  %106 = extractelement <4 x i32> %105, i32 0
  %107 = bitcast i8* %94 to i32*
  store i32 %106, i32* %107, align 1
  %108 = getelementptr inbounds i8, i8* %94, i64 %1
  %109 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 102, i16 154, i16 102, i16 154, i16 102, i16 154, i16 102, i16 154>) #5
  %110 = shufflevector <16 x i8> %24, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %111 = bitcast <16 x i8> %110 to <8 x i16>
  %112 = shufflevector <8 x i16> %111, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %113 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %112, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %114 = add <4 x i32> %109, <i32 256, i32 256, i32 256, i32 256>
  %115 = add <4 x i32> %114, %113
  %116 = ashr <4 x i32> %115, <i32 9, i32 9, i32 9, i32 9>
  %117 = bitcast <4 x i32> %116 to <16 x i8>
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %119 = bitcast <16 x i8> %118 to <4 x i32>
  %120 = extractelement <4 x i32> %119, i32 0
  %121 = bitcast i8* %108 to i32*
  store i32 %120, i32* %121, align 1
  %122 = getelementptr inbounds i8, i8* %108, i64 %1
  %123 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 84, i16 172, i16 84, i16 172, i16 84, i16 172, i16 84, i16 172>) #5
  %124 = shufflevector <16 x i8> %24, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %125 = bitcast <16 x i8> %124 to <8 x i16>
  %126 = shufflevector <8 x i16> %125, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %127 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %126, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %128 = add <4 x i32> %123, <i32 256, i32 256, i32 256, i32 256>
  %129 = add <4 x i32> %128, %127
  %130 = ashr <4 x i32> %129, <i32 9, i32 9, i32 9, i32 9>
  %131 = bitcast <4 x i32> %130 to <16 x i8>
  %132 = shufflevector <16 x i8> %131, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %133 = bitcast <16 x i8> %132 to <4 x i32>
  %134 = extractelement <4 x i32> %133, i32 0
  %135 = bitcast i8* %122 to i32*
  store i32 %134, i32* %135, align 1
  %136 = shl i64 %1, 3
  %137 = getelementptr inbounds i8, i8* %0, i64 %136
  %138 = shufflevector <16 x i8> %6, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %139 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 68, i16 188, i16 68, i16 188, i16 68, i16 188, i16 68, i16 188>) #5
  %140 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %141 = bitcast <16 x i8> %140 to <8 x i16>
  %142 = shufflevector <8 x i16> %141, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %143 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %142, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %144 = add <4 x i32> %139, <i32 256, i32 256, i32 256, i32 256>
  %145 = add <4 x i32> %144, %143
  %146 = ashr <4 x i32> %145, <i32 9, i32 9, i32 9, i32 9>
  %147 = bitcast <4 x i32> %146 to <16 x i8>
  %148 = shufflevector <16 x i8> %147, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %149 = bitcast <16 x i8> %148 to <4 x i32>
  %150 = extractelement <4 x i32> %149, i32 0
  %151 = bitcast i8* %137 to i32*
  store i32 %150, i32* %151, align 1
  %152 = getelementptr inbounds i8, i8* %137, i64 %1
  %153 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 54, i16 202, i16 54, i16 202, i16 54, i16 202, i16 54, i16 202>) #5
  %154 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %155 = bitcast <16 x i8> %154 to <8 x i16>
  %156 = shufflevector <8 x i16> %155, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %156, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %158 = add <4 x i32> %153, <i32 256, i32 256, i32 256, i32 256>
  %159 = add <4 x i32> %158, %157
  %160 = ashr <4 x i32> %159, <i32 9, i32 9, i32 9, i32 9>
  %161 = bitcast <4 x i32> %160 to <16 x i8>
  %162 = shufflevector <16 x i8> %161, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %163 = bitcast <16 x i8> %162 to <4 x i32>
  %164 = extractelement <4 x i32> %163, i32 0
  %165 = bitcast i8* %152 to i32*
  store i32 %164, i32* %165, align 1
  %166 = getelementptr inbounds i8, i8* %152, i64 %1
  %167 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 43, i16 213, i16 43, i16 213, i16 43, i16 213, i16 43, i16 213>) #5
  %168 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %169 = bitcast <16 x i8> %168 to <8 x i16>
  %170 = shufflevector <8 x i16> %169, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %171 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %170, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %172 = add <4 x i32> %167, <i32 256, i32 256, i32 256, i32 256>
  %173 = add <4 x i32> %172, %171
  %174 = ashr <4 x i32> %173, <i32 9, i32 9, i32 9, i32 9>
  %175 = bitcast <4 x i32> %174 to <16 x i8>
  %176 = shufflevector <16 x i8> %175, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %177 = bitcast <16 x i8> %176 to <4 x i32>
  %178 = extractelement <4 x i32> %177, i32 0
  %179 = bitcast i8* %166 to i32*
  store i32 %178, i32* %179, align 1
  %180 = getelementptr inbounds i8, i8* %166, i64 %1
  %181 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 33, i16 223, i16 33, i16 223, i16 33, i16 223, i16 33, i16 223>) #5
  %182 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %183 = bitcast <16 x i8> %182 to <8 x i16>
  %184 = shufflevector <8 x i16> %183, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %185 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %184, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %186 = add <4 x i32> %181, <i32 256, i32 256, i32 256, i32 256>
  %187 = add <4 x i32> %186, %185
  %188 = ashr <4 x i32> %187, <i32 9, i32 9, i32 9, i32 9>
  %189 = bitcast <4 x i32> %188 to <16 x i8>
  %190 = shufflevector <16 x i8> %189, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %191 = bitcast <16 x i8> %190 to <4 x i32>
  %192 = extractelement <4 x i32> %191, i32 0
  %193 = bitcast i8* %180 to i32*
  store i32 %192, i32* %193, align 1
  %194 = getelementptr inbounds i8, i8* %180, i64 %1
  %195 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 26, i16 230, i16 26, i16 230, i16 26, i16 230, i16 26, i16 230>) #5
  %196 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %197 = bitcast <16 x i8> %196 to <8 x i16>
  %198 = shufflevector <8 x i16> %197, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %199 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %198, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %200 = add <4 x i32> %195, <i32 256, i32 256, i32 256, i32 256>
  %201 = add <4 x i32> %200, %199
  %202 = ashr <4 x i32> %201, <i32 9, i32 9, i32 9, i32 9>
  %203 = bitcast <4 x i32> %202 to <16 x i8>
  %204 = shufflevector <16 x i8> %203, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %205 = bitcast <16 x i8> %204 to <4 x i32>
  %206 = extractelement <4 x i32> %205, i32 0
  %207 = bitcast i8* %194 to i32*
  store i32 %206, i32* %207, align 1
  %208 = getelementptr inbounds i8, i8* %194, i64 %1
  %209 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 20, i16 236, i16 20, i16 236, i16 20, i16 236, i16 20, i16 236>) #5
  %210 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %211 = bitcast <16 x i8> %210 to <8 x i16>
  %212 = shufflevector <8 x i16> %211, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %213 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %212, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %214 = add <4 x i32> %209, <i32 256, i32 256, i32 256, i32 256>
  %215 = add <4 x i32> %214, %213
  %216 = ashr <4 x i32> %215, <i32 9, i32 9, i32 9, i32 9>
  %217 = bitcast <4 x i32> %216 to <16 x i8>
  %218 = shufflevector <16 x i8> %217, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %219 = bitcast <16 x i8> %218 to <4 x i32>
  %220 = extractelement <4 x i32> %219, i32 0
  %221 = bitcast i8* %208 to i32*
  store i32 %220, i32* %221, align 1
  %222 = getelementptr inbounds i8, i8* %208, i64 %1
  %223 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 17, i16 239, i16 17, i16 239, i16 17, i16 239, i16 17, i16 239>) #5
  %224 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %225 = bitcast <16 x i8> %224 to <8 x i16>
  %226 = shufflevector <8 x i16> %225, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %227 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %226, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %228 = add <4 x i32> %223, <i32 256, i32 256, i32 256, i32 256>
  %229 = add <4 x i32> %228, %227
  %230 = ashr <4 x i32> %229, <i32 9, i32 9, i32 9, i32 9>
  %231 = bitcast <4 x i32> %230 to <16 x i8>
  %232 = shufflevector <16 x i8> %231, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %233 = bitcast <16 x i8> %232 to <4 x i32>
  %234 = extractelement <4 x i32> %233, i32 0
  %235 = bitcast i8* %222 to i32*
  store i32 %234, i32* %235, align 1
  %236 = getelementptr inbounds i8, i8* %222, i64 %1
  %237 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 16, i16 240, i16 16, i16 240, i16 16, i16 240, i16 16, i16 240>) #5
  %238 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %239 = bitcast <16 x i8> %238 to <8 x i16>
  %240 = shufflevector <8 x i16> %239, <8 x i16> %23, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %241 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %240, <8 x i16> <i16 255, i16 1, i16 149, i16 107, i16 85, i16 171, i16 64, i16 192>) #5
  %242 = add <4 x i32> %237, <i32 256, i32 256, i32 256, i32 256>
  %243 = add <4 x i32> %242, %241
  %244 = ashr <4 x i32> %243, <i32 9, i32 9, i32 9, i32 9>
  %245 = bitcast <4 x i32> %244 to <16 x i8>
  %246 = shufflevector <16 x i8> %245, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %247 = bitcast <16 x i8> %246 to <4 x i32>
  %248 = extractelement <4 x i32> %247, i32 0
  %249 = bitcast i8* %236 to i32*
  store i32 %248, i32* %249, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Smooth8x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 3
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = shufflevector <8 x i16> %15, <8 x i16> %9, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %17 = shufflevector <8 x i16> %15, <8 x i16> %9, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %18 = getelementptr inbounds i8, i8* %2, i64 7
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %23 = bitcast i8* %3 to i32*
  %24 = load i32, i32* %23, align 1
  %25 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %24, i32 0
  %26 = bitcast <4 x i32> %25 to <16 x i8>
  %27 = shufflevector <16 x i8> %26, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %28 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 255, i16 1, i16 255, i16 1, i16 255, i16 1, i16 255, i16 1>) #5
  %29 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> <i16 255, i16 1, i16 255, i16 1, i16 255, i16 1, i16 255, i16 1>) #5
  %30 = shufflevector <16 x i8> %27, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %31 = bitcast <16 x i8> %30 to <8 x i16>
  %32 = shufflevector <8 x i16> %31, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %33 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %34 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %35 = add <4 x i32> %28, <i32 256, i32 256, i32 256, i32 256>
  %36 = add <4 x i32> %35, %33
  %37 = ashr <4 x i32> %36, <i32 9, i32 9, i32 9, i32 9>
  %38 = add <4 x i32> %29, <i32 256, i32 256, i32 256, i32 256>
  %39 = add <4 x i32> %38, %34
  %40 = ashr <4 x i32> %39, <i32 9, i32 9, i32 9, i32 9>
  %41 = bitcast <4 x i32> %37 to <8 x i16>
  %42 = bitcast <4 x i32> %40 to <8 x i16>
  %43 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %41, <8 x i16> %42) #5
  %44 = shufflevector <16 x i8> %43, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %45 = bitcast <16 x i8> %44 to <2 x i64>
  %46 = extractelement <2 x i64> %45, i32 0
  %47 = bitcast i8* %0 to i64*
  store i64 %46, i64* %47, align 1
  %48 = getelementptr inbounds i8, i8* %0, i64 %1
  %49 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 149, i16 107, i16 149, i16 107, i16 149, i16 107, i16 149, i16 107>) #5
  %50 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> <i16 149, i16 107, i16 149, i16 107, i16 149, i16 107, i16 149, i16 107>) #5
  %51 = shufflevector <16 x i8> %27, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %52 = bitcast <16 x i8> %51 to <8 x i16>
  %53 = shufflevector <8 x i16> %52, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %54 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %55 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %56 = add <4 x i32> %49, <i32 256, i32 256, i32 256, i32 256>
  %57 = add <4 x i32> %56, %54
  %58 = ashr <4 x i32> %57, <i32 9, i32 9, i32 9, i32 9>
  %59 = add <4 x i32> %50, <i32 256, i32 256, i32 256, i32 256>
  %60 = add <4 x i32> %59, %55
  %61 = ashr <4 x i32> %60, <i32 9, i32 9, i32 9, i32 9>
  %62 = bitcast <4 x i32> %58 to <8 x i16>
  %63 = bitcast <4 x i32> %61 to <8 x i16>
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %62, <8 x i16> %63) #5
  %65 = shufflevector <16 x i8> %64, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %66 = bitcast <16 x i8> %65 to <2 x i64>
  %67 = extractelement <2 x i64> %66, i32 0
  %68 = bitcast i8* %48 to i64*
  store i64 %67, i64* %68, align 1
  %69 = getelementptr inbounds i8, i8* %48, i64 %1
  %70 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 85, i16 171, i16 85, i16 171, i16 85, i16 171, i16 85, i16 171>) #5
  %71 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> <i16 85, i16 171, i16 85, i16 171, i16 85, i16 171, i16 85, i16 171>) #5
  %72 = shufflevector <16 x i8> %27, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %73 = bitcast <16 x i8> %72 to <8 x i16>
  %74 = shufflevector <8 x i16> %73, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %75 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %74, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %76 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %74, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %77 = add <4 x i32> %70, <i32 256, i32 256, i32 256, i32 256>
  %78 = add <4 x i32> %77, %75
  %79 = ashr <4 x i32> %78, <i32 9, i32 9, i32 9, i32 9>
  %80 = add <4 x i32> %71, <i32 256, i32 256, i32 256, i32 256>
  %81 = add <4 x i32> %80, %76
  %82 = ashr <4 x i32> %81, <i32 9, i32 9, i32 9, i32 9>
  %83 = bitcast <4 x i32> %79 to <8 x i16>
  %84 = bitcast <4 x i32> %82 to <8 x i16>
  %85 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %83, <8 x i16> %84) #5
  %86 = shufflevector <16 x i8> %85, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %87 = bitcast <16 x i8> %86 to <2 x i64>
  %88 = extractelement <2 x i64> %87, i32 0
  %89 = bitcast i8* %69 to i64*
  store i64 %88, i64* %89, align 1
  %90 = getelementptr inbounds i8, i8* %69, i64 %1
  %91 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 64, i16 192, i16 64, i16 192, i16 64, i16 192, i16 64, i16 192>) #5
  %92 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> <i16 64, i16 192, i16 64, i16 192, i16 64, i16 192, i16 64, i16 192>) #5
  %93 = shufflevector <16 x i8> %27, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %94 = bitcast <16 x i8> %93 to <8 x i16>
  %95 = shufflevector <8 x i16> %94, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %95, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %97 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %95, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %98 = add <4 x i32> %91, <i32 256, i32 256, i32 256, i32 256>
  %99 = add <4 x i32> %98, %96
  %100 = ashr <4 x i32> %99, <i32 9, i32 9, i32 9, i32 9>
  %101 = add <4 x i32> %92, <i32 256, i32 256, i32 256, i32 256>
  %102 = add <4 x i32> %101, %97
  %103 = ashr <4 x i32> %102, <i32 9, i32 9, i32 9, i32 9>
  %104 = bitcast <4 x i32> %100 to <8 x i16>
  %105 = bitcast <4 x i32> %103 to <8 x i16>
  %106 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %104, <8 x i16> %105) #5
  %107 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %108 = bitcast <16 x i8> %107 to <2 x i64>
  %109 = extractelement <2 x i64> %108, i32 0
  %110 = bitcast i8* %90 to i64*
  store i64 %109, i64* %110, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Smooth8x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = shufflevector <8 x i16> %15, <8 x i16> %9, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %17 = shufflevector <8 x i16> %15, <8 x i16> %9, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %18 = getelementptr inbounds i8, i8* %2, i64 7
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %23 = bitcast i8* %3 to i64*
  %24 = load i64, i64* %23, align 1
  %25 = insertelement <2 x i64> undef, i64 %24, i32 0
  %26 = bitcast <2 x i64> %25 to <16 x i8>
  %27 = shufflevector <16 x i8> %26, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  br label %28

28:                                               ; preds = %28, %4
  %29 = phi i8* [ %0, %4 ], [ %59, %28 ]
  %30 = phi <2 x i64> [ <i64 72058693566333184, i64 72058693566333184>, %4 ], [ %61, %28 ]
  %31 = phi <8 x i16> [ <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %4 ], [ %60, %28 ]
  %32 = phi i32 [ 0, %4 ], [ %62, %28 ]
  %33 = bitcast <2 x i64> %30 to <16 x i8>
  %34 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -1, i8 0, i8 -59, i8 0, i8 -110, i8 0, i8 105, i8 0, i8 73, i8 0, i8 50, i8 0, i8 37, i8 0, i8 32, i8 0>, <16 x i8> %33) #5
  %35 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 1, i8 0, i8 59, i8 0, i8 110, i8 0, i8 -105, i8 0, i8 -73, i8 0, i8 -50, i8 0, i8 -37, i8 0, i8 -32, i8 0>, <16 x i8> %33) #5
  %36 = bitcast <16 x i8> %34 to <8 x i16>
  %37 = bitcast <16 x i8> %35 to <8 x i16>
  %38 = shufflevector <8 x i16> %36, <8 x i16> %37, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %39 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> %38) #5
  %40 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> %38) #5
  %41 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %27, <16 x i8> %33) #5
  %42 = bitcast <16 x i8> %41 to <8 x i16>
  %43 = shufflevector <8 x i16> %42, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %44 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %43, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %45 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %43, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %46 = add <4 x i32> %39, <i32 256, i32 256, i32 256, i32 256>
  %47 = add <4 x i32> %46, %44
  %48 = ashr <4 x i32> %47, <i32 9, i32 9, i32 9, i32 9>
  %49 = add <4 x i32> %40, <i32 256, i32 256, i32 256, i32 256>
  %50 = add <4 x i32> %49, %45
  %51 = ashr <4 x i32> %50, <i32 9, i32 9, i32 9, i32 9>
  %52 = bitcast <4 x i32> %48 to <8 x i16>
  %53 = bitcast <4 x i32> %51 to <8 x i16>
  %54 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %52, <8 x i16> %53) #5
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %56 = bitcast <16 x i8> %55 to <2 x i64>
  %57 = extractelement <2 x i64> %56, i32 0
  %58 = bitcast i8* %29 to i64*
  store i64 %57, i64* %58, align 1
  %59 = getelementptr inbounds i8, i8* %29, i64 %1
  %60 = add <8 x i16> %31, <i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514>
  %61 = bitcast <8 x i16> %60 to <2 x i64>
  %62 = add nuw nsw i32 %32, 1
  %63 = icmp eq i32 %62, 8
  br i1 %63, label %64, label %28

64:                                               ; preds = %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Smooth8x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = shufflevector <8 x i16> %15, <8 x i16> %9, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %17 = shufflevector <8 x i16> %15, <8 x i16> %9, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %18 = getelementptr inbounds i8, i8* %2, i64 7
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> zeroinitializer
  %23 = bitcast i8* %3 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 1
  %25 = shufflevector <16 x i8> %24, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  br label %26

26:                                               ; preds = %26, %4
  %27 = phi i8* [ %0, %4 ], [ %57, %26 ]
  %28 = phi <2 x i64> [ <i64 72058693566333184, i64 72058693566333184>, %4 ], [ %59, %26 ]
  %29 = phi <8 x i16> [ <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %4 ], [ %58, %26 ]
  %30 = phi i32 [ 0, %4 ], [ %60, %26 ]
  %31 = bitcast <2 x i64> %28 to <16 x i8>
  %32 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -1, i8 0, i8 -31, i8 0, i8 -60, i8 0, i8 -86, i8 0, i8 -111, i8 0, i8 123, i8 0, i8 102, i8 0, i8 84, i8 0>, <16 x i8> %31) #5
  %33 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 1, i8 0, i8 31, i8 0, i8 60, i8 0, i8 86, i8 0, i8 111, i8 0, i8 -123, i8 0, i8 -102, i8 0, i8 -84, i8 0>, <16 x i8> %31) #5
  %34 = bitcast <16 x i8> %32 to <8 x i16>
  %35 = bitcast <16 x i8> %33 to <8 x i16>
  %36 = shufflevector <8 x i16> %34, <8 x i16> %35, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %37 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> %36) #5
  %38 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> %36) #5
  %39 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %25, <16 x i8> %31) #5
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = shufflevector <8 x i16> %40, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %42 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %41, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %43 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %41, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %44 = add <4 x i32> %37, <i32 256, i32 256, i32 256, i32 256>
  %45 = add <4 x i32> %44, %42
  %46 = ashr <4 x i32> %45, <i32 9, i32 9, i32 9, i32 9>
  %47 = add <4 x i32> %38, <i32 256, i32 256, i32 256, i32 256>
  %48 = add <4 x i32> %47, %43
  %49 = ashr <4 x i32> %48, <i32 9, i32 9, i32 9, i32 9>
  %50 = bitcast <4 x i32> %46 to <8 x i16>
  %51 = bitcast <4 x i32> %49 to <8 x i16>
  %52 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %50, <8 x i16> %51) #5
  %53 = shufflevector <16 x i8> %52, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %54 = bitcast <16 x i8> %53 to <2 x i64>
  %55 = extractelement <2 x i64> %54, i32 0
  %56 = bitcast i8* %27 to i64*
  store i64 %55, i64* %56, align 1
  %57 = getelementptr inbounds i8, i8* %27, i64 %1
  %58 = add <8 x i16> %29, <i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514>
  %59 = bitcast <8 x i16> %58 to <2 x i64>
  %60 = add nuw nsw i32 %30, 1
  %61 = icmp eq i32 %60, 8
  br i1 %61, label %62, label %26

62:                                               ; preds = %26
  %63 = shl i64 %1, 3
  %64 = getelementptr inbounds i8, i8* %0, i64 %63
  %65 = shufflevector <16 x i8> %24, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  br label %66

66:                                               ; preds = %66, %62
  %67 = phi i8* [ %64, %62 ], [ %97, %66 ]
  %68 = phi <2 x i64> [ <i64 72058693566333184, i64 72058693566333184>, %62 ], [ %99, %66 ]
  %69 = phi <8 x i16> [ <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %62 ], [ %98, %66 ]
  %70 = phi i32 [ 0, %62 ], [ %100, %66 ]
  %71 = bitcast <2 x i64> %68 to <16 x i8>
  %72 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 68, i8 0, i8 54, i8 0, i8 43, i8 0, i8 33, i8 0, i8 26, i8 0, i8 20, i8 0, i8 17, i8 0, i8 16, i8 0>, <16 x i8> %71) #5
  %73 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -68, i8 0, i8 -54, i8 0, i8 -43, i8 0, i8 -33, i8 0, i8 -26, i8 0, i8 -20, i8 0, i8 -17, i8 0, i8 -16, i8 0>, <16 x i8> %71) #5
  %74 = bitcast <16 x i8> %72 to <8 x i16>
  %75 = bitcast <16 x i8> %73 to <8 x i16>
  %76 = shufflevector <8 x i16> %74, <8 x i16> %75, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> %76) #5
  %78 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> %76) #5
  %79 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %65, <16 x i8> %71) #5
  %80 = bitcast <16 x i8> %79 to <8 x i16>
  %81 = shufflevector <8 x i16> %80, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %81, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %83 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %81, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %84 = add <4 x i32> %77, <i32 256, i32 256, i32 256, i32 256>
  %85 = add <4 x i32> %84, %82
  %86 = ashr <4 x i32> %85, <i32 9, i32 9, i32 9, i32 9>
  %87 = add <4 x i32> %78, <i32 256, i32 256, i32 256, i32 256>
  %88 = add <4 x i32> %87, %83
  %89 = ashr <4 x i32> %88, <i32 9, i32 9, i32 9, i32 9>
  %90 = bitcast <4 x i32> %86 to <8 x i16>
  %91 = bitcast <4 x i32> %89 to <8 x i16>
  %92 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> %91) #5
  %93 = shufflevector <16 x i8> %92, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %94 = bitcast <16 x i8> %93 to <2 x i64>
  %95 = extractelement <2 x i64> %94, i32 0
  %96 = bitcast i8* %67 to i64*
  store i64 %95, i64* %96, align 1
  %97 = getelementptr inbounds i8, i8* %67, i64 %1
  %98 = add <8 x i16> %69, <i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514>
  %99 = bitcast <8 x i16> %98 to <2 x i64>
  %100 = add nuw nsw i32 %70, 1
  %101 = icmp eq i32 %100, 8
  br i1 %101, label %102, label %66

102:                                              ; preds = %66
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Smooth8x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = shufflevector <8 x i16> %15, <8 x i16> %9, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %17 = shufflevector <8 x i16> %15, <8 x i16> %9, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %18 = getelementptr inbounds i8, i8* %2, i64 7
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> zeroinitializer
  %23 = bitcast i8* %3 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 1
  %25 = getelementptr inbounds i8, i8* %3, i64 16
  %26 = bitcast i8* %25 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 1
  %28 = shufflevector <16 x i8> %24, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  br label %29

29:                                               ; preds = %29, %4
  %30 = phi i8* [ %0, %4 ], [ %60, %29 ]
  %31 = phi <2 x i64> [ <i64 72058693566333184, i64 72058693566333184>, %4 ], [ %62, %29 ]
  %32 = phi <8 x i16> [ <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %4 ], [ %61, %29 ]
  %33 = phi i32 [ 0, %4 ], [ %63, %29 ]
  %34 = bitcast <2 x i64> %31 to <16 x i8>
  %35 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -1, i8 0, i8 -16, i8 0, i8 -31, i8 0, i8 -46, i8 0, i8 -60, i8 0, i8 -74, i8 0, i8 -87, i8 0, i8 -99, i8 0>, <16 x i8> %34) #5
  %36 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 1, i8 0, i8 16, i8 0, i8 31, i8 0, i8 46, i8 0, i8 60, i8 0, i8 74, i8 0, i8 87, i8 0, i8 99, i8 0>, <16 x i8> %34) #5
  %37 = bitcast <16 x i8> %35 to <8 x i16>
  %38 = bitcast <16 x i8> %36 to <8 x i16>
  %39 = shufflevector <8 x i16> %37, <8 x i16> %38, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %40 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> %39) #5
  %41 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> %39) #5
  %42 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %28, <16 x i8> %34) #5
  %43 = bitcast <16 x i8> %42 to <8 x i16>
  %44 = shufflevector <8 x i16> %43, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %45 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %44, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %46 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %44, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %47 = add <4 x i32> %40, <i32 256, i32 256, i32 256, i32 256>
  %48 = add <4 x i32> %47, %45
  %49 = ashr <4 x i32> %48, <i32 9, i32 9, i32 9, i32 9>
  %50 = add <4 x i32> %41, <i32 256, i32 256, i32 256, i32 256>
  %51 = add <4 x i32> %50, %46
  %52 = ashr <4 x i32> %51, <i32 9, i32 9, i32 9, i32 9>
  %53 = bitcast <4 x i32> %49 to <8 x i16>
  %54 = bitcast <4 x i32> %52 to <8 x i16>
  %55 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %54) #5
  %56 = shufflevector <16 x i8> %55, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %57 = bitcast <16 x i8> %56 to <2 x i64>
  %58 = extractelement <2 x i64> %57, i32 0
  %59 = bitcast i8* %30 to i64*
  store i64 %58, i64* %59, align 1
  %60 = getelementptr inbounds i8, i8* %30, i64 %1
  %61 = add <8 x i16> %32, <i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514>
  %62 = bitcast <8 x i16> %61 to <2 x i64>
  %63 = add nuw nsw i32 %33, 1
  %64 = icmp eq i32 %63, 8
  br i1 %64, label %65, label %29

65:                                               ; preds = %29
  %66 = shl i64 %1, 3
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = shufflevector <16 x i8> %24, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  br label %69

69:                                               ; preds = %69, %65
  %70 = phi i8* [ %67, %65 ], [ %100, %69 ]
  %71 = phi <2 x i64> [ <i64 72058693566333184, i64 72058693566333184>, %65 ], [ %102, %69 ]
  %72 = phi <8 x i16> [ <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %65 ], [ %101, %69 ]
  %73 = phi i32 [ 0, %65 ], [ %103, %69 ]
  %74 = bitcast <2 x i64> %71 to <16 x i8>
  %75 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -111, i8 0, i8 -123, i8 0, i8 122, i8 0, i8 111, i8 0, i8 101, i8 0, i8 92, i8 0, i8 83, i8 0, i8 74, i8 0>, <16 x i8> %74) #5
  %76 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 111, i8 0, i8 123, i8 0, i8 -122, i8 0, i8 -111, i8 0, i8 -101, i8 0, i8 -92, i8 0, i8 -83, i8 0, i8 -74, i8 0>, <16 x i8> %74) #5
  %77 = bitcast <16 x i8> %75 to <8 x i16>
  %78 = bitcast <16 x i8> %76 to <8 x i16>
  %79 = shufflevector <8 x i16> %77, <8 x i16> %78, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> %79) #5
  %81 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> %79) #5
  %82 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %68, <16 x i8> %74) #5
  %83 = bitcast <16 x i8> %82 to <8 x i16>
  %84 = shufflevector <8 x i16> %83, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %85 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %84, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %86 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %84, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %87 = add <4 x i32> %80, <i32 256, i32 256, i32 256, i32 256>
  %88 = add <4 x i32> %87, %85
  %89 = ashr <4 x i32> %88, <i32 9, i32 9, i32 9, i32 9>
  %90 = add <4 x i32> %81, <i32 256, i32 256, i32 256, i32 256>
  %91 = add <4 x i32> %90, %86
  %92 = ashr <4 x i32> %91, <i32 9, i32 9, i32 9, i32 9>
  %93 = bitcast <4 x i32> %89 to <8 x i16>
  %94 = bitcast <4 x i32> %92 to <8 x i16>
  %95 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %93, <8 x i16> %94) #5
  %96 = shufflevector <16 x i8> %95, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %97 = bitcast <16 x i8> %96 to <2 x i64>
  %98 = extractelement <2 x i64> %97, i32 0
  %99 = bitcast i8* %70 to i64*
  store i64 %98, i64* %99, align 1
  %100 = getelementptr inbounds i8, i8* %70, i64 %1
  %101 = add <8 x i16> %72, <i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514>
  %102 = bitcast <8 x i16> %101 to <2 x i64>
  %103 = add nuw nsw i32 %73, 1
  %104 = icmp eq i32 %103, 8
  br i1 %104, label %105, label %69

105:                                              ; preds = %69
  %106 = getelementptr inbounds i8, i8* %67, i64 %66
  %107 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  br label %108

108:                                              ; preds = %108, %105
  %109 = phi i8* [ %106, %105 ], [ %139, %108 ]
  %110 = phi <2 x i64> [ <i64 72058693566333184, i64 72058693566333184>, %105 ], [ %141, %108 ]
  %111 = phi <8 x i16> [ <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %105 ], [ %140, %108 ]
  %112 = phi i32 [ 0, %105 ], [ %142, %108 ]
  %113 = bitcast <2 x i64> %110 to <16 x i8>
  %114 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 66, i8 0, i8 59, i8 0, i8 52, i8 0, i8 45, i8 0, i8 39, i8 0, i8 34, i8 0, i8 29, i8 0, i8 25, i8 0>, <16 x i8> %113) #5
  %115 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -66, i8 0, i8 -59, i8 0, i8 -52, i8 0, i8 -45, i8 0, i8 -39, i8 0, i8 -34, i8 0, i8 -29, i8 0, i8 -25, i8 0>, <16 x i8> %113) #5
  %116 = bitcast <16 x i8> %114 to <8 x i16>
  %117 = bitcast <16 x i8> %115 to <8 x i16>
  %118 = shufflevector <8 x i16> %116, <8 x i16> %117, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %119 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> %118) #5
  %120 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> %118) #5
  %121 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %107, <16 x i8> %113) #5
  %122 = bitcast <16 x i8> %121 to <8 x i16>
  %123 = shufflevector <8 x i16> %122, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %124 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %123, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %125 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %123, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %126 = add <4 x i32> %119, <i32 256, i32 256, i32 256, i32 256>
  %127 = add <4 x i32> %126, %124
  %128 = ashr <4 x i32> %127, <i32 9, i32 9, i32 9, i32 9>
  %129 = add <4 x i32> %120, <i32 256, i32 256, i32 256, i32 256>
  %130 = add <4 x i32> %129, %125
  %131 = ashr <4 x i32> %130, <i32 9, i32 9, i32 9, i32 9>
  %132 = bitcast <4 x i32> %128 to <8 x i16>
  %133 = bitcast <4 x i32> %131 to <8 x i16>
  %134 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %132, <8 x i16> %133) #5
  %135 = shufflevector <16 x i8> %134, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %136 = bitcast <16 x i8> %135 to <2 x i64>
  %137 = extractelement <2 x i64> %136, i32 0
  %138 = bitcast i8* %109 to i64*
  store i64 %137, i64* %138, align 1
  %139 = getelementptr inbounds i8, i8* %109, i64 %1
  %140 = add <8 x i16> %111, <i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514>
  %141 = bitcast <8 x i16> %140 to <2 x i64>
  %142 = add nuw nsw i32 %112, 1
  %143 = icmp eq i32 %142, 8
  br i1 %143, label %144, label %108

144:                                              ; preds = %108
  %145 = getelementptr inbounds i8, i8* %106, i64 %66
  %146 = shufflevector <16 x i8> %27, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  br label %147

147:                                              ; preds = %147, %144
  %148 = phi i8* [ %145, %144 ], [ %178, %147 ]
  %149 = phi <2 x i64> [ <i64 72058693566333184, i64 72058693566333184>, %144 ], [ %180, %147 ]
  %150 = phi <8 x i16> [ <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %144 ], [ %179, %147 ]
  %151 = phi i32 [ 0, %144 ], [ %181, %147 ]
  %152 = bitcast <2 x i64> %149 to <16 x i8>
  %153 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 21, i8 0, i8 17, i8 0, i8 14, i8 0, i8 12, i8 0, i8 10, i8 0, i8 9, i8 0, i8 8, i8 0, i8 8, i8 0>, <16 x i8> %152) #5
  %154 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -21, i8 0, i8 -17, i8 0, i8 -14, i8 0, i8 -12, i8 0, i8 -10, i8 0, i8 -9, i8 0, i8 -8, i8 0, i8 -8, i8 0>, <16 x i8> %152) #5
  %155 = bitcast <16 x i8> %153 to <8 x i16>
  %156 = bitcast <16 x i8> %154 to <8 x i16>
  %157 = shufflevector <8 x i16> %155, <8 x i16> %156, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %158 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> %157) #5
  %159 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> %157) #5
  %160 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %146, <16 x i8> %152) #5
  %161 = bitcast <16 x i8> %160 to <8 x i16>
  %162 = shufflevector <8 x i16> %161, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %163 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %162, <8 x i16> <i16 255, i16 1, i16 197, i16 59, i16 146, i16 110, i16 105, i16 151>) #5
  %164 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %162, <8 x i16> <i16 73, i16 183, i16 50, i16 206, i16 37, i16 219, i16 32, i16 224>) #5
  %165 = add <4 x i32> %158, <i32 256, i32 256, i32 256, i32 256>
  %166 = add <4 x i32> %165, %163
  %167 = ashr <4 x i32> %166, <i32 9, i32 9, i32 9, i32 9>
  %168 = add <4 x i32> %159, <i32 256, i32 256, i32 256, i32 256>
  %169 = add <4 x i32> %168, %164
  %170 = ashr <4 x i32> %169, <i32 9, i32 9, i32 9, i32 9>
  %171 = bitcast <4 x i32> %167 to <8 x i16>
  %172 = bitcast <4 x i32> %170 to <8 x i16>
  %173 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %171, <8 x i16> %172) #5
  %174 = shufflevector <16 x i8> %173, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %175 = bitcast <16 x i8> %174 to <2 x i64>
  %176 = extractelement <2 x i64> %175, i32 0
  %177 = bitcast i8* %148 to i64*
  store i64 %176, i64* %177, align 1
  %178 = getelementptr inbounds i8, i8* %148, i64 %1
  %179 = add <8 x i16> %150, <i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514, i16 514>
  %180 = bitcast <8 x i16> %179 to <2 x i64>
  %181 = add nuw nsw i32 %151, 1
  %182 = icmp eq i32 %181, 8
  br i1 %182, label %183, label %147

183:                                              ; preds = %147
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi4EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 3
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 15
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  br label %29

28:                                               ; preds = %29
  ret void

29:                                               ; preds = %29, %4
  %30 = phi i64 [ 0, %4 ], [ %101, %29 ]
  %31 = phi i8* [ %0, %4 ], [ %100, %29 ]
  %32 = getelementptr inbounds [124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 %30
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %34, i32 0
  %36 = getelementptr inbounds i8, i8* %3, i64 %30
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = bitcast <4 x i32> %35 to <8 x i16>
  %41 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %40
  %42 = mul <8 x i16> %41, %14
  %43 = bitcast <4 x i32> %39 to <8 x i16>
  %44 = shufflevector <8 x i16> %40, <8 x i16> %43, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %45 = bitcast <8 x i16> %44 to <4 x i32>
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <8 x i16> %42 to <4 x i32>
  %48 = add <4 x i32> %47, <i32 256, i32 undef, i32 undef, i32 undef>
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = bitcast <4 x i32> %46 to <8 x i16>
  %51 = load i64, i64* %15, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 -1, i8 -31, i8 -60, i8 -86, i8 -111, i8 123, i8 102, i8 84, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %56 = zext <8 x i8> %55 to <8 x i16>
  %57 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %50) #5
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %50) #5
  %61 = add <4 x i32> %58, %49
  %62 = add <4 x i32> %60, %49
  %63 = add <4 x i32> %61, %18
  %64 = add <4 x i32> %62, %20
  %65 = lshr <4 x i32> %63, <i32 9, i32 9, i32 9, i32 9>
  %66 = lshr <4 x i32> %64, <i32 9, i32 9, i32 9, i32 9>
  %67 = bitcast <4 x i32> %65 to <8 x i16>
  %68 = bitcast <4 x i32> %66 to <8 x i16>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> %68) #5
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #5
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %31 to i64*
  store i64 %73, i64* %74, align 1
  %75 = load i64, i64* %22, align 1
  %76 = insertelement <2 x i64> undef, i64 %75, i32 0
  %77 = bitcast <2 x i64> %76 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 68, i8 54, i8 43, i8 33, i8 26, i8 20, i8 17, i8 16, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = shufflevector <16 x i8> %78, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %80 = zext <8 x i8> %79 to <8 x i16>
  %81 = shufflevector <16 x i8> %78, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> %50) #5
  %83 = bitcast <16 x i8> %81 to <8 x i16>
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %83, <8 x i16> %50) #5
  %85 = add <4 x i32> %82, %49
  %86 = add <4 x i32> %84, %49
  %87 = add <4 x i32> %85, %25
  %88 = add <4 x i32> %86, %27
  %89 = lshr <4 x i32> %87, <i32 9, i32 9, i32 9, i32 9>
  %90 = lshr <4 x i32> %88, <i32 9, i32 9, i32 9, i32 9>
  %91 = bitcast <4 x i32> %89 to <8 x i16>
  %92 = bitcast <4 x i32> %90 to <8 x i16>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %91, <8 x i16> %92) #5
  %94 = getelementptr inbounds i8, i8* %31, i64 8
  %95 = bitcast <16 x i8> %93 to <8 x i16>
  %96 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %95, <8 x i16> undef) #5
  %97 = bitcast <16 x i8> %96 to <2 x i64>
  %98 = extractelement <2 x i64> %97, i32 0
  %99 = bitcast i8* %94 to i64*
  store i64 %98, i64* %99, align 1
  %100 = getelementptr inbounds i8, i8* %31, i64 %1
  %101 = add nuw nsw i64 %30, 1
  %102 = icmp eq i64 %101, 4
  br i1 %102, label %28, label %29
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi8EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 15
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  br label %29

28:                                               ; preds = %29
  ret void

29:                                               ; preds = %29, %4
  %30 = phi i64 [ 0, %4 ], [ %101, %29 ]
  %31 = phi i8* [ %0, %4 ], [ %100, %29 ]
  %32 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 4), i64 %30
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %34, i32 0
  %36 = getelementptr inbounds i8, i8* %3, i64 %30
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = bitcast <4 x i32> %35 to <8 x i16>
  %41 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %40
  %42 = mul <8 x i16> %41, %14
  %43 = bitcast <4 x i32> %39 to <8 x i16>
  %44 = shufflevector <8 x i16> %40, <8 x i16> %43, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %45 = bitcast <8 x i16> %44 to <4 x i32>
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <8 x i16> %42 to <4 x i32>
  %48 = add <4 x i32> %47, <i32 256, i32 undef, i32 undef, i32 undef>
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = bitcast <4 x i32> %46 to <8 x i16>
  %51 = load i64, i64* %15, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 -1, i8 -31, i8 -60, i8 -86, i8 -111, i8 123, i8 102, i8 84, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %56 = zext <8 x i8> %55 to <8 x i16>
  %57 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %50) #5
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %50) #5
  %61 = add <4 x i32> %58, %49
  %62 = add <4 x i32> %60, %49
  %63 = add <4 x i32> %61, %18
  %64 = add <4 x i32> %62, %20
  %65 = lshr <4 x i32> %63, <i32 9, i32 9, i32 9, i32 9>
  %66 = lshr <4 x i32> %64, <i32 9, i32 9, i32 9, i32 9>
  %67 = bitcast <4 x i32> %65 to <8 x i16>
  %68 = bitcast <4 x i32> %66 to <8 x i16>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> %68) #5
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #5
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %31 to i64*
  store i64 %73, i64* %74, align 1
  %75 = load i64, i64* %22, align 1
  %76 = insertelement <2 x i64> undef, i64 %75, i32 0
  %77 = bitcast <2 x i64> %76 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 68, i8 54, i8 43, i8 33, i8 26, i8 20, i8 17, i8 16, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = shufflevector <16 x i8> %78, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %80 = zext <8 x i8> %79 to <8 x i16>
  %81 = shufflevector <16 x i8> %78, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> %50) #5
  %83 = bitcast <16 x i8> %81 to <8 x i16>
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %83, <8 x i16> %50) #5
  %85 = add <4 x i32> %82, %49
  %86 = add <4 x i32> %84, %49
  %87 = add <4 x i32> %85, %25
  %88 = add <4 x i32> %86, %27
  %89 = lshr <4 x i32> %87, <i32 9, i32 9, i32 9, i32 9>
  %90 = lshr <4 x i32> %88, <i32 9, i32 9, i32 9, i32 9>
  %91 = bitcast <4 x i32> %89 to <8 x i16>
  %92 = bitcast <4 x i32> %90 to <8 x i16>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %91, <8 x i16> %92) #5
  %94 = getelementptr inbounds i8, i8* %31, i64 8
  %95 = bitcast <16 x i8> %93 to <8 x i16>
  %96 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %95, <8 x i16> undef) #5
  %97 = bitcast <16 x i8> %96 to <2 x i64>
  %98 = extractelement <2 x i64> %97, i32 0
  %99 = bitcast i8* %94 to i64*
  store i64 %98, i64* %99, align 1
  %100 = getelementptr inbounds i8, i8* %31, i64 %1
  %101 = add nuw nsw i64 %30, 1
  %102 = icmp eq i64 %101, 8
  br i1 %102, label %28, label %29
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi16EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 15
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  br label %29

28:                                               ; preds = %29
  ret void

29:                                               ; preds = %29, %4
  %30 = phi i64 [ 0, %4 ], [ %101, %29 ]
  %31 = phi i8* [ %0, %4 ], [ %100, %29 ]
  %32 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 12), i64 %30
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %34, i32 0
  %36 = getelementptr inbounds i8, i8* %3, i64 %30
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = bitcast <4 x i32> %35 to <8 x i16>
  %41 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %40
  %42 = mul <8 x i16> %41, %14
  %43 = bitcast <4 x i32> %39 to <8 x i16>
  %44 = shufflevector <8 x i16> %40, <8 x i16> %43, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %45 = bitcast <8 x i16> %44 to <4 x i32>
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <8 x i16> %42 to <4 x i32>
  %48 = add <4 x i32> %47, <i32 256, i32 undef, i32 undef, i32 undef>
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = bitcast <4 x i32> %46 to <8 x i16>
  %51 = load i64, i64* %15, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 -1, i8 -31, i8 -60, i8 -86, i8 -111, i8 123, i8 102, i8 84, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %56 = zext <8 x i8> %55 to <8 x i16>
  %57 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %50) #5
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %50) #5
  %61 = add <4 x i32> %58, %49
  %62 = add <4 x i32> %60, %49
  %63 = add <4 x i32> %61, %18
  %64 = add <4 x i32> %62, %20
  %65 = lshr <4 x i32> %63, <i32 9, i32 9, i32 9, i32 9>
  %66 = lshr <4 x i32> %64, <i32 9, i32 9, i32 9, i32 9>
  %67 = bitcast <4 x i32> %65 to <8 x i16>
  %68 = bitcast <4 x i32> %66 to <8 x i16>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> %68) #5
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #5
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %31 to i64*
  store i64 %73, i64* %74, align 1
  %75 = load i64, i64* %22, align 1
  %76 = insertelement <2 x i64> undef, i64 %75, i32 0
  %77 = bitcast <2 x i64> %76 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 68, i8 54, i8 43, i8 33, i8 26, i8 20, i8 17, i8 16, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = shufflevector <16 x i8> %78, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %80 = zext <8 x i8> %79 to <8 x i16>
  %81 = shufflevector <16 x i8> %78, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> %50) #5
  %83 = bitcast <16 x i8> %81 to <8 x i16>
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %83, <8 x i16> %50) #5
  %85 = add <4 x i32> %82, %49
  %86 = add <4 x i32> %84, %49
  %87 = add <4 x i32> %85, %25
  %88 = add <4 x i32> %86, %27
  %89 = lshr <4 x i32> %87, <i32 9, i32 9, i32 9, i32 9>
  %90 = lshr <4 x i32> %88, <i32 9, i32 9, i32 9, i32 9>
  %91 = bitcast <4 x i32> %89 to <8 x i16>
  %92 = bitcast <4 x i32> %90 to <8 x i16>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %91, <8 x i16> %92) #5
  %94 = getelementptr inbounds i8, i8* %31, i64 8
  %95 = bitcast <16 x i8> %93 to <8 x i16>
  %96 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %95, <8 x i16> undef) #5
  %97 = bitcast <16 x i8> %96 to <2 x i64>
  %98 = extractelement <2 x i64> %97, i32 0
  %99 = bitcast i8* %94 to i64*
  store i64 %98, i64* %99, align 1
  %100 = getelementptr inbounds i8, i8* %31, i64 %1
  %101 = add nuw nsw i64 %30, 1
  %102 = icmp eq i64 %101, 16
  br i1 %102, label %28, label %29
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi32EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 15
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  br label %29

28:                                               ; preds = %29
  ret void

29:                                               ; preds = %29, %4
  %30 = phi i64 [ 0, %4 ], [ %101, %29 ]
  %31 = phi i8* [ %0, %4 ], [ %100, %29 ]
  %32 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 28), i64 %30
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %34, i32 0
  %36 = getelementptr inbounds i8, i8* %3, i64 %30
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = bitcast <4 x i32> %35 to <8 x i16>
  %41 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %40
  %42 = mul <8 x i16> %41, %14
  %43 = bitcast <4 x i32> %39 to <8 x i16>
  %44 = shufflevector <8 x i16> %40, <8 x i16> %43, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %45 = bitcast <8 x i16> %44 to <4 x i32>
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <8 x i16> %42 to <4 x i32>
  %48 = add <4 x i32> %47, <i32 256, i32 undef, i32 undef, i32 undef>
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = bitcast <4 x i32> %46 to <8 x i16>
  %51 = load i64, i64* %15, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 -1, i8 -31, i8 -60, i8 -86, i8 -111, i8 123, i8 102, i8 84, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %56 = zext <8 x i8> %55 to <8 x i16>
  %57 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %50) #5
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %50) #5
  %61 = add <4 x i32> %58, %49
  %62 = add <4 x i32> %60, %49
  %63 = add <4 x i32> %61, %18
  %64 = add <4 x i32> %62, %20
  %65 = lshr <4 x i32> %63, <i32 9, i32 9, i32 9, i32 9>
  %66 = lshr <4 x i32> %64, <i32 9, i32 9, i32 9, i32 9>
  %67 = bitcast <4 x i32> %65 to <8 x i16>
  %68 = bitcast <4 x i32> %66 to <8 x i16>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> %68) #5
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #5
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %31 to i64*
  store i64 %73, i64* %74, align 1
  %75 = load i64, i64* %22, align 1
  %76 = insertelement <2 x i64> undef, i64 %75, i32 0
  %77 = bitcast <2 x i64> %76 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 68, i8 54, i8 43, i8 33, i8 26, i8 20, i8 17, i8 16, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = shufflevector <16 x i8> %78, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %80 = zext <8 x i8> %79 to <8 x i16>
  %81 = shufflevector <16 x i8> %78, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> %50) #5
  %83 = bitcast <16 x i8> %81 to <8 x i16>
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %83, <8 x i16> %50) #5
  %85 = add <4 x i32> %82, %49
  %86 = add <4 x i32> %84, %49
  %87 = add <4 x i32> %85, %25
  %88 = add <4 x i32> %86, %27
  %89 = lshr <4 x i32> %87, <i32 9, i32 9, i32 9, i32 9>
  %90 = lshr <4 x i32> %88, <i32 9, i32 9, i32 9, i32 9>
  %91 = bitcast <4 x i32> %89 to <8 x i16>
  %92 = bitcast <4 x i32> %90 to <8 x i16>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %91, <8 x i16> %92) #5
  %94 = getelementptr inbounds i8, i8* %31, i64 8
  %95 = bitcast <16 x i8> %93 to <8 x i16>
  %96 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %95, <8 x i16> undef) #5
  %97 = bitcast <16 x i8> %96 to <2 x i64>
  %98 = extractelement <2 x i64> %97, i32 0
  %99 = bitcast i8* %94 to i64*
  store i64 %98, i64* %99, align 1
  %100 = getelementptr inbounds i8, i8* %31, i64 %1
  %101 = add nuw nsw i64 %30, 1
  %102 = icmp eq i64 %101, 32
  br i1 %102, label %28, label %29
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi16ELi64EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 15
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  br label %29

28:                                               ; preds = %29
  ret void

29:                                               ; preds = %29, %4
  %30 = phi i64 [ 0, %4 ], [ %101, %29 ]
  %31 = phi i8* [ %0, %4 ], [ %100, %29 ]
  %32 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %30
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %34, i32 0
  %36 = getelementptr inbounds i8, i8* %3, i64 %30
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = bitcast <4 x i32> %35 to <8 x i16>
  %41 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %40
  %42 = mul <8 x i16> %41, %14
  %43 = bitcast <4 x i32> %39 to <8 x i16>
  %44 = shufflevector <8 x i16> %40, <8 x i16> %43, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %45 = bitcast <8 x i16> %44 to <4 x i32>
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <8 x i16> %42 to <4 x i32>
  %48 = add <4 x i32> %47, <i32 256, i32 undef, i32 undef, i32 undef>
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = bitcast <4 x i32> %46 to <8 x i16>
  %51 = load i64, i64* %15, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 -1, i8 -31, i8 -60, i8 -86, i8 -111, i8 123, i8 102, i8 84, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %56 = zext <8 x i8> %55 to <8 x i16>
  %57 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %50) #5
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %50) #5
  %61 = add <4 x i32> %58, %49
  %62 = add <4 x i32> %60, %49
  %63 = add <4 x i32> %61, %18
  %64 = add <4 x i32> %62, %20
  %65 = lshr <4 x i32> %63, <i32 9, i32 9, i32 9, i32 9>
  %66 = lshr <4 x i32> %64, <i32 9, i32 9, i32 9, i32 9>
  %67 = bitcast <4 x i32> %65 to <8 x i16>
  %68 = bitcast <4 x i32> %66 to <8 x i16>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> %68) #5
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #5
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %31 to i64*
  store i64 %73, i64* %74, align 1
  %75 = load i64, i64* %22, align 1
  %76 = insertelement <2 x i64> undef, i64 %75, i32 0
  %77 = bitcast <2 x i64> %76 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 68, i8 54, i8 43, i8 33, i8 26, i8 20, i8 17, i8 16, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = shufflevector <16 x i8> %78, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %80 = zext <8 x i8> %79 to <8 x i16>
  %81 = shufflevector <16 x i8> %78, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> %50) #5
  %83 = bitcast <16 x i8> %81 to <8 x i16>
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %83, <8 x i16> %50) #5
  %85 = add <4 x i32> %82, %49
  %86 = add <4 x i32> %84, %49
  %87 = add <4 x i32> %85, %25
  %88 = add <4 x i32> %86, %27
  %89 = lshr <4 x i32> %87, <i32 9, i32 9, i32 9, i32 9>
  %90 = lshr <4 x i32> %88, <i32 9, i32 9, i32 9, i32 9>
  %91 = bitcast <4 x i32> %89 to <8 x i16>
  %92 = bitcast <4 x i32> %90 to <8 x i16>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %91, <8 x i16> %92) #5
  %94 = getelementptr inbounds i8, i8* %31, i64 8
  %95 = bitcast <16 x i8> %93 to <8 x i16>
  %96 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %95, <8 x i16> undef) #5
  %97 = bitcast <16 x i8> %96 to <2 x i64>
  %98 = extractelement <2 x i64> %97, i32 0
  %99 = bitcast i8* %94 to i64*
  store i64 %98, i64* %99, align 1
  %100 = getelementptr inbounds i8, i8* %31, i64 %1
  %101 = add nuw nsw i64 %30, 1
  %102 = icmp eq i64 %101, 64
  br i1 %102, label %28, label %29
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi32ELi8EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 31
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  %28 = getelementptr inbounds i8, i8* %2, i64 16
  %29 = bitcast i8* %28 to i64*
  %30 = mul <8 x i16> %13, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %31 = shufflevector <8 x i16> %30, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %32 = zext <4 x i16> %31 to <4 x i32>
  %33 = shufflevector <8 x i16> %30, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %34 = bitcast <8 x i16> %33 to <4 x i32>
  %35 = getelementptr inbounds i8, i8* %2, i64 24
  %36 = bitcast i8* %35 to i64*
  %37 = mul <8 x i16> %13, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %38 = shufflevector <8 x i16> %37, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %39 = zext <4 x i16> %38 to <4 x i32>
  %40 = shufflevector <8 x i16> %37, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %41 = bitcast <8 x i16> %40 to <4 x i32>
  br label %43

42:                                               ; preds = %43
  ret void

43:                                               ; preds = %43, %4
  %44 = phi i64 [ 0, %4 ], [ %165, %43 ]
  %45 = phi i8* [ %0, %4 ], [ %164, %43 ]
  %46 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 4), i64 %44
  %47 = load i8, i8* %46, align 1
  %48 = zext i8 %47 to i32
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %3, i64 %44
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = insertelement <4 x i32> undef, i32 %52, i32 0
  %54 = bitcast <4 x i32> %49 to <8 x i16>
  %55 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %54
  %56 = mul <8 x i16> %55, %14
  %57 = bitcast <4 x i32> %53 to <8 x i16>
  %58 = shufflevector <8 x i16> %54, <8 x i16> %57, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %59 = bitcast <8 x i16> %58 to <4 x i32>
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = bitcast <8 x i16> %56 to <4 x i32>
  %62 = add <4 x i32> %61, <i32 256, i32 undef, i32 undef, i32 undef>
  %63 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> zeroinitializer
  %64 = bitcast <4 x i32> %60 to <8 x i16>
  %65 = load i64, i64* %15, align 1
  %66 = insertelement <2 x i64> undef, i64 %65, i32 0
  %67 = bitcast <2 x i64> %66 to <16 x i8>
  %68 = shufflevector <16 x i8> %67, <16 x i8> <i8 -1, i8 -16, i8 -31, i8 -46, i8 -60, i8 -74, i8 -87, i8 -99, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %69 = shufflevector <16 x i8> %68, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %70 = zext <8 x i8> %69 to <8 x i16>
  %71 = shufflevector <16 x i8> %68, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %72 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %70, <8 x i16> %64) #5
  %73 = bitcast <16 x i8> %71 to <8 x i16>
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %73, <8 x i16> %64) #5
  %75 = add <4 x i32> %72, %63
  %76 = add <4 x i32> %74, %63
  %77 = add <4 x i32> %75, %18
  %78 = add <4 x i32> %76, %20
  %79 = lshr <4 x i32> %77, <i32 9, i32 9, i32 9, i32 9>
  %80 = lshr <4 x i32> %78, <i32 9, i32 9, i32 9, i32 9>
  %81 = bitcast <4 x i32> %79 to <8 x i16>
  %82 = bitcast <4 x i32> %80 to <8 x i16>
  %83 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %82) #5
  %84 = bitcast <16 x i8> %83 to <8 x i16>
  %85 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %84, <8 x i16> undef) #5
  %86 = bitcast <16 x i8> %85 to <2 x i64>
  %87 = extractelement <2 x i64> %86, i32 0
  %88 = bitcast i8* %45 to i64*
  store i64 %87, i64* %88, align 1
  %89 = load i64, i64* %22, align 1
  %90 = insertelement <2 x i64> undef, i64 %89, i32 0
  %91 = bitcast <2 x i64> %90 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 -111, i8 -123, i8 122, i8 111, i8 101, i8 92, i8 83, i8 74, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %93 = shufflevector <16 x i8> %92, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %94 = zext <8 x i8> %93 to <8 x i16>
  %95 = shufflevector <16 x i8> %92, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %94, <8 x i16> %64) #5
  %97 = bitcast <16 x i8> %95 to <8 x i16>
  %98 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> %64) #5
  %99 = add <4 x i32> %96, %63
  %100 = add <4 x i32> %98, %63
  %101 = add <4 x i32> %99, %25
  %102 = add <4 x i32> %100, %27
  %103 = lshr <4 x i32> %101, <i32 9, i32 9, i32 9, i32 9>
  %104 = lshr <4 x i32> %102, <i32 9, i32 9, i32 9, i32 9>
  %105 = bitcast <4 x i32> %103 to <8 x i16>
  %106 = bitcast <4 x i32> %104 to <8 x i16>
  %107 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %105, <8 x i16> %106) #5
  %108 = getelementptr inbounds i8, i8* %45, i64 8
  %109 = bitcast <16 x i8> %107 to <8 x i16>
  %110 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> undef) #5
  %111 = bitcast <16 x i8> %110 to <2 x i64>
  %112 = extractelement <2 x i64> %111, i32 0
  %113 = bitcast i8* %108 to i64*
  store i64 %112, i64* %113, align 1
  %114 = load i64, i64* %29, align 1
  %115 = insertelement <2 x i64> undef, i64 %114, i32 0
  %116 = bitcast <2 x i64> %115 to <16 x i8>
  %117 = shufflevector <16 x i8> %116, <16 x i8> <i8 66, i8 59, i8 52, i8 45, i8 39, i8 34, i8 29, i8 25, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %119 = zext <8 x i8> %118 to <8 x i16>
  %120 = shufflevector <16 x i8> %117, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> %64) #5
  %122 = bitcast <16 x i8> %120 to <8 x i16>
  %123 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %122, <8 x i16> %64) #5
  %124 = add <4 x i32> %121, %63
  %125 = add <4 x i32> %123, %63
  %126 = add <4 x i32> %124, %32
  %127 = add <4 x i32> %125, %34
  %128 = lshr <4 x i32> %126, <i32 9, i32 9, i32 9, i32 9>
  %129 = lshr <4 x i32> %127, <i32 9, i32 9, i32 9, i32 9>
  %130 = bitcast <4 x i32> %128 to <8 x i16>
  %131 = bitcast <4 x i32> %129 to <8 x i16>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> %131) #5
  %133 = getelementptr inbounds i8, i8* %45, i64 16
  %134 = bitcast <16 x i8> %132 to <8 x i16>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %134, <8 x i16> undef) #5
  %136 = bitcast <16 x i8> %135 to <2 x i64>
  %137 = extractelement <2 x i64> %136, i32 0
  %138 = bitcast i8* %133 to i64*
  store i64 %137, i64* %138, align 1
  %139 = load i64, i64* %36, align 1
  %140 = insertelement <2 x i64> undef, i64 %139, i32 0
  %141 = bitcast <2 x i64> %140 to <16 x i8>
  %142 = shufflevector <16 x i8> %141, <16 x i8> <i8 21, i8 17, i8 14, i8 12, i8 10, i8 9, i8 8, i8 8, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %143 = shufflevector <16 x i8> %142, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %144 = zext <8 x i8> %143 to <8 x i16>
  %145 = shufflevector <16 x i8> %142, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %146 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %144, <8 x i16> %64) #5
  %147 = bitcast <16 x i8> %145 to <8 x i16>
  %148 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> %64) #5
  %149 = add <4 x i32> %146, %63
  %150 = add <4 x i32> %148, %63
  %151 = add <4 x i32> %149, %39
  %152 = add <4 x i32> %150, %41
  %153 = lshr <4 x i32> %151, <i32 9, i32 9, i32 9, i32 9>
  %154 = lshr <4 x i32> %152, <i32 9, i32 9, i32 9, i32 9>
  %155 = bitcast <4 x i32> %153 to <8 x i16>
  %156 = bitcast <4 x i32> %154 to <8 x i16>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %156) #5
  %158 = getelementptr inbounds i8, i8* %45, i64 24
  %159 = bitcast <16 x i8> %157 to <8 x i16>
  %160 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> undef) #5
  %161 = bitcast <16 x i8> %160 to <2 x i64>
  %162 = extractelement <2 x i64> %161, i32 0
  %163 = bitcast i8* %158 to i64*
  store i64 %162, i64* %163, align 1
  %164 = getelementptr inbounds i8, i8* %45, i64 %1
  %165 = add nuw nsw i64 %44, 1
  %166 = icmp eq i64 %165, 8
  br i1 %166, label %42, label %43
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi32ELi16EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 31
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  %28 = getelementptr inbounds i8, i8* %2, i64 16
  %29 = bitcast i8* %28 to i64*
  %30 = mul <8 x i16> %13, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %31 = shufflevector <8 x i16> %30, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %32 = zext <4 x i16> %31 to <4 x i32>
  %33 = shufflevector <8 x i16> %30, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %34 = bitcast <8 x i16> %33 to <4 x i32>
  %35 = getelementptr inbounds i8, i8* %2, i64 24
  %36 = bitcast i8* %35 to i64*
  %37 = mul <8 x i16> %13, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %38 = shufflevector <8 x i16> %37, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %39 = zext <4 x i16> %38 to <4 x i32>
  %40 = shufflevector <8 x i16> %37, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %41 = bitcast <8 x i16> %40 to <4 x i32>
  br label %43

42:                                               ; preds = %43
  ret void

43:                                               ; preds = %43, %4
  %44 = phi i64 [ 0, %4 ], [ %165, %43 ]
  %45 = phi i8* [ %0, %4 ], [ %164, %43 ]
  %46 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 12), i64 %44
  %47 = load i8, i8* %46, align 1
  %48 = zext i8 %47 to i32
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %3, i64 %44
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = insertelement <4 x i32> undef, i32 %52, i32 0
  %54 = bitcast <4 x i32> %49 to <8 x i16>
  %55 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %54
  %56 = mul <8 x i16> %55, %14
  %57 = bitcast <4 x i32> %53 to <8 x i16>
  %58 = shufflevector <8 x i16> %54, <8 x i16> %57, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %59 = bitcast <8 x i16> %58 to <4 x i32>
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = bitcast <8 x i16> %56 to <4 x i32>
  %62 = add <4 x i32> %61, <i32 256, i32 undef, i32 undef, i32 undef>
  %63 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> zeroinitializer
  %64 = bitcast <4 x i32> %60 to <8 x i16>
  %65 = load i64, i64* %15, align 1
  %66 = insertelement <2 x i64> undef, i64 %65, i32 0
  %67 = bitcast <2 x i64> %66 to <16 x i8>
  %68 = shufflevector <16 x i8> %67, <16 x i8> <i8 -1, i8 -16, i8 -31, i8 -46, i8 -60, i8 -74, i8 -87, i8 -99, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %69 = shufflevector <16 x i8> %68, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %70 = zext <8 x i8> %69 to <8 x i16>
  %71 = shufflevector <16 x i8> %68, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %72 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %70, <8 x i16> %64) #5
  %73 = bitcast <16 x i8> %71 to <8 x i16>
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %73, <8 x i16> %64) #5
  %75 = add <4 x i32> %72, %63
  %76 = add <4 x i32> %74, %63
  %77 = add <4 x i32> %75, %18
  %78 = add <4 x i32> %76, %20
  %79 = lshr <4 x i32> %77, <i32 9, i32 9, i32 9, i32 9>
  %80 = lshr <4 x i32> %78, <i32 9, i32 9, i32 9, i32 9>
  %81 = bitcast <4 x i32> %79 to <8 x i16>
  %82 = bitcast <4 x i32> %80 to <8 x i16>
  %83 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %82) #5
  %84 = bitcast <16 x i8> %83 to <8 x i16>
  %85 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %84, <8 x i16> undef) #5
  %86 = bitcast <16 x i8> %85 to <2 x i64>
  %87 = extractelement <2 x i64> %86, i32 0
  %88 = bitcast i8* %45 to i64*
  store i64 %87, i64* %88, align 1
  %89 = load i64, i64* %22, align 1
  %90 = insertelement <2 x i64> undef, i64 %89, i32 0
  %91 = bitcast <2 x i64> %90 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 -111, i8 -123, i8 122, i8 111, i8 101, i8 92, i8 83, i8 74, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %93 = shufflevector <16 x i8> %92, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %94 = zext <8 x i8> %93 to <8 x i16>
  %95 = shufflevector <16 x i8> %92, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %94, <8 x i16> %64) #5
  %97 = bitcast <16 x i8> %95 to <8 x i16>
  %98 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> %64) #5
  %99 = add <4 x i32> %96, %63
  %100 = add <4 x i32> %98, %63
  %101 = add <4 x i32> %99, %25
  %102 = add <4 x i32> %100, %27
  %103 = lshr <4 x i32> %101, <i32 9, i32 9, i32 9, i32 9>
  %104 = lshr <4 x i32> %102, <i32 9, i32 9, i32 9, i32 9>
  %105 = bitcast <4 x i32> %103 to <8 x i16>
  %106 = bitcast <4 x i32> %104 to <8 x i16>
  %107 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %105, <8 x i16> %106) #5
  %108 = getelementptr inbounds i8, i8* %45, i64 8
  %109 = bitcast <16 x i8> %107 to <8 x i16>
  %110 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> undef) #5
  %111 = bitcast <16 x i8> %110 to <2 x i64>
  %112 = extractelement <2 x i64> %111, i32 0
  %113 = bitcast i8* %108 to i64*
  store i64 %112, i64* %113, align 1
  %114 = load i64, i64* %29, align 1
  %115 = insertelement <2 x i64> undef, i64 %114, i32 0
  %116 = bitcast <2 x i64> %115 to <16 x i8>
  %117 = shufflevector <16 x i8> %116, <16 x i8> <i8 66, i8 59, i8 52, i8 45, i8 39, i8 34, i8 29, i8 25, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %119 = zext <8 x i8> %118 to <8 x i16>
  %120 = shufflevector <16 x i8> %117, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> %64) #5
  %122 = bitcast <16 x i8> %120 to <8 x i16>
  %123 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %122, <8 x i16> %64) #5
  %124 = add <4 x i32> %121, %63
  %125 = add <4 x i32> %123, %63
  %126 = add <4 x i32> %124, %32
  %127 = add <4 x i32> %125, %34
  %128 = lshr <4 x i32> %126, <i32 9, i32 9, i32 9, i32 9>
  %129 = lshr <4 x i32> %127, <i32 9, i32 9, i32 9, i32 9>
  %130 = bitcast <4 x i32> %128 to <8 x i16>
  %131 = bitcast <4 x i32> %129 to <8 x i16>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> %131) #5
  %133 = getelementptr inbounds i8, i8* %45, i64 16
  %134 = bitcast <16 x i8> %132 to <8 x i16>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %134, <8 x i16> undef) #5
  %136 = bitcast <16 x i8> %135 to <2 x i64>
  %137 = extractelement <2 x i64> %136, i32 0
  %138 = bitcast i8* %133 to i64*
  store i64 %137, i64* %138, align 1
  %139 = load i64, i64* %36, align 1
  %140 = insertelement <2 x i64> undef, i64 %139, i32 0
  %141 = bitcast <2 x i64> %140 to <16 x i8>
  %142 = shufflevector <16 x i8> %141, <16 x i8> <i8 21, i8 17, i8 14, i8 12, i8 10, i8 9, i8 8, i8 8, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %143 = shufflevector <16 x i8> %142, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %144 = zext <8 x i8> %143 to <8 x i16>
  %145 = shufflevector <16 x i8> %142, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %146 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %144, <8 x i16> %64) #5
  %147 = bitcast <16 x i8> %145 to <8 x i16>
  %148 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> %64) #5
  %149 = add <4 x i32> %146, %63
  %150 = add <4 x i32> %148, %63
  %151 = add <4 x i32> %149, %39
  %152 = add <4 x i32> %150, %41
  %153 = lshr <4 x i32> %151, <i32 9, i32 9, i32 9, i32 9>
  %154 = lshr <4 x i32> %152, <i32 9, i32 9, i32 9, i32 9>
  %155 = bitcast <4 x i32> %153 to <8 x i16>
  %156 = bitcast <4 x i32> %154 to <8 x i16>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %156) #5
  %158 = getelementptr inbounds i8, i8* %45, i64 24
  %159 = bitcast <16 x i8> %157 to <8 x i16>
  %160 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> undef) #5
  %161 = bitcast <16 x i8> %160 to <2 x i64>
  %162 = extractelement <2 x i64> %161, i32 0
  %163 = bitcast i8* %158 to i64*
  store i64 %162, i64* %163, align 1
  %164 = getelementptr inbounds i8, i8* %45, i64 %1
  %165 = add nuw nsw i64 %44, 1
  %166 = icmp eq i64 %165, 16
  br i1 %166, label %42, label %43
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi32ELi32EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 31
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  %28 = getelementptr inbounds i8, i8* %2, i64 16
  %29 = bitcast i8* %28 to i64*
  %30 = mul <8 x i16> %13, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %31 = shufflevector <8 x i16> %30, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %32 = zext <4 x i16> %31 to <4 x i32>
  %33 = shufflevector <8 x i16> %30, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %34 = bitcast <8 x i16> %33 to <4 x i32>
  %35 = getelementptr inbounds i8, i8* %2, i64 24
  %36 = bitcast i8* %35 to i64*
  %37 = mul <8 x i16> %13, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %38 = shufflevector <8 x i16> %37, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %39 = zext <4 x i16> %38 to <4 x i32>
  %40 = shufflevector <8 x i16> %37, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %41 = bitcast <8 x i16> %40 to <4 x i32>
  br label %43

42:                                               ; preds = %43
  ret void

43:                                               ; preds = %43, %4
  %44 = phi i64 [ 0, %4 ], [ %165, %43 ]
  %45 = phi i8* [ %0, %4 ], [ %164, %43 ]
  %46 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 28), i64 %44
  %47 = load i8, i8* %46, align 1
  %48 = zext i8 %47 to i32
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %3, i64 %44
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = insertelement <4 x i32> undef, i32 %52, i32 0
  %54 = bitcast <4 x i32> %49 to <8 x i16>
  %55 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %54
  %56 = mul <8 x i16> %55, %14
  %57 = bitcast <4 x i32> %53 to <8 x i16>
  %58 = shufflevector <8 x i16> %54, <8 x i16> %57, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %59 = bitcast <8 x i16> %58 to <4 x i32>
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = bitcast <8 x i16> %56 to <4 x i32>
  %62 = add <4 x i32> %61, <i32 256, i32 undef, i32 undef, i32 undef>
  %63 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> zeroinitializer
  %64 = bitcast <4 x i32> %60 to <8 x i16>
  %65 = load i64, i64* %15, align 1
  %66 = insertelement <2 x i64> undef, i64 %65, i32 0
  %67 = bitcast <2 x i64> %66 to <16 x i8>
  %68 = shufflevector <16 x i8> %67, <16 x i8> <i8 -1, i8 -16, i8 -31, i8 -46, i8 -60, i8 -74, i8 -87, i8 -99, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %69 = shufflevector <16 x i8> %68, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %70 = zext <8 x i8> %69 to <8 x i16>
  %71 = shufflevector <16 x i8> %68, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %72 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %70, <8 x i16> %64) #5
  %73 = bitcast <16 x i8> %71 to <8 x i16>
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %73, <8 x i16> %64) #5
  %75 = add <4 x i32> %72, %63
  %76 = add <4 x i32> %74, %63
  %77 = add <4 x i32> %75, %18
  %78 = add <4 x i32> %76, %20
  %79 = lshr <4 x i32> %77, <i32 9, i32 9, i32 9, i32 9>
  %80 = lshr <4 x i32> %78, <i32 9, i32 9, i32 9, i32 9>
  %81 = bitcast <4 x i32> %79 to <8 x i16>
  %82 = bitcast <4 x i32> %80 to <8 x i16>
  %83 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %82) #5
  %84 = bitcast <16 x i8> %83 to <8 x i16>
  %85 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %84, <8 x i16> undef) #5
  %86 = bitcast <16 x i8> %85 to <2 x i64>
  %87 = extractelement <2 x i64> %86, i32 0
  %88 = bitcast i8* %45 to i64*
  store i64 %87, i64* %88, align 1
  %89 = load i64, i64* %22, align 1
  %90 = insertelement <2 x i64> undef, i64 %89, i32 0
  %91 = bitcast <2 x i64> %90 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 -111, i8 -123, i8 122, i8 111, i8 101, i8 92, i8 83, i8 74, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %93 = shufflevector <16 x i8> %92, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %94 = zext <8 x i8> %93 to <8 x i16>
  %95 = shufflevector <16 x i8> %92, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %94, <8 x i16> %64) #5
  %97 = bitcast <16 x i8> %95 to <8 x i16>
  %98 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> %64) #5
  %99 = add <4 x i32> %96, %63
  %100 = add <4 x i32> %98, %63
  %101 = add <4 x i32> %99, %25
  %102 = add <4 x i32> %100, %27
  %103 = lshr <4 x i32> %101, <i32 9, i32 9, i32 9, i32 9>
  %104 = lshr <4 x i32> %102, <i32 9, i32 9, i32 9, i32 9>
  %105 = bitcast <4 x i32> %103 to <8 x i16>
  %106 = bitcast <4 x i32> %104 to <8 x i16>
  %107 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %105, <8 x i16> %106) #5
  %108 = getelementptr inbounds i8, i8* %45, i64 8
  %109 = bitcast <16 x i8> %107 to <8 x i16>
  %110 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> undef) #5
  %111 = bitcast <16 x i8> %110 to <2 x i64>
  %112 = extractelement <2 x i64> %111, i32 0
  %113 = bitcast i8* %108 to i64*
  store i64 %112, i64* %113, align 1
  %114 = load i64, i64* %29, align 1
  %115 = insertelement <2 x i64> undef, i64 %114, i32 0
  %116 = bitcast <2 x i64> %115 to <16 x i8>
  %117 = shufflevector <16 x i8> %116, <16 x i8> <i8 66, i8 59, i8 52, i8 45, i8 39, i8 34, i8 29, i8 25, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %119 = zext <8 x i8> %118 to <8 x i16>
  %120 = shufflevector <16 x i8> %117, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> %64) #5
  %122 = bitcast <16 x i8> %120 to <8 x i16>
  %123 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %122, <8 x i16> %64) #5
  %124 = add <4 x i32> %121, %63
  %125 = add <4 x i32> %123, %63
  %126 = add <4 x i32> %124, %32
  %127 = add <4 x i32> %125, %34
  %128 = lshr <4 x i32> %126, <i32 9, i32 9, i32 9, i32 9>
  %129 = lshr <4 x i32> %127, <i32 9, i32 9, i32 9, i32 9>
  %130 = bitcast <4 x i32> %128 to <8 x i16>
  %131 = bitcast <4 x i32> %129 to <8 x i16>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> %131) #5
  %133 = getelementptr inbounds i8, i8* %45, i64 16
  %134 = bitcast <16 x i8> %132 to <8 x i16>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %134, <8 x i16> undef) #5
  %136 = bitcast <16 x i8> %135 to <2 x i64>
  %137 = extractelement <2 x i64> %136, i32 0
  %138 = bitcast i8* %133 to i64*
  store i64 %137, i64* %138, align 1
  %139 = load i64, i64* %36, align 1
  %140 = insertelement <2 x i64> undef, i64 %139, i32 0
  %141 = bitcast <2 x i64> %140 to <16 x i8>
  %142 = shufflevector <16 x i8> %141, <16 x i8> <i8 21, i8 17, i8 14, i8 12, i8 10, i8 9, i8 8, i8 8, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %143 = shufflevector <16 x i8> %142, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %144 = zext <8 x i8> %143 to <8 x i16>
  %145 = shufflevector <16 x i8> %142, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %146 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %144, <8 x i16> %64) #5
  %147 = bitcast <16 x i8> %145 to <8 x i16>
  %148 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> %64) #5
  %149 = add <4 x i32> %146, %63
  %150 = add <4 x i32> %148, %63
  %151 = add <4 x i32> %149, %39
  %152 = add <4 x i32> %150, %41
  %153 = lshr <4 x i32> %151, <i32 9, i32 9, i32 9, i32 9>
  %154 = lshr <4 x i32> %152, <i32 9, i32 9, i32 9, i32 9>
  %155 = bitcast <4 x i32> %153 to <8 x i16>
  %156 = bitcast <4 x i32> %154 to <8 x i16>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %156) #5
  %158 = getelementptr inbounds i8, i8* %45, i64 24
  %159 = bitcast <16 x i8> %157 to <8 x i16>
  %160 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> undef) #5
  %161 = bitcast <16 x i8> %160 to <2 x i64>
  %162 = extractelement <2 x i64> %161, i32 0
  %163 = bitcast i8* %158 to i64*
  store i64 %162, i64* %163, align 1
  %164 = getelementptr inbounds i8, i8* %45, i64 %1
  %165 = add nuw nsw i64 %44, 1
  %166 = icmp eq i64 %165, 32
  br i1 %166, label %42, label %43
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi32ELi64EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 31
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  %15 = bitcast i8* %2 to i64*
  %16 = mul <8 x i16> %13, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = getelementptr inbounds i8, i8* %2, i64 8
  %22 = bitcast i8* %21 to i64*
  %23 = mul <8 x i16> %13, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %24 = shufflevector <8 x i16> %23, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = zext <4 x i16> %24 to <4 x i32>
  %26 = shufflevector <8 x i16> %23, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  %28 = getelementptr inbounds i8, i8* %2, i64 16
  %29 = bitcast i8* %28 to i64*
  %30 = mul <8 x i16> %13, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %31 = shufflevector <8 x i16> %30, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %32 = zext <4 x i16> %31 to <4 x i32>
  %33 = shufflevector <8 x i16> %30, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %34 = bitcast <8 x i16> %33 to <4 x i32>
  %35 = getelementptr inbounds i8, i8* %2, i64 24
  %36 = bitcast i8* %35 to i64*
  %37 = mul <8 x i16> %13, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %38 = shufflevector <8 x i16> %37, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %39 = zext <4 x i16> %38 to <4 x i32>
  %40 = shufflevector <8 x i16> %37, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %41 = bitcast <8 x i16> %40 to <4 x i32>
  br label %43

42:                                               ; preds = %43
  ret void

43:                                               ; preds = %43, %4
  %44 = phi i64 [ 0, %4 ], [ %165, %43 ]
  %45 = phi i8* [ %0, %4 ], [ %164, %43 ]
  %46 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %44
  %47 = load i8, i8* %46, align 1
  %48 = zext i8 %47 to i32
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %3, i64 %44
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = insertelement <4 x i32> undef, i32 %52, i32 0
  %54 = bitcast <4 x i32> %49 to <8 x i16>
  %55 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %54
  %56 = mul <8 x i16> %55, %14
  %57 = bitcast <4 x i32> %53 to <8 x i16>
  %58 = shufflevector <8 x i16> %54, <8 x i16> %57, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %59 = bitcast <8 x i16> %58 to <4 x i32>
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = bitcast <8 x i16> %56 to <4 x i32>
  %62 = add <4 x i32> %61, <i32 256, i32 undef, i32 undef, i32 undef>
  %63 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> zeroinitializer
  %64 = bitcast <4 x i32> %60 to <8 x i16>
  %65 = load i64, i64* %15, align 1
  %66 = insertelement <2 x i64> undef, i64 %65, i32 0
  %67 = bitcast <2 x i64> %66 to <16 x i8>
  %68 = shufflevector <16 x i8> %67, <16 x i8> <i8 -1, i8 -16, i8 -31, i8 -46, i8 -60, i8 -74, i8 -87, i8 -99, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %69 = shufflevector <16 x i8> %68, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %70 = zext <8 x i8> %69 to <8 x i16>
  %71 = shufflevector <16 x i8> %68, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %72 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %70, <8 x i16> %64) #5
  %73 = bitcast <16 x i8> %71 to <8 x i16>
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %73, <8 x i16> %64) #5
  %75 = add <4 x i32> %72, %63
  %76 = add <4 x i32> %74, %63
  %77 = add <4 x i32> %75, %18
  %78 = add <4 x i32> %76, %20
  %79 = lshr <4 x i32> %77, <i32 9, i32 9, i32 9, i32 9>
  %80 = lshr <4 x i32> %78, <i32 9, i32 9, i32 9, i32 9>
  %81 = bitcast <4 x i32> %79 to <8 x i16>
  %82 = bitcast <4 x i32> %80 to <8 x i16>
  %83 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %82) #5
  %84 = bitcast <16 x i8> %83 to <8 x i16>
  %85 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %84, <8 x i16> undef) #5
  %86 = bitcast <16 x i8> %85 to <2 x i64>
  %87 = extractelement <2 x i64> %86, i32 0
  %88 = bitcast i8* %45 to i64*
  store i64 %87, i64* %88, align 1
  %89 = load i64, i64* %22, align 1
  %90 = insertelement <2 x i64> undef, i64 %89, i32 0
  %91 = bitcast <2 x i64> %90 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 -111, i8 -123, i8 122, i8 111, i8 101, i8 92, i8 83, i8 74, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %93 = shufflevector <16 x i8> %92, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %94 = zext <8 x i8> %93 to <8 x i16>
  %95 = shufflevector <16 x i8> %92, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %94, <8 x i16> %64) #5
  %97 = bitcast <16 x i8> %95 to <8 x i16>
  %98 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> %64) #5
  %99 = add <4 x i32> %96, %63
  %100 = add <4 x i32> %98, %63
  %101 = add <4 x i32> %99, %25
  %102 = add <4 x i32> %100, %27
  %103 = lshr <4 x i32> %101, <i32 9, i32 9, i32 9, i32 9>
  %104 = lshr <4 x i32> %102, <i32 9, i32 9, i32 9, i32 9>
  %105 = bitcast <4 x i32> %103 to <8 x i16>
  %106 = bitcast <4 x i32> %104 to <8 x i16>
  %107 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %105, <8 x i16> %106) #5
  %108 = getelementptr inbounds i8, i8* %45, i64 8
  %109 = bitcast <16 x i8> %107 to <8 x i16>
  %110 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> undef) #5
  %111 = bitcast <16 x i8> %110 to <2 x i64>
  %112 = extractelement <2 x i64> %111, i32 0
  %113 = bitcast i8* %108 to i64*
  store i64 %112, i64* %113, align 1
  %114 = load i64, i64* %29, align 1
  %115 = insertelement <2 x i64> undef, i64 %114, i32 0
  %116 = bitcast <2 x i64> %115 to <16 x i8>
  %117 = shufflevector <16 x i8> %116, <16 x i8> <i8 66, i8 59, i8 52, i8 45, i8 39, i8 34, i8 29, i8 25, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %119 = zext <8 x i8> %118 to <8 x i16>
  %120 = shufflevector <16 x i8> %117, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> %64) #5
  %122 = bitcast <16 x i8> %120 to <8 x i16>
  %123 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %122, <8 x i16> %64) #5
  %124 = add <4 x i32> %121, %63
  %125 = add <4 x i32> %123, %63
  %126 = add <4 x i32> %124, %32
  %127 = add <4 x i32> %125, %34
  %128 = lshr <4 x i32> %126, <i32 9, i32 9, i32 9, i32 9>
  %129 = lshr <4 x i32> %127, <i32 9, i32 9, i32 9, i32 9>
  %130 = bitcast <4 x i32> %128 to <8 x i16>
  %131 = bitcast <4 x i32> %129 to <8 x i16>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> %131) #5
  %133 = getelementptr inbounds i8, i8* %45, i64 16
  %134 = bitcast <16 x i8> %132 to <8 x i16>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %134, <8 x i16> undef) #5
  %136 = bitcast <16 x i8> %135 to <2 x i64>
  %137 = extractelement <2 x i64> %136, i32 0
  %138 = bitcast i8* %133 to i64*
  store i64 %137, i64* %138, align 1
  %139 = load i64, i64* %36, align 1
  %140 = insertelement <2 x i64> undef, i64 %139, i32 0
  %141 = bitcast <2 x i64> %140 to <16 x i8>
  %142 = shufflevector <16 x i8> %141, <16 x i8> <i8 21, i8 17, i8 14, i8 12, i8 10, i8 9, i8 8, i8 8, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %143 = shufflevector <16 x i8> %142, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %144 = zext <8 x i8> %143 to <8 x i16>
  %145 = shufflevector <16 x i8> %142, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %146 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %144, <8 x i16> %64) #5
  %147 = bitcast <16 x i8> %145 to <8 x i16>
  %148 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> %64) #5
  %149 = add <4 x i32> %146, %63
  %150 = add <4 x i32> %148, %63
  %151 = add <4 x i32> %149, %39
  %152 = add <4 x i32> %150, %41
  %153 = lshr <4 x i32> %151, <i32 9, i32 9, i32 9, i32 9>
  %154 = lshr <4 x i32> %152, <i32 9, i32 9, i32 9, i32 9>
  %155 = bitcast <4 x i32> %153 to <8 x i16>
  %156 = bitcast <4 x i32> %154 to <8 x i16>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %156) #5
  %158 = getelementptr inbounds i8, i8* %45, i64 24
  %159 = bitcast <16 x i8> %157 to <8 x i16>
  %160 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> undef) #5
  %161 = bitcast <16 x i8> %160 to <2 x i64>
  %162 = extractelement <2 x i64> %161, i32 0
  %163 = bitcast i8* %158 to i64*
  store i64 %162, i64* %163, align 1
  %164 = getelementptr inbounds i8, i8* %45, i64 %1
  %165 = add nuw nsw i64 %44, 1
  %166 = icmp eq i64 %165, 64
  br i1 %166, label %42, label %43
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi64ELi16EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 63
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  br label %16

15:                                               ; preds = %38
  ret void

16:                                               ; preds = %38, %4
  %17 = phi i64 [ 0, %4 ], [ %40, %38 ]
  %18 = phi i8* [ %0, %4 ], [ %39, %38 ]
  %19 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 12), i64 %17
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %21, i32 0
  %23 = getelementptr inbounds i8, i8* %3, i64 %17
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = bitcast <4 x i32> %22 to <8 x i16>
  %28 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %27
  %29 = mul <8 x i16> %28, %14
  %30 = bitcast <4 x i32> %26 to <8 x i16>
  %31 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %32 = bitcast <8 x i16> %31 to <4 x i32>
  %33 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> zeroinitializer
  %34 = bitcast <8 x i16> %29 to <4 x i32>
  %35 = add <4 x i32> %34, <i32 256, i32 undef, i32 undef, i32 undef>
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = bitcast <4 x i32> %33 to <8 x i16>
  br label %42

38:                                               ; preds = %42
  %39 = getelementptr inbounds i8, i8* %18, i64 %1
  %40 = add nuw nsw i64 %17, 1
  %41 = icmp eq i64 %40, 16
  br i1 %41, label %15, label %16

42:                                               ; preds = %16, %42
  %43 = phi i64 [ 0, %16 ], [ %84, %42 ]
  %44 = getelementptr inbounds i8, i8* %2, i64 %43
  %45 = bitcast i8* %44 to i64*
  %46 = load i64, i64* %45, align 1
  %47 = insertelement <2 x i64> undef, i64 %46, i32 0
  %48 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %43
  %49 = bitcast i8* %48 to i64*
  %50 = load i64, i64* %49, align 4
  %51 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %50, i32 0
  %52 = bitcast <2 x i64> %47 to <16 x i8>
  %53 = bitcast <2 x i64> %51 to <16 x i8>
  %54 = shufflevector <16 x i8> %52, <16 x i8> %53, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %56 = zext <8 x i8> %55 to <8 x i16>
  %57 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %37) #5
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %37) #5
  %61 = shufflevector <16 x i8> %53, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %62 = zext <8 x i8> %61 to <8 x i16>
  %63 = sub nuw nsw <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %62
  %64 = mul <8 x i16> %63, %13
  %65 = shufflevector <8 x i16> %64, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %66 = zext <4 x i16> %65 to <4 x i32>
  %67 = shufflevector <8 x i16> %64, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %68 = add <4 x i32> %58, %36
  %69 = add <4 x i32> %60, %36
  %70 = add <4 x i32> %68, %66
  %71 = bitcast <8 x i16> %67 to <4 x i32>
  %72 = add <4 x i32> %69, %71
  %73 = lshr <4 x i32> %70, <i32 9, i32 9, i32 9, i32 9>
  %74 = lshr <4 x i32> %72, <i32 9, i32 9, i32 9, i32 9>
  %75 = bitcast <4 x i32> %73 to <8 x i16>
  %76 = bitcast <4 x i32> %74 to <8 x i16>
  %77 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %75, <8 x i16> %76) #5
  %78 = getelementptr inbounds i8, i8* %18, i64 %43
  %79 = bitcast <16 x i8> %77 to <8 x i16>
  %80 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> undef) #5
  %81 = bitcast <16 x i8> %80 to <2 x i64>
  %82 = extractelement <2 x i64> %81, i32 0
  %83 = bitcast i8* %78 to i64*
  store i64 %82, i64* %83, align 1
  %84 = add nuw nsw i64 %43, 8
  %85 = icmp ult i64 %84, 64
  br i1 %85, label %42, label %38
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi64ELi32EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 63
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  br label %16

15:                                               ; preds = %38
  ret void

16:                                               ; preds = %38, %4
  %17 = phi i64 [ 0, %4 ], [ %40, %38 ]
  %18 = phi i8* [ %0, %4 ], [ %39, %38 ]
  %19 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 28), i64 %17
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %21, i32 0
  %23 = getelementptr inbounds i8, i8* %3, i64 %17
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = bitcast <4 x i32> %22 to <8 x i16>
  %28 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %27
  %29 = mul <8 x i16> %28, %14
  %30 = bitcast <4 x i32> %26 to <8 x i16>
  %31 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %32 = bitcast <8 x i16> %31 to <4 x i32>
  %33 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> zeroinitializer
  %34 = bitcast <8 x i16> %29 to <4 x i32>
  %35 = add <4 x i32> %34, <i32 256, i32 undef, i32 undef, i32 undef>
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = bitcast <4 x i32> %33 to <8 x i16>
  br label %42

38:                                               ; preds = %42
  %39 = getelementptr inbounds i8, i8* %18, i64 %1
  %40 = add nuw nsw i64 %17, 1
  %41 = icmp eq i64 %40, 32
  br i1 %41, label %15, label %16

42:                                               ; preds = %16, %42
  %43 = phi i64 [ 0, %16 ], [ %84, %42 ]
  %44 = getelementptr inbounds i8, i8* %2, i64 %43
  %45 = bitcast i8* %44 to i64*
  %46 = load i64, i64* %45, align 1
  %47 = insertelement <2 x i64> undef, i64 %46, i32 0
  %48 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %43
  %49 = bitcast i8* %48 to i64*
  %50 = load i64, i64* %49, align 4
  %51 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %50, i32 0
  %52 = bitcast <2 x i64> %47 to <16 x i8>
  %53 = bitcast <2 x i64> %51 to <16 x i8>
  %54 = shufflevector <16 x i8> %52, <16 x i8> %53, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %56 = zext <8 x i8> %55 to <8 x i16>
  %57 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %37) #5
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %37) #5
  %61 = shufflevector <16 x i8> %53, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %62 = zext <8 x i8> %61 to <8 x i16>
  %63 = sub nuw nsw <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %62
  %64 = mul <8 x i16> %63, %13
  %65 = shufflevector <8 x i16> %64, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %66 = zext <4 x i16> %65 to <4 x i32>
  %67 = shufflevector <8 x i16> %64, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %68 = add <4 x i32> %58, %36
  %69 = add <4 x i32> %60, %36
  %70 = add <4 x i32> %68, %66
  %71 = bitcast <8 x i16> %67 to <4 x i32>
  %72 = add <4 x i32> %69, %71
  %73 = lshr <4 x i32> %70, <i32 9, i32 9, i32 9, i32 9>
  %74 = lshr <4 x i32> %72, <i32 9, i32 9, i32 9, i32 9>
  %75 = bitcast <4 x i32> %73 to <8 x i16>
  %76 = bitcast <4 x i32> %74 to <8 x i16>
  %77 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %75, <8 x i16> %76) #5
  %78 = getelementptr inbounds i8, i8* %18, i64 %43
  %79 = bitcast <16 x i8> %77 to <8 x i16>
  %80 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> undef) #5
  %81 = bitcast <16 x i8> %80 to <2 x i64>
  %82 = extractelement <2 x i64> %81, i32 0
  %83 = bitcast i8* %78 to i64*
  store i64 %82, i64* %83, align 1
  %84 = add nuw nsw i64 %43, 8
  %85 = icmp ult i64 %84, 64
  br i1 %85, label %42, label %38
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19SmoothWxHILi64ELi64EEEvPvlPKvS6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = getelementptr inbounds i8, i8* %3, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = getelementptr inbounds i8, i8* %2, i64 63
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = shufflevector <8 x i16> %12, <8 x i16> undef, <8 x i32> zeroinitializer
  %14 = bitcast <4 x i32> %8 to <8 x i16>
  br label %16

15:                                               ; preds = %38
  ret void

16:                                               ; preds = %38, %4
  %17 = phi i64 [ 0, %4 ], [ %40, %38 ]
  %18 = phi i8* [ %0, %4 ], [ %39, %38 ]
  %19 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %17
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %21, i32 0
  %23 = getelementptr inbounds i8, i8* %3, i64 %17
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = bitcast <4 x i32> %22 to <8 x i16>
  %28 = sub <8 x i16> <i16 256, i16 256, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef, i16 undef>, %27
  %29 = mul <8 x i16> %28, %14
  %30 = bitcast <4 x i32> %26 to <8 x i16>
  %31 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %32 = bitcast <8 x i16> %31 to <4 x i32>
  %33 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> zeroinitializer
  %34 = bitcast <8 x i16> %29 to <4 x i32>
  %35 = add <4 x i32> %34, <i32 256, i32 undef, i32 undef, i32 undef>
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = bitcast <4 x i32> %33 to <8 x i16>
  br label %42

38:                                               ; preds = %42
  %39 = getelementptr inbounds i8, i8* %18, i64 %1
  %40 = add nuw nsw i64 %17, 1
  %41 = icmp eq i64 %40, 64
  br i1 %41, label %15, label %16

42:                                               ; preds = %16, %42
  %43 = phi i64 [ 0, %16 ], [ %84, %42 ]
  %44 = getelementptr inbounds i8, i8* %2, i64 %43
  %45 = bitcast i8* %44 to i64*
  %46 = load i64, i64* %45, align 1
  %47 = insertelement <2 x i64> undef, i64 %46, i32 0
  %48 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %43
  %49 = bitcast i8* %48 to i64*
  %50 = load i64, i64* %49, align 4
  %51 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %50, i32 0
  %52 = bitcast <2 x i64> %47 to <16 x i8>
  %53 = bitcast <2 x i64> %51 to <16 x i8>
  %54 = shufflevector <16 x i8> %52, <16 x i8> %53, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %56 = zext <8 x i8> %55 to <8 x i16>
  %57 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %37) #5
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %37) #5
  %61 = shufflevector <16 x i8> %53, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %62 = zext <8 x i8> %61 to <8 x i16>
  %63 = sub nuw nsw <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %62
  %64 = mul <8 x i16> %63, %13
  %65 = shufflevector <8 x i16> %64, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %66 = zext <4 x i16> %65 to <4 x i32>
  %67 = shufflevector <8 x i16> %64, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %68 = add <4 x i32> %58, %36
  %69 = add <4 x i32> %60, %36
  %70 = add <4 x i32> %68, %66
  %71 = bitcast <8 x i16> %67 to <4 x i32>
  %72 = add <4 x i32> %69, %71
  %73 = lshr <4 x i32> %70, <i32 9, i32 9, i32 9, i32 9>
  %74 = lshr <4 x i32> %72, <i32 9, i32 9, i32 9, i32 9>
  %75 = bitcast <4 x i32> %73 to <8 x i16>
  %76 = bitcast <4 x i32> %74 to <8 x i16>
  %77 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %75, <8 x i16> %76) #5
  %78 = getelementptr inbounds i8, i8* %18, i64 %43
  %79 = bitcast <16 x i8> %77 to <8 x i16>
  %80 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> undef) #5
  %81 = bitcast <16 x i8> %80 to <2 x i64>
  %82 = extractelement <2 x i64> %81, i32 0
  %83 = bitcast i8* %78 to i64*
  store i64 %82, i64* %83, align 1
  %84 = add nuw nsw i64 %43, 8
  %85 = icmp ult i64 %84, 64
  br i1 %85, label %42, label %38
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_124SmoothVertical4x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %6, i32 0
  %8 = getelementptr inbounds i8, i8* %3, i64 3
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i16
  %11 = insertelement <8 x i16> undef, i16 %10, i32 0
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %13 = bitcast <4 x i32> %7 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = shufflevector <8 x i16> %15, <8 x i16> %12, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %17 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 255, i16 1, i16 255, i16 1, i16 255, i16 1, i16 255, i16 1>) #5
  %18 = add <4 x i32> %17, <i32 128, i32 128, i32 128, i32 128>
  %19 = ashr <4 x i32> %18, <i32 8, i32 8, i32 8, i32 8>
  %20 = bitcast <4 x i32> %19 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %22 = bitcast <16 x i8> %21 to <4 x i32>
  %23 = extractelement <4 x i32> %22, i32 0
  %24 = bitcast i8* %0 to i32*
  store i32 %23, i32* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %1
  %26 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 149, i16 107, i16 149, i16 107, i16 149, i16 107, i16 149, i16 107>) #5
  %27 = add <4 x i32> %26, <i32 128, i32 128, i32 128, i32 128>
  %28 = ashr <4 x i32> %27, <i32 8, i32 8, i32 8, i32 8>
  %29 = bitcast <4 x i32> %28 to <16 x i8>
  %30 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %31 = bitcast <16 x i8> %30 to <4 x i32>
  %32 = extractelement <4 x i32> %31, i32 0
  %33 = bitcast i8* %25 to i32*
  store i32 %32, i32* %33, align 1
  %34 = getelementptr inbounds i8, i8* %25, i64 %1
  %35 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 85, i16 171, i16 85, i16 171, i16 85, i16 171, i16 85, i16 171>) #5
  %36 = add <4 x i32> %35, <i32 128, i32 128, i32 128, i32 128>
  %37 = ashr <4 x i32> %36, <i32 8, i32 8, i32 8, i32 8>
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i8* %34 to i32*
  store i32 %41, i32* %42, align 1
  %43 = getelementptr inbounds i8, i8* %34, i64 %1
  %44 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 64, i16 192, i16 64, i16 192, i16 64, i16 192, i16 64, i16 192>) #5
  %45 = add <4 x i32> %44, <i32 128, i32 128, i32 128, i32 128>
  %46 = ashr <4 x i32> %45, <i32 8, i32 8, i32 8, i32 8>
  %47 = bitcast <4 x i32> %46 to <16 x i8>
  %48 = shufflevector <16 x i8> %47, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %49 = bitcast <16 x i8> %48 to <4 x i32>
  %50 = extractelement <4 x i32> %49, i32 0
  %51 = bitcast i8* %43 to i32*
  store i32 %50, i32* %51, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_124SmoothVertical4x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %6, i32 0
  %8 = getelementptr inbounds i8, i8* %3, i64 7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i16
  %11 = insertelement <8 x i16> undef, i16 %10, i32 0
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %13 = bitcast <4 x i32> %7 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = shufflevector <8 x i16> %15, <8 x i16> %12, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %17 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 255, i16 1, i16 255, i16 1, i16 255, i16 1, i16 255, i16 1>) #5
  %18 = add <4 x i32> %17, <i32 128, i32 128, i32 128, i32 128>
  %19 = ashr <4 x i32> %18, <i32 8, i32 8, i32 8, i32 8>
  %20 = bitcast <4 x i32> %19 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %22 = bitcast <16 x i8> %21 to <4 x i32>
  %23 = extractelement <4 x i32> %22, i32 0
  %24 = bitcast i8* %0 to i32*
  store i32 %23, i32* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %1
  %26 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 197, i16 59, i16 197, i16 59, i16 197, i16 59, i16 197, i16 59>) #5
  %27 = add <4 x i32> %26, <i32 128, i32 128, i32 128, i32 128>
  %28 = ashr <4 x i32> %27, <i32 8, i32 8, i32 8, i32 8>
  %29 = bitcast <4 x i32> %28 to <16 x i8>
  %30 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %31 = bitcast <16 x i8> %30 to <4 x i32>
  %32 = extractelement <4 x i32> %31, i32 0
  %33 = bitcast i8* %25 to i32*
  store i32 %32, i32* %33, align 1
  %34 = getelementptr inbounds i8, i8* %25, i64 %1
  %35 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 146, i16 110, i16 146, i16 110, i16 146, i16 110, i16 146, i16 110>) #5
  %36 = add <4 x i32> %35, <i32 128, i32 128, i32 128, i32 128>
  %37 = ashr <4 x i32> %36, <i32 8, i32 8, i32 8, i32 8>
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i8* %34 to i32*
  store i32 %41, i32* %42, align 1
  %43 = getelementptr inbounds i8, i8* %34, i64 %1
  %44 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 105, i16 151, i16 105, i16 151, i16 105, i16 151, i16 105, i16 151>) #5
  %45 = add <4 x i32> %44, <i32 128, i32 128, i32 128, i32 128>
  %46 = ashr <4 x i32> %45, <i32 8, i32 8, i32 8, i32 8>
  %47 = bitcast <4 x i32> %46 to <16 x i8>
  %48 = shufflevector <16 x i8> %47, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %49 = bitcast <16 x i8> %48 to <4 x i32>
  %50 = extractelement <4 x i32> %49, i32 0
  %51 = bitcast i8* %43 to i32*
  store i32 %50, i32* %51, align 1
  %52 = getelementptr inbounds i8, i8* %43, i64 %1
  %53 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 73, i16 183, i16 73, i16 183, i16 73, i16 183, i16 73, i16 183>) #5
  %54 = add <4 x i32> %53, <i32 128, i32 128, i32 128, i32 128>
  %55 = ashr <4 x i32> %54, <i32 8, i32 8, i32 8, i32 8>
  %56 = bitcast <4 x i32> %55 to <16 x i8>
  %57 = shufflevector <16 x i8> %56, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %58 = bitcast <16 x i8> %57 to <4 x i32>
  %59 = extractelement <4 x i32> %58, i32 0
  %60 = bitcast i8* %52 to i32*
  store i32 %59, i32* %60, align 1
  %61 = getelementptr inbounds i8, i8* %52, i64 %1
  %62 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 50, i16 206, i16 50, i16 206, i16 50, i16 206, i16 50, i16 206>) #5
  %63 = add <4 x i32> %62, <i32 128, i32 128, i32 128, i32 128>
  %64 = ashr <4 x i32> %63, <i32 8, i32 8, i32 8, i32 8>
  %65 = bitcast <4 x i32> %64 to <16 x i8>
  %66 = shufflevector <16 x i8> %65, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %67 = bitcast <16 x i8> %66 to <4 x i32>
  %68 = extractelement <4 x i32> %67, i32 0
  %69 = bitcast i8* %61 to i32*
  store i32 %68, i32* %69, align 1
  %70 = getelementptr inbounds i8, i8* %61, i64 %1
  %71 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 37, i16 219, i16 37, i16 219, i16 37, i16 219, i16 37, i16 219>) #5
  %72 = add <4 x i32> %71, <i32 128, i32 128, i32 128, i32 128>
  %73 = ashr <4 x i32> %72, <i32 8, i32 8, i32 8, i32 8>
  %74 = bitcast <4 x i32> %73 to <16 x i8>
  %75 = shufflevector <16 x i8> %74, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %76 = bitcast <16 x i8> %75 to <4 x i32>
  %77 = extractelement <4 x i32> %76, i32 0
  %78 = bitcast i8* %70 to i32*
  store i32 %77, i32* %78, align 1
  %79 = getelementptr inbounds i8, i8* %70, i64 %1
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 32, i16 224, i16 32, i16 224, i16 32, i16 224, i16 32, i16 224>) #5
  %81 = add <4 x i32> %80, <i32 128, i32 128, i32 128, i32 128>
  %82 = ashr <4 x i32> %81, <i32 8, i32 8, i32 8, i32 8>
  %83 = bitcast <4 x i32> %82 to <16 x i8>
  %84 = shufflevector <16 x i8> %83, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %85 = bitcast <16 x i8> %84 to <4 x i32>
  %86 = extractelement <4 x i32> %85, i32 0
  %87 = bitcast i8* %79 to i32*
  store i32 %86, i32* %87, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical4x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %6, i32 0
  %8 = getelementptr inbounds i8, i8* %3, i64 15
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i16
  %11 = insertelement <8 x i16> undef, i16 %10, i32 0
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %13 = bitcast <4 x i32> %7 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = shufflevector <8 x i16> %15, <8 x i16> %12, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %17 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 255, i16 1, i16 255, i16 1, i16 255, i16 1, i16 255, i16 1>) #5
  %18 = add <4 x i32> %17, <i32 128, i32 128, i32 128, i32 128>
  %19 = ashr <4 x i32> %18, <i32 8, i32 8, i32 8, i32 8>
  %20 = bitcast <4 x i32> %19 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %22 = bitcast <16 x i8> %21 to <4 x i32>
  %23 = extractelement <4 x i32> %22, i32 0
  %24 = bitcast i8* %0 to i32*
  store i32 %23, i32* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %1
  %26 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 225, i16 31, i16 225, i16 31, i16 225, i16 31, i16 225, i16 31>) #5
  %27 = add <4 x i32> %26, <i32 128, i32 128, i32 128, i32 128>
  %28 = ashr <4 x i32> %27, <i32 8, i32 8, i32 8, i32 8>
  %29 = bitcast <4 x i32> %28 to <16 x i8>
  %30 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %31 = bitcast <16 x i8> %30 to <4 x i32>
  %32 = extractelement <4 x i32> %31, i32 0
  %33 = bitcast i8* %25 to i32*
  store i32 %32, i32* %33, align 1
  %34 = getelementptr inbounds i8, i8* %25, i64 %1
  %35 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 196, i16 60, i16 196, i16 60, i16 196, i16 60, i16 196, i16 60>) #5
  %36 = add <4 x i32> %35, <i32 128, i32 128, i32 128, i32 128>
  %37 = ashr <4 x i32> %36, <i32 8, i32 8, i32 8, i32 8>
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i8* %34 to i32*
  store i32 %41, i32* %42, align 1
  %43 = getelementptr inbounds i8, i8* %34, i64 %1
  %44 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 170, i16 86, i16 170, i16 86, i16 170, i16 86, i16 170, i16 86>) #5
  %45 = add <4 x i32> %44, <i32 128, i32 128, i32 128, i32 128>
  %46 = ashr <4 x i32> %45, <i32 8, i32 8, i32 8, i32 8>
  %47 = bitcast <4 x i32> %46 to <16 x i8>
  %48 = shufflevector <16 x i8> %47, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %49 = bitcast <16 x i8> %48 to <4 x i32>
  %50 = extractelement <4 x i32> %49, i32 0
  %51 = bitcast i8* %43 to i32*
  store i32 %50, i32* %51, align 1
  %52 = getelementptr inbounds i8, i8* %43, i64 %1
  %53 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 145, i16 111, i16 145, i16 111, i16 145, i16 111, i16 145, i16 111>) #5
  %54 = add <4 x i32> %53, <i32 128, i32 128, i32 128, i32 128>
  %55 = ashr <4 x i32> %54, <i32 8, i32 8, i32 8, i32 8>
  %56 = bitcast <4 x i32> %55 to <16 x i8>
  %57 = shufflevector <16 x i8> %56, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %58 = bitcast <16 x i8> %57 to <4 x i32>
  %59 = extractelement <4 x i32> %58, i32 0
  %60 = bitcast i8* %52 to i32*
  store i32 %59, i32* %60, align 1
  %61 = getelementptr inbounds i8, i8* %52, i64 %1
  %62 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 123, i16 133, i16 123, i16 133, i16 123, i16 133, i16 123, i16 133>) #5
  %63 = add <4 x i32> %62, <i32 128, i32 128, i32 128, i32 128>
  %64 = ashr <4 x i32> %63, <i32 8, i32 8, i32 8, i32 8>
  %65 = bitcast <4 x i32> %64 to <16 x i8>
  %66 = shufflevector <16 x i8> %65, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %67 = bitcast <16 x i8> %66 to <4 x i32>
  %68 = extractelement <4 x i32> %67, i32 0
  %69 = bitcast i8* %61 to i32*
  store i32 %68, i32* %69, align 1
  %70 = getelementptr inbounds i8, i8* %61, i64 %1
  %71 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 102, i16 154, i16 102, i16 154, i16 102, i16 154, i16 102, i16 154>) #5
  %72 = add <4 x i32> %71, <i32 128, i32 128, i32 128, i32 128>
  %73 = ashr <4 x i32> %72, <i32 8, i32 8, i32 8, i32 8>
  %74 = bitcast <4 x i32> %73 to <16 x i8>
  %75 = shufflevector <16 x i8> %74, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %76 = bitcast <16 x i8> %75 to <4 x i32>
  %77 = extractelement <4 x i32> %76, i32 0
  %78 = bitcast i8* %70 to i32*
  store i32 %77, i32* %78, align 1
  %79 = getelementptr inbounds i8, i8* %70, i64 %1
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 84, i16 172, i16 84, i16 172, i16 84, i16 172, i16 84, i16 172>) #5
  %81 = add <4 x i32> %80, <i32 128, i32 128, i32 128, i32 128>
  %82 = ashr <4 x i32> %81, <i32 8, i32 8, i32 8, i32 8>
  %83 = bitcast <4 x i32> %82 to <16 x i8>
  %84 = shufflevector <16 x i8> %83, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %85 = bitcast <16 x i8> %84 to <4 x i32>
  %86 = extractelement <4 x i32> %85, i32 0
  %87 = bitcast i8* %79 to i32*
  store i32 %86, i32* %87, align 1
  %88 = shl i64 %1, 3
  %89 = getelementptr inbounds i8, i8* %0, i64 %88
  %90 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 68, i16 188, i16 68, i16 188, i16 68, i16 188, i16 68, i16 188>) #5
  %91 = add <4 x i32> %90, <i32 128, i32 128, i32 128, i32 128>
  %92 = ashr <4 x i32> %91, <i32 8, i32 8, i32 8, i32 8>
  %93 = bitcast <4 x i32> %92 to <16 x i8>
  %94 = shufflevector <16 x i8> %93, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %95 = bitcast <16 x i8> %94 to <4 x i32>
  %96 = extractelement <4 x i32> %95, i32 0
  %97 = bitcast i8* %89 to i32*
  store i32 %96, i32* %97, align 1
  %98 = getelementptr inbounds i8, i8* %89, i64 %1
  %99 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 54, i16 202, i16 54, i16 202, i16 54, i16 202, i16 54, i16 202>) #5
  %100 = add <4 x i32> %99, <i32 128, i32 128, i32 128, i32 128>
  %101 = ashr <4 x i32> %100, <i32 8, i32 8, i32 8, i32 8>
  %102 = bitcast <4 x i32> %101 to <16 x i8>
  %103 = shufflevector <16 x i8> %102, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %104 = bitcast <16 x i8> %103 to <4 x i32>
  %105 = extractelement <4 x i32> %104, i32 0
  %106 = bitcast i8* %98 to i32*
  store i32 %105, i32* %106, align 1
  %107 = getelementptr inbounds i8, i8* %98, i64 %1
  %108 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 43, i16 213, i16 43, i16 213, i16 43, i16 213, i16 43, i16 213>) #5
  %109 = add <4 x i32> %108, <i32 128, i32 128, i32 128, i32 128>
  %110 = ashr <4 x i32> %109, <i32 8, i32 8, i32 8, i32 8>
  %111 = bitcast <4 x i32> %110 to <16 x i8>
  %112 = shufflevector <16 x i8> %111, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %113 = bitcast <16 x i8> %112 to <4 x i32>
  %114 = extractelement <4 x i32> %113, i32 0
  %115 = bitcast i8* %107 to i32*
  store i32 %114, i32* %115, align 1
  %116 = getelementptr inbounds i8, i8* %107, i64 %1
  %117 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 33, i16 223, i16 33, i16 223, i16 33, i16 223, i16 33, i16 223>) #5
  %118 = add <4 x i32> %117, <i32 128, i32 128, i32 128, i32 128>
  %119 = ashr <4 x i32> %118, <i32 8, i32 8, i32 8, i32 8>
  %120 = bitcast <4 x i32> %119 to <16 x i8>
  %121 = shufflevector <16 x i8> %120, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %122 = bitcast <16 x i8> %121 to <4 x i32>
  %123 = extractelement <4 x i32> %122, i32 0
  %124 = bitcast i8* %116 to i32*
  store i32 %123, i32* %124, align 1
  %125 = getelementptr inbounds i8, i8* %116, i64 %1
  %126 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 26, i16 230, i16 26, i16 230, i16 26, i16 230, i16 26, i16 230>) #5
  %127 = add <4 x i32> %126, <i32 128, i32 128, i32 128, i32 128>
  %128 = ashr <4 x i32> %127, <i32 8, i32 8, i32 8, i32 8>
  %129 = bitcast <4 x i32> %128 to <16 x i8>
  %130 = shufflevector <16 x i8> %129, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %131 = bitcast <16 x i8> %130 to <4 x i32>
  %132 = extractelement <4 x i32> %131, i32 0
  %133 = bitcast i8* %125 to i32*
  store i32 %132, i32* %133, align 1
  %134 = getelementptr inbounds i8, i8* %125, i64 %1
  %135 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 20, i16 236, i16 20, i16 236, i16 20, i16 236, i16 20, i16 236>) #5
  %136 = add <4 x i32> %135, <i32 128, i32 128, i32 128, i32 128>
  %137 = ashr <4 x i32> %136, <i32 8, i32 8, i32 8, i32 8>
  %138 = bitcast <4 x i32> %137 to <16 x i8>
  %139 = shufflevector <16 x i8> %138, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %140 = bitcast <16 x i8> %139 to <4 x i32>
  %141 = extractelement <4 x i32> %140, i32 0
  %142 = bitcast i8* %134 to i32*
  store i32 %141, i32* %142, align 1
  %143 = getelementptr inbounds i8, i8* %134, i64 %1
  %144 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 17, i16 239, i16 17, i16 239, i16 17, i16 239, i16 17, i16 239>) #5
  %145 = add <4 x i32> %144, <i32 128, i32 128, i32 128, i32 128>
  %146 = ashr <4 x i32> %145, <i32 8, i32 8, i32 8, i32 8>
  %147 = bitcast <4 x i32> %146 to <16 x i8>
  %148 = shufflevector <16 x i8> %147, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %149 = bitcast <16 x i8> %148 to <4 x i32>
  %150 = extractelement <4 x i32> %149, i32 0
  %151 = bitcast i8* %143 to i32*
  store i32 %150, i32* %151, align 1
  %152 = getelementptr inbounds i8, i8* %143, i64 %1
  %153 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 16, i16 240, i16 16, i16 240, i16 16, i16 240, i16 16, i16 240>) #5
  %154 = add <4 x i32> %153, <i32 128, i32 128, i32 128, i32 128>
  %155 = ashr <4 x i32> %154, <i32 8, i32 8, i32 8, i32 8>
  %156 = bitcast <4 x i32> %155 to <16 x i8>
  %157 = shufflevector <16 x i8> %156, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %158 = bitcast <16 x i8> %157 to <4 x i32>
  %159 = extractelement <4 x i32> %158, i32 0
  %160 = bitcast i8* %152 to i32*
  store i32 %159, i32* %160, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_124SmoothVertical8x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 3
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 107, i16 171, i16 192, i16 256, i16 256, i16 256, i16 256>
  %11 = bitcast i8* %2 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %10 to <16 x i8>
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %19 = mul nuw <8 x i16> %16, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %20 = bitcast <16 x i8> %18 to <8 x i16>
  %21 = add <8 x i16> %19, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %22 = add <8 x i16> %21, %20
  %23 = lshr <8 x i16> %22, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %24 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> undef) #5
  %25 = bitcast <16 x i8> %24 to <2 x i64>
  %26 = extractelement <2 x i64> %25, i32 0
  %27 = bitcast i8* %0 to i64*
  store i64 %26, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %30 = mul nuw <8 x i16> %16, <i16 149, i16 149, i16 149, i16 149, i16 149, i16 149, i16 149, i16 149>
  %31 = bitcast <16 x i8> %29 to <8 x i16>
  %32 = add <8 x i16> %30, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %33 = add <8 x i16> %32, %31
  %34 = lshr <8 x i16> %33, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %35 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> undef) #5
  %36 = bitcast <16 x i8> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %36, i32 0
  %38 = bitcast i8* %28 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %28, i64 %1
  %40 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %41 = mul nuw nsw <8 x i16> %16, <i16 85, i16 85, i16 85, i16 85, i16 85, i16 85, i16 85, i16 85>
  %42 = bitcast <16 x i8> %40 to <8 x i16>
  %43 = add nuw <8 x i16> %41, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %44 = add <8 x i16> %43, %42
  %45 = lshr <8 x i16> %44, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %46 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %45, <8 x i16> undef) #5
  %47 = bitcast <16 x i8> %46 to <2 x i64>
  %48 = extractelement <2 x i64> %47, i32 0
  %49 = bitcast i8* %39 to i64*
  store i64 %48, i64* %49, align 1
  %50 = getelementptr inbounds i8, i8* %39, i64 %1
  %51 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %52 = shl nuw nsw <8 x i16> %16, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %53 = bitcast <16 x i8> %51 to <8 x i16>
  %54 = add nuw nsw <8 x i16> %52, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %55 = add <8 x i16> %54, %53
  %56 = lshr <8 x i16> %55, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %57 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %56, <8 x i16> undef) #5
  %58 = bitcast <16 x i8> %57 to <2 x i64>
  %59 = extractelement <2 x i64> %58, i32 0
  %60 = bitcast i8* %50 to i64*
  store i64 %59, i64* %60, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_124SmoothVertical8x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 59, i16 110, i16 151, i16 183, i16 206, i16 219, i16 224>
  %11 = bitcast i8* %2 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %10 to <16 x i8>
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %19 = mul nuw <8 x i16> %16, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %20 = bitcast <16 x i8> %18 to <8 x i16>
  %21 = add <8 x i16> %20, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %22 = add <8 x i16> %21, %19
  %23 = lshr <8 x i16> %22, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %24 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> undef) #5
  %25 = bitcast <16 x i8> %24 to <2 x i64>
  %26 = extractelement <2 x i64> %25, i32 0
  %27 = bitcast i8* %0 to i64*
  store i64 %26, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %30 = mul nuw <8 x i16> %16, <i16 197, i16 197, i16 197, i16 197, i16 197, i16 197, i16 197, i16 197>
  %31 = bitcast <16 x i8> %29 to <8 x i16>
  %32 = add <8 x i16> %31, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %33 = add <8 x i16> %32, %30
  %34 = lshr <8 x i16> %33, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %35 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> undef) #5
  %36 = bitcast <16 x i8> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %36, i32 0
  %38 = bitcast i8* %28 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %28, i64 %1
  %40 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %41 = mul nuw <8 x i16> %16, <i16 146, i16 146, i16 146, i16 146, i16 146, i16 146, i16 146, i16 146>
  %42 = bitcast <16 x i8> %40 to <8 x i16>
  %43 = add <8 x i16> %42, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %44 = add <8 x i16> %43, %41
  %45 = lshr <8 x i16> %44, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %46 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %45, <8 x i16> undef) #5
  %47 = bitcast <16 x i8> %46 to <2 x i64>
  %48 = extractelement <2 x i64> %47, i32 0
  %49 = bitcast i8* %39 to i64*
  store i64 %48, i64* %49, align 1
  %50 = getelementptr inbounds i8, i8* %39, i64 %1
  %51 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %52 = mul nuw nsw <8 x i16> %16, <i16 105, i16 105, i16 105, i16 105, i16 105, i16 105, i16 105, i16 105>
  %53 = bitcast <16 x i8> %51 to <8 x i16>
  %54 = add <8 x i16> %53, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %55 = add <8 x i16> %54, %52
  %56 = lshr <8 x i16> %55, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %57 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %56, <8 x i16> undef) #5
  %58 = bitcast <16 x i8> %57 to <2 x i64>
  %59 = extractelement <2 x i64> %58, i32 0
  %60 = bitcast i8* %50 to i64*
  store i64 %59, i64* %60, align 1
  %61 = getelementptr inbounds i8, i8* %50, i64 %1
  %62 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %63 = mul nuw nsw <8 x i16> %16, <i16 73, i16 73, i16 73, i16 73, i16 73, i16 73, i16 73, i16 73>
  %64 = bitcast <16 x i8> %62 to <8 x i16>
  %65 = add <8 x i16> %64, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %66 = add <8 x i16> %65, %63
  %67 = lshr <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> undef) #5
  %69 = bitcast <16 x i8> %68 to <2 x i64>
  %70 = extractelement <2 x i64> %69, i32 0
  %71 = bitcast i8* %61 to i64*
  store i64 %70, i64* %71, align 1
  %72 = getelementptr inbounds i8, i8* %61, i64 %1
  %73 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %74 = mul nuw nsw <8 x i16> %16, <i16 50, i16 50, i16 50, i16 50, i16 50, i16 50, i16 50, i16 50>
  %75 = bitcast <16 x i8> %73 to <8 x i16>
  %76 = add <8 x i16> %75, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %77 = add <8 x i16> %76, %74
  %78 = lshr <8 x i16> %77, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %79 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %78, <8 x i16> undef) #5
  %80 = bitcast <16 x i8> %79 to <2 x i64>
  %81 = extractelement <2 x i64> %80, i32 0
  %82 = bitcast i8* %72 to i64*
  store i64 %81, i64* %82, align 1
  %83 = getelementptr inbounds i8, i8* %72, i64 %1
  %84 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %85 = mul nuw nsw <8 x i16> %16, <i16 37, i16 37, i16 37, i16 37, i16 37, i16 37, i16 37, i16 37>
  %86 = bitcast <16 x i8> %84 to <8 x i16>
  %87 = add <8 x i16> %86, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %88 = add <8 x i16> %87, %85
  %89 = lshr <8 x i16> %88, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %90 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> undef) #5
  %91 = bitcast <16 x i8> %90 to <2 x i64>
  %92 = extractelement <2 x i64> %91, i32 0
  %93 = bitcast i8* %83 to i64*
  store i64 %92, i64* %93, align 1
  %94 = getelementptr inbounds i8, i8* %83, i64 %1
  %95 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %96 = shl nuw nsw <8 x i16> %16, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %97 = bitcast <16 x i8> %95 to <8 x i16>
  %98 = add <8 x i16> %97, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %99 = add <8 x i16> %98, %96
  %100 = lshr <8 x i16> %99, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> undef) #5
  %102 = bitcast <16 x i8> %101 to <2 x i64>
  %103 = extractelement <2 x i64> %102, i32 0
  %104 = bitcast i8* %94 to i64*
  store i64 %103, i64* %104, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical8x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %11 = bitcast i8* %2 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %10 to <16 x i8>
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %19 = mul nuw <8 x i16> %16, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %20 = bitcast <16 x i8> %18 to <8 x i16>
  %21 = add <8 x i16> %20, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %22 = add <8 x i16> %21, %19
  %23 = lshr <8 x i16> %22, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %24 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> undef) #5
  %25 = bitcast <16 x i8> %24 to <2 x i64>
  %26 = extractelement <2 x i64> %25, i32 0
  %27 = bitcast i8* %0 to i64*
  store i64 %26, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %30 = mul nuw <8 x i16> %16, <i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225>
  %31 = bitcast <16 x i8> %29 to <8 x i16>
  %32 = add <8 x i16> %31, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %33 = add <8 x i16> %32, %30
  %34 = lshr <8 x i16> %33, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %35 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> undef) #5
  %36 = bitcast <16 x i8> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %36, i32 0
  %38 = bitcast i8* %28 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %28, i64 %1
  %40 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %41 = mul nuw <8 x i16> %16, <i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196>
  %42 = bitcast <16 x i8> %40 to <8 x i16>
  %43 = add <8 x i16> %42, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %44 = add <8 x i16> %43, %41
  %45 = lshr <8 x i16> %44, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %46 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %45, <8 x i16> undef) #5
  %47 = bitcast <16 x i8> %46 to <2 x i64>
  %48 = extractelement <2 x i64> %47, i32 0
  %49 = bitcast i8* %39 to i64*
  store i64 %48, i64* %49, align 1
  %50 = getelementptr inbounds i8, i8* %39, i64 %1
  %51 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %52 = mul nuw <8 x i16> %16, <i16 170, i16 170, i16 170, i16 170, i16 170, i16 170, i16 170, i16 170>
  %53 = bitcast <16 x i8> %51 to <8 x i16>
  %54 = add <8 x i16> %53, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %55 = add <8 x i16> %54, %52
  %56 = lshr <8 x i16> %55, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %57 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %56, <8 x i16> undef) #5
  %58 = bitcast <16 x i8> %57 to <2 x i64>
  %59 = extractelement <2 x i64> %58, i32 0
  %60 = bitcast i8* %50 to i64*
  store i64 %59, i64* %60, align 1
  %61 = getelementptr inbounds i8, i8* %50, i64 %1
  %62 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %63 = mul nuw <8 x i16> %16, <i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145>
  %64 = bitcast <16 x i8> %62 to <8 x i16>
  %65 = add <8 x i16> %64, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %66 = add <8 x i16> %65, %63
  %67 = lshr <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> undef) #5
  %69 = bitcast <16 x i8> %68 to <2 x i64>
  %70 = extractelement <2 x i64> %69, i32 0
  %71 = bitcast i8* %61 to i64*
  store i64 %70, i64* %71, align 1
  %72 = getelementptr inbounds i8, i8* %61, i64 %1
  %73 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %74 = mul nuw nsw <8 x i16> %16, <i16 123, i16 123, i16 123, i16 123, i16 123, i16 123, i16 123, i16 123>
  %75 = bitcast <16 x i8> %73 to <8 x i16>
  %76 = add <8 x i16> %75, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %77 = add <8 x i16> %76, %74
  %78 = lshr <8 x i16> %77, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %79 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %78, <8 x i16> undef) #5
  %80 = bitcast <16 x i8> %79 to <2 x i64>
  %81 = extractelement <2 x i64> %80, i32 0
  %82 = bitcast i8* %72 to i64*
  store i64 %81, i64* %82, align 1
  %83 = getelementptr inbounds i8, i8* %72, i64 %1
  %84 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %85 = mul nuw nsw <8 x i16> %16, <i16 102, i16 102, i16 102, i16 102, i16 102, i16 102, i16 102, i16 102>
  %86 = bitcast <16 x i8> %84 to <8 x i16>
  %87 = add <8 x i16> %86, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %88 = add <8 x i16> %87, %85
  %89 = lshr <8 x i16> %88, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %90 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> undef) #5
  %91 = bitcast <16 x i8> %90 to <2 x i64>
  %92 = extractelement <2 x i64> %91, i32 0
  %93 = bitcast i8* %83 to i64*
  store i64 %92, i64* %93, align 1
  %94 = getelementptr inbounds i8, i8* %83, i64 %1
  %95 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %96 = mul nuw nsw <8 x i16> %16, <i16 84, i16 84, i16 84, i16 84, i16 84, i16 84, i16 84, i16 84>
  %97 = bitcast <16 x i8> %95 to <8 x i16>
  %98 = add <8 x i16> %97, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %99 = add <8 x i16> %98, %96
  %100 = lshr <8 x i16> %99, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> undef) #5
  %102 = bitcast <16 x i8> %101 to <2 x i64>
  %103 = extractelement <2 x i64> %102, i32 0
  %104 = bitcast i8* %94 to i64*
  store i64 %103, i64* %104, align 1
  %105 = getelementptr inbounds i8, i8* %94, i64 %1
  %106 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %107 = bitcast <8 x i16> %106 to <16 x i8>
  %108 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %109 = mul nuw nsw <8 x i16> %16, <i16 68, i16 68, i16 68, i16 68, i16 68, i16 68, i16 68, i16 68>
  %110 = bitcast <16 x i8> %108 to <8 x i16>
  %111 = add <8 x i16> %110, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %112 = add <8 x i16> %111, %109
  %113 = lshr <8 x i16> %112, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %114 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %113, <8 x i16> undef) #5
  %115 = bitcast <16 x i8> %114 to <2 x i64>
  %116 = extractelement <2 x i64> %115, i32 0
  %117 = bitcast i8* %105 to i64*
  store i64 %116, i64* %117, align 1
  %118 = getelementptr inbounds i8, i8* %105, i64 %1
  %119 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %120 = mul nuw nsw <8 x i16> %16, <i16 54, i16 54, i16 54, i16 54, i16 54, i16 54, i16 54, i16 54>
  %121 = bitcast <16 x i8> %119 to <8 x i16>
  %122 = add <8 x i16> %121, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %123 = add <8 x i16> %122, %120
  %124 = lshr <8 x i16> %123, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %125 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %124, <8 x i16> undef) #5
  %126 = bitcast <16 x i8> %125 to <2 x i64>
  %127 = extractelement <2 x i64> %126, i32 0
  %128 = bitcast i8* %118 to i64*
  store i64 %127, i64* %128, align 1
  %129 = getelementptr inbounds i8, i8* %118, i64 %1
  %130 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %131 = mul nuw nsw <8 x i16> %16, <i16 43, i16 43, i16 43, i16 43, i16 43, i16 43, i16 43, i16 43>
  %132 = bitcast <16 x i8> %130 to <8 x i16>
  %133 = add <8 x i16> %132, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %134 = add <8 x i16> %133, %131
  %135 = lshr <8 x i16> %134, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %135, <8 x i16> undef) #5
  %137 = bitcast <16 x i8> %136 to <2 x i64>
  %138 = extractelement <2 x i64> %137, i32 0
  %139 = bitcast i8* %129 to i64*
  store i64 %138, i64* %139, align 1
  %140 = getelementptr inbounds i8, i8* %129, i64 %1
  %141 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %142 = mul nuw nsw <8 x i16> %16, <i16 33, i16 33, i16 33, i16 33, i16 33, i16 33, i16 33, i16 33>
  %143 = bitcast <16 x i8> %141 to <8 x i16>
  %144 = add <8 x i16> %143, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %145 = add <8 x i16> %144, %142
  %146 = lshr <8 x i16> %145, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %147 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %146, <8 x i16> undef) #5
  %148 = bitcast <16 x i8> %147 to <2 x i64>
  %149 = extractelement <2 x i64> %148, i32 0
  %150 = bitcast i8* %140 to i64*
  store i64 %149, i64* %150, align 1
  %151 = getelementptr inbounds i8, i8* %140, i64 %1
  %152 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %153 = mul nuw nsw <8 x i16> %16, <i16 26, i16 26, i16 26, i16 26, i16 26, i16 26, i16 26, i16 26>
  %154 = bitcast <16 x i8> %152 to <8 x i16>
  %155 = add <8 x i16> %154, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %156 = add <8 x i16> %155, %153
  %157 = lshr <8 x i16> %156, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %158 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %157, <8 x i16> undef) #5
  %159 = bitcast <16 x i8> %158 to <2 x i64>
  %160 = extractelement <2 x i64> %159, i32 0
  %161 = bitcast i8* %151 to i64*
  store i64 %160, i64* %161, align 1
  %162 = getelementptr inbounds i8, i8* %151, i64 %1
  %163 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %164 = mul nuw nsw <8 x i16> %16, <i16 20, i16 20, i16 20, i16 20, i16 20, i16 20, i16 20, i16 20>
  %165 = bitcast <16 x i8> %163 to <8 x i16>
  %166 = add <8 x i16> %165, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %167 = add <8 x i16> %166, %164
  %168 = lshr <8 x i16> %167, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %169 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %168, <8 x i16> undef) #5
  %170 = bitcast <16 x i8> %169 to <2 x i64>
  %171 = extractelement <2 x i64> %170, i32 0
  %172 = bitcast i8* %162 to i64*
  store i64 %171, i64* %172, align 1
  %173 = getelementptr inbounds i8, i8* %162, i64 %1
  %174 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %175 = mul nuw nsw <8 x i16> %16, <i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17>
  %176 = bitcast <16 x i8> %174 to <8 x i16>
  %177 = add <8 x i16> %176, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %178 = add <8 x i16> %177, %175
  %179 = lshr <8 x i16> %178, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %180 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %179, <8 x i16> undef) #5
  %181 = bitcast <16 x i8> %180 to <2 x i64>
  %182 = extractelement <2 x i64> %181, i32 0
  %183 = bitcast i8* %173 to i64*
  store i64 %182, i64* %183, align 1
  %184 = getelementptr inbounds i8, i8* %173, i64 %1
  %185 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %186 = shl nuw nsw <8 x i16> %16, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %187 = bitcast <16 x i8> %185 to <8 x i16>
  %188 = add <8 x i16> %187, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %189 = add <8 x i16> %188, %186
  %190 = lshr <8 x i16> %189, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %190, <8 x i16> undef) #5
  %192 = bitcast <16 x i8> %191 to <2 x i64>
  %193 = extractelement <2 x i64> %192, i32 0
  %194 = bitcast i8* %184 to i64*
  store i64 %193, i64* %194, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical8x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %11 = mul <8 x i16> %9, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %12 = bitcast i8* %2 to i64*
  %13 = load i64, i64* %12, align 1
  %14 = insertelement <2 x i64> undef, i64 %13, i32 0
  %15 = bitcast <2 x i64> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %17 = zext <8 x i8> %16 to <8 x i16>
  %18 = bitcast <8 x i16> %10 to <16 x i8>
  %19 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %20 = mul nuw <8 x i16> %17, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %21 = bitcast <16 x i8> %19 to <8 x i16>
  %22 = add <8 x i16> %21, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %23 = add <8 x i16> %22, %20
  %24 = lshr <8 x i16> %23, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %25 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %24, <8 x i16> undef) #5
  %26 = bitcast <16 x i8> %25 to <2 x i64>
  %27 = extractelement <2 x i64> %26, i32 0
  %28 = bitcast i8* %0 to i64*
  store i64 %27, i64* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 %1
  %30 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %31 = mul nuw <8 x i16> %17, <i16 240, i16 240, i16 240, i16 240, i16 240, i16 240, i16 240, i16 240>
  %32 = bitcast <16 x i8> %30 to <8 x i16>
  %33 = add <8 x i16> %32, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %34 = add <8 x i16> %33, %31
  %35 = lshr <8 x i16> %34, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %35, <8 x i16> undef) #5
  %37 = bitcast <16 x i8> %36 to <2 x i64>
  %38 = extractelement <2 x i64> %37, i32 0
  %39 = bitcast i8* %29 to i64*
  store i64 %38, i64* %39, align 1
  %40 = getelementptr inbounds i8, i8* %29, i64 %1
  %41 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %42 = mul nuw <8 x i16> %17, <i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225>
  %43 = bitcast <16 x i8> %41 to <8 x i16>
  %44 = add <8 x i16> %43, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %45 = add <8 x i16> %44, %42
  %46 = lshr <8 x i16> %45, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %47 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %46, <8 x i16> undef) #5
  %48 = bitcast <16 x i8> %47 to <2 x i64>
  %49 = extractelement <2 x i64> %48, i32 0
  %50 = bitcast i8* %40 to i64*
  store i64 %49, i64* %50, align 1
  %51 = getelementptr inbounds i8, i8* %40, i64 %1
  %52 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %53 = mul nuw <8 x i16> %17, <i16 210, i16 210, i16 210, i16 210, i16 210, i16 210, i16 210, i16 210>
  %54 = bitcast <16 x i8> %52 to <8 x i16>
  %55 = add <8 x i16> %54, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %56 = add <8 x i16> %55, %53
  %57 = lshr <8 x i16> %56, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %58 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %57, <8 x i16> undef) #5
  %59 = bitcast <16 x i8> %58 to <2 x i64>
  %60 = extractelement <2 x i64> %59, i32 0
  %61 = bitcast i8* %51 to i64*
  store i64 %60, i64* %61, align 1
  %62 = getelementptr inbounds i8, i8* %51, i64 %1
  %63 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %64 = mul nuw <8 x i16> %17, <i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196>
  %65 = bitcast <16 x i8> %63 to <8 x i16>
  %66 = add <8 x i16> %65, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %67 = add <8 x i16> %66, %64
  %68 = lshr <8 x i16> %67, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> undef) #5
  %70 = bitcast <16 x i8> %69 to <2 x i64>
  %71 = extractelement <2 x i64> %70, i32 0
  %72 = bitcast i8* %62 to i64*
  store i64 %71, i64* %72, align 1
  %73 = getelementptr inbounds i8, i8* %62, i64 %1
  %74 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %75 = mul nuw <8 x i16> %17, <i16 182, i16 182, i16 182, i16 182, i16 182, i16 182, i16 182, i16 182>
  %76 = bitcast <16 x i8> %74 to <8 x i16>
  %77 = add <8 x i16> %76, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %78 = add <8 x i16> %77, %75
  %79 = lshr <8 x i16> %78, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %80 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> undef) #5
  %81 = bitcast <16 x i8> %80 to <2 x i64>
  %82 = extractelement <2 x i64> %81, i32 0
  %83 = bitcast i8* %73 to i64*
  store i64 %82, i64* %83, align 1
  %84 = getelementptr inbounds i8, i8* %73, i64 %1
  %85 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %86 = mul nuw <8 x i16> %17, <i16 169, i16 169, i16 169, i16 169, i16 169, i16 169, i16 169, i16 169>
  %87 = bitcast <16 x i8> %85 to <8 x i16>
  %88 = add <8 x i16> %87, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %89 = add <8 x i16> %88, %86
  %90 = lshr <8 x i16> %89, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %91 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> undef) #5
  %92 = bitcast <16 x i8> %91 to <2 x i64>
  %93 = extractelement <2 x i64> %92, i32 0
  %94 = bitcast i8* %84 to i64*
  store i64 %93, i64* %94, align 1
  %95 = getelementptr inbounds i8, i8* %84, i64 %1
  %96 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %97 = mul nuw <8 x i16> %17, <i16 157, i16 157, i16 157, i16 157, i16 157, i16 157, i16 157, i16 157>
  %98 = bitcast <16 x i8> %96 to <8 x i16>
  %99 = add <8 x i16> %98, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %100 = add <8 x i16> %99, %97
  %101 = lshr <8 x i16> %100, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %101, <8 x i16> undef) #5
  %103 = bitcast <16 x i8> %102 to <2 x i64>
  %104 = extractelement <2 x i64> %103, i32 0
  %105 = bitcast i8* %95 to i64*
  store i64 %104, i64* %105, align 1
  %106 = getelementptr inbounds i8, i8* %95, i64 %1
  %107 = mul <8 x i16> %9, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %108 = mul <8 x i16> %9, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %109 = bitcast <8 x i16> %107 to <16 x i8>
  %110 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %111 = mul nuw <8 x i16> %17, <i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145>
  %112 = bitcast <16 x i8> %110 to <8 x i16>
  %113 = add <8 x i16> %112, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %114 = add <8 x i16> %113, %111
  %115 = lshr <8 x i16> %114, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %116 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %115, <8 x i16> undef) #5
  %117 = bitcast <16 x i8> %116 to <2 x i64>
  %118 = extractelement <2 x i64> %117, i32 0
  %119 = bitcast i8* %106 to i64*
  store i64 %118, i64* %119, align 1
  %120 = getelementptr inbounds i8, i8* %106, i64 %1
  %121 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %122 = mul nuw <8 x i16> %17, <i16 133, i16 133, i16 133, i16 133, i16 133, i16 133, i16 133, i16 133>
  %123 = bitcast <16 x i8> %121 to <8 x i16>
  %124 = add <8 x i16> %123, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %125 = add <8 x i16> %124, %122
  %126 = lshr <8 x i16> %125, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %127 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %126, <8 x i16> undef) #5
  %128 = bitcast <16 x i8> %127 to <2 x i64>
  %129 = extractelement <2 x i64> %128, i32 0
  %130 = bitcast i8* %120 to i64*
  store i64 %129, i64* %130, align 1
  %131 = getelementptr inbounds i8, i8* %120, i64 %1
  %132 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %133 = mul nuw nsw <8 x i16> %17, <i16 122, i16 122, i16 122, i16 122, i16 122, i16 122, i16 122, i16 122>
  %134 = bitcast <16 x i8> %132 to <8 x i16>
  %135 = add <8 x i16> %134, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %136 = add <8 x i16> %135, %133
  %137 = lshr <8 x i16> %136, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %138 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %137, <8 x i16> undef) #5
  %139 = bitcast <16 x i8> %138 to <2 x i64>
  %140 = extractelement <2 x i64> %139, i32 0
  %141 = bitcast i8* %131 to i64*
  store i64 %140, i64* %141, align 1
  %142 = getelementptr inbounds i8, i8* %131, i64 %1
  %143 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %144 = mul nuw nsw <8 x i16> %17, <i16 111, i16 111, i16 111, i16 111, i16 111, i16 111, i16 111, i16 111>
  %145 = bitcast <16 x i8> %143 to <8 x i16>
  %146 = add <8 x i16> %145, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %147 = add <8 x i16> %146, %144
  %148 = lshr <8 x i16> %147, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %149 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %148, <8 x i16> undef) #5
  %150 = bitcast <16 x i8> %149 to <2 x i64>
  %151 = extractelement <2 x i64> %150, i32 0
  %152 = bitcast i8* %142 to i64*
  store i64 %151, i64* %152, align 1
  %153 = getelementptr inbounds i8, i8* %142, i64 %1
  %154 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %155 = mul nuw nsw <8 x i16> %17, <i16 101, i16 101, i16 101, i16 101, i16 101, i16 101, i16 101, i16 101>
  %156 = bitcast <16 x i8> %154 to <8 x i16>
  %157 = add <8 x i16> %156, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %158 = add <8 x i16> %157, %155
  %159 = lshr <8 x i16> %158, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %160 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> undef) #5
  %161 = bitcast <16 x i8> %160 to <2 x i64>
  %162 = extractelement <2 x i64> %161, i32 0
  %163 = bitcast i8* %153 to i64*
  store i64 %162, i64* %163, align 1
  %164 = getelementptr inbounds i8, i8* %153, i64 %1
  %165 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %166 = mul nuw nsw <8 x i16> %17, <i16 92, i16 92, i16 92, i16 92, i16 92, i16 92, i16 92, i16 92>
  %167 = bitcast <16 x i8> %165 to <8 x i16>
  %168 = add <8 x i16> %167, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %169 = add <8 x i16> %168, %166
  %170 = lshr <8 x i16> %169, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %171 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %170, <8 x i16> undef) #5
  %172 = bitcast <16 x i8> %171 to <2 x i64>
  %173 = extractelement <2 x i64> %172, i32 0
  %174 = bitcast i8* %164 to i64*
  store i64 %173, i64* %174, align 1
  %175 = getelementptr inbounds i8, i8* %164, i64 %1
  %176 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %177 = mul nuw nsw <8 x i16> %17, <i16 83, i16 83, i16 83, i16 83, i16 83, i16 83, i16 83, i16 83>
  %178 = bitcast <16 x i8> %176 to <8 x i16>
  %179 = add <8 x i16> %178, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %180 = add <8 x i16> %179, %177
  %181 = lshr <8 x i16> %180, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %182 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %181, <8 x i16> undef) #5
  %183 = bitcast <16 x i8> %182 to <2 x i64>
  %184 = extractelement <2 x i64> %183, i32 0
  %185 = bitcast i8* %175 to i64*
  store i64 %184, i64* %185, align 1
  %186 = getelementptr inbounds i8, i8* %175, i64 %1
  %187 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %188 = mul nuw nsw <8 x i16> %17, <i16 74, i16 74, i16 74, i16 74, i16 74, i16 74, i16 74, i16 74>
  %189 = bitcast <16 x i8> %187 to <8 x i16>
  %190 = add <8 x i16> %189, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %191 = add <8 x i16> %190, %188
  %192 = lshr <8 x i16> %191, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %193 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %192, <8 x i16> undef) #5
  %194 = bitcast <16 x i8> %193 to <2 x i64>
  %195 = extractelement <2 x i64> %194, i32 0
  %196 = bitcast i8* %186 to i64*
  store i64 %195, i64* %196, align 1
  %197 = getelementptr inbounds i8, i8* %186, i64 %1
  %198 = bitcast <8 x i16> %11 to <16 x i8>
  %199 = shufflevector <16 x i8> %198, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %200 = mul nuw nsw <8 x i16> %17, <i16 66, i16 66, i16 66, i16 66, i16 66, i16 66, i16 66, i16 66>
  %201 = bitcast <16 x i8> %199 to <8 x i16>
  %202 = add <8 x i16> %201, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %203 = add <8 x i16> %202, %200
  %204 = lshr <8 x i16> %203, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %205 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %204, <8 x i16> undef) #5
  %206 = bitcast <16 x i8> %205 to <2 x i64>
  %207 = extractelement <2 x i64> %206, i32 0
  %208 = bitcast i8* %197 to i64*
  store i64 %207, i64* %208, align 1
  %209 = getelementptr inbounds i8, i8* %197, i64 %1
  %210 = shufflevector <16 x i8> %198, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %211 = mul nuw nsw <8 x i16> %17, <i16 59, i16 59, i16 59, i16 59, i16 59, i16 59, i16 59, i16 59>
  %212 = bitcast <16 x i8> %210 to <8 x i16>
  %213 = add <8 x i16> %212, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %214 = add <8 x i16> %213, %211
  %215 = lshr <8 x i16> %214, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %216 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %215, <8 x i16> undef) #5
  %217 = bitcast <16 x i8> %216 to <2 x i64>
  %218 = extractelement <2 x i64> %217, i32 0
  %219 = bitcast i8* %209 to i64*
  store i64 %218, i64* %219, align 1
  %220 = getelementptr inbounds i8, i8* %209, i64 %1
  %221 = shufflevector <16 x i8> %198, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %222 = mul nuw nsw <8 x i16> %17, <i16 52, i16 52, i16 52, i16 52, i16 52, i16 52, i16 52, i16 52>
  %223 = bitcast <16 x i8> %221 to <8 x i16>
  %224 = add <8 x i16> %223, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %225 = add <8 x i16> %224, %222
  %226 = lshr <8 x i16> %225, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %227 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> undef) #5
  %228 = bitcast <16 x i8> %227 to <2 x i64>
  %229 = extractelement <2 x i64> %228, i32 0
  %230 = bitcast i8* %220 to i64*
  store i64 %229, i64* %230, align 1
  %231 = getelementptr inbounds i8, i8* %220, i64 %1
  %232 = shufflevector <16 x i8> %198, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %233 = mul nuw nsw <8 x i16> %17, <i16 45, i16 45, i16 45, i16 45, i16 45, i16 45, i16 45, i16 45>
  %234 = bitcast <16 x i8> %232 to <8 x i16>
  %235 = add <8 x i16> %234, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %236 = add <8 x i16> %235, %233
  %237 = lshr <8 x i16> %236, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %238 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %237, <8 x i16> undef) #5
  %239 = bitcast <16 x i8> %238 to <2 x i64>
  %240 = extractelement <2 x i64> %239, i32 0
  %241 = bitcast i8* %231 to i64*
  store i64 %240, i64* %241, align 1
  %242 = getelementptr inbounds i8, i8* %231, i64 %1
  %243 = shufflevector <16 x i8> %198, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %244 = mul nuw nsw <8 x i16> %17, <i16 39, i16 39, i16 39, i16 39, i16 39, i16 39, i16 39, i16 39>
  %245 = bitcast <16 x i8> %243 to <8 x i16>
  %246 = add <8 x i16> %245, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %247 = add <8 x i16> %246, %244
  %248 = lshr <8 x i16> %247, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %249 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %248, <8 x i16> undef) #5
  %250 = bitcast <16 x i8> %249 to <2 x i64>
  %251 = extractelement <2 x i64> %250, i32 0
  %252 = bitcast i8* %242 to i64*
  store i64 %251, i64* %252, align 1
  %253 = getelementptr inbounds i8, i8* %242, i64 %1
  %254 = shufflevector <16 x i8> %198, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %255 = mul nuw nsw <8 x i16> %17, <i16 34, i16 34, i16 34, i16 34, i16 34, i16 34, i16 34, i16 34>
  %256 = bitcast <16 x i8> %254 to <8 x i16>
  %257 = add <8 x i16> %256, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %258 = add <8 x i16> %257, %255
  %259 = lshr <8 x i16> %258, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %259, <8 x i16> undef) #5
  %261 = bitcast <16 x i8> %260 to <2 x i64>
  %262 = extractelement <2 x i64> %261, i32 0
  %263 = bitcast i8* %253 to i64*
  store i64 %262, i64* %263, align 1
  %264 = getelementptr inbounds i8, i8* %253, i64 %1
  %265 = shufflevector <16 x i8> %198, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %266 = mul nuw nsw <8 x i16> %17, <i16 29, i16 29, i16 29, i16 29, i16 29, i16 29, i16 29, i16 29>
  %267 = bitcast <16 x i8> %265 to <8 x i16>
  %268 = add <8 x i16> %267, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %269 = add <8 x i16> %268, %266
  %270 = lshr <8 x i16> %269, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %271 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %270, <8 x i16> undef) #5
  %272 = bitcast <16 x i8> %271 to <2 x i64>
  %273 = extractelement <2 x i64> %272, i32 0
  %274 = bitcast i8* %264 to i64*
  store i64 %273, i64* %274, align 1
  %275 = getelementptr inbounds i8, i8* %264, i64 %1
  %276 = shufflevector <16 x i8> %198, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %277 = mul nuw nsw <8 x i16> %17, <i16 25, i16 25, i16 25, i16 25, i16 25, i16 25, i16 25, i16 25>
  %278 = bitcast <16 x i8> %276 to <8 x i16>
  %279 = add <8 x i16> %278, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %280 = add <8 x i16> %279, %277
  %281 = lshr <8 x i16> %280, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %282 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %281, <8 x i16> undef) #5
  %283 = bitcast <16 x i8> %282 to <2 x i64>
  %284 = extractelement <2 x i64> %283, i32 0
  %285 = bitcast i8* %275 to i64*
  store i64 %284, i64* %285, align 1
  %286 = getelementptr inbounds i8, i8* %275, i64 %1
  %287 = bitcast <8 x i16> %108 to <16 x i8>
  %288 = shufflevector <16 x i8> %287, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %289 = mul nuw nsw <8 x i16> %17, <i16 21, i16 21, i16 21, i16 21, i16 21, i16 21, i16 21, i16 21>
  %290 = bitcast <16 x i8> %288 to <8 x i16>
  %291 = add <8 x i16> %290, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %292 = add <8 x i16> %291, %289
  %293 = lshr <8 x i16> %292, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %294 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %293, <8 x i16> undef) #5
  %295 = bitcast <16 x i8> %294 to <2 x i64>
  %296 = extractelement <2 x i64> %295, i32 0
  %297 = bitcast i8* %286 to i64*
  store i64 %296, i64* %297, align 1
  %298 = getelementptr inbounds i8, i8* %286, i64 %1
  %299 = shufflevector <16 x i8> %287, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %300 = mul nuw nsw <8 x i16> %17, <i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17>
  %301 = bitcast <16 x i8> %299 to <8 x i16>
  %302 = add <8 x i16> %301, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %303 = add <8 x i16> %302, %300
  %304 = lshr <8 x i16> %303, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %305 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %304, <8 x i16> undef) #5
  %306 = bitcast <16 x i8> %305 to <2 x i64>
  %307 = extractelement <2 x i64> %306, i32 0
  %308 = bitcast i8* %298 to i64*
  store i64 %307, i64* %308, align 1
  %309 = getelementptr inbounds i8, i8* %298, i64 %1
  %310 = shufflevector <16 x i8> %287, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %311 = mul nuw nsw <8 x i16> %17, <i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14>
  %312 = bitcast <16 x i8> %310 to <8 x i16>
  %313 = add <8 x i16> %312, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %314 = add <8 x i16> %313, %311
  %315 = lshr <8 x i16> %314, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %316 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %315, <8 x i16> undef) #5
  %317 = bitcast <16 x i8> %316 to <2 x i64>
  %318 = extractelement <2 x i64> %317, i32 0
  %319 = bitcast i8* %309 to i64*
  store i64 %318, i64* %319, align 1
  %320 = getelementptr inbounds i8, i8* %309, i64 %1
  %321 = shufflevector <16 x i8> %287, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %322 = mul nuw nsw <8 x i16> %17, <i16 12, i16 12, i16 12, i16 12, i16 12, i16 12, i16 12, i16 12>
  %323 = bitcast <16 x i8> %321 to <8 x i16>
  %324 = add <8 x i16> %323, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %325 = add <8 x i16> %324, %322
  %326 = lshr <8 x i16> %325, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %327 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %326, <8 x i16> undef) #5
  %328 = bitcast <16 x i8> %327 to <2 x i64>
  %329 = extractelement <2 x i64> %328, i32 0
  %330 = bitcast i8* %320 to i64*
  store i64 %329, i64* %330, align 1
  %331 = getelementptr inbounds i8, i8* %320, i64 %1
  %332 = shufflevector <16 x i8> %287, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %333 = mul nuw nsw <8 x i16> %17, <i16 10, i16 10, i16 10, i16 10, i16 10, i16 10, i16 10, i16 10>
  %334 = bitcast <16 x i8> %332 to <8 x i16>
  %335 = add <8 x i16> %334, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %336 = add <8 x i16> %335, %333
  %337 = lshr <8 x i16> %336, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %338 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %337, <8 x i16> undef) #5
  %339 = bitcast <16 x i8> %338 to <2 x i64>
  %340 = extractelement <2 x i64> %339, i32 0
  %341 = bitcast i8* %331 to i64*
  store i64 %340, i64* %341, align 1
  %342 = getelementptr inbounds i8, i8* %331, i64 %1
  %343 = shufflevector <16 x i8> %287, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %344 = mul nuw nsw <8 x i16> %17, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %345 = bitcast <16 x i8> %343 to <8 x i16>
  %346 = add <8 x i16> %345, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %347 = add <8 x i16> %346, %344
  %348 = lshr <8 x i16> %347, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %349 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %348, <8 x i16> undef) #5
  %350 = bitcast <16 x i8> %349 to <2 x i64>
  %351 = extractelement <2 x i64> %350, i32 0
  %352 = bitcast i8* %342 to i64*
  store i64 %351, i64* %352, align 1
  %353 = getelementptr inbounds i8, i8* %342, i64 %1
  %354 = shufflevector <16 x i8> %287, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %355 = shl nuw nsw <8 x i16> %17, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %356 = bitcast <16 x i8> %354 to <8 x i16>
  %357 = add <8 x i16> %356, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %358 = add <8 x i16> %357, %355
  %359 = lshr <8 x i16> %358, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %360 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %359, <8 x i16> undef) #5
  %361 = bitcast <16 x i8> %360 to <2 x i64>
  %362 = extractelement <2 x i64> %361, i32 0
  %363 = bitcast i8* %353 to i64*
  store i64 %362, i64* %363, align 1
  %364 = getelementptr inbounds i8, i8* %353, i64 %1
  %365 = shufflevector <16 x i8> %287, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %366 = shl nuw nsw <8 x i16> %17, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %367 = bitcast <16 x i8> %365 to <8 x i16>
  %368 = add <8 x i16> %367, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %369 = add <8 x i16> %368, %366
  %370 = lshr <8 x i16> %369, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %371 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %370, <8 x i16> undef) #5
  %372 = bitcast <16 x i8> %371 to <2 x i64>
  %373 = extractelement <2 x i64> %372, i32 0
  %374 = bitcast i8* %364 to i64*
  store i64 %373, i64* %374, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical16x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 3
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 107, i16 171, i16 192, i16 256, i16 256, i16 256, i16 256>
  %11 = bitcast i8* %2 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = shufflevector <16 x i8> %12, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %14 = zext <8 x i8> %13 to <8 x i16>
  %15 = shufflevector <16 x i8> %12, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %10 to <16 x i8>
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %19 = mul nuw <8 x i16> %14, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %20 = mul nuw <8 x i16> %16, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %21 = bitcast <16 x i8> %18 to <8 x i16>
  %22 = add <8 x i16> %21, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %23 = add <8 x i16> %22, %19
  %24 = lshr <8 x i16> %23, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %25 = add <8 x i16> %22, %20
  %26 = lshr <8 x i16> %25, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %27 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %24, <8 x i16> %26) #5
  %28 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 %1
  %30 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %31 = mul nuw <8 x i16> %14, <i16 149, i16 149, i16 149, i16 149, i16 149, i16 149, i16 149, i16 149>
  %32 = mul nuw <8 x i16> %16, <i16 149, i16 149, i16 149, i16 149, i16 149, i16 149, i16 149, i16 149>
  %33 = bitcast <16 x i8> %30 to <8 x i16>
  %34 = add <8 x i16> %33, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %35 = add <8 x i16> %34, %31
  %36 = lshr <8 x i16> %35, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %37 = add <8 x i16> %34, %32
  %38 = lshr <8 x i16> %37, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %39 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %36, <8 x i16> %38) #5
  %40 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %29, i64 %1
  %42 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %43 = mul nuw nsw <8 x i16> %14, <i16 85, i16 85, i16 85, i16 85, i16 85, i16 85, i16 85, i16 85>
  %44 = mul nuw nsw <8 x i16> %16, <i16 85, i16 85, i16 85, i16 85, i16 85, i16 85, i16 85, i16 85>
  %45 = bitcast <16 x i8> %42 to <8 x i16>
  %46 = add <8 x i16> %45, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %47 = add <8 x i16> %46, %43
  %48 = lshr <8 x i16> %47, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %49 = add <8 x i16> %46, %44
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %50) #5
  %52 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %51, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %41, i64 %1
  %54 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %55 = shl nuw nsw <8 x i16> %14, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %56 = shl nuw nsw <8 x i16> %16, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %57 = bitcast <16 x i8> %54 to <8 x i16>
  %58 = add <8 x i16> %57, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %59 = add <8 x i16> %58, %55
  %60 = lshr <8 x i16> %59, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %61 = add <8 x i16> %58, %56
  %62 = lshr <8 x i16> %61, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %63 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %60, <8 x i16> %62) #5
  %64 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %64, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical16x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 59, i16 110, i16 151, i16 183, i16 206, i16 219, i16 224>
  %11 = bitcast i8* %2 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = shufflevector <16 x i8> %12, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %14 = zext <8 x i8> %13 to <8 x i16>
  %15 = shufflevector <16 x i8> %12, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %10 to <16 x i8>
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %19 = mul nuw <8 x i16> %14, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %20 = mul nuw <8 x i16> %16, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %21 = bitcast <16 x i8> %18 to <8 x i16>
  %22 = add <8 x i16> %21, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %23 = add <8 x i16> %22, %19
  %24 = lshr <8 x i16> %23, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %25 = add <8 x i16> %22, %20
  %26 = lshr <8 x i16> %25, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %27 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %24, <8 x i16> %26) #5
  %28 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 %1
  %30 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %31 = mul nuw <8 x i16> %14, <i16 197, i16 197, i16 197, i16 197, i16 197, i16 197, i16 197, i16 197>
  %32 = mul nuw <8 x i16> %16, <i16 197, i16 197, i16 197, i16 197, i16 197, i16 197, i16 197, i16 197>
  %33 = bitcast <16 x i8> %30 to <8 x i16>
  %34 = add <8 x i16> %33, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %35 = add <8 x i16> %34, %31
  %36 = lshr <8 x i16> %35, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %37 = add <8 x i16> %34, %32
  %38 = lshr <8 x i16> %37, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %39 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %36, <8 x i16> %38) #5
  %40 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %29, i64 %1
  %42 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %43 = mul nuw <8 x i16> %14, <i16 146, i16 146, i16 146, i16 146, i16 146, i16 146, i16 146, i16 146>
  %44 = mul nuw <8 x i16> %16, <i16 146, i16 146, i16 146, i16 146, i16 146, i16 146, i16 146, i16 146>
  %45 = bitcast <16 x i8> %42 to <8 x i16>
  %46 = add <8 x i16> %45, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %47 = add <8 x i16> %46, %43
  %48 = lshr <8 x i16> %47, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %49 = add <8 x i16> %46, %44
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %50) #5
  %52 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %51, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %41, i64 %1
  %54 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %55 = mul nuw nsw <8 x i16> %14, <i16 105, i16 105, i16 105, i16 105, i16 105, i16 105, i16 105, i16 105>
  %56 = mul nuw nsw <8 x i16> %16, <i16 105, i16 105, i16 105, i16 105, i16 105, i16 105, i16 105, i16 105>
  %57 = bitcast <16 x i8> %54 to <8 x i16>
  %58 = add <8 x i16> %57, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %59 = add <8 x i16> %58, %55
  %60 = lshr <8 x i16> %59, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %61 = add <8 x i16> %58, %56
  %62 = lshr <8 x i16> %61, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %63 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %60, <8 x i16> %62) #5
  %64 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %53, i64 %1
  %66 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %67 = mul nuw nsw <8 x i16> %14, <i16 73, i16 73, i16 73, i16 73, i16 73, i16 73, i16 73, i16 73>
  %68 = mul nuw nsw <8 x i16> %16, <i16 73, i16 73, i16 73, i16 73, i16 73, i16 73, i16 73, i16 73>
  %69 = bitcast <16 x i8> %66 to <8 x i16>
  %70 = add <8 x i16> %69, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %71 = add <8 x i16> %70, %67
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = add <8 x i16> %70, %68
  %74 = lshr <8 x i16> %73, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %75 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> %74) #5
  %76 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %75, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %65, i64 %1
  %78 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %79 = mul nuw nsw <8 x i16> %14, <i16 50, i16 50, i16 50, i16 50, i16 50, i16 50, i16 50, i16 50>
  %80 = mul nuw nsw <8 x i16> %16, <i16 50, i16 50, i16 50, i16 50, i16 50, i16 50, i16 50, i16 50>
  %81 = bitcast <16 x i8> %78 to <8 x i16>
  %82 = add <8 x i16> %81, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %83 = add <8 x i16> %82, %79
  %84 = lshr <8 x i16> %83, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %85 = add <8 x i16> %82, %80
  %86 = lshr <8 x i16> %85, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %84, <8 x i16> %86) #5
  %88 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %87, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %77, i64 %1
  %90 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %91 = mul nuw nsw <8 x i16> %14, <i16 37, i16 37, i16 37, i16 37, i16 37, i16 37, i16 37, i16 37>
  %92 = mul nuw nsw <8 x i16> %16, <i16 37, i16 37, i16 37, i16 37, i16 37, i16 37, i16 37, i16 37>
  %93 = bitcast <16 x i8> %90 to <8 x i16>
  %94 = add <8 x i16> %93, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %95 = add <8 x i16> %94, %91
  %96 = lshr <8 x i16> %95, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %97 = add <8 x i16> %94, %92
  %98 = lshr <8 x i16> %97, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %98) #5
  %100 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %99, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %89, i64 %1
  %102 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %103 = shl nuw nsw <8 x i16> %14, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %104 = shl nuw nsw <8 x i16> %16, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %105 = bitcast <16 x i8> %102 to <8 x i16>
  %106 = add <8 x i16> %105, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %107 = add <8 x i16> %106, %103
  %108 = lshr <8 x i16> %107, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %109 = add <8 x i16> %106, %104
  %110 = lshr <8 x i16> %109, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %108, <8 x i16> %110) #5
  %112 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %111, <16 x i8>* %112, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical16x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %11 = bitcast i8* %2 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = shufflevector <16 x i8> %12, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %14 = zext <8 x i8> %13 to <8 x i16>
  %15 = shufflevector <16 x i8> %12, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %16 = bitcast <8 x i16> %10 to <16 x i8>
  %17 = bitcast <16 x i8> %15 to <8 x i16>
  %18 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %19 = mul nuw <8 x i16> %14, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %20 = mul <8 x i16> %17, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %21 = bitcast <16 x i8> %18 to <8 x i16>
  %22 = add <8 x i16> %21, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %23 = add <8 x i16> %22, %19
  %24 = lshr <8 x i16> %23, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %25 = add <8 x i16> %22, %20
  %26 = lshr <8 x i16> %25, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %27 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %24, <8 x i16> %26) #5
  %28 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 %1
  %30 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %31 = mul nuw <8 x i16> %14, <i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225>
  %32 = mul <8 x i16> %17, <i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225>
  %33 = bitcast <16 x i8> %30 to <8 x i16>
  %34 = add <8 x i16> %33, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %35 = add <8 x i16> %34, %31
  %36 = lshr <8 x i16> %35, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %37 = add <8 x i16> %34, %32
  %38 = lshr <8 x i16> %37, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %39 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %36, <8 x i16> %38) #5
  %40 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %29, i64 %1
  %42 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %43 = mul nuw <8 x i16> %14, <i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196>
  %44 = mul <8 x i16> %17, <i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196>
  %45 = bitcast <16 x i8> %42 to <8 x i16>
  %46 = add <8 x i16> %45, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %47 = add <8 x i16> %46, %43
  %48 = lshr <8 x i16> %47, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %49 = add <8 x i16> %46, %44
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %50) #5
  %52 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %51, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %41, i64 %1
  %54 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %55 = mul nuw <8 x i16> %14, <i16 170, i16 170, i16 170, i16 170, i16 170, i16 170, i16 170, i16 170>
  %56 = mul <8 x i16> %17, <i16 170, i16 170, i16 170, i16 170, i16 170, i16 170, i16 170, i16 170>
  %57 = bitcast <16 x i8> %54 to <8 x i16>
  %58 = add <8 x i16> %57, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %59 = add <8 x i16> %58, %55
  %60 = lshr <8 x i16> %59, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %61 = add <8 x i16> %58, %56
  %62 = lshr <8 x i16> %61, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %63 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %60, <8 x i16> %62) #5
  %64 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %53, i64 %1
  %66 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %67 = mul nuw <8 x i16> %14, <i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145>
  %68 = mul <8 x i16> %17, <i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145>
  %69 = bitcast <16 x i8> %66 to <8 x i16>
  %70 = add <8 x i16> %69, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %71 = add <8 x i16> %70, %67
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = add <8 x i16> %70, %68
  %74 = lshr <8 x i16> %73, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %75 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> %74) #5
  %76 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %75, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %65, i64 %1
  %78 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %79 = mul nuw nsw <8 x i16> %14, <i16 123, i16 123, i16 123, i16 123, i16 123, i16 123, i16 123, i16 123>
  %80 = mul <8 x i16> %17, <i16 123, i16 123, i16 123, i16 123, i16 123, i16 123, i16 123, i16 123>
  %81 = bitcast <16 x i8> %78 to <8 x i16>
  %82 = add <8 x i16> %81, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %83 = add <8 x i16> %82, %79
  %84 = lshr <8 x i16> %83, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %85 = add <8 x i16> %82, %80
  %86 = lshr <8 x i16> %85, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %84, <8 x i16> %86) #5
  %88 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %87, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %77, i64 %1
  %90 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %91 = mul nuw nsw <8 x i16> %14, <i16 102, i16 102, i16 102, i16 102, i16 102, i16 102, i16 102, i16 102>
  %92 = mul <8 x i16> %17, <i16 102, i16 102, i16 102, i16 102, i16 102, i16 102, i16 102, i16 102>
  %93 = bitcast <16 x i8> %90 to <8 x i16>
  %94 = add <8 x i16> %93, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %95 = add <8 x i16> %94, %91
  %96 = lshr <8 x i16> %95, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %97 = add <8 x i16> %94, %92
  %98 = lshr <8 x i16> %97, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %98) #5
  %100 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %99, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %89, i64 %1
  %102 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %103 = mul nuw nsw <8 x i16> %14, <i16 84, i16 84, i16 84, i16 84, i16 84, i16 84, i16 84, i16 84>
  %104 = mul <8 x i16> %17, <i16 84, i16 84, i16 84, i16 84, i16 84, i16 84, i16 84, i16 84>
  %105 = bitcast <16 x i8> %102 to <8 x i16>
  %106 = add <8 x i16> %105, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %107 = add <8 x i16> %106, %103
  %108 = lshr <8 x i16> %107, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %109 = add <8 x i16> %106, %104
  %110 = lshr <8 x i16> %109, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %108, <8 x i16> %110) #5
  %112 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %111, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %101, i64 %1
  %114 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %115 = bitcast <8 x i16> %114 to <16 x i8>
  %116 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %117 = mul nuw nsw <8 x i16> %14, <i16 68, i16 68, i16 68, i16 68, i16 68, i16 68, i16 68, i16 68>
  %118 = mul <8 x i16> %17, <i16 68, i16 68, i16 68, i16 68, i16 68, i16 68, i16 68, i16 68>
  %119 = bitcast <16 x i8> %116 to <8 x i16>
  %120 = add <8 x i16> %119, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %121 = add <8 x i16> %120, %117
  %122 = lshr <8 x i16> %121, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %123 = add <8 x i16> %120, %118
  %124 = lshr <8 x i16> %123, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %125 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %122, <8 x i16> %124) #5
  %126 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %125, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %113, i64 %1
  %128 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %129 = mul nuw nsw <8 x i16> %14, <i16 54, i16 54, i16 54, i16 54, i16 54, i16 54, i16 54, i16 54>
  %130 = mul <8 x i16> %17, <i16 54, i16 54, i16 54, i16 54, i16 54, i16 54, i16 54, i16 54>
  %131 = bitcast <16 x i8> %128 to <8 x i16>
  %132 = add <8 x i16> %131, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %133 = add <8 x i16> %132, %129
  %134 = lshr <8 x i16> %133, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %135 = add <8 x i16> %132, %130
  %136 = lshr <8 x i16> %135, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %137 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %134, <8 x i16> %136) #5
  %138 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %137, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %127, i64 %1
  %140 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %141 = mul nuw nsw <8 x i16> %14, <i16 43, i16 43, i16 43, i16 43, i16 43, i16 43, i16 43, i16 43>
  %142 = mul <8 x i16> %17, <i16 43, i16 43, i16 43, i16 43, i16 43, i16 43, i16 43, i16 43>
  %143 = bitcast <16 x i8> %140 to <8 x i16>
  %144 = add <8 x i16> %143, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %145 = add <8 x i16> %144, %141
  %146 = lshr <8 x i16> %145, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %147 = add <8 x i16> %144, %142
  %148 = lshr <8 x i16> %147, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %149 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %146, <8 x i16> %148) #5
  %150 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %149, <16 x i8>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %139, i64 %1
  %152 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %153 = mul nuw nsw <8 x i16> %14, <i16 33, i16 33, i16 33, i16 33, i16 33, i16 33, i16 33, i16 33>
  %154 = mul <8 x i16> %17, <i16 33, i16 33, i16 33, i16 33, i16 33, i16 33, i16 33, i16 33>
  %155 = bitcast <16 x i8> %152 to <8 x i16>
  %156 = add <8 x i16> %155, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %157 = add <8 x i16> %156, %153
  %158 = lshr <8 x i16> %157, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %159 = add <8 x i16> %156, %154
  %160 = lshr <8 x i16> %159, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %161 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %158, <8 x i16> %160) #5
  %162 = bitcast i8* %151 to <16 x i8>*
  store <16 x i8> %161, <16 x i8>* %162, align 1
  %163 = getelementptr inbounds i8, i8* %151, i64 %1
  %164 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %165 = mul nuw nsw <8 x i16> %14, <i16 26, i16 26, i16 26, i16 26, i16 26, i16 26, i16 26, i16 26>
  %166 = mul <8 x i16> %17, <i16 26, i16 26, i16 26, i16 26, i16 26, i16 26, i16 26, i16 26>
  %167 = bitcast <16 x i8> %164 to <8 x i16>
  %168 = add <8 x i16> %167, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %169 = add <8 x i16> %168, %165
  %170 = lshr <8 x i16> %169, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %171 = add <8 x i16> %168, %166
  %172 = lshr <8 x i16> %171, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %173 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %170, <8 x i16> %172) #5
  %174 = bitcast i8* %163 to <16 x i8>*
  store <16 x i8> %173, <16 x i8>* %174, align 1
  %175 = getelementptr inbounds i8, i8* %163, i64 %1
  %176 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %177 = mul nuw nsw <8 x i16> %14, <i16 20, i16 20, i16 20, i16 20, i16 20, i16 20, i16 20, i16 20>
  %178 = mul <8 x i16> %17, <i16 20, i16 20, i16 20, i16 20, i16 20, i16 20, i16 20, i16 20>
  %179 = bitcast <16 x i8> %176 to <8 x i16>
  %180 = add <8 x i16> %179, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %181 = add <8 x i16> %180, %177
  %182 = lshr <8 x i16> %181, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %183 = add <8 x i16> %180, %178
  %184 = lshr <8 x i16> %183, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %185 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %184) #5
  %186 = bitcast i8* %175 to <16 x i8>*
  store <16 x i8> %185, <16 x i8>* %186, align 1
  %187 = getelementptr inbounds i8, i8* %175, i64 %1
  %188 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %189 = mul nuw nsw <8 x i16> %14, <i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17>
  %190 = mul <8 x i16> %17, <i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17>
  %191 = bitcast <16 x i8> %188 to <8 x i16>
  %192 = add <8 x i16> %191, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %193 = add <8 x i16> %192, %189
  %194 = lshr <8 x i16> %193, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %195 = add <8 x i16> %192, %190
  %196 = lshr <8 x i16> %195, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %197 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %194, <8 x i16> %196) #5
  %198 = bitcast i8* %187 to <16 x i8>*
  store <16 x i8> %197, <16 x i8>* %198, align 1
  %199 = getelementptr inbounds i8, i8* %187, i64 %1
  %200 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %201 = shl nuw nsw <8 x i16> %14, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %202 = shl <8 x i16> %17, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %203 = bitcast <16 x i8> %200 to <8 x i16>
  %204 = add <8 x i16> %203, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %205 = add <8 x i16> %204, %201
  %206 = lshr <8 x i16> %205, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %207 = add <8 x i16> %204, %202
  %208 = lshr <8 x i16> %207, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %209 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %206, <8 x i16> %208) #5
  %210 = bitcast i8* %199 to <16 x i8>*
  store <16 x i8> %209, <16 x i8>* %210, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical16x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %11 = mul <8 x i16> %9, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %12 = bitcast i8* %2 to <16 x i8>*
  %13 = load <16 x i8>, <16 x i8>* %12, align 1
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = shufflevector <16 x i8> %13, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %17 = bitcast <8 x i16> %10 to <16 x i8>
  %18 = bitcast <16 x i8> %16 to <8 x i16>
  %19 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %20 = mul nuw <8 x i16> %15, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %21 = mul <8 x i16> %18, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %22 = bitcast <16 x i8> %19 to <8 x i16>
  %23 = add <8 x i16> %22, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %24 = add <8 x i16> %23, %20
  %25 = lshr <8 x i16> %24, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %26 = add <8 x i16> %23, %21
  %27 = lshr <8 x i16> %26, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %28 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %25, <8 x i16> %27) #5
  %29 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %28, <16 x i8>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %0, i64 %1
  %31 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %32 = mul nuw <8 x i16> %15, <i16 240, i16 240, i16 240, i16 240, i16 240, i16 240, i16 240, i16 240>
  %33 = mul <8 x i16> %18, <i16 240, i16 240, i16 240, i16 240, i16 240, i16 240, i16 240, i16 240>
  %34 = bitcast <16 x i8> %31 to <8 x i16>
  %35 = add <8 x i16> %34, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %36 = add <8 x i16> %35, %32
  %37 = lshr <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = add <8 x i16> %35, %33
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %39) #5
  %41 = bitcast i8* %30 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %30, i64 %1
  %43 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %44 = mul nuw <8 x i16> %15, <i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225>
  %45 = mul <8 x i16> %18, <i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225, i16 225>
  %46 = bitcast <16 x i8> %43 to <8 x i16>
  %47 = add <8 x i16> %46, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %48 = add <8 x i16> %47, %44
  %49 = lshr <8 x i16> %48, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %50 = add <8 x i16> %47, %45
  %51 = lshr <8 x i16> %50, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %52 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %49, <8 x i16> %51) #5
  %53 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %52, <16 x i8>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %42, i64 %1
  %55 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %56 = mul nuw <8 x i16> %15, <i16 210, i16 210, i16 210, i16 210, i16 210, i16 210, i16 210, i16 210>
  %57 = mul <8 x i16> %18, <i16 210, i16 210, i16 210, i16 210, i16 210, i16 210, i16 210, i16 210>
  %58 = bitcast <16 x i8> %55 to <8 x i16>
  %59 = add <8 x i16> %58, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %60 = add <8 x i16> %59, %56
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = add <8 x i16> %59, %57
  %63 = lshr <8 x i16> %62, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %61, <8 x i16> %63) #5
  %65 = bitcast i8* %54 to <16 x i8>*
  store <16 x i8> %64, <16 x i8>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %54, i64 %1
  %67 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %68 = mul nuw <8 x i16> %15, <i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196>
  %69 = mul <8 x i16> %18, <i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196, i16 196>
  %70 = bitcast <16 x i8> %67 to <8 x i16>
  %71 = add <8 x i16> %70, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %72 = add <8 x i16> %71, %68
  %73 = lshr <8 x i16> %72, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %74 = add <8 x i16> %71, %69
  %75 = lshr <8 x i16> %74, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %76 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %73, <8 x i16> %75) #5
  %77 = bitcast i8* %66 to <16 x i8>*
  store <16 x i8> %76, <16 x i8>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %66, i64 %1
  %79 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %80 = mul nuw <8 x i16> %15, <i16 182, i16 182, i16 182, i16 182, i16 182, i16 182, i16 182, i16 182>
  %81 = mul <8 x i16> %18, <i16 182, i16 182, i16 182, i16 182, i16 182, i16 182, i16 182, i16 182>
  %82 = bitcast <16 x i8> %79 to <8 x i16>
  %83 = add <8 x i16> %82, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %84 = add <8 x i16> %83, %80
  %85 = lshr <8 x i16> %84, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %86 = add <8 x i16> %83, %81
  %87 = lshr <8 x i16> %86, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %88 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> %87) #5
  %89 = bitcast i8* %78 to <16 x i8>*
  store <16 x i8> %88, <16 x i8>* %89, align 1
  %90 = getelementptr inbounds i8, i8* %78, i64 %1
  %91 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %92 = mul nuw <8 x i16> %15, <i16 169, i16 169, i16 169, i16 169, i16 169, i16 169, i16 169, i16 169>
  %93 = mul <8 x i16> %18, <i16 169, i16 169, i16 169, i16 169, i16 169, i16 169, i16 169, i16 169>
  %94 = bitcast <16 x i8> %91 to <8 x i16>
  %95 = add <8 x i16> %94, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %96 = add <8 x i16> %95, %92
  %97 = lshr <8 x i16> %96, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %98 = add <8 x i16> %95, %93
  %99 = lshr <8 x i16> %98, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %97, <8 x i16> %99) #5
  %101 = bitcast i8* %90 to <16 x i8>*
  store <16 x i8> %100, <16 x i8>* %101, align 1
  %102 = getelementptr inbounds i8, i8* %90, i64 %1
  %103 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %104 = mul nuw <8 x i16> %15, <i16 157, i16 157, i16 157, i16 157, i16 157, i16 157, i16 157, i16 157>
  %105 = mul <8 x i16> %18, <i16 157, i16 157, i16 157, i16 157, i16 157, i16 157, i16 157, i16 157>
  %106 = bitcast <16 x i8> %103 to <8 x i16>
  %107 = add <8 x i16> %106, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %108 = add <8 x i16> %107, %104
  %109 = lshr <8 x i16> %108, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %110 = add <8 x i16> %107, %105
  %111 = lshr <8 x i16> %110, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %112 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %111) #5
  %113 = bitcast i8* %102 to <16 x i8>*
  store <16 x i8> %112, <16 x i8>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %102, i64 %1
  %115 = mul <8 x i16> %9, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %116 = mul <8 x i16> %9, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %117 = bitcast <8 x i16> %115 to <16 x i8>
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %119 = mul nuw <8 x i16> %15, <i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145>
  %120 = mul <8 x i16> %18, <i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145, i16 145>
  %121 = bitcast <16 x i8> %118 to <8 x i16>
  %122 = add <8 x i16> %121, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %123 = add <8 x i16> %122, %119
  %124 = lshr <8 x i16> %123, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %125 = add <8 x i16> %122, %120
  %126 = lshr <8 x i16> %125, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %127 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %124, <8 x i16> %126) #5
  %128 = bitcast i8* %114 to <16 x i8>*
  store <16 x i8> %127, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %114, i64 %1
  %130 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %131 = mul nuw <8 x i16> %15, <i16 133, i16 133, i16 133, i16 133, i16 133, i16 133, i16 133, i16 133>
  %132 = mul <8 x i16> %18, <i16 133, i16 133, i16 133, i16 133, i16 133, i16 133, i16 133, i16 133>
  %133 = bitcast <16 x i8> %130 to <8 x i16>
  %134 = add <8 x i16> %133, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %135 = add <8 x i16> %134, %131
  %136 = lshr <8 x i16> %135, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %137 = add <8 x i16> %134, %132
  %138 = lshr <8 x i16> %137, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %139 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %136, <8 x i16> %138) #5
  %140 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %129, i64 %1
  %142 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %143 = mul nuw nsw <8 x i16> %15, <i16 122, i16 122, i16 122, i16 122, i16 122, i16 122, i16 122, i16 122>
  %144 = mul <8 x i16> %18, <i16 122, i16 122, i16 122, i16 122, i16 122, i16 122, i16 122, i16 122>
  %145 = bitcast <16 x i8> %142 to <8 x i16>
  %146 = add <8 x i16> %145, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %147 = add <8 x i16> %146, %143
  %148 = lshr <8 x i16> %147, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %149 = add <8 x i16> %146, %144
  %150 = lshr <8 x i16> %149, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %151 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %148, <8 x i16> %150) #5
  %152 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %151, <16 x i8>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %141, i64 %1
  %154 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %155 = mul nuw nsw <8 x i16> %15, <i16 111, i16 111, i16 111, i16 111, i16 111, i16 111, i16 111, i16 111>
  %156 = mul <8 x i16> %18, <i16 111, i16 111, i16 111, i16 111, i16 111, i16 111, i16 111, i16 111>
  %157 = bitcast <16 x i8> %154 to <8 x i16>
  %158 = add <8 x i16> %157, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %159 = add <8 x i16> %158, %155
  %160 = lshr <8 x i16> %159, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %161 = add <8 x i16> %158, %156
  %162 = lshr <8 x i16> %161, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %163 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %160, <8 x i16> %162) #5
  %164 = bitcast i8* %153 to <16 x i8>*
  store <16 x i8> %163, <16 x i8>* %164, align 1
  %165 = getelementptr inbounds i8, i8* %153, i64 %1
  %166 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %167 = mul nuw nsw <8 x i16> %15, <i16 101, i16 101, i16 101, i16 101, i16 101, i16 101, i16 101, i16 101>
  %168 = mul <8 x i16> %18, <i16 101, i16 101, i16 101, i16 101, i16 101, i16 101, i16 101, i16 101>
  %169 = bitcast <16 x i8> %166 to <8 x i16>
  %170 = add <8 x i16> %169, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %171 = add <8 x i16> %170, %167
  %172 = lshr <8 x i16> %171, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %173 = add <8 x i16> %170, %168
  %174 = lshr <8 x i16> %173, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %175 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %172, <8 x i16> %174) #5
  %176 = bitcast i8* %165 to <16 x i8>*
  store <16 x i8> %175, <16 x i8>* %176, align 1
  %177 = getelementptr inbounds i8, i8* %165, i64 %1
  %178 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %179 = mul nuw nsw <8 x i16> %15, <i16 92, i16 92, i16 92, i16 92, i16 92, i16 92, i16 92, i16 92>
  %180 = mul <8 x i16> %18, <i16 92, i16 92, i16 92, i16 92, i16 92, i16 92, i16 92, i16 92>
  %181 = bitcast <16 x i8> %178 to <8 x i16>
  %182 = add <8 x i16> %181, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %183 = add <8 x i16> %182, %179
  %184 = lshr <8 x i16> %183, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %185 = add <8 x i16> %182, %180
  %186 = lshr <8 x i16> %185, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %187 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %184, <8 x i16> %186) #5
  %188 = bitcast i8* %177 to <16 x i8>*
  store <16 x i8> %187, <16 x i8>* %188, align 1
  %189 = getelementptr inbounds i8, i8* %177, i64 %1
  %190 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %191 = mul nuw nsw <8 x i16> %15, <i16 83, i16 83, i16 83, i16 83, i16 83, i16 83, i16 83, i16 83>
  %192 = mul <8 x i16> %18, <i16 83, i16 83, i16 83, i16 83, i16 83, i16 83, i16 83, i16 83>
  %193 = bitcast <16 x i8> %190 to <8 x i16>
  %194 = add <8 x i16> %193, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %195 = add <8 x i16> %194, %191
  %196 = lshr <8 x i16> %195, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %197 = add <8 x i16> %194, %192
  %198 = lshr <8 x i16> %197, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %199 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %196, <8 x i16> %198) #5
  %200 = bitcast i8* %189 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 1
  %201 = getelementptr inbounds i8, i8* %189, i64 %1
  %202 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %203 = mul nuw nsw <8 x i16> %15, <i16 74, i16 74, i16 74, i16 74, i16 74, i16 74, i16 74, i16 74>
  %204 = mul <8 x i16> %18, <i16 74, i16 74, i16 74, i16 74, i16 74, i16 74, i16 74, i16 74>
  %205 = bitcast <16 x i8> %202 to <8 x i16>
  %206 = add <8 x i16> %205, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %207 = add <8 x i16> %206, %203
  %208 = lshr <8 x i16> %207, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %209 = add <8 x i16> %206, %204
  %210 = lshr <8 x i16> %209, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %211 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %208, <8 x i16> %210) #5
  %212 = bitcast i8* %201 to <16 x i8>*
  store <16 x i8> %211, <16 x i8>* %212, align 1
  %213 = getelementptr inbounds i8, i8* %201, i64 %1
  %214 = bitcast <8 x i16> %11 to <16 x i8>
  %215 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %216 = mul nuw nsw <8 x i16> %15, <i16 66, i16 66, i16 66, i16 66, i16 66, i16 66, i16 66, i16 66>
  %217 = mul <8 x i16> %18, <i16 66, i16 66, i16 66, i16 66, i16 66, i16 66, i16 66, i16 66>
  %218 = bitcast <16 x i8> %215 to <8 x i16>
  %219 = add <8 x i16> %218, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %220 = add <8 x i16> %219, %216
  %221 = lshr <8 x i16> %220, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %222 = add <8 x i16> %219, %217
  %223 = lshr <8 x i16> %222, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %224 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %221, <8 x i16> %223) #5
  %225 = bitcast i8* %213 to <16 x i8>*
  store <16 x i8> %224, <16 x i8>* %225, align 1
  %226 = getelementptr inbounds i8, i8* %213, i64 %1
  %227 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %228 = mul nuw nsw <8 x i16> %15, <i16 59, i16 59, i16 59, i16 59, i16 59, i16 59, i16 59, i16 59>
  %229 = mul <8 x i16> %18, <i16 59, i16 59, i16 59, i16 59, i16 59, i16 59, i16 59, i16 59>
  %230 = bitcast <16 x i8> %227 to <8 x i16>
  %231 = add <8 x i16> %230, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %232 = add <8 x i16> %231, %228
  %233 = lshr <8 x i16> %232, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %234 = add <8 x i16> %231, %229
  %235 = lshr <8 x i16> %234, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %236 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %233, <8 x i16> %235) #5
  %237 = bitcast i8* %226 to <16 x i8>*
  store <16 x i8> %236, <16 x i8>* %237, align 1
  %238 = getelementptr inbounds i8, i8* %226, i64 %1
  %239 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %240 = mul nuw nsw <8 x i16> %15, <i16 52, i16 52, i16 52, i16 52, i16 52, i16 52, i16 52, i16 52>
  %241 = mul <8 x i16> %18, <i16 52, i16 52, i16 52, i16 52, i16 52, i16 52, i16 52, i16 52>
  %242 = bitcast <16 x i8> %239 to <8 x i16>
  %243 = add <8 x i16> %242, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %244 = add <8 x i16> %243, %240
  %245 = lshr <8 x i16> %244, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %246 = add <8 x i16> %243, %241
  %247 = lshr <8 x i16> %246, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %248 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %245, <8 x i16> %247) #5
  %249 = bitcast i8* %238 to <16 x i8>*
  store <16 x i8> %248, <16 x i8>* %249, align 1
  %250 = getelementptr inbounds i8, i8* %238, i64 %1
  %251 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %252 = mul nuw nsw <8 x i16> %15, <i16 45, i16 45, i16 45, i16 45, i16 45, i16 45, i16 45, i16 45>
  %253 = mul <8 x i16> %18, <i16 45, i16 45, i16 45, i16 45, i16 45, i16 45, i16 45, i16 45>
  %254 = bitcast <16 x i8> %251 to <8 x i16>
  %255 = add <8 x i16> %254, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %256 = add <8 x i16> %255, %252
  %257 = lshr <8 x i16> %256, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %258 = add <8 x i16> %255, %253
  %259 = lshr <8 x i16> %258, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %257, <8 x i16> %259) #5
  %261 = bitcast i8* %250 to <16 x i8>*
  store <16 x i8> %260, <16 x i8>* %261, align 1
  %262 = getelementptr inbounds i8, i8* %250, i64 %1
  %263 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %264 = mul nuw nsw <8 x i16> %15, <i16 39, i16 39, i16 39, i16 39, i16 39, i16 39, i16 39, i16 39>
  %265 = mul <8 x i16> %18, <i16 39, i16 39, i16 39, i16 39, i16 39, i16 39, i16 39, i16 39>
  %266 = bitcast <16 x i8> %263 to <8 x i16>
  %267 = add <8 x i16> %266, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %268 = add <8 x i16> %267, %264
  %269 = lshr <8 x i16> %268, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %270 = add <8 x i16> %267, %265
  %271 = lshr <8 x i16> %270, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %272 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %269, <8 x i16> %271) #5
  %273 = bitcast i8* %262 to <16 x i8>*
  store <16 x i8> %272, <16 x i8>* %273, align 1
  %274 = getelementptr inbounds i8, i8* %262, i64 %1
  %275 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %276 = mul nuw nsw <8 x i16> %15, <i16 34, i16 34, i16 34, i16 34, i16 34, i16 34, i16 34, i16 34>
  %277 = mul <8 x i16> %18, <i16 34, i16 34, i16 34, i16 34, i16 34, i16 34, i16 34, i16 34>
  %278 = bitcast <16 x i8> %275 to <8 x i16>
  %279 = add <8 x i16> %278, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %280 = add <8 x i16> %279, %276
  %281 = lshr <8 x i16> %280, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %282 = add <8 x i16> %279, %277
  %283 = lshr <8 x i16> %282, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %284 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %281, <8 x i16> %283) #5
  %285 = bitcast i8* %274 to <16 x i8>*
  store <16 x i8> %284, <16 x i8>* %285, align 1
  %286 = getelementptr inbounds i8, i8* %274, i64 %1
  %287 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %288 = mul nuw nsw <8 x i16> %15, <i16 29, i16 29, i16 29, i16 29, i16 29, i16 29, i16 29, i16 29>
  %289 = mul <8 x i16> %18, <i16 29, i16 29, i16 29, i16 29, i16 29, i16 29, i16 29, i16 29>
  %290 = bitcast <16 x i8> %287 to <8 x i16>
  %291 = add <8 x i16> %290, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %292 = add <8 x i16> %291, %288
  %293 = lshr <8 x i16> %292, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %294 = add <8 x i16> %291, %289
  %295 = lshr <8 x i16> %294, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %296 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %293, <8 x i16> %295) #5
  %297 = bitcast i8* %286 to <16 x i8>*
  store <16 x i8> %296, <16 x i8>* %297, align 1
  %298 = getelementptr inbounds i8, i8* %286, i64 %1
  %299 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %300 = mul nuw nsw <8 x i16> %15, <i16 25, i16 25, i16 25, i16 25, i16 25, i16 25, i16 25, i16 25>
  %301 = mul <8 x i16> %18, <i16 25, i16 25, i16 25, i16 25, i16 25, i16 25, i16 25, i16 25>
  %302 = bitcast <16 x i8> %299 to <8 x i16>
  %303 = add <8 x i16> %302, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %304 = add <8 x i16> %303, %300
  %305 = lshr <8 x i16> %304, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %306 = add <8 x i16> %303, %301
  %307 = lshr <8 x i16> %306, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %308 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %305, <8 x i16> %307) #5
  %309 = bitcast i8* %298 to <16 x i8>*
  store <16 x i8> %308, <16 x i8>* %309, align 1
  %310 = getelementptr inbounds i8, i8* %298, i64 %1
  %311 = bitcast <8 x i16> %116 to <16 x i8>
  %312 = shufflevector <16 x i8> %311, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %313 = mul nuw nsw <8 x i16> %15, <i16 21, i16 21, i16 21, i16 21, i16 21, i16 21, i16 21, i16 21>
  %314 = mul <8 x i16> %18, <i16 21, i16 21, i16 21, i16 21, i16 21, i16 21, i16 21, i16 21>
  %315 = bitcast <16 x i8> %312 to <8 x i16>
  %316 = add <8 x i16> %315, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %317 = add <8 x i16> %316, %313
  %318 = lshr <8 x i16> %317, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %319 = add <8 x i16> %316, %314
  %320 = lshr <8 x i16> %319, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %321 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %318, <8 x i16> %320) #5
  %322 = bitcast i8* %310 to <16 x i8>*
  store <16 x i8> %321, <16 x i8>* %322, align 1
  %323 = getelementptr inbounds i8, i8* %310, i64 %1
  %324 = shufflevector <16 x i8> %311, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %325 = mul nuw nsw <8 x i16> %15, <i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17>
  %326 = mul <8 x i16> %18, <i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17, i16 17>
  %327 = bitcast <16 x i8> %324 to <8 x i16>
  %328 = add <8 x i16> %327, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %329 = add <8 x i16> %328, %325
  %330 = lshr <8 x i16> %329, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %331 = add <8 x i16> %328, %326
  %332 = lshr <8 x i16> %331, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %333 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %330, <8 x i16> %332) #5
  %334 = bitcast i8* %323 to <16 x i8>*
  store <16 x i8> %333, <16 x i8>* %334, align 1
  %335 = getelementptr inbounds i8, i8* %323, i64 %1
  %336 = shufflevector <16 x i8> %311, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %337 = mul nuw nsw <8 x i16> %15, <i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14>
  %338 = mul <8 x i16> %18, <i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14>
  %339 = bitcast <16 x i8> %336 to <8 x i16>
  %340 = add <8 x i16> %339, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %341 = add <8 x i16> %340, %337
  %342 = lshr <8 x i16> %341, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %343 = add <8 x i16> %340, %338
  %344 = lshr <8 x i16> %343, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %345 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %342, <8 x i16> %344) #5
  %346 = bitcast i8* %335 to <16 x i8>*
  store <16 x i8> %345, <16 x i8>* %346, align 1
  %347 = getelementptr inbounds i8, i8* %335, i64 %1
  %348 = shufflevector <16 x i8> %311, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %349 = mul nuw nsw <8 x i16> %15, <i16 12, i16 12, i16 12, i16 12, i16 12, i16 12, i16 12, i16 12>
  %350 = mul <8 x i16> %18, <i16 12, i16 12, i16 12, i16 12, i16 12, i16 12, i16 12, i16 12>
  %351 = bitcast <16 x i8> %348 to <8 x i16>
  %352 = add <8 x i16> %351, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %353 = add <8 x i16> %352, %349
  %354 = lshr <8 x i16> %353, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %355 = add <8 x i16> %352, %350
  %356 = lshr <8 x i16> %355, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %357 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %354, <8 x i16> %356) #5
  %358 = bitcast i8* %347 to <16 x i8>*
  store <16 x i8> %357, <16 x i8>* %358, align 1
  %359 = getelementptr inbounds i8, i8* %347, i64 %1
  %360 = shufflevector <16 x i8> %311, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %361 = mul nuw nsw <8 x i16> %15, <i16 10, i16 10, i16 10, i16 10, i16 10, i16 10, i16 10, i16 10>
  %362 = mul <8 x i16> %18, <i16 10, i16 10, i16 10, i16 10, i16 10, i16 10, i16 10, i16 10>
  %363 = bitcast <16 x i8> %360 to <8 x i16>
  %364 = add <8 x i16> %363, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %365 = add <8 x i16> %364, %361
  %366 = lshr <8 x i16> %365, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %367 = add <8 x i16> %364, %362
  %368 = lshr <8 x i16> %367, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %369 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %366, <8 x i16> %368) #5
  %370 = bitcast i8* %359 to <16 x i8>*
  store <16 x i8> %369, <16 x i8>* %370, align 1
  %371 = getelementptr inbounds i8, i8* %359, i64 %1
  %372 = shufflevector <16 x i8> %311, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %373 = mul nuw nsw <8 x i16> %15, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %374 = mul <8 x i16> %18, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %375 = bitcast <16 x i8> %372 to <8 x i16>
  %376 = add <8 x i16> %375, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %377 = add <8 x i16> %376, %373
  %378 = lshr <8 x i16> %377, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %379 = add <8 x i16> %376, %374
  %380 = lshr <8 x i16> %379, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %378, <8 x i16> %380) #5
  %382 = bitcast i8* %371 to <16 x i8>*
  store <16 x i8> %381, <16 x i8>* %382, align 1
  %383 = getelementptr inbounds i8, i8* %371, i64 %1
  %384 = shufflevector <16 x i8> %311, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %385 = shl nuw nsw <8 x i16> %15, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %386 = shl <8 x i16> %18, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %387 = bitcast <16 x i8> %384 to <8 x i16>
  %388 = add <8 x i16> %387, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %389 = add <8 x i16> %388, %385
  %390 = lshr <8 x i16> %389, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %391 = add <8 x i16> %388, %386
  %392 = lshr <8 x i16> %391, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %393 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %390, <8 x i16> %392) #5
  %394 = bitcast i8* %383 to <16 x i8>*
  store <16 x i8> %393, <16 x i8>* %394, align 1
  %395 = getelementptr inbounds i8, i8* %383, i64 %1
  %396 = shufflevector <16 x i8> %311, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %397 = shl nuw nsw <8 x i16> %15, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %398 = shl <8 x i16> %18, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %399 = bitcast <16 x i8> %396 to <8 x i16>
  %400 = add <8 x i16> %399, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %401 = add <8 x i16> %400, %397
  %402 = lshr <8 x i16> %401, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %403 = add <8 x i16> %400, %398
  %404 = lshr <8 x i16> %403, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %405 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %402, <8 x i16> %404) #5
  %406 = bitcast i8* %395 to <16 x i8>*
  store <16 x i8> %405, <16 x i8>* %406, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical16x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = shufflevector <16 x i8> %11, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %13 = zext <8 x i8> %12 to <8 x i16>
  %14 = shufflevector <16 x i8> %11, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %15 = bitcast <16 x i8> %14 to <8 x i16>
  br label %17

16:                                               ; preds = %17
  ret void

17:                                               ; preds = %4, %17
  %18 = phi i64 [ 0, %4 ], [ %258, %17 ]
  %19 = phi i8* [ %0, %4 ], [ %257, %17 ]
  %20 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %18
  %21 = bitcast i8* %20 to <16 x i8>*
  %22 = load <16 x i8>, <16 x i8>* %21, align 4
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %24 = zext <8 x i8> %23 to <8 x i16>
  %25 = shufflevector <16 x i8> %22, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %26 = sub nuw nsw <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %24
  %27 = bitcast <16 x i8> %25 to <8 x i16>
  %28 = mul <8 x i16> %26, %9
  %29 = bitcast <8 x i16> %24 to <16 x i8>
  %30 = bitcast <8 x i16> %28 to <16 x i8>
  %31 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %32 = shufflevector <16 x i8> %30, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %33 = bitcast <16 x i8> %31 to <8 x i16>
  %34 = mul <8 x i16> %33, %13
  %35 = mul <8 x i16> %33, %15
  %36 = bitcast <16 x i8> %32 to <8 x i16>
  %37 = add <8 x i16> %36, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %38 = add <8 x i16> %37, %34
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = add <8 x i16> %37, %35
  %41 = lshr <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %39, <8 x i16> %41) #5
  %43 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %19, i64 %1
  %45 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %46 = shufflevector <16 x i8> %30, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %47 = bitcast <16 x i8> %45 to <8 x i16>
  %48 = mul <8 x i16> %47, %13
  %49 = mul <8 x i16> %47, %15
  %50 = bitcast <16 x i8> %46 to <8 x i16>
  %51 = add <8 x i16> %50, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %52 = add <8 x i16> %51, %48
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = add <8 x i16> %51, %49
  %55 = lshr <8 x i16> %54, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %55) #5
  %57 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %44, i64 %1
  %59 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %60 = shufflevector <16 x i8> %30, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %61 = bitcast <16 x i8> %59 to <8 x i16>
  %62 = mul <8 x i16> %61, %13
  %63 = mul <8 x i16> %61, %15
  %64 = bitcast <16 x i8> %60 to <8 x i16>
  %65 = add <8 x i16> %64, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %66 = add <8 x i16> %65, %62
  %67 = lshr <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = add <8 x i16> %65, %63
  %69 = lshr <8 x i16> %68, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %70 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> %69) #5
  %71 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %58, i64 %1
  %73 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %74 = shufflevector <16 x i8> %30, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %75 = bitcast <16 x i8> %73 to <8 x i16>
  %76 = mul <8 x i16> %75, %13
  %77 = mul <8 x i16> %75, %15
  %78 = bitcast <16 x i8> %74 to <8 x i16>
  %79 = add <8 x i16> %78, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %80 = add <8 x i16> %79, %76
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = add <8 x i16> %79, %77
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %83) #5
  %85 = bitcast i8* %72 to <16 x i8>*
  store <16 x i8> %84, <16 x i8>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %72, i64 %1
  %87 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %88 = shufflevector <16 x i8> %30, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %89 = bitcast <16 x i8> %87 to <8 x i16>
  %90 = mul <8 x i16> %89, %13
  %91 = mul <8 x i16> %89, %15
  %92 = bitcast <16 x i8> %88 to <8 x i16>
  %93 = add <8 x i16> %92, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %94 = add <8 x i16> %93, %90
  %95 = lshr <8 x i16> %94, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %96 = add <8 x i16> %93, %91
  %97 = lshr <8 x i16> %96, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %98 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %95, <8 x i16> %97) #5
  %99 = bitcast i8* %86 to <16 x i8>*
  store <16 x i8> %98, <16 x i8>* %99, align 1
  %100 = getelementptr inbounds i8, i8* %86, i64 %1
  %101 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %102 = shufflevector <16 x i8> %30, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %103 = bitcast <16 x i8> %101 to <8 x i16>
  %104 = mul <8 x i16> %103, %13
  %105 = mul <8 x i16> %103, %15
  %106 = bitcast <16 x i8> %102 to <8 x i16>
  %107 = add <8 x i16> %106, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %108 = add <8 x i16> %107, %104
  %109 = lshr <8 x i16> %108, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %110 = add <8 x i16> %107, %105
  %111 = lshr <8 x i16> %110, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %112 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %111) #5
  %113 = bitcast i8* %100 to <16 x i8>*
  store <16 x i8> %112, <16 x i8>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %100, i64 %1
  %115 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %116 = shufflevector <16 x i8> %30, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %117 = bitcast <16 x i8> %115 to <8 x i16>
  %118 = mul <8 x i16> %117, %13
  %119 = mul <8 x i16> %117, %15
  %120 = bitcast <16 x i8> %116 to <8 x i16>
  %121 = add <8 x i16> %120, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %122 = add <8 x i16> %121, %118
  %123 = lshr <8 x i16> %122, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %124 = add <8 x i16> %121, %119
  %125 = lshr <8 x i16> %124, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %126 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %123, <8 x i16> %125) #5
  %127 = bitcast i8* %114 to <16 x i8>*
  store <16 x i8> %126, <16 x i8>* %127, align 1
  %128 = getelementptr inbounds i8, i8* %114, i64 %1
  %129 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %130 = shufflevector <16 x i8> %30, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %131 = bitcast <16 x i8> %129 to <8 x i16>
  %132 = mul <8 x i16> %131, %13
  %133 = mul <8 x i16> %131, %15
  %134 = bitcast <16 x i8> %130 to <8 x i16>
  %135 = add <8 x i16> %134, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %136 = add <8 x i16> %135, %132
  %137 = lshr <8 x i16> %136, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %138 = add <8 x i16> %135, %133
  %139 = lshr <8 x i16> %138, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %140 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %137, <8 x i16> %139) #5
  %141 = bitcast i8* %128 to <16 x i8>*
  store <16 x i8> %140, <16 x i8>* %141, align 1
  %142 = getelementptr inbounds i8, i8* %128, i64 %1
  %143 = sub <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %27
  %144 = mul <8 x i16> %143, %9
  %145 = bitcast <8 x i16> %144 to <16 x i8>
  %146 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %147 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %148 = bitcast <16 x i8> %146 to <8 x i16>
  %149 = mul <8 x i16> %148, %13
  %150 = mul <8 x i16> %148, %15
  %151 = bitcast <16 x i8> %147 to <8 x i16>
  %152 = add <8 x i16> %151, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %153 = add <8 x i16> %152, %149
  %154 = lshr <8 x i16> %153, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %155 = add <8 x i16> %152, %150
  %156 = lshr <8 x i16> %155, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %156) #5
  %158 = bitcast i8* %142 to <16 x i8>*
  store <16 x i8> %157, <16 x i8>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %142, i64 %1
  %160 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %161 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %162 = bitcast <16 x i8> %160 to <8 x i16>
  %163 = mul <8 x i16> %162, %13
  %164 = mul <8 x i16> %162, %15
  %165 = bitcast <16 x i8> %161 to <8 x i16>
  %166 = add <8 x i16> %165, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %167 = add <8 x i16> %166, %163
  %168 = lshr <8 x i16> %167, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %169 = add <8 x i16> %166, %164
  %170 = lshr <8 x i16> %169, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %171 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %168, <8 x i16> %170) #5
  %172 = bitcast i8* %159 to <16 x i8>*
  store <16 x i8> %171, <16 x i8>* %172, align 1
  %173 = getelementptr inbounds i8, i8* %159, i64 %1
  %174 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %175 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %176 = bitcast <16 x i8> %174 to <8 x i16>
  %177 = mul <8 x i16> %176, %13
  %178 = mul <8 x i16> %176, %15
  %179 = bitcast <16 x i8> %175 to <8 x i16>
  %180 = add <8 x i16> %179, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %181 = add <8 x i16> %180, %177
  %182 = lshr <8 x i16> %181, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %183 = add <8 x i16> %180, %178
  %184 = lshr <8 x i16> %183, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %185 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %184) #5
  %186 = bitcast i8* %173 to <16 x i8>*
  store <16 x i8> %185, <16 x i8>* %186, align 1
  %187 = getelementptr inbounds i8, i8* %173, i64 %1
  %188 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %189 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %190 = bitcast <16 x i8> %188 to <8 x i16>
  %191 = mul <8 x i16> %190, %13
  %192 = mul <8 x i16> %190, %15
  %193 = bitcast <16 x i8> %189 to <8 x i16>
  %194 = add <8 x i16> %193, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %195 = add <8 x i16> %194, %191
  %196 = lshr <8 x i16> %195, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %197 = add <8 x i16> %194, %192
  %198 = lshr <8 x i16> %197, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %199 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %196, <8 x i16> %198) #5
  %200 = bitcast i8* %187 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 1
  %201 = getelementptr inbounds i8, i8* %187, i64 %1
  %202 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %203 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %204 = bitcast <16 x i8> %202 to <8 x i16>
  %205 = mul <8 x i16> %204, %13
  %206 = mul <8 x i16> %204, %15
  %207 = bitcast <16 x i8> %203 to <8 x i16>
  %208 = add <8 x i16> %207, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %209 = add <8 x i16> %208, %205
  %210 = lshr <8 x i16> %209, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %211 = add <8 x i16> %208, %206
  %212 = lshr <8 x i16> %211, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %213 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %210, <8 x i16> %212) #5
  %214 = bitcast i8* %201 to <16 x i8>*
  store <16 x i8> %213, <16 x i8>* %214, align 1
  %215 = getelementptr inbounds i8, i8* %201, i64 %1
  %216 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %217 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %218 = bitcast <16 x i8> %216 to <8 x i16>
  %219 = mul <8 x i16> %218, %13
  %220 = mul <8 x i16> %218, %15
  %221 = bitcast <16 x i8> %217 to <8 x i16>
  %222 = add <8 x i16> %221, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %223 = add <8 x i16> %222, %219
  %224 = lshr <8 x i16> %223, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %225 = add <8 x i16> %222, %220
  %226 = lshr <8 x i16> %225, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %227 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %224, <8 x i16> %226) #5
  %228 = bitcast i8* %215 to <16 x i8>*
  store <16 x i8> %227, <16 x i8>* %228, align 1
  %229 = getelementptr inbounds i8, i8* %215, i64 %1
  %230 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %231 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %232 = bitcast <16 x i8> %230 to <8 x i16>
  %233 = mul <8 x i16> %232, %13
  %234 = mul <8 x i16> %232, %15
  %235 = bitcast <16 x i8> %231 to <8 x i16>
  %236 = add <8 x i16> %235, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %237 = add <8 x i16> %236, %233
  %238 = lshr <8 x i16> %237, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %239 = add <8 x i16> %236, %234
  %240 = lshr <8 x i16> %239, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %241 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %238, <8 x i16> %240) #5
  %242 = bitcast i8* %229 to <16 x i8>*
  store <16 x i8> %241, <16 x i8>* %242, align 1
  %243 = getelementptr inbounds i8, i8* %229, i64 %1
  %244 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %245 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %246 = bitcast <16 x i8> %244 to <8 x i16>
  %247 = mul <8 x i16> %246, %13
  %248 = mul <8 x i16> %246, %15
  %249 = bitcast <16 x i8> %245 to <8 x i16>
  %250 = add <8 x i16> %249, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %251 = add <8 x i16> %250, %247
  %252 = lshr <8 x i16> %251, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %253 = add <8 x i16> %250, %248
  %254 = lshr <8 x i16> %253, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %252, <8 x i16> %254) #5
  %256 = bitcast i8* %243 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 1
  %257 = getelementptr inbounds i8, i8* %243, i64 %1
  %258 = add nuw nsw i64 %18, 16
  %259 = icmp ult i64 %258, 64
  br i1 %259, label %17, label %16
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_125SmoothVertical32x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = shufflevector <16 x i8> %11, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = shufflevector <16 x i8> %11, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %18 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %14, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %21 = mul <8 x i16> %9, <i16 1, i16 59, i16 110, i16 151, i16 183, i16 206, i16 219, i16 224>
  %22 = bitcast <8 x i16> %21 to <16 x i8>
  %23 = bitcast <16 x i8> %17 to <8 x i16>
  %24 = bitcast <16 x i8> %20 to <8 x i16>
  br label %26

25:                                               ; preds = %26
  ret void

26:                                               ; preds = %4, %26
  %27 = phi i8* [ %0, %4 ], [ %54, %26 ]
  %28 = phi i32 [ 16777472, %4 ], [ %55, %26 ]
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = bitcast <4 x i32> %30 to <16 x i8>
  %32 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -1, i8 0, i8 -59, i8 0, i8 -110, i8 0, i8 105, i8 0, i8 73, i8 0, i8 50, i8 0, i8 37, i8 0, i8 32, i8 0>, <16 x i8> %31) #5
  %33 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %22, <16 x i8> %31) #5
  %34 = bitcast <16 x i8> %32 to <8 x i16>
  %35 = mul <8 x i16> %34, %16
  %36 = mul <8 x i16> %34, %23
  %37 = bitcast <16 x i8> %33 to <8 x i16>
  %38 = add <8 x i16> %37, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %39 = add <8 x i16> %38, %35
  %40 = lshr <8 x i16> %39, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %41 = add <8 x i16> %38, %36
  %42 = lshr <8 x i16> %41, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %43 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %40, <8 x i16> %42) #5
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = mul <8 x i16> %34, %19
  %47 = mul <8 x i16> %34, %24
  %48 = add <8 x i16> %38, %46
  %49 = lshr <8 x i16> %48, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %50 = add <8 x i16> %38, %47
  %51 = lshr <8 x i16> %50, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %52 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %49, <8 x i16> %51) #5
  %53 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %52, <16 x i8>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %27, i64 %1
  %55 = add nuw nsw i32 %28, 33686018
  %56 = icmp ult i32 %55, 252579599
  br i1 %56, label %26, label %25
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical32x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = shufflevector <16 x i8> %11, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = shufflevector <16 x i8> %11, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %18 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %14, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %21 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %22 = bitcast <8 x i16> %21 to <16 x i8>
  %23 = bitcast <16 x i8> %17 to <8 x i16>
  %24 = bitcast <16 x i8> %20 to <8 x i16>
  br label %28

25:                                               ; preds = %28
  %26 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  br label %60

28:                                               ; preds = %4, %28
  %29 = phi i8* [ %0, %4 ], [ %56, %28 ]
  %30 = phi i32 [ 16777472, %4 ], [ %57, %28 ]
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = bitcast <4 x i32> %32 to <16 x i8>
  %34 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -1, i8 0, i8 -31, i8 0, i8 -60, i8 0, i8 -86, i8 0, i8 -111, i8 0, i8 123, i8 0, i8 102, i8 0, i8 84, i8 0>, <16 x i8> %33) #5
  %35 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %22, <16 x i8> %33) #5
  %36 = bitcast <16 x i8> %34 to <8 x i16>
  %37 = mul <8 x i16> %36, %16
  %38 = mul <8 x i16> %36, %23
  %39 = bitcast <16 x i8> %35 to <8 x i16>
  %40 = add <8 x i16> %39, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %41 = add <8 x i16> %40, %37
  %42 = lshr <8 x i16> %41, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %43 = add <8 x i16> %40, %38
  %44 = lshr <8 x i16> %43, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %45 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %42, <8 x i16> %44) #5
  %46 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %45, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = mul <8 x i16> %36, %19
  %49 = mul <8 x i16> %36, %24
  %50 = add <8 x i16> %40, %48
  %51 = lshr <8 x i16> %50, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %52 = add <8 x i16> %40, %49
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %51, <8 x i16> %53) #5
  %55 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %54, <16 x i8>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %29, i64 %1
  %57 = add nuw nsw i32 %30, 33686018
  %58 = icmp ult i32 %57, 252579599
  br i1 %58, label %28, label %25

59:                                               ; preds = %60
  ret void

60:                                               ; preds = %25, %60
  %61 = phi i8* [ %56, %25 ], [ %88, %60 ]
  %62 = phi i32 [ 16777472, %25 ], [ %89, %60 ]
  %63 = insertelement <4 x i32> undef, i32 %62, i32 0
  %64 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> zeroinitializer
  %65 = bitcast <4 x i32> %64 to <16 x i8>
  %66 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 68, i8 0, i8 54, i8 0, i8 43, i8 0, i8 33, i8 0, i8 26, i8 0, i8 20, i8 0, i8 17, i8 0, i8 16, i8 0>, <16 x i8> %65) #5
  %67 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %27, <16 x i8> %65) #5
  %68 = bitcast <16 x i8> %66 to <8 x i16>
  %69 = mul <8 x i16> %68, %16
  %70 = mul <8 x i16> %68, %23
  %71 = bitcast <16 x i8> %67 to <8 x i16>
  %72 = add <8 x i16> %71, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %73 = add <8 x i16> %72, %69
  %74 = lshr <8 x i16> %73, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %75 = add <8 x i16> %72, %70
  %76 = lshr <8 x i16> %75, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %77 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %74, <8 x i16> %76) #5
  %78 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %61, i64 16
  %80 = mul <8 x i16> %68, %19
  %81 = mul <8 x i16> %68, %24
  %82 = add <8 x i16> %72, %80
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = add <8 x i16> %72, %81
  %85 = lshr <8 x i16> %84, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %86 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %83, <8 x i16> %85) #5
  %87 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %86, <16 x i8>* %87, align 1
  %88 = getelementptr inbounds i8, i8* %61, i64 %1
  %89 = add nuw nsw i32 %62, 33686018
  %90 = icmp ult i32 %89, 252579599
  br i1 %90, label %60, label %59
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical32x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = shufflevector <16 x i8> %11, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = shufflevector <16 x i8> %11, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %18 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %14, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %21 = mul <8 x i16> %9, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %22 = mul <8 x i16> %9, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %23 = bitcast <8 x i16> %21 to <16 x i8>
  %24 = bitcast <16 x i8> %17 to <8 x i16>
  %25 = bitcast <16 x i8> %20 to <8 x i16>
  br label %30

26:                                               ; preds = %30
  %27 = mul <8 x i16> %9, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %28 = mul <8 x i16> %9, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %29 = bitcast <8 x i16> %27 to <16 x i8>
  br label %63

30:                                               ; preds = %4, %30
  %31 = phi i8* [ %0, %4 ], [ %58, %30 ]
  %32 = phi i32 [ 16777472, %4 ], [ %59, %30 ]
  %33 = insertelement <4 x i32> undef, i32 %32, i32 0
  %34 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> zeroinitializer
  %35 = bitcast <4 x i32> %34 to <16 x i8>
  %36 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -1, i8 0, i8 -16, i8 0, i8 -31, i8 0, i8 -46, i8 0, i8 -60, i8 0, i8 -74, i8 0, i8 -87, i8 0, i8 -99, i8 0>, <16 x i8> %35) #5
  %37 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %23, <16 x i8> %35) #5
  %38 = bitcast <16 x i8> %36 to <8 x i16>
  %39 = mul <8 x i16> %38, %16
  %40 = mul <8 x i16> %38, %24
  %41 = bitcast <16 x i8> %37 to <8 x i16>
  %42 = add <8 x i16> %41, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %43 = add <8 x i16> %42, %39
  %44 = lshr <8 x i16> %43, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %45 = add <8 x i16> %42, %40
  %46 = lshr <8 x i16> %45, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %47 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %44, <8 x i16> %46) #5
  %48 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %31, i64 16
  %50 = mul <8 x i16> %38, %19
  %51 = mul <8 x i16> %38, %25
  %52 = add <8 x i16> %42, %50
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = add <8 x i16> %42, %51
  %55 = lshr <8 x i16> %54, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %55) #5
  %57 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %31, i64 %1
  %59 = add nuw nsw i32 %32, 33686018
  %60 = icmp ult i32 %59, 252579599
  br i1 %60, label %30, label %26

61:                                               ; preds = %63
  %62 = bitcast <8 x i16> %22 to <16 x i8>
  br label %96

63:                                               ; preds = %26, %63
  %64 = phi i8* [ %58, %26 ], [ %91, %63 ]
  %65 = phi i32 [ 16777472, %26 ], [ %92, %63 ]
  %66 = insertelement <4 x i32> undef, i32 %65, i32 0
  %67 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> zeroinitializer
  %68 = bitcast <4 x i32> %67 to <16 x i8>
  %69 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -111, i8 0, i8 -123, i8 0, i8 122, i8 0, i8 111, i8 0, i8 101, i8 0, i8 92, i8 0, i8 83, i8 0, i8 74, i8 0>, <16 x i8> %68) #5
  %70 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %29, <16 x i8> %68) #5
  %71 = bitcast <16 x i8> %69 to <8 x i16>
  %72 = mul <8 x i16> %71, %16
  %73 = mul <8 x i16> %71, %24
  %74 = bitcast <16 x i8> %70 to <8 x i16>
  %75 = add <8 x i16> %74, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %76 = add <8 x i16> %75, %72
  %77 = lshr <8 x i16> %76, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %78 = add <8 x i16> %75, %73
  %79 = lshr <8 x i16> %78, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %80 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %77, <8 x i16> %79) #5
  %81 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %80, <16 x i8>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %64, i64 16
  %83 = mul <8 x i16> %71, %19
  %84 = mul <8 x i16> %71, %25
  %85 = add <8 x i16> %75, %83
  %86 = lshr <8 x i16> %85, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %87 = add <8 x i16> %75, %84
  %88 = lshr <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %88) #5
  %90 = bitcast i8* %82 to <16 x i8>*
  store <16 x i8> %89, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %64, i64 %1
  %92 = add nuw nsw i32 %65, 33686018
  %93 = icmp ult i32 %92, 252579599
  br i1 %93, label %63, label %61

94:                                               ; preds = %96
  %95 = bitcast <8 x i16> %28 to <16 x i8>
  br label %128

96:                                               ; preds = %61, %96
  %97 = phi i8* [ %91, %61 ], [ %124, %96 ]
  %98 = phi i32 [ 16777472, %61 ], [ %125, %96 ]
  %99 = insertelement <4 x i32> undef, i32 %98, i32 0
  %100 = shufflevector <4 x i32> %99, <4 x i32> undef, <4 x i32> zeroinitializer
  %101 = bitcast <4 x i32> %100 to <16 x i8>
  %102 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 66, i8 0, i8 59, i8 0, i8 52, i8 0, i8 45, i8 0, i8 39, i8 0, i8 34, i8 0, i8 29, i8 0, i8 25, i8 0>, <16 x i8> %101) #5
  %103 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %62, <16 x i8> %101) #5
  %104 = bitcast <16 x i8> %102 to <8 x i16>
  %105 = mul <8 x i16> %104, %16
  %106 = mul <8 x i16> %104, %24
  %107 = bitcast <16 x i8> %103 to <8 x i16>
  %108 = add <8 x i16> %107, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %109 = add <8 x i16> %108, %105
  %110 = lshr <8 x i16> %109, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %111 = add <8 x i16> %108, %106
  %112 = lshr <8 x i16> %111, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %113 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %110, <8 x i16> %112) #5
  %114 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %113, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %97, i64 16
  %116 = mul <8 x i16> %104, %19
  %117 = mul <8 x i16> %104, %25
  %118 = add <8 x i16> %108, %116
  %119 = lshr <8 x i16> %118, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %120 = add <8 x i16> %108, %117
  %121 = lshr <8 x i16> %120, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %122 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> %121) #5
  %123 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %122, <16 x i8>* %123, align 1
  %124 = getelementptr inbounds i8, i8* %97, i64 %1
  %125 = add nuw nsw i32 %98, 33686018
  %126 = icmp ult i32 %125, 252579599
  br i1 %126, label %96, label %94

127:                                              ; preds = %128
  ret void

128:                                              ; preds = %94, %128
  %129 = phi i8* [ %124, %94 ], [ %156, %128 ]
  %130 = phi i32 [ 16777472, %94 ], [ %157, %128 ]
  %131 = insertelement <4 x i32> undef, i32 %130, i32 0
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> zeroinitializer
  %133 = bitcast <4 x i32> %132 to <16 x i8>
  %134 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 21, i8 0, i8 17, i8 0, i8 14, i8 0, i8 12, i8 0, i8 10, i8 0, i8 9, i8 0, i8 8, i8 0, i8 8, i8 0>, <16 x i8> %133) #5
  %135 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %95, <16 x i8> %133) #5
  %136 = bitcast <16 x i8> %134 to <8 x i16>
  %137 = mul <8 x i16> %136, %16
  %138 = mul <8 x i16> %136, %24
  %139 = bitcast <16 x i8> %135 to <8 x i16>
  %140 = add <8 x i16> %139, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %141 = add <8 x i16> %140, %137
  %142 = lshr <8 x i16> %141, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %143 = add <8 x i16> %140, %138
  %144 = lshr <8 x i16> %143, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %145 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %142, <8 x i16> %144) #5
  %146 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %145, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %129, i64 16
  %148 = mul <8 x i16> %136, %19
  %149 = mul <8 x i16> %136, %25
  %150 = add <8 x i16> %140, %148
  %151 = lshr <8 x i16> %150, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %152 = add <8 x i16> %140, %149
  %153 = lshr <8 x i16> %152, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %154 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %151, <8 x i16> %153) #5
  %155 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %154, <16 x i8>* %155, align 1
  %156 = getelementptr inbounds i8, i8* %129, i64 %1
  %157 = add nuw nsw i32 %130, 33686018
  %158 = icmp ult i32 %157, 252579599
  br i1 %158, label %128, label %127
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical32x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = shufflevector <16 x i8> %11, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = shufflevector <16 x i8> %11, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %18 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %14, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %21 = bitcast <16 x i8> %17 to <8 x i16>
  %22 = bitcast <16 x i8> %20 to <8 x i16>
  br label %24

23:                                               ; preds = %73
  ret void

24:                                               ; preds = %4, %73
  %25 = phi i64 [ 0, %4 ], [ %74, %73 ]
  %26 = phi i8* [ %0, %4 ], [ %104, %73 ]
  %27 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %25
  %28 = bitcast i8* %27 to <16 x i8>*
  %29 = load <16 x i8>, <16 x i8>* %28, align 4
  %30 = shufflevector <16 x i8> %29, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %31 = zext <8 x i8> %30 to <8 x i16>
  %32 = shufflevector <16 x i8> %29, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %33 = sub nuw nsw <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %31
  %34 = bitcast <16 x i8> %32 to <8 x i16>
  %35 = mul <8 x i16> %33, %9
  %36 = bitcast <8 x i16> %31 to <16 x i8>
  %37 = bitcast <8 x i16> %35 to <16 x i8>
  br label %42

38:                                               ; preds = %42
  %39 = sub <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %34
  %40 = mul <8 x i16> %39, %9
  %41 = bitcast <8 x i16> %40 to <16 x i8>
  br label %76

42:                                               ; preds = %24, %42
  %43 = phi i8* [ %26, %24 ], [ %70, %42 ]
  %44 = phi i32 [ 16777472, %24 ], [ %71, %42 ]
  %45 = insertelement <4 x i32> undef, i32 %44, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <4 x i32> %46 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %36, <16 x i8> %47) #5
  %49 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %37, <16 x i8> %47) #5
  %50 = bitcast <16 x i8> %48 to <8 x i16>
  %51 = mul <8 x i16> %50, %16
  %52 = mul <8 x i16> %50, %21
  %53 = bitcast <16 x i8> %49 to <8 x i16>
  %54 = add <8 x i16> %53, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %55 = add <8 x i16> %54, %51
  %56 = lshr <8 x i16> %55, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %57 = add <8 x i16> %54, %52
  %58 = lshr <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %56, <8 x i16> %58) #5
  %60 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %59, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %43, i64 16
  %62 = mul <8 x i16> %50, %19
  %63 = mul <8 x i16> %50, %22
  %64 = add <8 x i16> %54, %62
  %65 = lshr <8 x i16> %64, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %66 = add <8 x i16> %54, %63
  %67 = lshr <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %65, <8 x i16> %67) #5
  %69 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %68, <16 x i8>* %69, align 1
  %70 = getelementptr inbounds i8, i8* %43, i64 %1
  %71 = add nuw nsw i32 %44, 33686018
  %72 = icmp ult i32 %71, 252579599
  br i1 %72, label %42, label %38

73:                                               ; preds = %76
  %74 = add nuw nsw i64 %25, 16
  %75 = icmp ult i64 %74, 64
  br i1 %75, label %24, label %23

76:                                               ; preds = %38, %76
  %77 = phi i8* [ %70, %38 ], [ %104, %76 ]
  %78 = phi i32 [ 16777472, %38 ], [ %105, %76 ]
  %79 = insertelement <4 x i32> undef, i32 %78, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = bitcast <4 x i32> %80 to <16 x i8>
  %82 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %32, <16 x i8> %81) #5
  %83 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %41, <16 x i8> %81) #5
  %84 = bitcast <16 x i8> %82 to <8 x i16>
  %85 = mul <8 x i16> %84, %16
  %86 = mul <8 x i16> %84, %21
  %87 = bitcast <16 x i8> %83 to <8 x i16>
  %88 = add <8 x i16> %87, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %89 = add <8 x i16> %88, %85
  %90 = lshr <8 x i16> %89, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %91 = add <8 x i16> %88, %86
  %92 = lshr <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> %92) #5
  %94 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %93, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %77, i64 16
  %96 = mul <8 x i16> %84, %19
  %97 = mul <8 x i16> %84, %22
  %98 = add <8 x i16> %88, %96
  %99 = lshr <8 x i16> %98, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %100 = add <8 x i16> %88, %97
  %101 = lshr <8 x i16> %100, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %101) #5
  %103 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %102, <16 x i8>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %77, i64 %1
  %105 = add nuw nsw i32 %78, 33686018
  %106 = icmp ult i32 %105, 252579599
  br i1 %106, label %76, label %73
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical64x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = shufflevector <16 x i8> %11, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = shufflevector <16 x i8> %11, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %18 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %14, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %21 = getelementptr inbounds i8, i8* %2, i64 32
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = getelementptr inbounds i8, i8* %2, i64 48
  %25 = bitcast i8* %24 to <16 x i8>*
  %26 = load <16 x i8>, <16 x i8>* %25, align 1
  %27 = shufflevector <16 x i8> %23, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %28 = zext <8 x i8> %27 to <8 x i16>
  %29 = shufflevector <16 x i8> %23, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %30 = shufflevector <16 x i8> %26, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %31 = zext <8 x i8> %30 to <8 x i16>
  %32 = shufflevector <16 x i8> %26, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %33 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %34 = bitcast <8 x i16> %33 to <16 x i8>
  %35 = bitcast <16 x i8> %17 to <8 x i16>
  %36 = bitcast <16 x i8> %20 to <8 x i16>
  %37 = bitcast <16 x i8> %29 to <8 x i16>
  %38 = bitcast <16 x i8> %32 to <8 x i16>
  br label %42

39:                                               ; preds = %42
  %40 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %41 = bitcast <8 x i16> %40 to <16 x i8>
  br label %92

42:                                               ; preds = %4, %42
  %43 = phi i8* [ %0, %4 ], [ %88, %42 ]
  %44 = phi i32 [ 16777472, %4 ], [ %89, %42 ]
  %45 = insertelement <4 x i32> undef, i32 %44, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <4 x i32> %46 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -1, i8 0, i8 -31, i8 0, i8 -60, i8 0, i8 -86, i8 0, i8 -111, i8 0, i8 123, i8 0, i8 102, i8 0, i8 84, i8 0>, <16 x i8> %47) #5
  %49 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %34, <16 x i8> %47) #5
  %50 = bitcast <16 x i8> %48 to <8 x i16>
  %51 = mul <8 x i16> %50, %16
  %52 = mul <8 x i16> %50, %35
  %53 = bitcast <16 x i8> %49 to <8 x i16>
  %54 = add <8 x i16> %53, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %55 = add <8 x i16> %54, %51
  %56 = lshr <8 x i16> %55, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %57 = add <8 x i16> %54, %52
  %58 = lshr <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %56, <8 x i16> %58) #5
  %60 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %59, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %43, i64 16
  %62 = mul <8 x i16> %50, %19
  %63 = mul <8 x i16> %50, %36
  %64 = add <8 x i16> %54, %62
  %65 = lshr <8 x i16> %64, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %66 = add <8 x i16> %54, %63
  %67 = lshr <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %65, <8 x i16> %67) #5
  %69 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %68, <16 x i8>* %69, align 1
  %70 = getelementptr inbounds i8, i8* %43, i64 32
  %71 = mul <8 x i16> %50, %28
  %72 = mul <8 x i16> %50, %37
  %73 = add <8 x i16> %54, %71
  %74 = lshr <8 x i16> %73, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %75 = add <8 x i16> %54, %72
  %76 = lshr <8 x i16> %75, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %77 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %74, <8 x i16> %76) #5
  %78 = bitcast i8* %70 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %43, i64 48
  %80 = mul <8 x i16> %50, %31
  %81 = mul <8 x i16> %50, %38
  %82 = add <8 x i16> %54, %80
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = add <8 x i16> %54, %81
  %85 = lshr <8 x i16> %84, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %86 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %83, <8 x i16> %85) #5
  %87 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %86, <16 x i8>* %87, align 1
  %88 = getelementptr inbounds i8, i8* %43, i64 %1
  %89 = add nuw nsw i32 %44, 33686018
  %90 = icmp ult i32 %89, 252579599
  br i1 %90, label %42, label %39

91:                                               ; preds = %92
  ret void

92:                                               ; preds = %39, %92
  %93 = phi i8* [ %88, %39 ], [ %138, %92 ]
  %94 = phi i32 [ 16777472, %39 ], [ %139, %92 ]
  %95 = insertelement <4 x i32> undef, i32 %94, i32 0
  %96 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> zeroinitializer
  %97 = bitcast <4 x i32> %96 to <16 x i8>
  %98 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 68, i8 0, i8 54, i8 0, i8 43, i8 0, i8 33, i8 0, i8 26, i8 0, i8 20, i8 0, i8 17, i8 0, i8 16, i8 0>, <16 x i8> %97) #5
  %99 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %41, <16 x i8> %97) #5
  %100 = bitcast <16 x i8> %98 to <8 x i16>
  %101 = mul <8 x i16> %100, %16
  %102 = mul <8 x i16> %100, %35
  %103 = bitcast <16 x i8> %99 to <8 x i16>
  %104 = add <8 x i16> %103, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %105 = add <8 x i16> %104, %101
  %106 = lshr <8 x i16> %105, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %107 = add <8 x i16> %104, %102
  %108 = lshr <8 x i16> %107, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %109 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %106, <8 x i16> %108) #5
  %110 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %109, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %93, i64 16
  %112 = mul <8 x i16> %100, %19
  %113 = mul <8 x i16> %100, %36
  %114 = add <8 x i16> %104, %112
  %115 = lshr <8 x i16> %114, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %116 = add <8 x i16> %104, %113
  %117 = lshr <8 x i16> %116, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %118 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %115, <8 x i16> %117) #5
  %119 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %118, <16 x i8>* %119, align 1
  %120 = getelementptr inbounds i8, i8* %93, i64 32
  %121 = mul <8 x i16> %100, %28
  %122 = mul <8 x i16> %100, %37
  %123 = add <8 x i16> %104, %121
  %124 = lshr <8 x i16> %123, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %125 = add <8 x i16> %104, %122
  %126 = lshr <8 x i16> %125, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %127 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %124, <8 x i16> %126) #5
  %128 = bitcast i8* %120 to <16 x i8>*
  store <16 x i8> %127, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %93, i64 48
  %130 = mul <8 x i16> %100, %31
  %131 = mul <8 x i16> %100, %38
  %132 = add <8 x i16> %104, %130
  %133 = lshr <8 x i16> %132, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %134 = add <8 x i16> %104, %131
  %135 = lshr <8 x i16> %134, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %133, <8 x i16> %135) #5
  %137 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %136, <16 x i8>* %137, align 1
  %138 = getelementptr inbounds i8, i8* %93, i64 %1
  %139 = add nuw nsw i32 %94, 33686018
  %140 = icmp ult i32 %139, 252579599
  br i1 %140, label %92, label %91
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical64x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = shufflevector <16 x i8> %11, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = shufflevector <16 x i8> %11, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %18 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %14, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %21 = getelementptr inbounds i8, i8* %2, i64 32
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = getelementptr inbounds i8, i8* %2, i64 48
  %25 = bitcast i8* %24 to <16 x i8>*
  %26 = load <16 x i8>, <16 x i8>* %25, align 1
  %27 = shufflevector <16 x i8> %23, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %28 = zext <8 x i8> %27 to <8 x i16>
  %29 = shufflevector <16 x i8> %23, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %30 = shufflevector <16 x i8> %26, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %31 = zext <8 x i8> %30 to <8 x i16>
  %32 = shufflevector <16 x i8> %26, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %33 = mul <8 x i16> %9, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %34 = mul <8 x i16> %9, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %35 = bitcast <8 x i16> %33 to <16 x i8>
  %36 = bitcast <16 x i8> %17 to <8 x i16>
  %37 = bitcast <16 x i8> %20 to <8 x i16>
  %38 = bitcast <16 x i8> %29 to <8 x i16>
  %39 = bitcast <16 x i8> %32 to <8 x i16>
  br label %44

40:                                               ; preds = %44
  %41 = mul <8 x i16> %9, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %42 = mul <8 x i16> %9, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %43 = bitcast <8 x i16> %41 to <16 x i8>
  br label %95

44:                                               ; preds = %4, %44
  %45 = phi i8* [ %0, %4 ], [ %90, %44 ]
  %46 = phi i32 [ 16777472, %4 ], [ %91, %44 ]
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = bitcast <4 x i32> %48 to <16 x i8>
  %50 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -1, i8 0, i8 -16, i8 0, i8 -31, i8 0, i8 -46, i8 0, i8 -60, i8 0, i8 -74, i8 0, i8 -87, i8 0, i8 -99, i8 0>, <16 x i8> %49) #5
  %51 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %35, <16 x i8> %49) #5
  %52 = bitcast <16 x i8> %50 to <8 x i16>
  %53 = mul <8 x i16> %52, %16
  %54 = mul <8 x i16> %52, %36
  %55 = bitcast <16 x i8> %51 to <8 x i16>
  %56 = add <8 x i16> %55, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %57 = add <8 x i16> %56, %53
  %58 = lshr <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = add <8 x i16> %56, %54
  %60 = lshr <8 x i16> %59, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %61 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %58, <8 x i16> %60) #5
  %62 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %61, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %45, i64 16
  %64 = mul <8 x i16> %52, %19
  %65 = mul <8 x i16> %52, %37
  %66 = add <8 x i16> %56, %64
  %67 = lshr <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = add <8 x i16> %56, %65
  %69 = lshr <8 x i16> %68, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %70 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %67, <8 x i16> %69) #5
  %71 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %45, i64 32
  %73 = mul <8 x i16> %52, %28
  %74 = mul <8 x i16> %52, %38
  %75 = add <8 x i16> %56, %73
  %76 = lshr <8 x i16> %75, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %77 = add <8 x i16> %56, %74
  %78 = lshr <8 x i16> %77, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %79 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %76, <8 x i16> %78) #5
  %80 = bitcast i8* %72 to <16 x i8>*
  store <16 x i8> %79, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %45, i64 48
  %82 = mul <8 x i16> %52, %31
  %83 = mul <8 x i16> %52, %39
  %84 = add <8 x i16> %56, %82
  %85 = lshr <8 x i16> %84, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %86 = add <8 x i16> %56, %83
  %87 = lshr <8 x i16> %86, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %88 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> %87) #5
  %89 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %88, <16 x i8>* %89, align 1
  %90 = getelementptr inbounds i8, i8* %45, i64 %1
  %91 = add nuw nsw i32 %46, 33686018
  %92 = icmp ult i32 %91, 252579599
  br i1 %92, label %44, label %40

93:                                               ; preds = %95
  %94 = bitcast <8 x i16> %34 to <16 x i8>
  br label %146

95:                                               ; preds = %40, %95
  %96 = phi i8* [ %90, %40 ], [ %141, %95 ]
  %97 = phi i32 [ 16777472, %40 ], [ %142, %95 ]
  %98 = insertelement <4 x i32> undef, i32 %97, i32 0
  %99 = shufflevector <4 x i32> %98, <4 x i32> undef, <4 x i32> zeroinitializer
  %100 = bitcast <4 x i32> %99 to <16 x i8>
  %101 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 -111, i8 0, i8 -123, i8 0, i8 122, i8 0, i8 111, i8 0, i8 101, i8 0, i8 92, i8 0, i8 83, i8 0, i8 74, i8 0>, <16 x i8> %100) #5
  %102 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %43, <16 x i8> %100) #5
  %103 = bitcast <16 x i8> %101 to <8 x i16>
  %104 = mul <8 x i16> %103, %16
  %105 = mul <8 x i16> %103, %36
  %106 = bitcast <16 x i8> %102 to <8 x i16>
  %107 = add <8 x i16> %106, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %108 = add <8 x i16> %107, %104
  %109 = lshr <8 x i16> %108, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %110 = add <8 x i16> %107, %105
  %111 = lshr <8 x i16> %110, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %112 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %111) #5
  %113 = bitcast i8* %96 to <16 x i8>*
  store <16 x i8> %112, <16 x i8>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %96, i64 16
  %115 = mul <8 x i16> %103, %19
  %116 = mul <8 x i16> %103, %37
  %117 = add <8 x i16> %107, %115
  %118 = lshr <8 x i16> %117, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %119 = add <8 x i16> %107, %116
  %120 = lshr <8 x i16> %119, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %121 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %120) #5
  %122 = bitcast i8* %114 to <16 x i8>*
  store <16 x i8> %121, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %96, i64 32
  %124 = mul <8 x i16> %103, %28
  %125 = mul <8 x i16> %103, %38
  %126 = add <8 x i16> %107, %124
  %127 = lshr <8 x i16> %126, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %128 = add <8 x i16> %107, %125
  %129 = lshr <8 x i16> %128, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %130 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %127, <8 x i16> %129) #5
  %131 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %130, <16 x i8>* %131, align 1
  %132 = getelementptr inbounds i8, i8* %96, i64 48
  %133 = mul <8 x i16> %103, %31
  %134 = mul <8 x i16> %103, %39
  %135 = add <8 x i16> %107, %133
  %136 = lshr <8 x i16> %135, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %137 = add <8 x i16> %107, %134
  %138 = lshr <8 x i16> %137, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %139 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %136, <8 x i16> %138) #5
  %140 = bitcast i8* %132 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %96, i64 %1
  %142 = add nuw nsw i32 %97, 33686018
  %143 = icmp ult i32 %142, 252579599
  br i1 %143, label %95, label %93

144:                                              ; preds = %146
  %145 = bitcast <8 x i16> %42 to <16 x i8>
  br label %196

146:                                              ; preds = %93, %146
  %147 = phi i8* [ %141, %93 ], [ %192, %146 ]
  %148 = phi i32 [ 16777472, %93 ], [ %193, %146 ]
  %149 = insertelement <4 x i32> undef, i32 %148, i32 0
  %150 = shufflevector <4 x i32> %149, <4 x i32> undef, <4 x i32> zeroinitializer
  %151 = bitcast <4 x i32> %150 to <16 x i8>
  %152 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 66, i8 0, i8 59, i8 0, i8 52, i8 0, i8 45, i8 0, i8 39, i8 0, i8 34, i8 0, i8 29, i8 0, i8 25, i8 0>, <16 x i8> %151) #5
  %153 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %94, <16 x i8> %151) #5
  %154 = bitcast <16 x i8> %152 to <8 x i16>
  %155 = mul <8 x i16> %154, %16
  %156 = mul <8 x i16> %154, %36
  %157 = bitcast <16 x i8> %153 to <8 x i16>
  %158 = add <8 x i16> %157, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %159 = add <8 x i16> %158, %155
  %160 = lshr <8 x i16> %159, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %161 = add <8 x i16> %158, %156
  %162 = lshr <8 x i16> %161, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %163 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %160, <8 x i16> %162) #5
  %164 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %163, <16 x i8>* %164, align 1
  %165 = getelementptr inbounds i8, i8* %147, i64 16
  %166 = mul <8 x i16> %154, %19
  %167 = mul <8 x i16> %154, %37
  %168 = add <8 x i16> %158, %166
  %169 = lshr <8 x i16> %168, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %170 = add <8 x i16> %158, %167
  %171 = lshr <8 x i16> %170, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %172 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %169, <8 x i16> %171) #5
  %173 = bitcast i8* %165 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 1
  %174 = getelementptr inbounds i8, i8* %147, i64 32
  %175 = mul <8 x i16> %154, %28
  %176 = mul <8 x i16> %154, %38
  %177 = add <8 x i16> %158, %175
  %178 = lshr <8 x i16> %177, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %179 = add <8 x i16> %158, %176
  %180 = lshr <8 x i16> %179, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %181 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %178, <8 x i16> %180) #5
  %182 = bitcast i8* %174 to <16 x i8>*
  store <16 x i8> %181, <16 x i8>* %182, align 1
  %183 = getelementptr inbounds i8, i8* %147, i64 48
  %184 = mul <8 x i16> %154, %31
  %185 = mul <8 x i16> %154, %39
  %186 = add <8 x i16> %158, %184
  %187 = lshr <8 x i16> %186, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %188 = add <8 x i16> %158, %185
  %189 = lshr <8 x i16> %188, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %189) #5
  %191 = bitcast i8* %183 to <16 x i8>*
  store <16 x i8> %190, <16 x i8>* %191, align 1
  %192 = getelementptr inbounds i8, i8* %147, i64 %1
  %193 = add nuw nsw i32 %148, 33686018
  %194 = icmp ult i32 %193, 252579599
  br i1 %194, label %146, label %144

195:                                              ; preds = %196
  ret void

196:                                              ; preds = %144, %196
  %197 = phi i8* [ %192, %144 ], [ %242, %196 ]
  %198 = phi i32 [ 16777472, %144 ], [ %243, %196 ]
  %199 = insertelement <4 x i32> undef, i32 %198, i32 0
  %200 = shufflevector <4 x i32> %199, <4 x i32> undef, <4 x i32> zeroinitializer
  %201 = bitcast <4 x i32> %200 to <16 x i8>
  %202 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> <i8 21, i8 0, i8 17, i8 0, i8 14, i8 0, i8 12, i8 0, i8 10, i8 0, i8 9, i8 0, i8 8, i8 0, i8 8, i8 0>, <16 x i8> %201) #5
  %203 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %145, <16 x i8> %201) #5
  %204 = bitcast <16 x i8> %202 to <8 x i16>
  %205 = mul <8 x i16> %204, %16
  %206 = mul <8 x i16> %204, %36
  %207 = bitcast <16 x i8> %203 to <8 x i16>
  %208 = add <8 x i16> %207, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %209 = add <8 x i16> %208, %205
  %210 = lshr <8 x i16> %209, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %211 = add <8 x i16> %208, %206
  %212 = lshr <8 x i16> %211, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %213 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %210, <8 x i16> %212) #5
  %214 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %213, <16 x i8>* %214, align 1
  %215 = getelementptr inbounds i8, i8* %197, i64 16
  %216 = mul <8 x i16> %204, %19
  %217 = mul <8 x i16> %204, %37
  %218 = add <8 x i16> %208, %216
  %219 = lshr <8 x i16> %218, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %220 = add <8 x i16> %208, %217
  %221 = lshr <8 x i16> %220, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %222 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %219, <8 x i16> %221) #5
  %223 = bitcast i8* %215 to <16 x i8>*
  store <16 x i8> %222, <16 x i8>* %223, align 1
  %224 = getelementptr inbounds i8, i8* %197, i64 32
  %225 = mul <8 x i16> %204, %28
  %226 = mul <8 x i16> %204, %38
  %227 = add <8 x i16> %208, %225
  %228 = lshr <8 x i16> %227, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %229 = add <8 x i16> %208, %226
  %230 = lshr <8 x i16> %229, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %231 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %228, <8 x i16> %230) #5
  %232 = bitcast i8* %224 to <16 x i8>*
  store <16 x i8> %231, <16 x i8>* %232, align 1
  %233 = getelementptr inbounds i8, i8* %197, i64 48
  %234 = mul <8 x i16> %204, %31
  %235 = mul <8 x i16> %204, %39
  %236 = add <8 x i16> %208, %234
  %237 = lshr <8 x i16> %236, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %238 = add <8 x i16> %208, %235
  %239 = lshr <8 x i16> %238, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %240 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %237, <8 x i16> %239) #5
  %241 = bitcast i8* %233 to <16 x i8>*
  store <16 x i8> %240, <16 x i8>* %241, align 1
  %242 = getelementptr inbounds i8, i8* %197, i64 %1
  %243 = add nuw nsw i32 %198, 33686018
  %244 = icmp ult i32 %243, 252579599
  br i1 %244, label %196, label %195
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothVertical64x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %3, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %2 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = shufflevector <16 x i8> %11, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = shufflevector <16 x i8> %11, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %18 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %14, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %21 = getelementptr inbounds i8, i8* %2, i64 32
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = getelementptr inbounds i8, i8* %2, i64 48
  %25 = bitcast i8* %24 to <16 x i8>*
  %26 = load <16 x i8>, <16 x i8>* %25, align 1
  %27 = shufflevector <16 x i8> %23, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %28 = zext <8 x i8> %27 to <8 x i16>
  %29 = shufflevector <16 x i8> %23, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %30 = shufflevector <16 x i8> %26, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %31 = zext <8 x i8> %30 to <8 x i16>
  %32 = shufflevector <16 x i8> %26, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %33 = bitcast <16 x i8> %17 to <8 x i16>
  %34 = bitcast <16 x i8> %20 to <8 x i16>
  %35 = bitcast <16 x i8> %29 to <8 x i16>
  %36 = bitcast <16 x i8> %32 to <8 x i16>
  br label %38

37:                                               ; preds = %105
  ret void

38:                                               ; preds = %4, %105
  %39 = phi i64 [ 0, %4 ], [ %106, %105 ]
  %40 = phi i8* [ %0, %4 ], [ %154, %105 ]
  %41 = getelementptr inbounds i8, i8* getelementptr inbounds ([124 x i8], [124 x i8]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114kSmoothWeightsE, i64 0, i64 60), i64 %39
  %42 = bitcast i8* %41 to <16 x i8>*
  %43 = load <16 x i8>, <16 x i8>* %42, align 4
  %44 = shufflevector <16 x i8> %43, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %45 = zext <8 x i8> %44 to <8 x i16>
  %46 = shufflevector <16 x i8> %43, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %47 = sub nuw nsw <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %45
  %48 = bitcast <16 x i8> %46 to <8 x i16>
  %49 = mul <8 x i16> %47, %9
  %50 = bitcast <8 x i16> %45 to <16 x i8>
  %51 = bitcast <8 x i16> %49 to <16 x i8>
  br label %56

52:                                               ; preds = %56
  %53 = sub <8 x i16> <i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256, i16 256>, %48
  %54 = mul <8 x i16> %53, %9
  %55 = bitcast <8 x i16> %54 to <16 x i8>
  br label %108

56:                                               ; preds = %38, %56
  %57 = phi i8* [ %40, %38 ], [ %102, %56 ]
  %58 = phi i32 [ 16777472, %38 ], [ %103, %56 ]
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = bitcast <4 x i32> %60 to <16 x i8>
  %62 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %50, <16 x i8> %61) #5
  %63 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %51, <16 x i8> %61) #5
  %64 = bitcast <16 x i8> %62 to <8 x i16>
  %65 = mul <8 x i16> %64, %16
  %66 = mul <8 x i16> %64, %33
  %67 = bitcast <16 x i8> %63 to <8 x i16>
  %68 = add <8 x i16> %67, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %69 = add <8 x i16> %68, %65
  %70 = lshr <8 x i16> %69, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %71 = add <8 x i16> %68, %66
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> %72) #5
  %74 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %57, i64 16
  %76 = mul <8 x i16> %64, %19
  %77 = mul <8 x i16> %64, %34
  %78 = add <8 x i16> %68, %76
  %79 = lshr <8 x i16> %78, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %80 = add <8 x i16> %68, %77
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %81) #5
  %83 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %82, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %57, i64 32
  %85 = mul <8 x i16> %64, %28
  %86 = mul <8 x i16> %64, %35
  %87 = add <8 x i16> %68, %85
  %88 = lshr <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = add <8 x i16> %68, %86
  %90 = lshr <8 x i16> %89, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %91 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %90) #5
  %92 = bitcast i8* %84 to <16 x i8>*
  store <16 x i8> %91, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %57, i64 48
  %94 = mul <8 x i16> %64, %31
  %95 = mul <8 x i16> %64, %36
  %96 = add <8 x i16> %68, %94
  %97 = lshr <8 x i16> %96, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %98 = add <8 x i16> %68, %95
  %99 = lshr <8 x i16> %98, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %97, <8 x i16> %99) #5
  %101 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %100, <16 x i8>* %101, align 1
  %102 = getelementptr inbounds i8, i8* %57, i64 %1
  %103 = add nuw nsw i32 %58, 33686018
  %104 = icmp ult i32 %103, 252579599
  br i1 %104, label %56, label %52

105:                                              ; preds = %108
  %106 = add nuw nsw i64 %39, 16
  %107 = icmp ult i64 %106, 64
  br i1 %107, label %38, label %37

108:                                              ; preds = %52, %108
  %109 = phi i8* [ %102, %52 ], [ %154, %108 ]
  %110 = phi i32 [ 16777472, %52 ], [ %155, %108 ]
  %111 = insertelement <4 x i32> undef, i32 %110, i32 0
  %112 = shufflevector <4 x i32> %111, <4 x i32> undef, <4 x i32> zeroinitializer
  %113 = bitcast <4 x i32> %112 to <16 x i8>
  %114 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %46, <16 x i8> %113) #5
  %115 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %55, <16 x i8> %113) #5
  %116 = bitcast <16 x i8> %114 to <8 x i16>
  %117 = mul <8 x i16> %116, %16
  %118 = mul <8 x i16> %116, %33
  %119 = bitcast <16 x i8> %115 to <8 x i16>
  %120 = add <8 x i16> %119, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %121 = add <8 x i16> %120, %117
  %122 = lshr <8 x i16> %121, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %123 = add <8 x i16> %120, %118
  %124 = lshr <8 x i16> %123, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %125 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %122, <8 x i16> %124) #5
  %126 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %125, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %109, i64 16
  %128 = mul <8 x i16> %116, %19
  %129 = mul <8 x i16> %116, %34
  %130 = add <8 x i16> %120, %128
  %131 = lshr <8 x i16> %130, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %132 = add <8 x i16> %120, %129
  %133 = lshr <8 x i16> %132, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %134 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %131, <8 x i16> %133) #5
  %135 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %134, <16 x i8>* %135, align 1
  %136 = getelementptr inbounds i8, i8* %109, i64 32
  %137 = mul <8 x i16> %116, %28
  %138 = mul <8 x i16> %116, %35
  %139 = add <8 x i16> %120, %137
  %140 = lshr <8 x i16> %139, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %141 = add <8 x i16> %120, %138
  %142 = lshr <8 x i16> %141, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %143 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %140, <8 x i16> %142) #5
  %144 = bitcast i8* %136 to <16 x i8>*
  store <16 x i8> %143, <16 x i8>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %109, i64 48
  %146 = mul <8 x i16> %116, %31
  %147 = mul <8 x i16> %116, %36
  %148 = add <8 x i16> %120, %146
  %149 = lshr <8 x i16> %148, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %150 = add <8 x i16> %120, %147
  %151 = lshr <8 x i16> %150, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %152 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %149, <8 x i16> %151) #5
  %153 = bitcast i8* %145 to <16 x i8>*
  store <16 x i8> %152, <16 x i8>* %153, align 1
  %154 = getelementptr inbounds i8, i8* %109, i64 %1
  %155 = add nuw nsw i32 %110, 33686018
  %156 = icmp ult i32 %155, 252579599
  br i1 %156, label %108, label %105
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothHorizontal4x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 3
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = shufflevector <4 x i32> %8, <4 x i32> undef, <4 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i32*
  %11 = load i32, i32* %10, align 1
  %12 = insertelement <4 x i32> undef, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %15 = zext <4 x i8> %14 to <4 x i32>
  %16 = bitcast <4 x i32> %9 to <8 x i16>
  %17 = mul <8 x i16> %16, <i16 1, i16 0, i16 107, i16 0, i16 171, i16 0, i16 192, i16 0>
  %18 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = bitcast <4 x i32> %18 to <8 x i16>
  %20 = mul <8 x i16> %19, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %21 = bitcast <8 x i16> %17 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = add <4 x i32> %21, <i32 128, i32 128, i32 128, i32 128>
  %24 = add <4 x i32> %23, %22
  %25 = lshr <4 x i32> %24, <i32 8, i32 8, i32 8, i32 8>
  %26 = bitcast <4 x i32> %25 to <16 x i8>
  %27 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %28 = bitcast <16 x i8> %27 to <4 x i32>
  %29 = extractelement <4 x i32> %28, i32 0
  %30 = bitcast i8* %0 to i32*
  store i32 %29, i32* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %1
  %32 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %33 = bitcast <4 x i32> %32 to <8 x i16>
  %34 = mul <8 x i16> %33, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %35 = bitcast <8 x i16> %34 to <4 x i32>
  %36 = add <4 x i32> %23, %35
  %37 = lshr <4 x i32> %36, <i32 8, i32 8, i32 8, i32 8>
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i8* %31 to i32*
  store i32 %41, i32* %42, align 1
  %43 = getelementptr inbounds i8, i8* %31, i64 %1
  %44 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %45 = bitcast <4 x i32> %44 to <8 x i16>
  %46 = mul <8 x i16> %45, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %47 = bitcast <8 x i16> %46 to <4 x i32>
  %48 = add <4 x i32> %23, %47
  %49 = lshr <4 x i32> %48, <i32 8, i32 8, i32 8, i32 8>
  %50 = bitcast <4 x i32> %49 to <16 x i8>
  %51 = shufflevector <16 x i8> %50, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %52 = bitcast <16 x i8> %51 to <4 x i32>
  %53 = extractelement <4 x i32> %52, i32 0
  %54 = bitcast i8* %43 to i32*
  store i32 %53, i32* %54, align 1
  %55 = getelementptr inbounds i8, i8* %43, i64 %1
  %56 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %57 = bitcast <4 x i32> %56 to <8 x i16>
  %58 = mul <8 x i16> %57, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %59 = bitcast <8 x i16> %58 to <4 x i32>
  %60 = add <4 x i32> %23, %59
  %61 = lshr <4 x i32> %60, <i32 8, i32 8, i32 8, i32 8>
  %62 = bitcast <4 x i32> %61 to <16 x i8>
  %63 = shufflevector <16 x i8> %62, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %64 = bitcast <16 x i8> %63 to <4 x i32>
  %65 = extractelement <4 x i32> %64, i32 0
  %66 = bitcast i8* %55 to i32*
  store i32 %65, i32* %66, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothHorizontal4x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 3
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = shufflevector <4 x i32> %8, <4 x i32> undef, <4 x i32> zeroinitializer
  %10 = bitcast <4 x i32> %9 to <8 x i16>
  %11 = mul <8 x i16> %10, <i16 1, i16 0, i16 107, i16 0, i16 171, i16 0, i16 192, i16 0>
  %12 = bitcast i8* %3 to i32*
  %13 = load i32, i32* %12, align 1
  %14 = insertelement <4 x i32> undef, i32 %13, i32 0
  %15 = bitcast <4 x i32> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i8> %16 to <4 x i32>
  %18 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = bitcast <4 x i32> %18 to <8 x i16>
  %20 = mul <8 x i16> %19, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %21 = bitcast <8 x i16> %11 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = add <4 x i32> %21, <i32 128, i32 128, i32 128, i32 128>
  %24 = add <4 x i32> %23, %22
  %25 = lshr <4 x i32> %24, <i32 8, i32 8, i32 8, i32 8>
  %26 = bitcast <4 x i32> %25 to <16 x i8>
  %27 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %28 = bitcast <16 x i8> %27 to <4 x i32>
  %29 = extractelement <4 x i32> %28, i32 0
  %30 = bitcast i8* %0 to i32*
  store i32 %29, i32* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %1
  %32 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %33 = bitcast <4 x i32> %32 to <8 x i16>
  %34 = mul <8 x i16> %33, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %35 = bitcast <8 x i16> %34 to <4 x i32>
  %36 = add <4 x i32> %23, %35
  %37 = lshr <4 x i32> %36, <i32 8, i32 8, i32 8, i32 8>
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i8* %31 to i32*
  store i32 %41, i32* %42, align 1
  %43 = getelementptr inbounds i8, i8* %31, i64 %1
  %44 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %45 = bitcast <4 x i32> %44 to <8 x i16>
  %46 = mul <8 x i16> %45, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %47 = bitcast <8 x i16> %46 to <4 x i32>
  %48 = add <4 x i32> %23, %47
  %49 = lshr <4 x i32> %48, <i32 8, i32 8, i32 8, i32 8>
  %50 = bitcast <4 x i32> %49 to <16 x i8>
  %51 = shufflevector <16 x i8> %50, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %52 = bitcast <16 x i8> %51 to <4 x i32>
  %53 = extractelement <4 x i32> %52, i32 0
  %54 = bitcast i8* %43 to i32*
  store i32 %53, i32* %54, align 1
  %55 = getelementptr inbounds i8, i8* %43, i64 %1
  %56 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %57 = bitcast <4 x i32> %56 to <8 x i16>
  %58 = mul <8 x i16> %57, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %59 = bitcast <8 x i16> %58 to <4 x i32>
  %60 = add <4 x i32> %23, %59
  %61 = lshr <4 x i32> %60, <i32 8, i32 8, i32 8, i32 8>
  %62 = bitcast <4 x i32> %61 to <16 x i8>
  %63 = shufflevector <16 x i8> %62, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %64 = bitcast <16 x i8> %63 to <4 x i32>
  %65 = extractelement <4 x i32> %64, i32 0
  %66 = bitcast i8* %55 to i32*
  store i32 %65, i32* %66, align 1
  %67 = getelementptr inbounds i8, i8* %55, i64 %1
  %68 = getelementptr inbounds i8, i8* %3, i64 4
  %69 = bitcast i8* %68 to i32*
  %70 = load i32, i32* %69, align 1
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = bitcast <4 x i32> %71 to <16 x i8>
  %73 = shufflevector <16 x i8> %72, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %74 = zext <4 x i8> %73 to <4 x i32>
  %75 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> zeroinitializer
  %76 = bitcast <4 x i32> %75 to <8 x i16>
  %77 = mul <8 x i16> %76, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %78 = bitcast <8 x i16> %77 to <4 x i32>
  %79 = add <4 x i32> %23, %78
  %80 = lshr <4 x i32> %79, <i32 8, i32 8, i32 8, i32 8>
  %81 = bitcast <4 x i32> %80 to <16 x i8>
  %82 = shufflevector <16 x i8> %81, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %83 = bitcast <16 x i8> %82 to <4 x i32>
  %84 = extractelement <4 x i32> %83, i32 0
  %85 = bitcast i8* %67 to i32*
  store i32 %84, i32* %85, align 1
  %86 = getelementptr inbounds i8, i8* %67, i64 %1
  %87 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %88 = bitcast <4 x i32> %87 to <8 x i16>
  %89 = mul <8 x i16> %88, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %90 = bitcast <8 x i16> %89 to <4 x i32>
  %91 = add <4 x i32> %23, %90
  %92 = lshr <4 x i32> %91, <i32 8, i32 8, i32 8, i32 8>
  %93 = bitcast <4 x i32> %92 to <16 x i8>
  %94 = shufflevector <16 x i8> %93, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %95 = bitcast <16 x i8> %94 to <4 x i32>
  %96 = extractelement <4 x i32> %95, i32 0
  %97 = bitcast i8* %86 to i32*
  store i32 %96, i32* %97, align 1
  %98 = getelementptr inbounds i8, i8* %86, i64 %1
  %99 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %100 = bitcast <4 x i32> %99 to <8 x i16>
  %101 = mul <8 x i16> %100, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %102 = bitcast <8 x i16> %101 to <4 x i32>
  %103 = add <4 x i32> %23, %102
  %104 = lshr <4 x i32> %103, <i32 8, i32 8, i32 8, i32 8>
  %105 = bitcast <4 x i32> %104 to <16 x i8>
  %106 = shufflevector <16 x i8> %105, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %107 = bitcast <16 x i8> %106 to <4 x i32>
  %108 = extractelement <4 x i32> %107, i32 0
  %109 = bitcast i8* %98 to i32*
  store i32 %108, i32* %109, align 1
  %110 = getelementptr inbounds i8, i8* %98, i64 %1
  %111 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %112 = bitcast <4 x i32> %111 to <8 x i16>
  %113 = mul <8 x i16> %112, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %114 = bitcast <8 x i16> %113 to <4 x i32>
  %115 = add <4 x i32> %23, %114
  %116 = lshr <4 x i32> %115, <i32 8, i32 8, i32 8, i32 8>
  %117 = bitcast <4 x i32> %116 to <16 x i8>
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %119 = bitcast <16 x i8> %118 to <4 x i32>
  %120 = extractelement <4 x i32> %119, i32 0
  %121 = bitcast i8* %110 to i32*
  store i32 %120, i32* %121, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal4x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 3
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = insertelement <4 x i32> undef, i32 %7, i32 0
  %9 = shufflevector <4 x i32> %8, <4 x i32> undef, <4 x i32> zeroinitializer
  %10 = bitcast <4 x i32> %9 to <8 x i16>
  %11 = mul <8 x i16> %10, <i16 1, i16 0, i16 107, i16 0, i16 171, i16 0, i16 192, i16 0>
  %12 = bitcast i8* %3 to i32*
  %13 = load i32, i32* %12, align 1
  %14 = insertelement <4 x i32> undef, i32 %13, i32 0
  %15 = bitcast <4 x i32> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i8> %16 to <4 x i32>
  %18 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = bitcast <4 x i32> %18 to <8 x i16>
  %20 = mul <8 x i16> %19, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %21 = bitcast <8 x i16> %11 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = add <4 x i32> %21, <i32 128, i32 128, i32 128, i32 128>
  %24 = add <4 x i32> %23, %22
  %25 = lshr <4 x i32> %24, <i32 8, i32 8, i32 8, i32 8>
  %26 = bitcast <4 x i32> %25 to <16 x i8>
  %27 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %28 = bitcast <16 x i8> %27 to <4 x i32>
  %29 = extractelement <4 x i32> %28, i32 0
  %30 = bitcast i8* %0 to i32*
  store i32 %29, i32* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %1
  %32 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %33 = bitcast <4 x i32> %32 to <8 x i16>
  %34 = mul <8 x i16> %33, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %35 = bitcast <8 x i16> %34 to <4 x i32>
  %36 = add <4 x i32> %23, %35
  %37 = lshr <4 x i32> %36, <i32 8, i32 8, i32 8, i32 8>
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i8* %31 to i32*
  store i32 %41, i32* %42, align 1
  %43 = getelementptr inbounds i8, i8* %31, i64 %1
  %44 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %45 = bitcast <4 x i32> %44 to <8 x i16>
  %46 = mul <8 x i16> %45, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %47 = bitcast <8 x i16> %46 to <4 x i32>
  %48 = add <4 x i32> %23, %47
  %49 = lshr <4 x i32> %48, <i32 8, i32 8, i32 8, i32 8>
  %50 = bitcast <4 x i32> %49 to <16 x i8>
  %51 = shufflevector <16 x i8> %50, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %52 = bitcast <16 x i8> %51 to <4 x i32>
  %53 = extractelement <4 x i32> %52, i32 0
  %54 = bitcast i8* %43 to i32*
  store i32 %53, i32* %54, align 1
  %55 = getelementptr inbounds i8, i8* %43, i64 %1
  %56 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %57 = bitcast <4 x i32> %56 to <8 x i16>
  %58 = mul <8 x i16> %57, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %59 = bitcast <8 x i16> %58 to <4 x i32>
  %60 = add <4 x i32> %23, %59
  %61 = lshr <4 x i32> %60, <i32 8, i32 8, i32 8, i32 8>
  %62 = bitcast <4 x i32> %61 to <16 x i8>
  %63 = shufflevector <16 x i8> %62, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %64 = bitcast <16 x i8> %63 to <4 x i32>
  %65 = extractelement <4 x i32> %64, i32 0
  %66 = bitcast i8* %55 to i32*
  store i32 %65, i32* %66, align 1
  %67 = getelementptr inbounds i8, i8* %55, i64 %1
  %68 = getelementptr inbounds i8, i8* %3, i64 4
  %69 = bitcast i8* %68 to i32*
  %70 = load i32, i32* %69, align 1
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = bitcast <4 x i32> %71 to <16 x i8>
  %73 = shufflevector <16 x i8> %72, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %74 = zext <4 x i8> %73 to <4 x i32>
  %75 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> zeroinitializer
  %76 = bitcast <4 x i32> %75 to <8 x i16>
  %77 = mul <8 x i16> %76, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %78 = bitcast <8 x i16> %77 to <4 x i32>
  %79 = add <4 x i32> %23, %78
  %80 = lshr <4 x i32> %79, <i32 8, i32 8, i32 8, i32 8>
  %81 = bitcast <4 x i32> %80 to <16 x i8>
  %82 = shufflevector <16 x i8> %81, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %83 = bitcast <16 x i8> %82 to <4 x i32>
  %84 = extractelement <4 x i32> %83, i32 0
  %85 = bitcast i8* %67 to i32*
  store i32 %84, i32* %85, align 1
  %86 = getelementptr inbounds i8, i8* %67, i64 %1
  %87 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %88 = bitcast <4 x i32> %87 to <8 x i16>
  %89 = mul <8 x i16> %88, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %90 = bitcast <8 x i16> %89 to <4 x i32>
  %91 = add <4 x i32> %23, %90
  %92 = lshr <4 x i32> %91, <i32 8, i32 8, i32 8, i32 8>
  %93 = bitcast <4 x i32> %92 to <16 x i8>
  %94 = shufflevector <16 x i8> %93, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %95 = bitcast <16 x i8> %94 to <4 x i32>
  %96 = extractelement <4 x i32> %95, i32 0
  %97 = bitcast i8* %86 to i32*
  store i32 %96, i32* %97, align 1
  %98 = getelementptr inbounds i8, i8* %86, i64 %1
  %99 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %100 = bitcast <4 x i32> %99 to <8 x i16>
  %101 = mul <8 x i16> %100, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %102 = bitcast <8 x i16> %101 to <4 x i32>
  %103 = add <4 x i32> %23, %102
  %104 = lshr <4 x i32> %103, <i32 8, i32 8, i32 8, i32 8>
  %105 = bitcast <4 x i32> %104 to <16 x i8>
  %106 = shufflevector <16 x i8> %105, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %107 = bitcast <16 x i8> %106 to <4 x i32>
  %108 = extractelement <4 x i32> %107, i32 0
  %109 = bitcast i8* %98 to i32*
  store i32 %108, i32* %109, align 1
  %110 = getelementptr inbounds i8, i8* %98, i64 %1
  %111 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %112 = bitcast <4 x i32> %111 to <8 x i16>
  %113 = mul <8 x i16> %112, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %114 = bitcast <8 x i16> %113 to <4 x i32>
  %115 = add <4 x i32> %23, %114
  %116 = lshr <4 x i32> %115, <i32 8, i32 8, i32 8, i32 8>
  %117 = bitcast <4 x i32> %116 to <16 x i8>
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %119 = bitcast <16 x i8> %118 to <4 x i32>
  %120 = extractelement <4 x i32> %119, i32 0
  %121 = bitcast i8* %110 to i32*
  store i32 %120, i32* %121, align 1
  %122 = getelementptr inbounds i8, i8* %110, i64 %1
  %123 = getelementptr inbounds i8, i8* %3, i64 8
  %124 = bitcast i8* %123 to i32*
  %125 = load i32, i32* %124, align 1
  %126 = insertelement <4 x i32> undef, i32 %125, i32 0
  %127 = bitcast <4 x i32> %126 to <16 x i8>
  %128 = shufflevector <16 x i8> %127, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %129 = zext <4 x i8> %128 to <4 x i32>
  %130 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> zeroinitializer
  %131 = bitcast <4 x i32> %130 to <8 x i16>
  %132 = mul <8 x i16> %131, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %133 = bitcast <8 x i16> %132 to <4 x i32>
  %134 = add <4 x i32> %23, %133
  %135 = lshr <4 x i32> %134, <i32 8, i32 8, i32 8, i32 8>
  %136 = bitcast <4 x i32> %135 to <16 x i8>
  %137 = shufflevector <16 x i8> %136, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %138 = bitcast <16 x i8> %137 to <4 x i32>
  %139 = extractelement <4 x i32> %138, i32 0
  %140 = bitcast i8* %122 to i32*
  store i32 %139, i32* %140, align 1
  %141 = getelementptr inbounds i8, i8* %122, i64 %1
  %142 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %143 = bitcast <4 x i32> %142 to <8 x i16>
  %144 = mul <8 x i16> %143, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %145 = bitcast <8 x i16> %144 to <4 x i32>
  %146 = add <4 x i32> %23, %145
  %147 = lshr <4 x i32> %146, <i32 8, i32 8, i32 8, i32 8>
  %148 = bitcast <4 x i32> %147 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %150 = bitcast <16 x i8> %149 to <4 x i32>
  %151 = extractelement <4 x i32> %150, i32 0
  %152 = bitcast i8* %141 to i32*
  store i32 %151, i32* %152, align 1
  %153 = getelementptr inbounds i8, i8* %141, i64 %1
  %154 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %155 = bitcast <4 x i32> %154 to <8 x i16>
  %156 = mul <8 x i16> %155, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %157 = bitcast <8 x i16> %156 to <4 x i32>
  %158 = add <4 x i32> %23, %157
  %159 = lshr <4 x i32> %158, <i32 8, i32 8, i32 8, i32 8>
  %160 = bitcast <4 x i32> %159 to <16 x i8>
  %161 = shufflevector <16 x i8> %160, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %162 = bitcast <16 x i8> %161 to <4 x i32>
  %163 = extractelement <4 x i32> %162, i32 0
  %164 = bitcast i8* %153 to i32*
  store i32 %163, i32* %164, align 1
  %165 = getelementptr inbounds i8, i8* %153, i64 %1
  %166 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %167 = bitcast <4 x i32> %166 to <8 x i16>
  %168 = mul <8 x i16> %167, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %169 = bitcast <8 x i16> %168 to <4 x i32>
  %170 = add <4 x i32> %23, %169
  %171 = lshr <4 x i32> %170, <i32 8, i32 8, i32 8, i32 8>
  %172 = bitcast <4 x i32> %171 to <16 x i8>
  %173 = shufflevector <16 x i8> %172, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %174 = bitcast <16 x i8> %173 to <4 x i32>
  %175 = extractelement <4 x i32> %174, i32 0
  %176 = bitcast i8* %165 to i32*
  store i32 %175, i32* %176, align 1
  %177 = getelementptr inbounds i8, i8* %165, i64 %1
  %178 = getelementptr inbounds i8, i8* %3, i64 12
  %179 = bitcast i8* %178 to i32*
  %180 = load i32, i32* %179, align 1
  %181 = insertelement <4 x i32> undef, i32 %180, i32 0
  %182 = bitcast <4 x i32> %181 to <16 x i8>
  %183 = shufflevector <16 x i8> %182, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %184 = zext <4 x i8> %183 to <4 x i32>
  %185 = shufflevector <4 x i32> %184, <4 x i32> undef, <4 x i32> zeroinitializer
  %186 = bitcast <4 x i32> %185 to <8 x i16>
  %187 = mul <8 x i16> %186, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %188 = bitcast <8 x i16> %187 to <4 x i32>
  %189 = add <4 x i32> %23, %188
  %190 = lshr <4 x i32> %189, <i32 8, i32 8, i32 8, i32 8>
  %191 = bitcast <4 x i32> %190 to <16 x i8>
  %192 = shufflevector <16 x i8> %191, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %193 = bitcast <16 x i8> %192 to <4 x i32>
  %194 = extractelement <4 x i32> %193, i32 0
  %195 = bitcast i8* %177 to i32*
  store i32 %194, i32* %195, align 1
  %196 = getelementptr inbounds i8, i8* %177, i64 %1
  %197 = shufflevector <4 x i32> %184, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %198 = bitcast <4 x i32> %197 to <8 x i16>
  %199 = mul <8 x i16> %198, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %200 = bitcast <8 x i16> %199 to <4 x i32>
  %201 = add <4 x i32> %23, %200
  %202 = lshr <4 x i32> %201, <i32 8, i32 8, i32 8, i32 8>
  %203 = bitcast <4 x i32> %202 to <16 x i8>
  %204 = shufflevector <16 x i8> %203, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %205 = bitcast <16 x i8> %204 to <4 x i32>
  %206 = extractelement <4 x i32> %205, i32 0
  %207 = bitcast i8* %196 to i32*
  store i32 %206, i32* %207, align 1
  %208 = getelementptr inbounds i8, i8* %196, i64 %1
  %209 = shufflevector <4 x i32> %184, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %210 = bitcast <4 x i32> %209 to <8 x i16>
  %211 = mul <8 x i16> %210, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %212 = bitcast <8 x i16> %211 to <4 x i32>
  %213 = add <4 x i32> %23, %212
  %214 = lshr <4 x i32> %213, <i32 8, i32 8, i32 8, i32 8>
  %215 = bitcast <4 x i32> %214 to <16 x i8>
  %216 = shufflevector <16 x i8> %215, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %217 = bitcast <16 x i8> %216 to <4 x i32>
  %218 = extractelement <4 x i32> %217, i32 0
  %219 = bitcast i8* %208 to i32*
  store i32 %218, i32* %219, align 1
  %220 = getelementptr inbounds i8, i8* %208, i64 %1
  %221 = shufflevector <4 x i32> %184, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %222 = bitcast <4 x i32> %221 to <8 x i16>
  %223 = mul <8 x i16> %222, <i16 255, i16 0, i16 149, i16 0, i16 85, i16 0, i16 64, i16 0>
  %224 = bitcast <8 x i16> %223 to <4 x i32>
  %225 = add <4 x i32> %23, %224
  %226 = lshr <4 x i32> %225, <i32 8, i32 8, i32 8, i32 8>
  %227 = bitcast <4 x i32> %226 to <16 x i8>
  %228 = shufflevector <16 x i8> %227, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %229 = bitcast <16 x i8> %228 to <4 x i32>
  %230 = extractelement <4 x i32> %229, i32 0
  %231 = bitcast i8* %220 to i32*
  store i32 %230, i32* %231, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothHorizontal8x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i32*
  %11 = load i32, i32* %10, align 1
  %12 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = mul <8 x i16> %9, <i16 1, i16 59, i16 110, i16 151, i16 183, i16 206, i16 219, i16 224>
  %17 = bitcast <8 x i16> %15 to <16 x i8>
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %19 = bitcast <16 x i8> %18 to <8 x i16>
  %20 = mul <8 x i16> %19, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %21 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %22 = add <8 x i16> %21, %20
  %23 = lshr <8 x i16> %22, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %24 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> undef) #5
  %25 = bitcast <16 x i8> %24 to <2 x i64>
  %26 = extractelement <2 x i64> %25, i32 0
  %27 = bitcast i8* %0 to i64*
  store i64 %26, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %30 = bitcast <16 x i8> %29 to <8 x i16>
  %31 = mul <8 x i16> %30, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %32 = add <8 x i16> %21, %31
  %33 = lshr <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %33, <8 x i16> undef) #5
  %35 = bitcast <16 x i8> %34 to <2 x i64>
  %36 = extractelement <2 x i64> %35, i32 0
  %37 = bitcast i8* %28 to i64*
  store i64 %36, i64* %37, align 1
  %38 = getelementptr inbounds i8, i8* %28, i64 %1
  %39 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = mul <8 x i16> %40, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %42 = add <8 x i16> %21, %41
  %43 = lshr <8 x i16> %42, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %44 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %43, <8 x i16> undef) #5
  %45 = bitcast <16 x i8> %44 to <2 x i64>
  %46 = extractelement <2 x i64> %45, i32 0
  %47 = bitcast i8* %38 to i64*
  store i64 %46, i64* %47, align 1
  %48 = getelementptr inbounds i8, i8* %38, i64 %1
  %49 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %50 = bitcast <16 x i8> %49 to <8 x i16>
  %51 = mul <8 x i16> %50, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %52 = add <8 x i16> %21, %51
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> undef) #5
  %55 = bitcast <16 x i8> %54 to <2 x i64>
  %56 = extractelement <2 x i64> %55, i32 0
  %57 = bitcast i8* %48 to i64*
  store i64 %56, i64* %57, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_126SmoothHorizontal8x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = mul <8 x i16> %9, <i16 1, i16 59, i16 110, i16 151, i16 183, i16 206, i16 219, i16 224>
  %17 = bitcast <8 x i16> %15 to <16 x i8>
  %18 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %19 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %20 = bitcast <16 x i8> %19 to <8 x i16>
  %21 = mul <8 x i16> %20, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %22 = add <8 x i16> %18, %21
  %23 = lshr <8 x i16> %22, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %24 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> undef) #5
  %25 = bitcast <16 x i8> %24 to <2 x i64>
  %26 = extractelement <2 x i64> %25, i32 0
  %27 = bitcast i8* %0 to i64*
  store i64 %26, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %30 = bitcast <16 x i8> %29 to <8 x i16>
  %31 = mul <8 x i16> %30, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %32 = add <8 x i16> %18, %31
  %33 = lshr <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %33, <8 x i16> undef) #5
  %35 = bitcast <16 x i8> %34 to <2 x i64>
  %36 = extractelement <2 x i64> %35, i32 0
  %37 = bitcast i8* %28 to i64*
  store i64 %36, i64* %37, align 1
  %38 = getelementptr inbounds i8, i8* %28, i64 %1
  %39 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = mul <8 x i16> %40, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %42 = add <8 x i16> %18, %41
  %43 = lshr <8 x i16> %42, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %44 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %43, <8 x i16> undef) #5
  %45 = bitcast <16 x i8> %44 to <2 x i64>
  %46 = extractelement <2 x i64> %45, i32 0
  %47 = bitcast i8* %38 to i64*
  store i64 %46, i64* %47, align 1
  %48 = getelementptr inbounds i8, i8* %38, i64 %1
  %49 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %50 = bitcast <16 x i8> %49 to <8 x i16>
  %51 = mul <8 x i16> %50, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %52 = add <8 x i16> %18, %51
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> undef) #5
  %55 = bitcast <16 x i8> %54 to <2 x i64>
  %56 = extractelement <2 x i64> %55, i32 0
  %57 = bitcast i8* %48 to i64*
  store i64 %56, i64* %57, align 1
  %58 = getelementptr inbounds i8, i8* %48, i64 %1
  %59 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %60 = bitcast <16 x i8> %59 to <8 x i16>
  %61 = mul <8 x i16> %60, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %62 = add <8 x i16> %18, %61
  %63 = lshr <8 x i16> %62, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> undef) #5
  %65 = bitcast <16 x i8> %64 to <2 x i64>
  %66 = extractelement <2 x i64> %65, i32 0
  %67 = bitcast i8* %58 to i64*
  store i64 %66, i64* %67, align 1
  %68 = getelementptr inbounds i8, i8* %58, i64 %1
  %69 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = mul <8 x i16> %70, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %72 = add <8 x i16> %18, %71
  %73 = lshr <8 x i16> %72, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %74 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %73, <8 x i16> undef) #5
  %75 = bitcast <16 x i8> %74 to <2 x i64>
  %76 = extractelement <2 x i64> %75, i32 0
  %77 = bitcast i8* %68 to i64*
  store i64 %76, i64* %77, align 1
  %78 = getelementptr inbounds i8, i8* %68, i64 %1
  %79 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %80 = bitcast <16 x i8> %79 to <8 x i16>
  %81 = mul <8 x i16> %80, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %82 = add <8 x i16> %18, %81
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %83, <8 x i16> undef) #5
  %85 = bitcast <16 x i8> %84 to <2 x i64>
  %86 = extractelement <2 x i64> %85, i32 0
  %87 = bitcast i8* %78 to i64*
  store i64 %86, i64* %87, align 1
  %88 = getelementptr inbounds i8, i8* %78, i64 %1
  %89 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %90 = bitcast <16 x i8> %89 to <8 x i16>
  %91 = mul <8 x i16> %90, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %92 = add <8 x i16> %18, %91
  %93 = lshr <8 x i16> %92, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %94 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %93, <8 x i16> undef) #5
  %95 = bitcast <16 x i8> %94 to <2 x i64>
  %96 = extractelement <2 x i64> %95, i32 0
  %97 = bitcast i8* %88 to i64*
  store i64 %96, i64* %97, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal8x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 59, i16 110, i16 151, i16 183, i16 206, i16 219, i16 224>
  %11 = bitcast i8* %3 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %16 to <16 x i8>
  %18 = add <8 x i16> %10, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %19 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %20 = bitcast <16 x i8> %19 to <8 x i16>
  %21 = mul <8 x i16> %20, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %22 = add <8 x i16> %18, %21
  %23 = lshr <8 x i16> %22, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %24 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> undef) #5
  %25 = bitcast <16 x i8> %24 to <2 x i64>
  %26 = extractelement <2 x i64> %25, i32 0
  %27 = bitcast i8* %0 to i64*
  store i64 %26, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %30 = bitcast <16 x i8> %29 to <8 x i16>
  %31 = mul <8 x i16> %30, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %32 = add <8 x i16> %18, %31
  %33 = lshr <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %33, <8 x i16> undef) #5
  %35 = bitcast <16 x i8> %34 to <2 x i64>
  %36 = extractelement <2 x i64> %35, i32 0
  %37 = bitcast i8* %28 to i64*
  store i64 %36, i64* %37, align 1
  %38 = getelementptr inbounds i8, i8* %28, i64 %1
  %39 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = mul <8 x i16> %40, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %42 = add <8 x i16> %18, %41
  %43 = lshr <8 x i16> %42, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %44 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %43, <8 x i16> undef) #5
  %45 = bitcast <16 x i8> %44 to <2 x i64>
  %46 = extractelement <2 x i64> %45, i32 0
  %47 = bitcast i8* %38 to i64*
  store i64 %46, i64* %47, align 1
  %48 = getelementptr inbounds i8, i8* %38, i64 %1
  %49 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %50 = bitcast <16 x i8> %49 to <8 x i16>
  %51 = mul <8 x i16> %50, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %52 = add <8 x i16> %18, %51
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> undef) #5
  %55 = bitcast <16 x i8> %54 to <2 x i64>
  %56 = extractelement <2 x i64> %55, i32 0
  %57 = bitcast i8* %48 to i64*
  store i64 %56, i64* %57, align 1
  %58 = getelementptr inbounds i8, i8* %48, i64 %1
  %59 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %60 = bitcast <16 x i8> %59 to <8 x i16>
  %61 = mul <8 x i16> %60, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %62 = add <8 x i16> %18, %61
  %63 = lshr <8 x i16> %62, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> undef) #5
  %65 = bitcast <16 x i8> %64 to <2 x i64>
  %66 = extractelement <2 x i64> %65, i32 0
  %67 = bitcast i8* %58 to i64*
  store i64 %66, i64* %67, align 1
  %68 = getelementptr inbounds i8, i8* %58, i64 %1
  %69 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = mul <8 x i16> %70, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %72 = add <8 x i16> %18, %71
  %73 = lshr <8 x i16> %72, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %74 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %73, <8 x i16> undef) #5
  %75 = bitcast <16 x i8> %74 to <2 x i64>
  %76 = extractelement <2 x i64> %75, i32 0
  %77 = bitcast i8* %68 to i64*
  store i64 %76, i64* %77, align 1
  %78 = getelementptr inbounds i8, i8* %68, i64 %1
  %79 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %80 = bitcast <16 x i8> %79 to <8 x i16>
  %81 = mul <8 x i16> %80, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %82 = add <8 x i16> %18, %81
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %83, <8 x i16> undef) #5
  %85 = bitcast <16 x i8> %84 to <2 x i64>
  %86 = extractelement <2 x i64> %85, i32 0
  %87 = bitcast i8* %78 to i64*
  store i64 %86, i64* %87, align 1
  %88 = getelementptr inbounds i8, i8* %78, i64 %1
  %89 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %90 = bitcast <16 x i8> %89 to <8 x i16>
  %91 = mul <8 x i16> %90, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %92 = add <8 x i16> %18, %91
  %93 = lshr <8 x i16> %92, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %94 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %93, <8 x i16> undef) #5
  %95 = bitcast <16 x i8> %94 to <2 x i64>
  %96 = extractelement <2 x i64> %95, i32 0
  %97 = bitcast i8* %88 to i64*
  store i64 %96, i64* %97, align 1
  %98 = getelementptr inbounds i8, i8* %88, i64 %1
  %99 = getelementptr inbounds i8, i8* %3, i64 8
  %100 = bitcast i8* %99 to i64*
  %101 = load i64, i64* %100, align 1
  %102 = insertelement <2 x i64> undef, i64 %101, i32 0
  %103 = bitcast <2 x i64> %102 to <16 x i8>
  %104 = shufflevector <16 x i8> %103, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %105 = zext <8 x i8> %104 to <8 x i16>
  %106 = bitcast <8 x i16> %105 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %108 = bitcast <16 x i8> %107 to <8 x i16>
  %109 = mul <8 x i16> %108, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %110 = add <8 x i16> %18, %109
  %111 = lshr <8 x i16> %110, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %112 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %111, <8 x i16> undef) #5
  %113 = bitcast <16 x i8> %112 to <2 x i64>
  %114 = extractelement <2 x i64> %113, i32 0
  %115 = bitcast i8* %98 to i64*
  store i64 %114, i64* %115, align 1
  %116 = getelementptr inbounds i8, i8* %98, i64 %1
  %117 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %118 = bitcast <16 x i8> %117 to <8 x i16>
  %119 = mul <8 x i16> %118, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %120 = add <8 x i16> %18, %119
  %121 = lshr <8 x i16> %120, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %122 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> undef) #5
  %123 = bitcast <16 x i8> %122 to <2 x i64>
  %124 = extractelement <2 x i64> %123, i32 0
  %125 = bitcast i8* %116 to i64*
  store i64 %124, i64* %125, align 1
  %126 = getelementptr inbounds i8, i8* %116, i64 %1
  %127 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %128 = bitcast <16 x i8> %127 to <8 x i16>
  %129 = mul <8 x i16> %128, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %130 = add <8 x i16> %18, %129
  %131 = lshr <8 x i16> %130, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %131, <8 x i16> undef) #5
  %133 = bitcast <16 x i8> %132 to <2 x i64>
  %134 = extractelement <2 x i64> %133, i32 0
  %135 = bitcast i8* %126 to i64*
  store i64 %134, i64* %135, align 1
  %136 = getelementptr inbounds i8, i8* %126, i64 %1
  %137 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %138 = bitcast <16 x i8> %137 to <8 x i16>
  %139 = mul <8 x i16> %138, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %140 = add <8 x i16> %18, %139
  %141 = lshr <8 x i16> %140, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %142 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %141, <8 x i16> undef) #5
  %143 = bitcast <16 x i8> %142 to <2 x i64>
  %144 = extractelement <2 x i64> %143, i32 0
  %145 = bitcast i8* %136 to i64*
  store i64 %144, i64* %145, align 1
  %146 = getelementptr inbounds i8, i8* %136, i64 %1
  %147 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %148 = bitcast <16 x i8> %147 to <8 x i16>
  %149 = mul <8 x i16> %148, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %150 = add <8 x i16> %18, %149
  %151 = lshr <8 x i16> %150, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %152 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %151, <8 x i16> undef) #5
  %153 = bitcast <16 x i8> %152 to <2 x i64>
  %154 = extractelement <2 x i64> %153, i32 0
  %155 = bitcast i8* %146 to i64*
  store i64 %154, i64* %155, align 1
  %156 = getelementptr inbounds i8, i8* %146, i64 %1
  %157 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %158 = bitcast <16 x i8> %157 to <8 x i16>
  %159 = mul <8 x i16> %158, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %160 = add <8 x i16> %18, %159
  %161 = lshr <8 x i16> %160, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %162 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> undef) #5
  %163 = bitcast <16 x i8> %162 to <2 x i64>
  %164 = extractelement <2 x i64> %163, i32 0
  %165 = bitcast i8* %156 to i64*
  store i64 %164, i64* %165, align 1
  %166 = getelementptr inbounds i8, i8* %156, i64 %1
  %167 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %168 = bitcast <16 x i8> %167 to <8 x i16>
  %169 = mul <8 x i16> %168, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %170 = add <8 x i16> %18, %169
  %171 = lshr <8 x i16> %170, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %172 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %171, <8 x i16> undef) #5
  %173 = bitcast <16 x i8> %172 to <2 x i64>
  %174 = extractelement <2 x i64> %173, i32 0
  %175 = bitcast i8* %166 to i64*
  store i64 %174, i64* %175, align 1
  %176 = getelementptr inbounds i8, i8* %166, i64 %1
  %177 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %178 = bitcast <16 x i8> %177 to <8 x i16>
  %179 = mul <8 x i16> %178, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %180 = add <8 x i16> %18, %179
  %181 = lshr <8 x i16> %180, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %182 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %181, <8 x i16> undef) #5
  %183 = bitcast <16 x i8> %182 to <2 x i64>
  %184 = extractelement <2 x i64> %183, i32 0
  %185 = bitcast i8* %176 to i64*
  store i64 %184, i64* %185, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal8x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 7
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 59, i16 110, i16 151, i16 183, i16 206, i16 219, i16 224>
  %11 = bitcast i8* %3 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %16 to <16 x i8>
  %18 = add <8 x i16> %10, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %19 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %20 = bitcast <16 x i8> %19 to <8 x i16>
  %21 = mul <8 x i16> %20, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %22 = add <8 x i16> %18, %21
  %23 = lshr <8 x i16> %22, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %24 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> undef) #5
  %25 = bitcast <16 x i8> %24 to <2 x i64>
  %26 = extractelement <2 x i64> %25, i32 0
  %27 = bitcast i8* %0 to i64*
  store i64 %26, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %30 = bitcast <16 x i8> %29 to <8 x i16>
  %31 = mul <8 x i16> %30, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %32 = add <8 x i16> %18, %31
  %33 = lshr <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %33, <8 x i16> undef) #5
  %35 = bitcast <16 x i8> %34 to <2 x i64>
  %36 = extractelement <2 x i64> %35, i32 0
  %37 = bitcast i8* %28 to i64*
  store i64 %36, i64* %37, align 1
  %38 = getelementptr inbounds i8, i8* %28, i64 %1
  %39 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = mul <8 x i16> %40, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %42 = add <8 x i16> %18, %41
  %43 = lshr <8 x i16> %42, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %44 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %43, <8 x i16> undef) #5
  %45 = bitcast <16 x i8> %44 to <2 x i64>
  %46 = extractelement <2 x i64> %45, i32 0
  %47 = bitcast i8* %38 to i64*
  store i64 %46, i64* %47, align 1
  %48 = getelementptr inbounds i8, i8* %38, i64 %1
  %49 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %50 = bitcast <16 x i8> %49 to <8 x i16>
  %51 = mul <8 x i16> %50, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %52 = add <8 x i16> %18, %51
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> undef) #5
  %55 = bitcast <16 x i8> %54 to <2 x i64>
  %56 = extractelement <2 x i64> %55, i32 0
  %57 = bitcast i8* %48 to i64*
  store i64 %56, i64* %57, align 1
  %58 = getelementptr inbounds i8, i8* %48, i64 %1
  %59 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %60 = bitcast <16 x i8> %59 to <8 x i16>
  %61 = mul <8 x i16> %60, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %62 = add <8 x i16> %18, %61
  %63 = lshr <8 x i16> %62, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> undef) #5
  %65 = bitcast <16 x i8> %64 to <2 x i64>
  %66 = extractelement <2 x i64> %65, i32 0
  %67 = bitcast i8* %58 to i64*
  store i64 %66, i64* %67, align 1
  %68 = getelementptr inbounds i8, i8* %58, i64 %1
  %69 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = mul <8 x i16> %70, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %72 = add <8 x i16> %18, %71
  %73 = lshr <8 x i16> %72, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %74 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %73, <8 x i16> undef) #5
  %75 = bitcast <16 x i8> %74 to <2 x i64>
  %76 = extractelement <2 x i64> %75, i32 0
  %77 = bitcast i8* %68 to i64*
  store i64 %76, i64* %77, align 1
  %78 = getelementptr inbounds i8, i8* %68, i64 %1
  %79 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %80 = bitcast <16 x i8> %79 to <8 x i16>
  %81 = mul <8 x i16> %80, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %82 = add <8 x i16> %18, %81
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %83, <8 x i16> undef) #5
  %85 = bitcast <16 x i8> %84 to <2 x i64>
  %86 = extractelement <2 x i64> %85, i32 0
  %87 = bitcast i8* %78 to i64*
  store i64 %86, i64* %87, align 1
  %88 = getelementptr inbounds i8, i8* %78, i64 %1
  %89 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %90 = bitcast <16 x i8> %89 to <8 x i16>
  %91 = mul <8 x i16> %90, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %92 = add <8 x i16> %18, %91
  %93 = lshr <8 x i16> %92, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %94 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %93, <8 x i16> undef) #5
  %95 = bitcast <16 x i8> %94 to <2 x i64>
  %96 = extractelement <2 x i64> %95, i32 0
  %97 = bitcast i8* %88 to i64*
  store i64 %96, i64* %97, align 1
  %98 = getelementptr inbounds i8, i8* %88, i64 %1
  %99 = getelementptr inbounds i8, i8* %3, i64 8
  %100 = bitcast i8* %99 to i64*
  %101 = load i64, i64* %100, align 1
  %102 = insertelement <2 x i64> undef, i64 %101, i32 0
  %103 = bitcast <2 x i64> %102 to <16 x i8>
  %104 = shufflevector <16 x i8> %103, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %105 = zext <8 x i8> %104 to <8 x i16>
  %106 = bitcast <8 x i16> %105 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %108 = bitcast <16 x i8> %107 to <8 x i16>
  %109 = mul <8 x i16> %108, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %110 = add <8 x i16> %18, %109
  %111 = lshr <8 x i16> %110, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %112 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %111, <8 x i16> undef) #5
  %113 = bitcast <16 x i8> %112 to <2 x i64>
  %114 = extractelement <2 x i64> %113, i32 0
  %115 = bitcast i8* %98 to i64*
  store i64 %114, i64* %115, align 1
  %116 = getelementptr inbounds i8, i8* %98, i64 %1
  %117 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %118 = bitcast <16 x i8> %117 to <8 x i16>
  %119 = mul <8 x i16> %118, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %120 = add <8 x i16> %18, %119
  %121 = lshr <8 x i16> %120, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %122 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> undef) #5
  %123 = bitcast <16 x i8> %122 to <2 x i64>
  %124 = extractelement <2 x i64> %123, i32 0
  %125 = bitcast i8* %116 to i64*
  store i64 %124, i64* %125, align 1
  %126 = getelementptr inbounds i8, i8* %116, i64 %1
  %127 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %128 = bitcast <16 x i8> %127 to <8 x i16>
  %129 = mul <8 x i16> %128, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %130 = add <8 x i16> %18, %129
  %131 = lshr <8 x i16> %130, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %131, <8 x i16> undef) #5
  %133 = bitcast <16 x i8> %132 to <2 x i64>
  %134 = extractelement <2 x i64> %133, i32 0
  %135 = bitcast i8* %126 to i64*
  store i64 %134, i64* %135, align 1
  %136 = getelementptr inbounds i8, i8* %126, i64 %1
  %137 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %138 = bitcast <16 x i8> %137 to <8 x i16>
  %139 = mul <8 x i16> %138, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %140 = add <8 x i16> %18, %139
  %141 = lshr <8 x i16> %140, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %142 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %141, <8 x i16> undef) #5
  %143 = bitcast <16 x i8> %142 to <2 x i64>
  %144 = extractelement <2 x i64> %143, i32 0
  %145 = bitcast i8* %136 to i64*
  store i64 %144, i64* %145, align 1
  %146 = getelementptr inbounds i8, i8* %136, i64 %1
  %147 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %148 = bitcast <16 x i8> %147 to <8 x i16>
  %149 = mul <8 x i16> %148, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %150 = add <8 x i16> %18, %149
  %151 = lshr <8 x i16> %150, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %152 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %151, <8 x i16> undef) #5
  %153 = bitcast <16 x i8> %152 to <2 x i64>
  %154 = extractelement <2 x i64> %153, i32 0
  %155 = bitcast i8* %146 to i64*
  store i64 %154, i64* %155, align 1
  %156 = getelementptr inbounds i8, i8* %146, i64 %1
  %157 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %158 = bitcast <16 x i8> %157 to <8 x i16>
  %159 = mul <8 x i16> %158, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %160 = add <8 x i16> %18, %159
  %161 = lshr <8 x i16> %160, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %162 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> undef) #5
  %163 = bitcast <16 x i8> %162 to <2 x i64>
  %164 = extractelement <2 x i64> %163, i32 0
  %165 = bitcast i8* %156 to i64*
  store i64 %164, i64* %165, align 1
  %166 = getelementptr inbounds i8, i8* %156, i64 %1
  %167 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %168 = bitcast <16 x i8> %167 to <8 x i16>
  %169 = mul <8 x i16> %168, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %170 = add <8 x i16> %18, %169
  %171 = lshr <8 x i16> %170, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %172 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %171, <8 x i16> undef) #5
  %173 = bitcast <16 x i8> %172 to <2 x i64>
  %174 = extractelement <2 x i64> %173, i32 0
  %175 = bitcast i8* %166 to i64*
  store i64 %174, i64* %175, align 1
  %176 = getelementptr inbounds i8, i8* %166, i64 %1
  %177 = shufflevector <16 x i8> %106, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %178 = bitcast <16 x i8> %177 to <8 x i16>
  %179 = mul <8 x i16> %178, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %180 = add <8 x i16> %18, %179
  %181 = lshr <8 x i16> %180, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %182 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %181, <8 x i16> undef) #5
  %183 = bitcast <16 x i8> %182 to <2 x i64>
  %184 = extractelement <2 x i64> %183, i32 0
  %185 = bitcast i8* %176 to i64*
  store i64 %184, i64* %185, align 1
  %186 = getelementptr inbounds i8, i8* %176, i64 %1
  %187 = getelementptr inbounds i8, i8* %3, i64 16
  %188 = bitcast i8* %187 to i64*
  %189 = load i64, i64* %188, align 1
  %190 = insertelement <2 x i64> undef, i64 %189, i32 0
  %191 = bitcast <2 x i64> %190 to <16 x i8>
  %192 = shufflevector <16 x i8> %191, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %193 = zext <8 x i8> %192 to <8 x i16>
  %194 = bitcast <8 x i16> %193 to <16 x i8>
  %195 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %196 = bitcast <16 x i8> %195 to <8 x i16>
  %197 = mul <8 x i16> %196, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %198 = add <8 x i16> %18, %197
  %199 = lshr <8 x i16> %198, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %200 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %199, <8 x i16> undef) #5
  %201 = bitcast <16 x i8> %200 to <2 x i64>
  %202 = extractelement <2 x i64> %201, i32 0
  %203 = bitcast i8* %186 to i64*
  store i64 %202, i64* %203, align 1
  %204 = getelementptr inbounds i8, i8* %186, i64 %1
  %205 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %206 = bitcast <16 x i8> %205 to <8 x i16>
  %207 = mul <8 x i16> %206, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %208 = add <8 x i16> %18, %207
  %209 = lshr <8 x i16> %208, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %210 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %209, <8 x i16> undef) #5
  %211 = bitcast <16 x i8> %210 to <2 x i64>
  %212 = extractelement <2 x i64> %211, i32 0
  %213 = bitcast i8* %204 to i64*
  store i64 %212, i64* %213, align 1
  %214 = getelementptr inbounds i8, i8* %204, i64 %1
  %215 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %216 = bitcast <16 x i8> %215 to <8 x i16>
  %217 = mul <8 x i16> %216, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %218 = add <8 x i16> %18, %217
  %219 = lshr <8 x i16> %218, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %220 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %219, <8 x i16> undef) #5
  %221 = bitcast <16 x i8> %220 to <2 x i64>
  %222 = extractelement <2 x i64> %221, i32 0
  %223 = bitcast i8* %214 to i64*
  store i64 %222, i64* %223, align 1
  %224 = getelementptr inbounds i8, i8* %214, i64 %1
  %225 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %226 = bitcast <16 x i8> %225 to <8 x i16>
  %227 = mul <8 x i16> %226, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %228 = add <8 x i16> %18, %227
  %229 = lshr <8 x i16> %228, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %230 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %229, <8 x i16> undef) #5
  %231 = bitcast <16 x i8> %230 to <2 x i64>
  %232 = extractelement <2 x i64> %231, i32 0
  %233 = bitcast i8* %224 to i64*
  store i64 %232, i64* %233, align 1
  %234 = getelementptr inbounds i8, i8* %224, i64 %1
  %235 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %236 = bitcast <16 x i8> %235 to <8 x i16>
  %237 = mul <8 x i16> %236, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %238 = add <8 x i16> %18, %237
  %239 = lshr <8 x i16> %238, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %240 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %239, <8 x i16> undef) #5
  %241 = bitcast <16 x i8> %240 to <2 x i64>
  %242 = extractelement <2 x i64> %241, i32 0
  %243 = bitcast i8* %234 to i64*
  store i64 %242, i64* %243, align 1
  %244 = getelementptr inbounds i8, i8* %234, i64 %1
  %245 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %246 = bitcast <16 x i8> %245 to <8 x i16>
  %247 = mul <8 x i16> %246, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %248 = add <8 x i16> %18, %247
  %249 = lshr <8 x i16> %248, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %250 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %249, <8 x i16> undef) #5
  %251 = bitcast <16 x i8> %250 to <2 x i64>
  %252 = extractelement <2 x i64> %251, i32 0
  %253 = bitcast i8* %244 to i64*
  store i64 %252, i64* %253, align 1
  %254 = getelementptr inbounds i8, i8* %244, i64 %1
  %255 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %256 = bitcast <16 x i8> %255 to <8 x i16>
  %257 = mul <8 x i16> %256, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %258 = add <8 x i16> %18, %257
  %259 = lshr <8 x i16> %258, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %259, <8 x i16> undef) #5
  %261 = bitcast <16 x i8> %260 to <2 x i64>
  %262 = extractelement <2 x i64> %261, i32 0
  %263 = bitcast i8* %254 to i64*
  store i64 %262, i64* %263, align 1
  %264 = getelementptr inbounds i8, i8* %254, i64 %1
  %265 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %266 = bitcast <16 x i8> %265 to <8 x i16>
  %267 = mul <8 x i16> %266, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %268 = add <8 x i16> %18, %267
  %269 = lshr <8 x i16> %268, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %270 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %269, <8 x i16> undef) #5
  %271 = bitcast <16 x i8> %270 to <2 x i64>
  %272 = extractelement <2 x i64> %271, i32 0
  %273 = bitcast i8* %264 to i64*
  store i64 %272, i64* %273, align 1
  %274 = getelementptr inbounds i8, i8* %264, i64 %1
  %275 = getelementptr inbounds i8, i8* %3, i64 24
  %276 = bitcast i8* %275 to i64*
  %277 = load i64, i64* %276, align 1
  %278 = insertelement <2 x i64> undef, i64 %277, i32 0
  %279 = bitcast <2 x i64> %278 to <16 x i8>
  %280 = shufflevector <16 x i8> %279, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %281 = zext <8 x i8> %280 to <8 x i16>
  %282 = bitcast <8 x i16> %281 to <16 x i8>
  %283 = shufflevector <16 x i8> %282, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %284 = bitcast <16 x i8> %283 to <8 x i16>
  %285 = mul <8 x i16> %284, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %286 = add <8 x i16> %18, %285
  %287 = lshr <8 x i16> %286, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %288 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %287, <8 x i16> undef) #5
  %289 = bitcast <16 x i8> %288 to <2 x i64>
  %290 = extractelement <2 x i64> %289, i32 0
  %291 = bitcast i8* %274 to i64*
  store i64 %290, i64* %291, align 1
  %292 = getelementptr inbounds i8, i8* %274, i64 %1
  %293 = shufflevector <16 x i8> %282, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %294 = bitcast <16 x i8> %293 to <8 x i16>
  %295 = mul <8 x i16> %294, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %296 = add <8 x i16> %18, %295
  %297 = lshr <8 x i16> %296, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %298 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %297, <8 x i16> undef) #5
  %299 = bitcast <16 x i8> %298 to <2 x i64>
  %300 = extractelement <2 x i64> %299, i32 0
  %301 = bitcast i8* %292 to i64*
  store i64 %300, i64* %301, align 1
  %302 = getelementptr inbounds i8, i8* %292, i64 %1
  %303 = shufflevector <16 x i8> %282, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %304 = bitcast <16 x i8> %303 to <8 x i16>
  %305 = mul <8 x i16> %304, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %306 = add <8 x i16> %18, %305
  %307 = lshr <8 x i16> %306, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %308 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %307, <8 x i16> undef) #5
  %309 = bitcast <16 x i8> %308 to <2 x i64>
  %310 = extractelement <2 x i64> %309, i32 0
  %311 = bitcast i8* %302 to i64*
  store i64 %310, i64* %311, align 1
  %312 = getelementptr inbounds i8, i8* %302, i64 %1
  %313 = shufflevector <16 x i8> %282, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %314 = bitcast <16 x i8> %313 to <8 x i16>
  %315 = mul <8 x i16> %314, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %316 = add <8 x i16> %18, %315
  %317 = lshr <8 x i16> %316, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %317, <8 x i16> undef) #5
  %319 = bitcast <16 x i8> %318 to <2 x i64>
  %320 = extractelement <2 x i64> %319, i32 0
  %321 = bitcast i8* %312 to i64*
  store i64 %320, i64* %321, align 1
  %322 = getelementptr inbounds i8, i8* %312, i64 %1
  %323 = shufflevector <16 x i8> %282, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %324 = bitcast <16 x i8> %323 to <8 x i16>
  %325 = mul <8 x i16> %324, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %326 = add <8 x i16> %18, %325
  %327 = lshr <8 x i16> %326, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %328 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %327, <8 x i16> undef) #5
  %329 = bitcast <16 x i8> %328 to <2 x i64>
  %330 = extractelement <2 x i64> %329, i32 0
  %331 = bitcast i8* %322 to i64*
  store i64 %330, i64* %331, align 1
  %332 = getelementptr inbounds i8, i8* %322, i64 %1
  %333 = shufflevector <16 x i8> %282, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %334 = bitcast <16 x i8> %333 to <8 x i16>
  %335 = mul <8 x i16> %334, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %336 = add <8 x i16> %18, %335
  %337 = lshr <8 x i16> %336, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %338 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %337, <8 x i16> undef) #5
  %339 = bitcast <16 x i8> %338 to <2 x i64>
  %340 = extractelement <2 x i64> %339, i32 0
  %341 = bitcast i8* %332 to i64*
  store i64 %340, i64* %341, align 1
  %342 = getelementptr inbounds i8, i8* %332, i64 %1
  %343 = shufflevector <16 x i8> %282, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %344 = bitcast <16 x i8> %343 to <8 x i16>
  %345 = mul <8 x i16> %344, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %346 = add <8 x i16> %18, %345
  %347 = lshr <8 x i16> %346, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %348 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> undef) #5
  %349 = bitcast <16 x i8> %348 to <2 x i64>
  %350 = extractelement <2 x i64> %349, i32 0
  %351 = bitcast i8* %342 to i64*
  store i64 %350, i64* %351, align 1
  %352 = getelementptr inbounds i8, i8* %342, i64 %1
  %353 = shufflevector <16 x i8> %282, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %354 = bitcast <16 x i8> %353 to <8 x i16>
  %355 = mul <8 x i16> %354, <i16 255, i16 197, i16 146, i16 105, i16 73, i16 50, i16 37, i16 32>
  %356 = add <8 x i16> %18, %355
  %357 = lshr <8 x i16> %356, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %358 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %357, <8 x i16> undef) #5
  %359 = bitcast <16 x i8> %358 to <2 x i64>
  %360 = extractelement <2 x i64> %359, i32 0
  %361 = bitcast i8* %352 to i64*
  store i64 %360, i64* %361, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal16x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i32*
  %11 = load i32, i32* %10, align 1
  %12 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %17 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %18 = bitcast <8 x i16> %15 to <16 x i8>
  %19 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %20 = bitcast <16 x i8> %19 to <8 x i16>
  %21 = mul <8 x i16> %20, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %22 = mul <8 x i16> %20, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %23 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %24 = add <8 x i16> %23, %21
  %25 = lshr <8 x i16> %24, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %26 = add <8 x i16> %17, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %27 = add <8 x i16> %26, %22
  %28 = lshr <8 x i16> %27, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %25, <8 x i16> %28) #5
  %30 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %29, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %1
  %32 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %33 = bitcast <16 x i8> %32 to <8 x i16>
  %34 = mul <8 x i16> %33, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %35 = mul <8 x i16> %33, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %36 = add <8 x i16> %23, %34
  %37 = lshr <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = add <8 x i16> %26, %35
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %39) #5
  %41 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %31, i64 %1
  %43 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %44 = bitcast <16 x i8> %43 to <8 x i16>
  %45 = mul <8 x i16> %44, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %46 = mul <8 x i16> %44, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %47 = add <8 x i16> %23, %45
  %48 = lshr <8 x i16> %47, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %49 = add <8 x i16> %26, %46
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %50) #5
  %52 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %51, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %42, i64 %1
  %54 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %55 = bitcast <16 x i8> %54 to <8 x i16>
  %56 = mul <8 x i16> %55, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %57 = mul <8 x i16> %55, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %58 = add <8 x i16> %23, %56
  %59 = lshr <8 x i16> %58, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %60 = add <8 x i16> %26, %57
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %59, <8 x i16> %61) #5
  %63 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal16x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %17 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %18 = bitcast <8 x i16> %15 to <16 x i8>
  %19 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %20 = add <8 x i16> %17, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %21 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %22 = bitcast <16 x i8> %21 to <8 x i16>
  %23 = mul <8 x i16> %22, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %24 = mul <8 x i16> %22, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %25 = add <8 x i16> %19, %23
  %26 = lshr <8 x i16> %25, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %27 = add <8 x i16> %20, %24
  %28 = lshr <8 x i16> %27, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %26, <8 x i16> %28) #5
  %30 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %29, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %1
  %32 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %33 = bitcast <16 x i8> %32 to <8 x i16>
  %34 = mul <8 x i16> %33, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %35 = mul <8 x i16> %33, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %36 = add <8 x i16> %19, %34
  %37 = lshr <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = add <8 x i16> %20, %35
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %39) #5
  %41 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %31, i64 %1
  %43 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %44 = bitcast <16 x i8> %43 to <8 x i16>
  %45 = mul <8 x i16> %44, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %46 = mul <8 x i16> %44, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %47 = add <8 x i16> %19, %45
  %48 = lshr <8 x i16> %47, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %49 = add <8 x i16> %20, %46
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %50) #5
  %52 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %51, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %42, i64 %1
  %54 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %55 = bitcast <16 x i8> %54 to <8 x i16>
  %56 = mul <8 x i16> %55, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %57 = mul <8 x i16> %55, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %58 = add <8 x i16> %19, %56
  %59 = lshr <8 x i16> %58, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %60 = add <8 x i16> %20, %57
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %59, <8 x i16> %61) #5
  %63 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %53, i64 %1
  %65 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %66 = bitcast <16 x i8> %65 to <8 x i16>
  %67 = mul <8 x i16> %66, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %68 = mul <8 x i16> %66, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %69 = add <8 x i16> %19, %67
  %70 = lshr <8 x i16> %69, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %71 = add <8 x i16> %20, %68
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> %72) #5
  %74 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %64, i64 %1
  %76 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %77 = bitcast <16 x i8> %76 to <8 x i16>
  %78 = mul <8 x i16> %77, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %79 = mul <8 x i16> %77, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %80 = add <8 x i16> %19, %78
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = add <8 x i16> %20, %79
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %83) #5
  %85 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %84, <16 x i8>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %75, i64 %1
  %87 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %88 = bitcast <16 x i8> %87 to <8 x i16>
  %89 = mul <8 x i16> %88, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %90 = mul <8 x i16> %88, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %91 = add <8 x i16> %19, %89
  %92 = lshr <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = add <8 x i16> %20, %90
  %94 = lshr <8 x i16> %93, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %95 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %92, <8 x i16> %94) #5
  %96 = bitcast i8* %86 to <16 x i8>*
  store <16 x i8> %95, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %86, i64 %1
  %98 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %99 = bitcast <16 x i8> %98 to <8 x i16>
  %100 = mul <8 x i16> %99, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %101 = mul <8 x i16> %99, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %102 = add <8 x i16> %19, %100
  %103 = lshr <8 x i16> %102, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %104 = add <8 x i16> %20, %101
  %105 = lshr <8 x i16> %104, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %106 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %103, <8 x i16> %105) #5
  %107 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal16x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %11 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %12 = bitcast i8* %3 to i64*
  %13 = load i64, i64* %12, align 1
  %14 = insertelement <2 x i64> undef, i64 %13, i32 0
  %15 = bitcast <2 x i64> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %17 = zext <8 x i8> %16 to <8 x i16>
  %18 = bitcast <8 x i16> %17 to <16 x i8>
  %19 = add <8 x i16> %10, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %20 = add <8 x i16> %11, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %21 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %22 = bitcast <16 x i8> %21 to <8 x i16>
  %23 = mul <8 x i16> %22, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %24 = mul <8 x i16> %22, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %25 = add <8 x i16> %19, %23
  %26 = lshr <8 x i16> %25, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %27 = add <8 x i16> %20, %24
  %28 = lshr <8 x i16> %27, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %26, <8 x i16> %28) #5
  %30 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %29, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %1
  %32 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %33 = bitcast <16 x i8> %32 to <8 x i16>
  %34 = mul <8 x i16> %33, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %35 = mul <8 x i16> %33, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %36 = add <8 x i16> %19, %34
  %37 = lshr <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = add <8 x i16> %20, %35
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %39) #5
  %41 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %31, i64 %1
  %43 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %44 = bitcast <16 x i8> %43 to <8 x i16>
  %45 = mul <8 x i16> %44, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %46 = mul <8 x i16> %44, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %47 = add <8 x i16> %19, %45
  %48 = lshr <8 x i16> %47, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %49 = add <8 x i16> %20, %46
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %50) #5
  %52 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %51, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %42, i64 %1
  %54 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %55 = bitcast <16 x i8> %54 to <8 x i16>
  %56 = mul <8 x i16> %55, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %57 = mul <8 x i16> %55, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %58 = add <8 x i16> %19, %56
  %59 = lshr <8 x i16> %58, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %60 = add <8 x i16> %20, %57
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %59, <8 x i16> %61) #5
  %63 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %53, i64 %1
  %65 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %66 = bitcast <16 x i8> %65 to <8 x i16>
  %67 = mul <8 x i16> %66, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %68 = mul <8 x i16> %66, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %69 = add <8 x i16> %19, %67
  %70 = lshr <8 x i16> %69, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %71 = add <8 x i16> %20, %68
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> %72) #5
  %74 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %64, i64 %1
  %76 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %77 = bitcast <16 x i8> %76 to <8 x i16>
  %78 = mul <8 x i16> %77, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %79 = mul <8 x i16> %77, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %80 = add <8 x i16> %19, %78
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = add <8 x i16> %20, %79
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %83) #5
  %85 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %84, <16 x i8>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %75, i64 %1
  %87 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %88 = bitcast <16 x i8> %87 to <8 x i16>
  %89 = mul <8 x i16> %88, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %90 = mul <8 x i16> %88, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %91 = add <8 x i16> %19, %89
  %92 = lshr <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = add <8 x i16> %20, %90
  %94 = lshr <8 x i16> %93, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %95 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %92, <8 x i16> %94) #5
  %96 = bitcast i8* %86 to <16 x i8>*
  store <16 x i8> %95, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %86, i64 %1
  %98 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %99 = bitcast <16 x i8> %98 to <8 x i16>
  %100 = mul <8 x i16> %99, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %101 = mul <8 x i16> %99, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %102 = add <8 x i16> %19, %100
  %103 = lshr <8 x i16> %102, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %104 = add <8 x i16> %20, %101
  %105 = lshr <8 x i16> %104, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %106 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %103, <8 x i16> %105) #5
  %107 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 1
  %108 = getelementptr inbounds i8, i8* %97, i64 %1
  %109 = getelementptr inbounds i8, i8* %3, i64 8
  %110 = bitcast i8* %109 to i64*
  %111 = load i64, i64* %110, align 1
  %112 = insertelement <2 x i64> undef, i64 %111, i32 0
  %113 = bitcast <2 x i64> %112 to <16 x i8>
  %114 = shufflevector <16 x i8> %113, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %115 = zext <8 x i8> %114 to <8 x i16>
  %116 = bitcast <8 x i16> %115 to <16 x i8>
  %117 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %118 = bitcast <16 x i8> %117 to <8 x i16>
  %119 = mul <8 x i16> %118, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %120 = mul <8 x i16> %118, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %121 = add <8 x i16> %19, %119
  %122 = lshr <8 x i16> %121, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %123 = add <8 x i16> %20, %120
  %124 = lshr <8 x i16> %123, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %125 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %122, <8 x i16> %124) #5
  %126 = bitcast i8* %108 to <16 x i8>*
  store <16 x i8> %125, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %108, i64 %1
  %128 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %129 = bitcast <16 x i8> %128 to <8 x i16>
  %130 = mul <8 x i16> %129, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %131 = mul <8 x i16> %129, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %132 = add <8 x i16> %19, %130
  %133 = lshr <8 x i16> %132, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %134 = add <8 x i16> %20, %131
  %135 = lshr <8 x i16> %134, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %133, <8 x i16> %135) #5
  %137 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %136, <16 x i8>* %137, align 1
  %138 = getelementptr inbounds i8, i8* %127, i64 %1
  %139 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %140 = bitcast <16 x i8> %139 to <8 x i16>
  %141 = mul <8 x i16> %140, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %142 = mul <8 x i16> %140, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %143 = add <8 x i16> %19, %141
  %144 = lshr <8 x i16> %143, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %145 = add <8 x i16> %20, %142
  %146 = lshr <8 x i16> %145, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %147 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %144, <8 x i16> %146) #5
  %148 = bitcast i8* %138 to <16 x i8>*
  store <16 x i8> %147, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %138, i64 %1
  %150 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %151 = bitcast <16 x i8> %150 to <8 x i16>
  %152 = mul <8 x i16> %151, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %153 = mul <8 x i16> %151, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %154 = add <8 x i16> %19, %152
  %155 = lshr <8 x i16> %154, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %156 = add <8 x i16> %20, %153
  %157 = lshr <8 x i16> %156, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %158 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %157) #5
  %159 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %158, <16 x i8>* %159, align 1
  %160 = getelementptr inbounds i8, i8* %149, i64 %1
  %161 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %162 = bitcast <16 x i8> %161 to <8 x i16>
  %163 = mul <8 x i16> %162, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %164 = mul <8 x i16> %162, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %165 = add <8 x i16> %19, %163
  %166 = lshr <8 x i16> %165, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %167 = add <8 x i16> %20, %164
  %168 = lshr <8 x i16> %167, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %169 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %166, <8 x i16> %168) #5
  %170 = bitcast i8* %160 to <16 x i8>*
  store <16 x i8> %169, <16 x i8>* %170, align 1
  %171 = getelementptr inbounds i8, i8* %160, i64 %1
  %172 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %173 = bitcast <16 x i8> %172 to <8 x i16>
  %174 = mul <8 x i16> %173, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %175 = mul <8 x i16> %173, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %176 = add <8 x i16> %19, %174
  %177 = lshr <8 x i16> %176, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %178 = add <8 x i16> %20, %175
  %179 = lshr <8 x i16> %178, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %180 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %177, <8 x i16> %179) #5
  %181 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %180, <16 x i8>* %181, align 1
  %182 = getelementptr inbounds i8, i8* %171, i64 %1
  %183 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %184 = bitcast <16 x i8> %183 to <8 x i16>
  %185 = mul <8 x i16> %184, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %186 = mul <8 x i16> %184, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %187 = add <8 x i16> %19, %185
  %188 = lshr <8 x i16> %187, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %189 = add <8 x i16> %20, %186
  %190 = lshr <8 x i16> %189, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %188, <8 x i16> %190) #5
  %192 = bitcast i8* %182 to <16 x i8>*
  store <16 x i8> %191, <16 x i8>* %192, align 1
  %193 = getelementptr inbounds i8, i8* %182, i64 %1
  %194 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %195 = bitcast <16 x i8> %194 to <8 x i16>
  %196 = mul <8 x i16> %195, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %197 = mul <8 x i16> %195, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %198 = add <8 x i16> %19, %196
  %199 = lshr <8 x i16> %198, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %200 = add <8 x i16> %20, %197
  %201 = lshr <8 x i16> %200, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %202 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %199, <8 x i16> %201) #5
  %203 = bitcast i8* %193 to <16 x i8>*
  store <16 x i8> %202, <16 x i8>* %203, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal16x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %11 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %12 = bitcast i8* %3 to i64*
  %13 = load i64, i64* %12, align 1
  %14 = insertelement <2 x i64> undef, i64 %13, i32 0
  %15 = bitcast <2 x i64> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %17 = zext <8 x i8> %16 to <8 x i16>
  %18 = bitcast <8 x i16> %17 to <16 x i8>
  %19 = add <8 x i16> %10, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %20 = add <8 x i16> %11, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %21 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %22 = bitcast <16 x i8> %21 to <8 x i16>
  %23 = mul <8 x i16> %22, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %24 = mul <8 x i16> %22, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %25 = add <8 x i16> %19, %23
  %26 = lshr <8 x i16> %25, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %27 = add <8 x i16> %20, %24
  %28 = lshr <8 x i16> %27, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %26, <8 x i16> %28) #5
  %30 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %29, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %1
  %32 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %33 = bitcast <16 x i8> %32 to <8 x i16>
  %34 = mul <8 x i16> %33, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %35 = mul <8 x i16> %33, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %36 = add <8 x i16> %19, %34
  %37 = lshr <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = add <8 x i16> %20, %35
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %39) #5
  %41 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %31, i64 %1
  %43 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %44 = bitcast <16 x i8> %43 to <8 x i16>
  %45 = mul <8 x i16> %44, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %46 = mul <8 x i16> %44, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %47 = add <8 x i16> %19, %45
  %48 = lshr <8 x i16> %47, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %49 = add <8 x i16> %20, %46
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %50) #5
  %52 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %51, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %42, i64 %1
  %54 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %55 = bitcast <16 x i8> %54 to <8 x i16>
  %56 = mul <8 x i16> %55, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %57 = mul <8 x i16> %55, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %58 = add <8 x i16> %19, %56
  %59 = lshr <8 x i16> %58, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %60 = add <8 x i16> %20, %57
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %59, <8 x i16> %61) #5
  %63 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %53, i64 %1
  %65 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %66 = bitcast <16 x i8> %65 to <8 x i16>
  %67 = mul <8 x i16> %66, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %68 = mul <8 x i16> %66, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %69 = add <8 x i16> %19, %67
  %70 = lshr <8 x i16> %69, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %71 = add <8 x i16> %20, %68
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> %72) #5
  %74 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %64, i64 %1
  %76 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %77 = bitcast <16 x i8> %76 to <8 x i16>
  %78 = mul <8 x i16> %77, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %79 = mul <8 x i16> %77, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %80 = add <8 x i16> %19, %78
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = add <8 x i16> %20, %79
  %83 = lshr <8 x i16> %82, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %83) #5
  %85 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %84, <16 x i8>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %75, i64 %1
  %87 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %88 = bitcast <16 x i8> %87 to <8 x i16>
  %89 = mul <8 x i16> %88, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %90 = mul <8 x i16> %88, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %91 = add <8 x i16> %19, %89
  %92 = lshr <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = add <8 x i16> %20, %90
  %94 = lshr <8 x i16> %93, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %95 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %92, <8 x i16> %94) #5
  %96 = bitcast i8* %86 to <16 x i8>*
  store <16 x i8> %95, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %86, i64 %1
  %98 = shufflevector <16 x i8> %18, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %99 = bitcast <16 x i8> %98 to <8 x i16>
  %100 = mul <8 x i16> %99, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %101 = mul <8 x i16> %99, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %102 = add <8 x i16> %19, %100
  %103 = lshr <8 x i16> %102, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %104 = add <8 x i16> %20, %101
  %105 = lshr <8 x i16> %104, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %106 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %103, <8 x i16> %105) #5
  %107 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 1
  %108 = getelementptr inbounds i8, i8* %97, i64 %1
  %109 = getelementptr inbounds i8, i8* %3, i64 8
  %110 = bitcast i8* %109 to i64*
  %111 = load i64, i64* %110, align 1
  %112 = insertelement <2 x i64> undef, i64 %111, i32 0
  %113 = bitcast <2 x i64> %112 to <16 x i8>
  %114 = shufflevector <16 x i8> %113, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %115 = zext <8 x i8> %114 to <8 x i16>
  %116 = bitcast <8 x i16> %115 to <16 x i8>
  %117 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %118 = bitcast <16 x i8> %117 to <8 x i16>
  %119 = mul <8 x i16> %118, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %120 = mul <8 x i16> %118, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %121 = add <8 x i16> %19, %119
  %122 = lshr <8 x i16> %121, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %123 = add <8 x i16> %20, %120
  %124 = lshr <8 x i16> %123, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %125 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %122, <8 x i16> %124) #5
  %126 = bitcast i8* %108 to <16 x i8>*
  store <16 x i8> %125, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %108, i64 %1
  %128 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %129 = bitcast <16 x i8> %128 to <8 x i16>
  %130 = mul <8 x i16> %129, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %131 = mul <8 x i16> %129, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %132 = add <8 x i16> %19, %130
  %133 = lshr <8 x i16> %132, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %134 = add <8 x i16> %20, %131
  %135 = lshr <8 x i16> %134, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %133, <8 x i16> %135) #5
  %137 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %136, <16 x i8>* %137, align 1
  %138 = getelementptr inbounds i8, i8* %127, i64 %1
  %139 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %140 = bitcast <16 x i8> %139 to <8 x i16>
  %141 = mul <8 x i16> %140, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %142 = mul <8 x i16> %140, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %143 = add <8 x i16> %19, %141
  %144 = lshr <8 x i16> %143, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %145 = add <8 x i16> %20, %142
  %146 = lshr <8 x i16> %145, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %147 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %144, <8 x i16> %146) #5
  %148 = bitcast i8* %138 to <16 x i8>*
  store <16 x i8> %147, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %138, i64 %1
  %150 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %151 = bitcast <16 x i8> %150 to <8 x i16>
  %152 = mul <8 x i16> %151, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %153 = mul <8 x i16> %151, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %154 = add <8 x i16> %19, %152
  %155 = lshr <8 x i16> %154, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %156 = add <8 x i16> %20, %153
  %157 = lshr <8 x i16> %156, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %158 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %157) #5
  %159 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %158, <16 x i8>* %159, align 1
  %160 = getelementptr inbounds i8, i8* %149, i64 %1
  %161 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %162 = bitcast <16 x i8> %161 to <8 x i16>
  %163 = mul <8 x i16> %162, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %164 = mul <8 x i16> %162, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %165 = add <8 x i16> %19, %163
  %166 = lshr <8 x i16> %165, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %167 = add <8 x i16> %20, %164
  %168 = lshr <8 x i16> %167, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %169 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %166, <8 x i16> %168) #5
  %170 = bitcast i8* %160 to <16 x i8>*
  store <16 x i8> %169, <16 x i8>* %170, align 1
  %171 = getelementptr inbounds i8, i8* %160, i64 %1
  %172 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %173 = bitcast <16 x i8> %172 to <8 x i16>
  %174 = mul <8 x i16> %173, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %175 = mul <8 x i16> %173, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %176 = add <8 x i16> %19, %174
  %177 = lshr <8 x i16> %176, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %178 = add <8 x i16> %20, %175
  %179 = lshr <8 x i16> %178, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %180 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %177, <8 x i16> %179) #5
  %181 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %180, <16 x i8>* %181, align 1
  %182 = getelementptr inbounds i8, i8* %171, i64 %1
  %183 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %184 = bitcast <16 x i8> %183 to <8 x i16>
  %185 = mul <8 x i16> %184, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %186 = mul <8 x i16> %184, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %187 = add <8 x i16> %19, %185
  %188 = lshr <8 x i16> %187, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %189 = add <8 x i16> %20, %186
  %190 = lshr <8 x i16> %189, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %188, <8 x i16> %190) #5
  %192 = bitcast i8* %182 to <16 x i8>*
  store <16 x i8> %191, <16 x i8>* %192, align 1
  %193 = getelementptr inbounds i8, i8* %182, i64 %1
  %194 = shufflevector <16 x i8> %116, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %195 = bitcast <16 x i8> %194 to <8 x i16>
  %196 = mul <8 x i16> %195, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %197 = mul <8 x i16> %195, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %198 = add <8 x i16> %19, %196
  %199 = lshr <8 x i16> %198, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %200 = add <8 x i16> %20, %197
  %201 = lshr <8 x i16> %200, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %202 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %199, <8 x i16> %201) #5
  %203 = bitcast i8* %193 to <16 x i8>*
  store <16 x i8> %202, <16 x i8>* %203, align 1
  %204 = getelementptr inbounds i8, i8* %193, i64 %1
  %205 = getelementptr inbounds i8, i8* %3, i64 16
  %206 = bitcast i8* %205 to i64*
  %207 = load i64, i64* %206, align 1
  %208 = insertelement <2 x i64> undef, i64 %207, i32 0
  %209 = bitcast <2 x i64> %208 to <16 x i8>
  %210 = shufflevector <16 x i8> %209, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %211 = zext <8 x i8> %210 to <8 x i16>
  %212 = bitcast <8 x i16> %211 to <16 x i8>
  %213 = shufflevector <16 x i8> %212, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %214 = bitcast <16 x i8> %213 to <8 x i16>
  %215 = mul <8 x i16> %214, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %216 = mul <8 x i16> %214, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %217 = add <8 x i16> %19, %215
  %218 = lshr <8 x i16> %217, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %219 = add <8 x i16> %20, %216
  %220 = lshr <8 x i16> %219, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %221 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %218, <8 x i16> %220) #5
  %222 = bitcast i8* %204 to <16 x i8>*
  store <16 x i8> %221, <16 x i8>* %222, align 1
  %223 = getelementptr inbounds i8, i8* %204, i64 %1
  %224 = shufflevector <16 x i8> %212, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %225 = bitcast <16 x i8> %224 to <8 x i16>
  %226 = mul <8 x i16> %225, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %227 = mul <8 x i16> %225, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %228 = add <8 x i16> %19, %226
  %229 = lshr <8 x i16> %228, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %230 = add <8 x i16> %20, %227
  %231 = lshr <8 x i16> %230, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %232 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %229, <8 x i16> %231) #5
  %233 = bitcast i8* %223 to <16 x i8>*
  store <16 x i8> %232, <16 x i8>* %233, align 1
  %234 = getelementptr inbounds i8, i8* %223, i64 %1
  %235 = shufflevector <16 x i8> %212, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %236 = bitcast <16 x i8> %235 to <8 x i16>
  %237 = mul <8 x i16> %236, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %238 = mul <8 x i16> %236, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %239 = add <8 x i16> %19, %237
  %240 = lshr <8 x i16> %239, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %241 = add <8 x i16> %20, %238
  %242 = lshr <8 x i16> %241, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %243 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %240, <8 x i16> %242) #5
  %244 = bitcast i8* %234 to <16 x i8>*
  store <16 x i8> %243, <16 x i8>* %244, align 1
  %245 = getelementptr inbounds i8, i8* %234, i64 %1
  %246 = shufflevector <16 x i8> %212, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %247 = bitcast <16 x i8> %246 to <8 x i16>
  %248 = mul <8 x i16> %247, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %249 = mul <8 x i16> %247, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %250 = add <8 x i16> %19, %248
  %251 = lshr <8 x i16> %250, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %252 = add <8 x i16> %20, %249
  %253 = lshr <8 x i16> %252, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %254 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %251, <8 x i16> %253) #5
  %255 = bitcast i8* %245 to <16 x i8>*
  store <16 x i8> %254, <16 x i8>* %255, align 1
  %256 = getelementptr inbounds i8, i8* %245, i64 %1
  %257 = shufflevector <16 x i8> %212, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %258 = bitcast <16 x i8> %257 to <8 x i16>
  %259 = mul <8 x i16> %258, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %260 = mul <8 x i16> %258, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %261 = add <8 x i16> %19, %259
  %262 = lshr <8 x i16> %261, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %263 = add <8 x i16> %20, %260
  %264 = lshr <8 x i16> %263, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %265 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %262, <8 x i16> %264) #5
  %266 = bitcast i8* %256 to <16 x i8>*
  store <16 x i8> %265, <16 x i8>* %266, align 1
  %267 = getelementptr inbounds i8, i8* %256, i64 %1
  %268 = shufflevector <16 x i8> %212, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %269 = bitcast <16 x i8> %268 to <8 x i16>
  %270 = mul <8 x i16> %269, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %271 = mul <8 x i16> %269, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %272 = add <8 x i16> %19, %270
  %273 = lshr <8 x i16> %272, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %274 = add <8 x i16> %20, %271
  %275 = lshr <8 x i16> %274, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %276 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %273, <8 x i16> %275) #5
  %277 = bitcast i8* %267 to <16 x i8>*
  store <16 x i8> %276, <16 x i8>* %277, align 1
  %278 = getelementptr inbounds i8, i8* %267, i64 %1
  %279 = shufflevector <16 x i8> %212, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %280 = bitcast <16 x i8> %279 to <8 x i16>
  %281 = mul <8 x i16> %280, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %282 = mul <8 x i16> %280, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %283 = add <8 x i16> %19, %281
  %284 = lshr <8 x i16> %283, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %285 = add <8 x i16> %20, %282
  %286 = lshr <8 x i16> %285, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %287 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %284, <8 x i16> %286) #5
  %288 = bitcast i8* %278 to <16 x i8>*
  store <16 x i8> %287, <16 x i8>* %288, align 1
  %289 = getelementptr inbounds i8, i8* %278, i64 %1
  %290 = shufflevector <16 x i8> %212, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %291 = bitcast <16 x i8> %290 to <8 x i16>
  %292 = mul <8 x i16> %291, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %293 = mul <8 x i16> %291, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %294 = add <8 x i16> %19, %292
  %295 = lshr <8 x i16> %294, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %296 = add <8 x i16> %20, %293
  %297 = lshr <8 x i16> %296, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %298 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %295, <8 x i16> %297) #5
  %299 = bitcast i8* %289 to <16 x i8>*
  store <16 x i8> %298, <16 x i8>* %299, align 1
  %300 = getelementptr inbounds i8, i8* %289, i64 %1
  %301 = getelementptr inbounds i8, i8* %3, i64 24
  %302 = bitcast i8* %301 to i64*
  %303 = load i64, i64* %302, align 1
  %304 = insertelement <2 x i64> undef, i64 %303, i32 0
  %305 = bitcast <2 x i64> %304 to <16 x i8>
  %306 = shufflevector <16 x i8> %305, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %307 = zext <8 x i8> %306 to <8 x i16>
  %308 = bitcast <8 x i16> %307 to <16 x i8>
  %309 = shufflevector <16 x i8> %308, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %310 = bitcast <16 x i8> %309 to <8 x i16>
  %311 = mul <8 x i16> %310, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %312 = mul <8 x i16> %310, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %313 = add <8 x i16> %19, %311
  %314 = lshr <8 x i16> %313, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %315 = add <8 x i16> %20, %312
  %316 = lshr <8 x i16> %315, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %317 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %314, <8 x i16> %316) #5
  %318 = bitcast i8* %300 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 1
  %319 = getelementptr inbounds i8, i8* %300, i64 %1
  %320 = shufflevector <16 x i8> %308, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %321 = bitcast <16 x i8> %320 to <8 x i16>
  %322 = mul <8 x i16> %321, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %323 = mul <8 x i16> %321, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %324 = add <8 x i16> %19, %322
  %325 = lshr <8 x i16> %324, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %326 = add <8 x i16> %20, %323
  %327 = lshr <8 x i16> %326, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %328 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %325, <8 x i16> %327) #5
  %329 = bitcast i8* %319 to <16 x i8>*
  store <16 x i8> %328, <16 x i8>* %329, align 1
  %330 = getelementptr inbounds i8, i8* %319, i64 %1
  %331 = shufflevector <16 x i8> %308, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %332 = bitcast <16 x i8> %331 to <8 x i16>
  %333 = mul <8 x i16> %332, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %334 = mul <8 x i16> %332, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %335 = add <8 x i16> %19, %333
  %336 = lshr <8 x i16> %335, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %337 = add <8 x i16> %20, %334
  %338 = lshr <8 x i16> %337, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %339 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %336, <8 x i16> %338) #5
  %340 = bitcast i8* %330 to <16 x i8>*
  store <16 x i8> %339, <16 x i8>* %340, align 1
  %341 = getelementptr inbounds i8, i8* %330, i64 %1
  %342 = shufflevector <16 x i8> %308, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %343 = bitcast <16 x i8> %342 to <8 x i16>
  %344 = mul <8 x i16> %343, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %345 = mul <8 x i16> %343, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %346 = add <8 x i16> %19, %344
  %347 = lshr <8 x i16> %346, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %348 = add <8 x i16> %20, %345
  %349 = lshr <8 x i16> %348, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %350 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %349) #5
  %351 = bitcast i8* %341 to <16 x i8>*
  store <16 x i8> %350, <16 x i8>* %351, align 1
  %352 = getelementptr inbounds i8, i8* %341, i64 %1
  %353 = shufflevector <16 x i8> %308, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %354 = bitcast <16 x i8> %353 to <8 x i16>
  %355 = mul <8 x i16> %354, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %356 = mul <8 x i16> %354, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %357 = add <8 x i16> %19, %355
  %358 = lshr <8 x i16> %357, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %359 = add <8 x i16> %20, %356
  %360 = lshr <8 x i16> %359, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %361 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %358, <8 x i16> %360) #5
  %362 = bitcast i8* %352 to <16 x i8>*
  store <16 x i8> %361, <16 x i8>* %362, align 1
  %363 = getelementptr inbounds i8, i8* %352, i64 %1
  %364 = shufflevector <16 x i8> %308, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %365 = bitcast <16 x i8> %364 to <8 x i16>
  %366 = mul <8 x i16> %365, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %367 = mul <8 x i16> %365, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %368 = add <8 x i16> %19, %366
  %369 = lshr <8 x i16> %368, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %370 = add <8 x i16> %20, %367
  %371 = lshr <8 x i16> %370, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %372 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %369, <8 x i16> %371) #5
  %373 = bitcast i8* %363 to <16 x i8>*
  store <16 x i8> %372, <16 x i8>* %373, align 1
  %374 = getelementptr inbounds i8, i8* %363, i64 %1
  %375 = shufflevector <16 x i8> %308, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %376 = bitcast <16 x i8> %375 to <8 x i16>
  %377 = mul <8 x i16> %376, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %378 = mul <8 x i16> %376, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %379 = add <8 x i16> %19, %377
  %380 = lshr <8 x i16> %379, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %381 = add <8 x i16> %20, %378
  %382 = lshr <8 x i16> %381, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %383 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %380, <8 x i16> %382) #5
  %384 = bitcast i8* %374 to <16 x i8>*
  store <16 x i8> %383, <16 x i8>* %384, align 1
  %385 = getelementptr inbounds i8, i8* %374, i64 %1
  %386 = shufflevector <16 x i8> %308, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %387 = bitcast <16 x i8> %386 to <8 x i16>
  %388 = mul <8 x i16> %387, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %389 = mul <8 x i16> %387, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %390 = add <8 x i16> %19, %388
  %391 = lshr <8 x i16> %390, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %392 = add <8 x i16> %20, %389
  %393 = lshr <8 x i16> %392, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %394 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %391, <8 x i16> %393) #5
  %395 = bitcast i8* %385 to <16 x i8>*
  store <16 x i8> %394, <16 x i8>* %395, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal16x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 15
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 31, i16 60, i16 86, i16 111, i16 133, i16 154, i16 172>
  %11 = mul <8 x i16> %9, <i16 188, i16 202, i16 213, i16 223, i16 230, i16 236, i16 239, i16 240>
  %12 = add <8 x i16> %10, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %13 = add <8 x i16> %11, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  br label %15

14:                                               ; preds = %15
  ret void

15:                                               ; preds = %4, %15
  %16 = phi i64 [ 0, %4 ], [ %114, %15 ]
  %17 = phi i8* [ %0, %4 ], [ %113, %15 ]
  %18 = getelementptr inbounds i8, i8* %3, i64 %16
  %19 = bitcast i8* %18 to i64*
  %20 = load i64, i64* %19, align 1
  %21 = insertelement <2 x i64> undef, i64 %20, i32 0
  %22 = bitcast <2 x i64> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %24 = zext <8 x i8> %23 to <8 x i16>
  %25 = bitcast <8 x i16> %24 to <16 x i8>
  %26 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %27 = bitcast <16 x i8> %26 to <8 x i16>
  %28 = mul <8 x i16> %27, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %29 = mul <8 x i16> %27, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %30 = add <8 x i16> %12, %28
  %31 = lshr <8 x i16> %30, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %32 = add <8 x i16> %13, %29
  %33 = lshr <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> %33) #5
  %35 = bitcast i8* %17 to <16 x i8>*
  store <16 x i8> %34, <16 x i8>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %17, i64 %1
  %37 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %38 = bitcast <16 x i8> %37 to <8 x i16>
  %39 = mul <8 x i16> %38, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %40 = mul <8 x i16> %38, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %41 = add <8 x i16> %12, %39
  %42 = lshr <8 x i16> %41, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %43 = add <8 x i16> %13, %40
  %44 = lshr <8 x i16> %43, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %45 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %42, <8 x i16> %44) #5
  %46 = bitcast i8* %36 to <16 x i8>*
  store <16 x i8> %45, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %36, i64 %1
  %48 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %49 = bitcast <16 x i8> %48 to <8 x i16>
  %50 = mul <8 x i16> %49, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %51 = mul <8 x i16> %49, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %52 = add <8 x i16> %12, %50
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = add <8 x i16> %13, %51
  %55 = lshr <8 x i16> %54, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %55) #5
  %57 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %47, i64 %1
  %59 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %60 = bitcast <16 x i8> %59 to <8 x i16>
  %61 = mul <8 x i16> %60, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %62 = mul <8 x i16> %60, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %63 = add <8 x i16> %12, %61
  %64 = lshr <8 x i16> %63, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %65 = add <8 x i16> %13, %62
  %66 = lshr <8 x i16> %65, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %64, <8 x i16> %66) #5
  %68 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %67, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %58, i64 %1
  %70 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %71 = bitcast <16 x i8> %70 to <8 x i16>
  %72 = mul <8 x i16> %71, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %73 = mul <8 x i16> %71, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %74 = add <8 x i16> %12, %72
  %75 = lshr <8 x i16> %74, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %76 = add <8 x i16> %13, %73
  %77 = lshr <8 x i16> %76, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %78 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %75, <8 x i16> %77) #5
  %79 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %78, <16 x i8>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %69, i64 %1
  %81 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %82 = bitcast <16 x i8> %81 to <8 x i16>
  %83 = mul <8 x i16> %82, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %84 = mul <8 x i16> %82, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %85 = add <8 x i16> %12, %83
  %86 = lshr <8 x i16> %85, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %87 = add <8 x i16> %13, %84
  %88 = lshr <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %88) #5
  %90 = bitcast i8* %80 to <16 x i8>*
  store <16 x i8> %89, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %80, i64 %1
  %92 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %93 = bitcast <16 x i8> %92 to <8 x i16>
  %94 = mul <8 x i16> %93, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %95 = mul <8 x i16> %93, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %96 = add <8 x i16> %12, %94
  %97 = lshr <8 x i16> %96, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %98 = add <8 x i16> %13, %95
  %99 = lshr <8 x i16> %98, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %97, <8 x i16> %99) #5
  %101 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %100, <16 x i8>* %101, align 1
  %102 = getelementptr inbounds i8, i8* %91, i64 %1
  %103 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %104 = bitcast <16 x i8> %103 to <8 x i16>
  %105 = mul <8 x i16> %104, <i16 255, i16 225, i16 196, i16 170, i16 145, i16 123, i16 102, i16 84>
  %106 = mul <8 x i16> %104, <i16 68, i16 54, i16 43, i16 33, i16 26, i16 20, i16 17, i16 16>
  %107 = add <8 x i16> %12, %105
  %108 = lshr <8 x i16> %107, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %109 = add <8 x i16> %13, %106
  %110 = lshr <8 x i16> %109, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %108, <8 x i16> %110) #5
  %112 = bitcast i8* %102 to <16 x i8>*
  store <16 x i8> %111, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %102, i64 %1
  %114 = add nuw nsw i64 %16, 8
  %115 = icmp ult i64 %114, 64
  br i1 %115, label %15, label %14
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SmoothHorizontal32x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = mul <8 x i16> %9, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %17 = mul <8 x i16> %9, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %18 = mul <8 x i16> %9, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %19 = mul <8 x i16> %9, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %20 = bitcast <8 x i16> %15 to <16 x i8>
  %21 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %22 = add <8 x i16> %17, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %23 = add <8 x i16> %18, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %24 = add <8 x i16> %19, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %25 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %26 = bitcast <16 x i8> %25 to <8 x i16>
  %27 = mul <8 x i16> %26, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %28 = mul <8 x i16> %26, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %29 = add <8 x i16> %21, %27
  %30 = lshr <8 x i16> %29, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %31 = add <8 x i16> %22, %28
  %32 = lshr <8 x i16> %31, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %33 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> %32) #5
  %34 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %33, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %0, i64 16
  %36 = mul <8 x i16> %26, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %37 = mul <8 x i16> %26, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %38 = add <8 x i16> %23, %36
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = add <8 x i16> %24, %37
  %41 = lshr <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %39, <8 x i16> %41) #5
  %43 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %0, i64 %1
  %45 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %46 = bitcast <16 x i8> %45 to <8 x i16>
  %47 = mul <8 x i16> %46, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %48 = mul <8 x i16> %46, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %49 = add <8 x i16> %21, %47
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = add <8 x i16> %22, %48
  %52 = lshr <8 x i16> %51, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %53 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %50, <8 x i16> %52) #5
  %54 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %44, i64 16
  %56 = mul <8 x i16> %46, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %57 = mul <8 x i16> %46, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %58 = add <8 x i16> %23, %56
  %59 = lshr <8 x i16> %58, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %60 = add <8 x i16> %24, %57
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %59, <8 x i16> %61) #5
  %63 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %44, i64 %1
  %65 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %66 = bitcast <16 x i8> %65 to <8 x i16>
  %67 = mul <8 x i16> %66, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %68 = mul <8 x i16> %66, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %69 = add <8 x i16> %21, %67
  %70 = lshr <8 x i16> %69, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %71 = add <8 x i16> %22, %68
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> %72) #5
  %74 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %64, i64 16
  %76 = mul <8 x i16> %66, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %77 = mul <8 x i16> %66, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %78 = add <8 x i16> %23, %76
  %79 = lshr <8 x i16> %78, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %80 = add <8 x i16> %24, %77
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %81) #5
  %83 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %82, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %64, i64 %1
  %85 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %86 = bitcast <16 x i8> %85 to <8 x i16>
  %87 = mul <8 x i16> %86, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %88 = mul <8 x i16> %86, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %89 = add <8 x i16> %21, %87
  %90 = lshr <8 x i16> %89, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %91 = add <8 x i16> %22, %88
  %92 = lshr <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> %92) #5
  %94 = bitcast i8* %84 to <16 x i8>*
  store <16 x i8> %93, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %84, i64 16
  %96 = mul <8 x i16> %86, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %97 = mul <8 x i16> %86, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %98 = add <8 x i16> %23, %96
  %99 = lshr <8 x i16> %98, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %100 = add <8 x i16> %24, %97
  %101 = lshr <8 x i16> %100, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %101) #5
  %103 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %102, <16 x i8>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %84, i64 %1
  %105 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %106 = bitcast <16 x i8> %105 to <8 x i16>
  %107 = mul <8 x i16> %106, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %108 = mul <8 x i16> %106, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %109 = add <8 x i16> %21, %107
  %110 = lshr <8 x i16> %109, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %111 = add <8 x i16> %22, %108
  %112 = lshr <8 x i16> %111, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %113 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %110, <8 x i16> %112) #5
  %114 = bitcast i8* %104 to <16 x i8>*
  store <16 x i8> %113, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %104, i64 16
  %116 = mul <8 x i16> %106, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %117 = mul <8 x i16> %106, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %118 = add <8 x i16> %23, %116
  %119 = lshr <8 x i16> %118, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %120 = add <8 x i16> %24, %117
  %121 = lshr <8 x i16> %120, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %122 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> %121) #5
  %123 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %122, <16 x i8>* %123, align 1
  %124 = getelementptr inbounds i8, i8* %104, i64 %1
  %125 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %126 = bitcast <16 x i8> %125 to <8 x i16>
  %127 = mul <8 x i16> %126, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %128 = mul <8 x i16> %126, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %129 = add <8 x i16> %21, %127
  %130 = lshr <8 x i16> %129, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %131 = add <8 x i16> %22, %128
  %132 = lshr <8 x i16> %131, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %133 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> %132) #5
  %134 = bitcast i8* %124 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %124, i64 16
  %136 = mul <8 x i16> %126, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %137 = mul <8 x i16> %126, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %138 = add <8 x i16> %23, %136
  %139 = lshr <8 x i16> %138, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %140 = add <8 x i16> %24, %137
  %141 = lshr <8 x i16> %140, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %142 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %139, <8 x i16> %141) #5
  %143 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %142, <16 x i8>* %143, align 1
  %144 = getelementptr inbounds i8, i8* %124, i64 %1
  %145 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %146 = bitcast <16 x i8> %145 to <8 x i16>
  %147 = mul <8 x i16> %146, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %148 = mul <8 x i16> %146, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %149 = add <8 x i16> %21, %147
  %150 = lshr <8 x i16> %149, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %151 = add <8 x i16> %22, %148
  %152 = lshr <8 x i16> %151, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %153 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %152) #5
  %154 = bitcast i8* %144 to <16 x i8>*
  store <16 x i8> %153, <16 x i8>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %144, i64 16
  %156 = mul <8 x i16> %146, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %157 = mul <8 x i16> %146, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %158 = add <8 x i16> %23, %156
  %159 = lshr <8 x i16> %158, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %160 = add <8 x i16> %24, %157
  %161 = lshr <8 x i16> %160, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %162 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> %161) #5
  %163 = bitcast i8* %155 to <16 x i8>*
  store <16 x i8> %162, <16 x i8>* %163, align 1
  %164 = getelementptr inbounds i8, i8* %144, i64 %1
  %165 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %166 = bitcast <16 x i8> %165 to <8 x i16>
  %167 = mul <8 x i16> %166, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %168 = mul <8 x i16> %166, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %169 = add <8 x i16> %21, %167
  %170 = lshr <8 x i16> %169, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %171 = add <8 x i16> %22, %168
  %172 = lshr <8 x i16> %171, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %173 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %170, <8 x i16> %172) #5
  %174 = bitcast i8* %164 to <16 x i8>*
  store <16 x i8> %173, <16 x i8>* %174, align 1
  %175 = getelementptr inbounds i8, i8* %164, i64 16
  %176 = mul <8 x i16> %166, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %177 = mul <8 x i16> %166, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %178 = add <8 x i16> %23, %176
  %179 = lshr <8 x i16> %178, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %180 = add <8 x i16> %24, %177
  %181 = lshr <8 x i16> %180, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %182 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %179, <8 x i16> %181) #5
  %183 = bitcast i8* %175 to <16 x i8>*
  store <16 x i8> %182, <16 x i8>* %183, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal32x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = mul <8 x i16> %9, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %17 = mul <8 x i16> %9, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %18 = mul <8 x i16> %9, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %19 = mul <8 x i16> %9, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %20 = bitcast <8 x i16> %15 to <16 x i8>
  %21 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %22 = add <8 x i16> %17, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %23 = add <8 x i16> %18, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %24 = add <8 x i16> %19, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %25 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %26 = bitcast <16 x i8> %25 to <8 x i16>
  %27 = mul <8 x i16> %26, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %28 = mul <8 x i16> %26, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %29 = add <8 x i16> %21, %27
  %30 = lshr <8 x i16> %29, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %31 = add <8 x i16> %22, %28
  %32 = lshr <8 x i16> %31, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %33 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> %32) #5
  %34 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %33, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %0, i64 16
  %36 = mul <8 x i16> %26, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %37 = mul <8 x i16> %26, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %38 = add <8 x i16> %23, %36
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = add <8 x i16> %24, %37
  %41 = lshr <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %39, <8 x i16> %41) #5
  %43 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %0, i64 %1
  %45 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %46 = bitcast <16 x i8> %45 to <8 x i16>
  %47 = mul <8 x i16> %46, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %48 = mul <8 x i16> %46, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %49 = add <8 x i16> %21, %47
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = add <8 x i16> %22, %48
  %52 = lshr <8 x i16> %51, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %53 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %50, <8 x i16> %52) #5
  %54 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %44, i64 16
  %56 = mul <8 x i16> %46, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %57 = mul <8 x i16> %46, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %58 = add <8 x i16> %23, %56
  %59 = lshr <8 x i16> %58, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %60 = add <8 x i16> %24, %57
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %59, <8 x i16> %61) #5
  %63 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %44, i64 %1
  %65 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %66 = bitcast <16 x i8> %65 to <8 x i16>
  %67 = mul <8 x i16> %66, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %68 = mul <8 x i16> %66, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %69 = add <8 x i16> %21, %67
  %70 = lshr <8 x i16> %69, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %71 = add <8 x i16> %22, %68
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> %72) #5
  %74 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %64, i64 16
  %76 = mul <8 x i16> %66, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %77 = mul <8 x i16> %66, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %78 = add <8 x i16> %23, %76
  %79 = lshr <8 x i16> %78, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %80 = add <8 x i16> %24, %77
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %81) #5
  %83 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %82, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %64, i64 %1
  %85 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %86 = bitcast <16 x i8> %85 to <8 x i16>
  %87 = mul <8 x i16> %86, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %88 = mul <8 x i16> %86, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %89 = add <8 x i16> %21, %87
  %90 = lshr <8 x i16> %89, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %91 = add <8 x i16> %22, %88
  %92 = lshr <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> %92) #5
  %94 = bitcast i8* %84 to <16 x i8>*
  store <16 x i8> %93, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %84, i64 16
  %96 = mul <8 x i16> %86, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %97 = mul <8 x i16> %86, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %98 = add <8 x i16> %23, %96
  %99 = lshr <8 x i16> %98, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %100 = add <8 x i16> %24, %97
  %101 = lshr <8 x i16> %100, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %101) #5
  %103 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %102, <16 x i8>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %84, i64 %1
  %105 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %106 = bitcast <16 x i8> %105 to <8 x i16>
  %107 = mul <8 x i16> %106, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %108 = mul <8 x i16> %106, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %109 = add <8 x i16> %21, %107
  %110 = lshr <8 x i16> %109, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %111 = add <8 x i16> %22, %108
  %112 = lshr <8 x i16> %111, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %113 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %110, <8 x i16> %112) #5
  %114 = bitcast i8* %104 to <16 x i8>*
  store <16 x i8> %113, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %104, i64 16
  %116 = mul <8 x i16> %106, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %117 = mul <8 x i16> %106, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %118 = add <8 x i16> %23, %116
  %119 = lshr <8 x i16> %118, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %120 = add <8 x i16> %24, %117
  %121 = lshr <8 x i16> %120, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %122 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> %121) #5
  %123 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %122, <16 x i8>* %123, align 1
  %124 = getelementptr inbounds i8, i8* %104, i64 %1
  %125 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %126 = bitcast <16 x i8> %125 to <8 x i16>
  %127 = mul <8 x i16> %126, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %128 = mul <8 x i16> %126, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %129 = add <8 x i16> %21, %127
  %130 = lshr <8 x i16> %129, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %131 = add <8 x i16> %22, %128
  %132 = lshr <8 x i16> %131, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %133 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> %132) #5
  %134 = bitcast i8* %124 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %124, i64 16
  %136 = mul <8 x i16> %126, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %137 = mul <8 x i16> %126, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %138 = add <8 x i16> %23, %136
  %139 = lshr <8 x i16> %138, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %140 = add <8 x i16> %24, %137
  %141 = lshr <8 x i16> %140, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %142 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %139, <8 x i16> %141) #5
  %143 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %142, <16 x i8>* %143, align 1
  %144 = getelementptr inbounds i8, i8* %124, i64 %1
  %145 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %146 = bitcast <16 x i8> %145 to <8 x i16>
  %147 = mul <8 x i16> %146, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %148 = mul <8 x i16> %146, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %149 = add <8 x i16> %21, %147
  %150 = lshr <8 x i16> %149, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %151 = add <8 x i16> %22, %148
  %152 = lshr <8 x i16> %151, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %153 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %152) #5
  %154 = bitcast i8* %144 to <16 x i8>*
  store <16 x i8> %153, <16 x i8>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %144, i64 16
  %156 = mul <8 x i16> %146, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %157 = mul <8 x i16> %146, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %158 = add <8 x i16> %23, %156
  %159 = lshr <8 x i16> %158, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %160 = add <8 x i16> %24, %157
  %161 = lshr <8 x i16> %160, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %162 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> %161) #5
  %163 = bitcast i8* %155 to <16 x i8>*
  store <16 x i8> %162, <16 x i8>* %163, align 1
  %164 = getelementptr inbounds i8, i8* %144, i64 %1
  %165 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %166 = bitcast <16 x i8> %165 to <8 x i16>
  %167 = mul <8 x i16> %166, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %168 = mul <8 x i16> %166, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %169 = add <8 x i16> %21, %167
  %170 = lshr <8 x i16> %169, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %171 = add <8 x i16> %22, %168
  %172 = lshr <8 x i16> %171, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %173 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %170, <8 x i16> %172) #5
  %174 = bitcast i8* %164 to <16 x i8>*
  store <16 x i8> %173, <16 x i8>* %174, align 1
  %175 = getelementptr inbounds i8, i8* %164, i64 16
  %176 = mul <8 x i16> %166, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %177 = mul <8 x i16> %166, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %178 = add <8 x i16> %23, %176
  %179 = lshr <8 x i16> %178, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %180 = add <8 x i16> %24, %177
  %181 = lshr <8 x i16> %180, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %182 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %179, <8 x i16> %181) #5
  %183 = bitcast i8* %175 to <16 x i8>*
  store <16 x i8> %182, <16 x i8>* %183, align 1
  %184 = getelementptr inbounds i8, i8* %164, i64 %1
  %185 = getelementptr inbounds i8, i8* %3, i64 8
  %186 = bitcast i8* %185 to i64*
  %187 = load i64, i64* %186, align 1
  %188 = insertelement <2 x i64> undef, i64 %187, i32 0
  %189 = bitcast <2 x i64> %188 to <16 x i8>
  %190 = shufflevector <16 x i8> %189, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %191 = zext <8 x i8> %190 to <8 x i16>
  %192 = bitcast <8 x i16> %191 to <16 x i8>
  %193 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %194 = bitcast <16 x i8> %193 to <8 x i16>
  %195 = mul <8 x i16> %194, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %196 = mul <8 x i16> %194, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %197 = add <8 x i16> %21, %195
  %198 = lshr <8 x i16> %197, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %199 = add <8 x i16> %22, %196
  %200 = lshr <8 x i16> %199, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %198, <8 x i16> %200) #5
  %202 = bitcast i8* %184 to <16 x i8>*
  store <16 x i8> %201, <16 x i8>* %202, align 1
  %203 = getelementptr inbounds i8, i8* %184, i64 16
  %204 = mul <8 x i16> %194, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %205 = mul <8 x i16> %194, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %206 = add <8 x i16> %23, %204
  %207 = lshr <8 x i16> %206, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %208 = add <8 x i16> %24, %205
  %209 = lshr <8 x i16> %208, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %210 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %207, <8 x i16> %209) #5
  %211 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %210, <16 x i8>* %211, align 1
  %212 = getelementptr inbounds i8, i8* %184, i64 %1
  %213 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %214 = bitcast <16 x i8> %213 to <8 x i16>
  %215 = mul <8 x i16> %214, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %216 = mul <8 x i16> %214, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %217 = add <8 x i16> %21, %215
  %218 = lshr <8 x i16> %217, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %219 = add <8 x i16> %22, %216
  %220 = lshr <8 x i16> %219, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %221 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %218, <8 x i16> %220) #5
  %222 = bitcast i8* %212 to <16 x i8>*
  store <16 x i8> %221, <16 x i8>* %222, align 1
  %223 = getelementptr inbounds i8, i8* %212, i64 16
  %224 = mul <8 x i16> %214, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %225 = mul <8 x i16> %214, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %226 = add <8 x i16> %23, %224
  %227 = lshr <8 x i16> %226, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %228 = add <8 x i16> %24, %225
  %229 = lshr <8 x i16> %228, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %230 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %227, <8 x i16> %229) #5
  %231 = bitcast i8* %223 to <16 x i8>*
  store <16 x i8> %230, <16 x i8>* %231, align 1
  %232 = getelementptr inbounds i8, i8* %212, i64 %1
  %233 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %234 = bitcast <16 x i8> %233 to <8 x i16>
  %235 = mul <8 x i16> %234, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %236 = mul <8 x i16> %234, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %237 = add <8 x i16> %21, %235
  %238 = lshr <8 x i16> %237, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %239 = add <8 x i16> %22, %236
  %240 = lshr <8 x i16> %239, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %241 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %238, <8 x i16> %240) #5
  %242 = bitcast i8* %232 to <16 x i8>*
  store <16 x i8> %241, <16 x i8>* %242, align 1
  %243 = getelementptr inbounds i8, i8* %232, i64 16
  %244 = mul <8 x i16> %234, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %245 = mul <8 x i16> %234, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %246 = add <8 x i16> %23, %244
  %247 = lshr <8 x i16> %246, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %248 = add <8 x i16> %24, %245
  %249 = lshr <8 x i16> %248, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %250 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %247, <8 x i16> %249) #5
  %251 = bitcast i8* %243 to <16 x i8>*
  store <16 x i8> %250, <16 x i8>* %251, align 1
  %252 = getelementptr inbounds i8, i8* %232, i64 %1
  %253 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %254 = bitcast <16 x i8> %253 to <8 x i16>
  %255 = mul <8 x i16> %254, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %256 = mul <8 x i16> %254, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %257 = add <8 x i16> %21, %255
  %258 = lshr <8 x i16> %257, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %259 = add <8 x i16> %22, %256
  %260 = lshr <8 x i16> %259, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %261 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %258, <8 x i16> %260) #5
  %262 = bitcast i8* %252 to <16 x i8>*
  store <16 x i8> %261, <16 x i8>* %262, align 1
  %263 = getelementptr inbounds i8, i8* %252, i64 16
  %264 = mul <8 x i16> %254, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %265 = mul <8 x i16> %254, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %266 = add <8 x i16> %23, %264
  %267 = lshr <8 x i16> %266, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %268 = add <8 x i16> %24, %265
  %269 = lshr <8 x i16> %268, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %270 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %267, <8 x i16> %269) #5
  %271 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %270, <16 x i8>* %271, align 1
  %272 = getelementptr inbounds i8, i8* %252, i64 %1
  %273 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %274 = bitcast <16 x i8> %273 to <8 x i16>
  %275 = mul <8 x i16> %274, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %276 = mul <8 x i16> %274, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %277 = add <8 x i16> %21, %275
  %278 = lshr <8 x i16> %277, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %279 = add <8 x i16> %22, %276
  %280 = lshr <8 x i16> %279, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %281 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %278, <8 x i16> %280) #5
  %282 = bitcast i8* %272 to <16 x i8>*
  store <16 x i8> %281, <16 x i8>* %282, align 1
  %283 = getelementptr inbounds i8, i8* %272, i64 16
  %284 = mul <8 x i16> %274, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %285 = mul <8 x i16> %274, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %286 = add <8 x i16> %23, %284
  %287 = lshr <8 x i16> %286, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %288 = add <8 x i16> %24, %285
  %289 = lshr <8 x i16> %288, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %290 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %287, <8 x i16> %289) #5
  %291 = bitcast i8* %283 to <16 x i8>*
  store <16 x i8> %290, <16 x i8>* %291, align 1
  %292 = getelementptr inbounds i8, i8* %272, i64 %1
  %293 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %294 = bitcast <16 x i8> %293 to <8 x i16>
  %295 = mul <8 x i16> %294, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %296 = mul <8 x i16> %294, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %297 = add <8 x i16> %21, %295
  %298 = lshr <8 x i16> %297, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %299 = add <8 x i16> %22, %296
  %300 = lshr <8 x i16> %299, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %301 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %298, <8 x i16> %300) #5
  %302 = bitcast i8* %292 to <16 x i8>*
  store <16 x i8> %301, <16 x i8>* %302, align 1
  %303 = getelementptr inbounds i8, i8* %292, i64 16
  %304 = mul <8 x i16> %294, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %305 = mul <8 x i16> %294, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %306 = add <8 x i16> %23, %304
  %307 = lshr <8 x i16> %306, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %308 = add <8 x i16> %24, %305
  %309 = lshr <8 x i16> %308, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %310 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %307, <8 x i16> %309) #5
  %311 = bitcast i8* %303 to <16 x i8>*
  store <16 x i8> %310, <16 x i8>* %311, align 1
  %312 = getelementptr inbounds i8, i8* %292, i64 %1
  %313 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %314 = bitcast <16 x i8> %313 to <8 x i16>
  %315 = mul <8 x i16> %314, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %316 = mul <8 x i16> %314, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %317 = add <8 x i16> %21, %315
  %318 = lshr <8 x i16> %317, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %319 = add <8 x i16> %22, %316
  %320 = lshr <8 x i16> %319, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %321 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %318, <8 x i16> %320) #5
  %322 = bitcast i8* %312 to <16 x i8>*
  store <16 x i8> %321, <16 x i8>* %322, align 1
  %323 = getelementptr inbounds i8, i8* %312, i64 16
  %324 = mul <8 x i16> %314, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %325 = mul <8 x i16> %314, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %326 = add <8 x i16> %23, %324
  %327 = lshr <8 x i16> %326, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %328 = add <8 x i16> %24, %325
  %329 = lshr <8 x i16> %328, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %330 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %327, <8 x i16> %329) #5
  %331 = bitcast i8* %323 to <16 x i8>*
  store <16 x i8> %330, <16 x i8>* %331, align 1
  %332 = getelementptr inbounds i8, i8* %312, i64 %1
  %333 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %334 = bitcast <16 x i8> %333 to <8 x i16>
  %335 = mul <8 x i16> %334, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %336 = mul <8 x i16> %334, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %337 = add <8 x i16> %21, %335
  %338 = lshr <8 x i16> %337, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %339 = add <8 x i16> %22, %336
  %340 = lshr <8 x i16> %339, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %341 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %338, <8 x i16> %340) #5
  %342 = bitcast i8* %332 to <16 x i8>*
  store <16 x i8> %341, <16 x i8>* %342, align 1
  %343 = getelementptr inbounds i8, i8* %332, i64 16
  %344 = mul <8 x i16> %334, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %345 = mul <8 x i16> %334, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %346 = add <8 x i16> %23, %344
  %347 = lshr <8 x i16> %346, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %348 = add <8 x i16> %24, %345
  %349 = lshr <8 x i16> %348, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %350 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %349) #5
  %351 = bitcast i8* %343 to <16 x i8>*
  store <16 x i8> %350, <16 x i8>* %351, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal32x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %11 = mul <8 x i16> %9, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %12 = mul <8 x i16> %9, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %13 = mul <8 x i16> %9, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %14 = bitcast i8* %3 to i64*
  %15 = load i64, i64* %14, align 1
  %16 = insertelement <2 x i64> undef, i64 %15, i32 0
  %17 = bitcast <2 x i64> %16 to <16 x i8>
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = bitcast <8 x i16> %19 to <16 x i8>
  %21 = add <8 x i16> %10, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %22 = add <8 x i16> %11, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %23 = add <8 x i16> %12, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %24 = add <8 x i16> %13, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %25 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %26 = bitcast <16 x i8> %25 to <8 x i16>
  %27 = mul <8 x i16> %26, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %28 = mul <8 x i16> %26, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %29 = add <8 x i16> %21, %27
  %30 = lshr <8 x i16> %29, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %31 = add <8 x i16> %22, %28
  %32 = lshr <8 x i16> %31, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %33 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> %32) #5
  %34 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %33, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %0, i64 16
  %36 = mul <8 x i16> %26, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %37 = mul <8 x i16> %26, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %38 = add <8 x i16> %23, %36
  %39 = lshr <8 x i16> %38, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %40 = add <8 x i16> %24, %37
  %41 = lshr <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %39, <8 x i16> %41) #5
  %43 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %0, i64 %1
  %45 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %46 = bitcast <16 x i8> %45 to <8 x i16>
  %47 = mul <8 x i16> %46, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %48 = mul <8 x i16> %46, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %49 = add <8 x i16> %21, %47
  %50 = lshr <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = add <8 x i16> %22, %48
  %52 = lshr <8 x i16> %51, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %53 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %50, <8 x i16> %52) #5
  %54 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %44, i64 16
  %56 = mul <8 x i16> %46, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %57 = mul <8 x i16> %46, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %58 = add <8 x i16> %23, %56
  %59 = lshr <8 x i16> %58, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %60 = add <8 x i16> %24, %57
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %59, <8 x i16> %61) #5
  %63 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %44, i64 %1
  %65 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %66 = bitcast <16 x i8> %65 to <8 x i16>
  %67 = mul <8 x i16> %66, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %68 = mul <8 x i16> %66, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %69 = add <8 x i16> %21, %67
  %70 = lshr <8 x i16> %69, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %71 = add <8 x i16> %22, %68
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> %72) #5
  %74 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %64, i64 16
  %76 = mul <8 x i16> %66, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %77 = mul <8 x i16> %66, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %78 = add <8 x i16> %23, %76
  %79 = lshr <8 x i16> %78, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %80 = add <8 x i16> %24, %77
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %81) #5
  %83 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %82, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %64, i64 %1
  %85 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %86 = bitcast <16 x i8> %85 to <8 x i16>
  %87 = mul <8 x i16> %86, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %88 = mul <8 x i16> %86, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %89 = add <8 x i16> %21, %87
  %90 = lshr <8 x i16> %89, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %91 = add <8 x i16> %22, %88
  %92 = lshr <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> %92) #5
  %94 = bitcast i8* %84 to <16 x i8>*
  store <16 x i8> %93, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %84, i64 16
  %96 = mul <8 x i16> %86, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %97 = mul <8 x i16> %86, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %98 = add <8 x i16> %23, %96
  %99 = lshr <8 x i16> %98, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %100 = add <8 x i16> %24, %97
  %101 = lshr <8 x i16> %100, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %101) #5
  %103 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %102, <16 x i8>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %84, i64 %1
  %105 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %106 = bitcast <16 x i8> %105 to <8 x i16>
  %107 = mul <8 x i16> %106, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %108 = mul <8 x i16> %106, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %109 = add <8 x i16> %21, %107
  %110 = lshr <8 x i16> %109, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %111 = add <8 x i16> %22, %108
  %112 = lshr <8 x i16> %111, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %113 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %110, <8 x i16> %112) #5
  %114 = bitcast i8* %104 to <16 x i8>*
  store <16 x i8> %113, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %104, i64 16
  %116 = mul <8 x i16> %106, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %117 = mul <8 x i16> %106, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %118 = add <8 x i16> %23, %116
  %119 = lshr <8 x i16> %118, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %120 = add <8 x i16> %24, %117
  %121 = lshr <8 x i16> %120, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %122 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> %121) #5
  %123 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %122, <16 x i8>* %123, align 1
  %124 = getelementptr inbounds i8, i8* %104, i64 %1
  %125 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %126 = bitcast <16 x i8> %125 to <8 x i16>
  %127 = mul <8 x i16> %126, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %128 = mul <8 x i16> %126, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %129 = add <8 x i16> %21, %127
  %130 = lshr <8 x i16> %129, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %131 = add <8 x i16> %22, %128
  %132 = lshr <8 x i16> %131, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %133 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> %132) #5
  %134 = bitcast i8* %124 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %124, i64 16
  %136 = mul <8 x i16> %126, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %137 = mul <8 x i16> %126, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %138 = add <8 x i16> %23, %136
  %139 = lshr <8 x i16> %138, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %140 = add <8 x i16> %24, %137
  %141 = lshr <8 x i16> %140, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %142 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %139, <8 x i16> %141) #5
  %143 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %142, <16 x i8>* %143, align 1
  %144 = getelementptr inbounds i8, i8* %124, i64 %1
  %145 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %146 = bitcast <16 x i8> %145 to <8 x i16>
  %147 = mul <8 x i16> %146, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %148 = mul <8 x i16> %146, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %149 = add <8 x i16> %21, %147
  %150 = lshr <8 x i16> %149, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %151 = add <8 x i16> %22, %148
  %152 = lshr <8 x i16> %151, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %153 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %152) #5
  %154 = bitcast i8* %144 to <16 x i8>*
  store <16 x i8> %153, <16 x i8>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %144, i64 16
  %156 = mul <8 x i16> %146, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %157 = mul <8 x i16> %146, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %158 = add <8 x i16> %23, %156
  %159 = lshr <8 x i16> %158, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %160 = add <8 x i16> %24, %157
  %161 = lshr <8 x i16> %160, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %162 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> %161) #5
  %163 = bitcast i8* %155 to <16 x i8>*
  store <16 x i8> %162, <16 x i8>* %163, align 1
  %164 = getelementptr inbounds i8, i8* %144, i64 %1
  %165 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %166 = bitcast <16 x i8> %165 to <8 x i16>
  %167 = mul <8 x i16> %166, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %168 = mul <8 x i16> %166, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %169 = add <8 x i16> %21, %167
  %170 = lshr <8 x i16> %169, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %171 = add <8 x i16> %22, %168
  %172 = lshr <8 x i16> %171, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %173 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %170, <8 x i16> %172) #5
  %174 = bitcast i8* %164 to <16 x i8>*
  store <16 x i8> %173, <16 x i8>* %174, align 1
  %175 = getelementptr inbounds i8, i8* %164, i64 16
  %176 = mul <8 x i16> %166, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %177 = mul <8 x i16> %166, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %178 = add <8 x i16> %23, %176
  %179 = lshr <8 x i16> %178, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %180 = add <8 x i16> %24, %177
  %181 = lshr <8 x i16> %180, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %182 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %179, <8 x i16> %181) #5
  %183 = bitcast i8* %175 to <16 x i8>*
  store <16 x i8> %182, <16 x i8>* %183, align 1
  %184 = getelementptr inbounds i8, i8* %164, i64 %1
  %185 = getelementptr inbounds i8, i8* %3, i64 8
  %186 = bitcast i8* %185 to i64*
  %187 = load i64, i64* %186, align 1
  %188 = insertelement <2 x i64> undef, i64 %187, i32 0
  %189 = bitcast <2 x i64> %188 to <16 x i8>
  %190 = shufflevector <16 x i8> %189, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %191 = zext <8 x i8> %190 to <8 x i16>
  %192 = bitcast <8 x i16> %191 to <16 x i8>
  %193 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %194 = bitcast <16 x i8> %193 to <8 x i16>
  %195 = mul <8 x i16> %194, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %196 = mul <8 x i16> %194, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %197 = add <8 x i16> %21, %195
  %198 = lshr <8 x i16> %197, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %199 = add <8 x i16> %22, %196
  %200 = lshr <8 x i16> %199, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %198, <8 x i16> %200) #5
  %202 = bitcast i8* %184 to <16 x i8>*
  store <16 x i8> %201, <16 x i8>* %202, align 1
  %203 = getelementptr inbounds i8, i8* %184, i64 16
  %204 = mul <8 x i16> %194, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %205 = mul <8 x i16> %194, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %206 = add <8 x i16> %23, %204
  %207 = lshr <8 x i16> %206, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %208 = add <8 x i16> %24, %205
  %209 = lshr <8 x i16> %208, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %210 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %207, <8 x i16> %209) #5
  %211 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %210, <16 x i8>* %211, align 1
  %212 = getelementptr inbounds i8, i8* %184, i64 %1
  %213 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %214 = bitcast <16 x i8> %213 to <8 x i16>
  %215 = mul <8 x i16> %214, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %216 = mul <8 x i16> %214, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %217 = add <8 x i16> %21, %215
  %218 = lshr <8 x i16> %217, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %219 = add <8 x i16> %22, %216
  %220 = lshr <8 x i16> %219, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %221 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %218, <8 x i16> %220) #5
  %222 = bitcast i8* %212 to <16 x i8>*
  store <16 x i8> %221, <16 x i8>* %222, align 1
  %223 = getelementptr inbounds i8, i8* %212, i64 16
  %224 = mul <8 x i16> %214, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %225 = mul <8 x i16> %214, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %226 = add <8 x i16> %23, %224
  %227 = lshr <8 x i16> %226, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %228 = add <8 x i16> %24, %225
  %229 = lshr <8 x i16> %228, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %230 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %227, <8 x i16> %229) #5
  %231 = bitcast i8* %223 to <16 x i8>*
  store <16 x i8> %230, <16 x i8>* %231, align 1
  %232 = getelementptr inbounds i8, i8* %212, i64 %1
  %233 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %234 = bitcast <16 x i8> %233 to <8 x i16>
  %235 = mul <8 x i16> %234, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %236 = mul <8 x i16> %234, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %237 = add <8 x i16> %21, %235
  %238 = lshr <8 x i16> %237, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %239 = add <8 x i16> %22, %236
  %240 = lshr <8 x i16> %239, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %241 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %238, <8 x i16> %240) #5
  %242 = bitcast i8* %232 to <16 x i8>*
  store <16 x i8> %241, <16 x i8>* %242, align 1
  %243 = getelementptr inbounds i8, i8* %232, i64 16
  %244 = mul <8 x i16> %234, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %245 = mul <8 x i16> %234, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %246 = add <8 x i16> %23, %244
  %247 = lshr <8 x i16> %246, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %248 = add <8 x i16> %24, %245
  %249 = lshr <8 x i16> %248, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %250 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %247, <8 x i16> %249) #5
  %251 = bitcast i8* %243 to <16 x i8>*
  store <16 x i8> %250, <16 x i8>* %251, align 1
  %252 = getelementptr inbounds i8, i8* %232, i64 %1
  %253 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %254 = bitcast <16 x i8> %253 to <8 x i16>
  %255 = mul <8 x i16> %254, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %256 = mul <8 x i16> %254, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %257 = add <8 x i16> %21, %255
  %258 = lshr <8 x i16> %257, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %259 = add <8 x i16> %22, %256
  %260 = lshr <8 x i16> %259, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %261 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %258, <8 x i16> %260) #5
  %262 = bitcast i8* %252 to <16 x i8>*
  store <16 x i8> %261, <16 x i8>* %262, align 1
  %263 = getelementptr inbounds i8, i8* %252, i64 16
  %264 = mul <8 x i16> %254, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %265 = mul <8 x i16> %254, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %266 = add <8 x i16> %23, %264
  %267 = lshr <8 x i16> %266, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %268 = add <8 x i16> %24, %265
  %269 = lshr <8 x i16> %268, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %270 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %267, <8 x i16> %269) #5
  %271 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %270, <16 x i8>* %271, align 1
  %272 = getelementptr inbounds i8, i8* %252, i64 %1
  %273 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %274 = bitcast <16 x i8> %273 to <8 x i16>
  %275 = mul <8 x i16> %274, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %276 = mul <8 x i16> %274, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %277 = add <8 x i16> %21, %275
  %278 = lshr <8 x i16> %277, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %279 = add <8 x i16> %22, %276
  %280 = lshr <8 x i16> %279, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %281 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %278, <8 x i16> %280) #5
  %282 = bitcast i8* %272 to <16 x i8>*
  store <16 x i8> %281, <16 x i8>* %282, align 1
  %283 = getelementptr inbounds i8, i8* %272, i64 16
  %284 = mul <8 x i16> %274, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %285 = mul <8 x i16> %274, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %286 = add <8 x i16> %23, %284
  %287 = lshr <8 x i16> %286, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %288 = add <8 x i16> %24, %285
  %289 = lshr <8 x i16> %288, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %290 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %287, <8 x i16> %289) #5
  %291 = bitcast i8* %283 to <16 x i8>*
  store <16 x i8> %290, <16 x i8>* %291, align 1
  %292 = getelementptr inbounds i8, i8* %272, i64 %1
  %293 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %294 = bitcast <16 x i8> %293 to <8 x i16>
  %295 = mul <8 x i16> %294, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %296 = mul <8 x i16> %294, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %297 = add <8 x i16> %21, %295
  %298 = lshr <8 x i16> %297, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %299 = add <8 x i16> %22, %296
  %300 = lshr <8 x i16> %299, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %301 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %298, <8 x i16> %300) #5
  %302 = bitcast i8* %292 to <16 x i8>*
  store <16 x i8> %301, <16 x i8>* %302, align 1
  %303 = getelementptr inbounds i8, i8* %292, i64 16
  %304 = mul <8 x i16> %294, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %305 = mul <8 x i16> %294, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %306 = add <8 x i16> %23, %304
  %307 = lshr <8 x i16> %306, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %308 = add <8 x i16> %24, %305
  %309 = lshr <8 x i16> %308, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %310 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %307, <8 x i16> %309) #5
  %311 = bitcast i8* %303 to <16 x i8>*
  store <16 x i8> %310, <16 x i8>* %311, align 1
  %312 = getelementptr inbounds i8, i8* %292, i64 %1
  %313 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %314 = bitcast <16 x i8> %313 to <8 x i16>
  %315 = mul <8 x i16> %314, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %316 = mul <8 x i16> %314, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %317 = add <8 x i16> %21, %315
  %318 = lshr <8 x i16> %317, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %319 = add <8 x i16> %22, %316
  %320 = lshr <8 x i16> %319, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %321 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %318, <8 x i16> %320) #5
  %322 = bitcast i8* %312 to <16 x i8>*
  store <16 x i8> %321, <16 x i8>* %322, align 1
  %323 = getelementptr inbounds i8, i8* %312, i64 16
  %324 = mul <8 x i16> %314, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %325 = mul <8 x i16> %314, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %326 = add <8 x i16> %23, %324
  %327 = lshr <8 x i16> %326, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %328 = add <8 x i16> %24, %325
  %329 = lshr <8 x i16> %328, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %330 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %327, <8 x i16> %329) #5
  %331 = bitcast i8* %323 to <16 x i8>*
  store <16 x i8> %330, <16 x i8>* %331, align 1
  %332 = getelementptr inbounds i8, i8* %312, i64 %1
  %333 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %334 = bitcast <16 x i8> %333 to <8 x i16>
  %335 = mul <8 x i16> %334, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %336 = mul <8 x i16> %334, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %337 = add <8 x i16> %21, %335
  %338 = lshr <8 x i16> %337, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %339 = add <8 x i16> %22, %336
  %340 = lshr <8 x i16> %339, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %341 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %338, <8 x i16> %340) #5
  %342 = bitcast i8* %332 to <16 x i8>*
  store <16 x i8> %341, <16 x i8>* %342, align 1
  %343 = getelementptr inbounds i8, i8* %332, i64 16
  %344 = mul <8 x i16> %334, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %345 = mul <8 x i16> %334, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %346 = add <8 x i16> %23, %344
  %347 = lshr <8 x i16> %346, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %348 = add <8 x i16> %24, %345
  %349 = lshr <8 x i16> %348, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %350 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %349) #5
  %351 = bitcast i8* %343 to <16 x i8>*
  store <16 x i8> %350, <16 x i8>* %351, align 1
  %352 = getelementptr inbounds i8, i8* %332, i64 %1
  %353 = getelementptr inbounds i8, i8* %3, i64 16
  %354 = bitcast i8* %353 to i64*
  %355 = load i64, i64* %354, align 1
  %356 = insertelement <2 x i64> undef, i64 %355, i32 0
  %357 = bitcast <2 x i64> %356 to <16 x i8>
  %358 = shufflevector <16 x i8> %357, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %359 = zext <8 x i8> %358 to <8 x i16>
  %360 = bitcast <8 x i16> %359 to <16 x i8>
  %361 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %362 = bitcast <16 x i8> %361 to <8 x i16>
  %363 = mul <8 x i16> %362, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %364 = mul <8 x i16> %362, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %365 = add <8 x i16> %21, %363
  %366 = lshr <8 x i16> %365, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %367 = add <8 x i16> %22, %364
  %368 = lshr <8 x i16> %367, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %369 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %366, <8 x i16> %368) #5
  %370 = bitcast i8* %352 to <16 x i8>*
  store <16 x i8> %369, <16 x i8>* %370, align 1
  %371 = getelementptr inbounds i8, i8* %352, i64 16
  %372 = mul <8 x i16> %362, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %373 = mul <8 x i16> %362, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %374 = add <8 x i16> %23, %372
  %375 = lshr <8 x i16> %374, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %376 = add <8 x i16> %24, %373
  %377 = lshr <8 x i16> %376, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %378 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %375, <8 x i16> %377) #5
  %379 = bitcast i8* %371 to <16 x i8>*
  store <16 x i8> %378, <16 x i8>* %379, align 1
  %380 = getelementptr inbounds i8, i8* %352, i64 %1
  %381 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %382 = bitcast <16 x i8> %381 to <8 x i16>
  %383 = mul <8 x i16> %382, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %384 = mul <8 x i16> %382, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %385 = add <8 x i16> %21, %383
  %386 = lshr <8 x i16> %385, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %387 = add <8 x i16> %22, %384
  %388 = lshr <8 x i16> %387, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %389 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %386, <8 x i16> %388) #5
  %390 = bitcast i8* %380 to <16 x i8>*
  store <16 x i8> %389, <16 x i8>* %390, align 1
  %391 = getelementptr inbounds i8, i8* %380, i64 16
  %392 = mul <8 x i16> %382, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %393 = mul <8 x i16> %382, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %394 = add <8 x i16> %23, %392
  %395 = lshr <8 x i16> %394, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %396 = add <8 x i16> %24, %393
  %397 = lshr <8 x i16> %396, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %398 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %395, <8 x i16> %397) #5
  %399 = bitcast i8* %391 to <16 x i8>*
  store <16 x i8> %398, <16 x i8>* %399, align 1
  %400 = getelementptr inbounds i8, i8* %380, i64 %1
  %401 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %402 = bitcast <16 x i8> %401 to <8 x i16>
  %403 = mul <8 x i16> %402, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %404 = mul <8 x i16> %402, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %405 = add <8 x i16> %21, %403
  %406 = lshr <8 x i16> %405, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %407 = add <8 x i16> %22, %404
  %408 = lshr <8 x i16> %407, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %409 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %406, <8 x i16> %408) #5
  %410 = bitcast i8* %400 to <16 x i8>*
  store <16 x i8> %409, <16 x i8>* %410, align 1
  %411 = getelementptr inbounds i8, i8* %400, i64 16
  %412 = mul <8 x i16> %402, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %413 = mul <8 x i16> %402, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %414 = add <8 x i16> %23, %412
  %415 = lshr <8 x i16> %414, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %416 = add <8 x i16> %24, %413
  %417 = lshr <8 x i16> %416, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %418 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %415, <8 x i16> %417) #5
  %419 = bitcast i8* %411 to <16 x i8>*
  store <16 x i8> %418, <16 x i8>* %419, align 1
  %420 = getelementptr inbounds i8, i8* %400, i64 %1
  %421 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %422 = bitcast <16 x i8> %421 to <8 x i16>
  %423 = mul <8 x i16> %422, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %424 = mul <8 x i16> %422, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %425 = add <8 x i16> %21, %423
  %426 = lshr <8 x i16> %425, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %427 = add <8 x i16> %22, %424
  %428 = lshr <8 x i16> %427, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %429 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %426, <8 x i16> %428) #5
  %430 = bitcast i8* %420 to <16 x i8>*
  store <16 x i8> %429, <16 x i8>* %430, align 1
  %431 = getelementptr inbounds i8, i8* %420, i64 16
  %432 = mul <8 x i16> %422, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %433 = mul <8 x i16> %422, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %434 = add <8 x i16> %23, %432
  %435 = lshr <8 x i16> %434, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %436 = add <8 x i16> %24, %433
  %437 = lshr <8 x i16> %436, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %438 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %435, <8 x i16> %437) #5
  %439 = bitcast i8* %431 to <16 x i8>*
  store <16 x i8> %438, <16 x i8>* %439, align 1
  %440 = getelementptr inbounds i8, i8* %420, i64 %1
  %441 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %442 = bitcast <16 x i8> %441 to <8 x i16>
  %443 = mul <8 x i16> %442, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %444 = mul <8 x i16> %442, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %445 = add <8 x i16> %21, %443
  %446 = lshr <8 x i16> %445, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %447 = add <8 x i16> %22, %444
  %448 = lshr <8 x i16> %447, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %449 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %446, <8 x i16> %448) #5
  %450 = bitcast i8* %440 to <16 x i8>*
  store <16 x i8> %449, <16 x i8>* %450, align 1
  %451 = getelementptr inbounds i8, i8* %440, i64 16
  %452 = mul <8 x i16> %442, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %453 = mul <8 x i16> %442, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %454 = add <8 x i16> %23, %452
  %455 = lshr <8 x i16> %454, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %456 = add <8 x i16> %24, %453
  %457 = lshr <8 x i16> %456, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %458 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %455, <8 x i16> %457) #5
  %459 = bitcast i8* %451 to <16 x i8>*
  store <16 x i8> %458, <16 x i8>* %459, align 1
  %460 = getelementptr inbounds i8, i8* %440, i64 %1
  %461 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %462 = bitcast <16 x i8> %461 to <8 x i16>
  %463 = mul <8 x i16> %462, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %464 = mul <8 x i16> %462, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %465 = add <8 x i16> %21, %463
  %466 = lshr <8 x i16> %465, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %467 = add <8 x i16> %22, %464
  %468 = lshr <8 x i16> %467, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %469 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %466, <8 x i16> %468) #5
  %470 = bitcast i8* %460 to <16 x i8>*
  store <16 x i8> %469, <16 x i8>* %470, align 1
  %471 = getelementptr inbounds i8, i8* %460, i64 16
  %472 = mul <8 x i16> %462, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %473 = mul <8 x i16> %462, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %474 = add <8 x i16> %23, %472
  %475 = lshr <8 x i16> %474, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %476 = add <8 x i16> %24, %473
  %477 = lshr <8 x i16> %476, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %478 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %475, <8 x i16> %477) #5
  %479 = bitcast i8* %471 to <16 x i8>*
  store <16 x i8> %478, <16 x i8>* %479, align 1
  %480 = getelementptr inbounds i8, i8* %460, i64 %1
  %481 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %482 = bitcast <16 x i8> %481 to <8 x i16>
  %483 = mul <8 x i16> %482, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %484 = mul <8 x i16> %482, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %485 = add <8 x i16> %21, %483
  %486 = lshr <8 x i16> %485, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %487 = add <8 x i16> %22, %484
  %488 = lshr <8 x i16> %487, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %489 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %486, <8 x i16> %488) #5
  %490 = bitcast i8* %480 to <16 x i8>*
  store <16 x i8> %489, <16 x i8>* %490, align 1
  %491 = getelementptr inbounds i8, i8* %480, i64 16
  %492 = mul <8 x i16> %482, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %493 = mul <8 x i16> %482, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %494 = add <8 x i16> %23, %492
  %495 = lshr <8 x i16> %494, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %496 = add <8 x i16> %24, %493
  %497 = lshr <8 x i16> %496, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %498 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %495, <8 x i16> %497) #5
  %499 = bitcast i8* %491 to <16 x i8>*
  store <16 x i8> %498, <16 x i8>* %499, align 1
  %500 = getelementptr inbounds i8, i8* %480, i64 %1
  %501 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %502 = bitcast <16 x i8> %501 to <8 x i16>
  %503 = mul <8 x i16> %502, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %504 = mul <8 x i16> %502, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %505 = add <8 x i16> %21, %503
  %506 = lshr <8 x i16> %505, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %507 = add <8 x i16> %22, %504
  %508 = lshr <8 x i16> %507, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %509 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %506, <8 x i16> %508) #5
  %510 = bitcast i8* %500 to <16 x i8>*
  store <16 x i8> %509, <16 x i8>* %510, align 1
  %511 = getelementptr inbounds i8, i8* %500, i64 16
  %512 = mul <8 x i16> %502, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %513 = mul <8 x i16> %502, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %514 = add <8 x i16> %23, %512
  %515 = lshr <8 x i16> %514, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %516 = add <8 x i16> %24, %513
  %517 = lshr <8 x i16> %516, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %518 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %515, <8 x i16> %517) #5
  %519 = bitcast i8* %511 to <16 x i8>*
  store <16 x i8> %518, <16 x i8>* %519, align 1
  %520 = getelementptr inbounds i8, i8* %500, i64 %1
  %521 = getelementptr inbounds i8, i8* %3, i64 24
  %522 = bitcast i8* %521 to i64*
  %523 = load i64, i64* %522, align 1
  %524 = insertelement <2 x i64> undef, i64 %523, i32 0
  %525 = bitcast <2 x i64> %524 to <16 x i8>
  %526 = shufflevector <16 x i8> %525, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %527 = zext <8 x i8> %526 to <8 x i16>
  %528 = bitcast <8 x i16> %527 to <16 x i8>
  %529 = shufflevector <16 x i8> %528, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %530 = bitcast <16 x i8> %529 to <8 x i16>
  %531 = mul <8 x i16> %530, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %532 = mul <8 x i16> %530, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %533 = add <8 x i16> %21, %531
  %534 = lshr <8 x i16> %533, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %535 = add <8 x i16> %22, %532
  %536 = lshr <8 x i16> %535, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %537 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %534, <8 x i16> %536) #5
  %538 = bitcast i8* %520 to <16 x i8>*
  store <16 x i8> %537, <16 x i8>* %538, align 1
  %539 = getelementptr inbounds i8, i8* %520, i64 16
  %540 = mul <8 x i16> %530, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %541 = mul <8 x i16> %530, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %542 = add <8 x i16> %23, %540
  %543 = lshr <8 x i16> %542, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %544 = add <8 x i16> %24, %541
  %545 = lshr <8 x i16> %544, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %546 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %543, <8 x i16> %545) #5
  %547 = bitcast i8* %539 to <16 x i8>*
  store <16 x i8> %546, <16 x i8>* %547, align 1
  %548 = getelementptr inbounds i8, i8* %520, i64 %1
  %549 = shufflevector <16 x i8> %528, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %550 = bitcast <16 x i8> %549 to <8 x i16>
  %551 = mul <8 x i16> %550, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %552 = mul <8 x i16> %550, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %553 = add <8 x i16> %21, %551
  %554 = lshr <8 x i16> %553, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %555 = add <8 x i16> %22, %552
  %556 = lshr <8 x i16> %555, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %557 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %554, <8 x i16> %556) #5
  %558 = bitcast i8* %548 to <16 x i8>*
  store <16 x i8> %557, <16 x i8>* %558, align 1
  %559 = getelementptr inbounds i8, i8* %548, i64 16
  %560 = mul <8 x i16> %550, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %561 = mul <8 x i16> %550, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %562 = add <8 x i16> %23, %560
  %563 = lshr <8 x i16> %562, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %564 = add <8 x i16> %24, %561
  %565 = lshr <8 x i16> %564, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %566 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %563, <8 x i16> %565) #5
  %567 = bitcast i8* %559 to <16 x i8>*
  store <16 x i8> %566, <16 x i8>* %567, align 1
  %568 = getelementptr inbounds i8, i8* %548, i64 %1
  %569 = shufflevector <16 x i8> %528, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %570 = bitcast <16 x i8> %569 to <8 x i16>
  %571 = mul <8 x i16> %570, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %572 = mul <8 x i16> %570, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %573 = add <8 x i16> %21, %571
  %574 = lshr <8 x i16> %573, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %575 = add <8 x i16> %22, %572
  %576 = lshr <8 x i16> %575, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %577 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %574, <8 x i16> %576) #5
  %578 = bitcast i8* %568 to <16 x i8>*
  store <16 x i8> %577, <16 x i8>* %578, align 1
  %579 = getelementptr inbounds i8, i8* %568, i64 16
  %580 = mul <8 x i16> %570, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %581 = mul <8 x i16> %570, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %582 = add <8 x i16> %23, %580
  %583 = lshr <8 x i16> %582, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %584 = add <8 x i16> %24, %581
  %585 = lshr <8 x i16> %584, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %586 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %583, <8 x i16> %585) #5
  %587 = bitcast i8* %579 to <16 x i8>*
  store <16 x i8> %586, <16 x i8>* %587, align 1
  %588 = getelementptr inbounds i8, i8* %568, i64 %1
  %589 = shufflevector <16 x i8> %528, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %590 = bitcast <16 x i8> %589 to <8 x i16>
  %591 = mul <8 x i16> %590, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %592 = mul <8 x i16> %590, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %593 = add <8 x i16> %21, %591
  %594 = lshr <8 x i16> %593, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %595 = add <8 x i16> %22, %592
  %596 = lshr <8 x i16> %595, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %597 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %594, <8 x i16> %596) #5
  %598 = bitcast i8* %588 to <16 x i8>*
  store <16 x i8> %597, <16 x i8>* %598, align 1
  %599 = getelementptr inbounds i8, i8* %588, i64 16
  %600 = mul <8 x i16> %590, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %601 = mul <8 x i16> %590, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %602 = add <8 x i16> %23, %600
  %603 = lshr <8 x i16> %602, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %604 = add <8 x i16> %24, %601
  %605 = lshr <8 x i16> %604, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %606 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %603, <8 x i16> %605) #5
  %607 = bitcast i8* %599 to <16 x i8>*
  store <16 x i8> %606, <16 x i8>* %607, align 1
  %608 = getelementptr inbounds i8, i8* %588, i64 %1
  %609 = shufflevector <16 x i8> %528, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %610 = bitcast <16 x i8> %609 to <8 x i16>
  %611 = mul <8 x i16> %610, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %612 = mul <8 x i16> %610, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %613 = add <8 x i16> %21, %611
  %614 = lshr <8 x i16> %613, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %615 = add <8 x i16> %22, %612
  %616 = lshr <8 x i16> %615, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %617 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %614, <8 x i16> %616) #5
  %618 = bitcast i8* %608 to <16 x i8>*
  store <16 x i8> %617, <16 x i8>* %618, align 1
  %619 = getelementptr inbounds i8, i8* %608, i64 16
  %620 = mul <8 x i16> %610, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %621 = mul <8 x i16> %610, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %622 = add <8 x i16> %23, %620
  %623 = lshr <8 x i16> %622, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %624 = add <8 x i16> %24, %621
  %625 = lshr <8 x i16> %624, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %626 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %623, <8 x i16> %625) #5
  %627 = bitcast i8* %619 to <16 x i8>*
  store <16 x i8> %626, <16 x i8>* %627, align 1
  %628 = getelementptr inbounds i8, i8* %608, i64 %1
  %629 = shufflevector <16 x i8> %528, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %630 = bitcast <16 x i8> %629 to <8 x i16>
  %631 = mul <8 x i16> %630, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %632 = mul <8 x i16> %630, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %633 = add <8 x i16> %21, %631
  %634 = lshr <8 x i16> %633, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %635 = add <8 x i16> %22, %632
  %636 = lshr <8 x i16> %635, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %637 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %634, <8 x i16> %636) #5
  %638 = bitcast i8* %628 to <16 x i8>*
  store <16 x i8> %637, <16 x i8>* %638, align 1
  %639 = getelementptr inbounds i8, i8* %628, i64 16
  %640 = mul <8 x i16> %630, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %641 = mul <8 x i16> %630, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %642 = add <8 x i16> %23, %640
  %643 = lshr <8 x i16> %642, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %644 = add <8 x i16> %24, %641
  %645 = lshr <8 x i16> %644, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %646 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %643, <8 x i16> %645) #5
  %647 = bitcast i8* %639 to <16 x i8>*
  store <16 x i8> %646, <16 x i8>* %647, align 1
  %648 = getelementptr inbounds i8, i8* %628, i64 %1
  %649 = shufflevector <16 x i8> %528, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %650 = bitcast <16 x i8> %649 to <8 x i16>
  %651 = mul <8 x i16> %650, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %652 = mul <8 x i16> %650, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %653 = add <8 x i16> %21, %651
  %654 = lshr <8 x i16> %653, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %655 = add <8 x i16> %22, %652
  %656 = lshr <8 x i16> %655, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %657 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %654, <8 x i16> %656) #5
  %658 = bitcast i8* %648 to <16 x i8>*
  store <16 x i8> %657, <16 x i8>* %658, align 1
  %659 = getelementptr inbounds i8, i8* %648, i64 16
  %660 = mul <8 x i16> %650, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %661 = mul <8 x i16> %650, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %662 = add <8 x i16> %23, %660
  %663 = lshr <8 x i16> %662, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %664 = add <8 x i16> %24, %661
  %665 = lshr <8 x i16> %664, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %666 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %663, <8 x i16> %665) #5
  %667 = bitcast i8* %659 to <16 x i8>*
  store <16 x i8> %666, <16 x i8>* %667, align 1
  %668 = getelementptr inbounds i8, i8* %648, i64 %1
  %669 = shufflevector <16 x i8> %528, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %670 = bitcast <16 x i8> %669 to <8 x i16>
  %671 = mul <8 x i16> %670, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %672 = mul <8 x i16> %670, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %673 = add <8 x i16> %21, %671
  %674 = lshr <8 x i16> %673, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %675 = add <8 x i16> %22, %672
  %676 = lshr <8 x i16> %675, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %677 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %674, <8 x i16> %676) #5
  %678 = bitcast i8* %668 to <16 x i8>*
  store <16 x i8> %677, <16 x i8>* %678, align 1
  %679 = getelementptr inbounds i8, i8* %668, i64 16
  %680 = mul <8 x i16> %670, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %681 = mul <8 x i16> %670, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %682 = add <8 x i16> %23, %680
  %683 = lshr <8 x i16> %682, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %684 = add <8 x i16> %24, %681
  %685 = lshr <8 x i16> %684, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %686 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %683, <8 x i16> %685) #5
  %687 = bitcast i8* %679 to <16 x i8>*
  store <16 x i8> %686, <16 x i8>* %687, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal32x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 16, i16 31, i16 46, i16 60, i16 74, i16 87, i16 99>
  %11 = mul <8 x i16> %9, <i16 111, i16 123, i16 134, i16 145, i16 155, i16 164, i16 173, i16 182>
  %12 = mul <8 x i16> %9, <i16 190, i16 197, i16 204, i16 211, i16 217, i16 222, i16 227, i16 231>
  %13 = mul <8 x i16> %9, <i16 235, i16 239, i16 242, i16 244, i16 246, i16 247, i16 248, i16 248>
  %14 = add <8 x i16> %10, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %15 = add <8 x i16> %11, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %16 = add <8 x i16> %12, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %17 = add <8 x i16> %13, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  br label %19

18:                                               ; preds = %19
  ret void

19:                                               ; preds = %4, %19
  %20 = phi i64 [ 0, %4 ], [ %190, %19 ]
  %21 = phi i8* [ %0, %4 ], [ %189, %19 ]
  %22 = getelementptr inbounds i8, i8* %3, i64 %20
  %23 = bitcast i8* %22 to i64*
  %24 = load i64, i64* %23, align 1
  %25 = insertelement <2 x i64> undef, i64 %24, i32 0
  %26 = bitcast <2 x i64> %25 to <16 x i8>
  %27 = shufflevector <16 x i8> %26, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %28 = zext <8 x i8> %27 to <8 x i16>
  %29 = bitcast <8 x i16> %28 to <16 x i8>
  %30 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %31 = bitcast <16 x i8> %30 to <8 x i16>
  %32 = mul <8 x i16> %31, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %33 = mul <8 x i16> %31, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %34 = add <8 x i16> %14, %32
  %35 = lshr <8 x i16> %34, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %36 = add <8 x i16> %15, %33
  %37 = lshr <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %35, <8 x i16> %37) #5
  %39 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %38, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %21, i64 16
  %41 = mul <8 x i16> %31, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %42 = mul <8 x i16> %31, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %43 = add <8 x i16> %16, %41
  %44 = lshr <8 x i16> %43, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %45 = add <8 x i16> %17, %42
  %46 = lshr <8 x i16> %45, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %47 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %44, <8 x i16> %46) #5
  %48 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %21, i64 %1
  %50 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %51 = bitcast <16 x i8> %50 to <8 x i16>
  %52 = mul <8 x i16> %51, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %53 = mul <8 x i16> %51, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %54 = add <8 x i16> %14, %52
  %55 = lshr <8 x i16> %54, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %56 = add <8 x i16> %15, %53
  %57 = lshr <8 x i16> %56, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %58 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %57) #5
  %59 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %58, <16 x i8>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %49, i64 16
  %61 = mul <8 x i16> %51, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %62 = mul <8 x i16> %51, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %63 = add <8 x i16> %16, %61
  %64 = lshr <8 x i16> %63, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %65 = add <8 x i16> %17, %62
  %66 = lshr <8 x i16> %65, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %64, <8 x i16> %66) #5
  %68 = bitcast i8* %60 to <16 x i8>*
  store <16 x i8> %67, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %49, i64 %1
  %70 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %71 = bitcast <16 x i8> %70 to <8 x i16>
  %72 = mul <8 x i16> %71, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %73 = mul <8 x i16> %71, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %74 = add <8 x i16> %14, %72
  %75 = lshr <8 x i16> %74, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %76 = add <8 x i16> %15, %73
  %77 = lshr <8 x i16> %76, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %78 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %75, <8 x i16> %77) #5
  %79 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %78, <16 x i8>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %69, i64 16
  %81 = mul <8 x i16> %71, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %82 = mul <8 x i16> %71, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %83 = add <8 x i16> %16, %81
  %84 = lshr <8 x i16> %83, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %85 = add <8 x i16> %17, %82
  %86 = lshr <8 x i16> %85, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %84, <8 x i16> %86) #5
  %88 = bitcast i8* %80 to <16 x i8>*
  store <16 x i8> %87, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %69, i64 %1
  %90 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %91 = bitcast <16 x i8> %90 to <8 x i16>
  %92 = mul <8 x i16> %91, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %93 = mul <8 x i16> %91, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %94 = add <8 x i16> %14, %92
  %95 = lshr <8 x i16> %94, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %96 = add <8 x i16> %15, %93
  %97 = lshr <8 x i16> %96, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %98 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %95, <8 x i16> %97) #5
  %99 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %98, <16 x i8>* %99, align 1
  %100 = getelementptr inbounds i8, i8* %89, i64 16
  %101 = mul <8 x i16> %91, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %102 = mul <8 x i16> %91, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %103 = add <8 x i16> %16, %101
  %104 = lshr <8 x i16> %103, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %105 = add <8 x i16> %17, %102
  %106 = lshr <8 x i16> %105, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %107 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %104, <8 x i16> %106) #5
  %108 = bitcast i8* %100 to <16 x i8>*
  store <16 x i8> %107, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %89, i64 %1
  %110 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %111 = bitcast <16 x i8> %110 to <8 x i16>
  %112 = mul <8 x i16> %111, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %113 = mul <8 x i16> %111, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %114 = add <8 x i16> %14, %112
  %115 = lshr <8 x i16> %114, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %116 = add <8 x i16> %15, %113
  %117 = lshr <8 x i16> %116, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %118 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %115, <8 x i16> %117) #5
  %119 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %118, <16 x i8>* %119, align 1
  %120 = getelementptr inbounds i8, i8* %109, i64 16
  %121 = mul <8 x i16> %111, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %122 = mul <8 x i16> %111, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %123 = add <8 x i16> %16, %121
  %124 = lshr <8 x i16> %123, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %125 = add <8 x i16> %17, %122
  %126 = lshr <8 x i16> %125, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %127 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %124, <8 x i16> %126) #5
  %128 = bitcast i8* %120 to <16 x i8>*
  store <16 x i8> %127, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %109, i64 %1
  %130 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %131 = bitcast <16 x i8> %130 to <8 x i16>
  %132 = mul <8 x i16> %131, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %133 = mul <8 x i16> %131, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %134 = add <8 x i16> %14, %132
  %135 = lshr <8 x i16> %134, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %136 = add <8 x i16> %15, %133
  %137 = lshr <8 x i16> %136, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %138 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %135, <8 x i16> %137) #5
  %139 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %138, <16 x i8>* %139, align 1
  %140 = getelementptr inbounds i8, i8* %129, i64 16
  %141 = mul <8 x i16> %131, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %142 = mul <8 x i16> %131, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %143 = add <8 x i16> %16, %141
  %144 = lshr <8 x i16> %143, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %145 = add <8 x i16> %17, %142
  %146 = lshr <8 x i16> %145, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %147 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %144, <8 x i16> %146) #5
  %148 = bitcast i8* %140 to <16 x i8>*
  store <16 x i8> %147, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %129, i64 %1
  %150 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %151 = bitcast <16 x i8> %150 to <8 x i16>
  %152 = mul <8 x i16> %151, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %153 = mul <8 x i16> %151, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %154 = add <8 x i16> %14, %152
  %155 = lshr <8 x i16> %154, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %156 = add <8 x i16> %15, %153
  %157 = lshr <8 x i16> %156, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %158 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %157) #5
  %159 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %158, <16 x i8>* %159, align 1
  %160 = getelementptr inbounds i8, i8* %149, i64 16
  %161 = mul <8 x i16> %151, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %162 = mul <8 x i16> %151, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %163 = add <8 x i16> %16, %161
  %164 = lshr <8 x i16> %163, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %165 = add <8 x i16> %17, %162
  %166 = lshr <8 x i16> %165, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %167 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %164, <8 x i16> %166) #5
  %168 = bitcast i8* %160 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 1
  %169 = getelementptr inbounds i8, i8* %149, i64 %1
  %170 = shufflevector <16 x i8> %29, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %171 = bitcast <16 x i8> %170 to <8 x i16>
  %172 = mul <8 x i16> %171, <i16 255, i16 240, i16 225, i16 210, i16 196, i16 182, i16 169, i16 157>
  %173 = mul <8 x i16> %171, <i16 145, i16 133, i16 122, i16 111, i16 101, i16 92, i16 83, i16 74>
  %174 = add <8 x i16> %14, %172
  %175 = lshr <8 x i16> %174, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %176 = add <8 x i16> %15, %173
  %177 = lshr <8 x i16> %176, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %178 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %175, <8 x i16> %177) #5
  %179 = bitcast i8* %169 to <16 x i8>*
  store <16 x i8> %178, <16 x i8>* %179, align 1
  %180 = getelementptr inbounds i8, i8* %169, i64 16
  %181 = mul <8 x i16> %171, <i16 66, i16 59, i16 52, i16 45, i16 39, i16 34, i16 29, i16 25>
  %182 = mul <8 x i16> %171, <i16 21, i16 17, i16 14, i16 12, i16 10, i16 9, i16 8, i16 8>
  %183 = add <8 x i16> %16, %181
  %184 = lshr <8 x i16> %183, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %185 = add <8 x i16> %17, %182
  %186 = lshr <8 x i16> %185, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %187 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %184, <8 x i16> %186) #5
  %188 = bitcast i8* %180 to <16 x i8>*
  store <16 x i8> %187, <16 x i8>* %188, align 1
  %189 = getelementptr inbounds i8, i8* %169, i64 %1
  %190 = add nuw nsw i64 %20, 8
  %191 = icmp ult i64 %190, 64
  br i1 %191, label %19, label %18
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal64x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = mul <8 x i16> %9, <i16 1, i16 8, i16 16, i16 23, i16 31, i16 38, i16 46, i16 53>
  %17 = mul <8 x i16> %9, <i16 60, i16 67, i16 74, i16 80, i16 87, i16 93, i16 100, i16 106>
  %18 = mul <8 x i16> %9, <i16 112, i16 118, i16 123, i16 129, i16 135, i16 140, i16 145, i16 150>
  %19 = mul <8 x i16> %9, <i16 155, i16 160, i16 165, i16 170, i16 174, i16 179, i16 183, i16 187>
  %20 = mul <8 x i16> %9, <i16 191, i16 195, i16 199, i16 202, i16 206, i16 209, i16 212, i16 215>
  %21 = mul <8 x i16> %9, <i16 218, i16 221, i16 224, i16 227, i16 229, i16 231, i16 234, i16 236>
  %22 = mul <8 x i16> %9, <i16 238, i16 240, i16 241, i16 243, i16 244, i16 246, i16 247, i16 248>
  %23 = mul <8 x i16> %9, <i16 249, i16 250, i16 250, i16 251, i16 251, i16 252, i16 252, i16 252>
  %24 = bitcast <8 x i16> %15 to <16 x i8>
  %25 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %26 = add <8 x i16> %17, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %27 = add <8 x i16> %18, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %28 = add <8 x i16> %19, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %29 = add <8 x i16> %20, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %30 = add <8 x i16> %21, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %31 = add <8 x i16> %22, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %32 = add <8 x i16> %23, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  br label %42

33:                                               ; preds = %42
  %34 = getelementptr inbounds i8, i8* %3, i64 8
  %35 = bitcast i8* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = bitcast <2 x i64> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %40 = zext <8 x i8> %39 to <8 x i16>
  %41 = bitcast <8 x i16> %40 to <16 x i8>
  br label %89

42:                                               ; preds = %4, %42
  %43 = phi i32 [ 16777472, %4 ], [ %86, %42 ]
  %44 = phi i8* [ %0, %4 ], [ %85, %42 ]
  %45 = insertelement <4 x i32> undef, i32 %43, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <4 x i32> %46 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %24, <16 x i8> %47) #5
  %49 = bitcast <16 x i8> %48 to <8 x i16>
  %50 = mul <8 x i16> %49, <i16 255, i16 248, i16 240, i16 233, i16 225, i16 218, i16 210, i16 203>
  %51 = mul <8 x i16> %49, <i16 196, i16 189, i16 182, i16 176, i16 169, i16 163, i16 156, i16 150>
  %52 = add <8 x i16> %25, %50
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = add <8 x i16> %26, %51
  %55 = lshr <8 x i16> %54, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %55) #5
  %57 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %44, i64 16
  %59 = mul <8 x i16> %49, <i16 144, i16 138, i16 133, i16 127, i16 121, i16 116, i16 111, i16 106>
  %60 = mul <8 x i16> %49, <i16 101, i16 96, i16 91, i16 86, i16 82, i16 77, i16 73, i16 69>
  %61 = add <8 x i16> %27, %59
  %62 = lshr <8 x i16> %61, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %63 = add <8 x i16> %28, %60
  %64 = lshr <8 x i16> %63, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %65 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %62, <8 x i16> %64) #5
  %66 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %65, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %44, i64 32
  %68 = mul <8 x i16> %49, <i16 65, i16 61, i16 57, i16 54, i16 50, i16 47, i16 44, i16 41>
  %69 = mul <8 x i16> %49, <i16 38, i16 35, i16 32, i16 29, i16 27, i16 25, i16 22, i16 20>
  %70 = add <8 x i16> %29, %68
  %71 = lshr <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = add <8 x i16> %30, %69
  %73 = lshr <8 x i16> %72, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %74 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %71, <8 x i16> %73) #5
  %75 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %74, <16 x i8>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %44, i64 48
  %77 = mul <8 x i16> %49, <i16 18, i16 16, i16 15, i16 13, i16 12, i16 10, i16 9, i16 8>
  %78 = mul <8 x i16> %49, <i16 7, i16 6, i16 6, i16 5, i16 5, i16 4, i16 4, i16 4>
  %79 = add <8 x i16> %31, %77
  %80 = lshr <8 x i16> %79, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %81 = add <8 x i16> %32, %78
  %82 = lshr <8 x i16> %81, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %83 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %80, <8 x i16> %82) #5
  %84 = bitcast i8* %76 to <16 x i8>*
  store <16 x i8> %83, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %44, i64 %1
  %86 = add nuw nsw i32 %43, 33686018
  %87 = icmp ult i32 %86, 252579599
  br i1 %87, label %42, label %33

88:                                               ; preds = %89
  ret void

89:                                               ; preds = %33, %89
  %90 = phi i32 [ 16777472, %33 ], [ %133, %89 ]
  %91 = phi i8* [ %85, %33 ], [ %132, %89 ]
  %92 = insertelement <4 x i32> undef, i32 %90, i32 0
  %93 = shufflevector <4 x i32> %92, <4 x i32> undef, <4 x i32> zeroinitializer
  %94 = bitcast <4 x i32> %93 to <16 x i8>
  %95 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %41, <16 x i8> %94) #5
  %96 = bitcast <16 x i8> %95 to <8 x i16>
  %97 = mul <8 x i16> %96, <i16 255, i16 248, i16 240, i16 233, i16 225, i16 218, i16 210, i16 203>
  %98 = mul <8 x i16> %96, <i16 196, i16 189, i16 182, i16 176, i16 169, i16 163, i16 156, i16 150>
  %99 = add <8 x i16> %25, %97
  %100 = lshr <8 x i16> %99, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %101 = add <8 x i16> %26, %98
  %102 = lshr <8 x i16> %101, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %103 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %102) #5
  %104 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %91, i64 16
  %106 = mul <8 x i16> %96, <i16 144, i16 138, i16 133, i16 127, i16 121, i16 116, i16 111, i16 106>
  %107 = mul <8 x i16> %96, <i16 101, i16 96, i16 91, i16 86, i16 82, i16 77, i16 73, i16 69>
  %108 = add <8 x i16> %27, %106
  %109 = lshr <8 x i16> %108, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %110 = add <8 x i16> %28, %107
  %111 = lshr <8 x i16> %110, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %112 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %111) #5
  %113 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %112, <16 x i8>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %91, i64 32
  %115 = mul <8 x i16> %96, <i16 65, i16 61, i16 57, i16 54, i16 50, i16 47, i16 44, i16 41>
  %116 = mul <8 x i16> %96, <i16 38, i16 35, i16 32, i16 29, i16 27, i16 25, i16 22, i16 20>
  %117 = add <8 x i16> %29, %115
  %118 = lshr <8 x i16> %117, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %119 = add <8 x i16> %30, %116
  %120 = lshr <8 x i16> %119, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %121 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %120) #5
  %122 = bitcast i8* %114 to <16 x i8>*
  store <16 x i8> %121, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %91, i64 48
  %124 = mul <8 x i16> %96, <i16 18, i16 16, i16 15, i16 13, i16 12, i16 10, i16 9, i16 8>
  %125 = mul <8 x i16> %96, <i16 7, i16 6, i16 6, i16 5, i16 5, i16 4, i16 4, i16 4>
  %126 = add <8 x i16> %31, %124
  %127 = lshr <8 x i16> %126, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %128 = add <8 x i16> %32, %125
  %129 = lshr <8 x i16> %128, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %130 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %127, <8 x i16> %129) #5
  %131 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %130, <16 x i8>* %131, align 1
  %132 = getelementptr inbounds i8, i8* %91, i64 %1
  %133 = add nuw nsw i32 %90, 33686018
  %134 = icmp ult i32 %133, 252579599
  br i1 %134, label %89, label %88
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal64x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = bitcast i8* %3 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %15 = zext <8 x i8> %14 to <8 x i16>
  %16 = mul <8 x i16> %9, <i16 1, i16 8, i16 16, i16 23, i16 31, i16 38, i16 46, i16 53>
  %17 = mul <8 x i16> %9, <i16 60, i16 67, i16 74, i16 80, i16 87, i16 93, i16 100, i16 106>
  %18 = mul <8 x i16> %9, <i16 112, i16 118, i16 123, i16 129, i16 135, i16 140, i16 145, i16 150>
  %19 = mul <8 x i16> %9, <i16 155, i16 160, i16 165, i16 170, i16 174, i16 179, i16 183, i16 187>
  %20 = mul <8 x i16> %9, <i16 191, i16 195, i16 199, i16 202, i16 206, i16 209, i16 212, i16 215>
  %21 = mul <8 x i16> %9, <i16 218, i16 221, i16 224, i16 227, i16 229, i16 231, i16 234, i16 236>
  %22 = mul <8 x i16> %9, <i16 238, i16 240, i16 241, i16 243, i16 244, i16 246, i16 247, i16 248>
  %23 = mul <8 x i16> %9, <i16 249, i16 250, i16 250, i16 251, i16 251, i16 252, i16 252, i16 252>
  %24 = bitcast <8 x i16> %15 to <16 x i8>
  %25 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %26 = add <8 x i16> %17, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %27 = add <8 x i16> %18, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %28 = add <8 x i16> %19, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %29 = add <8 x i16> %20, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %30 = add <8 x i16> %21, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %31 = add <8 x i16> %22, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %32 = add <8 x i16> %23, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  br label %42

33:                                               ; preds = %42
  %34 = getelementptr inbounds i8, i8* %3, i64 8
  %35 = bitcast i8* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = bitcast <2 x i64> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %40 = zext <8 x i8> %39 to <8 x i16>
  %41 = bitcast <8 x i16> %40 to <16 x i8>
  br label %97

42:                                               ; preds = %4, %42
  %43 = phi i8* [ %0, %4 ], [ %85, %42 ]
  %44 = phi i32 [ 16777472, %4 ], [ %86, %42 ]
  %45 = insertelement <4 x i32> undef, i32 %44, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <4 x i32> %46 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %24, <16 x i8> %47) #5
  %49 = bitcast <16 x i8> %48 to <8 x i16>
  %50 = mul <8 x i16> %49, <i16 255, i16 248, i16 240, i16 233, i16 225, i16 218, i16 210, i16 203>
  %51 = mul <8 x i16> %49, <i16 196, i16 189, i16 182, i16 176, i16 169, i16 163, i16 156, i16 150>
  %52 = add <8 x i16> %25, %50
  %53 = lshr <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = add <8 x i16> %26, %51
  %55 = lshr <8 x i16> %54, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %55) #5
  %57 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %43, i64 16
  %59 = mul <8 x i16> %49, <i16 144, i16 138, i16 133, i16 127, i16 121, i16 116, i16 111, i16 106>
  %60 = mul <8 x i16> %49, <i16 101, i16 96, i16 91, i16 86, i16 82, i16 77, i16 73, i16 69>
  %61 = add <8 x i16> %27, %59
  %62 = lshr <8 x i16> %61, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %63 = add <8 x i16> %28, %60
  %64 = lshr <8 x i16> %63, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %65 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %62, <8 x i16> %64) #5
  %66 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %65, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %43, i64 32
  %68 = mul <8 x i16> %49, <i16 65, i16 61, i16 57, i16 54, i16 50, i16 47, i16 44, i16 41>
  %69 = mul <8 x i16> %49, <i16 38, i16 35, i16 32, i16 29, i16 27, i16 25, i16 22, i16 20>
  %70 = add <8 x i16> %29, %68
  %71 = lshr <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = add <8 x i16> %30, %69
  %73 = lshr <8 x i16> %72, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %74 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %71, <8 x i16> %73) #5
  %75 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %74, <16 x i8>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %43, i64 48
  %77 = mul <8 x i16> %49, <i16 18, i16 16, i16 15, i16 13, i16 12, i16 10, i16 9, i16 8>
  %78 = mul <8 x i16> %49, <i16 7, i16 6, i16 6, i16 5, i16 5, i16 4, i16 4, i16 4>
  %79 = add <8 x i16> %31, %77
  %80 = lshr <8 x i16> %79, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %81 = add <8 x i16> %32, %78
  %82 = lshr <8 x i16> %81, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %83 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %80, <8 x i16> %82) #5
  %84 = bitcast i8* %76 to <16 x i8>*
  store <16 x i8> %83, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %43, i64 %1
  %86 = add nuw nsw i32 %44, 33686018
  %87 = icmp ult i32 %86, 252579599
  br i1 %87, label %42, label %33

88:                                               ; preds = %97
  %89 = getelementptr inbounds i8, i8* %3, i64 16
  %90 = bitcast i8* %89 to i64*
  %91 = load i64, i64* %90, align 1
  %92 = insertelement <2 x i64> undef, i64 %91, i32 0
  %93 = bitcast <2 x i64> %92 to <16 x i8>
  %94 = shufflevector <16 x i8> %93, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %95 = zext <8 x i8> %94 to <8 x i16>
  %96 = bitcast <8 x i16> %95 to <16 x i8>
  br label %152

97:                                               ; preds = %33, %97
  %98 = phi i8* [ %85, %33 ], [ %140, %97 ]
  %99 = phi i32 [ 16777472, %33 ], [ %141, %97 ]
  %100 = insertelement <4 x i32> undef, i32 %99, i32 0
  %101 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> zeroinitializer
  %102 = bitcast <4 x i32> %101 to <16 x i8>
  %103 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %41, <16 x i8> %102) #5
  %104 = bitcast <16 x i8> %103 to <8 x i16>
  %105 = mul <8 x i16> %104, <i16 255, i16 248, i16 240, i16 233, i16 225, i16 218, i16 210, i16 203>
  %106 = mul <8 x i16> %104, <i16 196, i16 189, i16 182, i16 176, i16 169, i16 163, i16 156, i16 150>
  %107 = add <8 x i16> %25, %105
  %108 = lshr <8 x i16> %107, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %109 = add <8 x i16> %26, %106
  %110 = lshr <8 x i16> %109, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %108, <8 x i16> %110) #5
  %112 = bitcast i8* %98 to <16 x i8>*
  store <16 x i8> %111, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %98, i64 16
  %114 = mul <8 x i16> %104, <i16 144, i16 138, i16 133, i16 127, i16 121, i16 116, i16 111, i16 106>
  %115 = mul <8 x i16> %104, <i16 101, i16 96, i16 91, i16 86, i16 82, i16 77, i16 73, i16 69>
  %116 = add <8 x i16> %27, %114
  %117 = lshr <8 x i16> %116, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %118 = add <8 x i16> %28, %115
  %119 = lshr <8 x i16> %118, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %120 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %117, <8 x i16> %119) #5
  %121 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %120, <16 x i8>* %121, align 1
  %122 = getelementptr inbounds i8, i8* %98, i64 32
  %123 = mul <8 x i16> %104, <i16 65, i16 61, i16 57, i16 54, i16 50, i16 47, i16 44, i16 41>
  %124 = mul <8 x i16> %104, <i16 38, i16 35, i16 32, i16 29, i16 27, i16 25, i16 22, i16 20>
  %125 = add <8 x i16> %29, %123
  %126 = lshr <8 x i16> %125, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %127 = add <8 x i16> %30, %124
  %128 = lshr <8 x i16> %127, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %126, <8 x i16> %128) #5
  %130 = bitcast i8* %122 to <16 x i8>*
  store <16 x i8> %129, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %98, i64 48
  %132 = mul <8 x i16> %104, <i16 18, i16 16, i16 15, i16 13, i16 12, i16 10, i16 9, i16 8>
  %133 = mul <8 x i16> %104, <i16 7, i16 6, i16 6, i16 5, i16 5, i16 4, i16 4, i16 4>
  %134 = add <8 x i16> %31, %132
  %135 = lshr <8 x i16> %134, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %136 = add <8 x i16> %32, %133
  %137 = lshr <8 x i16> %136, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %138 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %135, <8 x i16> %137) #5
  %139 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %138, <16 x i8>* %139, align 1
  %140 = getelementptr inbounds i8, i8* %98, i64 %1
  %141 = add nuw nsw i32 %99, 33686018
  %142 = icmp ult i32 %141, 252579599
  br i1 %142, label %97, label %88

143:                                              ; preds = %152
  %144 = getelementptr inbounds i8, i8* %3, i64 24
  %145 = bitcast i8* %144 to i64*
  %146 = load i64, i64* %145, align 1
  %147 = insertelement <2 x i64> undef, i64 %146, i32 0
  %148 = bitcast <2 x i64> %147 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %150 = zext <8 x i8> %149 to <8 x i16>
  %151 = bitcast <8 x i16> %150 to <16 x i8>
  br label %199

152:                                              ; preds = %88, %152
  %153 = phi i8* [ %140, %88 ], [ %195, %152 ]
  %154 = phi i32 [ 16777472, %88 ], [ %196, %152 ]
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = bitcast <4 x i32> %156 to <16 x i8>
  %158 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %96, <16 x i8> %157) #5
  %159 = bitcast <16 x i8> %158 to <8 x i16>
  %160 = mul <8 x i16> %159, <i16 255, i16 248, i16 240, i16 233, i16 225, i16 218, i16 210, i16 203>
  %161 = mul <8 x i16> %159, <i16 196, i16 189, i16 182, i16 176, i16 169, i16 163, i16 156, i16 150>
  %162 = add <8 x i16> %25, %160
  %163 = lshr <8 x i16> %162, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %164 = add <8 x i16> %26, %161
  %165 = lshr <8 x i16> %164, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %166 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %165) #5
  %167 = bitcast i8* %153 to <16 x i8>*
  store <16 x i8> %166, <16 x i8>* %167, align 1
  %168 = getelementptr inbounds i8, i8* %153, i64 16
  %169 = mul <8 x i16> %159, <i16 144, i16 138, i16 133, i16 127, i16 121, i16 116, i16 111, i16 106>
  %170 = mul <8 x i16> %159, <i16 101, i16 96, i16 91, i16 86, i16 82, i16 77, i16 73, i16 69>
  %171 = add <8 x i16> %27, %169
  %172 = lshr <8 x i16> %171, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %173 = add <8 x i16> %28, %170
  %174 = lshr <8 x i16> %173, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %175 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %172, <8 x i16> %174) #5
  %176 = bitcast i8* %168 to <16 x i8>*
  store <16 x i8> %175, <16 x i8>* %176, align 1
  %177 = getelementptr inbounds i8, i8* %153, i64 32
  %178 = mul <8 x i16> %159, <i16 65, i16 61, i16 57, i16 54, i16 50, i16 47, i16 44, i16 41>
  %179 = mul <8 x i16> %159, <i16 38, i16 35, i16 32, i16 29, i16 27, i16 25, i16 22, i16 20>
  %180 = add <8 x i16> %29, %178
  %181 = lshr <8 x i16> %180, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %182 = add <8 x i16> %30, %179
  %183 = lshr <8 x i16> %182, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %184 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %181, <8 x i16> %183) #5
  %185 = bitcast i8* %177 to <16 x i8>*
  store <16 x i8> %184, <16 x i8>* %185, align 1
  %186 = getelementptr inbounds i8, i8* %153, i64 48
  %187 = mul <8 x i16> %159, <i16 18, i16 16, i16 15, i16 13, i16 12, i16 10, i16 9, i16 8>
  %188 = mul <8 x i16> %159, <i16 7, i16 6, i16 6, i16 5, i16 5, i16 4, i16 4, i16 4>
  %189 = add <8 x i16> %31, %187
  %190 = lshr <8 x i16> %189, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %191 = add <8 x i16> %32, %188
  %192 = lshr <8 x i16> %191, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %193 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %190, <8 x i16> %192) #5
  %194 = bitcast i8* %186 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 1
  %195 = getelementptr inbounds i8, i8* %153, i64 %1
  %196 = add nuw nsw i32 %154, 33686018
  %197 = icmp ult i32 %196, 252579599
  br i1 %197, label %152, label %143

198:                                              ; preds = %199
  ret void

199:                                              ; preds = %143, %199
  %200 = phi i32 [ 16777472, %143 ], [ %243, %199 ]
  %201 = phi i8* [ %195, %143 ], [ %242, %199 ]
  %202 = insertelement <4 x i32> undef, i32 %200, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = bitcast <4 x i32> %203 to <16 x i8>
  %205 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %151, <16 x i8> %204) #5
  %206 = bitcast <16 x i8> %205 to <8 x i16>
  %207 = mul <8 x i16> %206, <i16 255, i16 248, i16 240, i16 233, i16 225, i16 218, i16 210, i16 203>
  %208 = mul <8 x i16> %206, <i16 196, i16 189, i16 182, i16 176, i16 169, i16 163, i16 156, i16 150>
  %209 = add <8 x i16> %25, %207
  %210 = lshr <8 x i16> %209, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %211 = add <8 x i16> %26, %208
  %212 = lshr <8 x i16> %211, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %213 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %210, <8 x i16> %212) #5
  %214 = bitcast i8* %201 to <16 x i8>*
  store <16 x i8> %213, <16 x i8>* %214, align 1
  %215 = getelementptr inbounds i8, i8* %201, i64 16
  %216 = mul <8 x i16> %206, <i16 144, i16 138, i16 133, i16 127, i16 121, i16 116, i16 111, i16 106>
  %217 = mul <8 x i16> %206, <i16 101, i16 96, i16 91, i16 86, i16 82, i16 77, i16 73, i16 69>
  %218 = add <8 x i16> %27, %216
  %219 = lshr <8 x i16> %218, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %220 = add <8 x i16> %28, %217
  %221 = lshr <8 x i16> %220, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %222 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %219, <8 x i16> %221) #5
  %223 = bitcast i8* %215 to <16 x i8>*
  store <16 x i8> %222, <16 x i8>* %223, align 1
  %224 = getelementptr inbounds i8, i8* %201, i64 32
  %225 = mul <8 x i16> %206, <i16 65, i16 61, i16 57, i16 54, i16 50, i16 47, i16 44, i16 41>
  %226 = mul <8 x i16> %206, <i16 38, i16 35, i16 32, i16 29, i16 27, i16 25, i16 22, i16 20>
  %227 = add <8 x i16> %29, %225
  %228 = lshr <8 x i16> %227, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %229 = add <8 x i16> %30, %226
  %230 = lshr <8 x i16> %229, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %231 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %228, <8 x i16> %230) #5
  %232 = bitcast i8* %224 to <16 x i8>*
  store <16 x i8> %231, <16 x i8>* %232, align 1
  %233 = getelementptr inbounds i8, i8* %201, i64 48
  %234 = mul <8 x i16> %206, <i16 18, i16 16, i16 15, i16 13, i16 12, i16 10, i16 9, i16 8>
  %235 = mul <8 x i16> %206, <i16 7, i16 6, i16 6, i16 5, i16 5, i16 4, i16 4, i16 4>
  %236 = add <8 x i16> %31, %234
  %237 = lshr <8 x i16> %236, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %238 = add <8 x i16> %32, %235
  %239 = lshr <8 x i16> %238, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %240 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %237, <8 x i16> %239) #5
  %241 = bitcast i8* %233 to <16 x i8>*
  store <16 x i8> %240, <16 x i8>* %241, align 1
  %242 = getelementptr inbounds i8, i8* %201, i64 %1
  %243 = add nuw nsw i32 %200, 33686018
  %244 = icmp ult i32 %243, 252579599
  br i1 %244, label %199, label %198
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_128SmoothHorizontal64x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #2 {
  %5 = getelementptr inbounds i8, i8* %2, i64 63
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i16
  %8 = insertelement <8 x i16> undef, i16 %7, i32 0
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> zeroinitializer
  %10 = mul <8 x i16> %9, <i16 1, i16 8, i16 16, i16 23, i16 31, i16 38, i16 46, i16 53>
  %11 = mul <8 x i16> %9, <i16 60, i16 67, i16 74, i16 80, i16 87, i16 93, i16 100, i16 106>
  %12 = mul <8 x i16> %9, <i16 112, i16 118, i16 123, i16 129, i16 135, i16 140, i16 145, i16 150>
  %13 = mul <8 x i16> %9, <i16 155, i16 160, i16 165, i16 170, i16 174, i16 179, i16 183, i16 187>
  %14 = mul <8 x i16> %9, <i16 191, i16 195, i16 199, i16 202, i16 206, i16 209, i16 212, i16 215>
  %15 = mul <8 x i16> %9, <i16 218, i16 221, i16 224, i16 227, i16 229, i16 231, i16 234, i16 236>
  %16 = mul <8 x i16> %9, <i16 238, i16 240, i16 241, i16 243, i16 244, i16 246, i16 247, i16 248>
  %17 = mul <8 x i16> %9, <i16 249, i16 250, i16 250, i16 251, i16 251, i16 252, i16 252, i16 252>
  %18 = add <8 x i16> %10, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %19 = add <8 x i16> %11, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %20 = add <8 x i16> %12, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %21 = add <8 x i16> %13, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %22 = add <8 x i16> %14, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %23 = add <8 x i16> %15, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %24 = add <8 x i16> %16, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  %25 = add <8 x i16> %17, <i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128>
  br label %27

26:                                               ; preds = %38
  ret void

27:                                               ; preds = %4, %38
  %28 = phi i64 [ 0, %4 ], [ %39, %38 ]
  %29 = phi i8* [ %0, %4 ], [ %84, %38 ]
  %30 = getelementptr inbounds i8, i8* %3, i64 %28
  %31 = bitcast i8* %30 to i64*
  %32 = load i64, i64* %31, align 1
  %33 = insertelement <2 x i64> undef, i64 %32, i32 0
  %34 = bitcast <2 x i64> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %36 = zext <8 x i8> %35 to <8 x i16>
  %37 = bitcast <8 x i16> %36 to <16 x i8>
  br label %41

38:                                               ; preds = %41
  %39 = add nuw nsw i64 %28, 8
  %40 = icmp ult i64 %39, 64
  br i1 %40, label %27, label %26

41:                                               ; preds = %27, %41
  %42 = phi i32 [ 16777472, %27 ], [ %85, %41 ]
  %43 = phi i8* [ %29, %27 ], [ %84, %41 ]
  %44 = insertelement <4 x i32> undef, i32 %42, i32 0
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> zeroinitializer
  %46 = bitcast <4 x i32> %45 to <16 x i8>
  %47 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %37, <16 x i8> %46) #5
  %48 = bitcast <16 x i8> %47 to <8 x i16>
  %49 = mul <8 x i16> %48, <i16 255, i16 248, i16 240, i16 233, i16 225, i16 218, i16 210, i16 203>
  %50 = mul <8 x i16> %48, <i16 196, i16 189, i16 182, i16 176, i16 169, i16 163, i16 156, i16 150>
  %51 = add <8 x i16> %18, %49
  %52 = lshr <8 x i16> %51, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %53 = add <8 x i16> %19, %50
  %54 = lshr <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %52, <8 x i16> %54) #5
  %56 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %55, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %43, i64 16
  %58 = mul <8 x i16> %48, <i16 144, i16 138, i16 133, i16 127, i16 121, i16 116, i16 111, i16 106>
  %59 = mul <8 x i16> %48, <i16 101, i16 96, i16 91, i16 86, i16 82, i16 77, i16 73, i16 69>
  %60 = add <8 x i16> %20, %58
  %61 = lshr <8 x i16> %60, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %62 = add <8 x i16> %21, %59
  %63 = lshr <8 x i16> %62, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %61, <8 x i16> %63) #5
  %65 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %64, <16 x i8>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %43, i64 32
  %67 = mul <8 x i16> %48, <i16 65, i16 61, i16 57, i16 54, i16 50, i16 47, i16 44, i16 41>
  %68 = mul <8 x i16> %48, <i16 38, i16 35, i16 32, i16 29, i16 27, i16 25, i16 22, i16 20>
  %69 = add <8 x i16> %22, %67
  %70 = lshr <8 x i16> %69, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %71 = add <8 x i16> %23, %68
  %72 = lshr <8 x i16> %71, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> %72) #5
  %74 = bitcast i8* %66 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %43, i64 48
  %76 = mul <8 x i16> %48, <i16 18, i16 16, i16 15, i16 13, i16 12, i16 10, i16 9, i16 8>
  %77 = mul <8 x i16> %48, <i16 7, i16 6, i16 6, i16 5, i16 5, i16 4, i16 4, i16 4>
  %78 = add <8 x i16> %24, %76
  %79 = lshr <8 x i16> %78, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %80 = add <8 x i16> %25, %77
  %81 = lshr <8 x i16> %80, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %82 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %81) #5
  %83 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %82, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %43, i64 %1
  %85 = add nuw nsw i32 %42, 33686018
  %86 = icmp ult i32 %85, 252579599
  br i1 %86, label %41, label %38
}

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #4

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
