; ModuleID = '../../third_party/libgav1/src/src/dsp/x86/warp_sse4.cc'
source_filename = "../../third_party/libgav1/src/src/dsp/x86/warp_sse4.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.libgav1::dsp::Dsp" = type { void (i8*, i8*, i32, i32, i8*, i64)*, void (i8*, i64, i8*, i32*)*, [2 x [3 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*]], [19 x void (i8*, i64, [32 x i16]*, i32)*], [19 x [3 x void ([32 x i16]*, i32, i32, i8*, i64)*]], [2 x [2 x [2 x [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i8*, i64)*]]]], [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i64)*], void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)*, void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i8*, i8, i8, i32, i32, i8*, i64)*, %"struct.libgav1::dsp::FilmGrainFuncs", void (i8*, i64, i8*, i8*, i8, i32, i32)*, [3 x void (i8*, i8*, i64, i8*, i64, i32, i32)*], void (i8*, i32, i32)*, void (i8*, i32)*, [19 x [10 x void (i8*, i64, i8*, i8*)*]], [4 x [5 x [2 x void (i8, i8, i32, i8*, i32, i32, i8*)*]]], [4 x [2 x void (i8*, i64, i32, i32, i32)*]], [2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*], [3 x [2 x void (i8*, i8*, i64, i8*, i64, i32, i32, i8*, i64)*]], void (%"struct.libgav1::ReferenceInfo"*, i32, i32, i32, i32, i32, i32, %"struct.libgav1::TemporalMotionField"*)*, [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32*, i32, %"union.libgav1::CompoundMotionVector"*)*], [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32, i32, %"struct.libgav1::MotionVector"*)*], [2 x void (i8*, i64, i32, i32, i8*, i64)*], void (i32, i32, i32, i8*)*, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, [6 x [6 x [2 x void (i8*, i8*, i8*, i64)*]]] }
%"struct.libgav1::dsp::FilmGrainFuncs" = type { [3 x void (%"struct.libgav1::FilmGrainParams"*, i8*)*], [2 x [4 x void (%"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i8*, i8*)*]], [2 x void (i8*, i32, i32, i32, i32, i32, i8*)*], void (i8*, i32, i32, i32, i32, i8*)*, void (i32, i8*, i8*, i8*)*, void (i8*, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64)*, [2 x void (i8, %"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64, i8*, i64)*] }
%"struct.libgav1::FilmGrainParams" = type { i8, i8, i8, i8, i8, i8, i8, i8, [14 x i8], [14 x i8], [10 x i8], [10 x i8], [10 x i8], [10 x i8], i8, i8, [24 x i8], [25 x i8], [25 x i8], i8, i16, i32, i32, i8, i8, i16, i8, i8, i16 }
%"struct.libgav1::RestorationUnitInfo" = type { i8, %"struct.libgav1::SgrProjInfo", [16 x i8], %"struct.libgav1::WienerInfo" }
%"struct.libgav1::SgrProjInfo" = type { i32, [2 x i32] }
%"struct.libgav1::WienerInfo" = type { [2 x i16], [28 x i8], [2 x [4 x i16]], [16 x i8] }
%"union.libgav1::RestorationBuffer" = type { %"struct.libgav1::SgrBuffer", [5024 x i8] }
%"struct.libgav1::SgrBuffer" = type { [1152 x i16], [1440 x i16], [1152 x i32], [1440 x i32], [1024 x i16], [768 x i16], [512 x i16], [1024 x i32], [768 x i32], [512 x i32], [288 x i8], [288 x i32] }
%"struct.libgav1::ReferenceInfo" = type { %"struct.std::__1::array", %"struct.std::__1::array.0", %"struct.std::__1::array.0", %"struct.std::__1::array.1", %"struct.std::__1::array.2", %"class.libgav1::Array2D", %"class.libgav1::Array2D.4" }
%"struct.std::__1::array" = type { [8 x i8] }
%"struct.std::__1::array.0" = type { [8 x i8] }
%"struct.std::__1::array.1" = type { [8 x i8] }
%"struct.std::__1::array.2" = type { [8 x i16] }
%"class.libgav1::Array2D" = type { %"class.std::__1::unique_ptr", i64, i64, %"class.libgav1::Array2DView" }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i8* }
%"class.libgav1::Array2DView" = type { i32, i32, i8* }
%"class.libgav1::Array2D.4" = type { %"class.std::__1::unique_ptr.5", i64, i64, %"class.libgav1::Array2DView.11" }
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.libgav1::MotionVector"* }
%"struct.libgav1::MotionVector" = type { %union.anon }
%union.anon = type { i32 }
%"class.libgav1::Array2DView.11" = type { i32, i32, %"struct.libgav1::MotionVector"* }
%"struct.libgav1::TemporalMotionField" = type { %"class.libgav1::Array2D.4", %"class.libgav1::Array2D.12" }
%"class.libgav1::Array2D.12" = type { %"class.std::__1::unique_ptr.13", i64, i64, %"class.libgav1::Array2DView.19" }
%"class.std::__1::unique_ptr.13" = type { %"class.std::__1::__compressed_pair.14" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.15" }
%"struct.std::__1::__compressed_pair_elem.15" = type { i8* }
%"class.libgav1::Array2DView.19" = type { i32, i32, i8* }
%"union.libgav1::CompoundMotionVector" = type { i64 }
%union.anon.20 = type { [15 x [8 x i16]] }
%union.anon.21 = type { [15 x [8 x i16]] }

@_ZN7libgav114kWarpedFiltersE = external local_unnamed_addr constant [193 x [8 x i16]], align 16
@_ZN7libgav115kWarpedFilters8E = external local_unnamed_addr constant [193 x [8 x i8]], align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN7libgav13dsp15WarpInit_SSE4_1Ev() local_unnamed_addr #0 {
  %1 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 8) #5
  %2 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 27
  %3 = bitcast void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)** %2 to <2 x void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*>*
  store <2 x void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*> <void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Warp_SSE4_1ILb1EEEvPKvliiPKiiiiiiissssPvl, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Warp_SSE4_1ILb0EEEvPKvliiPKiiiiiiissssPvl>, <2 x void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*>* %3, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

declare %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Warp_SSE4_1ILb0EEEvPKvliiPKiiiiiiissssPvl(i8* nocapture readonly, i64, i32, i32, i32* nocapture readonly, i32, i32, i32, i32, i32, i32, i16 signext, i16 signext, i16 signext, i16 signext, i8* nocapture, i64) #3 {
  %18 = alloca %union.anon.20, align 16
  %19 = add i32 %7, 4
  %20 = add i32 %8, 4
  %21 = shl i32 %20, %6
  %22 = add i32 %19, %9
  %23 = shl i32 %22, %5
  %24 = add i32 %20, %10
  %25 = shl i32 %24, %6
  %26 = shl nsw i64 %16, 3
  %27 = shl i32 %19, %5
  %28 = bitcast %union.anon.20* %18 to i8*
  %29 = getelementptr inbounds i32, i32* %4, i64 2
  %30 = getelementptr inbounds i32, i32* %4, i64 3
  %31 = getelementptr inbounds i32, i32* %4, i64 4
  %32 = getelementptr inbounds i32, i32* %4, i64 5
  %33 = getelementptr inbounds i32, i32* %4, i64 1
  %34 = sext i16 %11 to i32
  %35 = sext i16 %12 to i32
  %36 = mul nsw i32 %35, -7
  %37 = shl nsw i32 %34, 2
  %38 = add nsw i32 %34, 512
  %39 = add nsw i32 %3, -1
  %40 = sext i16 %13 to i32
  %41 = sext i16 %14 to i32
  %42 = shl nsw i32 %41, 2
  %43 = shl nsw i32 %40, 2
  %44 = sext i32 %2 to i64
  %45 = getelementptr inbounds i8, i8* %0, i64 -1
  %46 = getelementptr inbounds i8, i8* %45, i64 %44
  %47 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 0, i64 8
  %48 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 0, i64 9
  %49 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 0, i64 10
  %50 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 0, i64 11
  %51 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 0, i64 12
  %52 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 0, i64 13
  %53 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 0, i64 14
  %54 = shl i32 8, %5
  %55 = shl i32 8, %6
  %56 = bitcast %union.anon.20* %18 to <8 x i16>*
  br label %57

57:                                               ; preds = %901, %17
  %58 = phi i8* [ %15, %17 ], [ %902, %901 ]
  %59 = phi i32 [ %21, %17 ], [ %903, %901 ]
  br label %60

60:                                               ; preds = %897, %57
  %61 = phi i32 [ %27, %57 ], [ %898, %897 ]
  %62 = phi i8* [ %58, %57 ], [ %899, %897 ]
  call void @llvm.lifetime.start.p0i8(i64 240, i8* nonnull %28) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %28, i8 -86, i64 240, i1 false) #5
  %63 = load i32, i32* %29, align 4
  %64 = mul nsw i32 %63, %61
  %65 = load i32, i32* %30, align 4
  %66 = mul nsw i32 %65, %59
  %67 = add nsw i32 %66, %64
  %68 = load i32, i32* %4, align 4
  %69 = add nsw i32 %67, %68
  %70 = load i32, i32* %31, align 4
  %71 = mul nsw i32 %70, %61
  %72 = load i32, i32* %32, align 4
  %73 = mul nsw i32 %72, %59
  %74 = add nsw i32 %73, %71
  %75 = load i32, i32* %33, align 4
  %76 = add nsw i32 %74, %75
  %77 = ashr i32 %69, %5
  %78 = ashr i32 %76, %6
  %79 = ashr i32 %77, 16
  %80 = ashr i32 %78, 16
  %81 = add nsw i32 %79, -6
  %82 = icmp sge i32 %81, %2
  %83 = icmp slt i32 %77, -393216
  %84 = or i1 %83, %82
  %85 = add nsw i32 %80, -6
  %86 = icmp sge i32 %85, %3
  %87 = icmp slt i32 %78, -393216
  %88 = or i1 %87, %86
  br i1 %84, label %89, label %404

89:                                               ; preds = %60
  %90 = select i1 %83, i8* %0, i8* %46
  br i1 %88, label %91, label %125

91:                                               ; preds = %89
  %92 = select i1 %87, i32 0, i32 %39
  %93 = sext i32 %92 to i64
  %94 = mul nsw i64 %93, %1
  %95 = getelementptr inbounds i8, i8* %90, i64 %94
  %96 = load i8, i8* %95, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %62, i8 %96, i64 8, i1 false) #5
  %97 = bitcast i8* %62 to i64*
  %98 = getelementptr inbounds i8, i8* %62, i64 %16
  %99 = bitcast i8* %98 to i64*
  %100 = zext i8 %96 to i64
  %101 = shl nuw nsw i64 %100, 8
  %102 = or i64 %101, %100
  %103 = shl nuw nsw i64 %102, 16
  %104 = or i64 %103, %102
  %105 = shl nuw i64 %104, 32
  %106 = or i64 %105, %104
  store i64 %106, i64* %99, align 1
  %107 = getelementptr inbounds i8, i8* %98, i64 %16
  %108 = bitcast i8* %107 to i64*
  %109 = load i64, i64* %97, align 1
  store i64 %109, i64* %108, align 1
  %110 = getelementptr inbounds i8, i8* %107, i64 %16
  %111 = bitcast i8* %110 to i64*
  %112 = load i64, i64* %97, align 1
  store i64 %112, i64* %111, align 1
  %113 = getelementptr inbounds i8, i8* %110, i64 %16
  %114 = bitcast i8* %113 to i64*
  %115 = load i64, i64* %97, align 1
  store i64 %115, i64* %114, align 1
  %116 = getelementptr inbounds i8, i8* %113, i64 %16
  %117 = bitcast i8* %116 to i64*
  %118 = load i64, i64* %97, align 1
  store i64 %118, i64* %117, align 1
  %119 = getelementptr inbounds i8, i8* %116, i64 %16
  %120 = bitcast i8* %119 to i64*
  %121 = load i64, i64* %97, align 1
  store i64 %121, i64* %120, align 1
  %122 = getelementptr inbounds i8, i8* %119, i64 %16
  %123 = bitcast i8* %122 to i64*
  %124 = load i64, i64* %97, align 1
  store i64 %124, i64* %123, align 1
  br label %897

125:                                              ; preds = %89
  %126 = sext i32 %80 to i64
  %127 = add nsw i64 %126, -7
  %128 = mul nsw i64 %127, %1
  %129 = getelementptr inbounds i8, i8* %90, i64 %128
  %130 = load i8, i8* %129, align 1
  %131 = add nsw i64 %126, -6
  %132 = mul nsw i64 %131, %1
  %133 = getelementptr inbounds i8, i8* %90, i64 %132
  %134 = load i8, i8* %133, align 1
  %135 = add nsw i64 %126, -5
  %136 = mul nsw i64 %135, %1
  %137 = getelementptr inbounds i8, i8* %90, i64 %136
  %138 = load i8, i8* %137, align 1
  %139 = add nsw i64 %126, -4
  %140 = mul nsw i64 %139, %1
  %141 = getelementptr inbounds i8, i8* %90, i64 %140
  %142 = load i8, i8* %141, align 1
  %143 = add nsw i64 %126, -3
  %144 = mul nsw i64 %143, %1
  %145 = getelementptr inbounds i8, i8* %90, i64 %144
  %146 = load i8, i8* %145, align 1
  %147 = add nsw i64 %126, -2
  %148 = mul nsw i64 %147, %1
  %149 = getelementptr inbounds i8, i8* %90, i64 %148
  %150 = load i8, i8* %149, align 1
  %151 = add nsw i64 %126, -1
  %152 = mul nsw i64 %151, %1
  %153 = getelementptr inbounds i8, i8* %90, i64 %152
  %154 = load i8, i8* %153, align 1
  %155 = mul nsw i64 %126, %1
  %156 = getelementptr inbounds i8, i8* %90, i64 %155
  %157 = load i8, i8* %156, align 1
  %158 = insertelement <8 x i8> undef, i8 %130, i32 0
  %159 = insertelement <8 x i8> %158, i8 %134, i32 1
  %160 = insertelement <8 x i8> %159, i8 %138, i32 2
  %161 = insertelement <8 x i8> %160, i8 %142, i32 3
  %162 = insertelement <8 x i8> %161, i8 %146, i32 4
  %163 = insertelement <8 x i8> %162, i8 %150, i32 5
  %164 = insertelement <8 x i8> %163, i8 %154, i32 6
  %165 = insertelement <8 x i8> %164, i8 %157, i32 7
  %166 = zext <8 x i8> %165 to <8 x i16>
  %167 = shl nuw nsw <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  store <8 x i16> %167, <8 x i16>* %56, align 16
  %168 = add nsw i64 %126, 1
  %169 = mul nsw i64 %168, %1
  %170 = getelementptr inbounds i8, i8* %90, i64 %169
  %171 = load i8, i8* %170, align 1
  %172 = zext i8 %171 to i16
  %173 = shl nuw nsw i16 %172, 4
  store i16 %173, i16* %47, align 16
  %174 = add nsw i64 %126, 2
  %175 = mul nsw i64 %174, %1
  %176 = getelementptr inbounds i8, i8* %90, i64 %175
  %177 = load i8, i8* %176, align 1
  %178 = zext i8 %177 to i16
  %179 = shl nuw nsw i16 %178, 4
  store i16 %179, i16* %48, align 2
  %180 = add nsw i64 %126, 3
  %181 = mul nsw i64 %180, %1
  %182 = getelementptr inbounds i8, i8* %90, i64 %181
  %183 = load i8, i8* %182, align 1
  %184 = zext i8 %183 to i16
  %185 = shl nuw nsw i16 %184, 4
  store i16 %185, i16* %49, align 4
  %186 = add nsw i64 %126, 4
  %187 = mul nsw i64 %186, %1
  %188 = getelementptr inbounds i8, i8* %90, i64 %187
  %189 = load i8, i8* %188, align 1
  %190 = zext i8 %189 to i16
  %191 = shl nuw nsw i16 %190, 4
  store i16 %191, i16* %50, align 2
  %192 = add nsw i64 %126, 5
  %193 = mul nsw i64 %192, %1
  %194 = getelementptr inbounds i8, i8* %90, i64 %193
  %195 = load i8, i8* %194, align 1
  %196 = zext i8 %195 to i16
  %197 = shl nuw nsw i16 %196, 4
  store i16 %197, i16* %51, align 8
  %198 = add nsw i64 %126, 6
  %199 = mul nsw i64 %198, %1
  %200 = getelementptr inbounds i8, i8* %90, i64 %199
  %201 = load i8, i8* %200, align 1
  %202 = zext i8 %201 to i16
  %203 = shl nuw nsw i16 %202, 4
  store i16 %203, i16* %52, align 2
  %204 = add nsw i64 %126, 7
  %205 = mul nsw i64 %204, %1
  %206 = getelementptr inbounds i8, i8* %90, i64 %205
  %207 = load i8, i8* %206, align 1
  %208 = zext i8 %207 to i16
  %209 = shl nuw nsw i16 %208, 4
  store i16 %209, i16* %53, align 4
  %210 = and i32 %78, 65535
  %211 = sub nsw i32 %210, %42
  br label %212

212:                                              ; preds = %212, %125
  %213 = phi i64 [ 0, %125 ], [ %402, %212 ]
  %214 = phi i8* [ %62, %125 ], [ %400, %212 ]
  %215 = phi i32 [ %211, %125 ], [ %401, %212 ]
  %216 = sub nsw i32 %215, %43
  %217 = add nsw i32 %216, 512
  %218 = ashr i32 %217, 10
  %219 = add nsw i32 %218, 64
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %220, i64 0
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = add nsw i32 %216, %40
  %225 = add nsw i32 %224, 512
  %226 = ashr i32 %225, 10
  %227 = add nsw i32 %226, 64
  %228 = sext i32 %227 to i64
  %229 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %228, i64 0
  %230 = bitcast i16* %229 to <8 x i16>*
  %231 = load <8 x i16>, <8 x i16>* %230, align 16
  %232 = add nsw i32 %224, %40
  %233 = add nsw i32 %232, 512
  %234 = ashr i32 %233, 10
  %235 = add nsw i32 %234, 64
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %236, i64 0
  %238 = bitcast i16* %237 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = add nsw i32 %232, %40
  %241 = add nsw i32 %240, 512
  %242 = ashr i32 %241, 10
  %243 = add nsw i32 %242, 64
  %244 = sext i32 %243 to i64
  %245 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %244, i64 0
  %246 = bitcast i16* %245 to <8 x i16>*
  %247 = load <8 x i16>, <8 x i16>* %246, align 16
  %248 = add nsw i32 %240, %40
  %249 = add i32 %248, 512
  %250 = ashr i32 %249, 10
  %251 = add nsw i32 %250, 64
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %252, i64 0
  %254 = bitcast i16* %253 to <8 x i16>*
  %255 = load <8 x i16>, <8 x i16>* %254, align 16
  %256 = add i32 %249, %40
  %257 = ashr i32 %256, 10
  %258 = add nsw i32 %257, 64
  %259 = sext i32 %258 to i64
  %260 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %259, i64 0
  %261 = bitcast i16* %260 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = add i32 %256, %40
  %264 = ashr i32 %263, 10
  %265 = add nsw i32 %264, 64
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %266, i64 0
  %268 = bitcast i16* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = add i32 %263, %40
  %271 = ashr i32 %270, 10
  %272 = add nsw i32 %271, 64
  %273 = sext i32 %272 to i64
  %274 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %273, i64 0
  %275 = bitcast i16* %274 to <8 x i16>*
  %276 = load <8 x i16>, <8 x i16>* %275, align 16
  %277 = shufflevector <8 x i16> %223, <8 x i16> %231, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %278 = shufflevector <8 x i16> %239, <8 x i16> %247, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %279 = shufflevector <8 x i16> %255, <8 x i16> %262, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %280 = shufflevector <8 x i16> %269, <8 x i16> %276, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %281 = shufflevector <8 x i16> %223, <8 x i16> %231, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %282 = shufflevector <8 x i16> %239, <8 x i16> %247, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %283 = shufflevector <8 x i16> %255, <8 x i16> %262, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %284 = shufflevector <8 x i16> %269, <8 x i16> %276, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %285 = bitcast <8 x i16> %277 to <4 x i32>
  %286 = bitcast <8 x i16> %278 to <4 x i32>
  %287 = shufflevector <4 x i32> %285, <4 x i32> %286, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %288 = bitcast <4 x i32> %287 to <2 x i64>
  %289 = bitcast <8 x i16> %279 to <4 x i32>
  %290 = bitcast <8 x i16> %280 to <4 x i32>
  %291 = shufflevector <4 x i32> %289, <4 x i32> %290, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %292 = bitcast <4 x i32> %291 to <2 x i64>
  %293 = bitcast <8 x i16> %281 to <4 x i32>
  %294 = bitcast <8 x i16> %282 to <4 x i32>
  %295 = shufflevector <4 x i32> %293, <4 x i32> %294, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %296 = bitcast <4 x i32> %295 to <2 x i64>
  %297 = bitcast <8 x i16> %283 to <4 x i32>
  %298 = bitcast <8 x i16> %284 to <4 x i32>
  %299 = shufflevector <4 x i32> %297, <4 x i32> %298, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %300 = bitcast <4 x i32> %299 to <2 x i64>
  %301 = shufflevector <4 x i32> %285, <4 x i32> %286, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %302 = bitcast <4 x i32> %301 to <2 x i64>
  %303 = shufflevector <4 x i32> %289, <4 x i32> %290, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %304 = bitcast <4 x i32> %303 to <2 x i64>
  %305 = shufflevector <4 x i32> %293, <4 x i32> %294, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %306 = bitcast <4 x i32> %305 to <2 x i64>
  %307 = shufflevector <4 x i32> %297, <4 x i32> %298, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %308 = bitcast <4 x i32> %307 to <2 x i64>
  %309 = shufflevector <2 x i64> %288, <2 x i64> %292, <2 x i32> <i32 0, i32 2>
  %310 = shufflevector <2 x i64> %288, <2 x i64> %292, <2 x i32> <i32 1, i32 3>
  %311 = shufflevector <2 x i64> %302, <2 x i64> %304, <2 x i32> <i32 0, i32 2>
  %312 = shufflevector <2 x i64> %302, <2 x i64> %304, <2 x i32> <i32 1, i32 3>
  %313 = shufflevector <2 x i64> %296, <2 x i64> %300, <2 x i32> <i32 0, i32 2>
  %314 = shufflevector <2 x i64> %296, <2 x i64> %300, <2 x i32> <i32 1, i32 3>
  %315 = shufflevector <2 x i64> %306, <2 x i64> %308, <2 x i32> <i32 0, i32 2>
  %316 = shufflevector <2 x i64> %306, <2 x i64> %308, <2 x i32> <i32 1, i32 3>
  %317 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 0, i64 %213
  %318 = bitcast <2 x i64> %309 to <8 x i16>
  %319 = bitcast <2 x i64> %310 to <8 x i16>
  %320 = shufflevector <8 x i16> %318, <8 x i16> %319, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %321 = shufflevector <8 x i16> %318, <8 x i16> %319, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %322 = getelementptr inbounds i16, i16* %317, i64 1
  %323 = load i16, i16* %322, align 2
  %324 = zext i16 %323 to i32
  %325 = shl nuw i32 %324, 16
  %326 = load i16, i16* %317, align 2
  %327 = sext i16 %326 to i32
  %328 = or i32 %325, %327
  %329 = insertelement <4 x i32> undef, i32 %328, i32 0
  %330 = shufflevector <4 x i32> %329, <4 x i32> undef, <4 x i32> zeroinitializer
  %331 = bitcast <4 x i32> %330 to <8 x i16>
  %332 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %320, <8 x i16> %331) #5
  %333 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %321, <8 x i16> %331) #5
  %334 = bitcast <2 x i64> %311 to <8 x i16>
  %335 = bitcast <2 x i64> %312 to <8 x i16>
  %336 = shufflevector <8 x i16> %334, <8 x i16> %335, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %337 = shufflevector <8 x i16> %334, <8 x i16> %335, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = getelementptr inbounds i16, i16* %317, i64 3
  %339 = load i16, i16* %338, align 2
  %340 = zext i16 %339 to i32
  %341 = shl nuw i32 %340, 16
  %342 = getelementptr inbounds i16, i16* %317, i64 2
  %343 = load i16, i16* %342, align 2
  %344 = sext i16 %343 to i32
  %345 = or i32 %341, %344
  %346 = insertelement <4 x i32> undef, i32 %345, i32 0
  %347 = shufflevector <4 x i32> %346, <4 x i32> undef, <4 x i32> zeroinitializer
  %348 = bitcast <4 x i32> %347 to <8 x i16>
  %349 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %336, <8 x i16> %348) #5
  %350 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %337, <8 x i16> %348) #5
  %351 = bitcast <2 x i64> %313 to <8 x i16>
  %352 = bitcast <2 x i64> %314 to <8 x i16>
  %353 = shufflevector <8 x i16> %351, <8 x i16> %352, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %354 = shufflevector <8 x i16> %351, <8 x i16> %352, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %355 = getelementptr inbounds i16, i16* %317, i64 5
  %356 = load i16, i16* %355, align 2
  %357 = zext i16 %356 to i32
  %358 = shl nuw i32 %357, 16
  %359 = getelementptr inbounds i16, i16* %317, i64 4
  %360 = load i16, i16* %359, align 2
  %361 = sext i16 %360 to i32
  %362 = or i32 %358, %361
  %363 = insertelement <4 x i32> undef, i32 %362, i32 0
  %364 = shufflevector <4 x i32> %363, <4 x i32> undef, <4 x i32> zeroinitializer
  %365 = bitcast <4 x i32> %364 to <8 x i16>
  %366 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %353, <8 x i16> %365) #5
  %367 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %354, <8 x i16> %365) #5
  %368 = bitcast <2 x i64> %315 to <8 x i16>
  %369 = bitcast <2 x i64> %316 to <8 x i16>
  %370 = shufflevector <8 x i16> %368, <8 x i16> %369, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %371 = shufflevector <8 x i16> %368, <8 x i16> %369, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %372 = getelementptr inbounds i16, i16* %317, i64 7
  %373 = load i16, i16* %372, align 2
  %374 = zext i16 %373 to i32
  %375 = shl nuw i32 %374, 16
  %376 = getelementptr inbounds i16, i16* %317, i64 6
  %377 = load i16, i16* %376, align 2
  %378 = sext i16 %377 to i32
  %379 = or i32 %375, %378
  %380 = insertelement <4 x i32> undef, i32 %379, i32 0
  %381 = shufflevector <4 x i32> %380, <4 x i32> undef, <4 x i32> zeroinitializer
  %382 = bitcast <4 x i32> %381 to <8 x i16>
  %383 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %370, <8 x i16> %382) #5
  %384 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %371, <8 x i16> %382) #5
  %385 = add <4 x i32> %332, <i32 1024, i32 1024, i32 1024, i32 1024>
  %386 = add <4 x i32> %385, %349
  %387 = add <4 x i32> %386, %366
  %388 = add <4 x i32> %387, %383
  %389 = ashr <4 x i32> %388, <i32 11, i32 11, i32 11, i32 11>
  %390 = add <4 x i32> %333, <i32 1024, i32 1024, i32 1024, i32 1024>
  %391 = add <4 x i32> %390, %350
  %392 = add <4 x i32> %391, %367
  %393 = add <4 x i32> %392, %384
  %394 = ashr <4 x i32> %393, <i32 11, i32 11, i32 11, i32 11>
  %395 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %389, <4 x i32> %394) #5
  %396 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %395, <8 x i16> undef) #5
  %397 = bitcast <16 x i8> %396 to <2 x i64>
  %398 = extractelement <2 x i64> %397, i32 0
  %399 = bitcast i8* %214 to i64*
  store i64 %398, i64* %399, align 1
  %400 = getelementptr inbounds i8, i8* %214, i64 %16
  %401 = add nsw i32 %215, %41
  %402 = add nuw nsw i64 %213, 1
  %403 = icmp eq i64 %402, 8
  br i1 %403, label %897, label %212

404:                                              ; preds = %60
  br i1 %88, label %405, label %556

405:                                              ; preds = %404
  %406 = select i1 %87, i32 0, i32 %39
  %407 = sext i32 %406 to i64
  %408 = mul nsw i64 %407, %1
  %409 = getelementptr inbounds i8, i8* %0, i64 %408
  %410 = add nsw i32 %79, -7
  %411 = sext i32 %410 to i64
  %412 = getelementptr inbounds i8, i8* %409, i64 %411
  %413 = bitcast i8* %412 to <16 x i8>*
  %414 = load <16 x i8>, <16 x i8>* %413, align 1
  %415 = and i32 %77, 65535
  %416 = add nsw i32 %415, %36
  %417 = shufflevector <16 x i8> %414, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %418 = shufflevector <16 x i8> %414, <16 x i8> %417, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %419 = shufflevector <16 x i8> %414, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %420 = shufflevector <16 x i8> %419, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %421 = shufflevector <16 x i8> %419, <16 x i8> %420, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %422 = shufflevector <16 x i8> %419, <16 x i8> <i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18>
  %423 = shufflevector <16 x i8> %422, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %424 = shufflevector <16 x i8> %422, <16 x i8> %423, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %425 = shufflevector <16 x i8> %422, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %426 = shufflevector <16 x i8> %425, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %427 = shufflevector <16 x i8> %425, <16 x i8> %426, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  br label %428

428:                                              ; preds = %428, %405
  %429 = phi i64 [ -7, %405 ], [ %554, %428 ]
  %430 = phi i32 [ %416, %405 ], [ %553, %428 ]
  %431 = add nsw i64 %429, 7
  %432 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %431, i64 0
  %433 = sub nsw i32 %430, %37
  %434 = add nsw i32 %433, 512
  %435 = ashr i32 %434, 10
  %436 = add nsw i32 %435, 64
  %437 = sext i32 %436 to i64
  %438 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %437, i64 0
  %439 = bitcast i8* %438 to i64*
  %440 = load i64, i64* %439, align 8
  %441 = insertelement <2 x i64> undef, i64 %440, i32 0
  %442 = add nsw i32 %433, %34
  %443 = add nsw i32 %442, 512
  %444 = ashr i32 %443, 10
  %445 = add nsw i32 %444, 64
  %446 = sext i32 %445 to i64
  %447 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %446, i64 0
  %448 = bitcast i8* %447 to i64*
  %449 = load i64, i64* %448, align 8
  %450 = insertelement <2 x i64> undef, i64 %449, i32 0
  %451 = add nsw i32 %442, %34
  %452 = add nsw i32 %451, 512
  %453 = ashr i32 %452, 10
  %454 = add nsw i32 %453, 64
  %455 = sext i32 %454 to i64
  %456 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %455, i64 0
  %457 = bitcast i8* %456 to i64*
  %458 = load i64, i64* %457, align 8
  %459 = insertelement <2 x i64> undef, i64 %458, i32 0
  %460 = add nsw i32 %451, %34
  %461 = add nsw i32 %460, 512
  %462 = ashr i32 %461, 10
  %463 = add nsw i32 %462, 64
  %464 = sext i32 %463 to i64
  %465 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %464, i64 0
  %466 = bitcast i8* %465 to i64*
  %467 = load i64, i64* %466, align 8
  %468 = insertelement <2 x i64> undef, i64 %467, i32 0
  %469 = add nsw i32 %460, %34
  %470 = add nsw i32 %469, 512
  %471 = ashr i32 %470, 10
  %472 = add nsw i32 %471, 64
  %473 = sext i32 %472 to i64
  %474 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %473, i64 0
  %475 = bitcast i8* %474 to i64*
  %476 = load i64, i64* %475, align 8
  %477 = insertelement <2 x i64> undef, i64 %476, i32 0
  %478 = add nsw i32 %469, %34
  %479 = add nsw i32 %478, 512
  %480 = ashr i32 %479, 10
  %481 = add nsw i32 %480, 64
  %482 = sext i32 %481 to i64
  %483 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %482, i64 0
  %484 = bitcast i8* %483 to i64*
  %485 = load i64, i64* %484, align 8
  %486 = insertelement <2 x i64> undef, i64 %485, i32 0
  %487 = add i32 %38, %478
  %488 = ashr i32 %487, 10
  %489 = add nsw i32 %488, 64
  %490 = sext i32 %489 to i64
  %491 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %490, i64 0
  %492 = bitcast i8* %491 to i64*
  %493 = load i64, i64* %492, align 8
  %494 = insertelement <2 x i64> undef, i64 %493, i32 0
  %495 = add i32 %487, %34
  %496 = ashr i32 %495, 10
  %497 = add nsw i32 %496, 64
  %498 = sext i32 %497 to i64
  %499 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %498, i64 0
  %500 = bitcast i8* %499 to i64*
  %501 = load i64, i64* %500, align 8
  %502 = insertelement <2 x i64> undef, i64 %501, i32 0
  %503 = bitcast <2 x i64> %441 to <16 x i8>
  %504 = bitcast <2 x i64> %450 to <16 x i8>
  %505 = shufflevector <16 x i8> %503, <16 x i8> %504, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %506 = bitcast <2 x i64> %459 to <16 x i8>
  %507 = bitcast <2 x i64> %468 to <16 x i8>
  %508 = shufflevector <16 x i8> %506, <16 x i8> %507, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %509 = bitcast <2 x i64> %477 to <16 x i8>
  %510 = bitcast <2 x i64> %486 to <16 x i8>
  %511 = shufflevector <16 x i8> %509, <16 x i8> %510, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %512 = bitcast <2 x i64> %494 to <16 x i8>
  %513 = bitcast <2 x i64> %502 to <16 x i8>
  %514 = shufflevector <16 x i8> %512, <16 x i8> %513, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %515 = bitcast <16 x i8> %505 to <8 x i16>
  %516 = bitcast <16 x i8> %508 to <8 x i16>
  %517 = shufflevector <8 x i16> %515, <8 x i16> %516, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %518 = bitcast <16 x i8> %511 to <8 x i16>
  %519 = bitcast <16 x i8> %514 to <8 x i16>
  %520 = shufflevector <8 x i16> %518, <8 x i16> %519, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %521 = shufflevector <8 x i16> %515, <8 x i16> %516, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %522 = shufflevector <8 x i16> %518, <8 x i16> %519, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %523 = bitcast <8 x i16> %517 to <4 x i32>
  %524 = bitcast <8 x i16> %520 to <4 x i32>
  %525 = shufflevector <4 x i32> %523, <4 x i32> %524, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %526 = shufflevector <4 x i32> %523, <4 x i32> %524, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %527 = bitcast <8 x i16> %521 to <4 x i32>
  %528 = bitcast <8 x i16> %522 to <4 x i32>
  %529 = shufflevector <4 x i32> %527, <4 x i32> %528, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %530 = shufflevector <4 x i32> %527, <4 x i32> %528, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %531 = bitcast <4 x i32> %525 to <16 x i8>
  %532 = bitcast <4 x i32> %526 to <16 x i8>
  %533 = shufflevector <16 x i8> %531, <16 x i8> %532, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %534 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %418, <16 x i8> %533) #5
  %535 = shufflevector <16 x i8> %531, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %536 = shufflevector <16 x i8> %532, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %537 = shufflevector <16 x i8> %535, <16 x i8> %536, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %538 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %421, <16 x i8> %537) #5
  %539 = bitcast <4 x i32> %529 to <16 x i8>
  %540 = bitcast <4 x i32> %530 to <16 x i8>
  %541 = shufflevector <16 x i8> %539, <16 x i8> %540, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %542 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %424, <16 x i8> %541) #5
  %543 = shufflevector <16 x i8> %539, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %544 = shufflevector <16 x i8> %540, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %545 = shufflevector <16 x i8> %543, <16 x i8> %544, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %546 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %427, <16 x i8> %545) #5
  %547 = add <8 x i16> %534, <i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380>
  %548 = add <8 x i16> %547, %538
  %549 = add <8 x i16> %548, %542
  %550 = add <8 x i16> %549, %546
  %551 = ashr <8 x i16> %550, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %552 = bitcast i16* %432 to <8 x i16>*
  store <8 x i16> %551, <8 x i16>* %552, align 16
  %553 = add nsw i32 %430, %35
  %554 = add nsw i64 %429, 1
  %555 = icmp eq i64 %554, 8
  br i1 %555, label %707, label %428

556:                                              ; preds = %404
  %557 = and i32 %77, 65535
  %558 = add nsw i32 %557, %36
  %559 = add nsw i32 %79, -7
  %560 = sext i32 %559 to i64
  %561 = sext i32 %80 to i64
  %562 = getelementptr inbounds i8, i8* %0, i64 %560
  br label %563

563:                                              ; preds = %563, %556
  %564 = phi i64 [ -7, %556 ], [ %705, %563 ]
  %565 = phi i32 [ %558, %556 ], [ %704, %563 ]
  %566 = add nsw i64 %564, %561
  %567 = mul nsw i64 %566, %1
  %568 = getelementptr inbounds i8, i8* %562, i64 %567
  %569 = bitcast i8* %568 to <16 x i8>*
  %570 = load <16 x i8>, <16 x i8>* %569, align 1
  %571 = add nsw i64 %564, 7
  %572 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %571, i64 0
  %573 = sub nsw i32 %565, %37
  %574 = add nsw i32 %573, 512
  %575 = ashr i32 %574, 10
  %576 = add nsw i32 %575, 64
  %577 = sext i32 %576 to i64
  %578 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %577, i64 0
  %579 = bitcast i8* %578 to i64*
  %580 = load i64, i64* %579, align 8
  %581 = insertelement <2 x i64> undef, i64 %580, i32 0
  %582 = add nsw i32 %573, %34
  %583 = add nsw i32 %582, 512
  %584 = ashr i32 %583, 10
  %585 = add nsw i32 %584, 64
  %586 = sext i32 %585 to i64
  %587 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %586, i64 0
  %588 = bitcast i8* %587 to i64*
  %589 = load i64, i64* %588, align 8
  %590 = insertelement <2 x i64> undef, i64 %589, i32 0
  %591 = add nsw i32 %582, %34
  %592 = add nsw i32 %591, 512
  %593 = ashr i32 %592, 10
  %594 = add nsw i32 %593, 64
  %595 = sext i32 %594 to i64
  %596 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %595, i64 0
  %597 = bitcast i8* %596 to i64*
  %598 = load i64, i64* %597, align 8
  %599 = insertelement <2 x i64> undef, i64 %598, i32 0
  %600 = add nsw i32 %591, %34
  %601 = add nsw i32 %600, 512
  %602 = ashr i32 %601, 10
  %603 = add nsw i32 %602, 64
  %604 = sext i32 %603 to i64
  %605 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %604, i64 0
  %606 = bitcast i8* %605 to i64*
  %607 = load i64, i64* %606, align 8
  %608 = insertelement <2 x i64> undef, i64 %607, i32 0
  %609 = add nsw i32 %600, %34
  %610 = add nsw i32 %609, 512
  %611 = ashr i32 %610, 10
  %612 = add nsw i32 %611, 64
  %613 = sext i32 %612 to i64
  %614 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %613, i64 0
  %615 = bitcast i8* %614 to i64*
  %616 = load i64, i64* %615, align 8
  %617 = insertelement <2 x i64> undef, i64 %616, i32 0
  %618 = add nsw i32 %609, %34
  %619 = add nsw i32 %618, 512
  %620 = ashr i32 %619, 10
  %621 = add nsw i32 %620, 64
  %622 = sext i32 %621 to i64
  %623 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %622, i64 0
  %624 = bitcast i8* %623 to i64*
  %625 = load i64, i64* %624, align 8
  %626 = insertelement <2 x i64> undef, i64 %625, i32 0
  %627 = add i32 %38, %618
  %628 = ashr i32 %627, 10
  %629 = add nsw i32 %628, 64
  %630 = sext i32 %629 to i64
  %631 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %630, i64 0
  %632 = bitcast i8* %631 to i64*
  %633 = load i64, i64* %632, align 8
  %634 = insertelement <2 x i64> undef, i64 %633, i32 0
  %635 = add i32 %627, %34
  %636 = ashr i32 %635, 10
  %637 = add nsw i32 %636, 64
  %638 = sext i32 %637 to i64
  %639 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %638, i64 0
  %640 = bitcast i8* %639 to i64*
  %641 = load i64, i64* %640, align 8
  %642 = insertelement <2 x i64> undef, i64 %641, i32 0
  %643 = bitcast <2 x i64> %581 to <16 x i8>
  %644 = bitcast <2 x i64> %590 to <16 x i8>
  %645 = shufflevector <16 x i8> %643, <16 x i8> %644, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %646 = bitcast <2 x i64> %599 to <16 x i8>
  %647 = bitcast <2 x i64> %608 to <16 x i8>
  %648 = shufflevector <16 x i8> %646, <16 x i8> %647, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %649 = bitcast <2 x i64> %617 to <16 x i8>
  %650 = bitcast <2 x i64> %626 to <16 x i8>
  %651 = shufflevector <16 x i8> %649, <16 x i8> %650, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %652 = bitcast <2 x i64> %634 to <16 x i8>
  %653 = bitcast <2 x i64> %642 to <16 x i8>
  %654 = shufflevector <16 x i8> %652, <16 x i8> %653, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %655 = bitcast <16 x i8> %645 to <8 x i16>
  %656 = bitcast <16 x i8> %648 to <8 x i16>
  %657 = shufflevector <8 x i16> %655, <8 x i16> %656, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %658 = bitcast <16 x i8> %651 to <8 x i16>
  %659 = bitcast <16 x i8> %654 to <8 x i16>
  %660 = shufflevector <8 x i16> %658, <8 x i16> %659, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %661 = shufflevector <8 x i16> %655, <8 x i16> %656, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %662 = shufflevector <8 x i16> %658, <8 x i16> %659, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %663 = bitcast <8 x i16> %657 to <4 x i32>
  %664 = bitcast <8 x i16> %660 to <4 x i32>
  %665 = shufflevector <4 x i32> %663, <4 x i32> %664, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %666 = shufflevector <4 x i32> %663, <4 x i32> %664, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %667 = bitcast <8 x i16> %661 to <4 x i32>
  %668 = bitcast <8 x i16> %662 to <4 x i32>
  %669 = shufflevector <4 x i32> %667, <4 x i32> %668, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %670 = shufflevector <4 x i32> %667, <4 x i32> %668, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %671 = bitcast <4 x i32> %665 to <16 x i8>
  %672 = bitcast <4 x i32> %666 to <16 x i8>
  %673 = shufflevector <16 x i8> %671, <16 x i8> %672, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %674 = shufflevector <16 x i8> %570, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %675 = shufflevector <16 x i8> %570, <16 x i8> %674, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %676 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %675, <16 x i8> %673) #5
  %677 = shufflevector <16 x i8> %570, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %678 = shufflevector <16 x i8> %671, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %679 = shufflevector <16 x i8> %672, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %680 = shufflevector <16 x i8> %678, <16 x i8> %679, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %681 = shufflevector <16 x i8> %677, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %682 = shufflevector <16 x i8> %677, <16 x i8> %681, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %683 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %682, <16 x i8> %680) #5
  %684 = shufflevector <16 x i8> %677, <16 x i8> <i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18>
  %685 = bitcast <4 x i32> %669 to <16 x i8>
  %686 = bitcast <4 x i32> %670 to <16 x i8>
  %687 = shufflevector <16 x i8> %685, <16 x i8> %686, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %688 = shufflevector <16 x i8> %684, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %689 = shufflevector <16 x i8> %684, <16 x i8> %688, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %690 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %689, <16 x i8> %687) #5
  %691 = shufflevector <16 x i8> %684, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %692 = shufflevector <16 x i8> %685, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %693 = shufflevector <16 x i8> %686, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %694 = shufflevector <16 x i8> %692, <16 x i8> %693, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %695 = shufflevector <16 x i8> %691, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %696 = shufflevector <16 x i8> %691, <16 x i8> %695, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %697 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %696, <16 x i8> %694) #5
  %698 = add <8 x i16> %676, <i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380>
  %699 = add <8 x i16> %698, %683
  %700 = add <8 x i16> %699, %690
  %701 = add <8 x i16> %700, %697
  %702 = ashr <8 x i16> %701, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %703 = bitcast i16* %572 to <8 x i16>*
  store <8 x i16> %702, <8 x i16>* %703, align 16
  %704 = add nsw i32 %565, %35
  %705 = add nsw i64 %564, 1
  %706 = icmp eq i64 %705, 8
  br i1 %706, label %707, label %563

707:                                              ; preds = %563, %428
  %708 = and i32 %78, 65535
  %709 = sub nsw i32 %708, %42
  br label %710

710:                                              ; preds = %710, %707
  %711 = phi i64 [ 0, %707 ], [ %823, %710 ]
  %712 = phi i8* [ %62, %707 ], [ %894, %710 ]
  %713 = phi i32 [ %709, %707 ], [ %895, %710 ]
  %714 = sub nsw i32 %713, %43
  %715 = add nsw i32 %714, 512
  %716 = ashr i32 %715, 10
  %717 = add nsw i32 %716, 64
  %718 = sext i32 %717 to i64
  %719 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %718, i64 0
  %720 = bitcast i16* %719 to <8 x i16>*
  %721 = load <8 x i16>, <8 x i16>* %720, align 16
  %722 = add nsw i32 %714, %40
  %723 = add nsw i32 %722, 512
  %724 = ashr i32 %723, 10
  %725 = add nsw i32 %724, 64
  %726 = sext i32 %725 to i64
  %727 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %726, i64 0
  %728 = bitcast i16* %727 to <8 x i16>*
  %729 = load <8 x i16>, <8 x i16>* %728, align 16
  %730 = add nsw i32 %722, %40
  %731 = add nsw i32 %730, 512
  %732 = ashr i32 %731, 10
  %733 = add nsw i32 %732, 64
  %734 = sext i32 %733 to i64
  %735 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %734, i64 0
  %736 = bitcast i16* %735 to <8 x i16>*
  %737 = load <8 x i16>, <8 x i16>* %736, align 16
  %738 = add nsw i32 %730, %40
  %739 = add nsw i32 %738, 512
  %740 = ashr i32 %739, 10
  %741 = add nsw i32 %740, 64
  %742 = sext i32 %741 to i64
  %743 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %742, i64 0
  %744 = bitcast i16* %743 to <8 x i16>*
  %745 = load <8 x i16>, <8 x i16>* %744, align 16
  %746 = add nsw i32 %738, %40
  %747 = add nsw i32 %746, 512
  %748 = ashr i32 %747, 10
  %749 = add nsw i32 %748, 64
  %750 = sext i32 %749 to i64
  %751 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %750, i64 0
  %752 = bitcast i16* %751 to <8 x i16>*
  %753 = load <8 x i16>, <8 x i16>* %752, align 16
  %754 = add nsw i32 %746, %40
  %755 = add i32 %754, 512
  %756 = ashr i32 %755, 10
  %757 = add nsw i32 %756, 64
  %758 = sext i32 %757 to i64
  %759 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %758, i64 0
  %760 = bitcast i16* %759 to <8 x i16>*
  %761 = load <8 x i16>, <8 x i16>* %760, align 16
  %762 = add i32 %755, %40
  %763 = ashr i32 %762, 10
  %764 = add nsw i32 %763, 64
  %765 = sext i32 %764 to i64
  %766 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %765, i64 0
  %767 = bitcast i16* %766 to <8 x i16>*
  %768 = load <8 x i16>, <8 x i16>* %767, align 16
  %769 = add i32 %762, %40
  %770 = ashr i32 %769, 10
  %771 = add nsw i32 %770, 64
  %772 = sext i32 %771 to i64
  %773 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %772, i64 0
  %774 = bitcast i16* %773 to <8 x i16>*
  %775 = load <8 x i16>, <8 x i16>* %774, align 16
  %776 = shufflevector <8 x i16> %721, <8 x i16> %729, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %777 = shufflevector <8 x i16> %737, <8 x i16> %745, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %778 = shufflevector <8 x i16> %753, <8 x i16> %761, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %779 = shufflevector <8 x i16> %768, <8 x i16> %775, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %780 = shufflevector <8 x i16> %721, <8 x i16> %729, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %781 = shufflevector <8 x i16> %737, <8 x i16> %745, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %782 = shufflevector <8 x i16> %753, <8 x i16> %761, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %783 = shufflevector <8 x i16> %768, <8 x i16> %775, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %784 = bitcast <8 x i16> %776 to <4 x i32>
  %785 = bitcast <8 x i16> %777 to <4 x i32>
  %786 = shufflevector <4 x i32> %784, <4 x i32> %785, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %787 = bitcast <4 x i32> %786 to <2 x i64>
  %788 = bitcast <8 x i16> %778 to <4 x i32>
  %789 = bitcast <8 x i16> %779 to <4 x i32>
  %790 = shufflevector <4 x i32> %788, <4 x i32> %789, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %791 = bitcast <4 x i32> %790 to <2 x i64>
  %792 = bitcast <8 x i16> %780 to <4 x i32>
  %793 = bitcast <8 x i16> %781 to <4 x i32>
  %794 = shufflevector <4 x i32> %792, <4 x i32> %793, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %795 = bitcast <4 x i32> %794 to <2 x i64>
  %796 = bitcast <8 x i16> %782 to <4 x i32>
  %797 = bitcast <8 x i16> %783 to <4 x i32>
  %798 = shufflevector <4 x i32> %796, <4 x i32> %797, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %799 = bitcast <4 x i32> %798 to <2 x i64>
  %800 = shufflevector <4 x i32> %784, <4 x i32> %785, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %801 = bitcast <4 x i32> %800 to <2 x i64>
  %802 = shufflevector <4 x i32> %788, <4 x i32> %789, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %803 = bitcast <4 x i32> %802 to <2 x i64>
  %804 = shufflevector <4 x i32> %792, <4 x i32> %793, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %805 = bitcast <4 x i32> %804 to <2 x i64>
  %806 = shufflevector <4 x i32> %796, <4 x i32> %797, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %807 = bitcast <4 x i32> %806 to <2 x i64>
  %808 = shufflevector <2 x i64> %787, <2 x i64> %791, <2 x i32> <i32 0, i32 2>
  %809 = shufflevector <2 x i64> %787, <2 x i64> %791, <2 x i32> <i32 1, i32 3>
  %810 = shufflevector <2 x i64> %801, <2 x i64> %803, <2 x i32> <i32 0, i32 2>
  %811 = shufflevector <2 x i64> %801, <2 x i64> %803, <2 x i32> <i32 1, i32 3>
  %812 = shufflevector <2 x i64> %795, <2 x i64> %799, <2 x i32> <i32 0, i32 2>
  %813 = shufflevector <2 x i64> %795, <2 x i64> %799, <2 x i32> <i32 1, i32 3>
  %814 = shufflevector <2 x i64> %805, <2 x i64> %807, <2 x i32> <i32 0, i32 2>
  %815 = shufflevector <2 x i64> %805, <2 x i64> %807, <2 x i32> <i32 1, i32 3>
  %816 = bitcast <2 x i64> %808 to <8 x i16>
  %817 = bitcast <2 x i64> %809 to <8 x i16>
  %818 = shufflevector <8 x i16> %816, <8 x i16> %817, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %819 = shufflevector <8 x i16> %816, <8 x i16> %817, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %820 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %711, i64 0
  %821 = bitcast i16* %820 to <8 x i16>*
  %822 = load <8 x i16>, <8 x i16>* %821, align 16
  %823 = add nuw nsw i64 %711, 1
  %824 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %823, i64 0
  %825 = bitcast i16* %824 to <8 x i16>*
  %826 = load <8 x i16>, <8 x i16>* %825, align 16
  %827 = shufflevector <8 x i16> %822, <8 x i16> %826, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %828 = shufflevector <8 x i16> %822, <8 x i16> %826, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %829 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %818, <8 x i16> %827) #5
  %830 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %819, <8 x i16> %828) #5
  %831 = bitcast <2 x i64> %810 to <8 x i16>
  %832 = bitcast <2 x i64> %811 to <8 x i16>
  %833 = shufflevector <8 x i16> %831, <8 x i16> %832, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %834 = shufflevector <8 x i16> %831, <8 x i16> %832, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %835 = add nuw nsw i64 %711, 2
  %836 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %835, i64 0
  %837 = bitcast i16* %836 to <8 x i16>*
  %838 = load <8 x i16>, <8 x i16>* %837, align 16
  %839 = add nuw nsw i64 %711, 3
  %840 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %839, i64 0
  %841 = bitcast i16* %840 to <8 x i16>*
  %842 = load <8 x i16>, <8 x i16>* %841, align 16
  %843 = shufflevector <8 x i16> %838, <8 x i16> %842, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %844 = shufflevector <8 x i16> %838, <8 x i16> %842, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %845 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %833, <8 x i16> %843) #5
  %846 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %834, <8 x i16> %844) #5
  %847 = bitcast <2 x i64> %812 to <8 x i16>
  %848 = bitcast <2 x i64> %813 to <8 x i16>
  %849 = shufflevector <8 x i16> %847, <8 x i16> %848, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %850 = shufflevector <8 x i16> %847, <8 x i16> %848, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %851 = add nuw nsw i64 %711, 4
  %852 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %851, i64 0
  %853 = bitcast i16* %852 to <8 x i16>*
  %854 = load <8 x i16>, <8 x i16>* %853, align 16
  %855 = add nuw nsw i64 %711, 5
  %856 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %855, i64 0
  %857 = bitcast i16* %856 to <8 x i16>*
  %858 = load <8 x i16>, <8 x i16>* %857, align 16
  %859 = shufflevector <8 x i16> %854, <8 x i16> %858, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %860 = shufflevector <8 x i16> %854, <8 x i16> %858, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %861 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %849, <8 x i16> %859) #5
  %862 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %850, <8 x i16> %860) #5
  %863 = bitcast <2 x i64> %814 to <8 x i16>
  %864 = bitcast <2 x i64> %815 to <8 x i16>
  %865 = shufflevector <8 x i16> %863, <8 x i16> %864, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %866 = shufflevector <8 x i16> %863, <8 x i16> %864, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %867 = add nuw nsw i64 %711, 6
  %868 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %867, i64 0
  %869 = bitcast i16* %868 to <8 x i16>*
  %870 = load <8 x i16>, <8 x i16>* %869, align 16
  %871 = add nuw nsw i64 %711, 7
  %872 = getelementptr inbounds %union.anon.20, %union.anon.20* %18, i64 0, i32 0, i64 %871, i64 0
  %873 = bitcast i16* %872 to <8 x i16>*
  %874 = load <8 x i16>, <8 x i16>* %873, align 16
  %875 = shufflevector <8 x i16> %870, <8 x i16> %874, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %876 = shufflevector <8 x i16> %870, <8 x i16> %874, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %877 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %865, <8 x i16> %875) #5
  %878 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %866, <8 x i16> %876) #5
  %879 = add <4 x i32> %829, <i32 263168, i32 263168, i32 263168, i32 263168>
  %880 = add <4 x i32> %879, %845
  %881 = add <4 x i32> %880, %861
  %882 = add <4 x i32> %881, %877
  %883 = ashr <4 x i32> %882, <i32 11, i32 11, i32 11, i32 11>
  %884 = add <4 x i32> %830, <i32 263168, i32 263168, i32 263168, i32 263168>
  %885 = add <4 x i32> %884, %846
  %886 = add <4 x i32> %885, %862
  %887 = add <4 x i32> %886, %878
  %888 = ashr <4 x i32> %887, <i32 11, i32 11, i32 11, i32 11>
  %889 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %883, <4 x i32> %888) #5
  %890 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %889, <8 x i16> undef) #5
  %891 = bitcast <16 x i8> %890 to <2 x i64>
  %892 = extractelement <2 x i64> %891, i32 0
  %893 = bitcast i8* %712 to i64*
  store i64 %892, i64* %893, align 1
  %894 = getelementptr inbounds i8, i8* %712, i64 %16
  %895 = add nsw i32 %713, %41
  %896 = icmp eq i64 %823, 8
  br i1 %896, label %897, label %710

897:                                              ; preds = %710, %212, %91
  call void @llvm.lifetime.end.p0i8(i64 240, i8* nonnull %28) #5
  %898 = add nsw i32 %61, %54
  %899 = getelementptr inbounds i8, i8* %62, i64 8
  %900 = icmp slt i32 %898, %23
  br i1 %900, label %60, label %901

901:                                              ; preds = %897
  %902 = getelementptr inbounds i8, i8* %58, i64 %26
  %903 = add nsw i32 %59, %55
  %904 = icmp slt i32 %903, %25
  br i1 %904, label %57, label %905

905:                                              ; preds = %901
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Warp_SSE4_1ILb1EEEvPKvliiPKiiiiiiissssPvl(i8* nocapture readonly, i64, i32, i32, i32* nocapture readonly, i32, i32, i32, i32, i32, i32, i16 signext, i16 signext, i16 signext, i16 signext, i8* nocapture, i64) #3 {
  %18 = alloca %union.anon.21, align 16
  %19 = bitcast i8* %15 to i16*
  %20 = add i32 %7, 4
  %21 = add i32 %8, 4
  %22 = shl i32 %21, %6
  %23 = add i32 %20, %9
  %24 = shl i32 %23, %5
  %25 = add i32 %21, %10
  %26 = shl i32 %25, %6
  %27 = shl nsw i64 %16, 3
  %28 = shl i32 %20, %5
  %29 = bitcast %union.anon.21* %18 to i8*
  %30 = getelementptr inbounds i32, i32* %4, i64 2
  %31 = getelementptr inbounds i32, i32* %4, i64 3
  %32 = getelementptr inbounds i32, i32* %4, i64 4
  %33 = getelementptr inbounds i32, i32* %4, i64 5
  %34 = getelementptr inbounds i32, i32* %4, i64 1
  %35 = sext i16 %11 to i32
  %36 = sext i16 %12 to i32
  %37 = mul nsw i32 %36, -7
  %38 = shl nsw i32 %35, 2
  %39 = add nsw i32 %35, 512
  %40 = add nsw i32 %3, -1
  %41 = sext i16 %13 to i32
  %42 = sext i16 %14 to i32
  %43 = shl nsw i32 %42, 2
  %44 = shl nsw i32 %41, 2
  %45 = sext i32 %2 to i64
  %46 = getelementptr inbounds i8, i8* %0, i64 -1
  %47 = getelementptr inbounds i8, i8* %46, i64 %45
  %48 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 0, i64 8
  %49 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 0, i64 9
  %50 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 0, i64 10
  %51 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 0, i64 11
  %52 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 0, i64 12
  %53 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 0, i64 13
  %54 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 0, i64 14
  %55 = shl i32 8, %5
  %56 = shl i32 8, %6
  %57 = bitcast %union.anon.21* %18 to <8 x i16>*
  br label %58

58:                                               ; preds = %888, %17
  %59 = phi i16* [ %19, %17 ], [ %889, %888 ]
  %60 = phi i32 [ %22, %17 ], [ %890, %888 ]
  br label %61

61:                                               ; preds = %884, %58
  %62 = phi i32 [ %28, %58 ], [ %885, %884 ]
  %63 = phi i16* [ %59, %58 ], [ %886, %884 ]
  call void @llvm.lifetime.start.p0i8(i64 240, i8* nonnull %29) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %29, i8 -86, i64 240, i1 false) #5
  %64 = load i32, i32* %30, align 4
  %65 = mul nsw i32 %64, %62
  %66 = load i32, i32* %31, align 4
  %67 = mul nsw i32 %66, %60
  %68 = add nsw i32 %67, %65
  %69 = load i32, i32* %4, align 4
  %70 = add nsw i32 %68, %69
  %71 = load i32, i32* %32, align 4
  %72 = mul nsw i32 %71, %62
  %73 = load i32, i32* %33, align 4
  %74 = mul nsw i32 %73, %60
  %75 = add nsw i32 %74, %72
  %76 = load i32, i32* %34, align 4
  %77 = add nsw i32 %75, %76
  %78 = ashr i32 %70, %5
  %79 = ashr i32 %77, %6
  %80 = ashr i32 %78, 16
  %81 = ashr i32 %79, 16
  %82 = add nsw i32 %80, -6
  %83 = icmp sge i32 %82, %2
  %84 = icmp slt i32 %78, -393216
  %85 = or i1 %84, %83
  %86 = add nsw i32 %81, -6
  %87 = icmp sge i32 %86, %3
  %88 = icmp slt i32 %79, -393216
  %89 = or i1 %88, %87
  br i1 %85, label %90, label %394

90:                                               ; preds = %61
  %91 = select i1 %84, i8* %0, i8* %47
  br i1 %89, label %92, label %118

92:                                               ; preds = %90
  %93 = select i1 %88, i32 0, i32 %40
  %94 = sext i32 %93 to i64
  %95 = mul nsw i64 %94, %1
  %96 = getelementptr inbounds i8, i8* %91, i64 %95
  %97 = load i8, i8* %96, align 1
  %98 = zext i8 %97 to i16
  %99 = shl nuw nsw i16 %98, 4
  %100 = insertelement <8 x i16> undef, i16 %99, i32 0
  %101 = shufflevector <8 x i16> %100, <8 x i16> undef, <8 x i32> zeroinitializer
  %102 = bitcast i16* %63 to i8*
  %103 = bitcast i16* %63 to <8 x i16>*
  store <8 x i16> %101, <8 x i16>* %103, align 1
  %104 = getelementptr inbounds i16, i16* %63, i64 %16
  %105 = bitcast i16* %104 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %105, i8* align 2 %102, i64 16, i1 false) #5
  %106 = getelementptr inbounds i16, i16* %104, i64 %16
  %107 = bitcast i16* %106 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %107, i8* align 2 %102, i64 16, i1 false) #5
  %108 = getelementptr inbounds i16, i16* %106, i64 %16
  %109 = bitcast i16* %108 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %109, i8* align 2 %102, i64 16, i1 false) #5
  %110 = getelementptr inbounds i16, i16* %108, i64 %16
  %111 = bitcast i16* %110 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %111, i8* align 2 %102, i64 16, i1 false) #5
  %112 = getelementptr inbounds i16, i16* %110, i64 %16
  %113 = bitcast i16* %112 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %113, i8* align 2 %102, i64 16, i1 false) #5
  %114 = getelementptr inbounds i16, i16* %112, i64 %16
  %115 = bitcast i16* %114 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %115, i8* align 2 %102, i64 16, i1 false) #5
  %116 = getelementptr inbounds i16, i16* %114, i64 %16
  %117 = bitcast i16* %116 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %117, i8* align 2 %102, i64 16, i1 false) #5
  br label %884

118:                                              ; preds = %90
  %119 = sext i32 %81 to i64
  %120 = add nsw i64 %119, -7
  %121 = mul nsw i64 %120, %1
  %122 = getelementptr inbounds i8, i8* %91, i64 %121
  %123 = load i8, i8* %122, align 1
  %124 = add nsw i64 %119, -6
  %125 = mul nsw i64 %124, %1
  %126 = getelementptr inbounds i8, i8* %91, i64 %125
  %127 = load i8, i8* %126, align 1
  %128 = add nsw i64 %119, -5
  %129 = mul nsw i64 %128, %1
  %130 = getelementptr inbounds i8, i8* %91, i64 %129
  %131 = load i8, i8* %130, align 1
  %132 = add nsw i64 %119, -4
  %133 = mul nsw i64 %132, %1
  %134 = getelementptr inbounds i8, i8* %91, i64 %133
  %135 = load i8, i8* %134, align 1
  %136 = add nsw i64 %119, -3
  %137 = mul nsw i64 %136, %1
  %138 = getelementptr inbounds i8, i8* %91, i64 %137
  %139 = load i8, i8* %138, align 1
  %140 = add nsw i64 %119, -2
  %141 = mul nsw i64 %140, %1
  %142 = getelementptr inbounds i8, i8* %91, i64 %141
  %143 = load i8, i8* %142, align 1
  %144 = add nsw i64 %119, -1
  %145 = mul nsw i64 %144, %1
  %146 = getelementptr inbounds i8, i8* %91, i64 %145
  %147 = load i8, i8* %146, align 1
  %148 = mul nsw i64 %119, %1
  %149 = getelementptr inbounds i8, i8* %91, i64 %148
  %150 = load i8, i8* %149, align 1
  %151 = insertelement <8 x i8> undef, i8 %123, i32 0
  %152 = insertelement <8 x i8> %151, i8 %127, i32 1
  %153 = insertelement <8 x i8> %152, i8 %131, i32 2
  %154 = insertelement <8 x i8> %153, i8 %135, i32 3
  %155 = insertelement <8 x i8> %154, i8 %139, i32 4
  %156 = insertelement <8 x i8> %155, i8 %143, i32 5
  %157 = insertelement <8 x i8> %156, i8 %147, i32 6
  %158 = insertelement <8 x i8> %157, i8 %150, i32 7
  %159 = zext <8 x i8> %158 to <8 x i16>
  %160 = shl nuw nsw <8 x i16> %159, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  store <8 x i16> %160, <8 x i16>* %57, align 16
  %161 = add nsw i64 %119, 1
  %162 = mul nsw i64 %161, %1
  %163 = getelementptr inbounds i8, i8* %91, i64 %162
  %164 = load i8, i8* %163, align 1
  %165 = zext i8 %164 to i16
  %166 = shl nuw nsw i16 %165, 4
  store i16 %166, i16* %48, align 16
  %167 = add nsw i64 %119, 2
  %168 = mul nsw i64 %167, %1
  %169 = getelementptr inbounds i8, i8* %91, i64 %168
  %170 = load i8, i8* %169, align 1
  %171 = zext i8 %170 to i16
  %172 = shl nuw nsw i16 %171, 4
  store i16 %172, i16* %49, align 2
  %173 = add nsw i64 %119, 3
  %174 = mul nsw i64 %173, %1
  %175 = getelementptr inbounds i8, i8* %91, i64 %174
  %176 = load i8, i8* %175, align 1
  %177 = zext i8 %176 to i16
  %178 = shl nuw nsw i16 %177, 4
  store i16 %178, i16* %50, align 4
  %179 = add nsw i64 %119, 4
  %180 = mul nsw i64 %179, %1
  %181 = getelementptr inbounds i8, i8* %91, i64 %180
  %182 = load i8, i8* %181, align 1
  %183 = zext i8 %182 to i16
  %184 = shl nuw nsw i16 %183, 4
  store i16 %184, i16* %51, align 2
  %185 = add nsw i64 %119, 5
  %186 = mul nsw i64 %185, %1
  %187 = getelementptr inbounds i8, i8* %91, i64 %186
  %188 = load i8, i8* %187, align 1
  %189 = zext i8 %188 to i16
  %190 = shl nuw nsw i16 %189, 4
  store i16 %190, i16* %52, align 8
  %191 = add nsw i64 %119, 6
  %192 = mul nsw i64 %191, %1
  %193 = getelementptr inbounds i8, i8* %91, i64 %192
  %194 = load i8, i8* %193, align 1
  %195 = zext i8 %194 to i16
  %196 = shl nuw nsw i16 %195, 4
  store i16 %196, i16* %53, align 2
  %197 = add nsw i64 %119, 7
  %198 = mul nsw i64 %197, %1
  %199 = getelementptr inbounds i8, i8* %91, i64 %198
  %200 = load i8, i8* %199, align 1
  %201 = zext i8 %200 to i16
  %202 = shl nuw nsw i16 %201, 4
  store i16 %202, i16* %54, align 4
  %203 = and i32 %79, 65535
  %204 = sub nsw i32 %203, %43
  br label %205

205:                                              ; preds = %205, %118
  %206 = phi i64 [ 0, %118 ], [ %392, %205 ]
  %207 = phi i16* [ %63, %118 ], [ %390, %205 ]
  %208 = phi i32 [ %204, %118 ], [ %391, %205 ]
  %209 = sub nsw i32 %208, %44
  %210 = add nsw i32 %209, 512
  %211 = ashr i32 %210, 10
  %212 = add nsw i32 %211, 64
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %213, i64 0
  %215 = bitcast i16* %214 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = add nsw i32 %209, %41
  %218 = add nsw i32 %217, 512
  %219 = ashr i32 %218, 10
  %220 = add nsw i32 %219, 64
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %221, i64 0
  %223 = bitcast i16* %222 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = add nsw i32 %217, %41
  %226 = add nsw i32 %225, 512
  %227 = ashr i32 %226, 10
  %228 = add nsw i32 %227, 64
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %229, i64 0
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = add nsw i32 %225, %41
  %234 = add nsw i32 %233, 512
  %235 = ashr i32 %234, 10
  %236 = add nsw i32 %235, 64
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %237, i64 0
  %239 = bitcast i16* %238 to <8 x i16>*
  %240 = load <8 x i16>, <8 x i16>* %239, align 16
  %241 = add nsw i32 %233, %41
  %242 = add i32 %241, 512
  %243 = ashr i32 %242, 10
  %244 = add nsw i32 %243, 64
  %245 = sext i32 %244 to i64
  %246 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %245, i64 0
  %247 = bitcast i16* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = add i32 %242, %41
  %250 = ashr i32 %249, 10
  %251 = add nsw i32 %250, 64
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %252, i64 0
  %254 = bitcast i16* %253 to <8 x i16>*
  %255 = load <8 x i16>, <8 x i16>* %254, align 16
  %256 = add i32 %249, %41
  %257 = ashr i32 %256, 10
  %258 = add nsw i32 %257, 64
  %259 = sext i32 %258 to i64
  %260 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %259, i64 0
  %261 = bitcast i16* %260 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = add i32 %256, %41
  %264 = ashr i32 %263, 10
  %265 = add nsw i32 %264, 64
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %266, i64 0
  %268 = bitcast i16* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = shufflevector <8 x i16> %216, <8 x i16> %224, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %271 = shufflevector <8 x i16> %232, <8 x i16> %240, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %272 = shufflevector <8 x i16> %248, <8 x i16> %255, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %273 = shufflevector <8 x i16> %262, <8 x i16> %269, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %274 = shufflevector <8 x i16> %216, <8 x i16> %224, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %232, <8 x i16> %240, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = shufflevector <8 x i16> %248, <8 x i16> %255, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %277 = shufflevector <8 x i16> %262, <8 x i16> %269, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %278 = bitcast <8 x i16> %270 to <4 x i32>
  %279 = bitcast <8 x i16> %271 to <4 x i32>
  %280 = shufflevector <4 x i32> %278, <4 x i32> %279, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %281 = bitcast <4 x i32> %280 to <2 x i64>
  %282 = bitcast <8 x i16> %272 to <4 x i32>
  %283 = bitcast <8 x i16> %273 to <4 x i32>
  %284 = shufflevector <4 x i32> %282, <4 x i32> %283, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %285 = bitcast <4 x i32> %284 to <2 x i64>
  %286 = bitcast <8 x i16> %274 to <4 x i32>
  %287 = bitcast <8 x i16> %275 to <4 x i32>
  %288 = shufflevector <4 x i32> %286, <4 x i32> %287, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %289 = bitcast <4 x i32> %288 to <2 x i64>
  %290 = bitcast <8 x i16> %276 to <4 x i32>
  %291 = bitcast <8 x i16> %277 to <4 x i32>
  %292 = shufflevector <4 x i32> %290, <4 x i32> %291, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %293 = bitcast <4 x i32> %292 to <2 x i64>
  %294 = shufflevector <4 x i32> %278, <4 x i32> %279, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %295 = bitcast <4 x i32> %294 to <2 x i64>
  %296 = shufflevector <4 x i32> %282, <4 x i32> %283, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %297 = bitcast <4 x i32> %296 to <2 x i64>
  %298 = shufflevector <4 x i32> %286, <4 x i32> %287, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %299 = bitcast <4 x i32> %298 to <2 x i64>
  %300 = shufflevector <4 x i32> %290, <4 x i32> %291, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %301 = bitcast <4 x i32> %300 to <2 x i64>
  %302 = shufflevector <2 x i64> %281, <2 x i64> %285, <2 x i32> <i32 0, i32 2>
  %303 = shufflevector <2 x i64> %281, <2 x i64> %285, <2 x i32> <i32 1, i32 3>
  %304 = shufflevector <2 x i64> %295, <2 x i64> %297, <2 x i32> <i32 0, i32 2>
  %305 = shufflevector <2 x i64> %295, <2 x i64> %297, <2 x i32> <i32 1, i32 3>
  %306 = shufflevector <2 x i64> %289, <2 x i64> %293, <2 x i32> <i32 0, i32 2>
  %307 = shufflevector <2 x i64> %289, <2 x i64> %293, <2 x i32> <i32 1, i32 3>
  %308 = shufflevector <2 x i64> %299, <2 x i64> %301, <2 x i32> <i32 0, i32 2>
  %309 = shufflevector <2 x i64> %299, <2 x i64> %301, <2 x i32> <i32 1, i32 3>
  %310 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 0, i64 %206
  %311 = bitcast <2 x i64> %302 to <8 x i16>
  %312 = bitcast <2 x i64> %303 to <8 x i16>
  %313 = shufflevector <8 x i16> %311, <8 x i16> %312, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %314 = shufflevector <8 x i16> %311, <8 x i16> %312, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %315 = getelementptr inbounds i16, i16* %310, i64 1
  %316 = load i16, i16* %315, align 2
  %317 = zext i16 %316 to i32
  %318 = shl nuw i32 %317, 16
  %319 = load i16, i16* %310, align 2
  %320 = sext i16 %319 to i32
  %321 = or i32 %318, %320
  %322 = insertelement <4 x i32> undef, i32 %321, i32 0
  %323 = shufflevector <4 x i32> %322, <4 x i32> undef, <4 x i32> zeroinitializer
  %324 = bitcast <4 x i32> %323 to <8 x i16>
  %325 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %313, <8 x i16> %324) #5
  %326 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %314, <8 x i16> %324) #5
  %327 = bitcast <2 x i64> %304 to <8 x i16>
  %328 = bitcast <2 x i64> %305 to <8 x i16>
  %329 = shufflevector <8 x i16> %327, <8 x i16> %328, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %330 = shufflevector <8 x i16> %327, <8 x i16> %328, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %331 = getelementptr inbounds i16, i16* %310, i64 3
  %332 = load i16, i16* %331, align 2
  %333 = zext i16 %332 to i32
  %334 = shl nuw i32 %333, 16
  %335 = getelementptr inbounds i16, i16* %310, i64 2
  %336 = load i16, i16* %335, align 2
  %337 = sext i16 %336 to i32
  %338 = or i32 %334, %337
  %339 = insertelement <4 x i32> undef, i32 %338, i32 0
  %340 = shufflevector <4 x i32> %339, <4 x i32> undef, <4 x i32> zeroinitializer
  %341 = bitcast <4 x i32> %340 to <8 x i16>
  %342 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %329, <8 x i16> %341) #5
  %343 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %330, <8 x i16> %341) #5
  %344 = bitcast <2 x i64> %306 to <8 x i16>
  %345 = bitcast <2 x i64> %307 to <8 x i16>
  %346 = shufflevector <8 x i16> %344, <8 x i16> %345, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %347 = shufflevector <8 x i16> %344, <8 x i16> %345, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %348 = getelementptr inbounds i16, i16* %310, i64 5
  %349 = load i16, i16* %348, align 2
  %350 = zext i16 %349 to i32
  %351 = shl nuw i32 %350, 16
  %352 = getelementptr inbounds i16, i16* %310, i64 4
  %353 = load i16, i16* %352, align 2
  %354 = sext i16 %353 to i32
  %355 = or i32 %351, %354
  %356 = insertelement <4 x i32> undef, i32 %355, i32 0
  %357 = shufflevector <4 x i32> %356, <4 x i32> undef, <4 x i32> zeroinitializer
  %358 = bitcast <4 x i32> %357 to <8 x i16>
  %359 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %346, <8 x i16> %358) #5
  %360 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %347, <8 x i16> %358) #5
  %361 = bitcast <2 x i64> %308 to <8 x i16>
  %362 = bitcast <2 x i64> %309 to <8 x i16>
  %363 = shufflevector <8 x i16> %361, <8 x i16> %362, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %364 = shufflevector <8 x i16> %361, <8 x i16> %362, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = getelementptr inbounds i16, i16* %310, i64 7
  %366 = load i16, i16* %365, align 2
  %367 = zext i16 %366 to i32
  %368 = shl nuw i32 %367, 16
  %369 = getelementptr inbounds i16, i16* %310, i64 6
  %370 = load i16, i16* %369, align 2
  %371 = sext i16 %370 to i32
  %372 = or i32 %368, %371
  %373 = insertelement <4 x i32> undef, i32 %372, i32 0
  %374 = shufflevector <4 x i32> %373, <4 x i32> undef, <4 x i32> zeroinitializer
  %375 = bitcast <4 x i32> %374 to <8 x i16>
  %376 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %363, <8 x i16> %375) #5
  %377 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %364, <8 x i16> %375) #5
  %378 = add <4 x i32> %325, <i32 64, i32 64, i32 64, i32 64>
  %379 = add <4 x i32> %378, %342
  %380 = add <4 x i32> %379, %359
  %381 = add <4 x i32> %380, %376
  %382 = ashr <4 x i32> %381, <i32 7, i32 7, i32 7, i32 7>
  %383 = add <4 x i32> %326, <i32 64, i32 64, i32 64, i32 64>
  %384 = add <4 x i32> %383, %343
  %385 = add <4 x i32> %384, %360
  %386 = add <4 x i32> %385, %377
  %387 = ashr <4 x i32> %386, <i32 7, i32 7, i32 7, i32 7>
  %388 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %382, <4 x i32> %387) #5
  %389 = bitcast i16* %207 to <8 x i16>*
  store <8 x i16> %388, <8 x i16>* %389, align 1
  %390 = getelementptr inbounds i16, i16* %207, i64 %16
  %391 = add nsw i32 %208, %42
  %392 = add nuw nsw i64 %206, 1
  %393 = icmp eq i64 %392, 8
  br i1 %393, label %884, label %205

394:                                              ; preds = %61
  br i1 %89, label %395, label %546

395:                                              ; preds = %394
  %396 = select i1 %88, i32 0, i32 %40
  %397 = sext i32 %396 to i64
  %398 = mul nsw i64 %397, %1
  %399 = getelementptr inbounds i8, i8* %0, i64 %398
  %400 = add nsw i32 %80, -7
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i8, i8* %399, i64 %401
  %403 = bitcast i8* %402 to <16 x i8>*
  %404 = load <16 x i8>, <16 x i8>* %403, align 1
  %405 = and i32 %78, 65535
  %406 = add nsw i32 %405, %37
  %407 = shufflevector <16 x i8> %404, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %408 = shufflevector <16 x i8> %404, <16 x i8> %407, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %409 = shufflevector <16 x i8> %404, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %410 = shufflevector <16 x i8> %409, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %411 = shufflevector <16 x i8> %409, <16 x i8> %410, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %412 = shufflevector <16 x i8> %409, <16 x i8> <i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18>
  %413 = shufflevector <16 x i8> %412, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %414 = shufflevector <16 x i8> %412, <16 x i8> %413, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %415 = shufflevector <16 x i8> %412, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %416 = shufflevector <16 x i8> %415, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %417 = shufflevector <16 x i8> %415, <16 x i8> %416, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  br label %418

418:                                              ; preds = %418, %395
  %419 = phi i64 [ -7, %395 ], [ %544, %418 ]
  %420 = phi i32 [ %406, %395 ], [ %543, %418 ]
  %421 = add nsw i64 %419, 7
  %422 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %421, i64 0
  %423 = sub nsw i32 %420, %38
  %424 = add nsw i32 %423, 512
  %425 = ashr i32 %424, 10
  %426 = add nsw i32 %425, 64
  %427 = sext i32 %426 to i64
  %428 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %427, i64 0
  %429 = bitcast i8* %428 to i64*
  %430 = load i64, i64* %429, align 8
  %431 = insertelement <2 x i64> undef, i64 %430, i32 0
  %432 = add nsw i32 %423, %35
  %433 = add nsw i32 %432, 512
  %434 = ashr i32 %433, 10
  %435 = add nsw i32 %434, 64
  %436 = sext i32 %435 to i64
  %437 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %436, i64 0
  %438 = bitcast i8* %437 to i64*
  %439 = load i64, i64* %438, align 8
  %440 = insertelement <2 x i64> undef, i64 %439, i32 0
  %441 = add nsw i32 %432, %35
  %442 = add nsw i32 %441, 512
  %443 = ashr i32 %442, 10
  %444 = add nsw i32 %443, 64
  %445 = sext i32 %444 to i64
  %446 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %445, i64 0
  %447 = bitcast i8* %446 to i64*
  %448 = load i64, i64* %447, align 8
  %449 = insertelement <2 x i64> undef, i64 %448, i32 0
  %450 = add nsw i32 %441, %35
  %451 = add nsw i32 %450, 512
  %452 = ashr i32 %451, 10
  %453 = add nsw i32 %452, 64
  %454 = sext i32 %453 to i64
  %455 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %454, i64 0
  %456 = bitcast i8* %455 to i64*
  %457 = load i64, i64* %456, align 8
  %458 = insertelement <2 x i64> undef, i64 %457, i32 0
  %459 = add nsw i32 %450, %35
  %460 = add nsw i32 %459, 512
  %461 = ashr i32 %460, 10
  %462 = add nsw i32 %461, 64
  %463 = sext i32 %462 to i64
  %464 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %463, i64 0
  %465 = bitcast i8* %464 to i64*
  %466 = load i64, i64* %465, align 8
  %467 = insertelement <2 x i64> undef, i64 %466, i32 0
  %468 = add nsw i32 %459, %35
  %469 = add nsw i32 %468, 512
  %470 = ashr i32 %469, 10
  %471 = add nsw i32 %470, 64
  %472 = sext i32 %471 to i64
  %473 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %472, i64 0
  %474 = bitcast i8* %473 to i64*
  %475 = load i64, i64* %474, align 8
  %476 = insertelement <2 x i64> undef, i64 %475, i32 0
  %477 = add i32 %39, %468
  %478 = ashr i32 %477, 10
  %479 = add nsw i32 %478, 64
  %480 = sext i32 %479 to i64
  %481 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %480, i64 0
  %482 = bitcast i8* %481 to i64*
  %483 = load i64, i64* %482, align 8
  %484 = insertelement <2 x i64> undef, i64 %483, i32 0
  %485 = add i32 %477, %35
  %486 = ashr i32 %485, 10
  %487 = add nsw i32 %486, 64
  %488 = sext i32 %487 to i64
  %489 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %488, i64 0
  %490 = bitcast i8* %489 to i64*
  %491 = load i64, i64* %490, align 8
  %492 = insertelement <2 x i64> undef, i64 %491, i32 0
  %493 = bitcast <2 x i64> %431 to <16 x i8>
  %494 = bitcast <2 x i64> %440 to <16 x i8>
  %495 = shufflevector <16 x i8> %493, <16 x i8> %494, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %496 = bitcast <2 x i64> %449 to <16 x i8>
  %497 = bitcast <2 x i64> %458 to <16 x i8>
  %498 = shufflevector <16 x i8> %496, <16 x i8> %497, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %499 = bitcast <2 x i64> %467 to <16 x i8>
  %500 = bitcast <2 x i64> %476 to <16 x i8>
  %501 = shufflevector <16 x i8> %499, <16 x i8> %500, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %502 = bitcast <2 x i64> %484 to <16 x i8>
  %503 = bitcast <2 x i64> %492 to <16 x i8>
  %504 = shufflevector <16 x i8> %502, <16 x i8> %503, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %505 = bitcast <16 x i8> %495 to <8 x i16>
  %506 = bitcast <16 x i8> %498 to <8 x i16>
  %507 = shufflevector <8 x i16> %505, <8 x i16> %506, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %508 = bitcast <16 x i8> %501 to <8 x i16>
  %509 = bitcast <16 x i8> %504 to <8 x i16>
  %510 = shufflevector <8 x i16> %508, <8 x i16> %509, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %511 = shufflevector <8 x i16> %505, <8 x i16> %506, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %512 = shufflevector <8 x i16> %508, <8 x i16> %509, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %513 = bitcast <8 x i16> %507 to <4 x i32>
  %514 = bitcast <8 x i16> %510 to <4 x i32>
  %515 = shufflevector <4 x i32> %513, <4 x i32> %514, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %516 = shufflevector <4 x i32> %513, <4 x i32> %514, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %517 = bitcast <8 x i16> %511 to <4 x i32>
  %518 = bitcast <8 x i16> %512 to <4 x i32>
  %519 = shufflevector <4 x i32> %517, <4 x i32> %518, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %520 = shufflevector <4 x i32> %517, <4 x i32> %518, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %521 = bitcast <4 x i32> %515 to <16 x i8>
  %522 = bitcast <4 x i32> %516 to <16 x i8>
  %523 = shufflevector <16 x i8> %521, <16 x i8> %522, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %524 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %408, <16 x i8> %523) #5
  %525 = shufflevector <16 x i8> %521, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %526 = shufflevector <16 x i8> %522, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %527 = shufflevector <16 x i8> %525, <16 x i8> %526, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %528 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %411, <16 x i8> %527) #5
  %529 = bitcast <4 x i32> %519 to <16 x i8>
  %530 = bitcast <4 x i32> %520 to <16 x i8>
  %531 = shufflevector <16 x i8> %529, <16 x i8> %530, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %532 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %414, <16 x i8> %531) #5
  %533 = shufflevector <16 x i8> %529, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %534 = shufflevector <16 x i8> %530, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %535 = shufflevector <16 x i8> %533, <16 x i8> %534, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %536 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %417, <16 x i8> %535) #5
  %537 = add <8 x i16> %524, <i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380>
  %538 = add <8 x i16> %537, %528
  %539 = add <8 x i16> %538, %532
  %540 = add <8 x i16> %539, %536
  %541 = ashr <8 x i16> %540, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %542 = bitcast i16* %422 to <8 x i16>*
  store <8 x i16> %541, <8 x i16>* %542, align 16
  %543 = add nsw i32 %420, %36
  %544 = add nsw i64 %419, 1
  %545 = icmp eq i64 %544, 8
  br i1 %545, label %697, label %418

546:                                              ; preds = %394
  %547 = and i32 %78, 65535
  %548 = add nsw i32 %547, %37
  %549 = add nsw i32 %80, -7
  %550 = sext i32 %549 to i64
  %551 = sext i32 %81 to i64
  %552 = getelementptr inbounds i8, i8* %0, i64 %550
  br label %553

553:                                              ; preds = %553, %546
  %554 = phi i64 [ -7, %546 ], [ %695, %553 ]
  %555 = phi i32 [ %548, %546 ], [ %694, %553 ]
  %556 = add nsw i64 %554, %551
  %557 = mul nsw i64 %556, %1
  %558 = getelementptr inbounds i8, i8* %552, i64 %557
  %559 = bitcast i8* %558 to <16 x i8>*
  %560 = load <16 x i8>, <16 x i8>* %559, align 1
  %561 = add nsw i64 %554, 7
  %562 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %561, i64 0
  %563 = sub nsw i32 %555, %38
  %564 = add nsw i32 %563, 512
  %565 = ashr i32 %564, 10
  %566 = add nsw i32 %565, 64
  %567 = sext i32 %566 to i64
  %568 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %567, i64 0
  %569 = bitcast i8* %568 to i64*
  %570 = load i64, i64* %569, align 8
  %571 = insertelement <2 x i64> undef, i64 %570, i32 0
  %572 = add nsw i32 %563, %35
  %573 = add nsw i32 %572, 512
  %574 = ashr i32 %573, 10
  %575 = add nsw i32 %574, 64
  %576 = sext i32 %575 to i64
  %577 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %576, i64 0
  %578 = bitcast i8* %577 to i64*
  %579 = load i64, i64* %578, align 8
  %580 = insertelement <2 x i64> undef, i64 %579, i32 0
  %581 = add nsw i32 %572, %35
  %582 = add nsw i32 %581, 512
  %583 = ashr i32 %582, 10
  %584 = add nsw i32 %583, 64
  %585 = sext i32 %584 to i64
  %586 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %585, i64 0
  %587 = bitcast i8* %586 to i64*
  %588 = load i64, i64* %587, align 8
  %589 = insertelement <2 x i64> undef, i64 %588, i32 0
  %590 = add nsw i32 %581, %35
  %591 = add nsw i32 %590, 512
  %592 = ashr i32 %591, 10
  %593 = add nsw i32 %592, 64
  %594 = sext i32 %593 to i64
  %595 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %594, i64 0
  %596 = bitcast i8* %595 to i64*
  %597 = load i64, i64* %596, align 8
  %598 = insertelement <2 x i64> undef, i64 %597, i32 0
  %599 = add nsw i32 %590, %35
  %600 = add nsw i32 %599, 512
  %601 = ashr i32 %600, 10
  %602 = add nsw i32 %601, 64
  %603 = sext i32 %602 to i64
  %604 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %603, i64 0
  %605 = bitcast i8* %604 to i64*
  %606 = load i64, i64* %605, align 8
  %607 = insertelement <2 x i64> undef, i64 %606, i32 0
  %608 = add nsw i32 %599, %35
  %609 = add nsw i32 %608, 512
  %610 = ashr i32 %609, 10
  %611 = add nsw i32 %610, 64
  %612 = sext i32 %611 to i64
  %613 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %612, i64 0
  %614 = bitcast i8* %613 to i64*
  %615 = load i64, i64* %614, align 8
  %616 = insertelement <2 x i64> undef, i64 %615, i32 0
  %617 = add i32 %39, %608
  %618 = ashr i32 %617, 10
  %619 = add nsw i32 %618, 64
  %620 = sext i32 %619 to i64
  %621 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %620, i64 0
  %622 = bitcast i8* %621 to i64*
  %623 = load i64, i64* %622, align 8
  %624 = insertelement <2 x i64> undef, i64 %623, i32 0
  %625 = add i32 %617, %35
  %626 = ashr i32 %625, 10
  %627 = add nsw i32 %626, 64
  %628 = sext i32 %627 to i64
  %629 = getelementptr inbounds [193 x [8 x i8]], [193 x [8 x i8]]* @_ZN7libgav115kWarpedFilters8E, i64 0, i64 %628, i64 0
  %630 = bitcast i8* %629 to i64*
  %631 = load i64, i64* %630, align 8
  %632 = insertelement <2 x i64> undef, i64 %631, i32 0
  %633 = bitcast <2 x i64> %571 to <16 x i8>
  %634 = bitcast <2 x i64> %580 to <16 x i8>
  %635 = shufflevector <16 x i8> %633, <16 x i8> %634, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %636 = bitcast <2 x i64> %589 to <16 x i8>
  %637 = bitcast <2 x i64> %598 to <16 x i8>
  %638 = shufflevector <16 x i8> %636, <16 x i8> %637, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %639 = bitcast <2 x i64> %607 to <16 x i8>
  %640 = bitcast <2 x i64> %616 to <16 x i8>
  %641 = shufflevector <16 x i8> %639, <16 x i8> %640, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %642 = bitcast <2 x i64> %624 to <16 x i8>
  %643 = bitcast <2 x i64> %632 to <16 x i8>
  %644 = shufflevector <16 x i8> %642, <16 x i8> %643, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %645 = bitcast <16 x i8> %635 to <8 x i16>
  %646 = bitcast <16 x i8> %638 to <8 x i16>
  %647 = shufflevector <8 x i16> %645, <8 x i16> %646, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %648 = bitcast <16 x i8> %641 to <8 x i16>
  %649 = bitcast <16 x i8> %644 to <8 x i16>
  %650 = shufflevector <8 x i16> %648, <8 x i16> %649, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %651 = shufflevector <8 x i16> %645, <8 x i16> %646, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %652 = shufflevector <8 x i16> %648, <8 x i16> %649, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %653 = bitcast <8 x i16> %647 to <4 x i32>
  %654 = bitcast <8 x i16> %650 to <4 x i32>
  %655 = shufflevector <4 x i32> %653, <4 x i32> %654, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %656 = shufflevector <4 x i32> %653, <4 x i32> %654, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %657 = bitcast <8 x i16> %651 to <4 x i32>
  %658 = bitcast <8 x i16> %652 to <4 x i32>
  %659 = shufflevector <4 x i32> %657, <4 x i32> %658, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %660 = shufflevector <4 x i32> %657, <4 x i32> %658, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %661 = bitcast <4 x i32> %655 to <16 x i8>
  %662 = bitcast <4 x i32> %656 to <16 x i8>
  %663 = shufflevector <16 x i8> %661, <16 x i8> %662, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %664 = shufflevector <16 x i8> %560, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %665 = shufflevector <16 x i8> %560, <16 x i8> %664, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %666 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %665, <16 x i8> %663) #5
  %667 = shufflevector <16 x i8> %560, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %668 = shufflevector <16 x i8> %661, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %669 = shufflevector <16 x i8> %662, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %670 = shufflevector <16 x i8> %668, <16 x i8> %669, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %671 = shufflevector <16 x i8> %667, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %672 = shufflevector <16 x i8> %667, <16 x i8> %671, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %673 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %672, <16 x i8> %670) #5
  %674 = shufflevector <16 x i8> %667, <16 x i8> <i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18>
  %675 = bitcast <4 x i32> %659 to <16 x i8>
  %676 = bitcast <4 x i32> %660 to <16 x i8>
  %677 = shufflevector <16 x i8> %675, <16 x i8> %676, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %678 = shufflevector <16 x i8> %674, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %679 = shufflevector <16 x i8> %674, <16 x i8> %678, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %680 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %679, <16 x i8> %677) #5
  %681 = shufflevector <16 x i8> %674, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %682 = shufflevector <16 x i8> %675, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %683 = shufflevector <16 x i8> %676, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %684 = shufflevector <16 x i8> %682, <16 x i8> %683, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %685 = shufflevector <16 x i8> %681, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %686 = shufflevector <16 x i8> %681, <16 x i8> %685, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %687 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %686, <16 x i8> %684) #5
  %688 = add <8 x i16> %666, <i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380, i16 -16380>
  %689 = add <8 x i16> %688, %673
  %690 = add <8 x i16> %689, %680
  %691 = add <8 x i16> %690, %687
  %692 = ashr <8 x i16> %691, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %693 = bitcast i16* %562 to <8 x i16>*
  store <8 x i16> %692, <8 x i16>* %693, align 16
  %694 = add nsw i32 %555, %36
  %695 = add nsw i64 %554, 1
  %696 = icmp eq i64 %695, 8
  br i1 %696, label %697, label %553

697:                                              ; preds = %553, %418
  %698 = and i32 %79, 65535
  %699 = sub nsw i32 %698, %43
  br label %700

700:                                              ; preds = %700, %697
  %701 = phi i64 [ 0, %697 ], [ %813, %700 ]
  %702 = phi i16* [ %63, %697 ], [ %881, %700 ]
  %703 = phi i32 [ %699, %697 ], [ %882, %700 ]
  %704 = sub nsw i32 %703, %44
  %705 = add nsw i32 %704, 512
  %706 = ashr i32 %705, 10
  %707 = add nsw i32 %706, 64
  %708 = sext i32 %707 to i64
  %709 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %708, i64 0
  %710 = bitcast i16* %709 to <8 x i16>*
  %711 = load <8 x i16>, <8 x i16>* %710, align 16
  %712 = add nsw i32 %704, %41
  %713 = add nsw i32 %712, 512
  %714 = ashr i32 %713, 10
  %715 = add nsw i32 %714, 64
  %716 = sext i32 %715 to i64
  %717 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %716, i64 0
  %718 = bitcast i16* %717 to <8 x i16>*
  %719 = load <8 x i16>, <8 x i16>* %718, align 16
  %720 = add nsw i32 %712, %41
  %721 = add nsw i32 %720, 512
  %722 = ashr i32 %721, 10
  %723 = add nsw i32 %722, 64
  %724 = sext i32 %723 to i64
  %725 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %724, i64 0
  %726 = bitcast i16* %725 to <8 x i16>*
  %727 = load <8 x i16>, <8 x i16>* %726, align 16
  %728 = add nsw i32 %720, %41
  %729 = add nsw i32 %728, 512
  %730 = ashr i32 %729, 10
  %731 = add nsw i32 %730, 64
  %732 = sext i32 %731 to i64
  %733 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %732, i64 0
  %734 = bitcast i16* %733 to <8 x i16>*
  %735 = load <8 x i16>, <8 x i16>* %734, align 16
  %736 = add nsw i32 %728, %41
  %737 = add nsw i32 %736, 512
  %738 = ashr i32 %737, 10
  %739 = add nsw i32 %738, 64
  %740 = sext i32 %739 to i64
  %741 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %740, i64 0
  %742 = bitcast i16* %741 to <8 x i16>*
  %743 = load <8 x i16>, <8 x i16>* %742, align 16
  %744 = add nsw i32 %736, %41
  %745 = add i32 %744, 512
  %746 = ashr i32 %745, 10
  %747 = add nsw i32 %746, 64
  %748 = sext i32 %747 to i64
  %749 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %748, i64 0
  %750 = bitcast i16* %749 to <8 x i16>*
  %751 = load <8 x i16>, <8 x i16>* %750, align 16
  %752 = add i32 %745, %41
  %753 = ashr i32 %752, 10
  %754 = add nsw i32 %753, 64
  %755 = sext i32 %754 to i64
  %756 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %755, i64 0
  %757 = bitcast i16* %756 to <8 x i16>*
  %758 = load <8 x i16>, <8 x i16>* %757, align 16
  %759 = add i32 %752, %41
  %760 = ashr i32 %759, 10
  %761 = add nsw i32 %760, 64
  %762 = sext i32 %761 to i64
  %763 = getelementptr inbounds [193 x [8 x i16]], [193 x [8 x i16]]* @_ZN7libgav114kWarpedFiltersE, i64 0, i64 %762, i64 0
  %764 = bitcast i16* %763 to <8 x i16>*
  %765 = load <8 x i16>, <8 x i16>* %764, align 16
  %766 = shufflevector <8 x i16> %711, <8 x i16> %719, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %767 = shufflevector <8 x i16> %727, <8 x i16> %735, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %768 = shufflevector <8 x i16> %743, <8 x i16> %751, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %769 = shufflevector <8 x i16> %758, <8 x i16> %765, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %770 = shufflevector <8 x i16> %711, <8 x i16> %719, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %771 = shufflevector <8 x i16> %727, <8 x i16> %735, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %772 = shufflevector <8 x i16> %743, <8 x i16> %751, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %773 = shufflevector <8 x i16> %758, <8 x i16> %765, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %774 = bitcast <8 x i16> %766 to <4 x i32>
  %775 = bitcast <8 x i16> %767 to <4 x i32>
  %776 = shufflevector <4 x i32> %774, <4 x i32> %775, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %777 = bitcast <4 x i32> %776 to <2 x i64>
  %778 = bitcast <8 x i16> %768 to <4 x i32>
  %779 = bitcast <8 x i16> %769 to <4 x i32>
  %780 = shufflevector <4 x i32> %778, <4 x i32> %779, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %781 = bitcast <4 x i32> %780 to <2 x i64>
  %782 = bitcast <8 x i16> %770 to <4 x i32>
  %783 = bitcast <8 x i16> %771 to <4 x i32>
  %784 = shufflevector <4 x i32> %782, <4 x i32> %783, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %785 = bitcast <4 x i32> %784 to <2 x i64>
  %786 = bitcast <8 x i16> %772 to <4 x i32>
  %787 = bitcast <8 x i16> %773 to <4 x i32>
  %788 = shufflevector <4 x i32> %786, <4 x i32> %787, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %789 = bitcast <4 x i32> %788 to <2 x i64>
  %790 = shufflevector <4 x i32> %774, <4 x i32> %775, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %791 = bitcast <4 x i32> %790 to <2 x i64>
  %792 = shufflevector <4 x i32> %778, <4 x i32> %779, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %793 = bitcast <4 x i32> %792 to <2 x i64>
  %794 = shufflevector <4 x i32> %782, <4 x i32> %783, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %795 = bitcast <4 x i32> %794 to <2 x i64>
  %796 = shufflevector <4 x i32> %786, <4 x i32> %787, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %797 = bitcast <4 x i32> %796 to <2 x i64>
  %798 = shufflevector <2 x i64> %777, <2 x i64> %781, <2 x i32> <i32 0, i32 2>
  %799 = shufflevector <2 x i64> %777, <2 x i64> %781, <2 x i32> <i32 1, i32 3>
  %800 = shufflevector <2 x i64> %791, <2 x i64> %793, <2 x i32> <i32 0, i32 2>
  %801 = shufflevector <2 x i64> %791, <2 x i64> %793, <2 x i32> <i32 1, i32 3>
  %802 = shufflevector <2 x i64> %785, <2 x i64> %789, <2 x i32> <i32 0, i32 2>
  %803 = shufflevector <2 x i64> %785, <2 x i64> %789, <2 x i32> <i32 1, i32 3>
  %804 = shufflevector <2 x i64> %795, <2 x i64> %797, <2 x i32> <i32 0, i32 2>
  %805 = shufflevector <2 x i64> %795, <2 x i64> %797, <2 x i32> <i32 1, i32 3>
  %806 = bitcast <2 x i64> %798 to <8 x i16>
  %807 = bitcast <2 x i64> %799 to <8 x i16>
  %808 = shufflevector <8 x i16> %806, <8 x i16> %807, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %809 = shufflevector <8 x i16> %806, <8 x i16> %807, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %810 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %701, i64 0
  %811 = bitcast i16* %810 to <8 x i16>*
  %812 = load <8 x i16>, <8 x i16>* %811, align 16
  %813 = add nuw nsw i64 %701, 1
  %814 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %813, i64 0
  %815 = bitcast i16* %814 to <8 x i16>*
  %816 = load <8 x i16>, <8 x i16>* %815, align 16
  %817 = shufflevector <8 x i16> %812, <8 x i16> %816, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %818 = shufflevector <8 x i16> %812, <8 x i16> %816, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %819 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %808, <8 x i16> %817) #5
  %820 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %809, <8 x i16> %818) #5
  %821 = bitcast <2 x i64> %800 to <8 x i16>
  %822 = bitcast <2 x i64> %801 to <8 x i16>
  %823 = shufflevector <8 x i16> %821, <8 x i16> %822, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %824 = shufflevector <8 x i16> %821, <8 x i16> %822, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %825 = add nuw nsw i64 %701, 2
  %826 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %825, i64 0
  %827 = bitcast i16* %826 to <8 x i16>*
  %828 = load <8 x i16>, <8 x i16>* %827, align 16
  %829 = add nuw nsw i64 %701, 3
  %830 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %829, i64 0
  %831 = bitcast i16* %830 to <8 x i16>*
  %832 = load <8 x i16>, <8 x i16>* %831, align 16
  %833 = shufflevector <8 x i16> %828, <8 x i16> %832, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %834 = shufflevector <8 x i16> %828, <8 x i16> %832, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %835 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %823, <8 x i16> %833) #5
  %836 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %824, <8 x i16> %834) #5
  %837 = bitcast <2 x i64> %802 to <8 x i16>
  %838 = bitcast <2 x i64> %803 to <8 x i16>
  %839 = shufflevector <8 x i16> %837, <8 x i16> %838, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %840 = shufflevector <8 x i16> %837, <8 x i16> %838, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %841 = add nuw nsw i64 %701, 4
  %842 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %841, i64 0
  %843 = bitcast i16* %842 to <8 x i16>*
  %844 = load <8 x i16>, <8 x i16>* %843, align 16
  %845 = add nuw nsw i64 %701, 5
  %846 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %845, i64 0
  %847 = bitcast i16* %846 to <8 x i16>*
  %848 = load <8 x i16>, <8 x i16>* %847, align 16
  %849 = shufflevector <8 x i16> %844, <8 x i16> %848, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %850 = shufflevector <8 x i16> %844, <8 x i16> %848, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %851 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %839, <8 x i16> %849) #5
  %852 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %840, <8 x i16> %850) #5
  %853 = bitcast <2 x i64> %804 to <8 x i16>
  %854 = bitcast <2 x i64> %805 to <8 x i16>
  %855 = shufflevector <8 x i16> %853, <8 x i16> %854, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %856 = shufflevector <8 x i16> %853, <8 x i16> %854, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %857 = add nuw nsw i64 %701, 6
  %858 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %857, i64 0
  %859 = bitcast i16* %858 to <8 x i16>*
  %860 = load <8 x i16>, <8 x i16>* %859, align 16
  %861 = add nuw nsw i64 %701, 7
  %862 = getelementptr inbounds %union.anon.21, %union.anon.21* %18, i64 0, i32 0, i64 %861, i64 0
  %863 = bitcast i16* %862 to <8 x i16>*
  %864 = load <8 x i16>, <8 x i16>* %863, align 16
  %865 = shufflevector <8 x i16> %860, <8 x i16> %864, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %866 = shufflevector <8 x i16> %860, <8 x i16> %864, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %867 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %855, <8 x i16> %865) #5
  %868 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %856, <8 x i16> %866) #5
  %869 = add <4 x i32> %819, <i32 262208, i32 262208, i32 262208, i32 262208>
  %870 = add <4 x i32> %869, %835
  %871 = add <4 x i32> %870, %851
  %872 = add <4 x i32> %871, %867
  %873 = ashr <4 x i32> %872, <i32 7, i32 7, i32 7, i32 7>
  %874 = add <4 x i32> %820, <i32 262208, i32 262208, i32 262208, i32 262208>
  %875 = add <4 x i32> %874, %836
  %876 = add <4 x i32> %875, %852
  %877 = add <4 x i32> %876, %868
  %878 = ashr <4 x i32> %877, <i32 7, i32 7, i32 7, i32 7>
  %879 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %873, <4 x i32> %878) #5
  %880 = bitcast i16* %702 to <8 x i16>*
  store <8 x i16> %879, <8 x i16>* %880, align 1
  %881 = getelementptr inbounds i16, i16* %702, i64 %16
  %882 = add nsw i32 %703, %42
  %883 = icmp eq i64 %813, 8
  br i1 %883, label %884, label %700

884:                                              ; preds = %700, %205, %92
  call void @llvm.lifetime.end.p0i8(i64 240, i8* nonnull %29) #5
  %885 = add nsw i32 %62, %55
  %886 = getelementptr inbounds i16, i16* %63, i64 8
  %887 = icmp slt i32 %885, %24
  br i1 %887, label %61, label %888

888:                                              ; preds = %884
  %889 = getelementptr inbounds i16, i16* %59, i64 %27
  %890 = add nsw i32 %60, %56
  %891 = icmp slt i32 %890, %26
  br i1 %891, label %58, label %892

892:                                              ; preds = %888
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32>, <4 x i32>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #4

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
