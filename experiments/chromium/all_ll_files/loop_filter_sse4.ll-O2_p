; ModuleID = '../../third_party/libgav1/src/src/dsp/x86/loop_filter_sse4.cc'
source_filename = "../../third_party/libgav1/src/src/dsp/x86/loop_filter_sse4.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.libgav1::dsp::Dsp" = type { void (i8*, i8*, i32, i32, i8*, i64)*, void (i8*, i64, i8*, i32*)*, [2 x [3 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*]], [19 x void (i8*, i64, [32 x i16]*, i32)*], [19 x [3 x void ([32 x i16]*, i32, i32, i8*, i64)*]], [2 x [2 x [2 x [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i8*, i64)*]]]], [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i64)*], void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)*, void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i8*, i8, i8, i32, i32, i8*, i64)*, %"struct.libgav1::dsp::FilmGrainFuncs", void (i8*, i64, i8*, i8*, i8, i32, i32)*, [3 x void (i8*, i8*, i64, i8*, i64, i32, i32)*], void (i8*, i32, i32)*, void (i8*, i32)*, [19 x [10 x void (i8*, i64, i8*, i8*)*]], [4 x [5 x [2 x void (i8, i8, i32, i8*, i32, i32, i8*)*]]], [4 x [2 x void (i8*, i64, i32, i32, i32)*]], [2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*], [3 x [2 x void (i8*, i8*, i64, i8*, i64, i32, i32, i8*, i64)*]], void (%"struct.libgav1::ReferenceInfo"*, i32, i32, i32, i32, i32, i32, %"struct.libgav1::TemporalMotionField"*)*, [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32*, i32, %"union.libgav1::CompoundMotionVector"*)*], [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32, i32, %"struct.libgav1::MotionVector"*)*], [2 x void (i8*, i64, i32, i32, i8*, i64)*], void (i32, i32, i32, i8*)*, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, [6 x [6 x [2 x void (i8*, i8*, i8*, i64)*]]] }
%"struct.libgav1::dsp::FilmGrainFuncs" = type { [3 x void (%"struct.libgav1::FilmGrainParams"*, i8*)*], [2 x [4 x void (%"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i8*, i8*)*]], [2 x void (i8*, i32, i32, i32, i32, i32, i8*)*], void (i8*, i32, i32, i32, i32, i8*)*, void (i32, i8*, i8*, i8*)*, void (i8*, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64)*, [2 x void (i8, %"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64, i8*, i64)*] }
%"struct.libgav1::FilmGrainParams" = type { i8, i8, i8, i8, i8, i8, i8, i8, [14 x i8], [14 x i8], [10 x i8], [10 x i8], [10 x i8], [10 x i8], i8, i8, [24 x i8], [25 x i8], [25 x i8], i8, i16, i32, i32, i8, i8, i16, i8, i8, i16 }
%"struct.libgav1::RestorationUnitInfo" = type { i8, %"struct.libgav1::SgrProjInfo", [16 x i8], %"struct.libgav1::WienerInfo" }
%"struct.libgav1::SgrProjInfo" = type { i32, [2 x i32] }
%"struct.libgav1::WienerInfo" = type { [2 x i16], [28 x i8], [2 x [4 x i16]], [16 x i8] }
%"union.libgav1::RestorationBuffer" = type { %"struct.libgav1::SgrBuffer", [5024 x i8] }
%"struct.libgav1::SgrBuffer" = type { [1152 x i16], [1440 x i16], [1152 x i32], [1440 x i32], [1024 x i16], [768 x i16], [512 x i16], [1024 x i32], [768 x i32], [512 x i32], [288 x i8], [288 x i32] }
%"struct.libgav1::ReferenceInfo" = type { %"struct.std::__1::array", %"struct.std::__1::array.0", %"struct.std::__1::array.0", %"struct.std::__1::array.1", %"struct.std::__1::array.2", %"class.libgav1::Array2D", %"class.libgav1::Array2D.4" }
%"struct.std::__1::array" = type { [8 x i8] }
%"struct.std::__1::array.0" = type { [8 x i8] }
%"struct.std::__1::array.1" = type { [8 x i8] }
%"struct.std::__1::array.2" = type { [8 x i16] }
%"class.libgav1::Array2D" = type { %"class.std::__1::unique_ptr", i64, i64, %"class.libgav1::Array2DView" }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i8* }
%"class.libgav1::Array2DView" = type { i32, i32, i8* }
%"class.libgav1::Array2D.4" = type { %"class.std::__1::unique_ptr.5", i64, i64, %"class.libgav1::Array2DView.11" }
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.libgav1::MotionVector"* }
%"struct.libgav1::MotionVector" = type { %union.anon }
%union.anon = type { i32 }
%"class.libgav1::Array2DView.11" = type { i32, i32, %"struct.libgav1::MotionVector"* }
%"struct.libgav1::TemporalMotionField" = type { %"class.libgav1::Array2D.4", %"class.libgav1::Array2D.12" }
%"class.libgav1::Array2D.12" = type { %"class.std::__1::unique_ptr.13", i64, i64, %"class.libgav1::Array2DView.19" }
%"class.std::__1::unique_ptr.13" = type { %"class.std::__1::__compressed_pair.14" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.15" }
%"struct.std::__1::__compressed_pair_elem.15" = type { i8* }
%"class.libgav1::Array2DView.19" = type { i32, i32, i8* }
%"union.libgav1::CompoundMotionVector" = type { i64 }

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN7libgav13dsp21LoopFilterInit_SSE4_1Ev() local_unnamed_addr #0 {
  %1 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 8) #5
  %2 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 18, i64 0, i64 0
  %3 = bitcast void (i8*, i64, i32, i32, i32)** %2 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19Vertical4EPvliii, void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Horizontal4EPvliii>, <2 x void (i8*, i64, i32, i32, i32)*>* %3, align 8
  %4 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 18, i64 1, i64 0
  %5 = bitcast void (i8*, i64, i32, i32, i32)** %4 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19Vertical6EPvliii, void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Horizontal6EPvliii>, <2 x void (i8*, i64, i32, i32, i32)*>* %5, align 8
  %6 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 18, i64 2, i64 0
  %7 = bitcast void (i8*, i64, i32, i32, i32)** %6 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19Vertical8EPvliii, void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Horizontal8EPvliii>, <2 x void (i8*, i64, i32, i32, i32)*>* %7, align 8
  %8 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 18, i64 3, i64 0
  %9 = bitcast void (i8*, i64, i32, i32, i32)** %8 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_110Vertical14EPvliii, void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_112Horizontal14EPvliii>, <2 x void (i8*, i64, i32, i32, i32)*>* %9, align 8
  %10 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 10) #5
  %11 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %10, i64 0, i32 18, i64 0, i64 0
  %12 = bitcast void (i8*, i64, i32, i32, i32)** %11 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE9Vertical4EPvliii, void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE11Horizontal4EPvliii>, <2 x void (i8*, i64, i32, i32, i32)*>* %12, align 8
  %13 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %10, i64 0, i32 18, i64 1, i64 0
  %14 = bitcast void (i8*, i64, i32, i32, i32)** %13 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE9Vertical6EPvliii, void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE11Horizontal6EPvliii>, <2 x void (i8*, i64, i32, i32, i32)*>* %14, align 8
  %15 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %10, i64 0, i32 18, i64 2, i64 0
  %16 = bitcast void (i8*, i64, i32, i32, i32)** %15 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE9Vertical8EPvliii, void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE11Horizontal8EPvliii>, <2 x void (i8*, i64, i32, i32, i32)*>* %16, align 8
  %17 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %10, i64 0, i32 18, i64 3, i64 0
  %18 = bitcast void (i8*, i64, i32, i32, i32)** %17 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE10Vertical14EPvliii, void (i8*, i64, i32, i32, i32)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE12Horizontal14EPvliii>, <2 x void (i8*, i64, i32, i32, i32)*>* %18, align 8
  ret void
}

declare %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Horizontal4EPvliii(i8* nocapture, i64, i32, i32, i32) #2 {
  %6 = insertelement <4 x i32> undef, i32 %2, i32 0
  %7 = bitcast <4 x i32> %6 to <16 x i8>
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> zeroinitializer
  %9 = insertelement <4 x i32> undef, i32 %3, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %4, i32 0
  %13 = bitcast <4 x i32> %12 to <8 x i16>
  %14 = shufflevector <8 x i16> %13, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %15 = shl nsw i64 %1, 1
  %16 = sub i64 0, %15
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 1
  %20 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %19, i32 0
  %21 = sub i64 0, %1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = bitcast i8* %22 to i32*
  %24 = load i32, i32* %23, align 1
  %25 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %24, i32 0
  %26 = bitcast i8* %0 to i32*
  %27 = load i32, i32* %26, align 1
  %28 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %27, i32 0
  %29 = getelementptr inbounds i8, i8* %0, i64 %1
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 1
  %32 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %31, i32 0
  %33 = shufflevector <4 x i32> %20, <4 x i32> %32, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %34 = bitcast <4 x i32> %33 to <2 x i64>
  %35 = shufflevector <4 x i32> %25, <4 x i32> %28, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %36 = bitcast <4 x i32> %35 to <2 x i64>
  %37 = shufflevector <4 x i32> %28, <4 x i32> %32, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %38 = shufflevector <4 x i32> %25, <4 x i32> %20, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %39 = bitcast <4 x i32> %33 to <16 x i8>
  %40 = bitcast <4 x i32> %35 to <16 x i8>
  %41 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %39, <16 x i8> %40) #5
  %42 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %40, <16 x i8> %39) #5
  %43 = or <16 x i8> %42, %41
  %44 = shufflevector <16 x i8> %43, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %45 = icmp ugt <16 x i8> %43, %44
  %46 = select <16 x i1> %45, <16 x i8> %43, <16 x i8> %44
  %47 = shufflevector <16 x i8> %46, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %48 = zext <8 x i8> %47 to <8 x i16>
  %49 = icmp slt <8 x i16> %14, %48
  %50 = sext <8 x i1> %49 to <8 x i16>
  %51 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %50, <8 x i16> undef) #5
  %52 = bitcast <4 x i32> %38 to <16 x i8>
  %53 = bitcast <4 x i32> %37 to <16 x i8>
  %54 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %52, <16 x i8> %53) #5
  %55 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %53, <16 x i8> %52) #5
  %56 = or <16 x i8> %55, %54
  %57 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %56, <16 x i8> %56) #5
  %58 = bitcast <16 x i8> %56 to <8 x i16>
  %59 = lshr <8 x i16> %58, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %60 = bitcast <8 x i16> %59 to <16 x i8>
  %61 = and <16 x i8> %60, <i8 undef, i8 undef, i8 undef, i8 undef, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %62 = shufflevector <16 x i8> %61, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %63 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %57, <16 x i8> %62) #5
  %64 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %8) #5
  %65 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %46, <16 x i8> %11) #5
  %66 = or <16 x i8> %64, %65
  %67 = icmp eq <16 x i8> %66, zeroinitializer
  %68 = shufflevector <2 x i64> %36, <2 x i64> %34, <2 x i32> <i32 0, i32 2>
  %69 = xor <2 x i64> %68, <i64 -9187201950435737472, i64 -9187201950435737472>
  %70 = bitcast <2 x i64> %69 to <4 x i32>
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 0, i32 0>
  %72 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %73 = bitcast <16 x i8> %51 to <4 x i32>
  %74 = shufflevector <4 x i32> %73, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %75 = bitcast <4 x i32> %74 to <2 x i64>
  %76 = bitcast <4 x i32> %71 to <16 x i8>
  %77 = bitcast <4 x i32> %72 to <16 x i8>
  %78 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %76, <16 x i8> %77) #5
  %79 = shufflevector <16 x i8> %78, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %80 = bitcast <4 x i32> %74 to <16 x i8>
  %81 = and <16 x i8> %79, %80
  %82 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %81, <16 x i8> %78) #5
  %83 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %82, <16 x i8> %78) #5
  %84 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %83, <16 x i8> %78) #5
  %85 = select <16 x i1> %67, <16 x i8> %84, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %86 = bitcast <16 x i8> %85 to <4 x i32>
  %87 = shufflevector <4 x i32> %86, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %88 = bitcast <4 x i32> %87 to <16 x i8>
  %89 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %88, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 4, i8 4, i8 4, i8 4, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>) #5
  %90 = shufflevector <16 x i8> %89, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %91 = bitcast <16 x i8> %90 to <8 x i16>
  %92 = ashr <8 x i16> %91, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %92, <8 x i16> %92) #5
  %94 = bitcast <16 x i8> %93 to <2 x i64>
  %95 = bitcast <16 x i8> %93 to <4 x i32>
  %96 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %97 = bitcast <4 x i32> %96 to <16 x i8>
  %98 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %97, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %99 = shufflevector <16 x i8> %98, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %100 = bitcast <16 x i8> %99 to <8 x i16>
  %101 = ashr <8 x i16> %100, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %101, <8 x i16> undef) #5
  %103 = bitcast <16 x i8> %102 to <2 x i64>
  %104 = xor <2 x i64> %75, <i64 -1, i64 undef>
  %105 = and <2 x i64> %103, %104
  %106 = shufflevector <2 x i64> %94, <2 x i64> %105, <2 x i32> <i32 0, i32 2>
  %107 = bitcast <2 x i64> %106 to <16 x i8>
  %108 = tail call <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8> %107, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1, i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1>) #5
  %109 = bitcast <2 x i64> %69 to <16 x i8>
  %110 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %109, <16 x i8> %108) #5
  %111 = bitcast <16 x i8> %110 to <2 x i64>
  %112 = xor <2 x i64> %111, <i64 -9187201950435737472, i64 -9187201950435737472>
  %113 = bitcast <2 x i64> %112 to <16 x i8>
  %114 = shufflevector <16 x i8> %113, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %115 = bitcast <16 x i8> %114 to <4 x i32>
  %116 = extractelement <4 x i32> %115, i32 0
  store i32 %116, i32* %18, align 1
  %117 = bitcast <2 x i64> %112 to <4 x i32>
  %118 = extractelement <4 x i32> %117, i32 0
  store i32 %118, i32* %23, align 1
  %119 = shufflevector <16 x i8> %113, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %120 = bitcast <16 x i8> %119 to <4 x i32>
  %121 = extractelement <4 x i32> %120, i32 0
  store i32 %121, i32* %26, align 1
  %122 = shufflevector <16 x i8> %114, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %123 = bitcast <16 x i8> %122 to <4 x i32>
  %124 = extractelement <4 x i32> %123, i32 0
  store i32 %124, i32* %30, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Horizontal6EPvliii(i8* nocapture, i64, i32, i32, i32) #2 {
  %6 = insertelement <4 x i32> undef, i32 %2, i32 0
  %7 = bitcast <4 x i32> %6 to <16 x i8>
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> zeroinitializer
  %9 = insertelement <4 x i32> undef, i32 %3, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = insertelement <4 x i32> undef, i32 %4, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = mul i64 %1, -3
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 1
  %20 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %19, i32 0
  %21 = shl nsw i64 %1, 1
  %22 = sub i64 0, %21
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 1
  %26 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %25, i32 0
  %27 = sub i64 0, %1
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = bitcast i8* %28 to i32*
  %30 = load i32, i32* %29, align 1
  %31 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %30, i32 0
  %32 = bitcast i8* %0 to i32*
  %33 = load i32, i32* %32, align 1
  %34 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %33, i32 0
  %35 = getelementptr inbounds i8, i8* %0, i64 %1
  %36 = bitcast i8* %35 to i32*
  %37 = load i32, i32* %36, align 1
  %38 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %37, i32 0
  %39 = getelementptr inbounds i8, i8* %0, i64 %21
  %40 = bitcast i8* %39 to i32*
  %41 = load i32, i32* %40, align 1
  %42 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %41, i32 0
  %43 = shufflevector <4 x i32> %20, <4 x i32> %42, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %44 = shufflevector <4 x i32> %26, <4 x i32> %38, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %45 = bitcast <4 x i32> %44 to <2 x i64>
  %46 = shufflevector <4 x i32> %31, <4 x i32> %34, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %47 = bitcast <4 x i32> %46 to <2 x i64>
  %48 = shufflevector <4 x i32> %34, <4 x i32> %38, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %49 = shufflevector <4 x i32> %31, <4 x i32> %26, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %50 = bitcast <4 x i32> %44 to <16 x i8>
  %51 = bitcast <4 x i32> %46 to <16 x i8>
  %52 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %50, <16 x i8> %51) #5
  %53 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %51, <16 x i8> %50) #5
  %54 = or <16 x i8> %53, %52
  %55 = shufflevector <16 x i8> %54, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %56 = icmp ugt <16 x i8> %54, %55
  %57 = select <16 x i1> %56, <16 x i8> %54, <16 x i8> %55
  %58 = shufflevector <16 x i8> %57, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %59 = zext <8 x i8> %58 to <8 x i16>
  %60 = bitcast <16 x i8> %15 to <8 x i16>
  %61 = icmp slt <8 x i16> %60, %59
  %62 = sext <8 x i1> %61 to <8 x i16>
  %63 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %62, <8 x i16> undef) #5
  %64 = bitcast <4 x i32> %49 to <16 x i8>
  %65 = bitcast <4 x i32> %48 to <16 x i8>
  %66 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %64, <16 x i8> %65) #5
  %67 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %65, <16 x i8> %64) #5
  %68 = or <16 x i8> %67, %66
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> %68) #5
  %70 = bitcast <16 x i8> %68 to <8 x i16>
  %71 = lshr <8 x i16> %70, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %72 = bitcast <8 x i16> %71 to <16 x i8>
  %73 = and <16 x i8> %72, <i8 undef, i8 undef, i8 undef, i8 undef, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %74 = shufflevector <16 x i8> %73, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %75 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> %74) #5
  %76 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %75, <16 x i8> %8) #5
  %77 = bitcast <4 x i32> %43 to <16 x i8>
  %78 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %77, <16 x i8> %50) #5
  %79 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %50, <16 x i8> %77) #5
  %80 = or <16 x i8> %79, %78
  %81 = icmp ugt <16 x i8> %80, %54
  %82 = select <16 x i1> %81, <16 x i8> %80, <16 x i8> %54
  %83 = shufflevector <16 x i8> %82, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %84 = icmp ugt <16 x i8> %82, %83
  %85 = select <16 x i1> %84, <16 x i8> %82, <16 x i8> %83
  %86 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %85, <16 x i8> %11) #5
  %87 = or <16 x i8> %86, %76
  %88 = icmp eq <16 x i8> %87, zeroinitializer
  %89 = shufflevector <2 x i64> %47, <2 x i64> %45, <2 x i32> <i32 0, i32 2>
  %90 = xor <2 x i64> %89, <i64 -9187201950435737472, i64 -9187201950435737472>
  %91 = bitcast <2 x i64> %90 to <4 x i32>
  %92 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 0, i32 0>
  %93 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %94 = bitcast <16 x i8> %63 to <4 x i32>
  %95 = shufflevector <4 x i32> %94, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %96 = bitcast <4 x i32> %95 to <2 x i64>
  %97 = bitcast <4 x i32> %92 to <16 x i8>
  %98 = bitcast <4 x i32> %93 to <16 x i8>
  %99 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %97, <16 x i8> %98) #5
  %100 = shufflevector <16 x i8> %99, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %101 = bitcast <4 x i32> %95 to <16 x i8>
  %102 = and <16 x i8> %100, %101
  %103 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %102, <16 x i8> %99) #5
  %104 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %103, <16 x i8> %99) #5
  %105 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %104, <16 x i8> %99) #5
  %106 = select <16 x i1> %88, <16 x i8> %105, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %107 = bitcast <16 x i8> %106 to <4 x i32>
  %108 = shufflevector <4 x i32> %107, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %109 = bitcast <4 x i32> %108 to <16 x i8>
  %110 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %109, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 4, i8 4, i8 4, i8 4, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>) #5
  %111 = shufflevector <16 x i8> %110, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %112 = bitcast <16 x i8> %111 to <8 x i16>
  %113 = ashr <8 x i16> %112, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %114 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %113, <8 x i16> %113) #5
  %115 = bitcast <16 x i8> %114 to <2 x i64>
  %116 = bitcast <16 x i8> %114 to <4 x i32>
  %117 = shufflevector <4 x i32> %116, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %118 = bitcast <4 x i32> %117 to <16 x i8>
  %119 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %118, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %120 = shufflevector <16 x i8> %119, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %121 = bitcast <16 x i8> %120 to <8 x i16>
  %122 = ashr <8 x i16> %121, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %123 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %122, <8 x i16> undef) #5
  %124 = bitcast <16 x i8> %123 to <2 x i64>
  %125 = xor <2 x i64> %96, <i64 -1, i64 undef>
  %126 = and <2 x i64> %124, %125
  %127 = shufflevector <2 x i64> %115, <2 x i64> %126, <2 x i32> <i32 0, i32 2>
  %128 = bitcast <2 x i64> %127 to <16 x i8>
  %129 = tail call <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8> %128, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1, i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1>) #5
  %130 = bitcast <2 x i64> %90 to <16 x i8>
  %131 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %130, <16 x i8> %129) #5
  %132 = bitcast <16 x i8> %131 to <2 x i64>
  %133 = xor <2 x i64> %132, <i64 -9187201950435737472, i64 -9187201950435737472>
  %134 = bitcast <2 x i64> %133 to <16 x i8>
  %135 = shufflevector <16 x i8> %134, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %136 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %77, <16 x i8> %51) #5
  %137 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %51, <16 x i8> %77) #5
  %138 = or <16 x i8> %137, %136
  %139 = icmp ugt <16 x i8> %138, %54
  %140 = select <16 x i1> %139, <16 x i8> %138, <16 x i8> %54
  %141 = shufflevector <16 x i8> %140, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %142 = icmp ugt <16 x i8> %140, %141
  %143 = select <16 x i1> %142, <16 x i8> %140, <16 x i8> %141
  %144 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %143, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %145 = icmp eq <16 x i8> %144, zeroinitializer
  %146 = and <16 x i1> %88, %145
  %147 = sext <16 x i1> %146 to <16 x i8>
  %148 = bitcast <16 x i8> %147 to <4 x i32>
  %149 = shufflevector <4 x i32> %148, <4 x i32> undef, <4 x i32> zeroinitializer
  %150 = bitcast <4 x i32> %149 to <2 x i64>
  %151 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %150, <2 x i64> %150) #5
  %152 = icmp eq i32 %151, 0
  br i1 %152, label %153, label %185

153:                                              ; preds = %5
  %154 = shufflevector <16 x i8> %77, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %155 = zext <8 x i8> %154 to <8 x i16>
  %156 = shufflevector <16 x i8> %50, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %157 = zext <8 x i8> %156 to <8 x i16>
  %158 = shufflevector <16 x i8> %51, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %159 = zext <8 x i8> %158 to <8 x i16>
  %160 = bitcast <8 x i16> %157 to <4 x i32>
  %161 = shufflevector <4 x i32> %160, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %162 = bitcast <8 x i16> %159 to <4 x i32>
  %163 = shufflevector <4 x i32> %162, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %164 = shl nuw nsw <8 x i16> %155, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %165 = bitcast <4 x i32> %163 to <8 x i16>
  %166 = add nuw nsw <8 x i16> %157, %159
  %167 = shl nuw nsw <8 x i16> %166, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %168 = add nuw nsw <8 x i16> %155, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %169 = add nuw nsw <8 x i16> %168, %164
  %170 = add <8 x i16> %169, %165
  %171 = add <8 x i16> %170, %167
  %172 = lshr <8 x i16> %171, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %173 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %172, <8 x i16> %172) #5
  %174 = bitcast <4 x i32> %161 to <8 x i16>
  %175 = mul nsw <8 x i16> %155, <i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2>
  %176 = add <8 x i16> %175, %165
  %177 = add <8 x i16> %176, %174
  %178 = add <8 x i16> %177, %171
  %179 = lshr <8 x i16> %178, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %180 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %179, <8 x i16> %179) #5
  %181 = bitcast <4 x i32> %149 to <16 x i8>
  %182 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %135, <16 x i8> %173, <16 x i8> %181) #5
  %183 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %134, <16 x i8> %180, <16 x i8> %181) #5
  %184 = bitcast <16 x i8> %183 to <2 x i64>
  br label %185

185:                                              ; preds = %153, %5
  %186 = phi <16 x i8> [ %183, %153 ], [ %134, %5 ]
  %187 = phi <16 x i8> [ %182, %153 ], [ %135, %5 ]
  %188 = phi <2 x i64> [ %184, %153 ], [ %133, %5 ]
  %189 = bitcast <16 x i8> %187 to <4 x i32>
  %190 = extractelement <4 x i32> %189, i32 0
  store i32 %190, i32* %24, align 1
  %191 = bitcast <2 x i64> %188 to <4 x i32>
  %192 = extractelement <4 x i32> %191, i32 0
  store i32 %192, i32* %29, align 1
  %193 = shufflevector <16 x i8> %186, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %194 = bitcast <16 x i8> %193 to <4 x i32>
  %195 = extractelement <4 x i32> %194, i32 0
  store i32 %195, i32* %32, align 1
  %196 = shufflevector <16 x i8> %187, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %197 = bitcast <16 x i8> %196 to <4 x i32>
  %198 = extractelement <4 x i32> %197, i32 0
  store i32 %198, i32* %36, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_111Horizontal8EPvliii(i8* nocapture, i64, i32, i32, i32) #2 {
  %6 = insertelement <4 x i32> undef, i32 %2, i32 0
  %7 = bitcast <4 x i32> %6 to <16 x i8>
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> zeroinitializer
  %9 = insertelement <4 x i32> undef, i32 %3, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = insertelement <4 x i32> undef, i32 %4, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = shl nsw i64 %1, 2
  %17 = sub i64 0, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = bitcast i8* %18 to i32*
  %20 = load i32, i32* %19, align 1
  %21 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %20, i32 0
  %22 = mul nsw i64 %1, 3
  %23 = sub i64 0, %22
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = bitcast i8* %24 to i32*
  %26 = load i32, i32* %25, align 1
  %27 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %26, i32 0
  %28 = shl nsw i64 %1, 1
  %29 = sub i64 0, %28
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = bitcast i8* %30 to i32*
  %32 = load i32, i32* %31, align 1
  %33 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %32, i32 0
  %34 = sub i64 0, %1
  %35 = getelementptr inbounds i8, i8* %0, i64 %34
  %36 = bitcast i8* %35 to i32*
  %37 = load i32, i32* %36, align 1
  %38 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %37, i32 0
  %39 = bitcast i8* %0 to i32*
  %40 = load i32, i32* %39, align 1
  %41 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %40, i32 0
  %42 = getelementptr inbounds i8, i8* %0, i64 %1
  %43 = bitcast i8* %42 to i32*
  %44 = load i32, i32* %43, align 1
  %45 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %44, i32 0
  %46 = getelementptr inbounds i8, i8* %0, i64 %28
  %47 = bitcast i8* %46 to i32*
  %48 = load i32, i32* %47, align 1
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %0, i64 %22
  %51 = bitcast i8* %50 to i32*
  %52 = load i32, i32* %51, align 1
  %53 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %52, i32 0
  %54 = shufflevector <4 x i32> %21, <4 x i32> %53, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %55 = shufflevector <4 x i32> %27, <4 x i32> %49, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %56 = shufflevector <4 x i32> %33, <4 x i32> %45, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <4 x i32> %38, <4 x i32> %41, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <4 x i32> %41, <4 x i32> %45, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %61 = shufflevector <4 x i32> %38, <4 x i32> %33, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %62 = bitcast <4 x i32> %56 to <16 x i8>
  %63 = bitcast <4 x i32> %58 to <16 x i8>
  %64 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %62, <16 x i8> %63) #5
  %65 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %62) #5
  %66 = or <16 x i8> %65, %64
  %67 = shufflevector <16 x i8> %66, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %68 = icmp ugt <16 x i8> %66, %67
  %69 = select <16 x i1> %68, <16 x i8> %66, <16 x i8> %67
  %70 = shufflevector <16 x i8> %69, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %71 = zext <8 x i8> %70 to <8 x i16>
  %72 = bitcast <16 x i8> %15 to <8 x i16>
  %73 = icmp slt <8 x i16> %72, %71
  %74 = sext <8 x i1> %73 to <8 x i16>
  %75 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %74, <8 x i16> undef) #5
  %76 = bitcast <4 x i32> %61 to <16 x i8>
  %77 = bitcast <4 x i32> %60 to <16 x i8>
  %78 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %76, <16 x i8> %77) #5
  %79 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %77, <16 x i8> %76) #5
  %80 = or <16 x i8> %79, %78
  %81 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %80, <16 x i8> %80) #5
  %82 = bitcast <16 x i8> %80 to <8 x i16>
  %83 = lshr <8 x i16> %82, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %84 = bitcast <8 x i16> %83 to <16 x i8>
  %85 = and <16 x i8> %84, <i8 undef, i8 undef, i8 undef, i8 undef, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %86 = shufflevector <16 x i8> %85, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %87 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %81, <16 x i8> %86) #5
  %88 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %87, <16 x i8> %8) #5
  %89 = bitcast <4 x i32> %55 to <16 x i8>
  %90 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %89, <16 x i8> %62) #5
  %91 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %62, <16 x i8> %89) #5
  %92 = or <16 x i8> %91, %90
  %93 = icmp ugt <16 x i8> %92, %66
  %94 = select <16 x i1> %93, <16 x i8> %92, <16 x i8> %66
  %95 = bitcast <4 x i32> %54 to <16 x i8>
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %89) #5
  %97 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %89, <16 x i8> %95) #5
  %98 = or <16 x i8> %97, %96
  %99 = icmp ugt <16 x i8> %94, %98
  %100 = select <16 x i1> %99, <16 x i8> %94, <16 x i8> %98
  %101 = shufflevector <16 x i8> %100, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %102 = icmp ugt <16 x i8> %100, %101
  %103 = select <16 x i1> %102, <16 x i8> %100, <16 x i8> %101
  %104 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %103, <16 x i8> %11) #5
  %105 = or <16 x i8> %104, %88
  %106 = icmp eq <16 x i8> %105, zeroinitializer
  %107 = shufflevector <2 x i64> %59, <2 x i64> %57, <2 x i32> <i32 0, i32 2>
  %108 = xor <2 x i64> %107, <i64 -9187201950435737472, i64 -9187201950435737472>
  %109 = bitcast <2 x i64> %108 to <4 x i32>
  %110 = shufflevector <4 x i32> %109, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 0, i32 0>
  %111 = shufflevector <4 x i32> %109, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %112 = bitcast <16 x i8> %75 to <4 x i32>
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = bitcast <4 x i32> %110 to <16 x i8>
  %116 = bitcast <4 x i32> %111 to <16 x i8>
  %117 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %115, <16 x i8> %116) #5
  %118 = shufflevector <16 x i8> %117, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %119 = bitcast <4 x i32> %113 to <16 x i8>
  %120 = and <16 x i8> %118, %119
  %121 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %120, <16 x i8> %117) #5
  %122 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %121, <16 x i8> %117) #5
  %123 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %122, <16 x i8> %117) #5
  %124 = select <16 x i1> %106, <16 x i8> %123, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %125 = bitcast <16 x i8> %124 to <4 x i32>
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %127 = bitcast <4 x i32> %126 to <16 x i8>
  %128 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %127, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 4, i8 4, i8 4, i8 4, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>) #5
  %129 = shufflevector <16 x i8> %128, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %130 = bitcast <16 x i8> %129 to <8 x i16>
  %131 = ashr <8 x i16> %130, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %131, <8 x i16> %131) #5
  %133 = bitcast <16 x i8> %132 to <2 x i64>
  %134 = bitcast <16 x i8> %132 to <4 x i32>
  %135 = shufflevector <4 x i32> %134, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %136 = bitcast <4 x i32> %135 to <16 x i8>
  %137 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %136, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %138 = shufflevector <16 x i8> %137, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %139 = bitcast <16 x i8> %138 to <8 x i16>
  %140 = ashr <8 x i16> %139, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %141 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %140, <8 x i16> undef) #5
  %142 = bitcast <16 x i8> %141 to <2 x i64>
  %143 = xor <2 x i64> %114, <i64 -1, i64 undef>
  %144 = and <2 x i64> %142, %143
  %145 = shufflevector <2 x i64> %133, <2 x i64> %144, <2 x i32> <i32 0, i32 2>
  %146 = bitcast <2 x i64> %145 to <16 x i8>
  %147 = tail call <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8> %146, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1, i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1>) #5
  %148 = bitcast <2 x i64> %108 to <16 x i8>
  %149 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %148, <16 x i8> %147) #5
  %150 = bitcast <16 x i8> %149 to <2 x i64>
  %151 = xor <2 x i64> %150, <i64 -9187201950435737472, i64 -9187201950435737472>
  %152 = bitcast <2 x i64> %151 to <16 x i8>
  %153 = shufflevector <16 x i8> %152, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %154 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %89, <16 x i8> %63) #5
  %155 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %89) #5
  %156 = or <16 x i8> %155, %154
  %157 = icmp ugt <16 x i8> %156, %66
  %158 = select <16 x i1> %157, <16 x i8> %156, <16 x i8> %66
  %159 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %63) #5
  %160 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %95) #5
  %161 = or <16 x i8> %160, %159
  %162 = icmp ugt <16 x i8> %158, %161
  %163 = select <16 x i1> %162, <16 x i8> %158, <16 x i8> %161
  %164 = shufflevector <16 x i8> %163, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %165 = icmp ugt <16 x i8> %163, %164
  %166 = select <16 x i1> %165, <16 x i8> %163, <16 x i8> %164
  %167 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %166, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %168 = icmp eq <16 x i8> %167, zeroinitializer
  %169 = and <16 x i1> %106, %168
  %170 = sext <16 x i1> %169 to <16 x i8>
  %171 = bitcast <16 x i8> %170 to <4 x i32>
  %172 = shufflevector <4 x i32> %171, <4 x i32> undef, <4 x i32> zeroinitializer
  %173 = bitcast <4 x i32> %172 to <2 x i64>
  %174 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %173, <2 x i64> %173) #5
  %175 = icmp eq i32 %174, 0
  br i1 %175, label %176, label %226

176:                                              ; preds = %5
  %177 = shufflevector <16 x i8> %95, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %178 = zext <8 x i8> %177 to <8 x i16>
  %179 = shufflevector <16 x i8> %89, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %180 = zext <8 x i8> %179 to <8 x i16>
  %181 = shufflevector <16 x i8> %62, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %182 = zext <8 x i8> %181 to <8 x i16>
  %183 = shufflevector <16 x i8> %63, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %184 = zext <8 x i8> %183 to <8 x i16>
  %185 = bitcast <8 x i16> %180 to <4 x i32>
  %186 = shufflevector <4 x i32> %185, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %187 = bitcast <8 x i16> %182 to <4 x i32>
  %188 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %189 = bitcast <8 x i16> %184 to <4 x i32>
  %190 = shufflevector <4 x i32> %189, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %191 = shl nuw nsw <8 x i16> %178, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %192 = bitcast <4 x i32> %190 to <8 x i16>
  %193 = shl nuw nsw <8 x i16> %180, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %194 = add nuw nsw <8 x i16> %178, %182
  %195 = add nuw nsw <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = add nuw nsw <8 x i16> %195, %184
  %197 = add nuw nsw <8 x i16> %196, %193
  %198 = add <8 x i16> %197, %192
  %199 = add <8 x i16> %198, %191
  %200 = lshr <8 x i16> %199, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %200, <8 x i16> %200) #5
  %202 = bitcast <4 x i32> %188 to <8 x i16>
  %203 = sub nsw <8 x i16> %182, %180
  %204 = sub nsw <8 x i16> %203, %178
  %205 = add <8 x i16> %204, %202
  %206 = add <8 x i16> %205, %199
  %207 = lshr <8 x i16> %206, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %208 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %207, <8 x i16> %207) #5
  %209 = bitcast <4 x i32> %186 to <8 x i16>
  %210 = sub nsw <8 x i16> %184, %182
  %211 = sub nsw <8 x i16> %210, %178
  %212 = add <8 x i16> %211, %209
  %213 = add <8 x i16> %212, %206
  %214 = lshr <8 x i16> %213, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %215 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %214, <8 x i16> %214) #5
  %216 = bitcast <4 x i32> %172 to <16 x i8>
  %217 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %89, <16 x i8> %201, <16 x i8> %216) #5
  %218 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %153, <16 x i8> %208, <16 x i8> %216) #5
  %219 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %152, <16 x i8> %215, <16 x i8> %216) #5
  %220 = bitcast <16 x i8> %219 to <2 x i64>
  %221 = bitcast <16 x i8> %217 to <4 x i32>
  %222 = extractelement <4 x i32> %221, i32 0
  store i32 %222, i32* %25, align 1
  %223 = shufflevector <16 x i8> %217, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %224 = bitcast <16 x i8> %223 to <4 x i32>
  %225 = extractelement <4 x i32> %224, i32 0
  store i32 %225, i32* %47, align 1
  br label %226

226:                                              ; preds = %176, %5
  %227 = phi <16 x i8> [ %219, %176 ], [ %152, %5 ]
  %228 = phi <16 x i8> [ %218, %176 ], [ %153, %5 ]
  %229 = phi <2 x i64> [ %220, %176 ], [ %151, %5 ]
  %230 = bitcast <16 x i8> %228 to <4 x i32>
  %231 = extractelement <4 x i32> %230, i32 0
  store i32 %231, i32* %31, align 1
  %232 = bitcast <2 x i64> %229 to <4 x i32>
  %233 = extractelement <4 x i32> %232, i32 0
  store i32 %233, i32* %36, align 1
  %234 = shufflevector <16 x i8> %227, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %235 = bitcast <16 x i8> %234 to <4 x i32>
  %236 = extractelement <4 x i32> %235, i32 0
  store i32 %236, i32* %39, align 1
  %237 = shufflevector <16 x i8> %228, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %238 = bitcast <16 x i8> %237 to <4 x i32>
  %239 = extractelement <4 x i32> %238, i32 0
  store i32 %239, i32* %43, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_112Horizontal14EPvliii(i8* nocapture, i64, i32, i32, i32) #2 {
  %6 = insertelement <4 x i32> undef, i32 %2, i32 0
  %7 = bitcast <4 x i32> %6 to <16 x i8>
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> zeroinitializer
  %9 = insertelement <4 x i32> undef, i32 %3, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = insertelement <4 x i32> undef, i32 %4, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = shl nsw i64 %1, 2
  %17 = sub i64 0, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = bitcast i8* %18 to i32*
  %20 = load i32, i32* %19, align 1
  %21 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %20, i32 0
  %22 = mul nsw i64 %1, 3
  %23 = sub i64 0, %22
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = bitcast i8* %24 to i32*
  %26 = load i32, i32* %25, align 1
  %27 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %26, i32 0
  %28 = shl nsw i64 %1, 1
  %29 = sub i64 0, %28
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = bitcast i8* %30 to i32*
  %32 = load i32, i32* %31, align 1
  %33 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %32, i32 0
  %34 = sub i64 0, %1
  %35 = getelementptr inbounds i8, i8* %0, i64 %34
  %36 = bitcast i8* %35 to i32*
  %37 = load i32, i32* %36, align 1
  %38 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %37, i32 0
  %39 = bitcast i8* %0 to i32*
  %40 = load i32, i32* %39, align 1
  %41 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %40, i32 0
  %42 = getelementptr inbounds i8, i8* %0, i64 %1
  %43 = bitcast i8* %42 to i32*
  %44 = load i32, i32* %43, align 1
  %45 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %44, i32 0
  %46 = getelementptr inbounds i8, i8* %0, i64 %28
  %47 = bitcast i8* %46 to i32*
  %48 = load i32, i32* %47, align 1
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %0, i64 %22
  %51 = bitcast i8* %50 to i32*
  %52 = load i32, i32* %51, align 1
  %53 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %52, i32 0
  %54 = shufflevector <4 x i32> %21, <4 x i32> %53, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %55 = shufflevector <4 x i32> %27, <4 x i32> %49, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %56 = shufflevector <4 x i32> %33, <4 x i32> %45, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <4 x i32> %38, <4 x i32> %41, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <4 x i32> %41, <4 x i32> %45, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %61 = shufflevector <4 x i32> %38, <4 x i32> %33, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %62 = bitcast <4 x i32> %56 to <16 x i8>
  %63 = bitcast <4 x i32> %58 to <16 x i8>
  %64 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %62, <16 x i8> %63) #5
  %65 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %62) #5
  %66 = or <16 x i8> %65, %64
  %67 = shufflevector <16 x i8> %66, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %68 = icmp ugt <16 x i8> %66, %67
  %69 = select <16 x i1> %68, <16 x i8> %66, <16 x i8> %67
  %70 = shufflevector <16 x i8> %69, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %71 = zext <8 x i8> %70 to <8 x i16>
  %72 = bitcast <16 x i8> %15 to <8 x i16>
  %73 = icmp slt <8 x i16> %72, %71
  %74 = sext <8 x i1> %73 to <8 x i16>
  %75 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %74, <8 x i16> undef) #5
  %76 = bitcast <4 x i32> %61 to <16 x i8>
  %77 = bitcast <4 x i32> %60 to <16 x i8>
  %78 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %76, <16 x i8> %77) #5
  %79 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %77, <16 x i8> %76) #5
  %80 = or <16 x i8> %79, %78
  %81 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %80, <16 x i8> %80) #5
  %82 = bitcast <16 x i8> %80 to <8 x i16>
  %83 = lshr <8 x i16> %82, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %84 = bitcast <8 x i16> %83 to <16 x i8>
  %85 = and <16 x i8> %84, <i8 undef, i8 undef, i8 undef, i8 undef, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %86 = shufflevector <16 x i8> %85, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %87 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %81, <16 x i8> %86) #5
  %88 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %87, <16 x i8> %8) #5
  %89 = bitcast <4 x i32> %55 to <16 x i8>
  %90 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %89, <16 x i8> %62) #5
  %91 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %62, <16 x i8> %89) #5
  %92 = or <16 x i8> %91, %90
  %93 = icmp ugt <16 x i8> %92, %66
  %94 = select <16 x i1> %93, <16 x i8> %92, <16 x i8> %66
  %95 = bitcast <4 x i32> %54 to <16 x i8>
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %89) #5
  %97 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %89, <16 x i8> %95) #5
  %98 = or <16 x i8> %97, %96
  %99 = icmp ugt <16 x i8> %94, %98
  %100 = select <16 x i1> %99, <16 x i8> %94, <16 x i8> %98
  %101 = shufflevector <16 x i8> %100, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %102 = icmp ugt <16 x i8> %100, %101
  %103 = select <16 x i1> %102, <16 x i8> %100, <16 x i8> %101
  %104 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %103, <16 x i8> %11) #5
  %105 = or <16 x i8> %104, %88
  %106 = icmp eq <16 x i8> %105, zeroinitializer
  %107 = shufflevector <2 x i64> %59, <2 x i64> %57, <2 x i32> <i32 0, i32 2>
  %108 = xor <2 x i64> %107, <i64 -9187201950435737472, i64 -9187201950435737472>
  %109 = bitcast <2 x i64> %108 to <4 x i32>
  %110 = shufflevector <4 x i32> %109, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 0, i32 0>
  %111 = shufflevector <4 x i32> %109, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %112 = bitcast <16 x i8> %75 to <4 x i32>
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = bitcast <4 x i32> %110 to <16 x i8>
  %116 = bitcast <4 x i32> %111 to <16 x i8>
  %117 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %115, <16 x i8> %116) #5
  %118 = shufflevector <16 x i8> %117, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %119 = bitcast <4 x i32> %113 to <16 x i8>
  %120 = and <16 x i8> %118, %119
  %121 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %120, <16 x i8> %117) #5
  %122 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %121, <16 x i8> %117) #5
  %123 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %122, <16 x i8> %117) #5
  %124 = select <16 x i1> %106, <16 x i8> %123, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %125 = bitcast <16 x i8> %124 to <4 x i32>
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %127 = bitcast <4 x i32> %126 to <16 x i8>
  %128 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %127, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 4, i8 4, i8 4, i8 4, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>) #5
  %129 = shufflevector <16 x i8> %128, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %130 = bitcast <16 x i8> %129 to <8 x i16>
  %131 = ashr <8 x i16> %130, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %131, <8 x i16> %131) #5
  %133 = bitcast <16 x i8> %132 to <2 x i64>
  %134 = bitcast <16 x i8> %132 to <4 x i32>
  %135 = shufflevector <4 x i32> %134, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %136 = bitcast <4 x i32> %135 to <16 x i8>
  %137 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %136, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %138 = shufflevector <16 x i8> %137, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %139 = bitcast <16 x i8> %138 to <8 x i16>
  %140 = ashr <8 x i16> %139, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %141 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %140, <8 x i16> undef) #5
  %142 = bitcast <16 x i8> %141 to <2 x i64>
  %143 = xor <2 x i64> %114, <i64 -1, i64 undef>
  %144 = and <2 x i64> %142, %143
  %145 = shufflevector <2 x i64> %133, <2 x i64> %144, <2 x i32> <i32 0, i32 2>
  %146 = bitcast <2 x i64> %145 to <16 x i8>
  %147 = tail call <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8> %146, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1, i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1>) #5
  %148 = bitcast <2 x i64> %108 to <16 x i8>
  %149 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %148, <16 x i8> %147) #5
  %150 = bitcast <16 x i8> %149 to <2 x i64>
  %151 = xor <2 x i64> %150, <i64 -9187201950435737472, i64 -9187201950435737472>
  %152 = bitcast <2 x i64> %151 to <16 x i8>
  %153 = shufflevector <16 x i8> %152, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %154 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %89, <16 x i8> %63) #5
  %155 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %89) #5
  %156 = or <16 x i8> %155, %154
  %157 = icmp ugt <16 x i8> %156, %66
  %158 = select <16 x i1> %157, <16 x i8> %156, <16 x i8> %66
  %159 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %63) #5
  %160 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %95) #5
  %161 = or <16 x i8> %160, %159
  %162 = icmp ugt <16 x i8> %158, %161
  %163 = select <16 x i1> %162, <16 x i8> %158, <16 x i8> %161
  %164 = shufflevector <16 x i8> %163, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %165 = icmp ugt <16 x i8> %163, %164
  %166 = select <16 x i1> %165, <16 x i8> %163, <16 x i8> %164
  %167 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %166, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %168 = icmp eq <16 x i8> %167, zeroinitializer
  %169 = and <16 x i1> %106, %168
  %170 = sext <16 x i1> %169 to <16 x i8>
  %171 = bitcast <16 x i8> %170 to <4 x i32>
  %172 = shufflevector <4 x i32> %171, <4 x i32> undef, <4 x i32> zeroinitializer
  %173 = bitcast <4 x i32> %172 to <2 x i64>
  %174 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %173, <2 x i64> %173) #5
  %175 = icmp eq i32 %174, 0
  br i1 %175, label %176, label %370

176:                                              ; preds = %5
  %177 = mul i64 %1, -7
  %178 = getelementptr inbounds i8, i8* %0, i64 %177
  %179 = bitcast i8* %178 to i32*
  %180 = load i32, i32* %179, align 1
  %181 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %180, i32 0
  %182 = mul nsw i64 %1, 6
  %183 = sub i64 0, %182
  %184 = getelementptr inbounds i8, i8* %0, i64 %183
  %185 = bitcast i8* %184 to i32*
  %186 = load i32, i32* %185, align 1
  %187 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %186, i32 0
  %188 = mul nsw i64 %1, 5
  %189 = sub i64 0, %188
  %190 = getelementptr inbounds i8, i8* %0, i64 %189
  %191 = bitcast i8* %190 to i32*
  %192 = load i32, i32* %191, align 1
  %193 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %192, i32 0
  %194 = getelementptr inbounds i8, i8* %0, i64 %16
  %195 = bitcast i8* %194 to i32*
  %196 = load i32, i32* %195, align 1
  %197 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %196, i32 0
  %198 = getelementptr inbounds i8, i8* %0, i64 %188
  %199 = bitcast i8* %198 to i32*
  %200 = load i32, i32* %199, align 1
  %201 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %200, i32 0
  %202 = getelementptr inbounds i8, i8* %0, i64 %182
  %203 = bitcast i8* %202 to i32*
  %204 = load i32, i32* %203, align 1
  %205 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %204, i32 0
  %206 = shufflevector <4 x i32> %181, <4 x i32> %205, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %207 = shufflevector <4 x i32> %187, <4 x i32> %201, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %208 = shufflevector <4 x i32> %193, <4 x i32> %197, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %209 = bitcast <4 x i32> %207 to <16 x i8>
  %210 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %209, <16 x i8> %63) #5
  %211 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %209) #5
  %212 = or <16 x i8> %211, %210
  %213 = bitcast <4 x i32> %208 to <16 x i8>
  %214 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %213, <16 x i8> %63) #5
  %215 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %213) #5
  %216 = or <16 x i8> %215, %214
  %217 = icmp ugt <16 x i8> %212, %216
  %218 = select <16 x i1> %217, <16 x i8> %212, <16 x i8> %216
  %219 = bitcast <4 x i32> %206 to <16 x i8>
  %220 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %219, <16 x i8> %63) #5
  %221 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %219) #5
  %222 = or <16 x i8> %221, %220
  %223 = icmp ugt <16 x i8> %218, %222
  %224 = select <16 x i1> %223, <16 x i8> %218, <16 x i8> %222
  %225 = shufflevector <16 x i8> %224, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %226 = icmp ugt <16 x i8> %224, %225
  %227 = select <16 x i1> %226, <16 x i8> %224, <16 x i8> %225
  %228 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %227, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %229 = icmp eq <16 x i8> %228, zeroinitializer
  %230 = sext <16 x i1> %229 to <16 x i8>
  %231 = bitcast <16 x i8> %230 to <2 x i64>
  %232 = and <2 x i64> %231, %173
  %233 = bitcast <2 x i64> %232 to <4 x i32>
  %234 = shufflevector <4 x i32> %233, <4 x i32> undef, <4 x i32> zeroinitializer
  %235 = bitcast <4 x i32> %234 to <2 x i64>
  %236 = shufflevector <16 x i8> %95, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %237 = zext <8 x i8> %236 to <8 x i16>
  %238 = shufflevector <16 x i8> %89, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %239 = zext <8 x i8> %238 to <8 x i16>
  %240 = shufflevector <16 x i8> %62, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %241 = zext <8 x i8> %240 to <8 x i16>
  %242 = shufflevector <16 x i8> %63, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %243 = zext <8 x i8> %242 to <8 x i16>
  %244 = bitcast <8 x i16> %239 to <4 x i32>
  %245 = shufflevector <4 x i32> %244, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %246 = bitcast <8 x i16> %241 to <4 x i32>
  %247 = shufflevector <4 x i32> %246, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %248 = bitcast <8 x i16> %243 to <4 x i32>
  %249 = shufflevector <4 x i32> %248, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %250 = shl nuw nsw <8 x i16> %237, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %251 = bitcast <4 x i32> %249 to <8 x i16>
  %252 = shl nuw nsw <8 x i16> %239, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %253 = add nuw nsw <8 x i16> %237, %241
  %254 = add nuw nsw <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = add nuw nsw <8 x i16> %254, %243
  %256 = add nuw nsw <8 x i16> %255, %252
  %257 = add <8 x i16> %256, %251
  %258 = add <8 x i16> %257, %250
  %259 = lshr <8 x i16> %258, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %259, <8 x i16> %259) #5
  %261 = bitcast <4 x i32> %247 to <8 x i16>
  %262 = sub nsw <8 x i16> %241, %239
  %263 = sub nsw <8 x i16> %262, %237
  %264 = add <8 x i16> %263, %261
  %265 = add <8 x i16> %264, %258
  %266 = lshr <8 x i16> %265, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %266, <8 x i16> %266) #5
  %268 = bitcast <4 x i32> %245 to <8 x i16>
  %269 = sub nsw <8 x i16> %243, %241
  %270 = sub nsw <8 x i16> %269, %237
  %271 = add <8 x i16> %270, %268
  %272 = add <8 x i16> %271, %265
  %273 = lshr <8 x i16> %272, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %274 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %273, <8 x i16> %273) #5
  %275 = bitcast <4 x i32> %172 to <16 x i8>
  %276 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %89, <16 x i8> %260, <16 x i8> %275) #5
  %277 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %153, <16 x i8> %267, <16 x i8> %275) #5
  %278 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %152, <16 x i8> %274, <16 x i8> %275) #5
  %279 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %235, <2 x i64> %235) #5
  %280 = icmp eq i32 %279, 0
  br i1 %280, label %281, label %360

281:                                              ; preds = %176
  %282 = shufflevector <16 x i8> %219, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %283 = zext <8 x i8> %282 to <8 x i16>
  %284 = shufflevector <16 x i8> %209, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %285 = zext <8 x i8> %284 to <8 x i16>
  %286 = shufflevector <16 x i8> %213, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %287 = zext <8 x i8> %286 to <8 x i16>
  %288 = bitcast <8 x i16> %285 to <4 x i32>
  %289 = shufflevector <4 x i32> %288, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %290 = bitcast <8 x i16> %287 to <4 x i32>
  %291 = shufflevector <4 x i32> %290, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %292 = bitcast <8 x i16> %237 to <4 x i32>
  %293 = shufflevector <4 x i32> %292, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %294 = mul nuw nsw <8 x i16> %283, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %295 = add nuw nsw <8 x i16> %285, %287
  %296 = shl nuw nsw <8 x i16> %295, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %297 = add nuw nsw <8 x i16> %253, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %298 = add nuw nsw <8 x i16> %297, %243
  %299 = add nuw nsw <8 x i16> %298, %239
  %300 = add <8 x i16> %299, %251
  %301 = add <8 x i16> %300, %294
  %302 = add <8 x i16> %301, %296
  %303 = lshr <8 x i16> %302, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %304 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %303, <8 x i16> %303) #5
  %305 = shl nuw nsw <8 x i16> %283, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %306 = add <8 x i16> %261, %237
  %307 = sub <8 x i16> %306, %305
  %308 = add <8 x i16> %307, %302
  %309 = lshr <8 x i16> %308, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %310 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %309, <8 x i16> %309) #5
  %311 = add <8 x i16> %268, %239
  %312 = sub <8 x i16> %311, %285
  %313 = sub <8 x i16> %312, %283
  %314 = add <8 x i16> %313, %308
  %315 = lshr <8 x i16> %314, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %316 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %315, <8 x i16> %315) #5
  %317 = bitcast <4 x i32> %293 to <8 x i16>
  %318 = add <8 x i16> %317, %241
  %319 = sub <8 x i16> %318, %287
  %320 = sub <8 x i16> %319, %283
  %321 = add <8 x i16> %320, %314
  %322 = lshr <8 x i16> %321, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %323 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %322, <8 x i16> %322) #5
  %324 = bitcast <4 x i32> %291 to <8 x i16>
  %325 = sub nsw <8 x i16> %243, %237
  %326 = sub nsw <8 x i16> %325, %283
  %327 = add <8 x i16> %326, %324
  %328 = add <8 x i16> %327, %321
  %329 = lshr <8 x i16> %328, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %330 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %329, <8 x i16> %329) #5
  %331 = bitcast <4 x i32> %289 to <8 x i16>
  %332 = sub <8 x i16> %251, %239
  %333 = sub <8 x i16> %332, %283
  %334 = add <8 x i16> %333, %331
  %335 = add <8 x i16> %334, %328
  %336 = lshr <8 x i16> %335, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %337 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %336, <8 x i16> %336) #5
  %338 = bitcast <4 x i32> %234 to <16 x i8>
  %339 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %209, <16 x i8> %304, <16 x i8> %338) #5
  %340 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %213, <16 x i8> %310, <16 x i8> %338) #5
  %341 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %95, <16 x i8> %316, <16 x i8> %338) #5
  %342 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %276, <16 x i8> %323, <16 x i8> %338) #5
  %343 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %277, <16 x i8> %330, <16 x i8> %338) #5
  %344 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %278, <16 x i8> %337, <16 x i8> %338) #5
  %345 = bitcast <16 x i8> %339 to <4 x i32>
  %346 = extractelement <4 x i32> %345, i32 0
  store i32 %346, i32* %185, align 1
  %347 = bitcast <16 x i8> %340 to <4 x i32>
  %348 = extractelement <4 x i32> %347, i32 0
  store i32 %348, i32* %191, align 1
  %349 = bitcast <16 x i8> %341 to <4 x i32>
  %350 = extractelement <4 x i32> %349, i32 0
  store i32 %350, i32* %19, align 1
  %351 = shufflevector <16 x i8> %341, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %352 = bitcast <16 x i8> %351 to <4 x i32>
  %353 = extractelement <4 x i32> %352, i32 0
  store i32 %353, i32* %51, align 1
  %354 = shufflevector <16 x i8> %340, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %355 = bitcast <16 x i8> %354 to <4 x i32>
  %356 = extractelement <4 x i32> %355, i32 0
  store i32 %356, i32* %195, align 1
  %357 = shufflevector <16 x i8> %339, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %358 = bitcast <16 x i8> %357 to <4 x i32>
  %359 = extractelement <4 x i32> %358, i32 0
  store i32 %359, i32* %199, align 1
  br label %360

360:                                              ; preds = %281, %176
  %361 = phi <16 x i8> [ %342, %281 ], [ %276, %176 ]
  %362 = phi <16 x i8> [ %344, %281 ], [ %278, %176 ]
  %363 = phi <16 x i8> [ %343, %281 ], [ %277, %176 ]
  %364 = bitcast <16 x i8> %362 to <2 x i64>
  %365 = bitcast <16 x i8> %361 to <4 x i32>
  %366 = extractelement <4 x i32> %365, i32 0
  store i32 %366, i32* %25, align 1
  %367 = shufflevector <16 x i8> %361, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %368 = bitcast <16 x i8> %367 to <4 x i32>
  %369 = extractelement <4 x i32> %368, i32 0
  store i32 %369, i32* %47, align 1
  br label %370

370:                                              ; preds = %360, %5
  %371 = phi <16 x i8> [ %362, %360 ], [ %152, %5 ]
  %372 = phi <2 x i64> [ %364, %360 ], [ %151, %5 ]
  %373 = phi <16 x i8> [ %363, %360 ], [ %153, %5 ]
  %374 = bitcast <16 x i8> %373 to <4 x i32>
  %375 = extractelement <4 x i32> %374, i32 0
  store i32 %375, i32* %31, align 1
  %376 = bitcast <2 x i64> %372 to <4 x i32>
  %377 = extractelement <4 x i32> %376, i32 0
  store i32 %377, i32* %36, align 1
  %378 = shufflevector <16 x i8> %371, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %379 = bitcast <16 x i8> %378 to <4 x i32>
  %380 = extractelement <4 x i32> %379, i32 0
  store i32 %380, i32* %39, align 1
  %381 = shufflevector <16 x i8> %373, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %382 = bitcast <16 x i8> %381 to <4 x i32>
  %383 = extractelement <4 x i32> %382, i32 0
  store i32 %383, i32* %43, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19Vertical4EPvliii(i8* nocapture, i64, i32, i32, i32) #2 {
  %6 = insertelement <4 x i32> undef, i32 %2, i32 0
  %7 = bitcast <4 x i32> %6 to <16 x i8>
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> zeroinitializer
  %9 = insertelement <4 x i32> undef, i32 %3, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = insertelement <4 x i32> undef, i32 %4, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = getelementptr inbounds i8, i8* %0, i64 -2
  %17 = bitcast i8* %16 to i32*
  %18 = load i32, i32* %17, align 1
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = getelementptr inbounds i8, i8* %16, i64 %1
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 1
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shl nsw i64 %1, 1
  %25 = getelementptr inbounds i8, i8* %16, i64 %24
  %26 = bitcast i8* %25 to i32*
  %27 = load i32, i32* %26, align 1
  %28 = insertelement <4 x i32> undef, i32 %27, i32 0
  %29 = mul nsw i64 %1, 3
  %30 = getelementptr inbounds i8, i8* %16, i64 %29
  %31 = bitcast i8* %30 to i32*
  %32 = load i32, i32* %31, align 1
  %33 = insertelement <4 x i32> undef, i32 %32, i32 0
  %34 = bitcast <4 x i32> %19 to <16 x i8>
  %35 = bitcast <4 x i32> %23 to <16 x i8>
  %36 = shufflevector <16 x i8> %34, <16 x i8> %35, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %37 = bitcast <4 x i32> %28 to <16 x i8>
  %38 = bitcast <4 x i32> %33 to <16 x i8>
  %39 = shufflevector <16 x i8> %37, <16 x i8> %38, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %36 to <8 x i16>
  %41 = bitcast <16 x i8> %39 to <8 x i16>
  %42 = shufflevector <8 x i16> %40, <8 x i16> %41, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %43 = bitcast <8 x i16> %42 to <4 x i32>
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %45 = bitcast <4 x i32> %44 to <2 x i64>
  %46 = bitcast <8 x i16> %42 to <16 x i8>
  %47 = shufflevector <16 x i8> %46, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %48 = bitcast <16 x i8> %47 to <2 x i64>
  %49 = shufflevector <16 x i8> %46, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %50 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> <i32 1, i32 0, i32 0, i32 0>
  %51 = bitcast <4 x i32> %44 to <16 x i8>
  %52 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %51, <16 x i8> %47) #5
  %53 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %51) #5
  %54 = or <16 x i8> %53, %52
  %55 = shufflevector <16 x i8> %54, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %56 = icmp ugt <16 x i8> %54, %55
  %57 = select <16 x i1> %56, <16 x i8> %54, <16 x i8> %55
  %58 = shufflevector <16 x i8> %57, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %59 = zext <8 x i8> %58 to <8 x i16>
  %60 = bitcast <16 x i8> %15 to <8 x i16>
  %61 = icmp slt <8 x i16> %60, %59
  %62 = sext <8 x i1> %61 to <8 x i16>
  %63 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %62, <8 x i16> undef) #5
  %64 = bitcast <4 x i32> %50 to <16 x i8>
  %65 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %64, <16 x i8> %49) #5
  %66 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %49, <16 x i8> %64) #5
  %67 = or <16 x i8> %66, %65
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> %67) #5
  %69 = bitcast <16 x i8> %67 to <8 x i16>
  %70 = lshr <8 x i16> %69, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %71 = bitcast <8 x i16> %70 to <16 x i8>
  %72 = and <16 x i8> %71, <i8 undef, i8 undef, i8 undef, i8 undef, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %73 = shufflevector <16 x i8> %72, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %74 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> %73) #5
  %75 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %74, <16 x i8> %8) #5
  %76 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %57, <16 x i8> %11) #5
  %77 = or <16 x i8> %75, %76
  %78 = icmp eq <16 x i8> %77, zeroinitializer
  %79 = shufflevector <2 x i64> %48, <2 x i64> %45, <2 x i32> <i32 0, i32 2>
  %80 = xor <2 x i64> %79, <i64 -9187201950435737472, i64 -9187201950435737472>
  %81 = bitcast <2 x i64> %80 to <4 x i32>
  %82 = shufflevector <4 x i32> %81, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 0, i32 0>
  %83 = shufflevector <4 x i32> %81, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %84 = bitcast <16 x i8> %63 to <4 x i32>
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %86 = bitcast <4 x i32> %85 to <2 x i64>
  %87 = bitcast <4 x i32> %82 to <16 x i8>
  %88 = bitcast <4 x i32> %83 to <16 x i8>
  %89 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %87, <16 x i8> %88) #5
  %90 = shufflevector <16 x i8> %89, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %91 = bitcast <4 x i32> %85 to <16 x i8>
  %92 = and <16 x i8> %90, %91
  %93 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %92, <16 x i8> %89) #5
  %94 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %93, <16 x i8> %89) #5
  %95 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %94, <16 x i8> %89) #5
  %96 = select <16 x i1> %78, <16 x i8> %95, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %97 = bitcast <16 x i8> %96 to <4 x i32>
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %99 = bitcast <4 x i32> %98 to <16 x i8>
  %100 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %99, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 4, i8 4, i8 4, i8 4, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>) #5
  %101 = shufflevector <16 x i8> %100, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %102 = bitcast <16 x i8> %101 to <8 x i16>
  %103 = ashr <8 x i16> %102, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %104 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %103, <8 x i16> %103) #5
  %105 = bitcast <16 x i8> %104 to <2 x i64>
  %106 = bitcast <16 x i8> %104 to <4 x i32>
  %107 = shufflevector <4 x i32> %106, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %108 = bitcast <4 x i32> %107 to <16 x i8>
  %109 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %108, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %110 = shufflevector <16 x i8> %109, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %111 = bitcast <16 x i8> %110 to <8 x i16>
  %112 = ashr <8 x i16> %111, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %113 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %112, <8 x i16> undef) #5
  %114 = bitcast <16 x i8> %113 to <2 x i64>
  %115 = xor <2 x i64> %86, <i64 -1, i64 undef>
  %116 = and <2 x i64> %114, %115
  %117 = shufflevector <2 x i64> %105, <2 x i64> %116, <2 x i32> <i32 0, i32 2>
  %118 = bitcast <2 x i64> %117 to <16 x i8>
  %119 = tail call <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8> %118, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1, i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1>) #5
  %120 = bitcast <2 x i64> %80 to <16 x i8>
  %121 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %120, <16 x i8> %119) #5
  %122 = xor <16 x i8> %121, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %123 = shufflevector <16 x i8> %122, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %124 = shufflevector <16 x i8> %122, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %125 = shufflevector <16 x i8> %123, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %126 = shufflevector <16 x i8> %123, <16 x i8> %122, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %127 = shufflevector <16 x i8> %124, <16 x i8> %125, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %128 = bitcast <16 x i8> %126 to <8 x i16>
  %129 = bitcast <16 x i8> %127 to <8 x i16>
  %130 = shufflevector <8 x i16> %128, <8 x i16> %129, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %131 = bitcast <8 x i16> %130 to <16 x i8>
  %132 = shufflevector <16 x i8> %131, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %133 = shufflevector <16 x i8> %131, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %134 = shufflevector <16 x i8> %131, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %135 = bitcast <8 x i16> %130 to <4 x i32>
  %136 = extractelement <4 x i32> %135, i32 0
  store i32 %136, i32* %17, align 1
  %137 = bitcast <16 x i8> %132 to <4 x i32>
  %138 = extractelement <4 x i32> %137, i32 0
  store i32 %138, i32* %21, align 1
  %139 = bitcast <16 x i8> %133 to <4 x i32>
  %140 = extractelement <4 x i32> %139, i32 0
  store i32 %140, i32* %26, align 1
  %141 = bitcast <16 x i8> %134 to <4 x i32>
  %142 = extractelement <4 x i32> %141, i32 0
  store i32 %142, i32* %31, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19Vertical6EPvliii(i8* nocapture, i64, i32, i32, i32) #2 {
  %6 = insertelement <4 x i32> undef, i32 %2, i32 0
  %7 = bitcast <4 x i32> %6 to <16 x i8>
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> zeroinitializer
  %9 = insertelement <4 x i32> undef, i32 %3, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = insertelement <4 x i32> undef, i32 %4, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = getelementptr inbounds i8, i8* %0, i64 -3
  %17 = bitcast i8* %16 to i64*
  %18 = load i64, i64* %17, align 1
  %19 = insertelement <2 x i64> undef, i64 %18, i32 0
  %20 = getelementptr inbounds i8, i8* %16, i64 %1
  %21 = bitcast i8* %20 to i64*
  %22 = load i64, i64* %21, align 1
  %23 = insertelement <2 x i64> undef, i64 %22, i32 0
  %24 = shl nsw i64 %1, 1
  %25 = getelementptr inbounds i8, i8* %16, i64 %24
  %26 = bitcast i8* %25 to i64*
  %27 = load i64, i64* %26, align 1
  %28 = insertelement <2 x i64> undef, i64 %27, i32 0
  %29 = mul nsw i64 %1, 3
  %30 = getelementptr inbounds i8, i8* %16, i64 %29
  %31 = bitcast i8* %30 to i64*
  %32 = load i64, i64* %31, align 1
  %33 = insertelement <2 x i64> undef, i64 %32, i32 0
  %34 = bitcast <2 x i64> %19 to <16 x i8>
  %35 = bitcast <2 x i64> %23 to <16 x i8>
  %36 = shufflevector <16 x i8> %34, <16 x i8> %35, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %37 = bitcast <2 x i64> %28 to <16 x i8>
  %38 = bitcast <2 x i64> %33 to <16 x i8>
  %39 = shufflevector <16 x i8> %37, <16 x i8> %38, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %40 = bitcast <16 x i8> %36 to <8 x i16>
  %41 = bitcast <16 x i8> %39 to <8 x i16>
  %42 = shufflevector <8 x i16> %40, <8 x i16> %41, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %43 = shufflevector <8 x i16> %40, <8 x i16> %41, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %44 = bitcast <8 x i16> %42 to <16 x i8>
  %45 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %46 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %47 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %48 = bitcast <8 x i16> %43 to <16 x i8>
  %49 = shufflevector <16 x i8> %48, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %50 = bitcast <8 x i16> %42 to <4 x i32>
  %51 = bitcast <16 x i8> %49 to <4 x i32>
  %52 = shufflevector <4 x i32> %50, <4 x i32> %51, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %53 = bitcast <16 x i8> %45 to <4 x i32>
  %54 = bitcast <8 x i16> %43 to <4 x i32>
  %55 = shufflevector <4 x i32> %53, <4 x i32> %54, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %56 = bitcast <4 x i32> %55 to <2 x i64>
  %57 = bitcast <16 x i8> %46 to <4 x i32>
  %58 = bitcast <16 x i8> %47 to <4 x i32>
  %59 = shufflevector <4 x i32> %57, <4 x i32> %58, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %60 = bitcast <4 x i32> %59 to <2 x i64>
  %61 = shufflevector <4 x i32> %58, <4 x i32> %54, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %62 = shufflevector <4 x i32> %57, <4 x i32> %53, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %63 = bitcast <4 x i32> %55 to <16 x i8>
  %64 = bitcast <4 x i32> %59 to <16 x i8>
  %65 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %64) #5
  %66 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %64, <16 x i8> %63) #5
  %67 = or <16 x i8> %66, %65
  %68 = shufflevector <16 x i8> %67, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %69 = icmp ugt <16 x i8> %67, %68
  %70 = select <16 x i1> %69, <16 x i8> %67, <16 x i8> %68
  %71 = shufflevector <16 x i8> %70, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %72 = zext <8 x i8> %71 to <8 x i16>
  %73 = bitcast <16 x i8> %15 to <8 x i16>
  %74 = icmp slt <8 x i16> %73, %72
  %75 = sext <8 x i1> %74 to <8 x i16>
  %76 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %75, <8 x i16> undef) #5
  %77 = bitcast <4 x i32> %62 to <16 x i8>
  %78 = bitcast <4 x i32> %61 to <16 x i8>
  %79 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %77, <16 x i8> %78) #5
  %80 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %78, <16 x i8> %77) #5
  %81 = or <16 x i8> %80, %79
  %82 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %81, <16 x i8> %81) #5
  %83 = bitcast <16 x i8> %81 to <8 x i16>
  %84 = lshr <8 x i16> %83, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %85 = bitcast <8 x i16> %84 to <16 x i8>
  %86 = and <16 x i8> %85, <i8 undef, i8 undef, i8 undef, i8 undef, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %87 = shufflevector <16 x i8> %86, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %88 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %82, <16 x i8> %87) #5
  %89 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %8) #5
  %90 = bitcast <4 x i32> %52 to <16 x i8>
  %91 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %90, <16 x i8> %63) #5
  %92 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %90) #5
  %93 = or <16 x i8> %92, %91
  %94 = icmp ugt <16 x i8> %93, %67
  %95 = select <16 x i1> %94, <16 x i8> %93, <16 x i8> %67
  %96 = shufflevector <16 x i8> %95, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %97 = icmp ugt <16 x i8> %95, %96
  %98 = select <16 x i1> %97, <16 x i8> %95, <16 x i8> %96
  %99 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %98, <16 x i8> %11) #5
  %100 = or <16 x i8> %89, %99
  %101 = icmp eq <16 x i8> %100, zeroinitializer
  %102 = shufflevector <2 x i64> %60, <2 x i64> %56, <2 x i32> <i32 0, i32 2>
  %103 = xor <2 x i64> %102, <i64 -9187201950435737472, i64 -9187201950435737472>
  %104 = bitcast <2 x i64> %103 to <4 x i32>
  %105 = shufflevector <4 x i32> %104, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 0, i32 0>
  %106 = shufflevector <4 x i32> %104, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %107 = bitcast <16 x i8> %76 to <4 x i32>
  %108 = shufflevector <4 x i32> %107, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %109 = bitcast <4 x i32> %108 to <2 x i64>
  %110 = bitcast <4 x i32> %105 to <16 x i8>
  %111 = bitcast <4 x i32> %106 to <16 x i8>
  %112 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %110, <16 x i8> %111) #5
  %113 = shufflevector <16 x i8> %112, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %114 = bitcast <4 x i32> %108 to <16 x i8>
  %115 = and <16 x i8> %113, %114
  %116 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %115, <16 x i8> %112) #5
  %117 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %116, <16 x i8> %112) #5
  %118 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %117, <16 x i8> %112) #5
  %119 = select <16 x i1> %101, <16 x i8> %118, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %120 = bitcast <16 x i8> %119 to <4 x i32>
  %121 = shufflevector <4 x i32> %120, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %122 = bitcast <4 x i32> %121 to <16 x i8>
  %123 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %122, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 4, i8 4, i8 4, i8 4, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>) #5
  %124 = shufflevector <16 x i8> %123, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %125 = bitcast <16 x i8> %124 to <8 x i16>
  %126 = ashr <8 x i16> %125, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %127 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %126, <8 x i16> %126) #5
  %128 = bitcast <16 x i8> %127 to <2 x i64>
  %129 = bitcast <16 x i8> %127 to <4 x i32>
  %130 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %131 = bitcast <4 x i32> %130 to <16 x i8>
  %132 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %131, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %133 = shufflevector <16 x i8> %132, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %134 = bitcast <16 x i8> %133 to <8 x i16>
  %135 = ashr <8 x i16> %134, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %135, <8 x i16> undef) #5
  %137 = bitcast <16 x i8> %136 to <2 x i64>
  %138 = xor <2 x i64> %109, <i64 -1, i64 undef>
  %139 = and <2 x i64> %137, %138
  %140 = shufflevector <2 x i64> %128, <2 x i64> %139, <2 x i32> <i32 0, i32 2>
  %141 = bitcast <2 x i64> %140 to <16 x i8>
  %142 = tail call <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8> %141, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1, i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1>) #5
  %143 = bitcast <2 x i64> %103 to <16 x i8>
  %144 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %143, <16 x i8> %142) #5
  %145 = xor <16 x i8> %144, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %146 = shufflevector <16 x i8> %145, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %147 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %90, <16 x i8> %64) #5
  %148 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %64, <16 x i8> %90) #5
  %149 = or <16 x i8> %148, %147
  %150 = icmp ugt <16 x i8> %149, %67
  %151 = select <16 x i1> %150, <16 x i8> %149, <16 x i8> %67
  %152 = shufflevector <16 x i8> %151, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %153 = icmp ugt <16 x i8> %151, %152
  %154 = select <16 x i1> %153, <16 x i8> %151, <16 x i8> %152
  %155 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %154, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %156 = icmp eq <16 x i8> %155, zeroinitializer
  %157 = and <16 x i1> %101, %156
  %158 = sext <16 x i1> %157 to <16 x i8>
  %159 = bitcast <16 x i8> %158 to <4 x i32>
  %160 = shufflevector <4 x i32> %159, <4 x i32> undef, <4 x i32> zeroinitializer
  %161 = bitcast <4 x i32> %160 to <2 x i64>
  %162 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %161, <2 x i64> %161) #5
  %163 = icmp eq i32 %162, 0
  br i1 %163, label %164, label %195

164:                                              ; preds = %5
  %165 = shufflevector <16 x i8> %90, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %166 = zext <8 x i8> %165 to <8 x i16>
  %167 = shufflevector <16 x i8> %63, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %168 = zext <8 x i8> %167 to <8 x i16>
  %169 = shufflevector <16 x i8> %64, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %170 = zext <8 x i8> %169 to <8 x i16>
  %171 = bitcast <8 x i16> %168 to <4 x i32>
  %172 = shufflevector <4 x i32> %171, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %173 = bitcast <8 x i16> %170 to <4 x i32>
  %174 = shufflevector <4 x i32> %173, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %175 = shl nuw nsw <8 x i16> %166, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %176 = bitcast <4 x i32> %174 to <8 x i16>
  %177 = add nuw nsw <8 x i16> %170, %168
  %178 = shl nuw nsw <8 x i16> %177, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %179 = add nuw nsw <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %180 = add nuw nsw <8 x i16> %179, %175
  %181 = add nuw nsw <8 x i16> %180, %178
  %182 = add <8 x i16> %181, %176
  %183 = lshr <8 x i16> %182, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %184 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %183, <8 x i16> %183) #5
  %185 = bitcast <4 x i32> %172 to <8 x i16>
  %186 = mul nsw <8 x i16> %166, <i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2>
  %187 = add <8 x i16> %186, %185
  %188 = add <8 x i16> %187, %176
  %189 = add <8 x i16> %188, %182
  %190 = lshr <8 x i16> %189, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %190, <8 x i16> %190) #5
  %192 = bitcast <4 x i32> %160 to <16 x i8>
  %193 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %146, <16 x i8> %184, <16 x i8> %192) #5
  %194 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %145, <16 x i8> %191, <16 x i8> %192) #5
  br label %195

195:                                              ; preds = %164, %5
  %196 = phi <16 x i8> [ %194, %164 ], [ %145, %5 ]
  %197 = phi <16 x i8> [ %193, %164 ], [ %146, %5 ]
  %198 = shufflevector <16 x i8> %196, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %199 = shufflevector <16 x i8> %197, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %200 = shufflevector <16 x i8> %197, <16 x i8> %196, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %201 = shufflevector <16 x i8> %198, <16 x i8> %199, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %202 = bitcast <16 x i8> %200 to <8 x i16>
  %203 = bitcast <16 x i8> %201 to <8 x i16>
  %204 = shufflevector <8 x i16> %202, <8 x i16> %203, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %205 = bitcast <8 x i16> %204 to <16 x i8>
  %206 = shufflevector <16 x i8> %205, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %207 = shufflevector <16 x i8> %205, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %208 = shufflevector <16 x i8> %205, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %209 = getelementptr inbounds i8, i8* %0, i64 -2
  %210 = bitcast <8 x i16> %204 to <4 x i32>
  %211 = extractelement <4 x i32> %210, i32 0
  %212 = bitcast i8* %209 to i32*
  store i32 %211, i32* %212, align 1
  %213 = getelementptr inbounds i8, i8* %209, i64 %1
  %214 = bitcast <16 x i8> %206 to <4 x i32>
  %215 = extractelement <4 x i32> %214, i32 0
  %216 = bitcast i8* %213 to i32*
  store i32 %215, i32* %216, align 1
  %217 = getelementptr inbounds i8, i8* %209, i64 %24
  %218 = bitcast <16 x i8> %207 to <4 x i32>
  %219 = extractelement <4 x i32> %218, i32 0
  %220 = bitcast i8* %217 to i32*
  store i32 %219, i32* %220, align 1
  %221 = getelementptr inbounds i8, i8* %209, i64 %29
  %222 = bitcast <16 x i8> %208 to <4 x i32>
  %223 = extractelement <4 x i32> %222, i32 0
  %224 = bitcast i8* %221 to i32*
  store i32 %223, i32* %224, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_19Vertical8EPvliii(i8* nocapture, i64, i32, i32, i32) #2 {
  %6 = insertelement <4 x i32> undef, i32 %2, i32 0
  %7 = bitcast <4 x i32> %6 to <16 x i8>
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> zeroinitializer
  %9 = insertelement <4 x i32> undef, i32 %3, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = insertelement <4 x i32> undef, i32 %4, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = getelementptr inbounds i8, i8* %0, i64 -4
  %17 = bitcast i8* %16 to i64*
  %18 = load i64, i64* %17, align 1
  %19 = insertelement <2 x i64> undef, i64 %18, i32 0
  %20 = getelementptr inbounds i8, i8* %16, i64 %1
  %21 = bitcast i8* %20 to i64*
  %22 = load i64, i64* %21, align 1
  %23 = insertelement <2 x i64> undef, i64 %22, i32 0
  %24 = shl nsw i64 %1, 1
  %25 = getelementptr inbounds i8, i8* %16, i64 %24
  %26 = bitcast i8* %25 to i64*
  %27 = load i64, i64* %26, align 1
  %28 = insertelement <2 x i64> undef, i64 %27, i32 0
  %29 = mul nsw i64 %1, 3
  %30 = getelementptr inbounds i8, i8* %16, i64 %29
  %31 = bitcast i8* %30 to i64*
  %32 = load i64, i64* %31, align 1
  %33 = insertelement <2 x i64> undef, i64 %32, i32 0
  %34 = bitcast <2 x i64> %19 to <16 x i8>
  %35 = bitcast <2 x i64> %23 to <16 x i8>
  %36 = shufflevector <16 x i8> %34, <16 x i8> %35, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %37 = bitcast <2 x i64> %28 to <16 x i8>
  %38 = bitcast <2 x i64> %33 to <16 x i8>
  %39 = shufflevector <16 x i8> %37, <16 x i8> %38, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %40 = bitcast <16 x i8> %36 to <8 x i16>
  %41 = bitcast <16 x i8> %39 to <8 x i16>
  %42 = shufflevector <8 x i16> %40, <8 x i16> %41, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %43 = shufflevector <8 x i16> %40, <8 x i16> %41, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %44 = bitcast <8 x i16> %42 to <16 x i8>
  %45 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %46 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %47 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %48 = bitcast <8 x i16> %43 to <16 x i8>
  %49 = shufflevector <16 x i8> %48, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %50 = shufflevector <16 x i8> %48, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %51 = shufflevector <16 x i8> %48, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %52 = bitcast <8 x i16> %42 to <4 x i32>
  %53 = bitcast <16 x i8> %51 to <4 x i32>
  %54 = shufflevector <4 x i32> %52, <4 x i32> %53, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %55 = bitcast <16 x i8> %45 to <4 x i32>
  %56 = bitcast <16 x i8> %50 to <4 x i32>
  %57 = shufflevector <4 x i32> %55, <4 x i32> %56, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %58 = bitcast <16 x i8> %46 to <4 x i32>
  %59 = bitcast <16 x i8> %49 to <4 x i32>
  %60 = shufflevector <4 x i32> %58, <4 x i32> %59, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %61 = bitcast <4 x i32> %60 to <2 x i64>
  %62 = bitcast <16 x i8> %47 to <4 x i32>
  %63 = bitcast <8 x i16> %43 to <4 x i32>
  %64 = shufflevector <4 x i32> %62, <4 x i32> %63, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %65 = bitcast <4 x i32> %64 to <2 x i64>
  %66 = shufflevector <4 x i32> %63, <4 x i32> %59, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %67 = shufflevector <4 x i32> %62, <4 x i32> %58, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %68 = bitcast <4 x i32> %60 to <16 x i8>
  %69 = bitcast <4 x i32> %64 to <16 x i8>
  %70 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %68, <16 x i8> %69) #5
  %71 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %69, <16 x i8> %68) #5
  %72 = or <16 x i8> %71, %70
  %73 = shufflevector <16 x i8> %72, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %74 = icmp ugt <16 x i8> %72, %73
  %75 = select <16 x i1> %74, <16 x i8> %72, <16 x i8> %73
  %76 = shufflevector <16 x i8> %75, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %77 = zext <8 x i8> %76 to <8 x i16>
  %78 = bitcast <16 x i8> %15 to <8 x i16>
  %79 = icmp slt <8 x i16> %78, %77
  %80 = sext <8 x i1> %79 to <8 x i16>
  %81 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %80, <8 x i16> undef) #5
  %82 = bitcast <4 x i32> %67 to <16 x i8>
  %83 = bitcast <4 x i32> %66 to <16 x i8>
  %84 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %82, <16 x i8> %83) #5
  %85 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %82) #5
  %86 = or <16 x i8> %85, %84
  %87 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %86, <16 x i8> %86) #5
  %88 = bitcast <16 x i8> %86 to <8 x i16>
  %89 = lshr <8 x i16> %88, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %90 = bitcast <8 x i16> %89 to <16 x i8>
  %91 = and <16 x i8> %90, <i8 undef, i8 undef, i8 undef, i8 undef, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %93 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %87, <16 x i8> %92) #5
  %94 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %93, <16 x i8> %8) #5
  %95 = bitcast <4 x i32> %57 to <16 x i8>
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %68) #5
  %97 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %68, <16 x i8> %95) #5
  %98 = or <16 x i8> %97, %96
  %99 = icmp ugt <16 x i8> %98, %72
  %100 = select <16 x i1> %99, <16 x i8> %98, <16 x i8> %72
  %101 = bitcast <4 x i32> %54 to <16 x i8>
  %102 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %101, <16 x i8> %95) #5
  %103 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %101) #5
  %104 = or <16 x i8> %103, %102
  %105 = icmp ugt <16 x i8> %100, %104
  %106 = select <16 x i1> %105, <16 x i8> %100, <16 x i8> %104
  %107 = shufflevector <16 x i8> %106, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %108 = icmp ugt <16 x i8> %106, %107
  %109 = select <16 x i1> %108, <16 x i8> %106, <16 x i8> %107
  %110 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %109, <16 x i8> %11) #5
  %111 = or <16 x i8> %110, %94
  %112 = icmp eq <16 x i8> %111, zeroinitializer
  %113 = shufflevector <2 x i64> %65, <2 x i64> %61, <2 x i32> <i32 0, i32 2>
  %114 = xor <2 x i64> %113, <i64 -9187201950435737472, i64 -9187201950435737472>
  %115 = bitcast <2 x i64> %114 to <4 x i32>
  %116 = shufflevector <4 x i32> %115, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 0, i32 0>
  %117 = shufflevector <4 x i32> %115, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %118 = bitcast <16 x i8> %81 to <4 x i32>
  %119 = shufflevector <4 x i32> %118, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %120 = bitcast <4 x i32> %119 to <2 x i64>
  %121 = bitcast <4 x i32> %116 to <16 x i8>
  %122 = bitcast <4 x i32> %117 to <16 x i8>
  %123 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %121, <16 x i8> %122) #5
  %124 = shufflevector <16 x i8> %123, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %125 = bitcast <4 x i32> %119 to <16 x i8>
  %126 = and <16 x i8> %124, %125
  %127 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %126, <16 x i8> %123) #5
  %128 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %127, <16 x i8> %123) #5
  %129 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %128, <16 x i8> %123) #5
  %130 = select <16 x i1> %112, <16 x i8> %129, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %131 = bitcast <16 x i8> %130 to <4 x i32>
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %133 = bitcast <4 x i32> %132 to <16 x i8>
  %134 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %133, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 4, i8 4, i8 4, i8 4, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>) #5
  %135 = shufflevector <16 x i8> %134, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %136 = bitcast <16 x i8> %135 to <8 x i16>
  %137 = ashr <8 x i16> %136, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %138 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %137, <8 x i16> %137) #5
  %139 = bitcast <16 x i8> %138 to <2 x i64>
  %140 = bitcast <16 x i8> %138 to <4 x i32>
  %141 = shufflevector <4 x i32> %140, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %142 = bitcast <4 x i32> %141 to <16 x i8>
  %143 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %142, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %144 = shufflevector <16 x i8> %143, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %145 = bitcast <16 x i8> %144 to <8 x i16>
  %146 = ashr <8 x i16> %145, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %147 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %146, <8 x i16> undef) #5
  %148 = bitcast <16 x i8> %147 to <2 x i64>
  %149 = xor <2 x i64> %120, <i64 -1, i64 undef>
  %150 = and <2 x i64> %148, %149
  %151 = shufflevector <2 x i64> %139, <2 x i64> %150, <2 x i32> <i32 0, i32 2>
  %152 = bitcast <2 x i64> %151 to <16 x i8>
  %153 = tail call <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8> %152, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1, i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1>) #5
  %154 = bitcast <2 x i64> %114 to <16 x i8>
  %155 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %154, <16 x i8> %153) #5
  %156 = xor <16 x i8> %155, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %157 = shufflevector <16 x i8> %156, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %158 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %69) #5
  %159 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %69, <16 x i8> %95) #5
  %160 = or <16 x i8> %159, %158
  %161 = icmp ugt <16 x i8> %160, %72
  %162 = select <16 x i1> %161, <16 x i8> %160, <16 x i8> %72
  %163 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %101, <16 x i8> %69) #5
  %164 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %69, <16 x i8> %101) #5
  %165 = or <16 x i8> %164, %163
  %166 = icmp ugt <16 x i8> %162, %165
  %167 = select <16 x i1> %166, <16 x i8> %162, <16 x i8> %165
  %168 = shufflevector <16 x i8> %167, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %169 = icmp ugt <16 x i8> %167, %168
  %170 = select <16 x i1> %169, <16 x i8> %167, <16 x i8> %168
  %171 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %170, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %172 = icmp eq <16 x i8> %171, zeroinitializer
  %173 = and <16 x i1> %112, %172
  %174 = sext <16 x i1> %173 to <16 x i8>
  %175 = bitcast <16 x i8> %174 to <4 x i32>
  %176 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> zeroinitializer
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %177, <2 x i64> %177) #5
  %179 = icmp eq i32 %178, 0
  br i1 %179, label %180, label %224

180:                                              ; preds = %5
  %181 = shufflevector <16 x i8> %101, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %182 = zext <8 x i8> %181 to <8 x i16>
  %183 = shufflevector <16 x i8> %95, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %184 = zext <8 x i8> %183 to <8 x i16>
  %185 = shufflevector <16 x i8> %68, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %186 = zext <8 x i8> %185 to <8 x i16>
  %187 = shufflevector <16 x i8> %69, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %188 = zext <8 x i8> %187 to <8 x i16>
  %189 = bitcast <8 x i16> %184 to <4 x i32>
  %190 = shufflevector <4 x i32> %189, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %191 = bitcast <8 x i16> %186 to <4 x i32>
  %192 = shufflevector <4 x i32> %191, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %193 = bitcast <8 x i16> %188 to <4 x i32>
  %194 = shufflevector <4 x i32> %193, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %195 = shl nuw nsw <8 x i16> %182, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %196 = bitcast <4 x i32> %194 to <8 x i16>
  %197 = shl nuw nsw <8 x i16> %184, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %198 = add nuw nsw <8 x i16> %186, %182
  %199 = add nuw nsw <8 x i16> %198, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %200 = add nuw nsw <8 x i16> %199, %188
  %201 = add nuw nsw <8 x i16> %200, %195
  %202 = add nuw nsw <8 x i16> %201, %197
  %203 = add <8 x i16> %202, %196
  %204 = lshr <8 x i16> %203, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %205 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %204, <8 x i16> %204) #5
  %206 = bitcast <4 x i32> %192 to <8 x i16>
  %207 = add nuw nsw <8 x i16> %184, %182
  %208 = sub nsw <8 x i16> %186, %207
  %209 = add <8 x i16> %208, %206
  %210 = add <8 x i16> %209, %203
  %211 = lshr <8 x i16> %210, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %212 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %211, <8 x i16> %211) #5
  %213 = bitcast <4 x i32> %190 to <8 x i16>
  %214 = sub nsw <8 x i16> %188, %198
  %215 = add <8 x i16> %214, %213
  %216 = add <8 x i16> %215, %210
  %217 = lshr <8 x i16> %216, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %218 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %217, <8 x i16> %217) #5
  %219 = bitcast <4 x i32> %176 to <16 x i8>
  %220 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %95, <16 x i8> %205, <16 x i8> %219) #5
  %221 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %157, <16 x i8> %212, <16 x i8> %219) #5
  %222 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %156, <16 x i8> %218, <16 x i8> %219) #5
  %223 = shufflevector <16 x i8> %220, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  br label %224

224:                                              ; preds = %180, %5
  %225 = phi <16 x i8> [ %222, %180 ], [ %156, %5 ]
  %226 = phi <16 x i8> [ %223, %180 ], [ %50, %5 ]
  %227 = phi <16 x i8> [ %220, %180 ], [ %45, %5 ]
  %228 = phi <16 x i8> [ %221, %180 ], [ %157, %5 ]
  %229 = shufflevector <16 x i8> %225, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %230 = shufflevector <16 x i8> %228, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %231 = shufflevector <16 x i8> %44, <16 x i8> %227, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %232 = shufflevector <16 x i8> %228, <16 x i8> %225, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %233 = shufflevector <16 x i8> %229, <16 x i8> %230, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %234 = shufflevector <16 x i8> %226, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %235 = bitcast <16 x i8> %231 to <8 x i16>
  %236 = bitcast <16 x i8> %232 to <8 x i16>
  %237 = shufflevector <8 x i16> %235, <8 x i16> %236, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %238 = bitcast <16 x i8> %233 to <8 x i16>
  %239 = bitcast <16 x i8> %234 to <8 x i16>
  %240 = shufflevector <8 x i16> %238, <8 x i16> %239, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %241 = bitcast <8 x i16> %237 to <4 x i32>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = shufflevector <4 x i32> %241, <4 x i32> %242, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %244 = bitcast <4 x i32> %243 to <2 x i64>
  %245 = bitcast <4 x i32> %243 to <16 x i8>
  %246 = shufflevector <16 x i8> %245, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %247 = bitcast <16 x i8> %246 to <2 x i64>
  %248 = shufflevector <4 x i32> %241, <4 x i32> %242, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %249 = bitcast <4 x i32> %248 to <2 x i64>
  %250 = bitcast <4 x i32> %248 to <16 x i8>
  %251 = shufflevector <16 x i8> %250, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %252 = bitcast <16 x i8> %251 to <2 x i64>
  %253 = extractelement <2 x i64> %244, i32 0
  store i64 %253, i64* %17, align 1
  %254 = extractelement <2 x i64> %247, i32 0
  store i64 %254, i64* %21, align 1
  %255 = extractelement <2 x i64> %249, i32 0
  store i64 %255, i64* %26, align 1
  %256 = extractelement <2 x i64> %252, i32 0
  store i64 %256, i64* %31, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_110Vertical14EPvliii(i8* nocapture, i64, i32, i32, i32) #2 {
  %6 = insertelement <4 x i32> undef, i32 %2, i32 0
  %7 = bitcast <4 x i32> %6 to <16 x i8>
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> zeroinitializer
  %9 = insertelement <4 x i32> undef, i32 %3, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = insertelement <4 x i32> undef, i32 %4, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = getelementptr inbounds i8, i8* %0, i64 -8
  %17 = bitcast i8* %16 to <2 x i64>*
  %18 = bitcast i8* %16 to <16 x i8>*
  %19 = load <16 x i8>, <16 x i8>* %18, align 1
  %20 = getelementptr inbounds i8, i8* %16, i64 %1
  %21 = bitcast i8* %20 to <2 x i64>*
  %22 = bitcast i8* %20 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = shl nsw i64 %1, 1
  %25 = getelementptr inbounds i8, i8* %16, i64 %24
  %26 = bitcast i8* %25 to <2 x i64>*
  %27 = bitcast i8* %25 to <16 x i8>*
  %28 = load <16 x i8>, <16 x i8>* %27, align 1
  %29 = mul nsw i64 %1, 3
  %30 = getelementptr inbounds i8, i8* %16, i64 %29
  %31 = bitcast i8* %30 to <2 x i64>*
  %32 = bitcast i8* %30 to <16 x i8>*
  %33 = load <16 x i8>, <16 x i8>* %32, align 1
  %34 = shufflevector <16 x i8> %19, <16 x i8> %23, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %35 = shufflevector <16 x i8> %28, <16 x i8> %33, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = shufflevector <16 x i8> %19, <16 x i8> %23, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %37 = shufflevector <16 x i8> %28, <16 x i8> %33, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %38 = bitcast <16 x i8> %34 to <8 x i16>
  %39 = bitcast <16 x i8> %35 to <8 x i16>
  %40 = shufflevector <8 x i16> %38, <8 x i16> %39, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %41 = shufflevector <8 x i16> %38, <8 x i16> %39, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %42 = bitcast <16 x i8> %36 to <8 x i16>
  %43 = bitcast <16 x i8> %37 to <8 x i16>
  %44 = shufflevector <8 x i16> %42, <8 x i16> %43, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %45 = shufflevector <8 x i16> %42, <8 x i16> %43, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %46 = bitcast <8 x i16> %45 to <16 x i8>
  %47 = shufflevector <16 x i8> %46, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %48 = bitcast <8 x i16> %40 to <4 x i32>
  %49 = bitcast <16 x i8> %47 to <4 x i32>
  %50 = shufflevector <4 x i32> %48, <4 x i32> %49, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %51 = bitcast <8 x i16> %40 to <16 x i8>
  %52 = shufflevector <16 x i8> %51, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %53 = bitcast <16 x i8> %52 to <4 x i32>
  %54 = bitcast <8 x i16> %45 to <4 x i32>
  %55 = shufflevector <4 x i32> %53, <4 x i32> %54, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %56 = shufflevector <16 x i8> %46, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %57 = bitcast <16 x i8> %56 to <4 x i32>
  %58 = shufflevector <4 x i32> %48, <4 x i32> %57, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <16 x i8> %51, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %61 = bitcast <16 x i8> %60 to <4 x i32>
  %62 = shufflevector <4 x i32> %61, <4 x i32> %54, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %63 = bitcast <4 x i32> %62 to <2 x i64>
  %64 = bitcast <8 x i16> %44 to <16 x i8>
  %65 = shufflevector <16 x i8> %64, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %66 = bitcast <8 x i16> %41 to <4 x i32>
  %67 = bitcast <16 x i8> %65 to <4 x i32>
  %68 = shufflevector <4 x i32> %66, <4 x i32> %67, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %69 = bitcast <4 x i32> %68 to <2 x i64>
  %70 = bitcast <8 x i16> %41 to <16 x i8>
  %71 = shufflevector <16 x i8> %70, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %72 = bitcast <16 x i8> %71 to <4 x i32>
  %73 = bitcast <8 x i16> %44 to <4 x i32>
  %74 = shufflevector <4 x i32> %72, <4 x i32> %73, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %75 = shufflevector <16 x i8> %64, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11>
  %76 = bitcast <16 x i8> %75 to <4 x i32>
  %77 = shufflevector <4 x i32> %66, <4 x i32> %76, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %78 = bitcast <4 x i32> %77 to <2 x i64>
  %79 = shufflevector <16 x i8> %70, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %80 = bitcast <16 x i8> %79 to <4 x i32>
  %81 = shufflevector <4 x i32> %80, <4 x i32> %73, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = shufflevector <2 x i64> %82, <2 x i64> %78, <2 x i32> <i32 0, i32 2>
  %84 = bitcast <2 x i64> %83 to <4 x i32>
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 0, i32 0>
  %86 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 0>
  %87 = bitcast <4 x i32> %77 to <16 x i8>
  %88 = bitcast <4 x i32> %81 to <16 x i8>
  %89 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %87, <16 x i8> %88) #5
  %90 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %87) #5
  %91 = or <16 x i8> %90, %89
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %93 = icmp ugt <16 x i8> %91, %92
  %94 = select <16 x i1> %93, <16 x i8> %91, <16 x i8> %92
  %95 = shufflevector <16 x i8> %94, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %96 = zext <8 x i8> %95 to <8 x i16>
  %97 = bitcast <16 x i8> %15 to <8 x i16>
  %98 = icmp slt <8 x i16> %97, %96
  %99 = sext <8 x i1> %98 to <8 x i16>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %99, <8 x i16> undef) #5
  %101 = bitcast <4 x i32> %86 to <16 x i8>
  %102 = bitcast <4 x i32> %85 to <16 x i8>
  %103 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %101, <16 x i8> %102) #5
  %104 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %102, <16 x i8> %101) #5
  %105 = or <16 x i8> %104, %103
  %106 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %105, <16 x i8> %105) #5
  %107 = bitcast <16 x i8> %105 to <8 x i16>
  %108 = lshr <8 x i16> %107, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %109 = bitcast <8 x i16> %108 to <16 x i8>
  %110 = and <16 x i8> %109, <i8 undef, i8 undef, i8 undef, i8 undef, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %111 = shufflevector <16 x i8> %110, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %112 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %106, <16 x i8> %111) #5
  %113 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %112, <16 x i8> %8) #5
  %114 = bitcast <4 x i32> %74 to <16 x i8>
  %115 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %114, <16 x i8> %87) #5
  %116 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %87, <16 x i8> %114) #5
  %117 = or <16 x i8> %116, %115
  %118 = icmp ugt <16 x i8> %117, %91
  %119 = select <16 x i1> %118, <16 x i8> %117, <16 x i8> %91
  %120 = bitcast <4 x i32> %68 to <16 x i8>
  %121 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %120, <16 x i8> %114) #5
  %122 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %114, <16 x i8> %120) #5
  %123 = or <16 x i8> %122, %121
  %124 = icmp ugt <16 x i8> %119, %123
  %125 = select <16 x i1> %124, <16 x i8> %119, <16 x i8> %123
  %126 = shufflevector <16 x i8> %125, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %127 = icmp ugt <16 x i8> %125, %126
  %128 = select <16 x i1> %127, <16 x i8> %125, <16 x i8> %126
  %129 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %128, <16 x i8> %11) #5
  %130 = or <16 x i8> %113, %129
  %131 = icmp eq <16 x i8> %130, zeroinitializer
  %132 = xor <2 x i64> %83, <i64 -9187201950435737472, i64 -9187201950435737472>
  %133 = bitcast <2 x i64> %132 to <4 x i32>
  %134 = shufflevector <4 x i32> %133, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 0, i32 0>
  %135 = shufflevector <4 x i32> %133, <4 x i32> undef, <4 x i32> <i32 0, i32 3, i32 0, i32 0>
  %136 = bitcast <16 x i8> %100 to <4 x i32>
  %137 = shufflevector <4 x i32> %136, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = bitcast <4 x i32> %134 to <16 x i8>
  %140 = bitcast <4 x i32> %135 to <16 x i8>
  %141 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %139, <16 x i8> %140) #5
  %142 = shufflevector <16 x i8> %141, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %143 = bitcast <4 x i32> %137 to <16 x i8>
  %144 = and <16 x i8> %142, %143
  %145 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %144, <16 x i8> %141) #5
  %146 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %145, <16 x i8> %141) #5
  %147 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %146, <16 x i8> %141) #5
  %148 = select <16 x i1> %131, <16 x i8> %147, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %149 = bitcast <16 x i8> %148 to <4 x i32>
  %150 = shufflevector <4 x i32> %149, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %151 = bitcast <4 x i32> %150 to <16 x i8>
  %152 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %151, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 4, i8 4, i8 4, i8 4, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>) #5
  %153 = shufflevector <16 x i8> %152, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %154 = bitcast <16 x i8> %153 to <8 x i16>
  %155 = ashr <8 x i16> %154, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %156 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %155, <8 x i16> %155) #5
  %157 = bitcast <16 x i8> %156 to <2 x i64>
  %158 = bitcast <16 x i8> %156 to <4 x i32>
  %159 = shufflevector <4 x i32> %158, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %160 = bitcast <4 x i32> %159 to <16 x i8>
  %161 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %160, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %162 = shufflevector <16 x i8> %161, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %163 = bitcast <16 x i8> %162 to <8 x i16>
  %164 = ashr <8 x i16> %163, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %165 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %164, <8 x i16> undef) #5
  %166 = bitcast <16 x i8> %165 to <2 x i64>
  %167 = xor <2 x i64> %138, <i64 -1, i64 undef>
  %168 = and <2 x i64> %166, %167
  %169 = shufflevector <2 x i64> %157, <2 x i64> %168, <2 x i32> <i32 0, i32 2>
  %170 = bitcast <2 x i64> %169 to <16 x i8>
  %171 = tail call <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8> %170, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1, i8 1, i8 1, i8 1, i8 1, i8 -1, i8 -1, i8 -1, i8 -1>) #5
  %172 = bitcast <2 x i64> %132 to <16 x i8>
  %173 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %172, <16 x i8> %171) #5
  %174 = bitcast <16 x i8> %173 to <2 x i64>
  %175 = xor <2 x i64> %174, <i64 -9187201950435737472, i64 -9187201950435737472>
  %176 = bitcast <2 x i64> %175 to <16 x i8>
  %177 = shufflevector <16 x i8> %176, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %178 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %114, <16 x i8> %88) #5
  %179 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %114) #5
  %180 = or <16 x i8> %179, %178
  %181 = icmp ugt <16 x i8> %180, %91
  %182 = select <16 x i1> %181, <16 x i8> %180, <16 x i8> %91
  %183 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %120, <16 x i8> %88) #5
  %184 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %120) #5
  %185 = or <16 x i8> %184, %183
  %186 = icmp ugt <16 x i8> %182, %185
  %187 = select <16 x i1> %186, <16 x i8> %182, <16 x i8> %185
  %188 = shufflevector <16 x i8> %187, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %189 = icmp ugt <16 x i8> %187, %188
  %190 = select <16 x i1> %189, <16 x i8> %187, <16 x i8> %188
  %191 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %192 = icmp eq <16 x i8> %191, zeroinitializer
  %193 = and <16 x i1> %131, %192
  %194 = sext <16 x i1> %193 to <16 x i8>
  %195 = bitcast <16 x i8> %194 to <4 x i32>
  %196 = shufflevector <4 x i32> %195, <4 x i32> undef, <4 x i32> zeroinitializer
  %197 = bitcast <4 x i32> %196 to <2 x i64>
  %198 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %197, <2 x i64> %197) #5
  %199 = icmp eq i32 %198, 0
  br i1 %199, label %203, label %200

200:                                              ; preds = %5
  %201 = bitcast <4 x i32> %74 to <2 x i64>
  %202 = bitcast <4 x i32> %55 to <16 x i8>
  br label %346

203:                                              ; preds = %5
  %204 = bitcast <4 x i32> %58 to <16 x i8>
  %205 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %204, <16 x i8> %88) #5
  %206 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %204) #5
  %207 = or <16 x i8> %206, %205
  %208 = bitcast <4 x i32> %62 to <16 x i8>
  %209 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %208, <16 x i8> %88) #5
  %210 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %208) #5
  %211 = or <16 x i8> %210, %209
  %212 = icmp ugt <16 x i8> %207, %211
  %213 = select <16 x i1> %212, <16 x i8> %207, <16 x i8> %211
  %214 = bitcast <4 x i32> %55 to <16 x i8>
  %215 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %214, <16 x i8> %88) #5
  %216 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %214) #5
  %217 = or <16 x i8> %216, %215
  %218 = icmp ugt <16 x i8> %213, %217
  %219 = select <16 x i1> %218, <16 x i8> %213, <16 x i8> %217
  %220 = shufflevector <16 x i8> %219, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %221 = icmp ugt <16 x i8> %219, %220
  %222 = select <16 x i1> %221, <16 x i8> %219, <16 x i8> %220
  %223 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %222, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %224 = icmp eq <16 x i8> %223, zeroinitializer
  %225 = sext <16 x i1> %224 to <16 x i8>
  %226 = bitcast <16 x i8> %225 to <2 x i64>
  %227 = and <2 x i64> %197, %226
  %228 = bitcast <2 x i64> %227 to <4 x i32>
  %229 = shufflevector <4 x i32> %228, <4 x i32> undef, <4 x i32> zeroinitializer
  %230 = bitcast <4 x i32> %229 to <2 x i64>
  %231 = shufflevector <16 x i8> %120, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %232 = zext <8 x i8> %231 to <8 x i16>
  %233 = shufflevector <16 x i8> %114, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %234 = zext <8 x i8> %233 to <8 x i16>
  %235 = shufflevector <16 x i8> %87, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %236 = zext <8 x i8> %235 to <8 x i16>
  %237 = shufflevector <16 x i8> %88, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %238 = zext <8 x i8> %237 to <8 x i16>
  %239 = bitcast <8 x i16> %234 to <4 x i32>
  %240 = shufflevector <4 x i32> %239, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %241 = bitcast <8 x i16> %236 to <4 x i32>
  %242 = shufflevector <4 x i32> %241, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %243 = bitcast <8 x i16> %238 to <4 x i32>
  %244 = shufflevector <4 x i32> %243, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %245 = shl nuw nsw <8 x i16> %232, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %246 = bitcast <4 x i32> %244 to <8 x i16>
  %247 = shl nuw nsw <8 x i16> %234, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %248 = add nuw nsw <8 x i16> %236, %232
  %249 = add nuw nsw <8 x i16> %248, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %250 = add nuw nsw <8 x i16> %249, %238
  %251 = add nuw nsw <8 x i16> %250, %245
  %252 = add nuw nsw <8 x i16> %251, %247
  %253 = add <8 x i16> %252, %246
  %254 = lshr <8 x i16> %253, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %254, <8 x i16> %254) #5
  %256 = bitcast <4 x i32> %242 to <8 x i16>
  %257 = add nuw nsw <8 x i16> %234, %232
  %258 = sub nsw <8 x i16> %236, %257
  %259 = add <8 x i16> %258, %256
  %260 = add <8 x i16> %259, %253
  %261 = lshr <8 x i16> %260, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %262 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %261, <8 x i16> %261) #5
  %263 = bitcast <4 x i32> %240 to <8 x i16>
  %264 = sub nsw <8 x i16> %238, %248
  %265 = add <8 x i16> %264, %263
  %266 = add <8 x i16> %265, %260
  %267 = lshr <8 x i16> %266, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %268 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %267, <8 x i16> %267) #5
  %269 = bitcast <4 x i32> %196 to <16 x i8>
  %270 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %114, <16 x i8> %255, <16 x i8> %269) #5
  %271 = bitcast <16 x i8> %270 to <2 x i64>
  %272 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %177, <16 x i8> %262, <16 x i8> %269) #5
  %273 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %176, <16 x i8> %268, <16 x i8> %269) #5
  %274 = bitcast <16 x i8> %273 to <2 x i64>
  %275 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %230, <2 x i64> %230) #5
  %276 = icmp eq i32 %275, 0
  br i1 %276, label %277, label %346

277:                                              ; preds = %203
  %278 = shufflevector <16 x i8> %214, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %279 = zext <8 x i8> %278 to <8 x i16>
  %280 = shufflevector <16 x i8> %204, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %281 = zext <8 x i8> %280 to <8 x i16>
  %282 = shufflevector <16 x i8> %208, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %283 = zext <8 x i8> %282 to <8 x i16>
  %284 = bitcast <8 x i16> %281 to <4 x i32>
  %285 = shufflevector <4 x i32> %284, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %286 = bitcast <8 x i16> %283 to <4 x i32>
  %287 = shufflevector <4 x i32> %286, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %288 = bitcast <8 x i16> %232 to <4 x i32>
  %289 = shufflevector <4 x i32> %288, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %290 = mul nuw nsw <8 x i16> %279, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %291 = add nuw nsw <8 x i16> %283, %281
  %292 = shl nuw nsw <8 x i16> %291, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %293 = add nuw nsw <8 x i16> %248, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %294 = add nuw nsw <8 x i16> %293, %234
  %295 = add nuw nsw <8 x i16> %294, %238
  %296 = add nuw nsw <8 x i16> %295, %290
  %297 = add nuw nsw <8 x i16> %296, %292
  %298 = add <8 x i16> %297, %246
  %299 = lshr <8 x i16> %298, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %300 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %299, <8 x i16> %299) #5
  %301 = shl nuw nsw <8 x i16> %279, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %302 = sub nsw <8 x i16> %232, %301
  %303 = add <8 x i16> %302, %256
  %304 = add <8 x i16> %303, %298
  %305 = lshr <8 x i16> %304, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %306 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %305, <8 x i16> %305) #5
  %307 = add nuw nsw <8 x i16> %281, %279
  %308 = sub nsw <8 x i16> %234, %307
  %309 = add <8 x i16> %308, %263
  %310 = add <8 x i16> %309, %304
  %311 = lshr <8 x i16> %310, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %312 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %311, <8 x i16> %311) #5
  %313 = bitcast <4 x i32> %289 to <8 x i16>
  %314 = add nuw nsw <8 x i16> %283, %279
  %315 = sub nsw <8 x i16> %236, %314
  %316 = add <8 x i16> %315, %313
  %317 = add <8 x i16> %316, %310
  %318 = lshr <8 x i16> %317, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %319 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %318, <8 x i16> %318) #5
  %320 = bitcast <4 x i32> %287 to <8 x i16>
  %321 = add nuw nsw <8 x i16> %232, %279
  %322 = sub nsw <8 x i16> %238, %321
  %323 = add <8 x i16> %322, %320
  %324 = add <8 x i16> %323, %317
  %325 = lshr <8 x i16> %324, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %326 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %325, <8 x i16> %325) #5
  %327 = bitcast <4 x i32> %285 to <8 x i16>
  %328 = add nuw nsw <8 x i16> %234, %279
  %329 = sub <8 x i16> %327, %328
  %330 = add <8 x i16> %329, %246
  %331 = add <8 x i16> %330, %324
  %332 = lshr <8 x i16> %331, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %333 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %332, <8 x i16> %332) #5
  %334 = bitcast <4 x i32> %229 to <16 x i8>
  %335 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %204, <16 x i8> %300, <16 x i8> %334) #5
  %336 = bitcast <16 x i8> %335 to <2 x i64>
  %337 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %208, <16 x i8> %306, <16 x i8> %334) #5
  %338 = bitcast <16 x i8> %337 to <2 x i64>
  %339 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %120, <16 x i8> %312, <16 x i8> %334) #5
  %340 = bitcast <16 x i8> %339 to <2 x i64>
  %341 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %270, <16 x i8> %319, <16 x i8> %334) #5
  %342 = bitcast <16 x i8> %341 to <2 x i64>
  %343 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %272, <16 x i8> %326, <16 x i8> %334) #5
  %344 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %273, <16 x i8> %333, <16 x i8> %334) #5
  %345 = bitcast <16 x i8> %344 to <2 x i64>
  br label %346

346:                                              ; preds = %200, %203, %277
  %347 = phi <16 x i8> [ %202, %200 ], [ %214, %203 ], [ %214, %277 ]
  %348 = phi <2 x i64> [ %201, %200 ], [ %271, %203 ], [ %342, %277 ]
  %349 = phi <2 x i64> [ %69, %200 ], [ %69, %203 ], [ %340, %277 ]
  %350 = phi <2 x i64> [ %63, %200 ], [ %63, %203 ], [ %338, %277 ]
  %351 = phi <16 x i8> [ %177, %200 ], [ %272, %203 ], [ %343, %277 ]
  %352 = phi <2 x i64> [ %175, %200 ], [ %274, %203 ], [ %345, %277 ]
  %353 = phi <2 x i64> [ %59, %200 ], [ %59, %203 ], [ %336, %277 ]
  %354 = bitcast <4 x i32> %50 to <16 x i8>
  %355 = shufflevector <16 x i8> %354, <16 x i8> %347, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %356 = bitcast <2 x i64> %353 to <16 x i8>
  %357 = bitcast <2 x i64> %350 to <16 x i8>
  %358 = shufflevector <16 x i8> %356, <16 x i8> %357, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %359 = bitcast <2 x i64> %349 to <16 x i8>
  %360 = bitcast <2 x i64> %348 to <16 x i8>
  %361 = shufflevector <16 x i8> %359, <16 x i8> %360, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %362 = bitcast <2 x i64> %352 to <16 x i8>
  %363 = shufflevector <16 x i8> %351, <16 x i8> %362, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %364 = bitcast <16 x i8> %355 to <8 x i16>
  %365 = bitcast <16 x i8> %358 to <8 x i16>
  %366 = shufflevector <8 x i16> %364, <8 x i16> %365, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %367 = bitcast <16 x i8> %361 to <8 x i16>
  %368 = bitcast <16 x i8> %363 to <8 x i16>
  %369 = shufflevector <8 x i16> %367, <8 x i16> %368, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %370 = bitcast <8 x i16> %366 to <4 x i32>
  %371 = bitcast <8 x i16> %369 to <4 x i32>
  %372 = shufflevector <4 x i32> %370, <4 x i32> %371, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %373 = bitcast <4 x i32> %372 to <2 x i64>
  %374 = shufflevector <4 x i32> %370, <4 x i32> %371, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %375 = bitcast <4 x i32> %374 to <2 x i64>
  %376 = shufflevector <16 x i8> %362, <16 x i8> %351, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %377 = shufflevector <16 x i8> %360, <16 x i8> %359, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %378 = shufflevector <16 x i8> %357, <16 x i8> %356, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %379 = shufflevector <16 x i8> %347, <16 x i8> %354, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %380 = bitcast <16 x i8> %376 to <8 x i16>
  %381 = bitcast <16 x i8> %377 to <8 x i16>
  %382 = shufflevector <8 x i16> %380, <8 x i16> %381, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %383 = bitcast <16 x i8> %378 to <8 x i16>
  %384 = bitcast <16 x i8> %379 to <8 x i16>
  %385 = shufflevector <8 x i16> %383, <8 x i16> %384, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %386 = bitcast <8 x i16> %382 to <4 x i32>
  %387 = bitcast <8 x i16> %385 to <4 x i32>
  %388 = shufflevector <4 x i32> %386, <4 x i32> %387, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %389 = bitcast <4 x i32> %388 to <2 x i64>
  %390 = shufflevector <4 x i32> %386, <4 x i32> %387, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %391 = bitcast <4 x i32> %390 to <2 x i64>
  %392 = shufflevector <2 x i64> %373, <2 x i64> %389, <2 x i32> <i32 0, i32 2>
  %393 = shufflevector <2 x i64> %373, <2 x i64> %389, <2 x i32> <i32 1, i32 3>
  %394 = shufflevector <2 x i64> %375, <2 x i64> %391, <2 x i32> <i32 0, i32 2>
  %395 = shufflevector <2 x i64> %375, <2 x i64> %391, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %392, <2 x i64>* %17, align 1
  store <2 x i64> %393, <2 x i64>* %21, align 1
  store <2 x i64> %394, <2 x i64>* %26, align 1
  store <2 x i64> %395, <2 x i64>* %31, align 1
  ret void
}

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.usub.sat.v16i8(<16 x i8>, <16 x i8>) #3

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8>, <16 x i8>) #3

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8>, <16 x i8>) #3

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8>, <16 x i8>) #3

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.ssse3.psign.b.128(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone
declare i32 @llvm.x86.sse41.ptestz(<2 x i64>, <2 x i64>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8>, <16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE11Horizontal4EPvliii(i8* nocapture, i64, i32, i32, i32) #2 align 2 {
  %6 = bitcast i8* %0 to i16*
  %7 = sdiv i64 %1, 2
  %8 = shl i32 %2, 2
  %9 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %8, i32 0
  %10 = bitcast <4 x i32> %9 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %12 = shl i32 %3, 2
  %13 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %12, i32 0
  %14 = bitcast <4 x i32> %13 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %16 = shl i32 %4, 2
  %17 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %16, i32 0
  %18 = bitcast <4 x i32> %17 to <8 x i16>
  %19 = shufflevector <8 x i16> %18, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %20 = shl nsw i64 %7, 1
  %21 = sub i64 0, %20
  %22 = getelementptr inbounds i16, i16* %6, i64 %21
  %23 = bitcast i16* %22 to i64*
  %24 = load i64, i64* %23, align 1
  %25 = insertelement <2 x i64> undef, i64 %24, i32 0
  %26 = sub nsw i64 0, %7
  %27 = getelementptr inbounds i16, i16* %6, i64 %26
  %28 = bitcast i16* %27 to i64*
  %29 = load i64, i64* %28, align 1
  %30 = insertelement <2 x i64> undef, i64 %29, i32 0
  %31 = bitcast <2 x i64> %30 to <4 x float>
  %32 = bitcast i8* %0 to <2 x float>*
  %33 = load <2 x float>, <2 x float>* %32, align 1
  %34 = shufflevector <2 x float> %33, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %35 = shufflevector <4 x float> %31, <4 x float> %34, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %36 = bitcast <4 x float> %35 to <2 x i64>
  %37 = getelementptr inbounds i16, i16* %6, i64 %7
  %38 = bitcast <2 x i64> %25 to <4 x float>
  %39 = bitcast i16* %37 to <2 x float>*
  %40 = load <2 x float>, <2 x float>* %39, align 1
  %41 = shufflevector <2 x float> %40, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %42 = shufflevector <4 x float> %38, <4 x float> %41, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %43 = bitcast <4 x float> %42 to <2 x i64>
  %44 = shufflevector <2 x i64> %36, <2 x i64> %43, <2 x i32> <i32 1, i32 3>
  %45 = shufflevector <2 x i64> %36, <2 x i64> %43, <2 x i32> <i32 0, i32 2>
  %46 = bitcast <4 x float> %42 to <8 x i16>
  %47 = bitcast <4 x float> %35 to <8 x i16>
  %48 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %46, <8 x i16> %47) #5
  %49 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %47, <8 x i16> %46) #5
  %50 = or <8 x i16> %49, %48
  %51 = bitcast <8 x i16> %50 to <16 x i8>
  %52 = shufflevector <16 x i8> %51, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %53 = bitcast <16 x i8> %52 to <8 x i16>
  %54 = icmp ugt <8 x i16> %50, %53
  %55 = select <8 x i1> %54, <8 x i16> %50, <8 x i16> %53
  %56 = icmp sgt <8 x i16> %55, %19
  %57 = sext <8 x i1> %56 to <8 x i16>
  %58 = bitcast <2 x i64> %45 to <8 x i16>
  %59 = bitcast <2 x i64> %44 to <8 x i16>
  %60 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %58, <8 x i16> %59) #5
  %61 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %58) #5
  %62 = or <8 x i16> %61, %60
  %63 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %62, <8 x i16> %62) #5
  %64 = lshr <8 x i16> %62, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %65 = bitcast <8 x i16> %64 to <16 x i8>
  %66 = shufflevector <16 x i8> %65, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %67 = bitcast <16 x i8> %66 to <8 x i16>
  %68 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %63, <8 x i16> %67) #5
  %69 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %68, <8 x i16> %11) #5
  %70 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %55, <8 x i16> %15) #5
  %71 = or <8 x i16> %69, %70
  %72 = icmp eq <8 x i16> %71, zeroinitializer
  %73 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %46, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %74 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %47, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %75 = bitcast <8 x i16> %74 to <16 x i8>
  %76 = shufflevector <16 x i8> %75, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %77 = bitcast <8 x i16> %73 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %79 = bitcast <16 x i8> %78 to <8 x i16>
  %80 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %73, <8 x i16> %79) #5
  %81 = icmp slt <8 x i16> %80, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %82 = select <8 x i1> %81, <8 x i16> %80, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %83 = icmp sgt <8 x i16> %82, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %84 = select <8 x i1> %83, <8 x i16> %82, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %85 = bitcast <16 x i8> %76 to <8 x i16>
  %86 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %85, <8 x i16> %74) #5
  %87 = and <8 x i16> %84, %57
  %88 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %87, <8 x i16> %86) #5
  %89 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %88, <8 x i16> %86) #5
  %90 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %89, <8 x i16> %86) #5
  %91 = icmp slt <8 x i16> %90, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %92 = select <8 x i1> %91, <8 x i16> %90, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %93 = icmp sgt <8 x i16> %92, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %94 = select <8 x i1> %93, <8 x i16> %92, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %95 = select <8 x i1> %72, <8 x i16> %94, <8 x i16> zeroinitializer
  %96 = icmp slt <8 x i16> %95, <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %97 = select <8 x i1> %96, <8 x i16> %95, <8 x i16> <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %98 = add nsw <8 x i16> %97, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %99 = ashr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = icmp slt <8 x i16> %95, <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %101 = select <8 x i1> %100, <8 x i16> %95, <8 x i16> <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %102 = add nsw <8 x i16> %101, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %103 = ashr <8 x i16> %102, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %104 = add nsw <8 x i16> %99, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %105 = ashr <8 x i16> %104, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %106 = xor <8 x i16> %57, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %107 = and <8 x i16> %105, %106
  %108 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %73, <8 x i16> %107) #5
  %109 = bitcast <8 x i16> %108 to <2 x i64>
  %110 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %74, <8 x i16> %103) #5
  %111 = bitcast <8 x i16> %110 to <2 x i64>
  %112 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %85, <8 x i16> %99) #5
  %113 = bitcast <8 x i16> %112 to <2 x i64>
  %114 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %79, <8 x i16> %107) #5
  %115 = bitcast <8 x i16> %114 to <2 x i64>
  %116 = shufflevector <2 x i64> %109, <2 x i64> %115, <2 x i32> <i32 0, i32 2>
  %117 = shufflevector <2 x i64> %111, <2 x i64> %113, <2 x i32> <i32 0, i32 2>
  %118 = bitcast <2 x i64> %116 to <8 x i16>
  %119 = icmp slt <8 x i16> %118, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %120 = select <8 x i1> %119, <8 x i16> %118, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %121 = icmp sgt <8 x i16> %120, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %122 = select <8 x i1> %121, <8 x i16> %120, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %123 = bitcast <2 x i64> %117 to <8 x i16>
  %124 = icmp slt <8 x i16> %123, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %125 = select <8 x i1> %124, <8 x i16> %123, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %126 = icmp sgt <8 x i16> %125, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %127 = select <8 x i1> %126, <8 x i16> %125, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %128 = add nsw <8 x i16> %122, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %129 = bitcast <8 x i16> %128 to <2 x i64>
  %130 = add nsw <8 x i16> %127, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %131 = bitcast <8 x i16> %130 to <2 x i64>
  %132 = extractelement <2 x i64> %129, i32 0
  store i64 %132, i64* %23, align 1
  %133 = extractelement <2 x i64> %131, i32 0
  store i64 %133, i64* %28, align 1
  %134 = bitcast <8 x i16> %130 to <4 x float>
  %135 = shufflevector <4 x float> %134, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %135, <2 x float>* %32, align 1
  %136 = bitcast <8 x i16> %128 to <4 x float>
  %137 = shufflevector <4 x float> %136, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %137, <2 x float>* %39, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE11Horizontal6EPvliii(i8* nocapture, i64, i32, i32, i32) #2 align 2 {
  %6 = bitcast i8* %0 to i16*
  %7 = sdiv i64 %1, 2
  %8 = shl i32 %2, 2
  %9 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %8, i32 0
  %10 = bitcast <4 x i32> %9 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %12 = shl i32 %3, 2
  %13 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %12, i32 0
  %14 = bitcast <4 x i32> %13 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %16 = shl i32 %4, 2
  %17 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %16, i32 0
  %18 = bitcast <4 x i32> %17 to <8 x i16>
  %19 = shufflevector <8 x i16> %18, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %20 = mul i64 %7, -3
  %21 = getelementptr inbounds i16, i16* %6, i64 %20
  %22 = bitcast i16* %21 to i64*
  %23 = load i64, i64* %22, align 1
  %24 = insertelement <2 x i64> undef, i64 %23, i32 0
  %25 = shl nsw i64 %7, 1
  %26 = sub i64 0, %25
  %27 = getelementptr inbounds i16, i16* %6, i64 %26
  %28 = bitcast i16* %27 to i64*
  %29 = load i64, i64* %28, align 1
  %30 = insertelement <2 x i64> undef, i64 %29, i32 0
  %31 = sub nsw i64 0, %7
  %32 = getelementptr inbounds i16, i16* %6, i64 %31
  %33 = bitcast i16* %32 to i64*
  %34 = load i64, i64* %33, align 1
  %35 = insertelement <2 x i64> undef, i64 %34, i32 0
  %36 = bitcast i8* %0 to i64*
  %37 = load i64, i64* %36, align 1
  %38 = getelementptr inbounds i16, i16* %6, i64 %7
  %39 = bitcast i16* %38 to i64*
  %40 = load i64, i64* %39, align 1
  %41 = getelementptr inbounds i16, i16* %6, i64 %25
  %42 = bitcast i16* %41 to i64*
  %43 = load i64, i64* %42, align 1
  %44 = insertelement <2 x i64> %24, i64 %43, i32 1
  %45 = insertelement <2 x i64> %30, i64 %40, i32 1
  %46 = insertelement <2 x i64> %35, i64 %37, i32 1
  %47 = bitcast <2 x i64> %45 to <8 x i16>
  %48 = bitcast <2 x i64> %46 to <8 x i16>
  %49 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %47, <8 x i16> %48) #5
  %50 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %48, <8 x i16> %47) #5
  %51 = or <8 x i16> %50, %49
  %52 = bitcast <8 x i16> %51 to <16 x i8>
  %53 = shufflevector <16 x i8> %52, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %54 = bitcast <16 x i8> %53 to <8 x i16>
  %55 = icmp ugt <8 x i16> %51, %54
  %56 = select <8 x i1> %55, <8 x i16> %51, <8 x i16> %54
  %57 = icmp sgt <8 x i16> %56, %19
  %58 = sext <8 x i1> %57 to <8 x i16>
  %59 = insertelement <2 x i64> %45, i64 %37, i32 0
  %60 = shufflevector <2 x i64> %46, <2 x i64> %45, <2 x i32> <i32 0, i32 2>
  %61 = bitcast <2 x i64> %60 to <8 x i16>
  %62 = bitcast <2 x i64> %59 to <8 x i16>
  %63 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %61, <8 x i16> %62) #5
  %64 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %62, <8 x i16> %61) #5
  %65 = or <8 x i16> %64, %63
  %66 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %65, <8 x i16> %65) #5
  %67 = lshr <8 x i16> %65, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %68 = bitcast <8 x i16> %67 to <16 x i8>
  %69 = shufflevector <16 x i8> %68, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %66, <8 x i16> %70) #5
  %72 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %71, <8 x i16> %11) #5
  %73 = bitcast <2 x i64> %44 to <8 x i16>
  %74 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %73, <8 x i16> %47) #5
  %75 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %47, <8 x i16> %73) #5
  %76 = or <8 x i16> %75, %74
  %77 = icmp ugt <8 x i16> %76, %51
  %78 = select <8 x i1> %77, <8 x i16> %76, <8 x i16> %51
  %79 = bitcast <8 x i16> %78 to <16 x i8>
  %80 = shufflevector <16 x i8> %79, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %81 = bitcast <16 x i8> %80 to <8 x i16>
  %82 = icmp ugt <8 x i16> %78, %81
  %83 = select <8 x i1> %82, <8 x i16> %78, <8 x i16> %81
  %84 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %83, <8 x i16> %15) #5
  %85 = or <8 x i16> %84, %72
  %86 = icmp eq <8 x i16> %85, zeroinitializer
  %87 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %47, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %88 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %48, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %89 = bitcast <8 x i16> %88 to <16 x i8>
  %90 = shufflevector <16 x i8> %89, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %91 = bitcast <8 x i16> %87 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %93 = bitcast <16 x i8> %92 to <8 x i16>
  %94 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %87, <8 x i16> %93) #5
  %95 = icmp slt <8 x i16> %94, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %97 = icmp sgt <8 x i16> %96, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %99 = bitcast <16 x i8> %90 to <8 x i16>
  %100 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %99, <8 x i16> %88) #5
  %101 = and <8 x i16> %98, %58
  %102 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %101, <8 x i16> %100) #5
  %103 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %102, <8 x i16> %100) #5
  %104 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %103, <8 x i16> %100) #5
  %105 = icmp slt <8 x i16> %104, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %106 = select <8 x i1> %105, <8 x i16> %104, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %107 = icmp sgt <8 x i16> %106, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %108 = select <8 x i1> %107, <8 x i16> %106, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %109 = select <8 x i1> %86, <8 x i16> %108, <8 x i16> zeroinitializer
  %110 = icmp slt <8 x i16> %109, <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %111 = select <8 x i1> %110, <8 x i16> %109, <8 x i16> <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %112 = add nsw <8 x i16> %111, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %113 = ashr <8 x i16> %112, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %114 = icmp slt <8 x i16> %109, <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %115 = select <8 x i1> %114, <8 x i16> %109, <8 x i16> <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %116 = add nsw <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = ashr <8 x i16> %116, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %118 = add nsw <8 x i16> %113, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %119 = ashr <8 x i16> %118, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %120 = xor <8 x i16> %58, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %121 = and <8 x i16> %119, %120
  %122 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %87, <8 x i16> %121) #5
  %123 = bitcast <8 x i16> %122 to <2 x i64>
  %124 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %88, <8 x i16> %117) #5
  %125 = bitcast <8 x i16> %124 to <2 x i64>
  %126 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %99, <8 x i16> %113) #5
  %127 = bitcast <8 x i16> %126 to <2 x i64>
  %128 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %93, <8 x i16> %121) #5
  %129 = bitcast <8 x i16> %128 to <2 x i64>
  %130 = shufflevector <2 x i64> %123, <2 x i64> %129, <2 x i32> <i32 0, i32 2>
  %131 = shufflevector <2 x i64> %125, <2 x i64> %127, <2 x i32> <i32 0, i32 2>
  %132 = bitcast <2 x i64> %130 to <8 x i16>
  %133 = icmp slt <8 x i16> %132, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %134 = select <8 x i1> %133, <8 x i16> %132, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %135 = icmp sgt <8 x i16> %134, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %136 = select <8 x i1> %135, <8 x i16> %134, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %137 = bitcast <2 x i64> %131 to <8 x i16>
  %138 = icmp slt <8 x i16> %137, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %139 = select <8 x i1> %138, <8 x i16> %137, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %140 = icmp sgt <8 x i16> %139, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %141 = select <8 x i1> %140, <8 x i16> %139, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %142 = add nsw <8 x i16> %136, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %143 = bitcast <8 x i16> %142 to <2 x i64>
  %144 = add nsw <8 x i16> %141, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %145 = bitcast <8 x i16> %144 to <2 x i64>
  %146 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %73, <8 x i16> %48) #5
  %147 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %48, <8 x i16> %73) #5
  %148 = or <8 x i16> %147, %146
  %149 = icmp ugt <8 x i16> %148, %51
  %150 = select <8 x i1> %149, <8 x i16> %148, <8 x i16> %51
  %151 = bitcast <8 x i16> %150 to <16 x i8>
  %152 = shufflevector <16 x i8> %151, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %153 = bitcast <16 x i8> %152 to <8 x i16>
  %154 = icmp ugt <8 x i16> %150, %153
  %155 = select <8 x i1> %154, <8 x i16> %150, <8 x i16> %153
  %156 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %155, <8 x i16> <i16 4, i16 4, i16 4, i16 4, i16 0, i16 0, i16 0, i16 0>) #5
  %157 = icmp eq <8 x i16> %156, zeroinitializer
  %158 = and <8 x i1> %86, %157
  %159 = sext <8 x i1> %158 to <8 x i16>
  %160 = bitcast <8 x i16> %159 to <2 x i64>
  %161 = shufflevector <2 x i64> %160, <2 x i64> undef, <2 x i32> zeroinitializer
  %162 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %161, <2 x i64> %161) #5
  %163 = icmp eq i32 %162, 0
  br i1 %163, label %164, label %193

164:                                              ; preds = %5
  %165 = bitcast <2 x i64> %45 to <4 x i32>
  %166 = shufflevector <4 x i32> %165, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %167 = bitcast <2 x i64> %46 to <4 x i32>
  %168 = shufflevector <4 x i32> %167, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %169 = shl <8 x i16> %73, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %170 = bitcast <4 x i32> %168 to <8 x i16>
  %171 = add <8 x i16> %47, %48
  %172 = shl <8 x i16> %171, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %173 = add <8 x i16> %73, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %174 = add <8 x i16> %173, %170
  %175 = add <8 x i16> %174, %169
  %176 = add <8 x i16> %175, %172
  %177 = lshr <8 x i16> %176, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %178 = bitcast <4 x i32> %166 to <8 x i16>
  %179 = mul <8 x i16> %73, <i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2>
  %180 = add <8 x i16> %178, %170
  %181 = add <8 x i16> %180, %179
  %182 = add <8 x i16> %181, %176
  %183 = lshr <8 x i16> %182, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %184 = bitcast <8 x i16> %142 to <16 x i8>
  %185 = bitcast <8 x i16> %177 to <16 x i8>
  %186 = bitcast <2 x i64> %161 to <16 x i8>
  %187 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %184, <16 x i8> %185, <16 x i8> %186) #5
  %188 = bitcast <16 x i8> %187 to <2 x i64>
  %189 = bitcast <8 x i16> %144 to <16 x i8>
  %190 = bitcast <8 x i16> %183 to <16 x i8>
  %191 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %189, <16 x i8> %190, <16 x i8> %186) #5
  %192 = bitcast <16 x i8> %191 to <2 x i64>
  br label %193

193:                                              ; preds = %164, %5
  %194 = phi <2 x i64> [ %188, %164 ], [ %143, %5 ]
  %195 = phi <2 x i64> [ %192, %164 ], [ %145, %5 ]
  %196 = extractelement <2 x i64> %194, i32 0
  store i64 %196, i64* %28, align 1
  %197 = extractelement <2 x i64> %195, i32 0
  store i64 %197, i64* %33, align 1
  %198 = bitcast <2 x i64> %195 to <4 x float>
  %199 = shufflevector <4 x float> %198, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %200 = bitcast i8* %0 to <2 x float>*
  store <2 x float> %199, <2 x float>* %200, align 1
  %201 = bitcast <2 x i64> %194 to <4 x float>
  %202 = shufflevector <4 x float> %201, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %203 = bitcast i16* %38 to <2 x float>*
  store <2 x float> %202, <2 x float>* %203, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE11Horizontal8EPvliii(i8* nocapture, i64, i32, i32, i32) #2 align 2 {
  %6 = bitcast i8* %0 to i16*
  %7 = sdiv i64 %1, 2
  %8 = shl i32 %2, 2
  %9 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %8, i32 0
  %10 = bitcast <4 x i32> %9 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %12 = shl i32 %3, 2
  %13 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %12, i32 0
  %14 = bitcast <4 x i32> %13 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %16 = shl i32 %4, 2
  %17 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %16, i32 0
  %18 = bitcast <4 x i32> %17 to <8 x i16>
  %19 = shufflevector <8 x i16> %18, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %20 = shl nsw i64 %7, 2
  %21 = sub i64 0, %20
  %22 = getelementptr inbounds i16, i16* %6, i64 %21
  %23 = bitcast i16* %22 to i64*
  %24 = load i64, i64* %23, align 1
  %25 = insertelement <2 x i64> undef, i64 %24, i32 0
  %26 = mul nsw i64 %7, 3
  %27 = sub i64 0, %26
  %28 = getelementptr inbounds i16, i16* %6, i64 %27
  %29 = bitcast i16* %28 to i64*
  %30 = load i64, i64* %29, align 1
  %31 = insertelement <2 x i64> undef, i64 %30, i32 0
  %32 = shl nsw i64 %7, 1
  %33 = sub i64 0, %32
  %34 = getelementptr inbounds i16, i16* %6, i64 %33
  %35 = bitcast i16* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = sub nsw i64 0, %7
  %39 = getelementptr inbounds i16, i16* %6, i64 %38
  %40 = bitcast i16* %39 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> undef, i64 %41, i32 0
  %43 = bitcast i8* %0 to i64*
  %44 = load i64, i64* %43, align 1
  %45 = getelementptr inbounds i16, i16* %6, i64 %7
  %46 = bitcast i16* %45 to i64*
  %47 = load i64, i64* %46, align 1
  %48 = getelementptr inbounds i16, i16* %6, i64 %32
  %49 = bitcast i16* %48 to i64*
  %50 = load i64, i64* %49, align 1
  %51 = getelementptr inbounds i16, i16* %6, i64 %26
  %52 = bitcast i16* %51 to i64*
  %53 = load i64, i64* %52, align 1
  %54 = insertelement <2 x i64> %25, i64 %53, i32 1
  %55 = insertelement <2 x i64> %31, i64 %50, i32 1
  %56 = insertelement <2 x i64> %37, i64 %47, i32 1
  %57 = insertelement <2 x i64> %42, i64 %44, i32 1
  %58 = bitcast <2 x i64> %56 to <8 x i16>
  %59 = bitcast <2 x i64> %57 to <8 x i16>
  %60 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %58, <8 x i16> %59) #5
  %61 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %58) #5
  %62 = or <8 x i16> %61, %60
  %63 = bitcast <8 x i16> %62 to <16 x i8>
  %64 = shufflevector <16 x i8> %63, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %65 = bitcast <16 x i8> %64 to <8 x i16>
  %66 = icmp ugt <8 x i16> %62, %65
  %67 = select <8 x i1> %66, <8 x i16> %62, <8 x i16> %65
  %68 = icmp sgt <8 x i16> %67, %19
  %69 = sext <8 x i1> %68 to <8 x i16>
  %70 = insertelement <2 x i64> %56, i64 %44, i32 0
  %71 = shufflevector <2 x i64> %57, <2 x i64> %56, <2 x i32> <i32 0, i32 2>
  %72 = bitcast <2 x i64> %71 to <8 x i16>
  %73 = bitcast <2 x i64> %70 to <8 x i16>
  %74 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %72, <8 x i16> %73) #5
  %75 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %73, <8 x i16> %72) #5
  %76 = or <8 x i16> %75, %74
  %77 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %76, <8 x i16> %76) #5
  %78 = lshr <8 x i16> %76, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %79 = bitcast <8 x i16> %78 to <16 x i8>
  %80 = shufflevector <16 x i8> %79, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %81 = bitcast <16 x i8> %80 to <8 x i16>
  %82 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %77, <8 x i16> %81) #5
  %83 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %82, <8 x i16> %11) #5
  %84 = bitcast <2 x i64> %55 to <8 x i16>
  %85 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %84, <8 x i16> %58) #5
  %86 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %58, <8 x i16> %84) #5
  %87 = or <8 x i16> %86, %85
  %88 = icmp ugt <8 x i16> %87, %62
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> %62
  %90 = bitcast <2 x i64> %54 to <8 x i16>
  %91 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %90, <8 x i16> %84) #5
  %92 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %84, <8 x i16> %90) #5
  %93 = or <8 x i16> %92, %91
  %94 = icmp ugt <8 x i16> %89, %93
  %95 = select <8 x i1> %94, <8 x i16> %89, <8 x i16> %93
  %96 = bitcast <8 x i16> %95 to <16 x i8>
  %97 = shufflevector <16 x i8> %96, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %98 = bitcast <16 x i8> %97 to <8 x i16>
  %99 = icmp ugt <8 x i16> %95, %98
  %100 = select <8 x i1> %99, <8 x i16> %95, <8 x i16> %98
  %101 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %100, <8 x i16> %15) #5
  %102 = or <8 x i16> %101, %83
  %103 = icmp eq <8 x i16> %102, zeroinitializer
  %104 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %58, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %105 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %59, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %106 = bitcast <8 x i16> %105 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %108 = bitcast <8 x i16> %104 to <16 x i8>
  %109 = shufflevector <16 x i8> %108, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %110 = bitcast <16 x i8> %109 to <8 x i16>
  %111 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %104, <8 x i16> %110) #5
  %112 = icmp slt <8 x i16> %111, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %113 = select <8 x i1> %112, <8 x i16> %111, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %114 = icmp sgt <8 x i16> %113, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %116 = bitcast <16 x i8> %107 to <8 x i16>
  %117 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %116, <8 x i16> %105) #5
  %118 = and <8 x i16> %115, %69
  %119 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %118, <8 x i16> %117) #5
  %120 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %119, <8 x i16> %117) #5
  %121 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %120, <8 x i16> %117) #5
  %122 = icmp slt <8 x i16> %121, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %123 = select <8 x i1> %122, <8 x i16> %121, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %124 = icmp sgt <8 x i16> %123, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %125 = select <8 x i1> %124, <8 x i16> %123, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %126 = select <8 x i1> %103, <8 x i16> %125, <8 x i16> zeroinitializer
  %127 = icmp slt <8 x i16> %126, <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %129 = add nsw <8 x i16> %128, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %130 = ashr <8 x i16> %129, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %131 = icmp slt <8 x i16> %126, <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %132 = select <8 x i1> %131, <8 x i16> %126, <8 x i16> <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %133 = add nsw <8 x i16> %132, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %134 = ashr <8 x i16> %133, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %135 = add nsw <8 x i16> %130, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %136 = ashr <8 x i16> %135, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %137 = xor <8 x i16> %69, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %138 = and <8 x i16> %136, %137
  %139 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %104, <8 x i16> %138) #5
  %140 = bitcast <8 x i16> %139 to <2 x i64>
  %141 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %105, <8 x i16> %134) #5
  %142 = bitcast <8 x i16> %141 to <2 x i64>
  %143 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %116, <8 x i16> %130) #5
  %144 = bitcast <8 x i16> %143 to <2 x i64>
  %145 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %110, <8 x i16> %138) #5
  %146 = bitcast <8 x i16> %145 to <2 x i64>
  %147 = shufflevector <2 x i64> %140, <2 x i64> %146, <2 x i32> <i32 0, i32 2>
  %148 = shufflevector <2 x i64> %142, <2 x i64> %144, <2 x i32> <i32 0, i32 2>
  %149 = bitcast <2 x i64> %147 to <8 x i16>
  %150 = icmp slt <8 x i16> %149, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %152 = icmp sgt <8 x i16> %151, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %153 = select <8 x i1> %152, <8 x i16> %151, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %154 = bitcast <2 x i64> %148 to <8 x i16>
  %155 = icmp slt <8 x i16> %154, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %156 = select <8 x i1> %155, <8 x i16> %154, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %157 = icmp sgt <8 x i16> %156, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %158 = select <8 x i1> %157, <8 x i16> %156, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %159 = add nsw <8 x i16> %153, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %160 = bitcast <8 x i16> %159 to <2 x i64>
  %161 = add nsw <8 x i16> %158, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %162 = bitcast <8 x i16> %161 to <2 x i64>
  %163 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %84, <8 x i16> %59) #5
  %164 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %84) #5
  %165 = or <8 x i16> %164, %163
  %166 = icmp ugt <8 x i16> %165, %62
  %167 = select <8 x i1> %166, <8 x i16> %165, <8 x i16> %62
  %168 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %90, <8 x i16> %59) #5
  %169 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %90) #5
  %170 = or <8 x i16> %169, %168
  %171 = icmp ugt <8 x i16> %167, %170
  %172 = select <8 x i1> %171, <8 x i16> %167, <8 x i16> %170
  %173 = bitcast <8 x i16> %172 to <16 x i8>
  %174 = shufflevector <16 x i8> %173, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %175 = bitcast <16 x i8> %174 to <8 x i16>
  %176 = icmp ugt <8 x i16> %172, %175
  %177 = select <8 x i1> %176, <8 x i16> %172, <8 x i16> %175
  %178 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %177, <8 x i16> <i16 4, i16 4, i16 4, i16 4, i16 0, i16 0, i16 0, i16 0>) #5
  %179 = icmp eq <8 x i16> %178, zeroinitializer
  %180 = and <8 x i1> %103, %179
  %181 = sext <8 x i1> %180 to <8 x i16>
  %182 = bitcast <8 x i16> %181 to <2 x i64>
  %183 = shufflevector <2 x i64> %182, <2 x i64> undef, <2 x i32> zeroinitializer
  %184 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %183, <2 x i64> %183) #5
  %185 = icmp eq i32 %184, 0
  br i1 %185, label %186, label %232

186:                                              ; preds = %5
  %187 = bitcast <2 x i64> %55 to <4 x i32>
  %188 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %189 = bitcast <2 x i64> %56 to <4 x i32>
  %190 = shufflevector <4 x i32> %189, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %191 = bitcast <2 x i64> %57 to <4 x i32>
  %192 = shufflevector <4 x i32> %191, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %193 = shl <8 x i16> %90, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %194 = bitcast <4 x i32> %192 to <8 x i16>
  %195 = shl <8 x i16> %84, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %196 = add <8 x i16> %90, %58
  %197 = add <8 x i16> %196, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %198 = add <8 x i16> %197, %59
  %199 = add <8 x i16> %198, %194
  %200 = add <8 x i16> %199, %195
  %201 = add <8 x i16> %200, %193
  %202 = lshr <8 x i16> %201, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %203 = bitcast <4 x i32> %190 to <8 x i16>
  %204 = sub <8 x i16> %58, %84
  %205 = sub <8 x i16> %204, %90
  %206 = add <8 x i16> %205, %203
  %207 = add <8 x i16> %206, %201
  %208 = lshr <8 x i16> %207, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %209 = bitcast <4 x i32> %188 to <8 x i16>
  %210 = sub <8 x i16> %59, %58
  %211 = sub <8 x i16> %210, %90
  %212 = add <8 x i16> %211, %209
  %213 = add <8 x i16> %212, %207
  %214 = lshr <8 x i16> %213, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %215 = bitcast <2 x i64> %55 to <16 x i8>
  %216 = bitcast <8 x i16> %202 to <16 x i8>
  %217 = bitcast <2 x i64> %183 to <16 x i8>
  %218 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %215, <16 x i8> %216, <16 x i8> %217) #5
  %219 = bitcast <16 x i8> %218 to <2 x i64>
  %220 = bitcast <8 x i16> %159 to <16 x i8>
  %221 = bitcast <8 x i16> %208 to <16 x i8>
  %222 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %220, <16 x i8> %221, <16 x i8> %217) #5
  %223 = bitcast <16 x i8> %222 to <2 x i64>
  %224 = bitcast <8 x i16> %161 to <16 x i8>
  %225 = bitcast <8 x i16> %214 to <16 x i8>
  %226 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %224, <16 x i8> %225, <16 x i8> %217) #5
  %227 = bitcast <16 x i8> %226 to <2 x i64>
  %228 = extractelement <2 x i64> %219, i32 0
  store i64 %228, i64* %29, align 1
  %229 = bitcast <16 x i8> %218 to <4 x float>
  %230 = shufflevector <4 x float> %229, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %231 = bitcast i16* %48 to <2 x float>*
  store <2 x float> %230, <2 x float>* %231, align 1
  br label %232

232:                                              ; preds = %186, %5
  %233 = phi <2 x i64> [ %223, %186 ], [ %160, %5 ]
  %234 = phi <2 x i64> [ %227, %186 ], [ %162, %5 ]
  %235 = extractelement <2 x i64> %233, i32 0
  store i64 %235, i64* %35, align 1
  %236 = extractelement <2 x i64> %234, i32 0
  store i64 %236, i64* %40, align 1
  %237 = bitcast <2 x i64> %234 to <4 x float>
  %238 = shufflevector <4 x float> %237, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %239 = bitcast i8* %0 to <2 x float>*
  store <2 x float> %238, <2 x float>* %239, align 1
  %240 = bitcast <2 x i64> %233 to <4 x float>
  %241 = shufflevector <4 x float> %240, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %242 = bitcast i16* %45 to <2 x float>*
  store <2 x float> %241, <2 x float>* %242, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE12Horizontal14EPvliii(i8* nocapture, i64, i32, i32, i32) #2 align 2 {
  %6 = bitcast i8* %0 to i16*
  %7 = sdiv i64 %1, 2
  %8 = shl i32 %2, 2
  %9 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %8, i32 0
  %10 = bitcast <4 x i32> %9 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %12 = shl i32 %3, 2
  %13 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %12, i32 0
  %14 = bitcast <4 x i32> %13 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %16 = shl i32 %4, 2
  %17 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %16, i32 0
  %18 = bitcast <4 x i32> %17 to <8 x i16>
  %19 = shufflevector <8 x i16> %18, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %20 = shl nsw i64 %7, 2
  %21 = sub i64 0, %20
  %22 = getelementptr inbounds i16, i16* %6, i64 %21
  %23 = bitcast i16* %22 to i64*
  %24 = load i64, i64* %23, align 1
  %25 = insertelement <2 x i64> undef, i64 %24, i32 0
  %26 = mul nsw i64 %7, 3
  %27 = sub i64 0, %26
  %28 = getelementptr inbounds i16, i16* %6, i64 %27
  %29 = bitcast i16* %28 to i64*
  %30 = load i64, i64* %29, align 1
  %31 = insertelement <2 x i64> undef, i64 %30, i32 0
  %32 = shl nsw i64 %7, 1
  %33 = sub i64 0, %32
  %34 = getelementptr inbounds i16, i16* %6, i64 %33
  %35 = bitcast i16* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = sub nsw i64 0, %7
  %39 = getelementptr inbounds i16, i16* %6, i64 %38
  %40 = bitcast i16* %39 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> undef, i64 %41, i32 0
  %43 = bitcast i8* %0 to i64*
  %44 = load i64, i64* %43, align 1
  %45 = getelementptr inbounds i16, i16* %6, i64 %7
  %46 = bitcast i16* %45 to i64*
  %47 = load i64, i64* %46, align 1
  %48 = getelementptr inbounds i16, i16* %6, i64 %32
  %49 = bitcast i16* %48 to i64*
  %50 = load i64, i64* %49, align 1
  %51 = getelementptr inbounds i16, i16* %6, i64 %26
  %52 = bitcast i16* %51 to i64*
  %53 = load i64, i64* %52, align 1
  %54 = insertelement <2 x i64> %25, i64 %53, i32 1
  %55 = insertelement <2 x i64> %31, i64 %50, i32 1
  %56 = insertelement <2 x i64> %37, i64 %47, i32 1
  %57 = insertelement <2 x i64> %42, i64 %44, i32 1
  %58 = bitcast <2 x i64> %56 to <8 x i16>
  %59 = bitcast <2 x i64> %57 to <8 x i16>
  %60 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %58, <8 x i16> %59) #5
  %61 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %58) #5
  %62 = or <8 x i16> %61, %60
  %63 = bitcast <8 x i16> %62 to <16 x i8>
  %64 = shufflevector <16 x i8> %63, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %65 = bitcast <16 x i8> %64 to <8 x i16>
  %66 = icmp ugt <8 x i16> %62, %65
  %67 = select <8 x i1> %66, <8 x i16> %62, <8 x i16> %65
  %68 = icmp sgt <8 x i16> %67, %19
  %69 = sext <8 x i1> %68 to <8 x i16>
  %70 = insertelement <2 x i64> %56, i64 %44, i32 0
  %71 = shufflevector <2 x i64> %57, <2 x i64> %56, <2 x i32> <i32 0, i32 2>
  %72 = bitcast <2 x i64> %71 to <8 x i16>
  %73 = bitcast <2 x i64> %70 to <8 x i16>
  %74 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %72, <8 x i16> %73) #5
  %75 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %73, <8 x i16> %72) #5
  %76 = or <8 x i16> %75, %74
  %77 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %76, <8 x i16> %76) #5
  %78 = lshr <8 x i16> %76, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %79 = bitcast <8 x i16> %78 to <16 x i8>
  %80 = shufflevector <16 x i8> %79, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %81 = bitcast <16 x i8> %80 to <8 x i16>
  %82 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %77, <8 x i16> %81) #5
  %83 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %82, <8 x i16> %11) #5
  %84 = bitcast <2 x i64> %55 to <8 x i16>
  %85 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %84, <8 x i16> %58) #5
  %86 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %58, <8 x i16> %84) #5
  %87 = or <8 x i16> %86, %85
  %88 = icmp ugt <8 x i16> %87, %62
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> %62
  %90 = bitcast <2 x i64> %54 to <8 x i16>
  %91 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %90, <8 x i16> %84) #5
  %92 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %84, <8 x i16> %90) #5
  %93 = or <8 x i16> %92, %91
  %94 = icmp ugt <8 x i16> %89, %93
  %95 = select <8 x i1> %94, <8 x i16> %89, <8 x i16> %93
  %96 = bitcast <8 x i16> %95 to <16 x i8>
  %97 = shufflevector <16 x i8> %96, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %98 = bitcast <16 x i8> %97 to <8 x i16>
  %99 = icmp ugt <8 x i16> %95, %98
  %100 = select <8 x i1> %99, <8 x i16> %95, <8 x i16> %98
  %101 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %100, <8 x i16> %15) #5
  %102 = or <8 x i16> %101, %83
  %103 = icmp eq <8 x i16> %102, zeroinitializer
  %104 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %58, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %105 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %59, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %106 = bitcast <8 x i16> %105 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %108 = bitcast <8 x i16> %104 to <16 x i8>
  %109 = shufflevector <16 x i8> %108, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %110 = bitcast <16 x i8> %109 to <8 x i16>
  %111 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %104, <8 x i16> %110) #5
  %112 = icmp slt <8 x i16> %111, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %113 = select <8 x i1> %112, <8 x i16> %111, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %114 = icmp sgt <8 x i16> %113, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %116 = bitcast <16 x i8> %107 to <8 x i16>
  %117 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %116, <8 x i16> %105) #5
  %118 = and <8 x i16> %115, %69
  %119 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %118, <8 x i16> %117) #5
  %120 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %119, <8 x i16> %117) #5
  %121 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %120, <8 x i16> %117) #5
  %122 = icmp slt <8 x i16> %121, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %123 = select <8 x i1> %122, <8 x i16> %121, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %124 = icmp sgt <8 x i16> %123, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %125 = select <8 x i1> %124, <8 x i16> %123, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %126 = select <8 x i1> %103, <8 x i16> %125, <8 x i16> zeroinitializer
  %127 = icmp slt <8 x i16> %126, <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %129 = add nsw <8 x i16> %128, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %130 = ashr <8 x i16> %129, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %131 = icmp slt <8 x i16> %126, <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %132 = select <8 x i1> %131, <8 x i16> %126, <8 x i16> <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %133 = add nsw <8 x i16> %132, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %134 = ashr <8 x i16> %133, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %135 = add nsw <8 x i16> %130, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %136 = ashr <8 x i16> %135, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %137 = xor <8 x i16> %69, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %138 = and <8 x i16> %136, %137
  %139 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %104, <8 x i16> %138) #5
  %140 = bitcast <8 x i16> %139 to <2 x i64>
  %141 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %105, <8 x i16> %134) #5
  %142 = bitcast <8 x i16> %141 to <2 x i64>
  %143 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %116, <8 x i16> %130) #5
  %144 = bitcast <8 x i16> %143 to <2 x i64>
  %145 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %110, <8 x i16> %138) #5
  %146 = bitcast <8 x i16> %145 to <2 x i64>
  %147 = shufflevector <2 x i64> %140, <2 x i64> %146, <2 x i32> <i32 0, i32 2>
  %148 = shufflevector <2 x i64> %142, <2 x i64> %144, <2 x i32> <i32 0, i32 2>
  %149 = bitcast <2 x i64> %147 to <8 x i16>
  %150 = icmp slt <8 x i16> %149, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %152 = icmp sgt <8 x i16> %151, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %153 = select <8 x i1> %152, <8 x i16> %151, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %154 = bitcast <2 x i64> %148 to <8 x i16>
  %155 = icmp slt <8 x i16> %154, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %156 = select <8 x i1> %155, <8 x i16> %154, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %157 = icmp sgt <8 x i16> %156, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %158 = select <8 x i1> %157, <8 x i16> %156, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %159 = add nsw <8 x i16> %153, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %160 = bitcast <8 x i16> %159 to <2 x i64>
  %161 = add nsw <8 x i16> %158, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %162 = bitcast <8 x i16> %161 to <2 x i64>
  %163 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %84, <8 x i16> %59) #5
  %164 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %84) #5
  %165 = or <8 x i16> %164, %163
  %166 = icmp ugt <8 x i16> %165, %62
  %167 = select <8 x i1> %166, <8 x i16> %165, <8 x i16> %62
  %168 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %90, <8 x i16> %59) #5
  %169 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %90) #5
  %170 = or <8 x i16> %169, %168
  %171 = icmp ugt <8 x i16> %167, %170
  %172 = select <8 x i1> %171, <8 x i16> %167, <8 x i16> %170
  %173 = bitcast <8 x i16> %172 to <16 x i8>
  %174 = shufflevector <16 x i8> %173, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %175 = bitcast <16 x i8> %174 to <8 x i16>
  %176 = icmp ugt <8 x i16> %172, %175
  %177 = select <8 x i1> %176, <8 x i16> %172, <8 x i16> %175
  %178 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %177, <8 x i16> <i16 4, i16 4, i16 4, i16 4, i16 0, i16 0, i16 0, i16 0>) #5
  %179 = icmp eq <8 x i16> %178, zeroinitializer
  %180 = and <8 x i1> %103, %179
  %181 = sext <8 x i1> %180 to <8 x i16>
  %182 = bitcast <8 x i16> %181 to <2 x i64>
  %183 = shufflevector <2 x i64> %182, <2 x i64> undef, <2 x i32> zeroinitializer
  %184 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %183, <2 x i64> %183) #5
  %185 = icmp eq i32 %184, 0
  br i1 %185, label %186, label %370

186:                                              ; preds = %5
  %187 = mul i64 %7, -7
  %188 = getelementptr inbounds i16, i16* %6, i64 %187
  %189 = bitcast i16* %188 to i64*
  %190 = load i64, i64* %189, align 1
  %191 = insertelement <2 x i64> undef, i64 %190, i32 0
  %192 = mul nsw i64 %7, 6
  %193 = sub i64 0, %192
  %194 = getelementptr inbounds i16, i16* %6, i64 %193
  %195 = bitcast i16* %194 to i64*
  %196 = load i64, i64* %195, align 1
  %197 = insertelement <2 x i64> undef, i64 %196, i32 0
  %198 = mul nsw i64 %7, 5
  %199 = sub i64 0, %198
  %200 = getelementptr inbounds i16, i16* %6, i64 %199
  %201 = bitcast i16* %200 to i64*
  %202 = load i64, i64* %201, align 1
  %203 = insertelement <2 x i64> undef, i64 %202, i32 0
  %204 = getelementptr inbounds i16, i16* %6, i64 %20
  %205 = bitcast i16* %204 to i64*
  %206 = load i64, i64* %205, align 1
  %207 = getelementptr inbounds i16, i16* %6, i64 %198
  %208 = bitcast i16* %207 to i64*
  %209 = load i64, i64* %208, align 1
  %210 = getelementptr inbounds i16, i16* %6, i64 %192
  %211 = bitcast i16* %210 to i64*
  %212 = load i64, i64* %211, align 1
  %213 = insertelement <2 x i64> %191, i64 %212, i32 1
  %214 = insertelement <2 x i64> %197, i64 %209, i32 1
  %215 = insertelement <2 x i64> %203, i64 %206, i32 1
  %216 = bitcast <2 x i64> %214 to <8 x i16>
  %217 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %216, <8 x i16> %59) #5
  %218 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %216) #5
  %219 = or <8 x i16> %218, %217
  %220 = bitcast <2 x i64> %215 to <8 x i16>
  %221 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %220, <8 x i16> %59) #5
  %222 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %220) #5
  %223 = or <8 x i16> %222, %221
  %224 = icmp ugt <8 x i16> %219, %223
  %225 = select <8 x i1> %224, <8 x i16> %219, <8 x i16> %223
  %226 = bitcast <2 x i64> %213 to <8 x i16>
  %227 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %226, <8 x i16> %59) #5
  %228 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %59, <8 x i16> %226) #5
  %229 = or <8 x i16> %228, %227
  %230 = icmp ugt <8 x i16> %225, %229
  %231 = select <8 x i1> %230, <8 x i16> %225, <8 x i16> %229
  %232 = bitcast <8 x i16> %231 to <16 x i8>
  %233 = shufflevector <16 x i8> %232, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %234 = bitcast <16 x i8> %233 to <8 x i16>
  %235 = icmp ugt <8 x i16> %231, %234
  %236 = select <8 x i1> %235, <8 x i16> %231, <8 x i16> %234
  %237 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %236, <8 x i16> <i16 4, i16 4, i16 4, i16 4, i16 0, i16 0, i16 0, i16 0>) #5
  %238 = icmp eq <8 x i16> %237, zeroinitializer
  %239 = sext <8 x i1> %238 to <8 x i16>
  %240 = bitcast <8 x i16> %239 to <2 x i64>
  %241 = and <2 x i64> %183, %240
  %242 = shufflevector <2 x i64> %241, <2 x i64> undef, <2 x i32> zeroinitializer
  %243 = bitcast <2 x i64> %55 to <4 x i32>
  %244 = shufflevector <4 x i32> %243, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %245 = bitcast <2 x i64> %56 to <4 x i32>
  %246 = shufflevector <4 x i32> %245, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %247 = bitcast <2 x i64> %57 to <4 x i32>
  %248 = shufflevector <4 x i32> %247, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %249 = shl <8 x i16> %90, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %250 = bitcast <4 x i32> %248 to <8 x i16>
  %251 = shl <8 x i16> %84, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %252 = add <8 x i16> %90, %58
  %253 = add <8 x i16> %252, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %254 = add <8 x i16> %253, %59
  %255 = add <8 x i16> %254, %250
  %256 = add <8 x i16> %255, %251
  %257 = add <8 x i16> %256, %249
  %258 = lshr <8 x i16> %257, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %259 = bitcast <4 x i32> %246 to <8 x i16>
  %260 = sub <8 x i16> %58, %84
  %261 = sub <8 x i16> %260, %90
  %262 = add <8 x i16> %261, %259
  %263 = add <8 x i16> %262, %257
  %264 = lshr <8 x i16> %263, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %265 = bitcast <4 x i32> %244 to <8 x i16>
  %266 = sub <8 x i16> %59, %58
  %267 = sub <8 x i16> %266, %90
  %268 = add <8 x i16> %267, %265
  %269 = add <8 x i16> %268, %263
  %270 = lshr <8 x i16> %269, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %271 = bitcast <2 x i64> %55 to <16 x i8>
  %272 = bitcast <8 x i16> %258 to <16 x i8>
  %273 = bitcast <2 x i64> %183 to <16 x i8>
  %274 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %271, <16 x i8> %272, <16 x i8> %273) #5
  %275 = bitcast <8 x i16> %159 to <16 x i8>
  %276 = bitcast <8 x i16> %264 to <16 x i8>
  %277 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %275, <16 x i8> %276, <16 x i8> %273) #5
  %278 = bitcast <8 x i16> %161 to <16 x i8>
  %279 = bitcast <8 x i16> %270 to <16 x i8>
  %280 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %278, <16 x i8> %279, <16 x i8> %273) #5
  %281 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %242, <2 x i64> %242) #5
  %282 = icmp eq i32 %281, 0
  br i1 %282, label %283, label %359

283:                                              ; preds = %186
  %284 = bitcast <2 x i64> %214 to <4 x i32>
  %285 = shufflevector <4 x i32> %284, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %286 = bitcast <2 x i64> %215 to <4 x i32>
  %287 = shufflevector <4 x i32> %286, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %288 = bitcast <2 x i64> %54 to <4 x i32>
  %289 = shufflevector <4 x i32> %288, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %290 = mul <8 x i16> %226, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %291 = add <8 x i16> %216, %220
  %292 = shl <8 x i16> %291, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %293 = add <8 x i16> %252, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %294 = add <8 x i16> %293, %59
  %295 = add <8 x i16> %294, %84
  %296 = add <8 x i16> %295, %250
  %297 = add <8 x i16> %296, %290
  %298 = add <8 x i16> %297, %292
  %299 = lshr <8 x i16> %298, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %300 = shl <8 x i16> %226, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %301 = add <8 x i16> %259, %90
  %302 = sub <8 x i16> %301, %300
  %303 = add <8 x i16> %302, %298
  %304 = lshr <8 x i16> %303, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %305 = add <8 x i16> %265, %84
  %306 = sub <8 x i16> %305, %216
  %307 = sub <8 x i16> %306, %226
  %308 = add <8 x i16> %307, %303
  %309 = lshr <8 x i16> %308, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %310 = bitcast <4 x i32> %289 to <8 x i16>
  %311 = add <8 x i16> %310, %58
  %312 = sub <8 x i16> %311, %220
  %313 = sub <8 x i16> %312, %226
  %314 = add <8 x i16> %313, %308
  %315 = lshr <8 x i16> %314, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %316 = bitcast <4 x i32> %287 to <8 x i16>
  %317 = sub <8 x i16> %59, %90
  %318 = sub <8 x i16> %317, %226
  %319 = add <8 x i16> %318, %316
  %320 = add <8 x i16> %319, %314
  %321 = lshr <8 x i16> %320, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %322 = bitcast <4 x i32> %285 to <8 x i16>
  %323 = sub <8 x i16> %250, %84
  %324 = sub <8 x i16> %323, %226
  %325 = add <8 x i16> %324, %322
  %326 = add <8 x i16> %325, %320
  %327 = lshr <8 x i16> %326, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %328 = bitcast <2 x i64> %214 to <16 x i8>
  %329 = bitcast <8 x i16> %299 to <16 x i8>
  %330 = bitcast <2 x i64> %242 to <16 x i8>
  %331 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %328, <16 x i8> %329, <16 x i8> %330) #5
  %332 = bitcast <16 x i8> %331 to <2 x i64>
  %333 = bitcast <2 x i64> %215 to <16 x i8>
  %334 = bitcast <8 x i16> %304 to <16 x i8>
  %335 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %333, <16 x i8> %334, <16 x i8> %330) #5
  %336 = bitcast <16 x i8> %335 to <2 x i64>
  %337 = bitcast <2 x i64> %54 to <16 x i8>
  %338 = bitcast <8 x i16> %309 to <16 x i8>
  %339 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %337, <16 x i8> %338, <16 x i8> %330) #5
  %340 = bitcast <16 x i8> %339 to <2 x i64>
  %341 = bitcast <8 x i16> %315 to <16 x i8>
  %342 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %274, <16 x i8> %341, <16 x i8> %330) #5
  %343 = bitcast <8 x i16> %321 to <16 x i8>
  %344 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %277, <16 x i8> %343, <16 x i8> %330) #5
  %345 = bitcast <8 x i16> %327 to <16 x i8>
  %346 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %280, <16 x i8> %345, <16 x i8> %330) #5
  %347 = extractelement <2 x i64> %332, i32 0
  store i64 %347, i64* %195, align 1
  %348 = extractelement <2 x i64> %336, i32 0
  store i64 %348, i64* %201, align 1
  %349 = extractelement <2 x i64> %340, i32 0
  store i64 %349, i64* %23, align 1
  %350 = bitcast <16 x i8> %339 to <4 x float>
  %351 = shufflevector <4 x float> %350, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %352 = bitcast i16* %51 to <2 x float>*
  store <2 x float> %351, <2 x float>* %352, align 1
  %353 = bitcast <16 x i8> %335 to <4 x float>
  %354 = shufflevector <4 x float> %353, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %355 = bitcast i16* %204 to <2 x float>*
  store <2 x float> %354, <2 x float>* %355, align 1
  %356 = bitcast <16 x i8> %331 to <4 x float>
  %357 = shufflevector <4 x float> %356, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %358 = bitcast i16* %207 to <2 x float>*
  store <2 x float> %357, <2 x float>* %358, align 1
  br label %359

359:                                              ; preds = %283, %186
  %360 = phi <16 x i8> [ %342, %283 ], [ %274, %186 ]
  %361 = phi <16 x i8> [ %346, %283 ], [ %280, %186 ]
  %362 = phi <16 x i8> [ %344, %283 ], [ %277, %186 ]
  %363 = bitcast <16 x i8> %362 to <2 x i64>
  %364 = bitcast <16 x i8> %361 to <2 x i64>
  %365 = bitcast <16 x i8> %360 to <2 x i64>
  %366 = extractelement <2 x i64> %365, i32 0
  store i64 %366, i64* %29, align 1
  %367 = bitcast <16 x i8> %360 to <4 x float>
  %368 = shufflevector <4 x float> %367, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %369 = bitcast i16* %48 to <2 x float>*
  store <2 x float> %368, <2 x float>* %369, align 1
  br label %370

370:                                              ; preds = %359, %5
  %371 = phi <2 x i64> [ %364, %359 ], [ %162, %5 ]
  %372 = phi <2 x i64> [ %363, %359 ], [ %160, %5 ]
  %373 = extractelement <2 x i64> %372, i32 0
  store i64 %373, i64* %35, align 1
  %374 = extractelement <2 x i64> %371, i32 0
  store i64 %374, i64* %40, align 1
  %375 = bitcast <2 x i64> %371 to <4 x float>
  %376 = shufflevector <4 x float> %375, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %377 = bitcast i8* %0 to <2 x float>*
  store <2 x float> %376, <2 x float>* %377, align 1
  %378 = bitcast <2 x i64> %372 to <4 x float>
  %379 = shufflevector <4 x float> %378, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %380 = bitcast i16* %45 to <2 x float>*
  store <2 x float> %379, <2 x float>* %380, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE9Vertical4EPvliii(i8* nocapture, i64, i32, i32, i32) #2 align 2 {
  %6 = sdiv i64 %1, 2
  %7 = shl i32 %2, 2
  %8 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %7, i32 0
  %9 = bitcast <4 x i32> %8 to <8 x i16>
  %10 = shufflevector <8 x i16> %9, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %11 = shl i32 %3, 2
  %12 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <8 x i16>
  %14 = shufflevector <8 x i16> %13, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %15 = shl i32 %4, 2
  %16 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %15, i32 0
  %17 = bitcast <4 x i32> %16 to <8 x i16>
  %18 = shufflevector <8 x i16> %17, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %19 = getelementptr inbounds i8, i8* %0, i64 -4
  %20 = bitcast i8* %19 to i16*
  %21 = bitcast i8* %19 to i64*
  %22 = load i64, i64* %21, align 1
  %23 = insertelement <2 x i64> undef, i64 %22, i32 0
  %24 = getelementptr inbounds i16, i16* %20, i64 %6
  %25 = bitcast i16* %24 to i64*
  %26 = load i64, i64* %25, align 1
  %27 = insertelement <2 x i64> undef, i64 %26, i32 0
  %28 = shl nsw i64 %6, 1
  %29 = getelementptr inbounds i16, i16* %20, i64 %28
  %30 = bitcast i16* %29 to i64*
  %31 = load i64, i64* %30, align 1
  %32 = insertelement <2 x i64> undef, i64 %31, i32 0
  %33 = mul nsw i64 %6, 3
  %34 = getelementptr inbounds i16, i16* %20, i64 %33
  %35 = bitcast i16* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = bitcast <2 x i64> %23 to <8 x i16>
  %39 = bitcast <2 x i64> %27 to <8 x i16>
  %40 = shufflevector <8 x i16> %38, <8 x i16> %39, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %41 = bitcast <2 x i64> %32 to <8 x i16>
  %42 = bitcast <2 x i64> %37 to <8 x i16>
  %43 = shufflevector <8 x i16> %41, <8 x i16> %42, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %44 = bitcast <8 x i16> %40 to <4 x i32>
  %45 = bitcast <8 x i16> %43 to <4 x i32>
  %46 = shufflevector <4 x i32> %44, <4 x i32> %45, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %48 = bitcast <4 x i32> %47 to <2 x i64>
  %49 = shufflevector <4 x i32> %44, <4 x i32> %45, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %50 = bitcast <4 x i32> %49 to <2 x i64>
  %51 = shufflevector <2 x i64> %48, <2 x i64> %50, <2 x i32> <i32 1, i32 3>
  %52 = shufflevector <2 x i64> %48, <2 x i64> %50, <2 x i32> <i32 0, i32 2>
  %53 = bitcast <2 x i64> %51 to <8 x i16>
  %54 = bitcast <2 x i64> %52 to <8 x i16>
  %55 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %53, <8 x i16> %54) #5
  %56 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %54, <8 x i16> %53) #5
  %57 = or <8 x i16> %56, %55
  %58 = bitcast <8 x i16> %57 to <16 x i8>
  %59 = shufflevector <16 x i8> %58, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %60 = bitcast <16 x i8> %59 to <8 x i16>
  %61 = icmp ugt <8 x i16> %57, %60
  %62 = select <8 x i1> %61, <8 x i16> %57, <8 x i16> %60
  %63 = icmp sgt <8 x i16> %62, %18
  %64 = sext <8 x i1> %63 to <8 x i16>
  %65 = bitcast <4 x i32> %47 to <8 x i16>
  %66 = bitcast <4 x i32> %49 to <8 x i16>
  %67 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %65, <8 x i16> %66) #5
  %68 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %66, <8 x i16> %65) #5
  %69 = or <8 x i16> %68, %67
  %70 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %69, <8 x i16> %69) #5
  %71 = lshr <8 x i16> %69, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %72 = bitcast <8 x i16> %71 to <16 x i8>
  %73 = shufflevector <16 x i8> %72, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %74 = bitcast <16 x i8> %73 to <8 x i16>
  %75 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %70, <8 x i16> %74) #5
  %76 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %75, <8 x i16> %10) #5
  %77 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %62, <8 x i16> %14) #5
  %78 = or <8 x i16> %77, %76
  %79 = icmp eq <8 x i16> %78, zeroinitializer
  %80 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %53, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %81 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %54, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %82 = bitcast <8 x i16> %81 to <16 x i8>
  %83 = shufflevector <16 x i8> %82, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %84 = bitcast <8 x i16> %80 to <16 x i8>
  %85 = shufflevector <16 x i8> %84, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %86 = bitcast <16 x i8> %85 to <8 x i16>
  %87 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %80, <8 x i16> %86) #5
  %88 = icmp slt <8 x i16> %87, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %90 = icmp sgt <8 x i16> %89, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %91 = select <8 x i1> %90, <8 x i16> %89, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %92 = bitcast <16 x i8> %83 to <8 x i16>
  %93 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %92, <8 x i16> %81) #5
  %94 = and <8 x i16> %91, %64
  %95 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %94, <8 x i16> %93) #5
  %96 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %95, <8 x i16> %93) #5
  %97 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %96, <8 x i16> %93) #5
  %98 = icmp slt <8 x i16> %97, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %99 = select <8 x i1> %98, <8 x i16> %97, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %100 = icmp sgt <8 x i16> %99, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %101 = select <8 x i1> %100, <8 x i16> %99, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %102 = select <8 x i1> %79, <8 x i16> %101, <8 x i16> zeroinitializer
  %103 = icmp slt <8 x i16> %102, <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %104 = select <8 x i1> %103, <8 x i16> %102, <8 x i16> <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %105 = add nsw <8 x i16> %104, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %106 = ashr <8 x i16> %105, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %107 = icmp slt <8 x i16> %102, <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %108 = select <8 x i1> %107, <8 x i16> %102, <8 x i16> <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %109 = add nsw <8 x i16> %108, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %110 = ashr <8 x i16> %109, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %111 = add nsw <8 x i16> %106, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %112 = ashr <8 x i16> %111, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %113 = xor <8 x i16> %64, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %114 = and <8 x i16> %112, %113
  %115 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %80, <8 x i16> %114) #5
  %116 = bitcast <8 x i16> %115 to <2 x i64>
  %117 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %81, <8 x i16> %110) #5
  %118 = bitcast <8 x i16> %117 to <2 x i64>
  %119 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %92, <8 x i16> %106) #5
  %120 = bitcast <8 x i16> %119 to <2 x i64>
  %121 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %86, <8 x i16> %114) #5
  %122 = bitcast <8 x i16> %121 to <2 x i64>
  %123 = shufflevector <2 x i64> %116, <2 x i64> %122, <2 x i32> <i32 0, i32 2>
  %124 = shufflevector <2 x i64> %118, <2 x i64> %120, <2 x i32> <i32 0, i32 2>
  %125 = bitcast <2 x i64> %123 to <8 x i16>
  %126 = icmp slt <8 x i16> %125, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %127 = select <8 x i1> %126, <8 x i16> %125, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %128 = icmp sgt <8 x i16> %127, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %129 = select <8 x i1> %128, <8 x i16> %127, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %130 = bitcast <2 x i64> %124 to <8 x i16>
  %131 = icmp slt <8 x i16> %130, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %132 = select <8 x i1> %131, <8 x i16> %130, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %133 = icmp sgt <8 x i16> %132, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %134 = select <8 x i1> %133, <8 x i16> %132, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %135 = add nsw <8 x i16> %129, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %136 = add nsw <8 x i16> %134, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %137 = shufflevector <8 x i16> %135, <8 x i16> %136, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %138 = shufflevector <8 x i16> %136, <8 x i16> %135, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %139 = bitcast <8 x i16> %137 to <4 x i32>
  %140 = bitcast <8 x i16> %138 to <4 x i32>
  %141 = shufflevector <4 x i32> %139, <4 x i32> %140, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %142 = bitcast <4 x i32> %141 to <2 x i64>
  %143 = shufflevector <4 x i32> %139, <4 x i32> %140, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %144 = bitcast <4 x i32> %143 to <2 x i64>
  %145 = extractelement <2 x i64> %142, i32 0
  store i64 %145, i64* %21, align 1
  %146 = bitcast <4 x i32> %141 to <4 x float>
  %147 = shufflevector <4 x float> %146, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %148 = bitcast i16* %24 to <2 x float>*
  store <2 x float> %147, <2 x float>* %148, align 1
  %149 = extractelement <2 x i64> %144, i32 0
  store i64 %149, i64* %30, align 1
  %150 = bitcast <4 x i32> %143 to <4 x float>
  %151 = shufflevector <4 x float> %150, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %152 = bitcast i16* %34 to <2 x float>*
  store <2 x float> %151, <2 x float>* %152, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE9Vertical6EPvliii(i8* nocapture, i64, i32, i32, i32) #2 align 2 {
  %6 = sdiv i64 %1, 2
  %7 = shl i32 %2, 2
  %8 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %7, i32 0
  %9 = bitcast <4 x i32> %8 to <8 x i16>
  %10 = shufflevector <8 x i16> %9, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %11 = shl i32 %3, 2
  %12 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <8 x i16>
  %14 = shufflevector <8 x i16> %13, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %15 = shl i32 %4, 2
  %16 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %15, i32 0
  %17 = bitcast <4 x i32> %16 to <8 x i16>
  %18 = shufflevector <8 x i16> %17, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %19 = getelementptr inbounds i8, i8* %0, i64 -6
  %20 = bitcast i8* %19 to i16*
  %21 = bitcast i8* %19 to <8 x i16>*
  %22 = load <8 x i16>, <8 x i16>* %21, align 1
  %23 = getelementptr inbounds i16, i16* %20, i64 %6
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 1
  %26 = shl nsw i64 %6, 1
  %27 = getelementptr inbounds i16, i16* %20, i64 %26
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 1
  %30 = mul nsw i64 %6, 3
  %31 = getelementptr inbounds i16, i16* %20, i64 %30
  %32 = bitcast i16* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 1
  %34 = shufflevector <8 x i16> %22, <8 x i16> %25, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %35 = shufflevector <8 x i16> %29, <8 x i16> %33, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %36 = shufflevector <8 x i16> %22, <8 x i16> %25, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 undef, i32 undef, i32 undef, i32 undef>
  %37 = shufflevector <8 x i16> %29, <8 x i16> %33, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 undef, i32 undef, i32 undef, i32 undef>
  %38 = bitcast <8 x i16> %34 to <4 x i32>
  %39 = bitcast <8 x i16> %35 to <4 x i32>
  %40 = shufflevector <4 x i32> %38, <4 x i32> %39, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %41 = bitcast <8 x i16> %36 to <4 x i32>
  %42 = bitcast <8 x i16> %37 to <4 x i32>
  %43 = shufflevector <4 x i32> %41, <4 x i32> %42, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %44 = shufflevector <4 x i32> %38, <4 x i32> %39, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %45 = bitcast <4 x i32> %40 to <2 x i64>
  %46 = bitcast <4 x i32> %40 to <16 x i8>
  %47 = shufflevector <16 x i8> %46, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %48 = bitcast <16 x i8> %47 to <2 x i64>
  %49 = bitcast <4 x i32> %44 to <2 x i64>
  %50 = bitcast <4 x i32> %44 to <16 x i8>
  %51 = shufflevector <16 x i8> %50, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %52 = bitcast <16 x i8> %51 to <2 x i64>
  %53 = bitcast <4 x i32> %43 to <2 x i64>
  %54 = bitcast <4 x i32> %43 to <16 x i8>
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %56 = bitcast <16 x i8> %55 to <2 x i64>
  %57 = shufflevector <2 x i64> %45, <2 x i64> %56, <2 x i32> <i32 0, i32 2>
  %58 = shufflevector <2 x i64> %48, <2 x i64> %53, <2 x i32> <i32 0, i32 2>
  %59 = shufflevector <2 x i64> %49, <2 x i64> %52, <2 x i32> <i32 0, i32 2>
  %60 = bitcast <2 x i64> %58 to <8 x i16>
  %61 = bitcast <2 x i64> %59 to <8 x i16>
  %62 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %60, <8 x i16> %61) #5
  %63 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %61, <8 x i16> %60) #5
  %64 = or <8 x i16> %63, %62
  %65 = bitcast <8 x i16> %64 to <16 x i8>
  %66 = shufflevector <16 x i8> %65, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %67 = bitcast <16 x i8> %66 to <8 x i16>
  %68 = icmp ugt <8 x i16> %64, %67
  %69 = select <8 x i1> %68, <8 x i16> %64, <8 x i16> %67
  %70 = icmp sgt <8 x i16> %69, %18
  %71 = sext <8 x i1> %70 to <8 x i16>
  %72 = shufflevector <2 x i64> %59, <2 x i64> %58, <2 x i32> <i32 1, i32 3>
  %73 = shufflevector <2 x i64> %59, <2 x i64> %58, <2 x i32> <i32 0, i32 2>
  %74 = bitcast <2 x i64> %73 to <8 x i16>
  %75 = bitcast <2 x i64> %72 to <8 x i16>
  %76 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %74, <8 x i16> %75) #5
  %77 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %75, <8 x i16> %74) #5
  %78 = or <8 x i16> %77, %76
  %79 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %78, <8 x i16> %78) #5
  %80 = lshr <8 x i16> %78, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %81 = bitcast <8 x i16> %80 to <16 x i8>
  %82 = shufflevector <16 x i8> %81, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %83 = bitcast <16 x i8> %82 to <8 x i16>
  %84 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %79, <8 x i16> %83) #5
  %85 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %84, <8 x i16> %10) #5
  %86 = bitcast <2 x i64> %57 to <8 x i16>
  %87 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %86, <8 x i16> %60) #5
  %88 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %60, <8 x i16> %86) #5
  %89 = or <8 x i16> %88, %87
  %90 = icmp ugt <8 x i16> %89, %64
  %91 = select <8 x i1> %90, <8 x i16> %89, <8 x i16> %64
  %92 = bitcast <8 x i16> %91 to <16 x i8>
  %93 = shufflevector <16 x i8> %92, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %94 = bitcast <16 x i8> %93 to <8 x i16>
  %95 = icmp ugt <8 x i16> %91, %94
  %96 = select <8 x i1> %95, <8 x i16> %91, <8 x i16> %94
  %97 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %96, <8 x i16> %14) #5
  %98 = or <8 x i16> %97, %85
  %99 = icmp eq <8 x i16> %98, zeroinitializer
  %100 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %60, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %101 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %61, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %102 = bitcast <8 x i16> %101 to <16 x i8>
  %103 = shufflevector <16 x i8> %102, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %104 = bitcast <8 x i16> %100 to <16 x i8>
  %105 = shufflevector <16 x i8> %104, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %106 = bitcast <16 x i8> %105 to <8 x i16>
  %107 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %100, <8 x i16> %106) #5
  %108 = icmp slt <8 x i16> %107, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %109 = select <8 x i1> %108, <8 x i16> %107, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %110 = icmp sgt <8 x i16> %109, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %111 = select <8 x i1> %110, <8 x i16> %109, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %112 = bitcast <16 x i8> %103 to <8 x i16>
  %113 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %112, <8 x i16> %101) #5
  %114 = and <8 x i16> %111, %71
  %115 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %114, <8 x i16> %113) #5
  %116 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %115, <8 x i16> %113) #5
  %117 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %116, <8 x i16> %113) #5
  %118 = icmp slt <8 x i16> %117, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %119 = select <8 x i1> %118, <8 x i16> %117, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %120 = icmp sgt <8 x i16> %119, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %121 = select <8 x i1> %120, <8 x i16> %119, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %122 = select <8 x i1> %99, <8 x i16> %121, <8 x i16> zeroinitializer
  %123 = icmp slt <8 x i16> %122, <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %124 = select <8 x i1> %123, <8 x i16> %122, <8 x i16> <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %125 = add nsw <8 x i16> %124, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %126 = ashr <8 x i16> %125, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %127 = icmp slt <8 x i16> %122, <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %128 = select <8 x i1> %127, <8 x i16> %122, <8 x i16> <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %129 = add nsw <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = ashr <8 x i16> %129, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %131 = add nsw <8 x i16> %126, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %132 = ashr <8 x i16> %131, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %133 = xor <8 x i16> %71, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %134 = and <8 x i16> %132, %133
  %135 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %100, <8 x i16> %134) #5
  %136 = bitcast <8 x i16> %135 to <2 x i64>
  %137 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %101, <8 x i16> %130) #5
  %138 = bitcast <8 x i16> %137 to <2 x i64>
  %139 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %112, <8 x i16> %126) #5
  %140 = bitcast <8 x i16> %139 to <2 x i64>
  %141 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %106, <8 x i16> %134) #5
  %142 = bitcast <8 x i16> %141 to <2 x i64>
  %143 = shufflevector <2 x i64> %136, <2 x i64> %142, <2 x i32> <i32 0, i32 2>
  %144 = shufflevector <2 x i64> %138, <2 x i64> %140, <2 x i32> <i32 0, i32 2>
  %145 = bitcast <2 x i64> %143 to <8 x i16>
  %146 = icmp slt <8 x i16> %145, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %148 = icmp sgt <8 x i16> %147, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %149 = select <8 x i1> %148, <8 x i16> %147, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %150 = bitcast <2 x i64> %144 to <8 x i16>
  %151 = icmp slt <8 x i16> %150, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %152 = select <8 x i1> %151, <8 x i16> %150, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %153 = icmp sgt <8 x i16> %152, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %154 = select <8 x i1> %153, <8 x i16> %152, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %155 = add nsw <8 x i16> %149, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %156 = bitcast <8 x i16> %155 to <2 x i64>
  %157 = add nsw <8 x i16> %154, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %158 = bitcast <8 x i16> %157 to <2 x i64>
  %159 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %86, <8 x i16> %61) #5
  %160 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %61, <8 x i16> %86) #5
  %161 = or <8 x i16> %160, %159
  %162 = icmp ugt <8 x i16> %161, %64
  %163 = select <8 x i1> %162, <8 x i16> %161, <8 x i16> %64
  %164 = bitcast <8 x i16> %163 to <16 x i8>
  %165 = shufflevector <16 x i8> %164, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %166 = bitcast <16 x i8> %165 to <8 x i16>
  %167 = icmp ugt <8 x i16> %163, %166
  %168 = select <8 x i1> %167, <8 x i16> %163, <8 x i16> %166
  %169 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %168, <8 x i16> <i16 4, i16 4, i16 4, i16 4, i16 0, i16 0, i16 0, i16 0>) #5
  %170 = icmp eq <8 x i16> %169, zeroinitializer
  %171 = and <8 x i1> %99, %170
  %172 = sext <8 x i1> %171 to <8 x i16>
  %173 = bitcast <8 x i16> %172 to <2 x i64>
  %174 = shufflevector <2 x i64> %173, <2 x i64> undef, <2 x i32> zeroinitializer
  %175 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %174, <2 x i64> %174) #5
  %176 = icmp eq i32 %175, 0
  br i1 %176, label %177, label %206

177:                                              ; preds = %5
  %178 = bitcast <2 x i64> %58 to <4 x i32>
  %179 = shufflevector <4 x i32> %178, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %180 = bitcast <2 x i64> %59 to <4 x i32>
  %181 = shufflevector <4 x i32> %180, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %182 = shl <8 x i16> %86, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %183 = bitcast <4 x i32> %181 to <8 x i16>
  %184 = add <8 x i16> %61, %60
  %185 = shl <8 x i16> %184, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %186 = add <8 x i16> %86, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %187 = add <8 x i16> %186, %182
  %188 = add <8 x i16> %187, %183
  %189 = add <8 x i16> %188, %185
  %190 = lshr <8 x i16> %189, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %191 = bitcast <4 x i32> %179 to <8 x i16>
  %192 = mul <8 x i16> %86, <i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2>
  %193 = add <8 x i16> %192, %191
  %194 = add <8 x i16> %193, %183
  %195 = add <8 x i16> %194, %189
  %196 = lshr <8 x i16> %195, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %197 = bitcast <8 x i16> %155 to <16 x i8>
  %198 = bitcast <8 x i16> %190 to <16 x i8>
  %199 = bitcast <2 x i64> %174 to <16 x i8>
  %200 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %197, <16 x i8> %198, <16 x i8> %199) #5
  %201 = bitcast <16 x i8> %200 to <2 x i64>
  %202 = bitcast <8 x i16> %157 to <16 x i8>
  %203 = bitcast <8 x i16> %196 to <16 x i8>
  %204 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %202, <16 x i8> %203, <16 x i8> %199) #5
  %205 = bitcast <16 x i8> %204 to <2 x i64>
  br label %206

206:                                              ; preds = %177, %5
  %207 = phi <2 x i64> [ %201, %177 ], [ %156, %5 ]
  %208 = phi <2 x i64> [ %205, %177 ], [ %158, %5 ]
  %209 = bitcast <2 x i64> %207 to <8 x i16>
  %210 = bitcast <2 x i64> %208 to <8 x i16>
  %211 = shufflevector <8 x i16> %209, <8 x i16> %210, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %212 = shufflevector <8 x i16> %210, <8 x i16> %209, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = bitcast <8 x i16> %211 to <4 x i32>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = shufflevector <4 x i32> %213, <4 x i32> %214, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %216 = bitcast <4 x i32> %215 to <2 x i64>
  %217 = shufflevector <4 x i32> %213, <4 x i32> %214, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %218 = bitcast <4 x i32> %217 to <2 x i64>
  %219 = getelementptr inbounds i8, i8* %0, i64 -4
  %220 = bitcast i8* %219 to i16*
  %221 = extractelement <2 x i64> %216, i32 0
  %222 = bitcast i8* %219 to i64*
  store i64 %221, i64* %222, align 1
  %223 = getelementptr inbounds i16, i16* %220, i64 %6
  %224 = bitcast <4 x i32> %215 to <4 x float>
  %225 = shufflevector <4 x float> %224, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %226 = bitcast i16* %223 to <2 x float>*
  store <2 x float> %225, <2 x float>* %226, align 1
  %227 = getelementptr inbounds i16, i16* %220, i64 %26
  %228 = extractelement <2 x i64> %218, i32 0
  %229 = bitcast i16* %227 to i64*
  store i64 %228, i64* %229, align 1
  %230 = getelementptr inbounds i16, i16* %220, i64 %30
  %231 = bitcast <4 x i32> %217 to <4 x float>
  %232 = shufflevector <4 x float> %231, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %233 = bitcast i16* %230 to <2 x float>*
  store <2 x float> %232, <2 x float>* %233, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE9Vertical8EPvliii(i8* nocapture, i64, i32, i32, i32) #2 align 2 {
  %6 = sdiv i64 %1, 2
  %7 = shl i32 %2, 2
  %8 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %7, i32 0
  %9 = bitcast <4 x i32> %8 to <8 x i16>
  %10 = shufflevector <8 x i16> %9, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %11 = shl i32 %3, 2
  %12 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <8 x i16>
  %14 = shufflevector <8 x i16> %13, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %15 = shl i32 %4, 2
  %16 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %15, i32 0
  %17 = bitcast <4 x i32> %16 to <8 x i16>
  %18 = shufflevector <8 x i16> %17, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %19 = getelementptr inbounds i8, i8* %0, i64 -8
  %20 = bitcast i8* %19 to i16*
  %21 = bitcast i8* %19 to <2 x i64>*
  %22 = bitcast i8* %19 to <8 x i16>*
  %23 = load <8 x i16>, <8 x i16>* %22, align 1
  %24 = getelementptr inbounds i16, i16* %20, i64 %6
  %25 = bitcast i16* %24 to <2 x i64>*
  %26 = bitcast i16* %24 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 1
  %28 = shl nsw i64 %6, 1
  %29 = getelementptr inbounds i16, i16* %20, i64 %28
  %30 = bitcast i16* %29 to <2 x i64>*
  %31 = bitcast i16* %29 to <8 x i16>*
  %32 = load <8 x i16>, <8 x i16>* %31, align 1
  %33 = mul nsw i64 %6, 3
  %34 = getelementptr inbounds i16, i16* %20, i64 %33
  %35 = bitcast i16* %34 to <2 x i64>*
  %36 = bitcast i16* %34 to <8 x i16>*
  %37 = load <8 x i16>, <8 x i16>* %36, align 1
  %38 = shufflevector <8 x i16> %23, <8 x i16> %27, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %39 = shufflevector <8 x i16> %32, <8 x i16> %37, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %40 = shufflevector <8 x i16> %23, <8 x i16> %27, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %41 = shufflevector <8 x i16> %32, <8 x i16> %37, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %42 = bitcast <8 x i16> %38 to <4 x i32>
  %43 = bitcast <8 x i16> %39 to <4 x i32>
  %44 = shufflevector <4 x i32> %42, <4 x i32> %43, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %45 = bitcast <8 x i16> %40 to <4 x i32>
  %46 = bitcast <8 x i16> %41 to <4 x i32>
  %47 = shufflevector <4 x i32> %45, <4 x i32> %46, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %48 = shufflevector <4 x i32> %42, <4 x i32> %43, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %49 = shufflevector <4 x i32> %45, <4 x i32> %46, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %50 = bitcast <4 x i32> %44 to <2 x i64>
  %51 = bitcast <4 x i32> %44 to <16 x i8>
  %52 = shufflevector <16 x i8> %51, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %53 = bitcast <16 x i8> %52 to <2 x i64>
  %54 = bitcast <4 x i32> %48 to <2 x i64>
  %55 = bitcast <4 x i32> %48 to <16 x i8>
  %56 = shufflevector <16 x i8> %55, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %57 = bitcast <16 x i8> %56 to <2 x i64>
  %58 = bitcast <4 x i32> %47 to <2 x i64>
  %59 = bitcast <4 x i32> %47 to <16 x i8>
  %60 = shufflevector <16 x i8> %59, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %61 = bitcast <16 x i8> %60 to <2 x i64>
  %62 = bitcast <4 x i32> %49 to <2 x i64>
  %63 = bitcast <4 x i32> %49 to <16 x i8>
  %64 = shufflevector <16 x i8> %63, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %65 = bitcast <16 x i8> %64 to <2 x i64>
  %66 = shufflevector <2 x i64> %50, <2 x i64> %65, <2 x i32> <i32 0, i32 2>
  %67 = shufflevector <2 x i64> %53, <2 x i64> %62, <2 x i32> <i32 0, i32 2>
  %68 = shufflevector <2 x i64> %54, <2 x i64> %61, <2 x i32> <i32 0, i32 2>
  %69 = shufflevector <2 x i64> %57, <2 x i64> %58, <2 x i32> <i32 0, i32 2>
  %70 = bitcast <2 x i64> %68 to <8 x i16>
  %71 = bitcast <2 x i64> %69 to <8 x i16>
  %72 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %70, <8 x i16> %71) #5
  %73 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %71, <8 x i16> %70) #5
  %74 = or <8 x i16> %73, %72
  %75 = bitcast <8 x i16> %74 to <16 x i8>
  %76 = shufflevector <16 x i8> %75, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %77 = bitcast <16 x i8> %76 to <8 x i16>
  %78 = icmp ugt <8 x i16> %74, %77
  %79 = select <8 x i1> %78, <8 x i16> %74, <8 x i16> %77
  %80 = icmp sgt <8 x i16> %79, %18
  %81 = sext <8 x i1> %80 to <8 x i16>
  %82 = shufflevector <2 x i64> %69, <2 x i64> %68, <2 x i32> <i32 1, i32 3>
  %83 = shufflevector <2 x i64> %69, <2 x i64> %68, <2 x i32> <i32 0, i32 2>
  %84 = bitcast <2 x i64> %83 to <8 x i16>
  %85 = bitcast <2 x i64> %82 to <8 x i16>
  %86 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %84, <8 x i16> %85) #5
  %87 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %85, <8 x i16> %84) #5
  %88 = or <8 x i16> %87, %86
  %89 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %88, <8 x i16> %88) #5
  %90 = lshr <8 x i16> %88, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %91 = bitcast <8 x i16> %90 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %93 = bitcast <16 x i8> %92 to <8 x i16>
  %94 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %89, <8 x i16> %93) #5
  %95 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %94, <8 x i16> %10) #5
  %96 = bitcast <2 x i64> %67 to <8 x i16>
  %97 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %96, <8 x i16> %70) #5
  %98 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %70, <8 x i16> %96) #5
  %99 = or <8 x i16> %98, %97
  %100 = icmp ugt <8 x i16> %99, %74
  %101 = select <8 x i1> %100, <8 x i16> %99, <8 x i16> %74
  %102 = bitcast <2 x i64> %66 to <8 x i16>
  %103 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %102, <8 x i16> %96) #5
  %104 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %96, <8 x i16> %102) #5
  %105 = or <8 x i16> %104, %103
  %106 = icmp ugt <8 x i16> %101, %105
  %107 = select <8 x i1> %106, <8 x i16> %101, <8 x i16> %105
  %108 = bitcast <8 x i16> %107 to <16 x i8>
  %109 = shufflevector <16 x i8> %108, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %110 = bitcast <16 x i8> %109 to <8 x i16>
  %111 = icmp ugt <8 x i16> %107, %110
  %112 = select <8 x i1> %111, <8 x i16> %107, <8 x i16> %110
  %113 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %112, <8 x i16> %14) #5
  %114 = or <8 x i16> %113, %95
  %115 = icmp eq <8 x i16> %114, zeroinitializer
  %116 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %70, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %117 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %71, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %118 = bitcast <8 x i16> %117 to <16 x i8>
  %119 = shufflevector <16 x i8> %118, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %120 = bitcast <8 x i16> %116 to <16 x i8>
  %121 = shufflevector <16 x i8> %120, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %122 = bitcast <16 x i8> %121 to <8 x i16>
  %123 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %116, <8 x i16> %122) #5
  %124 = icmp slt <8 x i16> %123, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %125 = select <8 x i1> %124, <8 x i16> %123, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %126 = icmp sgt <8 x i16> %125, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %127 = select <8 x i1> %126, <8 x i16> %125, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %128 = bitcast <16 x i8> %119 to <8 x i16>
  %129 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %128, <8 x i16> %117) #5
  %130 = and <8 x i16> %127, %81
  %131 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %130, <8 x i16> %129) #5
  %132 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %131, <8 x i16> %129) #5
  %133 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %132, <8 x i16> %129) #5
  %134 = icmp slt <8 x i16> %133, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %135 = select <8 x i1> %134, <8 x i16> %133, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %136 = icmp sgt <8 x i16> %135, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %137 = select <8 x i1> %136, <8 x i16> %135, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %138 = select <8 x i1> %115, <8 x i16> %137, <8 x i16> zeroinitializer
  %139 = icmp slt <8 x i16> %138, <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %140 = select <8 x i1> %139, <8 x i16> %138, <8 x i16> <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %141 = add nsw <8 x i16> %140, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %142 = ashr <8 x i16> %141, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %143 = icmp slt <8 x i16> %138, <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %144 = select <8 x i1> %143, <8 x i16> %138, <8 x i16> <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %145 = add nsw <8 x i16> %144, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %146 = ashr <8 x i16> %145, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %147 = add nsw <8 x i16> %142, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %148 = ashr <8 x i16> %147, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %149 = xor <8 x i16> %81, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %150 = and <8 x i16> %148, %149
  %151 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %116, <8 x i16> %150) #5
  %152 = bitcast <8 x i16> %151 to <2 x i64>
  %153 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %117, <8 x i16> %146) #5
  %154 = bitcast <8 x i16> %153 to <2 x i64>
  %155 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %128, <8 x i16> %142) #5
  %156 = bitcast <8 x i16> %155 to <2 x i64>
  %157 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %122, <8 x i16> %150) #5
  %158 = bitcast <8 x i16> %157 to <2 x i64>
  %159 = shufflevector <2 x i64> %152, <2 x i64> %158, <2 x i32> <i32 0, i32 2>
  %160 = shufflevector <2 x i64> %154, <2 x i64> %156, <2 x i32> <i32 0, i32 2>
  %161 = bitcast <2 x i64> %159 to <8 x i16>
  %162 = icmp slt <8 x i16> %161, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %163 = select <8 x i1> %162, <8 x i16> %161, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %164 = icmp sgt <8 x i16> %163, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %165 = select <8 x i1> %164, <8 x i16> %163, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %166 = bitcast <2 x i64> %160 to <8 x i16>
  %167 = icmp slt <8 x i16> %166, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %168 = select <8 x i1> %167, <8 x i16> %166, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %169 = icmp sgt <8 x i16> %168, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %170 = select <8 x i1> %169, <8 x i16> %168, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %171 = add nsw <8 x i16> %165, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %172 = bitcast <8 x i16> %171 to <2 x i64>
  %173 = add nsw <8 x i16> %170, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %174 = bitcast <8 x i16> %173 to <2 x i64>
  %175 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %96, <8 x i16> %71) #5
  %176 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %71, <8 x i16> %96) #5
  %177 = or <8 x i16> %176, %175
  %178 = icmp ugt <8 x i16> %177, %74
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %74
  %180 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %102, <8 x i16> %71) #5
  %181 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %71, <8 x i16> %102) #5
  %182 = or <8 x i16> %181, %180
  %183 = icmp ugt <8 x i16> %179, %182
  %184 = select <8 x i1> %183, <8 x i16> %179, <8 x i16> %182
  %185 = bitcast <8 x i16> %184 to <16 x i8>
  %186 = shufflevector <16 x i8> %185, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %187 = bitcast <16 x i8> %186 to <8 x i16>
  %188 = icmp ugt <8 x i16> %184, %187
  %189 = select <8 x i1> %188, <8 x i16> %184, <8 x i16> %187
  %190 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %189, <8 x i16> <i16 4, i16 4, i16 4, i16 4, i16 0, i16 0, i16 0, i16 0>) #5
  %191 = icmp eq <8 x i16> %190, zeroinitializer
  %192 = and <8 x i1> %115, %191
  %193 = sext <8 x i1> %192 to <8 x i16>
  %194 = bitcast <8 x i16> %193 to <2 x i64>
  %195 = shufflevector <2 x i64> %194, <2 x i64> undef, <2 x i32> zeroinitializer
  %196 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %195, <2 x i64> %195) #5
  %197 = icmp eq i32 %196, 0
  br i1 %197, label %198, label %241

198:                                              ; preds = %5
  %199 = bitcast <2 x i64> %67 to <4 x i32>
  %200 = shufflevector <4 x i32> %199, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %201 = bitcast <2 x i64> %68 to <4 x i32>
  %202 = shufflevector <4 x i32> %201, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %203 = bitcast <2 x i64> %69 to <4 x i32>
  %204 = shufflevector <4 x i32> %203, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %205 = shl <8 x i16> %102, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %206 = bitcast <4 x i32> %204 to <8 x i16>
  %207 = shl <8 x i16> %96, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %208 = add <8 x i16> %70, %102
  %209 = add <8 x i16> %208, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %210 = add <8 x i16> %209, %71
  %211 = add <8 x i16> %210, %205
  %212 = add <8 x i16> %211, %207
  %213 = add <8 x i16> %212, %206
  %214 = lshr <8 x i16> %213, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %215 = bitcast <4 x i32> %202 to <8 x i16>
  %216 = add <8 x i16> %102, %96
  %217 = sub <8 x i16> %70, %216
  %218 = add <8 x i16> %217, %215
  %219 = add <8 x i16> %218, %213
  %220 = lshr <8 x i16> %219, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %221 = bitcast <4 x i32> %200 to <8 x i16>
  %222 = sub <8 x i16> %71, %208
  %223 = add <8 x i16> %222, %221
  %224 = add <8 x i16> %223, %219
  %225 = lshr <8 x i16> %224, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %226 = bitcast <2 x i64> %67 to <16 x i8>
  %227 = bitcast <8 x i16> %214 to <16 x i8>
  %228 = bitcast <2 x i64> %195 to <16 x i8>
  %229 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %226, <16 x i8> %227, <16 x i8> %228) #5
  %230 = bitcast <16 x i8> %229 to <2 x i64>
  %231 = bitcast <8 x i16> %171 to <16 x i8>
  %232 = bitcast <8 x i16> %220 to <16 x i8>
  %233 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %231, <16 x i8> %232, <16 x i8> %228) #5
  %234 = bitcast <16 x i8> %233 to <2 x i64>
  %235 = bitcast <8 x i16> %173 to <16 x i8>
  %236 = bitcast <8 x i16> %225 to <16 x i8>
  %237 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %235, <16 x i8> %236, <16 x i8> %228) #5
  %238 = bitcast <16 x i8> %237 to <2 x i64>
  %239 = shufflevector <16 x i8> %229, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %240 = bitcast <16 x i8> %239 to <2 x i64>
  br label %241

241:                                              ; preds = %198, %5
  %242 = phi <2 x i64> [ %230, %198 ], [ %53, %5 ]
  %243 = phi <2 x i64> [ %240, %198 ], [ %62, %5 ]
  %244 = phi <2 x i64> [ %234, %198 ], [ %172, %5 ]
  %245 = phi <2 x i64> [ %238, %198 ], [ %174, %5 ]
  %246 = bitcast <2 x i64> %245 to <16 x i8>
  %247 = shufflevector <16 x i8> %246, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %248 = bitcast <2 x i64> %244 to <16 x i8>
  %249 = shufflevector <16 x i8> %248, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %250 = bitcast <4 x i32> %44 to <8 x i16>
  %251 = bitcast <2 x i64> %242 to <8 x i16>
  %252 = shufflevector <8 x i16> %250, <8 x i16> %251, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %253 = bitcast <2 x i64> %244 to <8 x i16>
  %254 = bitcast <2 x i64> %245 to <8 x i16>
  %255 = shufflevector <8 x i16> %253, <8 x i16> %254, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %256 = bitcast <16 x i8> %247 to <8 x i16>
  %257 = bitcast <16 x i8> %249 to <8 x i16>
  %258 = shufflevector <8 x i16> %256, <8 x i16> %257, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %259 = bitcast <2 x i64> %243 to <8 x i16>
  %260 = bitcast <16 x i8> %64 to <8 x i16>
  %261 = shufflevector <8 x i16> %259, <8 x i16> %260, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %262 = bitcast <8 x i16> %252 to <4 x i32>
  %263 = bitcast <8 x i16> %255 to <4 x i32>
  %264 = shufflevector <4 x i32> %262, <4 x i32> %263, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %265 = bitcast <4 x i32> %264 to <2 x i64>
  %266 = bitcast <8 x i16> %258 to <4 x i32>
  %267 = bitcast <8 x i16> %261 to <4 x i32>
  %268 = shufflevector <4 x i32> %266, <4 x i32> %267, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %269 = bitcast <4 x i32> %268 to <2 x i64>
  %270 = shufflevector <4 x i32> %262, <4 x i32> %263, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %271 = bitcast <4 x i32> %270 to <2 x i64>
  %272 = shufflevector <4 x i32> %266, <4 x i32> %267, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %273 = bitcast <4 x i32> %272 to <2 x i64>
  %274 = shufflevector <2 x i64> %265, <2 x i64> %269, <2 x i32> <i32 0, i32 2>
  %275 = shufflevector <2 x i64> %265, <2 x i64> %269, <2 x i32> <i32 1, i32 3>
  %276 = shufflevector <2 x i64> %271, <2 x i64> %273, <2 x i32> <i32 0, i32 2>
  %277 = shufflevector <2 x i64> %271, <2 x i64> %273, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %274, <2 x i64>* %21, align 1
  store <2 x i64> %275, <2 x i64>* %25, align 1
  store <2 x i64> %276, <2 x i64>* %30, align 1
  store <2 x i64> %277, <2 x i64>* %35, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_122LoopFilterFuncs_SSE4_1ILi10EE10Vertical14EPvliii(i8* nocapture, i64, i32, i32, i32) #2 align 2 {
  %6 = sdiv i64 %1, 2
  %7 = shl i32 %2, 2
  %8 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %7, i32 0
  %9 = bitcast <4 x i32> %8 to <8 x i16>
  %10 = shufflevector <8 x i16> %9, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %11 = shl i32 %3, 2
  %12 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <8 x i16>
  %14 = shufflevector <8 x i16> %13, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %15 = shl i32 %4, 2
  %16 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %15, i32 0
  %17 = bitcast <4 x i32> %16 to <8 x i16>
  %18 = shufflevector <8 x i16> %17, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %19 = getelementptr inbounds i8, i8* %0, i64 -16
  %20 = bitcast i8* %19 to i16*
  %21 = bitcast i8* %19 to <2 x i64>*
  %22 = bitcast i8* %19 to <8 x i16>*
  %23 = load <8 x i16>, <8 x i16>* %22, align 1
  %24 = getelementptr inbounds i16, i16* %20, i64 %6
  %25 = bitcast i16* %24 to <2 x i64>*
  %26 = bitcast i16* %24 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 1
  %28 = shl nsw i64 %6, 1
  %29 = getelementptr inbounds i16, i16* %20, i64 %28
  %30 = bitcast i16* %29 to <2 x i64>*
  %31 = bitcast i16* %29 to <8 x i16>*
  %32 = load <8 x i16>, <8 x i16>* %31, align 1
  %33 = mul nsw i64 %6, 3
  %34 = getelementptr inbounds i16, i16* %20, i64 %33
  %35 = bitcast i16* %34 to <2 x i64>*
  %36 = bitcast i16* %34 to <8 x i16>*
  %37 = load <8 x i16>, <8 x i16>* %36, align 1
  %38 = shufflevector <8 x i16> %23, <8 x i16> %27, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %39 = shufflevector <8 x i16> %32, <8 x i16> %37, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %40 = shufflevector <8 x i16> %23, <8 x i16> %27, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %41 = shufflevector <8 x i16> %32, <8 x i16> %37, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %42 = bitcast <8 x i16> %38 to <4 x i32>
  %43 = bitcast <8 x i16> %39 to <4 x i32>
  %44 = shufflevector <4 x i32> %42, <4 x i32> %43, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %45 = bitcast <8 x i16> %40 to <4 x i32>
  %46 = bitcast <8 x i16> %41 to <4 x i32>
  %47 = shufflevector <4 x i32> %45, <4 x i32> %46, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %48 = shufflevector <4 x i32> %42, <4 x i32> %43, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %49 = shufflevector <4 x i32> %45, <4 x i32> %46, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %50 = bitcast <4 x i32> %44 to <2 x i64>
  %51 = bitcast <4 x i32> %44 to <16 x i8>
  %52 = shufflevector <16 x i8> %51, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %53 = bitcast <16 x i8> %52 to <2 x i64>
  %54 = bitcast <4 x i32> %48 to <2 x i64>
  %55 = bitcast <4 x i32> %48 to <16 x i8>
  %56 = shufflevector <16 x i8> %55, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %57 = bitcast <16 x i8> %56 to <2 x i64>
  %58 = bitcast <4 x i32> %47 to <2 x i64>
  %59 = bitcast <4 x i32> %47 to <16 x i8>
  %60 = shufflevector <16 x i8> %59, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %61 = bitcast <16 x i8> %60 to <2 x i64>
  %62 = bitcast <4 x i32> %49 to <2 x i64>
  %63 = bitcast <4 x i32> %49 to <16 x i8>
  %64 = shufflevector <16 x i8> %63, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %65 = bitcast <16 x i8> %64 to <2 x i64>
  %66 = bitcast i8* %0 to i16*
  %67 = bitcast i8* %0 to <2 x i64>*
  %68 = bitcast i8* %0 to <8 x i16>*
  %69 = load <8 x i16>, <8 x i16>* %68, align 1
  %70 = getelementptr inbounds i16, i16* %66, i64 %6
  %71 = bitcast i16* %70 to <2 x i64>*
  %72 = bitcast i16* %70 to <8 x i16>*
  %73 = load <8 x i16>, <8 x i16>* %72, align 1
  %74 = getelementptr inbounds i16, i16* %66, i64 %28
  %75 = bitcast i16* %74 to <2 x i64>*
  %76 = bitcast i16* %74 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 1
  %78 = getelementptr inbounds i16, i16* %66, i64 %33
  %79 = bitcast i16* %78 to <2 x i64>*
  %80 = bitcast i16* %78 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 1
  %82 = shufflevector <8 x i16> %69, <8 x i16> %73, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %83 = shufflevector <8 x i16> %77, <8 x i16> %81, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %84 = shufflevector <8 x i16> %69, <8 x i16> %73, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %85 = shufflevector <8 x i16> %77, <8 x i16> %81, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %86 = bitcast <8 x i16> %82 to <4 x i32>
  %87 = bitcast <8 x i16> %83 to <4 x i32>
  %88 = shufflevector <4 x i32> %86, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %89 = bitcast <8 x i16> %84 to <4 x i32>
  %90 = bitcast <8 x i16> %85 to <4 x i32>
  %91 = shufflevector <4 x i32> %89, <4 x i32> %90, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %92 = shufflevector <4 x i32> %86, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %93 = shufflevector <4 x i32> %89, <4 x i32> %90, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %94 = bitcast <4 x i32> %88 to <2 x i64>
  %95 = bitcast <4 x i32> %88 to <16 x i8>
  %96 = shufflevector <16 x i8> %95, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %97 = bitcast <16 x i8> %96 to <2 x i64>
  %98 = bitcast <4 x i32> %92 to <2 x i64>
  %99 = bitcast <4 x i32> %92 to <16 x i8>
  %100 = shufflevector <16 x i8> %99, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %101 = bitcast <16 x i8> %100 to <2 x i64>
  %102 = bitcast <4 x i32> %91 to <2 x i64>
  %103 = bitcast <4 x i32> %91 to <16 x i8>
  %104 = shufflevector <16 x i8> %103, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %105 = bitcast <16 x i8> %104 to <2 x i64>
  %106 = bitcast <4 x i32> %93 to <2 x i64>
  %107 = bitcast <4 x i32> %93 to <16 x i8>
  %108 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %109 = bitcast <16 x i8> %108 to <2 x i64>
  %110 = shufflevector <2 x i64> %50, <2 x i64> %109, <2 x i32> <i32 0, i32 2>
  %111 = shufflevector <2 x i64> %53, <2 x i64> %106, <2 x i32> <i32 0, i32 2>
  %112 = shufflevector <2 x i64> %54, <2 x i64> %105, <2 x i32> <i32 0, i32 2>
  %113 = shufflevector <2 x i64> %57, <2 x i64> %102, <2 x i32> <i32 0, i32 2>
  %114 = shufflevector <2 x i64> %58, <2 x i64> %101, <2 x i32> <i32 0, i32 2>
  %115 = shufflevector <2 x i64> %61, <2 x i64> %98, <2 x i32> <i32 0, i32 2>
  %116 = shufflevector <2 x i64> %62, <2 x i64> %97, <2 x i32> <i32 0, i32 2>
  %117 = shufflevector <2 x i64> %65, <2 x i64> %94, <2 x i32> <i32 0, i32 2>
  %118 = bitcast <2 x i64> %116 to <8 x i16>
  %119 = bitcast <2 x i64> %117 to <8 x i16>
  %120 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %118, <8 x i16> %119) #5
  %121 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %119, <8 x i16> %118) #5
  %122 = or <8 x i16> %121, %120
  %123 = bitcast <8 x i16> %122 to <16 x i8>
  %124 = shufflevector <16 x i8> %123, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %125 = bitcast <16 x i8> %124 to <8 x i16>
  %126 = icmp ugt <8 x i16> %122, %125
  %127 = select <8 x i1> %126, <8 x i16> %122, <8 x i16> %125
  %128 = icmp sgt <8 x i16> %127, %18
  %129 = sext <8 x i1> %128 to <8 x i16>
  %130 = shufflevector <2 x i64> %117, <2 x i64> %116, <2 x i32> <i32 1, i32 3>
  %131 = shufflevector <2 x i64> %117, <2 x i64> %116, <2 x i32> <i32 0, i32 2>
  %132 = bitcast <2 x i64> %131 to <8 x i16>
  %133 = bitcast <2 x i64> %130 to <8 x i16>
  %134 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %132, <8 x i16> %133) #5
  %135 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %133, <8 x i16> %132) #5
  %136 = or <8 x i16> %135, %134
  %137 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %136, <8 x i16> %136) #5
  %138 = lshr <8 x i16> %136, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %139 = bitcast <8 x i16> %138 to <16 x i8>
  %140 = shufflevector <16 x i8> %139, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %141 = bitcast <16 x i8> %140 to <8 x i16>
  %142 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %137, <8 x i16> %141) #5
  %143 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %142, <8 x i16> %10) #5
  %144 = bitcast <2 x i64> %115 to <8 x i16>
  %145 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %144, <8 x i16> %118) #5
  %146 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %118, <8 x i16> %144) #5
  %147 = or <8 x i16> %146, %145
  %148 = icmp ugt <8 x i16> %147, %122
  %149 = select <8 x i1> %148, <8 x i16> %147, <8 x i16> %122
  %150 = bitcast <2 x i64> %114 to <8 x i16>
  %151 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %150, <8 x i16> %144) #5
  %152 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %144, <8 x i16> %150) #5
  %153 = or <8 x i16> %152, %151
  %154 = icmp ugt <8 x i16> %149, %153
  %155 = select <8 x i1> %154, <8 x i16> %149, <8 x i16> %153
  %156 = bitcast <8 x i16> %155 to <16 x i8>
  %157 = shufflevector <16 x i8> %156, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %158 = bitcast <16 x i8> %157 to <8 x i16>
  %159 = icmp ugt <8 x i16> %155, %158
  %160 = select <8 x i1> %159, <8 x i16> %155, <8 x i16> %158
  %161 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %160, <8 x i16> %14) #5
  %162 = or <8 x i16> %161, %143
  %163 = icmp eq <8 x i16> %162, zeroinitializer
  %164 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %118, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %165 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %119, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>) #5
  %166 = bitcast <8 x i16> %165 to <16 x i8>
  %167 = shufflevector <16 x i8> %166, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %168 = bitcast <8 x i16> %164 to <16 x i8>
  %169 = shufflevector <16 x i8> %168, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %170 = bitcast <16 x i8> %169 to <8 x i16>
  %171 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %164, <8 x i16> %170) #5
  %172 = icmp slt <8 x i16> %171, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %173 = select <8 x i1> %172, <8 x i16> %171, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %174 = icmp sgt <8 x i16> %173, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %175 = select <8 x i1> %174, <8 x i16> %173, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %176 = bitcast <16 x i8> %167 to <8 x i16>
  %177 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %176, <8 x i16> %165) #5
  %178 = and <8 x i16> %175, %129
  %179 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %178, <8 x i16> %177) #5
  %180 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %179, <8 x i16> %177) #5
  %181 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %180, <8 x i16> %177) #5
  %182 = icmp slt <8 x i16> %181, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %183 = select <8 x i1> %182, <8 x i16> %181, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %184 = icmp sgt <8 x i16> %183, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %185 = select <8 x i1> %184, <8 x i16> %183, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %186 = select <8 x i1> %163, <8 x i16> %185, <8 x i16> zeroinitializer
  %187 = icmp slt <8 x i16> %186, <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %188 = select <8 x i1> %187, <8 x i16> %186, <8 x i16> <i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507, i16 507>
  %189 = add nsw <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = ashr <8 x i16> %189, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %191 = icmp slt <8 x i16> %186, <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %192 = select <8 x i1> %191, <8 x i16> %186, <8 x i16> <i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508, i16 508>
  %193 = add nsw <8 x i16> %192, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %194 = ashr <8 x i16> %193, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %195 = add nsw <8 x i16> %190, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %196 = ashr <8 x i16> %195, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %197 = xor <8 x i16> %129, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %198 = and <8 x i16> %196, %197
  %199 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %164, <8 x i16> %198) #5
  %200 = bitcast <8 x i16> %199 to <2 x i64>
  %201 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %165, <8 x i16> %194) #5
  %202 = bitcast <8 x i16> %201 to <2 x i64>
  %203 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %176, <8 x i16> %190) #5
  %204 = bitcast <8 x i16> %203 to <2 x i64>
  %205 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %170, <8 x i16> %198) #5
  %206 = bitcast <8 x i16> %205 to <2 x i64>
  %207 = shufflevector <2 x i64> %200, <2 x i64> %206, <2 x i32> <i32 0, i32 2>
  %208 = shufflevector <2 x i64> %202, <2 x i64> %204, <2 x i32> <i32 0, i32 2>
  %209 = bitcast <2 x i64> %207 to <8 x i16>
  %210 = icmp slt <8 x i16> %209, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %211 = select <8 x i1> %210, <8 x i16> %209, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %212 = icmp sgt <8 x i16> %211, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %213 = select <8 x i1> %212, <8 x i16> %211, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %214 = bitcast <2 x i64> %208 to <8 x i16>
  %215 = icmp slt <8 x i16> %214, <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %216 = select <8 x i1> %215, <8 x i16> %214, <8 x i16> <i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511, i16 511>
  %217 = icmp sgt <8 x i16> %216, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %218 = select <8 x i1> %217, <8 x i16> %216, <8 x i16> <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %219 = add nsw <8 x i16> %213, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %220 = add nsw <8 x i16> %218, <i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512, i16 512>
  %221 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %144, <8 x i16> %119) #5
  %222 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %119, <8 x i16> %144) #5
  %223 = or <8 x i16> %222, %221
  %224 = icmp ugt <8 x i16> %223, %122
  %225 = select <8 x i1> %224, <8 x i16> %223, <8 x i16> %122
  %226 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %150, <8 x i16> %119) #5
  %227 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %119, <8 x i16> %150) #5
  %228 = or <8 x i16> %227, %226
  %229 = icmp ugt <8 x i16> %225, %228
  %230 = select <8 x i1> %229, <8 x i16> %225, <8 x i16> %228
  %231 = bitcast <8 x i16> %230 to <16 x i8>
  %232 = shufflevector <16 x i8> %231, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %233 = bitcast <16 x i8> %232 to <8 x i16>
  %234 = icmp ugt <8 x i16> %230, %233
  %235 = select <8 x i1> %234, <8 x i16> %230, <8 x i16> %233
  %236 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %235, <8 x i16> <i16 4, i16 4, i16 4, i16 4, i16 0, i16 0, i16 0, i16 0>) #5
  %237 = icmp eq <8 x i16> %236, zeroinitializer
  %238 = and <8 x i1> %163, %237
  %239 = sext <8 x i1> %238 to <8 x i16>
  %240 = bitcast <8 x i16> %239 to <2 x i64>
  %241 = shufflevector <2 x i64> %240, <2 x i64> undef, <2 x i32> zeroinitializer
  %242 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %241, <2 x i64> %241) #5
  %243 = icmp eq i32 %242, 0
  br i1 %243, label %248, label %244

244:                                              ; preds = %5
  %245 = bitcast <8 x i16> %220 to <2 x i64>
  %246 = bitcast <8 x i16> %219 to <2 x i64>
  %247 = bitcast <2 x i64> %111 to <8 x i16>
  br label %386

248:                                              ; preds = %5
  %249 = bitcast <2 x i64> %112 to <8 x i16>
  %250 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %249, <8 x i16> %119) #5
  %251 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %119, <8 x i16> %249) #5
  %252 = or <8 x i16> %251, %250
  %253 = bitcast <2 x i64> %113 to <8 x i16>
  %254 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %253, <8 x i16> %119) #5
  %255 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %119, <8 x i16> %253) #5
  %256 = or <8 x i16> %255, %254
  %257 = icmp ugt <8 x i16> %252, %256
  %258 = select <8 x i1> %257, <8 x i16> %252, <8 x i16> %256
  %259 = bitcast <2 x i64> %111 to <8 x i16>
  %260 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %259, <8 x i16> %119) #5
  %261 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %119, <8 x i16> %259) #5
  %262 = or <8 x i16> %261, %260
  %263 = icmp ugt <8 x i16> %258, %262
  %264 = select <8 x i1> %263, <8 x i16> %258, <8 x i16> %262
  %265 = bitcast <8 x i16> %264 to <16 x i8>
  %266 = shufflevector <16 x i8> %265, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %267 = bitcast <16 x i8> %266 to <8 x i16>
  %268 = icmp ugt <8 x i16> %264, %267
  %269 = select <8 x i1> %268, <8 x i16> %264, <8 x i16> %267
  %270 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %269, <8 x i16> <i16 4, i16 4, i16 4, i16 4, i16 0, i16 0, i16 0, i16 0>) #5
  %271 = icmp eq <8 x i16> %270, zeroinitializer
  %272 = sext <8 x i1> %271 to <8 x i16>
  %273 = bitcast <8 x i16> %272 to <2 x i64>
  %274 = and <2 x i64> %241, %273
  %275 = shufflevector <2 x i64> %274, <2 x i64> undef, <2 x i32> zeroinitializer
  %276 = bitcast <2 x i64> %115 to <4 x i32>
  %277 = shufflevector <4 x i32> %276, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %278 = bitcast <2 x i64> %116 to <4 x i32>
  %279 = shufflevector <4 x i32> %278, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %280 = bitcast <2 x i64> %117 to <4 x i32>
  %281 = shufflevector <4 x i32> %280, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %282 = shl <8 x i16> %150, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %283 = bitcast <4 x i32> %281 to <8 x i16>
  %284 = shl <8 x i16> %144, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %285 = add <8 x i16> %118, %150
  %286 = add <8 x i16> %285, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %287 = add <8 x i16> %286, %119
  %288 = add <8 x i16> %287, %284
  %289 = add <8 x i16> %288, %283
  %290 = add <8 x i16> %289, %282
  %291 = lshr <8 x i16> %290, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %292 = bitcast <4 x i32> %279 to <8 x i16>
  %293 = add <8 x i16> %150, %144
  %294 = sub <8 x i16> %118, %293
  %295 = add <8 x i16> %294, %292
  %296 = add <8 x i16> %295, %290
  %297 = lshr <8 x i16> %296, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %298 = bitcast <4 x i32> %277 to <8 x i16>
  %299 = sub <8 x i16> %119, %118
  %300 = sub <8 x i16> %299, %150
  %301 = add <8 x i16> %300, %298
  %302 = add <8 x i16> %301, %296
  %303 = lshr <8 x i16> %302, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %304 = bitcast <2 x i64> %115 to <16 x i8>
  %305 = bitcast <8 x i16> %291 to <16 x i8>
  %306 = bitcast <2 x i64> %241 to <16 x i8>
  %307 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %304, <16 x i8> %305, <16 x i8> %306) #5
  %308 = bitcast <16 x i8> %307 to <2 x i64>
  %309 = bitcast <8 x i16> %219 to <16 x i8>
  %310 = bitcast <8 x i16> %297 to <16 x i8>
  %311 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %309, <16 x i8> %310, <16 x i8> %306) #5
  %312 = bitcast <16 x i8> %311 to <2 x i64>
  %313 = bitcast <8 x i16> %220 to <16 x i8>
  %314 = bitcast <8 x i16> %303 to <16 x i8>
  %315 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %313, <16 x i8> %314, <16 x i8> %306) #5
  %316 = bitcast <16 x i8> %315 to <2 x i64>
  %317 = tail call i32 @llvm.x86.sse41.ptestz(<2 x i64> %275, <2 x i64> %275) #5
  %318 = icmp eq i32 %317, 0
  br i1 %318, label %319, label %386

319:                                              ; preds = %248
  %320 = bitcast <2 x i64> %112 to <4 x i32>
  %321 = shufflevector <4 x i32> %320, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %322 = bitcast <2 x i64> %113 to <4 x i32>
  %323 = shufflevector <4 x i32> %322, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %324 = bitcast <2 x i64> %114 to <4 x i32>
  %325 = shufflevector <4 x i32> %324, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %326 = mul <8 x i16> %259, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %327 = add <8 x i16> %249, %253
  %328 = shl <8 x i16> %327, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %329 = add <8 x i16> %285, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %330 = add <8 x i16> %329, %144
  %331 = add <8 x i16> %330, %119
  %332 = add <8 x i16> %331, %326
  %333 = add <8 x i16> %332, %283
  %334 = add <8 x i16> %333, %328
  %335 = lshr <8 x i16> %334, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %336 = shl <8 x i16> %259, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %337 = sub <8 x i16> %150, %336
  %338 = add <8 x i16> %337, %292
  %339 = add <8 x i16> %338, %334
  %340 = lshr <8 x i16> %339, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %341 = sub <8 x i16> %144, %259
  %342 = sub <8 x i16> %341, %249
  %343 = add <8 x i16> %342, %298
  %344 = add <8 x i16> %343, %339
  %345 = lshr <8 x i16> %344, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %346 = bitcast <4 x i32> %325 to <8 x i16>
  %347 = add <8 x i16> %259, %253
  %348 = sub <8 x i16> %118, %347
  %349 = add <8 x i16> %348, %346
  %350 = add <8 x i16> %349, %344
  %351 = lshr <8 x i16> %350, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %352 = bitcast <4 x i32> %323 to <8 x i16>
  %353 = sub <8 x i16> %119, %259
  %354 = sub <8 x i16> %353, %150
  %355 = add <8 x i16> %354, %352
  %356 = add <8 x i16> %355, %350
  %357 = lshr <8 x i16> %356, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %358 = bitcast <4 x i32> %321 to <8 x i16>
  %359 = add <8 x i16> %144, %259
  %360 = sub <8 x i16> %283, %359
  %361 = add <8 x i16> %360, %358
  %362 = add <8 x i16> %361, %356
  %363 = lshr <8 x i16> %362, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %364 = bitcast <2 x i64> %112 to <16 x i8>
  %365 = bitcast <8 x i16> %335 to <16 x i8>
  %366 = bitcast <2 x i64> %275 to <16 x i8>
  %367 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %364, <16 x i8> %365, <16 x i8> %366) #5
  %368 = bitcast <16 x i8> %367 to <2 x i64>
  %369 = bitcast <2 x i64> %113 to <16 x i8>
  %370 = bitcast <8 x i16> %340 to <16 x i8>
  %371 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %369, <16 x i8> %370, <16 x i8> %366) #5
  %372 = bitcast <16 x i8> %371 to <2 x i64>
  %373 = bitcast <2 x i64> %114 to <16 x i8>
  %374 = bitcast <8 x i16> %345 to <16 x i8>
  %375 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %373, <16 x i8> %374, <16 x i8> %366) #5
  %376 = bitcast <8 x i16> %351 to <16 x i8>
  %377 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %307, <16 x i8> %376, <16 x i8> %366) #5
  %378 = bitcast <16 x i8> %377 to <2 x i64>
  %379 = bitcast <8 x i16> %357 to <16 x i8>
  %380 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %311, <16 x i8> %379, <16 x i8> %366) #5
  %381 = bitcast <16 x i8> %380 to <2 x i64>
  %382 = bitcast <8 x i16> %363 to <16 x i8>
  %383 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %315, <16 x i8> %382, <16 x i8> %366) #5
  %384 = bitcast <16 x i8> %383 to <2 x i64>
  %385 = bitcast <16 x i8> %375 to <8 x i16>
  br label %386

386:                                              ; preds = %244, %248, %319
  %387 = phi <8 x i16> [ %247, %244 ], [ %259, %248 ], [ %259, %319 ]
  %388 = phi <8 x i16> [ %150, %244 ], [ %150, %248 ], [ %385, %319 ]
  %389 = phi <2 x i64> [ %115, %244 ], [ %308, %248 ], [ %378, %319 ]
  %390 = phi <2 x i64> [ %113, %244 ], [ %113, %248 ], [ %372, %319 ]
  %391 = phi <2 x i64> [ %246, %244 ], [ %312, %248 ], [ %381, %319 ]
  %392 = phi <2 x i64> [ %245, %244 ], [ %316, %248 ], [ %384, %319 ]
  %393 = phi <2 x i64> [ %112, %244 ], [ %112, %248 ], [ %368, %319 ]
  %394 = bitcast <2 x i64> %110 to <8 x i16>
  %395 = shufflevector <8 x i16> %394, <8 x i16> %387, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %396 = bitcast <2 x i64> %393 to <8 x i16>
  %397 = bitcast <2 x i64> %390 to <8 x i16>
  %398 = shufflevector <8 x i16> %396, <8 x i16> %397, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %399 = bitcast <2 x i64> %389 to <8 x i16>
  %400 = shufflevector <8 x i16> %388, <8 x i16> %399, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %401 = bitcast <2 x i64> %391 to <8 x i16>
  %402 = bitcast <2 x i64> %392 to <8 x i16>
  %403 = shufflevector <8 x i16> %401, <8 x i16> %402, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %404 = bitcast <8 x i16> %395 to <4 x i32>
  %405 = bitcast <8 x i16> %398 to <4 x i32>
  %406 = shufflevector <4 x i32> %404, <4 x i32> %405, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %407 = bitcast <4 x i32> %406 to <2 x i64>
  %408 = bitcast <8 x i16> %400 to <4 x i32>
  %409 = bitcast <8 x i16> %403 to <4 x i32>
  %410 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %411 = bitcast <4 x i32> %410 to <2 x i64>
  %412 = shufflevector <4 x i32> %404, <4 x i32> %405, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %413 = bitcast <4 x i32> %412 to <2 x i64>
  %414 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %415 = bitcast <4 x i32> %414 to <2 x i64>
  %416 = shufflevector <2 x i64> %407, <2 x i64> %411, <2 x i32> <i32 0, i32 2>
  %417 = shufflevector <2 x i64> %407, <2 x i64> %411, <2 x i32> <i32 1, i32 3>
  %418 = shufflevector <2 x i64> %413, <2 x i64> %415, <2 x i32> <i32 0, i32 2>
  %419 = shufflevector <2 x i64> %413, <2 x i64> %415, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %416, <2 x i64>* %21, align 1
  store <2 x i64> %417, <2 x i64>* %25, align 1
  store <2 x i64> %418, <2 x i64>* %30, align 1
  store <2 x i64> %419, <2 x i64>* %35, align 1
  %420 = shufflevector <8 x i16> %402, <8 x i16> %401, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %421 = shufflevector <8 x i16> %399, <8 x i16> %388, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %422 = shufflevector <8 x i16> %397, <8 x i16> %396, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %423 = shufflevector <8 x i16> %387, <8 x i16> %394, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %424 = bitcast <8 x i16> %420 to <4 x i32>
  %425 = bitcast <8 x i16> %421 to <4 x i32>
  %426 = shufflevector <4 x i32> %424, <4 x i32> %425, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %427 = bitcast <4 x i32> %426 to <2 x i64>
  %428 = bitcast <8 x i16> %422 to <4 x i32>
  %429 = bitcast <8 x i16> %423 to <4 x i32>
  %430 = shufflevector <4 x i32> %428, <4 x i32> %429, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %431 = bitcast <4 x i32> %430 to <2 x i64>
  %432 = shufflevector <4 x i32> %424, <4 x i32> %425, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %433 = bitcast <4 x i32> %432 to <2 x i64>
  %434 = shufflevector <4 x i32> %428, <4 x i32> %429, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %435 = bitcast <4 x i32> %434 to <2 x i64>
  %436 = shufflevector <2 x i64> %427, <2 x i64> %431, <2 x i32> <i32 0, i32 2>
  %437 = shufflevector <2 x i64> %427, <2 x i64> %431, <2 x i32> <i32 1, i32 3>
  %438 = shufflevector <2 x i64> %433, <2 x i64> %435, <2 x i32> <i32 0, i32 2>
  %439 = shufflevector <2 x i64> %433, <2 x i64> %435, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %436, <2 x i64>* %67, align 1
  store <2 x i64> %437, <2 x i64>* %71, align 1
  store <2 x i64> %438, <2 x i64>* %75, align 1
  store <2 x i64> %439, <2 x i64>* %79, align 1
  ret void
}

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.usub.sat.v8i16(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #3

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone speculatable }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
