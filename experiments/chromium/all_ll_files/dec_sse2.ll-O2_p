; ModuleID = '../../third_party/libwebp/src/dsp/dec_sse2.c'
source_filename = "../../third_party/libwebp/src/dsp/dec_sse2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@VP8Transform = external local_unnamed_addr global void (i16*, i8*, i32)*, align 8
@VP8VFilter16 = external local_unnamed_addr global void (i8*, i32, i32, i32, i32)*, align 8
@VP8HFilter16 = external local_unnamed_addr global void (i8*, i32, i32, i32, i32)*, align 8
@VP8VFilter8 = external local_unnamed_addr global void (i8*, i8*, i32, i32, i32, i32)*, align 8
@VP8HFilter8 = external local_unnamed_addr global void (i8*, i8*, i32, i32, i32, i32)*, align 8
@VP8VFilter16i = external local_unnamed_addr global void (i8*, i32, i32, i32, i32)*, align 8
@VP8HFilter16i = external local_unnamed_addr global void (i8*, i32, i32, i32, i32)*, align 8
@VP8VFilter8i = external local_unnamed_addr global void (i8*, i8*, i32, i32, i32, i32)*, align 8
@VP8HFilter8i = external local_unnamed_addr global void (i8*, i8*, i32, i32, i32, i32)*, align 8
@VP8SimpleVFilter16 = external local_unnamed_addr global void (i8*, i32, i32)*, align 8
@VP8SimpleHFilter16 = external local_unnamed_addr global void (i8*, i32, i32)*, align 8
@VP8SimpleVFilter16i = external local_unnamed_addr global void (i8*, i32, i32)*, align 8
@VP8SimpleHFilter16i = external local_unnamed_addr global void (i8*, i32, i32)*, align 8
@VP8PredLuma4 = external local_unnamed_addr global [0 x void (i8*)*], align 8
@VP8PredLuma16 = external local_unnamed_addr global [0 x void (i8*)*], align 8
@VP8PredChroma8 = external local_unnamed_addr global [0 x void (i8*)*], align 8

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @VP8DspInitSSE2() local_unnamed_addr #0 {
  store void (i16*, i8*, i32)* @Transform_SSE2, void (i16*, i8*, i32)** @VP8Transform, align 8
  store void (i8*, i32, i32, i32, i32)* @VFilter16_SSE2, void (i8*, i32, i32, i32, i32)** @VP8VFilter16, align 8
  store void (i8*, i32, i32, i32, i32)* @HFilter16_SSE2, void (i8*, i32, i32, i32, i32)** @VP8HFilter16, align 8
  store void (i8*, i8*, i32, i32, i32, i32)* @VFilter8_SSE2, void (i8*, i8*, i32, i32, i32, i32)** @VP8VFilter8, align 8
  store void (i8*, i8*, i32, i32, i32, i32)* @HFilter8_SSE2, void (i8*, i8*, i32, i32, i32, i32)** @VP8HFilter8, align 8
  store void (i8*, i32, i32, i32, i32)* @VFilter16i_SSE2, void (i8*, i32, i32, i32, i32)** @VP8VFilter16i, align 8
  store void (i8*, i32, i32, i32, i32)* @HFilter16i_SSE2, void (i8*, i32, i32, i32, i32)** @VP8HFilter16i, align 8
  store void (i8*, i8*, i32, i32, i32, i32)* @VFilter8i_SSE2, void (i8*, i8*, i32, i32, i32, i32)** @VP8VFilter8i, align 8
  store void (i8*, i8*, i32, i32, i32, i32)* @HFilter8i_SSE2, void (i8*, i8*, i32, i32, i32, i32)** @VP8HFilter8i, align 8
  store void (i8*, i32, i32)* @SimpleVFilter16_SSE2, void (i8*, i32, i32)** @VP8SimpleVFilter16, align 8
  store void (i8*, i32, i32)* @SimpleHFilter16_SSE2, void (i8*, i32, i32)** @VP8SimpleHFilter16, align 8
  store void (i8*, i32, i32)* @SimpleVFilter16i_SSE2, void (i8*, i32, i32)** @VP8SimpleVFilter16i, align 8
  store void (i8*, i32, i32)* @SimpleHFilter16i_SSE2, void (i8*, i32, i32)** @VP8SimpleHFilter16i, align 8
  store <2 x void (i8*)*> <void (i8*)* @TM4_SSE2, void (i8*)* @VE4_SSE2>, <2 x void (i8*)*>* bitcast (void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredLuma4, i64 0, i64 1) to <2 x void (i8*)*>*), align 8
  store <2 x void (i8*)*> <void (i8*)* @RD4_SSE2, void (i8*)* @VR4_SSE2>, <2 x void (i8*)*>* bitcast (void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredLuma4, i64 0, i64 4) to <2 x void (i8*)*>*), align 8
  store <2 x void (i8*)*> <void (i8*)* @LD4_SSE2, void (i8*)* @VL4_SSE2>, <2 x void (i8*)*>* bitcast (void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredLuma4, i64 0, i64 6) to <2 x void (i8*)*>*), align 8
  store <2 x void (i8*)*> <void (i8*)* @DC16_SSE2, void (i8*)* @TM16_SSE2>, <2 x void (i8*)*>* bitcast ([0 x void (i8*)*]* @VP8PredLuma16 to <2 x void (i8*)*>*), align 8
  store <2 x void (i8*)*> <void (i8*)* @VE16_SSE2, void (i8*)* @HE16_SSE2>, <2 x void (i8*)*>* bitcast (void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredLuma16, i64 0, i64 2) to <2 x void (i8*)*>*), align 8
  store <2 x void (i8*)*> <void (i8*)* @DC16NoTop_SSE2, void (i8*)* @DC16NoLeft_SSE2>, <2 x void (i8*)*>* bitcast (void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredLuma16, i64 0, i64 4) to <2 x void (i8*)*>*), align 8
  store void (i8*)* @DC16NoTopLeft_SSE2, void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredLuma16, i64 0, i64 6), align 8
  store <2 x void (i8*)*> <void (i8*)* @DC8uv_SSE2, void (i8*)* @TM8uv_SSE2>, <2 x void (i8*)*>* bitcast ([0 x void (i8*)*]* @VP8PredChroma8 to <2 x void (i8*)*>*), align 8
  store void (i8*)* @VE8uv_SSE2, void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredChroma8, i64 0, i64 2), align 8
  store <2 x void (i8*)*> <void (i8*)* @DC8uvNoTop_SSE2, void (i8*)* @DC8uvNoLeft_SSE2>, <2 x void (i8*)*>* bitcast (void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredChroma8, i64 0, i64 4) to <2 x void (i8*)*>*), align 8
  store void (i8*)* @DC8uvNoTopLeft_SSE2, void (i8*)** getelementptr inbounds ([0 x void (i8*)*], [0 x void (i8*)*]* @VP8PredChroma8, i64 0, i64 6), align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @Transform_SSE2(i16* nocapture readonly, i8* nocapture, i32) #1 {
  %4 = bitcast i16* %0 to i64*
  %5 = load i64, i64* %4, align 1
  %6 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %5, i32 0
  %7 = getelementptr inbounds i16, i16* %0, i64 4
  %8 = bitcast i16* %7 to i64*
  %9 = load i64, i64* %8, align 1
  %10 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %9, i32 0
  %11 = getelementptr inbounds i16, i16* %0, i64 8
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 1
  %14 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %13, i32 0
  %15 = getelementptr inbounds i16, i16* %0, i64 12
  %16 = bitcast i16* %15 to i64*
  %17 = load i64, i64* %16, align 1
  %18 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %17, i32 0
  %19 = icmp ne i32 %2, 0
  br i1 %19, label %20, label %37

20:                                               ; preds = %3
  %21 = getelementptr inbounds i16, i16* %0, i64 16
  %22 = bitcast i16* %21 to i64*
  %23 = load i64, i64* %22, align 1
  %24 = getelementptr inbounds i16, i16* %0, i64 20
  %25 = bitcast i16* %24 to i64*
  %26 = load i64, i64* %25, align 1
  %27 = getelementptr inbounds i16, i16* %0, i64 24
  %28 = bitcast i16* %27 to i64*
  %29 = load i64, i64* %28, align 1
  %30 = getelementptr inbounds i16, i16* %0, i64 28
  %31 = bitcast i16* %30 to i64*
  %32 = load i64, i64* %31, align 1
  %33 = insertelement <2 x i64> %6, i64 %23, i32 1
  %34 = insertelement <2 x i64> %10, i64 %26, i32 1
  %35 = insertelement <2 x i64> %14, i64 %29, i32 1
  %36 = insertelement <2 x i64> %18, i64 %32, i32 1
  br label %37

37:                                               ; preds = %20, %3
  %38 = phi <2 x i64> [ %36, %20 ], [ %18, %3 ]
  %39 = phi <2 x i64> [ %35, %20 ], [ %14, %3 ]
  %40 = phi <2 x i64> [ %34, %20 ], [ %10, %3 ]
  %41 = phi <2 x i64> [ %33, %20 ], [ %6, %3 ]
  %42 = bitcast <2 x i64> %41 to <8 x i16>
  %43 = bitcast <2 x i64> %39 to <8 x i16>
  %44 = add <8 x i16> %42, %43
  %45 = sub <8 x i16> %42, %43
  %46 = bitcast <2 x i64> %40 to <8 x i16>
  %47 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %46, <8 x i16> <i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068>) #8
  %48 = bitcast <2 x i64> %38 to <8 x i16>
  %49 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %48, <8 x i16> <i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091>) #8
  %50 = sub <8 x i16> %46, %48
  %51 = sub <8 x i16> %47, %49
  %52 = add <8 x i16> %51, %50
  %53 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %46, <8 x i16> <i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091>) #8
  %54 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %48, <8 x i16> <i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068>) #8
  %55 = add <8 x i16> %46, %48
  %56 = add <8 x i16> %55, %53
  %57 = add <8 x i16> %56, %54
  %58 = add <8 x i16> %57, %44
  %59 = add <8 x i16> %52, %45
  %60 = sub <8 x i16> %45, %52
  %61 = sub <8 x i16> %44, %57
  %62 = shufflevector <8 x i16> %58, <8 x i16> %59, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %63 = shufflevector <8 x i16> %60, <8 x i16> %61, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %64 = shufflevector <8 x i16> %58, <8 x i16> %59, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %65 = shufflevector <8 x i16> %60, <8 x i16> %61, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %66 = bitcast <8 x i16> %62 to <4 x i32>
  %67 = bitcast <8 x i16> %63 to <4 x i32>
  %68 = shufflevector <4 x i32> %66, <4 x i32> %67, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %69 = bitcast <4 x i32> %68 to <2 x i64>
  %70 = bitcast <8 x i16> %64 to <4 x i32>
  %71 = bitcast <8 x i16> %65 to <4 x i32>
  %72 = shufflevector <4 x i32> %70, <4 x i32> %71, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %73 = bitcast <4 x i32> %72 to <2 x i64>
  %74 = shufflevector <4 x i32> %66, <4 x i32> %67, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %75 = bitcast <4 x i32> %74 to <2 x i64>
  %76 = shufflevector <4 x i32> %70, <4 x i32> %71, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %77 = bitcast <4 x i32> %76 to <2 x i64>
  %78 = shufflevector <2 x i64> %69, <2 x i64> %73, <2 x i32> <i32 0, i32 2>
  %79 = shufflevector <2 x i64> %69, <2 x i64> %73, <2 x i32> <i32 1, i32 3>
  %80 = shufflevector <2 x i64> %75, <2 x i64> %77, <2 x i32> <i32 0, i32 2>
  %81 = shufflevector <2 x i64> %75, <2 x i64> %77, <2 x i32> <i32 1, i32 3>
  %82 = bitcast <2 x i64> %78 to <8 x i16>
  %83 = add <8 x i16> %82, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %84 = bitcast <2 x i64> %80 to <8 x i16>
  %85 = add <8 x i16> %83, %84
  %86 = sub <8 x i16> %83, %84
  %87 = bitcast <2 x i64> %79 to <8 x i16>
  %88 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %87, <8 x i16> <i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068>) #8
  %89 = bitcast <2 x i64> %81 to <8 x i16>
  %90 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %89, <8 x i16> <i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091>) #8
  %91 = sub <8 x i16> %87, %89
  %92 = sub <8 x i16> %88, %90
  %93 = add <8 x i16> %91, %92
  %94 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %87, <8 x i16> <i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091, i16 20091>) #8
  %95 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %89, <8 x i16> <i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068, i16 -30068>) #8
  %96 = add <8 x i16> %95, %94
  %97 = add <8 x i16> %96, %87
  %98 = add <8 x i16> %97, %89
  %99 = add <8 x i16> %85, %98
  %100 = add <8 x i16> %93, %86
  %101 = sub <8 x i16> %86, %93
  %102 = sub <8 x i16> %85, %98
  %103 = ashr <8 x i16> %99, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %104 = ashr <8 x i16> %100, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %105 = ashr <8 x i16> %101, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %106 = ashr <8 x i16> %102, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %107 = shufflevector <8 x i16> %103, <8 x i16> %104, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %108 = shufflevector <8 x i16> %105, <8 x i16> %106, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %109 = shufflevector <8 x i16> %103, <8 x i16> %104, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %110 = shufflevector <8 x i16> %105, <8 x i16> %106, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %111 = bitcast <8 x i16> %107 to <4 x i32>
  %112 = bitcast <8 x i16> %108 to <4 x i32>
  %113 = shufflevector <4 x i32> %111, <4 x i32> %112, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = bitcast <8 x i16> %109 to <4 x i32>
  %116 = bitcast <8 x i16> %110 to <4 x i32>
  %117 = shufflevector <4 x i32> %115, <4 x i32> %116, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %111, <4 x i32> %112, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %120 = bitcast <4 x i32> %119 to <2 x i64>
  %121 = shufflevector <4 x i32> %115, <4 x i32> %116, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = shufflevector <2 x i64> %114, <2 x i64> %118, <2 x i32> <i32 0, i32 2>
  %124 = shufflevector <2 x i64> %114, <2 x i64> %118, <2 x i32> <i32 1, i32 3>
  %125 = shufflevector <2 x i64> %120, <2 x i64> %122, <2 x i32> <i32 0, i32 2>
  %126 = shufflevector <2 x i64> %120, <2 x i64> %122, <2 x i32> <i32 1, i32 3>
  br i1 %19, label %127, label %143

127:                                              ; preds = %37
  %128 = bitcast i8* %1 to i64*
  %129 = load i64, i64* %128, align 1
  %130 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %129, i32 0
  %131 = getelementptr inbounds i8, i8* %1, i64 32
  %132 = bitcast i8* %131 to i64*
  %133 = load i64, i64* %132, align 1
  %134 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %133, i32 0
  %135 = getelementptr inbounds i8, i8* %1, i64 64
  %136 = bitcast i8* %135 to i64*
  %137 = load i64, i64* %136, align 1
  %138 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %137, i32 0
  %139 = getelementptr inbounds i8, i8* %1, i64 96
  %140 = bitcast i8* %139 to i64*
  %141 = load i64, i64* %140, align 1
  %142 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %141, i32 0
  br label %163

143:                                              ; preds = %37
  %144 = bitcast i8* %1 to i32*
  %145 = load i32, i32* %144, align 1
  %146 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %145, i32 0
  %147 = bitcast <4 x i32> %146 to <2 x i64>
  %148 = getelementptr inbounds i8, i8* %1, i64 32
  %149 = bitcast i8* %148 to i32*
  %150 = load i32, i32* %149, align 1
  %151 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %150, i32 0
  %152 = bitcast <4 x i32> %151 to <2 x i64>
  %153 = getelementptr inbounds i8, i8* %1, i64 64
  %154 = bitcast i8* %153 to i32*
  %155 = load i32, i32* %154, align 1
  %156 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %155, i32 0
  %157 = bitcast <4 x i32> %156 to <2 x i64>
  %158 = getelementptr inbounds i8, i8* %1, i64 96
  %159 = bitcast i8* %158 to i32*
  %160 = load i32, i32* %159, align 1
  %161 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %160, i32 0
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  br label %163

163:                                              ; preds = %143, %127
  %164 = phi <2 x i64> [ %130, %127 ], [ %147, %143 ]
  %165 = phi <2 x i64> [ %134, %127 ], [ %152, %143 ]
  %166 = phi <2 x i64> [ %138, %127 ], [ %157, %143 ]
  %167 = phi <2 x i64> [ %142, %127 ], [ %162, %143 ]
  %168 = bitcast <2 x i64> %164 to <16 x i8>
  %169 = shufflevector <16 x i8> %168, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %170 = bitcast <2 x i64> %165 to <16 x i8>
  %171 = shufflevector <16 x i8> %170, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %172 = bitcast <2 x i64> %166 to <16 x i8>
  %173 = shufflevector <16 x i8> %172, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %174 = bitcast <2 x i64> %167 to <16 x i8>
  %175 = shufflevector <16 x i8> %174, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %176 = bitcast <16 x i8> %169 to <8 x i16>
  %177 = bitcast <2 x i64> %123 to <8 x i16>
  %178 = add <8 x i16> %176, %177
  %179 = bitcast <16 x i8> %171 to <8 x i16>
  %180 = bitcast <2 x i64> %124 to <8 x i16>
  %181 = add <8 x i16> %179, %180
  %182 = bitcast <16 x i8> %173 to <8 x i16>
  %183 = bitcast <2 x i64> %125 to <8 x i16>
  %184 = add <8 x i16> %182, %183
  %185 = bitcast <16 x i8> %175 to <8 x i16>
  %186 = bitcast <2 x i64> %126 to <8 x i16>
  %187 = add <8 x i16> %185, %186
  %188 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %178, <8 x i16> %178) #8
  %189 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %181, <8 x i16> %181) #8
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %184, <8 x i16> %184) #8
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %187) #8
  br i1 %19, label %192, label %208

192:                                              ; preds = %163
  %193 = bitcast <16 x i8> %191 to <2 x i64>
  %194 = bitcast <16 x i8> %190 to <2 x i64>
  %195 = bitcast <16 x i8> %189 to <2 x i64>
  %196 = bitcast <16 x i8> %188 to <2 x i64>
  %197 = extractelement <2 x i64> %196, i32 0
  %198 = bitcast i8* %1 to i64*
  store i64 %197, i64* %198, align 1
  %199 = getelementptr inbounds i8, i8* %1, i64 32
  %200 = extractelement <2 x i64> %195, i32 0
  %201 = bitcast i8* %199 to i64*
  store i64 %200, i64* %201, align 1
  %202 = getelementptr inbounds i8, i8* %1, i64 64
  %203 = extractelement <2 x i64> %194, i32 0
  %204 = bitcast i8* %202 to i64*
  store i64 %203, i64* %204, align 1
  %205 = getelementptr inbounds i8, i8* %1, i64 96
  %206 = extractelement <2 x i64> %193, i32 0
  %207 = bitcast i8* %205 to i64*
  store i64 %206, i64* %207, align 1
  br label %224

208:                                              ; preds = %163
  %209 = bitcast <16 x i8> %188 to <4 x i32>
  %210 = extractelement <4 x i32> %209, i32 0
  %211 = bitcast i8* %1 to i32*
  store i32 %210, i32* %211, align 1
  %212 = getelementptr inbounds i8, i8* %1, i64 32
  %213 = bitcast <16 x i8> %189 to <4 x i32>
  %214 = extractelement <4 x i32> %213, i32 0
  %215 = bitcast i8* %212 to i32*
  store i32 %214, i32* %215, align 1
  %216 = getelementptr inbounds i8, i8* %1, i64 64
  %217 = bitcast <16 x i8> %190 to <4 x i32>
  %218 = extractelement <4 x i32> %217, i32 0
  %219 = bitcast i8* %216 to i32*
  store i32 %218, i32* %219, align 1
  %220 = getelementptr inbounds i8, i8* %1, i64 96
  %221 = bitcast <16 x i8> %191 to <4 x i32>
  %222 = extractelement <4 x i32> %221, i32 0
  %223 = bitcast i8* %220 to i32*
  store i32 %222, i32* %223, align 1
  br label %224

224:                                              ; preds = %208, %192
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @VFilter16_SSE2(i8* nocapture, i32, i32, i32, i32) #1 {
  %6 = shl nsw i32 %1, 2
  %7 = sext i32 %6 to i64
  %8 = sub nsw i64 0, %7
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = bitcast i8* %9 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = sext i32 %1 to i64
  %13 = getelementptr inbounds i8, i8* %9, i64 %12
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = shl nsw i32 %1, 1
  %17 = sext i32 %16 to i64
  %18 = getelementptr inbounds i8, i8* %9, i64 %17
  %19 = bitcast i8* %18 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 1
  %21 = mul nsw i32 %1, 3
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i8, i8* %9, i64 %22
  %24 = bitcast i8* %23 to <16 x i8>*
  %25 = load <16 x i8>, <16 x i8>* %24, align 1
  %26 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %25, <16 x i8> %20) #8
  %27 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %20, <16 x i8> %25) #8
  %28 = or <16 x i8> %27, %26
  %29 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %15, <16 x i8> %11) #8
  %30 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %11, <16 x i8> %15) #8
  %31 = or <16 x i8> %30, %29
  %32 = icmp ugt <16 x i8> %28, %31
  %33 = select <16 x i1> %32, <16 x i8> %28, <16 x i8> %31
  %34 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %20, <16 x i8> %15) #8
  %35 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %15, <16 x i8> %20) #8
  %36 = or <16 x i8> %35, %34
  %37 = icmp ugt <16 x i8> %33, %36
  %38 = select <16 x i1> %37, <16 x i8> %33, <16 x i8> %36
  %39 = bitcast i8* %0 to <2 x i64>*
  %40 = bitcast i8* %0 to <16 x i8>*
  %41 = load <16 x i8>, <16 x i8>* %40, align 1
  %42 = getelementptr inbounds i8, i8* %0, i64 %12
  %43 = bitcast i8* %42 to <2 x i64>*
  %44 = bitcast i8* %42 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = getelementptr inbounds i8, i8* %0, i64 %17
  %47 = bitcast i8* %46 to <2 x i64>*
  %48 = bitcast i8* %46 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = getelementptr inbounds i8, i8* %0, i64 %22
  %51 = bitcast i8* %50 to <16 x i8>*
  %52 = load <16 x i8>, <16 x i8>* %51, align 1
  %53 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %41, <16 x i8> %45) #8
  %54 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %45, <16 x i8> %41) #8
  %55 = or <16 x i8> %54, %53
  %56 = icmp ugt <16 x i8> %38, %55
  %57 = select <16 x i1> %56, <16 x i8> %38, <16 x i8> %55
  %58 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %49, <16 x i8> %52) #8
  %59 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %52, <16 x i8> %49) #8
  %60 = or <16 x i8> %59, %58
  %61 = icmp ugt <16 x i8> %57, %60
  %62 = select <16 x i1> %61, <16 x i8> %57, <16 x i8> %60
  %63 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %45, <16 x i8> %49) #8
  %64 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %49, <16 x i8> %45) #8
  %65 = or <16 x i8> %64, %63
  %66 = icmp ugt <16 x i8> %62, %65
  %67 = select <16 x i1> %66, <16 x i8> %62, <16 x i8> %65
  %68 = trunc i32 %3 to i8
  %69 = insertelement <16 x i8> undef, i8 %68, i32 0
  %70 = shufflevector <16 x i8> %69, <16 x i8> undef, <16 x i32> zeroinitializer
  %71 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %67, <16 x i8> %70) #8
  %72 = icmp eq <16 x i8> %71, zeroinitializer
  %73 = trunc i32 %2 to i8
  %74 = insertelement <16 x i8> undef, i8 %73, i32 0
  %75 = shufflevector <16 x i8> %74, <16 x i8> undef, <16 x i32> zeroinitializer
  %76 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %45, <16 x i8> %20) #8
  %77 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %20, <16 x i8> %45) #8
  %78 = or <16 x i8> %77, %76
  %79 = bitcast <16 x i8> %78 to <8 x i16>
  %80 = lshr <8 x i16> %79, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %81 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %41, <16 x i8> %25) #8
  %82 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %25, <16 x i8> %41) #8
  %83 = or <16 x i8> %82, %81
  %84 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %83, <16 x i8> %83) #8
  %85 = bitcast <8 x i16> %80 to <16 x i8>
  %86 = and <16 x i8> %85, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %87 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %84, <16 x i8> %86) #8
  %88 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %87, <16 x i8> %75) #8
  %89 = icmp eq <16 x i8> %88, zeroinitializer
  %90 = and <16 x i1> %72, %89
  %91 = trunc i32 %4 to i8
  %92 = insertelement <16 x i8> undef, i8 %91, i32 0
  %93 = shufflevector <16 x i8> %92, <16 x i8> undef, <16 x i32> zeroinitializer
  %94 = icmp ugt <16 x i8> %28, %55
  %95 = select <16 x i1> %94, <16 x i8> %28, <16 x i8> %55
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %93) #8
  %97 = icmp eq <16 x i8> %96, zeroinitializer
  %98 = sext <16 x i1> %97 to <16 x i8>
  %99 = xor <16 x i8> %20, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %100 = xor <16 x i8> %45, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %101 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %99, <16 x i8> %100) #8
  %102 = xor <16 x i8> %41, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %103 = xor <16 x i8> %25, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %104 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %102, <16 x i8> %103) #8
  %105 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %101, <16 x i8> %104) #8
  %106 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %104, <16 x i8> %105) #8
  %107 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %104, <16 x i8> %106) #8
  %108 = xor <16 x i8> %98, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %109 = select <16 x i1> %90, <16 x i8> %107, <16 x i8> zeroinitializer
  %110 = and <16 x i8> %109, %108
  %111 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %110, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %112 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %110, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %113 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %112, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %114 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %112, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %115 = bitcast <16 x i8> %113 to <8 x i16>
  %116 = ashr <8 x i16> %115, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %117 = bitcast <16 x i8> %114 to <8 x i16>
  %118 = ashr <8 x i16> %117, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %119 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %116, <8 x i16> %118) #8
  %120 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %111, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %121 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %111, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %122 = bitcast <16 x i8> %120 to <8 x i16>
  %123 = ashr <8 x i16> %122, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %124 = bitcast <16 x i8> %121 to <8 x i16>
  %125 = ashr <8 x i16> %124, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %126 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %123, <8 x i16> %125) #8
  %127 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %102, <16 x i8> %119) #8
  %128 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %103, <16 x i8> %126) #8
  %129 = and <16 x i8> %109, %98
  %130 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %129, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %131 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %129, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %132 = bitcast <16 x i8> %130 to <8 x i16>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %132, <8 x i16> <i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304>) #8
  %134 = bitcast <16 x i8> %131 to <8 x i16>
  %135 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %134, <8 x i16> <i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304>) #8
  %136 = add <8 x i16> %133, <i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63>
  %137 = add <8 x i16> %135, <i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63>
  %138 = add <8 x i16> %136, %133
  %139 = add <8 x i16> %137, %135
  %140 = add <8 x i16> %138, %133
  %141 = add <8 x i16> %139, %135
  %142 = ashr <8 x i16> %136, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %143 = ashr <8 x i16> %137, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %144 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %142, <8 x i16> %143) #8
  %145 = xor <16 x i8> %15, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %146 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %145, <16 x i8> %144) #8
  %147 = bitcast <16 x i8> %146 to <2 x i64>
  %148 = xor <16 x i8> %49, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %149 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %148, <16 x i8> %144) #8
  %150 = bitcast <16 x i8> %149 to <2 x i64>
  %151 = xor <2 x i64> %147, <i64 -9187201950435737472, i64 -9187201950435737472>
  %152 = xor <2 x i64> %150, <i64 -9187201950435737472, i64 -9187201950435737472>
  %153 = ashr <8 x i16> %138, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %154 = ashr <8 x i16> %139, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %155 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %153, <8 x i16> %154) #8
  %156 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %99, <16 x i8> %155) #8
  %157 = bitcast <16 x i8> %156 to <2 x i64>
  %158 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %100, <16 x i8> %155) #8
  %159 = bitcast <16 x i8> %158 to <2 x i64>
  %160 = xor <2 x i64> %157, <i64 -9187201950435737472, i64 -9187201950435737472>
  %161 = xor <2 x i64> %159, <i64 -9187201950435737472, i64 -9187201950435737472>
  %162 = ashr <8 x i16> %140, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %163 = ashr <8 x i16> %141, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %162, <8 x i16> %163) #8
  %165 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %128, <16 x i8> %164) #8
  %166 = bitcast <16 x i8> %165 to <2 x i64>
  %167 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %127, <16 x i8> %164) #8
  %168 = bitcast <16 x i8> %167 to <2 x i64>
  %169 = xor <2 x i64> %166, <i64 -9187201950435737472, i64 -9187201950435737472>
  %170 = xor <2 x i64> %168, <i64 -9187201950435737472, i64 -9187201950435737472>
  %171 = mul nsw i32 %1, -3
  %172 = sext i32 %171 to i64
  %173 = getelementptr inbounds i8, i8* %0, i64 %172
  %174 = bitcast i8* %173 to <2 x i64>*
  store <2 x i64> %151, <2 x i64>* %174, align 1
  %175 = mul nsw i32 %1, -2
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds i8, i8* %0, i64 %176
  %178 = bitcast i8* %177 to <2 x i64>*
  store <2 x i64> %160, <2 x i64>* %178, align 1
  %179 = sub nsw i32 0, %1
  %180 = sext i32 %179 to i64
  %181 = getelementptr inbounds i8, i8* %0, i64 %180
  %182 = bitcast i8* %181 to <2 x i64>*
  store <2 x i64> %169, <2 x i64>* %182, align 1
  store <2 x i64> %170, <2 x i64>* %39, align 1
  store <2 x i64> %161, <2 x i64>* %43, align 1
  store <2 x i64> %152, <2 x i64>* %47, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @HFilter16_SSE2(i8* nocapture, i32, i32, i32, i32) #1 {
  %6 = getelementptr inbounds i8, i8* %0, i64 -4
  %7 = shl nsw i32 %1, 3
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds i8, i8* %6, i64 %8
  %10 = mul nsw i32 %1, 6
  %11 = sext i32 %10 to i64
  %12 = getelementptr inbounds i8, i8* %6, i64 %11
  %13 = bitcast i8* %12 to i32*
  %14 = load i32, i32* %13, align 1
  %15 = shl nsw i32 %1, 1
  %16 = sext i32 %15 to i64
  %17 = getelementptr inbounds i8, i8* %6, i64 %16
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 1
  %20 = shl nsw i32 %1, 2
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds i8, i8* %6, i64 %21
  %23 = bitcast i8* %22 to i32*
  %24 = load i32, i32* %23, align 1
  %25 = bitcast i8* %6 to i32*
  %26 = load i32, i32* %25, align 1
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = insertelement <4 x i32> %27, i32 %24, i32 1
  %29 = insertelement <4 x i32> %28, i32 %19, i32 2
  %30 = insertelement <4 x i32> %29, i32 %14, i32 3
  %31 = mul nsw i32 %1, 7
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i8, i8* %6, i64 %32
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 1
  %36 = mul nsw i32 %1, 3
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i8, i8* %6, i64 %37
  %39 = bitcast i8* %38 to i32*
  %40 = load i32, i32* %39, align 1
  %41 = mul nsw i32 %1, 5
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds i8, i8* %6, i64 %42
  %44 = bitcast i8* %43 to i32*
  %45 = load i32, i32* %44, align 1
  %46 = sext i32 %1 to i64
  %47 = getelementptr inbounds i8, i8* %6, i64 %46
  %48 = bitcast i8* %47 to i32*
  %49 = load i32, i32* %48, align 1
  %50 = insertelement <4 x i32> undef, i32 %49, i32 0
  %51 = insertelement <4 x i32> %50, i32 %45, i32 1
  %52 = insertelement <4 x i32> %51, i32 %40, i32 2
  %53 = insertelement <4 x i32> %52, i32 %35, i32 3
  %54 = bitcast <4 x i32> %30 to <16 x i8>
  %55 = bitcast <4 x i32> %53 to <16 x i8>
  %56 = shufflevector <16 x i8> %54, <16 x i8> %55, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %57 = shufflevector <16 x i8> %54, <16 x i8> %55, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %58 = bitcast <16 x i8> %56 to <8 x i16>
  %59 = bitcast <16 x i8> %57 to <8 x i16>
  %60 = shufflevector <8 x i16> %58, <8 x i16> %59, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %61 = shufflevector <8 x i16> %58, <8 x i16> %59, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %62 = bitcast <8 x i16> %60 to <4 x i32>
  %63 = bitcast <8 x i16> %61 to <4 x i32>
  %64 = shufflevector <4 x i32> %62, <4 x i32> %63, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %65 = bitcast <4 x i32> %64 to <2 x i64>
  %66 = shufflevector <4 x i32> %62, <4 x i32> %63, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %67 = bitcast <4 x i32> %66 to <2 x i64>
  %68 = getelementptr inbounds i8, i8* %9, i64 %11
  %69 = bitcast i8* %68 to i32*
  %70 = load i32, i32* %69, align 1
  %71 = getelementptr inbounds i8, i8* %9, i64 %16
  %72 = bitcast i8* %71 to i32*
  %73 = load i32, i32* %72, align 1
  %74 = getelementptr inbounds i8, i8* %9, i64 %21
  %75 = bitcast i8* %74 to i32*
  %76 = load i32, i32* %75, align 1
  %77 = bitcast i8* %9 to i32*
  %78 = load i32, i32* %77, align 1
  %79 = insertelement <4 x i32> undef, i32 %78, i32 0
  %80 = insertelement <4 x i32> %79, i32 %76, i32 1
  %81 = insertelement <4 x i32> %80, i32 %73, i32 2
  %82 = insertelement <4 x i32> %81, i32 %70, i32 3
  %83 = getelementptr inbounds i8, i8* %9, i64 %32
  %84 = bitcast i8* %83 to i32*
  %85 = load i32, i32* %84, align 1
  %86 = getelementptr inbounds i8, i8* %9, i64 %37
  %87 = bitcast i8* %86 to i32*
  %88 = load i32, i32* %87, align 1
  %89 = getelementptr inbounds i8, i8* %9, i64 %42
  %90 = bitcast i8* %89 to i32*
  %91 = load i32, i32* %90, align 1
  %92 = getelementptr inbounds i8, i8* %9, i64 %46
  %93 = bitcast i8* %92 to i32*
  %94 = load i32, i32* %93, align 1
  %95 = insertelement <4 x i32> undef, i32 %94, i32 0
  %96 = insertelement <4 x i32> %95, i32 %91, i32 1
  %97 = insertelement <4 x i32> %96, i32 %88, i32 2
  %98 = insertelement <4 x i32> %97, i32 %85, i32 3
  %99 = bitcast <4 x i32> %82 to <16 x i8>
  %100 = bitcast <4 x i32> %98 to <16 x i8>
  %101 = shufflevector <16 x i8> %99, <16 x i8> %100, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %102 = shufflevector <16 x i8> %99, <16 x i8> %100, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %103 = bitcast <16 x i8> %101 to <8 x i16>
  %104 = bitcast <16 x i8> %102 to <8 x i16>
  %105 = shufflevector <8 x i16> %103, <8 x i16> %104, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %106 = shufflevector <8 x i16> %103, <8 x i16> %104, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %107 = bitcast <8 x i16> %105 to <4 x i32>
  %108 = bitcast <8 x i16> %106 to <4 x i32>
  %109 = shufflevector <4 x i32> %107, <4 x i32> %108, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %110 = bitcast <4 x i32> %109 to <2 x i64>
  %111 = shufflevector <4 x i32> %107, <4 x i32> %108, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = shufflevector <2 x i64> %65, <2 x i64> %110, <2 x i32> <i32 0, i32 2>
  %114 = shufflevector <2 x i64> %65, <2 x i64> %110, <2 x i32> <i32 1, i32 3>
  %115 = shufflevector <2 x i64> %67, <2 x i64> %112, <2 x i32> <i32 0, i32 2>
  %116 = shufflevector <2 x i64> %67, <2 x i64> %112, <2 x i32> <i32 1, i32 3>
  %117 = bitcast <2 x i64> %116 to <16 x i8>
  %118 = bitcast <2 x i64> %115 to <16 x i8>
  %119 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %117, <16 x i8> %118) #8
  %120 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %118, <16 x i8> %117) #8
  %121 = or <16 x i8> %120, %119
  %122 = bitcast <2 x i64> %114 to <16 x i8>
  %123 = bitcast <2 x i64> %113 to <16 x i8>
  %124 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %122, <16 x i8> %123) #8
  %125 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %123, <16 x i8> %122) #8
  %126 = or <16 x i8> %125, %124
  %127 = icmp ugt <16 x i8> %121, %126
  %128 = select <16 x i1> %127, <16 x i8> %121, <16 x i8> %126
  %129 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %118, <16 x i8> %122) #8
  %130 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %122, <16 x i8> %118) #8
  %131 = or <16 x i8> %130, %129
  %132 = icmp ugt <16 x i8> %128, %131
  %133 = select <16 x i1> %132, <16 x i8> %128, <16 x i8> %131
  %134 = getelementptr inbounds i8, i8* %0, i64 %8
  %135 = getelementptr inbounds i8, i8* %0, i64 %11
  %136 = bitcast i8* %135 to i32*
  %137 = load i32, i32* %136, align 1
  %138 = getelementptr inbounds i8, i8* %0, i64 %16
  %139 = bitcast i8* %138 to i32*
  %140 = load i32, i32* %139, align 1
  %141 = getelementptr inbounds i8, i8* %0, i64 %21
  %142 = bitcast i8* %141 to i32*
  %143 = load i32, i32* %142, align 1
  %144 = bitcast i8* %0 to i32*
  %145 = load i32, i32* %144, align 1
  %146 = insertelement <4 x i32> undef, i32 %145, i32 0
  %147 = insertelement <4 x i32> %146, i32 %143, i32 1
  %148 = insertelement <4 x i32> %147, i32 %140, i32 2
  %149 = insertelement <4 x i32> %148, i32 %137, i32 3
  %150 = getelementptr inbounds i8, i8* %0, i64 %32
  %151 = bitcast i8* %150 to i32*
  %152 = load i32, i32* %151, align 1
  %153 = getelementptr inbounds i8, i8* %0, i64 %37
  %154 = bitcast i8* %153 to i32*
  %155 = load i32, i32* %154, align 1
  %156 = getelementptr inbounds i8, i8* %0, i64 %42
  %157 = bitcast i8* %156 to i32*
  %158 = load i32, i32* %157, align 1
  %159 = getelementptr inbounds i8, i8* %0, i64 %46
  %160 = bitcast i8* %159 to i32*
  %161 = load i32, i32* %160, align 1
  %162 = insertelement <4 x i32> undef, i32 %161, i32 0
  %163 = insertelement <4 x i32> %162, i32 %158, i32 1
  %164 = insertelement <4 x i32> %163, i32 %155, i32 2
  %165 = insertelement <4 x i32> %164, i32 %152, i32 3
  %166 = bitcast <4 x i32> %149 to <16 x i8>
  %167 = bitcast <4 x i32> %165 to <16 x i8>
  %168 = shufflevector <16 x i8> %166, <16 x i8> %167, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %169 = shufflevector <16 x i8> %166, <16 x i8> %167, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %170 = bitcast <16 x i8> %168 to <8 x i16>
  %171 = bitcast <16 x i8> %169 to <8 x i16>
  %172 = shufflevector <8 x i16> %170, <8 x i16> %171, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %173 = shufflevector <8 x i16> %170, <8 x i16> %171, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %174 = bitcast <8 x i16> %172 to <4 x i32>
  %175 = bitcast <8 x i16> %173 to <4 x i32>
  %176 = shufflevector <4 x i32> %174, <4 x i32> %175, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = shufflevector <4 x i32> %174, <4 x i32> %175, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %179 = bitcast <4 x i32> %178 to <2 x i64>
  %180 = getelementptr inbounds i8, i8* %134, i64 %11
  %181 = bitcast i8* %180 to i32*
  %182 = load i32, i32* %181, align 1
  %183 = getelementptr inbounds i8, i8* %134, i64 %16
  %184 = bitcast i8* %183 to i32*
  %185 = load i32, i32* %184, align 1
  %186 = getelementptr inbounds i8, i8* %134, i64 %21
  %187 = bitcast i8* %186 to i32*
  %188 = load i32, i32* %187, align 1
  %189 = bitcast i8* %134 to i32*
  %190 = load i32, i32* %189, align 1
  %191 = insertelement <4 x i32> undef, i32 %190, i32 0
  %192 = insertelement <4 x i32> %191, i32 %188, i32 1
  %193 = insertelement <4 x i32> %192, i32 %185, i32 2
  %194 = insertelement <4 x i32> %193, i32 %182, i32 3
  %195 = getelementptr inbounds i8, i8* %134, i64 %32
  %196 = bitcast i8* %195 to i32*
  %197 = load i32, i32* %196, align 1
  %198 = getelementptr inbounds i8, i8* %134, i64 %37
  %199 = bitcast i8* %198 to i32*
  %200 = load i32, i32* %199, align 1
  %201 = getelementptr inbounds i8, i8* %134, i64 %42
  %202 = bitcast i8* %201 to i32*
  %203 = load i32, i32* %202, align 1
  %204 = getelementptr inbounds i8, i8* %134, i64 %46
  %205 = bitcast i8* %204 to i32*
  %206 = load i32, i32* %205, align 1
  %207 = insertelement <4 x i32> undef, i32 %206, i32 0
  %208 = insertelement <4 x i32> %207, i32 %203, i32 1
  %209 = insertelement <4 x i32> %208, i32 %200, i32 2
  %210 = insertelement <4 x i32> %209, i32 %197, i32 3
  %211 = bitcast <4 x i32> %194 to <16 x i8>
  %212 = bitcast <4 x i32> %210 to <16 x i8>
  %213 = shufflevector <16 x i8> %211, <16 x i8> %212, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %214 = shufflevector <16 x i8> %211, <16 x i8> %212, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %215 = bitcast <16 x i8> %213 to <8 x i16>
  %216 = bitcast <16 x i8> %214 to <8 x i16>
  %217 = shufflevector <8 x i16> %215, <8 x i16> %216, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %218 = shufflevector <8 x i16> %215, <8 x i16> %216, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %219 = bitcast <8 x i16> %217 to <4 x i32>
  %220 = bitcast <8 x i16> %218 to <4 x i32>
  %221 = shufflevector <4 x i32> %219, <4 x i32> %220, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %222 = bitcast <4 x i32> %221 to <2 x i64>
  %223 = shufflevector <4 x i32> %219, <4 x i32> %220, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %224 = bitcast <4 x i32> %223 to <2 x i64>
  %225 = shufflevector <2 x i64> %177, <2 x i64> %222, <2 x i32> <i32 0, i32 2>
  %226 = shufflevector <2 x i64> %177, <2 x i64> %222, <2 x i32> <i32 1, i32 3>
  %227 = shufflevector <2 x i64> %179, <2 x i64> %224, <2 x i32> <i32 0, i32 2>
  %228 = shufflevector <2 x i64> %179, <2 x i64> %224, <2 x i32> <i32 1, i32 3>
  %229 = bitcast <2 x i64> %225 to <16 x i8>
  %230 = bitcast <2 x i64> %226 to <16 x i8>
  %231 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %229, <16 x i8> %230) #8
  %232 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %230, <16 x i8> %229) #8
  %233 = or <16 x i8> %232, %231
  %234 = icmp ugt <16 x i8> %133, %233
  %235 = select <16 x i1> %234, <16 x i8> %133, <16 x i8> %233
  %236 = bitcast <2 x i64> %227 to <16 x i8>
  %237 = bitcast <2 x i64> %228 to <16 x i8>
  %238 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %236, <16 x i8> %237) #8
  %239 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %237, <16 x i8> %236) #8
  %240 = or <16 x i8> %239, %238
  %241 = icmp ugt <16 x i8> %235, %240
  %242 = select <16 x i1> %241, <16 x i8> %235, <16 x i8> %240
  %243 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %230, <16 x i8> %236) #8
  %244 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %236, <16 x i8> %230) #8
  %245 = or <16 x i8> %244, %243
  %246 = icmp ugt <16 x i8> %242, %245
  %247 = select <16 x i1> %246, <16 x i8> %242, <16 x i8> %245
  %248 = trunc i32 %3 to i8
  %249 = insertelement <16 x i8> undef, i8 %248, i32 0
  %250 = shufflevector <16 x i8> %249, <16 x i8> undef, <16 x i32> zeroinitializer
  %251 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %247, <16 x i8> %250) #8
  %252 = icmp eq <16 x i8> %251, zeroinitializer
  %253 = trunc i32 %2 to i8
  %254 = insertelement <16 x i8> undef, i8 %253, i32 0
  %255 = shufflevector <16 x i8> %254, <16 x i8> undef, <16 x i32> zeroinitializer
  %256 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %230, <16 x i8> %118) #8
  %257 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %118, <16 x i8> %230) #8
  %258 = or <16 x i8> %257, %256
  %259 = bitcast <16 x i8> %258 to <8 x i16>
  %260 = lshr <8 x i16> %259, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %261 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %229, <16 x i8> %117) #8
  %262 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %117, <16 x i8> %229) #8
  %263 = or <16 x i8> %262, %261
  %264 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %263, <16 x i8> %263) #8
  %265 = bitcast <8 x i16> %260 to <16 x i8>
  %266 = and <16 x i8> %265, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %267 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %264, <16 x i8> %266) #8
  %268 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %267, <16 x i8> %255) #8
  %269 = icmp eq <16 x i8> %268, zeroinitializer
  %270 = and <16 x i1> %252, %269
  %271 = trunc i32 %4 to i8
  %272 = insertelement <16 x i8> undef, i8 %271, i32 0
  %273 = shufflevector <16 x i8> %272, <16 x i8> undef, <16 x i32> zeroinitializer
  %274 = icmp ugt <16 x i8> %121, %233
  %275 = select <16 x i1> %274, <16 x i8> %121, <16 x i8> %233
  %276 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %275, <16 x i8> %273) #8
  %277 = icmp eq <16 x i8> %276, zeroinitializer
  %278 = sext <16 x i1> %277 to <16 x i8>
  %279 = xor <16 x i8> %118, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %280 = xor <16 x i8> %230, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %281 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %279, <16 x i8> %280) #8
  %282 = xor <16 x i8> %229, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %283 = xor <16 x i8> %117, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %284 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %282, <16 x i8> %283) #8
  %285 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %281, <16 x i8> %284) #8
  %286 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %284, <16 x i8> %285) #8
  %287 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %284, <16 x i8> %286) #8
  %288 = xor <16 x i8> %278, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %289 = select <16 x i1> %270, <16 x i8> %287, <16 x i8> zeroinitializer
  %290 = and <16 x i8> %289, %288
  %291 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %290, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %292 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %290, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %293 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %292, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %294 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %292, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %295 = bitcast <16 x i8> %293 to <8 x i16>
  %296 = ashr <8 x i16> %295, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %297 = bitcast <16 x i8> %294 to <8 x i16>
  %298 = ashr <8 x i16> %297, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %299 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %296, <8 x i16> %298) #8
  %300 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %291, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %301 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %291, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %302 = bitcast <16 x i8> %300 to <8 x i16>
  %303 = ashr <8 x i16> %302, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %304 = bitcast <16 x i8> %301 to <8 x i16>
  %305 = ashr <8 x i16> %304, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %306 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %303, <8 x i16> %305) #8
  %307 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %282, <16 x i8> %299) #8
  %308 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %283, <16 x i8> %306) #8
  %309 = and <16 x i8> %289, %278
  %310 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %309, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %311 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %309, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %312 = bitcast <16 x i8> %310 to <8 x i16>
  %313 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %312, <8 x i16> <i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304>) #8
  %314 = bitcast <16 x i8> %311 to <8 x i16>
  %315 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %314, <8 x i16> <i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304>) #8
  %316 = add <8 x i16> %313, <i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63>
  %317 = add <8 x i16> %315, <i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63>
  %318 = add <8 x i16> %316, %313
  %319 = add <8 x i16> %317, %315
  %320 = add <8 x i16> %318, %313
  %321 = add <8 x i16> %319, %315
  %322 = ashr <8 x i16> %316, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %323 = ashr <8 x i16> %317, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %324 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %322, <8 x i16> %323) #8
  %325 = xor <16 x i8> %122, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %326 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %325, <16 x i8> %324) #8
  %327 = xor <16 x i8> %236, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %328 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %327, <16 x i8> %324) #8
  %329 = ashr <8 x i16> %318, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %330 = ashr <8 x i16> %319, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %331 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %329, <8 x i16> %330) #8
  %332 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %279, <16 x i8> %331) #8
  %333 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %280, <16 x i8> %331) #8
  %334 = ashr <8 x i16> %320, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %335 = ashr <8 x i16> %321, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %336 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %334, <8 x i16> %335) #8
  %337 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %308, <16 x i8> %336) #8
  %338 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %307, <16 x i8> %336) #8
  %339 = xor <16 x i8> %326, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %340 = shufflevector <16 x i8> %123, <16 x i8> %339, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %341 = shufflevector <16 x i8> %123, <16 x i8> %339, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %342 = xor <16 x i8> %332, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %343 = xor <16 x i8> %337, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %344 = shufflevector <16 x i8> %342, <16 x i8> %343, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %345 = shufflevector <16 x i8> %342, <16 x i8> %343, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %346 = bitcast <16 x i8> %340 to <8 x i16>
  %347 = bitcast <16 x i8> %344 to <8 x i16>
  %348 = shufflevector <8 x i16> %346, <8 x i16> %347, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %349 = shufflevector <8 x i16> %346, <8 x i16> %347, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %350 = bitcast <16 x i8> %341 to <8 x i16>
  %351 = bitcast <16 x i8> %345 to <8 x i16>
  %352 = shufflevector <8 x i16> %350, <8 x i16> %351, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %353 = shufflevector <8 x i16> %350, <8 x i16> %351, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %354 = bitcast <8 x i16> %348 to <4 x i32>
  %355 = extractelement <4 x i32> %354, i32 0
  store i32 %355, i32* %25, align 1
  %356 = bitcast <8 x i16> %348 to <16 x i8>
  %357 = shufflevector <16 x i8> %356, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %358 = bitcast <16 x i8> %357 to <4 x i32>
  %359 = extractelement <4 x i32> %358, i32 0
  store i32 %359, i32* %48, align 1
  %360 = shufflevector <16 x i8> %357, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %361 = getelementptr inbounds i8, i8* %47, i64 %46
  %362 = bitcast <16 x i8> %360 to <4 x i32>
  %363 = extractelement <4 x i32> %362, i32 0
  %364 = bitcast i8* %361 to i32*
  store i32 %363, i32* %364, align 1
  %365 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %366 = getelementptr inbounds i8, i8* %361, i64 %46
  %367 = bitcast <16 x i8> %365 to <4 x i32>
  %368 = extractelement <4 x i32> %367, i32 0
  %369 = bitcast i8* %366 to i32*
  store i32 %368, i32* %369, align 1
  %370 = bitcast <8 x i16> %349 to <4 x i32>
  %371 = extractelement <4 x i32> %370, i32 0
  store i32 %371, i32* %23, align 1
  %372 = bitcast <8 x i16> %349 to <16 x i8>
  %373 = shufflevector <16 x i8> %372, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %374 = getelementptr inbounds i8, i8* %22, i64 %46
  %375 = bitcast <16 x i8> %373 to <4 x i32>
  %376 = extractelement <4 x i32> %375, i32 0
  %377 = bitcast i8* %374 to i32*
  store i32 %376, i32* %377, align 1
  %378 = shufflevector <16 x i8> %373, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %379 = getelementptr inbounds i8, i8* %374, i64 %46
  %380 = bitcast <16 x i8> %378 to <4 x i32>
  %381 = extractelement <4 x i32> %380, i32 0
  %382 = bitcast i8* %379 to i32*
  store i32 %381, i32* %382, align 1
  %383 = shufflevector <16 x i8> %378, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %384 = getelementptr inbounds i8, i8* %379, i64 %46
  %385 = bitcast <16 x i8> %383 to <4 x i32>
  %386 = extractelement <4 x i32> %385, i32 0
  %387 = bitcast i8* %384 to i32*
  store i32 %386, i32* %387, align 1
  %388 = bitcast <8 x i16> %352 to <4 x i32>
  %389 = extractelement <4 x i32> %388, i32 0
  store i32 %389, i32* %77, align 1
  %390 = bitcast <8 x i16> %352 to <16 x i8>
  %391 = shufflevector <16 x i8> %390, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %392 = bitcast <16 x i8> %391 to <4 x i32>
  %393 = extractelement <4 x i32> %392, i32 0
  store i32 %393, i32* %93, align 1
  %394 = shufflevector <16 x i8> %391, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %395 = getelementptr inbounds i8, i8* %92, i64 %46
  %396 = bitcast <16 x i8> %394 to <4 x i32>
  %397 = extractelement <4 x i32> %396, i32 0
  %398 = bitcast i8* %395 to i32*
  store i32 %397, i32* %398, align 1
  %399 = shufflevector <16 x i8> %394, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %400 = getelementptr inbounds i8, i8* %395, i64 %46
  %401 = bitcast <16 x i8> %399 to <4 x i32>
  %402 = extractelement <4 x i32> %401, i32 0
  %403 = bitcast i8* %400 to i32*
  store i32 %402, i32* %403, align 1
  %404 = bitcast <8 x i16> %353 to <4 x i32>
  %405 = extractelement <4 x i32> %404, i32 0
  store i32 %405, i32* %75, align 1
  %406 = bitcast <8 x i16> %353 to <16 x i8>
  %407 = shufflevector <16 x i8> %406, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %408 = getelementptr inbounds i8, i8* %74, i64 %46
  %409 = bitcast <16 x i8> %407 to <4 x i32>
  %410 = extractelement <4 x i32> %409, i32 0
  %411 = bitcast i8* %408 to i32*
  store i32 %410, i32* %411, align 1
  %412 = shufflevector <16 x i8> %407, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %413 = getelementptr inbounds i8, i8* %408, i64 %46
  %414 = bitcast <16 x i8> %412 to <4 x i32>
  %415 = extractelement <4 x i32> %414, i32 0
  %416 = bitcast i8* %413 to i32*
  store i32 %415, i32* %416, align 1
  %417 = shufflevector <16 x i8> %412, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %418 = getelementptr inbounds i8, i8* %413, i64 %46
  %419 = bitcast <16 x i8> %417 to <4 x i32>
  %420 = extractelement <4 x i32> %419, i32 0
  %421 = bitcast i8* %418 to i32*
  store i32 %420, i32* %421, align 1
  %422 = xor <16 x i8> %333, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %423 = xor <16 x i8> %338, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %424 = shufflevector <16 x i8> %423, <16 x i8> %422, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %425 = shufflevector <16 x i8> %423, <16 x i8> %422, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %426 = xor <16 x i8> %328, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %427 = shufflevector <16 x i8> %426, <16 x i8> %237, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %428 = shufflevector <16 x i8> %426, <16 x i8> %237, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %429 = bitcast <16 x i8> %424 to <8 x i16>
  %430 = bitcast <16 x i8> %427 to <8 x i16>
  %431 = shufflevector <8 x i16> %429, <8 x i16> %430, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %432 = shufflevector <8 x i16> %429, <8 x i16> %430, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = bitcast <16 x i8> %425 to <8 x i16>
  %434 = bitcast <16 x i8> %428 to <8 x i16>
  %435 = shufflevector <8 x i16> %433, <8 x i16> %434, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %436 = shufflevector <8 x i16> %433, <8 x i16> %434, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %437 = bitcast <8 x i16> %431 to <4 x i32>
  %438 = extractelement <4 x i32> %437, i32 0
  store i32 %438, i32* %144, align 1
  %439 = bitcast <8 x i16> %431 to <16 x i8>
  %440 = shufflevector <16 x i8> %439, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %441 = bitcast <16 x i8> %440 to <4 x i32>
  %442 = extractelement <4 x i32> %441, i32 0
  store i32 %442, i32* %160, align 1
  %443 = shufflevector <16 x i8> %440, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %444 = getelementptr inbounds i8, i8* %159, i64 %46
  %445 = bitcast <16 x i8> %443 to <4 x i32>
  %446 = extractelement <4 x i32> %445, i32 0
  %447 = bitcast i8* %444 to i32*
  store i32 %446, i32* %447, align 1
  %448 = shufflevector <16 x i8> %443, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %449 = getelementptr inbounds i8, i8* %444, i64 %46
  %450 = bitcast <16 x i8> %448 to <4 x i32>
  %451 = extractelement <4 x i32> %450, i32 0
  %452 = bitcast i8* %449 to i32*
  store i32 %451, i32* %452, align 1
  %453 = bitcast <8 x i16> %432 to <4 x i32>
  %454 = extractelement <4 x i32> %453, i32 0
  store i32 %454, i32* %142, align 1
  %455 = bitcast <8 x i16> %432 to <16 x i8>
  %456 = shufflevector <16 x i8> %455, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %457 = getelementptr inbounds i8, i8* %141, i64 %46
  %458 = bitcast <16 x i8> %456 to <4 x i32>
  %459 = extractelement <4 x i32> %458, i32 0
  %460 = bitcast i8* %457 to i32*
  store i32 %459, i32* %460, align 1
  %461 = shufflevector <16 x i8> %456, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %462 = getelementptr inbounds i8, i8* %457, i64 %46
  %463 = bitcast <16 x i8> %461 to <4 x i32>
  %464 = extractelement <4 x i32> %463, i32 0
  %465 = bitcast i8* %462 to i32*
  store i32 %464, i32* %465, align 1
  %466 = shufflevector <16 x i8> %461, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %467 = getelementptr inbounds i8, i8* %462, i64 %46
  %468 = bitcast <16 x i8> %466 to <4 x i32>
  %469 = extractelement <4 x i32> %468, i32 0
  %470 = bitcast i8* %467 to i32*
  store i32 %469, i32* %470, align 1
  %471 = bitcast <8 x i16> %435 to <4 x i32>
  %472 = extractelement <4 x i32> %471, i32 0
  store i32 %472, i32* %189, align 1
  %473 = bitcast <8 x i16> %435 to <16 x i8>
  %474 = shufflevector <16 x i8> %473, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %475 = bitcast <16 x i8> %474 to <4 x i32>
  %476 = extractelement <4 x i32> %475, i32 0
  store i32 %476, i32* %205, align 1
  %477 = shufflevector <16 x i8> %474, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %478 = getelementptr inbounds i8, i8* %204, i64 %46
  %479 = bitcast <16 x i8> %477 to <4 x i32>
  %480 = extractelement <4 x i32> %479, i32 0
  %481 = bitcast i8* %478 to i32*
  store i32 %480, i32* %481, align 1
  %482 = shufflevector <16 x i8> %477, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %483 = getelementptr inbounds i8, i8* %478, i64 %46
  %484 = bitcast <16 x i8> %482 to <4 x i32>
  %485 = extractelement <4 x i32> %484, i32 0
  %486 = bitcast i8* %483 to i32*
  store i32 %485, i32* %486, align 1
  %487 = bitcast <8 x i16> %436 to <4 x i32>
  %488 = extractelement <4 x i32> %487, i32 0
  store i32 %488, i32* %187, align 1
  %489 = bitcast <8 x i16> %436 to <16 x i8>
  %490 = shufflevector <16 x i8> %489, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %491 = getelementptr inbounds i8, i8* %186, i64 %46
  %492 = bitcast <16 x i8> %490 to <4 x i32>
  %493 = extractelement <4 x i32> %492, i32 0
  %494 = bitcast i8* %491 to i32*
  store i32 %493, i32* %494, align 1
  %495 = shufflevector <16 x i8> %490, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %496 = getelementptr inbounds i8, i8* %491, i64 %46
  %497 = bitcast <16 x i8> %495 to <4 x i32>
  %498 = extractelement <4 x i32> %497, i32 0
  %499 = bitcast i8* %496 to i32*
  store i32 %498, i32* %499, align 1
  %500 = shufflevector <16 x i8> %495, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %501 = getelementptr inbounds i8, i8* %496, i64 %46
  %502 = bitcast <16 x i8> %500 to <4 x i32>
  %503 = extractelement <4 x i32> %502, i32 0
  %504 = bitcast i8* %501 to i32*
  store i32 %503, i32* %504, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @VFilter8_SSE2(i8* nocapture, i8* nocapture, i32, i32, i32, i32) #1 {
  %7 = shl nsw i32 %2, 2
  %8 = sext i32 %7 to i64
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i8, i8* %0, i64 %9
  %11 = bitcast i8* %10 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = getelementptr inbounds i8, i8* %1, i64 %9
  %15 = bitcast i8* %14 to i64*
  %16 = load i64, i64* %15, align 1
  %17 = insertelement <2 x i64> %13, i64 %16, i32 1
  %18 = sext i32 %2 to i64
  %19 = getelementptr inbounds i8, i8* %10, i64 %18
  %20 = bitcast i8* %19 to i64*
  %21 = load i64, i64* %20, align 1
  %22 = insertelement <2 x i64> undef, i64 %21, i32 0
  %23 = getelementptr inbounds i8, i8* %14, i64 %18
  %24 = bitcast i8* %23 to i64*
  %25 = load i64, i64* %24, align 1
  %26 = insertelement <2 x i64> %22, i64 %25, i32 1
  %27 = shl nsw i32 %2, 1
  %28 = sext i32 %27 to i64
  %29 = getelementptr inbounds i8, i8* %10, i64 %28
  %30 = bitcast i8* %29 to i64*
  %31 = load i64, i64* %30, align 1
  %32 = insertelement <2 x i64> undef, i64 %31, i32 0
  %33 = getelementptr inbounds i8, i8* %14, i64 %28
  %34 = bitcast i8* %33 to i64*
  %35 = load i64, i64* %34, align 1
  %36 = insertelement <2 x i64> %32, i64 %35, i32 1
  %37 = mul nsw i32 %2, 3
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds i8, i8* %10, i64 %38
  %40 = bitcast i8* %39 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> undef, i64 %41, i32 0
  %43 = getelementptr inbounds i8, i8* %14, i64 %38
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> %42, i64 %45, i32 1
  %47 = bitcast <2 x i64> %46 to <16 x i8>
  %48 = bitcast <2 x i64> %36 to <16 x i8>
  %49 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %48) #8
  %50 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %48, <16 x i8> %47) #8
  %51 = or <16 x i8> %50, %49
  %52 = bitcast <2 x i64> %26 to <16 x i8>
  %53 = bitcast <2 x i64> %17 to <16 x i8>
  %54 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %52, <16 x i8> %53) #8
  %55 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %53, <16 x i8> %52) #8
  %56 = or <16 x i8> %55, %54
  %57 = icmp ugt <16 x i8> %51, %56
  %58 = select <16 x i1> %57, <16 x i8> %51, <16 x i8> %56
  %59 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %48, <16 x i8> %52) #8
  %60 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %52, <16 x i8> %48) #8
  %61 = or <16 x i8> %60, %59
  %62 = icmp ugt <16 x i8> %58, %61
  %63 = select <16 x i1> %62, <16 x i8> %58, <16 x i8> %61
  %64 = bitcast i8* %0 to i64*
  %65 = load i64, i64* %64, align 1
  %66 = insertelement <2 x i64> undef, i64 %65, i32 0
  %67 = bitcast i8* %1 to i64*
  %68 = load i64, i64* %67, align 1
  %69 = insertelement <2 x i64> %66, i64 %68, i32 1
  %70 = getelementptr inbounds i8, i8* %0, i64 %18
  %71 = bitcast i8* %70 to i64*
  %72 = load i64, i64* %71, align 1
  %73 = insertelement <2 x i64> undef, i64 %72, i32 0
  %74 = getelementptr inbounds i8, i8* %1, i64 %18
  %75 = bitcast i8* %74 to i64*
  %76 = load i64, i64* %75, align 1
  %77 = insertelement <2 x i64> %73, i64 %76, i32 1
  %78 = getelementptr inbounds i8, i8* %0, i64 %28
  %79 = bitcast i8* %78 to i64*
  %80 = load i64, i64* %79, align 1
  %81 = insertelement <2 x i64> undef, i64 %80, i32 0
  %82 = getelementptr inbounds i8, i8* %1, i64 %28
  %83 = bitcast i8* %82 to i64*
  %84 = load i64, i64* %83, align 1
  %85 = insertelement <2 x i64> %81, i64 %84, i32 1
  %86 = getelementptr inbounds i8, i8* %0, i64 %38
  %87 = bitcast i8* %86 to i64*
  %88 = load i64, i64* %87, align 1
  %89 = insertelement <2 x i64> undef, i64 %88, i32 0
  %90 = getelementptr inbounds i8, i8* %1, i64 %38
  %91 = bitcast i8* %90 to i64*
  %92 = load i64, i64* %91, align 1
  %93 = insertelement <2 x i64> %89, i64 %92, i32 1
  %94 = bitcast <2 x i64> %69 to <16 x i8>
  %95 = bitcast <2 x i64> %77 to <16 x i8>
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %94, <16 x i8> %95) #8
  %97 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %94) #8
  %98 = or <16 x i8> %97, %96
  %99 = icmp ugt <16 x i8> %63, %98
  %100 = select <16 x i1> %99, <16 x i8> %63, <16 x i8> %98
  %101 = bitcast <2 x i64> %85 to <16 x i8>
  %102 = bitcast <2 x i64> %93 to <16 x i8>
  %103 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %101, <16 x i8> %102) #8
  %104 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %102, <16 x i8> %101) #8
  %105 = or <16 x i8> %104, %103
  %106 = icmp ugt <16 x i8> %100, %105
  %107 = select <16 x i1> %106, <16 x i8> %100, <16 x i8> %105
  %108 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %101) #8
  %109 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %101, <16 x i8> %95) #8
  %110 = or <16 x i8> %109, %108
  %111 = icmp ugt <16 x i8> %107, %110
  %112 = select <16 x i1> %111, <16 x i8> %107, <16 x i8> %110
  %113 = trunc i32 %4 to i8
  %114 = insertelement <16 x i8> undef, i8 %113, i32 0
  %115 = shufflevector <16 x i8> %114, <16 x i8> undef, <16 x i32> zeroinitializer
  %116 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %112, <16 x i8> %115) #8
  %117 = icmp eq <16 x i8> %116, zeroinitializer
  %118 = trunc i32 %3 to i8
  %119 = insertelement <16 x i8> undef, i8 %118, i32 0
  %120 = shufflevector <16 x i8> %119, <16 x i8> undef, <16 x i32> zeroinitializer
  %121 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %95, <16 x i8> %48) #8
  %122 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %48, <16 x i8> %95) #8
  %123 = or <16 x i8> %122, %121
  %124 = bitcast <16 x i8> %123 to <8 x i16>
  %125 = lshr <8 x i16> %124, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %126 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %94, <16 x i8> %47) #8
  %127 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %94) #8
  %128 = or <16 x i8> %127, %126
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> %128) #8
  %130 = bitcast <8 x i16> %125 to <16 x i8>
  %131 = and <16 x i8> %130, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %132 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> %131) #8
  %133 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %132, <16 x i8> %120) #8
  %134 = icmp eq <16 x i8> %133, zeroinitializer
  %135 = and <16 x i1> %117, %134
  %136 = trunc i32 %5 to i8
  %137 = insertelement <16 x i8> undef, i8 %136, i32 0
  %138 = shufflevector <16 x i8> %137, <16 x i8> undef, <16 x i32> zeroinitializer
  %139 = icmp ugt <16 x i8> %51, %98
  %140 = select <16 x i1> %139, <16 x i8> %51, <16 x i8> %98
  %141 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %140, <16 x i8> %138) #8
  %142 = icmp eq <16 x i8> %141, zeroinitializer
  %143 = sext <16 x i1> %142 to <16 x i8>
  %144 = xor <16 x i8> %48, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %145 = xor <16 x i8> %95, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %146 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %144, <16 x i8> %145) #8
  %147 = xor <16 x i8> %94, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %148 = xor <16 x i8> %47, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %149 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %147, <16 x i8> %148) #8
  %150 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %146, <16 x i8> %149) #8
  %151 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %149, <16 x i8> %150) #8
  %152 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %149, <16 x i8> %151) #8
  %153 = xor <16 x i8> %143, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %154 = select <16 x i1> %135, <16 x i8> %152, <16 x i8> zeroinitializer
  %155 = and <16 x i8> %154, %153
  %156 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %155, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %157 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %155, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %158 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %157, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %159 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %157, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %160 = bitcast <16 x i8> %158 to <8 x i16>
  %161 = ashr <8 x i16> %160, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %162 = bitcast <16 x i8> %159 to <8 x i16>
  %163 = ashr <8 x i16> %162, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %161, <8 x i16> %163) #8
  %165 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %156, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %166 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %156, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %167 = bitcast <16 x i8> %165 to <8 x i16>
  %168 = ashr <8 x i16> %167, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %169 = bitcast <16 x i8> %166 to <8 x i16>
  %170 = ashr <8 x i16> %169, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %171 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %168, <8 x i16> %170) #8
  %172 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %147, <16 x i8> %164) #8
  %173 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %148, <16 x i8> %171) #8
  %174 = and <16 x i8> %154, %143
  %175 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %174, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %176 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %174, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %177 = bitcast <16 x i8> %175 to <8 x i16>
  %178 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %177, <8 x i16> <i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304>) #8
  %179 = bitcast <16 x i8> %176 to <8 x i16>
  %180 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %179, <8 x i16> <i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304>) #8
  %181 = add <8 x i16> %178, <i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63>
  %182 = add <8 x i16> %180, <i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63>
  %183 = add <8 x i16> %181, %178
  %184 = add <8 x i16> %182, %180
  %185 = add <8 x i16> %183, %178
  %186 = add <8 x i16> %184, %180
  %187 = ashr <8 x i16> %181, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %188 = ashr <8 x i16> %182, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %189 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %187, <8 x i16> %188) #8
  %190 = xor <16 x i8> %52, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %191 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %190, <16 x i8> %189) #8
  %192 = bitcast <16 x i8> %191 to <2 x i64>
  %193 = xor <16 x i8> %101, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %194 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %193, <16 x i8> %189) #8
  %195 = bitcast <16 x i8> %194 to <2 x i64>
  %196 = xor <2 x i64> %192, <i64 -9187201950435737472, i64 -9187201950435737472>
  %197 = xor <2 x i64> %195, <i64 -9187201950435737472, i64 -9187201950435737472>
  %198 = ashr <8 x i16> %183, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %199 = ashr <8 x i16> %184, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %200 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %198, <8 x i16> %199) #8
  %201 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %144, <16 x i8> %200) #8
  %202 = bitcast <16 x i8> %201 to <2 x i64>
  %203 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %145, <16 x i8> %200) #8
  %204 = bitcast <16 x i8> %203 to <2 x i64>
  %205 = xor <2 x i64> %202, <i64 -9187201950435737472, i64 -9187201950435737472>
  %206 = xor <2 x i64> %204, <i64 -9187201950435737472, i64 -9187201950435737472>
  %207 = ashr <8 x i16> %185, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %208 = ashr <8 x i16> %186, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %209 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %207, <8 x i16> %208) #8
  %210 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %173, <16 x i8> %209) #8
  %211 = bitcast <16 x i8> %210 to <2 x i64>
  %212 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %172, <16 x i8> %209) #8
  %213 = bitcast <16 x i8> %212 to <2 x i64>
  %214 = xor <2 x i64> %211, <i64 -9187201950435737472, i64 -9187201950435737472>
  %215 = xor <2 x i64> %213, <i64 -9187201950435737472, i64 -9187201950435737472>
  %216 = mul nsw i32 %2, -3
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds i8, i8* %0, i64 %217
  %219 = extractelement <2 x i64> %196, i32 0
  %220 = bitcast i8* %218 to i64*
  store i64 %219, i64* %220, align 1
  %221 = bitcast <2 x i64> %196 to <16 x i8>
  %222 = shufflevector <16 x i8> %221, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %223 = bitcast <16 x i8> %222 to <2 x i64>
  %224 = getelementptr inbounds i8, i8* %1, i64 %217
  %225 = extractelement <2 x i64> %223, i32 0
  %226 = bitcast i8* %224 to i64*
  store i64 %225, i64* %226, align 1
  %227 = mul nsw i32 %2, -2
  %228 = sext i32 %227 to i64
  %229 = getelementptr inbounds i8, i8* %0, i64 %228
  %230 = extractelement <2 x i64> %205, i32 0
  %231 = bitcast i8* %229 to i64*
  store i64 %230, i64* %231, align 1
  %232 = bitcast <2 x i64> %205 to <16 x i8>
  %233 = shufflevector <16 x i8> %232, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %234 = bitcast <16 x i8> %233 to <2 x i64>
  %235 = getelementptr inbounds i8, i8* %1, i64 %228
  %236 = extractelement <2 x i64> %234, i32 0
  %237 = bitcast i8* %235 to i64*
  store i64 %236, i64* %237, align 1
  %238 = sub nsw i32 0, %2
  %239 = sext i32 %238 to i64
  %240 = getelementptr inbounds i8, i8* %0, i64 %239
  %241 = extractelement <2 x i64> %214, i32 0
  %242 = bitcast i8* %240 to i64*
  store i64 %241, i64* %242, align 1
  %243 = bitcast <2 x i64> %214 to <16 x i8>
  %244 = shufflevector <16 x i8> %243, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %245 = bitcast <16 x i8> %244 to <2 x i64>
  %246 = getelementptr inbounds i8, i8* %1, i64 %239
  %247 = extractelement <2 x i64> %245, i32 0
  %248 = bitcast i8* %246 to i64*
  store i64 %247, i64* %248, align 1
  %249 = extractelement <2 x i64> %215, i32 0
  store i64 %249, i64* %64, align 1
  %250 = bitcast <2 x i64> %215 to <16 x i8>
  %251 = shufflevector <16 x i8> %250, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %252 = bitcast <16 x i8> %251 to <2 x i64>
  %253 = extractelement <2 x i64> %252, i32 0
  store i64 %253, i64* %67, align 1
  %254 = extractelement <2 x i64> %206, i32 0
  store i64 %254, i64* %71, align 1
  %255 = bitcast <2 x i64> %206 to <16 x i8>
  %256 = shufflevector <16 x i8> %255, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %257 = bitcast <16 x i8> %256 to <2 x i64>
  %258 = extractelement <2 x i64> %257, i32 0
  store i64 %258, i64* %75, align 1
  %259 = extractelement <2 x i64> %197, i32 0
  store i64 %259, i64* %79, align 1
  %260 = bitcast <2 x i64> %197 to <16 x i8>
  %261 = shufflevector <16 x i8> %260, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %262 = bitcast <16 x i8> %261 to <2 x i64>
  %263 = extractelement <2 x i64> %262, i32 0
  store i64 %263, i64* %83, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @HFilter8_SSE2(i8* nocapture, i8* nocapture, i32, i32, i32, i32) #1 {
  %7 = getelementptr inbounds i8, i8* %0, i64 -4
  %8 = getelementptr inbounds i8, i8* %1, i64 -4
  %9 = mul nsw i32 %2, 6
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %7, i64 %10
  %12 = bitcast i8* %11 to i32*
  %13 = load i32, i32* %12, align 1
  %14 = shl nsw i32 %2, 1
  %15 = sext i32 %14 to i64
  %16 = getelementptr inbounds i8, i8* %7, i64 %15
  %17 = bitcast i8* %16 to i32*
  %18 = load i32, i32* %17, align 1
  %19 = shl nsw i32 %2, 2
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i8, i8* %7, i64 %20
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 1
  %24 = bitcast i8* %7 to i32*
  %25 = load i32, i32* %24, align 1
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = insertelement <4 x i32> %26, i32 %23, i32 1
  %28 = insertelement <4 x i32> %27, i32 %18, i32 2
  %29 = insertelement <4 x i32> %28, i32 %13, i32 3
  %30 = mul nsw i32 %2, 7
  %31 = sext i32 %30 to i64
  %32 = getelementptr inbounds i8, i8* %7, i64 %31
  %33 = bitcast i8* %32 to i32*
  %34 = load i32, i32* %33, align 1
  %35 = mul nsw i32 %2, 3
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i8, i8* %7, i64 %36
  %38 = bitcast i8* %37 to i32*
  %39 = load i32, i32* %38, align 1
  %40 = mul nsw i32 %2, 5
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds i8, i8* %7, i64 %41
  %43 = bitcast i8* %42 to i32*
  %44 = load i32, i32* %43, align 1
  %45 = sext i32 %2 to i64
  %46 = getelementptr inbounds i8, i8* %7, i64 %45
  %47 = bitcast i8* %46 to i32*
  %48 = load i32, i32* %47, align 1
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = insertelement <4 x i32> %49, i32 %44, i32 1
  %51 = insertelement <4 x i32> %50, i32 %39, i32 2
  %52 = insertelement <4 x i32> %51, i32 %34, i32 3
  %53 = bitcast <4 x i32> %29 to <16 x i8>
  %54 = bitcast <4 x i32> %52 to <16 x i8>
  %55 = shufflevector <16 x i8> %53, <16 x i8> %54, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %56 = shufflevector <16 x i8> %53, <16 x i8> %54, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = bitcast <16 x i8> %55 to <8 x i16>
  %58 = bitcast <16 x i8> %56 to <8 x i16>
  %59 = shufflevector <8 x i16> %57, <8 x i16> %58, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %60 = shufflevector <8 x i16> %57, <8 x i16> %58, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %61 = bitcast <8 x i16> %59 to <4 x i32>
  %62 = bitcast <8 x i16> %60 to <4 x i32>
  %63 = shufflevector <4 x i32> %61, <4 x i32> %62, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %64 = bitcast <4 x i32> %63 to <2 x i64>
  %65 = shufflevector <4 x i32> %61, <4 x i32> %62, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %66 = bitcast <4 x i32> %65 to <2 x i64>
  %67 = getelementptr inbounds i8, i8* %8, i64 %10
  %68 = bitcast i8* %67 to i32*
  %69 = load i32, i32* %68, align 1
  %70 = getelementptr inbounds i8, i8* %8, i64 %15
  %71 = bitcast i8* %70 to i32*
  %72 = load i32, i32* %71, align 1
  %73 = getelementptr inbounds i8, i8* %8, i64 %20
  %74 = bitcast i8* %73 to i32*
  %75 = load i32, i32* %74, align 1
  %76 = bitcast i8* %8 to i32*
  %77 = load i32, i32* %76, align 1
  %78 = insertelement <4 x i32> undef, i32 %77, i32 0
  %79 = insertelement <4 x i32> %78, i32 %75, i32 1
  %80 = insertelement <4 x i32> %79, i32 %72, i32 2
  %81 = insertelement <4 x i32> %80, i32 %69, i32 3
  %82 = getelementptr inbounds i8, i8* %8, i64 %31
  %83 = bitcast i8* %82 to i32*
  %84 = load i32, i32* %83, align 1
  %85 = getelementptr inbounds i8, i8* %8, i64 %36
  %86 = bitcast i8* %85 to i32*
  %87 = load i32, i32* %86, align 1
  %88 = getelementptr inbounds i8, i8* %8, i64 %41
  %89 = bitcast i8* %88 to i32*
  %90 = load i32, i32* %89, align 1
  %91 = getelementptr inbounds i8, i8* %8, i64 %45
  %92 = bitcast i8* %91 to i32*
  %93 = load i32, i32* %92, align 1
  %94 = insertelement <4 x i32> undef, i32 %93, i32 0
  %95 = insertelement <4 x i32> %94, i32 %90, i32 1
  %96 = insertelement <4 x i32> %95, i32 %87, i32 2
  %97 = insertelement <4 x i32> %96, i32 %84, i32 3
  %98 = bitcast <4 x i32> %81 to <16 x i8>
  %99 = bitcast <4 x i32> %97 to <16 x i8>
  %100 = shufflevector <16 x i8> %98, <16 x i8> %99, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %101 = shufflevector <16 x i8> %98, <16 x i8> %99, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %102 = bitcast <16 x i8> %100 to <8 x i16>
  %103 = bitcast <16 x i8> %101 to <8 x i16>
  %104 = shufflevector <8 x i16> %102, <8 x i16> %103, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %105 = shufflevector <8 x i16> %102, <8 x i16> %103, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %106 = bitcast <8 x i16> %104 to <4 x i32>
  %107 = bitcast <8 x i16> %105 to <4 x i32>
  %108 = shufflevector <4 x i32> %106, <4 x i32> %107, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %109 = bitcast <4 x i32> %108 to <2 x i64>
  %110 = shufflevector <4 x i32> %106, <4 x i32> %107, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %111 = bitcast <4 x i32> %110 to <2 x i64>
  %112 = shufflevector <2 x i64> %64, <2 x i64> %109, <2 x i32> <i32 0, i32 2>
  %113 = shufflevector <2 x i64> %64, <2 x i64> %109, <2 x i32> <i32 1, i32 3>
  %114 = shufflevector <2 x i64> %66, <2 x i64> %111, <2 x i32> <i32 0, i32 2>
  %115 = shufflevector <2 x i64> %66, <2 x i64> %111, <2 x i32> <i32 1, i32 3>
  %116 = bitcast <2 x i64> %115 to <16 x i8>
  %117 = bitcast <2 x i64> %114 to <16 x i8>
  %118 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %116, <16 x i8> %117) #8
  %119 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %117, <16 x i8> %116) #8
  %120 = or <16 x i8> %119, %118
  %121 = bitcast <2 x i64> %113 to <16 x i8>
  %122 = bitcast <2 x i64> %112 to <16 x i8>
  %123 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %121, <16 x i8> %122) #8
  %124 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %122, <16 x i8> %121) #8
  %125 = or <16 x i8> %124, %123
  %126 = icmp ugt <16 x i8> %120, %125
  %127 = select <16 x i1> %126, <16 x i8> %120, <16 x i8> %125
  %128 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %117, <16 x i8> %121) #8
  %129 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %121, <16 x i8> %117) #8
  %130 = or <16 x i8> %129, %128
  %131 = icmp ugt <16 x i8> %127, %130
  %132 = select <16 x i1> %131, <16 x i8> %127, <16 x i8> %130
  %133 = getelementptr inbounds i8, i8* %0, i64 %10
  %134 = bitcast i8* %133 to i32*
  %135 = load i32, i32* %134, align 1
  %136 = getelementptr inbounds i8, i8* %0, i64 %15
  %137 = bitcast i8* %136 to i32*
  %138 = load i32, i32* %137, align 1
  %139 = getelementptr inbounds i8, i8* %0, i64 %20
  %140 = bitcast i8* %139 to i32*
  %141 = load i32, i32* %140, align 1
  %142 = bitcast i8* %0 to i32*
  %143 = load i32, i32* %142, align 1
  %144 = insertelement <4 x i32> undef, i32 %143, i32 0
  %145 = insertelement <4 x i32> %144, i32 %141, i32 1
  %146 = insertelement <4 x i32> %145, i32 %138, i32 2
  %147 = insertelement <4 x i32> %146, i32 %135, i32 3
  %148 = getelementptr inbounds i8, i8* %0, i64 %31
  %149 = bitcast i8* %148 to i32*
  %150 = load i32, i32* %149, align 1
  %151 = getelementptr inbounds i8, i8* %0, i64 %36
  %152 = bitcast i8* %151 to i32*
  %153 = load i32, i32* %152, align 1
  %154 = getelementptr inbounds i8, i8* %0, i64 %41
  %155 = bitcast i8* %154 to i32*
  %156 = load i32, i32* %155, align 1
  %157 = getelementptr inbounds i8, i8* %0, i64 %45
  %158 = bitcast i8* %157 to i32*
  %159 = load i32, i32* %158, align 1
  %160 = insertelement <4 x i32> undef, i32 %159, i32 0
  %161 = insertelement <4 x i32> %160, i32 %156, i32 1
  %162 = insertelement <4 x i32> %161, i32 %153, i32 2
  %163 = insertelement <4 x i32> %162, i32 %150, i32 3
  %164 = bitcast <4 x i32> %147 to <16 x i8>
  %165 = bitcast <4 x i32> %163 to <16 x i8>
  %166 = shufflevector <16 x i8> %164, <16 x i8> %165, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %167 = shufflevector <16 x i8> %164, <16 x i8> %165, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %168 = bitcast <16 x i8> %166 to <8 x i16>
  %169 = bitcast <16 x i8> %167 to <8 x i16>
  %170 = shufflevector <8 x i16> %168, <8 x i16> %169, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %171 = shufflevector <8 x i16> %168, <8 x i16> %169, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %172 = bitcast <8 x i16> %170 to <4 x i32>
  %173 = bitcast <8 x i16> %171 to <4 x i32>
  %174 = shufflevector <4 x i32> %172, <4 x i32> %173, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %175 = bitcast <4 x i32> %174 to <2 x i64>
  %176 = shufflevector <4 x i32> %172, <4 x i32> %173, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = getelementptr inbounds i8, i8* %1, i64 %10
  %179 = bitcast i8* %178 to i32*
  %180 = load i32, i32* %179, align 1
  %181 = getelementptr inbounds i8, i8* %1, i64 %15
  %182 = bitcast i8* %181 to i32*
  %183 = load i32, i32* %182, align 1
  %184 = getelementptr inbounds i8, i8* %1, i64 %20
  %185 = bitcast i8* %184 to i32*
  %186 = load i32, i32* %185, align 1
  %187 = bitcast i8* %1 to i32*
  %188 = load i32, i32* %187, align 1
  %189 = insertelement <4 x i32> undef, i32 %188, i32 0
  %190 = insertelement <4 x i32> %189, i32 %186, i32 1
  %191 = insertelement <4 x i32> %190, i32 %183, i32 2
  %192 = insertelement <4 x i32> %191, i32 %180, i32 3
  %193 = getelementptr inbounds i8, i8* %1, i64 %31
  %194 = bitcast i8* %193 to i32*
  %195 = load i32, i32* %194, align 1
  %196 = getelementptr inbounds i8, i8* %1, i64 %36
  %197 = bitcast i8* %196 to i32*
  %198 = load i32, i32* %197, align 1
  %199 = getelementptr inbounds i8, i8* %1, i64 %41
  %200 = bitcast i8* %199 to i32*
  %201 = load i32, i32* %200, align 1
  %202 = getelementptr inbounds i8, i8* %1, i64 %45
  %203 = bitcast i8* %202 to i32*
  %204 = load i32, i32* %203, align 1
  %205 = insertelement <4 x i32> undef, i32 %204, i32 0
  %206 = insertelement <4 x i32> %205, i32 %201, i32 1
  %207 = insertelement <4 x i32> %206, i32 %198, i32 2
  %208 = insertelement <4 x i32> %207, i32 %195, i32 3
  %209 = bitcast <4 x i32> %192 to <16 x i8>
  %210 = bitcast <4 x i32> %208 to <16 x i8>
  %211 = shufflevector <16 x i8> %209, <16 x i8> %210, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %212 = shufflevector <16 x i8> %209, <16 x i8> %210, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %213 = bitcast <16 x i8> %211 to <8 x i16>
  %214 = bitcast <16 x i8> %212 to <8 x i16>
  %215 = shufflevector <8 x i16> %213, <8 x i16> %214, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %216 = shufflevector <8 x i16> %213, <8 x i16> %214, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = shufflevector <4 x i32> %217, <4 x i32> %218, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %220 = bitcast <4 x i32> %219 to <2 x i64>
  %221 = shufflevector <4 x i32> %217, <4 x i32> %218, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %222 = bitcast <4 x i32> %221 to <2 x i64>
  %223 = shufflevector <2 x i64> %175, <2 x i64> %220, <2 x i32> <i32 0, i32 2>
  %224 = shufflevector <2 x i64> %175, <2 x i64> %220, <2 x i32> <i32 1, i32 3>
  %225 = shufflevector <2 x i64> %177, <2 x i64> %222, <2 x i32> <i32 0, i32 2>
  %226 = shufflevector <2 x i64> %177, <2 x i64> %222, <2 x i32> <i32 1, i32 3>
  %227 = bitcast <2 x i64> %223 to <16 x i8>
  %228 = bitcast <2 x i64> %224 to <16 x i8>
  %229 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %227, <16 x i8> %228) #8
  %230 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %228, <16 x i8> %227) #8
  %231 = or <16 x i8> %230, %229
  %232 = icmp ugt <16 x i8> %132, %231
  %233 = select <16 x i1> %232, <16 x i8> %132, <16 x i8> %231
  %234 = bitcast <2 x i64> %225 to <16 x i8>
  %235 = bitcast <2 x i64> %226 to <16 x i8>
  %236 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %234, <16 x i8> %235) #8
  %237 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %235, <16 x i8> %234) #8
  %238 = or <16 x i8> %237, %236
  %239 = icmp ugt <16 x i8> %233, %238
  %240 = select <16 x i1> %239, <16 x i8> %233, <16 x i8> %238
  %241 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %228, <16 x i8> %234) #8
  %242 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %234, <16 x i8> %228) #8
  %243 = or <16 x i8> %242, %241
  %244 = icmp ugt <16 x i8> %240, %243
  %245 = select <16 x i1> %244, <16 x i8> %240, <16 x i8> %243
  %246 = trunc i32 %4 to i8
  %247 = insertelement <16 x i8> undef, i8 %246, i32 0
  %248 = shufflevector <16 x i8> %247, <16 x i8> undef, <16 x i32> zeroinitializer
  %249 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %245, <16 x i8> %248) #8
  %250 = icmp eq <16 x i8> %249, zeroinitializer
  %251 = trunc i32 %3 to i8
  %252 = insertelement <16 x i8> undef, i8 %251, i32 0
  %253 = shufflevector <16 x i8> %252, <16 x i8> undef, <16 x i32> zeroinitializer
  %254 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %228, <16 x i8> %117) #8
  %255 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %117, <16 x i8> %228) #8
  %256 = or <16 x i8> %255, %254
  %257 = bitcast <16 x i8> %256 to <8 x i16>
  %258 = lshr <8 x i16> %257, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %259 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %227, <16 x i8> %116) #8
  %260 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %116, <16 x i8> %227) #8
  %261 = or <16 x i8> %260, %259
  %262 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %261, <16 x i8> %261) #8
  %263 = bitcast <8 x i16> %258 to <16 x i8>
  %264 = and <16 x i8> %263, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %265 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %262, <16 x i8> %264) #8
  %266 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %265, <16 x i8> %253) #8
  %267 = icmp eq <16 x i8> %266, zeroinitializer
  %268 = and <16 x i1> %250, %267
  %269 = trunc i32 %5 to i8
  %270 = insertelement <16 x i8> undef, i8 %269, i32 0
  %271 = shufflevector <16 x i8> %270, <16 x i8> undef, <16 x i32> zeroinitializer
  %272 = icmp ugt <16 x i8> %120, %231
  %273 = select <16 x i1> %272, <16 x i8> %120, <16 x i8> %231
  %274 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %273, <16 x i8> %271) #8
  %275 = icmp eq <16 x i8> %274, zeroinitializer
  %276 = sext <16 x i1> %275 to <16 x i8>
  %277 = xor <16 x i8> %117, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %278 = xor <16 x i8> %228, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %279 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %277, <16 x i8> %278) #8
  %280 = xor <16 x i8> %227, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %281 = xor <16 x i8> %116, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %282 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %280, <16 x i8> %281) #8
  %283 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %279, <16 x i8> %282) #8
  %284 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %282, <16 x i8> %283) #8
  %285 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %282, <16 x i8> %284) #8
  %286 = xor <16 x i8> %276, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %287 = select <16 x i1> %268, <16 x i8> %285, <16 x i8> zeroinitializer
  %288 = and <16 x i8> %287, %286
  %289 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %288, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %290 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %288, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %291 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %290, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %292 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %290, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %293 = bitcast <16 x i8> %291 to <8 x i16>
  %294 = ashr <8 x i16> %293, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %295 = bitcast <16 x i8> %292 to <8 x i16>
  %296 = ashr <8 x i16> %295, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %297 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %294, <8 x i16> %296) #8
  %298 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %289, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %299 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %289, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %300 = bitcast <16 x i8> %298 to <8 x i16>
  %301 = ashr <8 x i16> %300, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %302 = bitcast <16 x i8> %299 to <8 x i16>
  %303 = ashr <8 x i16> %302, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %304 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %301, <8 x i16> %303) #8
  %305 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %280, <16 x i8> %297) #8
  %306 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %281, <16 x i8> %304) #8
  %307 = and <16 x i8> %287, %276
  %308 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %307, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %309 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %307, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %310 = bitcast <16 x i8> %308 to <8 x i16>
  %311 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %310, <8 x i16> <i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304>) #8
  %312 = bitcast <16 x i8> %309 to <8 x i16>
  %313 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %312, <8 x i16> <i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304, i16 2304>) #8
  %314 = add <8 x i16> %311, <i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63>
  %315 = add <8 x i16> %313, <i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63, i16 63>
  %316 = add <8 x i16> %314, %311
  %317 = add <8 x i16> %315, %313
  %318 = add <8 x i16> %316, %311
  %319 = add <8 x i16> %317, %313
  %320 = ashr <8 x i16> %314, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %321 = ashr <8 x i16> %315, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %322 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %320, <8 x i16> %321) #8
  %323 = xor <16 x i8> %121, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %324 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %323, <16 x i8> %322) #8
  %325 = xor <16 x i8> %234, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %326 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %325, <16 x i8> %322) #8
  %327 = ashr <8 x i16> %316, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %328 = ashr <8 x i16> %317, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %329 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %327, <8 x i16> %328) #8
  %330 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %277, <16 x i8> %329) #8
  %331 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %278, <16 x i8> %329) #8
  %332 = ashr <8 x i16> %318, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %333 = ashr <8 x i16> %319, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %334 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %332, <8 x i16> %333) #8
  %335 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %306, <16 x i8> %334) #8
  %336 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %305, <16 x i8> %334) #8
  %337 = xor <16 x i8> %324, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %338 = shufflevector <16 x i8> %122, <16 x i8> %337, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %339 = shufflevector <16 x i8> %122, <16 x i8> %337, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %340 = xor <16 x i8> %330, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %341 = xor <16 x i8> %335, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %342 = shufflevector <16 x i8> %340, <16 x i8> %341, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %343 = shufflevector <16 x i8> %340, <16 x i8> %341, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %344 = bitcast <16 x i8> %338 to <8 x i16>
  %345 = bitcast <16 x i8> %342 to <8 x i16>
  %346 = shufflevector <8 x i16> %344, <8 x i16> %345, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %347 = shufflevector <8 x i16> %344, <8 x i16> %345, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %348 = bitcast <16 x i8> %339 to <8 x i16>
  %349 = bitcast <16 x i8> %343 to <8 x i16>
  %350 = shufflevector <8 x i16> %348, <8 x i16> %349, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %351 = shufflevector <8 x i16> %348, <8 x i16> %349, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %352 = bitcast <8 x i16> %346 to <4 x i32>
  %353 = extractelement <4 x i32> %352, i32 0
  store i32 %353, i32* %24, align 1
  %354 = bitcast <8 x i16> %346 to <16 x i8>
  %355 = shufflevector <16 x i8> %354, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %356 = bitcast <16 x i8> %355 to <4 x i32>
  %357 = extractelement <4 x i32> %356, i32 0
  store i32 %357, i32* %47, align 1
  %358 = shufflevector <16 x i8> %355, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %359 = getelementptr inbounds i8, i8* %46, i64 %45
  %360 = bitcast <16 x i8> %358 to <4 x i32>
  %361 = extractelement <4 x i32> %360, i32 0
  %362 = bitcast i8* %359 to i32*
  store i32 %361, i32* %362, align 1
  %363 = shufflevector <16 x i8> %358, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %364 = getelementptr inbounds i8, i8* %359, i64 %45
  %365 = bitcast <16 x i8> %363 to <4 x i32>
  %366 = extractelement <4 x i32> %365, i32 0
  %367 = bitcast i8* %364 to i32*
  store i32 %366, i32* %367, align 1
  %368 = bitcast <8 x i16> %347 to <4 x i32>
  %369 = extractelement <4 x i32> %368, i32 0
  store i32 %369, i32* %22, align 1
  %370 = bitcast <8 x i16> %347 to <16 x i8>
  %371 = shufflevector <16 x i8> %370, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %372 = getelementptr inbounds i8, i8* %21, i64 %45
  %373 = bitcast <16 x i8> %371 to <4 x i32>
  %374 = extractelement <4 x i32> %373, i32 0
  %375 = bitcast i8* %372 to i32*
  store i32 %374, i32* %375, align 1
  %376 = shufflevector <16 x i8> %371, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %377 = getelementptr inbounds i8, i8* %372, i64 %45
  %378 = bitcast <16 x i8> %376 to <4 x i32>
  %379 = extractelement <4 x i32> %378, i32 0
  %380 = bitcast i8* %377 to i32*
  store i32 %379, i32* %380, align 1
  %381 = shufflevector <16 x i8> %376, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %382 = getelementptr inbounds i8, i8* %377, i64 %45
  %383 = bitcast <16 x i8> %381 to <4 x i32>
  %384 = extractelement <4 x i32> %383, i32 0
  %385 = bitcast i8* %382 to i32*
  store i32 %384, i32* %385, align 1
  %386 = bitcast <8 x i16> %350 to <4 x i32>
  %387 = extractelement <4 x i32> %386, i32 0
  store i32 %387, i32* %76, align 1
  %388 = bitcast <8 x i16> %350 to <16 x i8>
  %389 = shufflevector <16 x i8> %388, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %390 = bitcast <16 x i8> %389 to <4 x i32>
  %391 = extractelement <4 x i32> %390, i32 0
  store i32 %391, i32* %92, align 1
  %392 = shufflevector <16 x i8> %389, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %393 = getelementptr inbounds i8, i8* %91, i64 %45
  %394 = bitcast <16 x i8> %392 to <4 x i32>
  %395 = extractelement <4 x i32> %394, i32 0
  %396 = bitcast i8* %393 to i32*
  store i32 %395, i32* %396, align 1
  %397 = shufflevector <16 x i8> %392, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %398 = getelementptr inbounds i8, i8* %393, i64 %45
  %399 = bitcast <16 x i8> %397 to <4 x i32>
  %400 = extractelement <4 x i32> %399, i32 0
  %401 = bitcast i8* %398 to i32*
  store i32 %400, i32* %401, align 1
  %402 = bitcast <8 x i16> %351 to <4 x i32>
  %403 = extractelement <4 x i32> %402, i32 0
  store i32 %403, i32* %74, align 1
  %404 = bitcast <8 x i16> %351 to <16 x i8>
  %405 = shufflevector <16 x i8> %404, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %406 = getelementptr inbounds i8, i8* %73, i64 %45
  %407 = bitcast <16 x i8> %405 to <4 x i32>
  %408 = extractelement <4 x i32> %407, i32 0
  %409 = bitcast i8* %406 to i32*
  store i32 %408, i32* %409, align 1
  %410 = shufflevector <16 x i8> %405, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %411 = getelementptr inbounds i8, i8* %406, i64 %45
  %412 = bitcast <16 x i8> %410 to <4 x i32>
  %413 = extractelement <4 x i32> %412, i32 0
  %414 = bitcast i8* %411 to i32*
  store i32 %413, i32* %414, align 1
  %415 = shufflevector <16 x i8> %410, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %416 = getelementptr inbounds i8, i8* %411, i64 %45
  %417 = bitcast <16 x i8> %415 to <4 x i32>
  %418 = extractelement <4 x i32> %417, i32 0
  %419 = bitcast i8* %416 to i32*
  store i32 %418, i32* %419, align 1
  %420 = xor <16 x i8> %331, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %421 = xor <16 x i8> %336, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %422 = shufflevector <16 x i8> %421, <16 x i8> %420, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %423 = shufflevector <16 x i8> %421, <16 x i8> %420, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %424 = xor <16 x i8> %326, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %425 = shufflevector <16 x i8> %424, <16 x i8> %235, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %426 = shufflevector <16 x i8> %424, <16 x i8> %235, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %427 = bitcast <16 x i8> %422 to <8 x i16>
  %428 = bitcast <16 x i8> %425 to <8 x i16>
  %429 = shufflevector <8 x i16> %427, <8 x i16> %428, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %430 = shufflevector <8 x i16> %427, <8 x i16> %428, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %431 = bitcast <16 x i8> %423 to <8 x i16>
  %432 = bitcast <16 x i8> %426 to <8 x i16>
  %433 = shufflevector <8 x i16> %431, <8 x i16> %432, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %434 = shufflevector <8 x i16> %431, <8 x i16> %432, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %435 = bitcast <8 x i16> %429 to <4 x i32>
  %436 = extractelement <4 x i32> %435, i32 0
  store i32 %436, i32* %142, align 1
  %437 = bitcast <8 x i16> %429 to <16 x i8>
  %438 = shufflevector <16 x i8> %437, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %439 = bitcast <16 x i8> %438 to <4 x i32>
  %440 = extractelement <4 x i32> %439, i32 0
  store i32 %440, i32* %158, align 1
  %441 = shufflevector <16 x i8> %438, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %442 = getelementptr inbounds i8, i8* %157, i64 %45
  %443 = bitcast <16 x i8> %441 to <4 x i32>
  %444 = extractelement <4 x i32> %443, i32 0
  %445 = bitcast i8* %442 to i32*
  store i32 %444, i32* %445, align 1
  %446 = shufflevector <16 x i8> %441, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %447 = getelementptr inbounds i8, i8* %442, i64 %45
  %448 = bitcast <16 x i8> %446 to <4 x i32>
  %449 = extractelement <4 x i32> %448, i32 0
  %450 = bitcast i8* %447 to i32*
  store i32 %449, i32* %450, align 1
  %451 = bitcast <8 x i16> %430 to <4 x i32>
  %452 = extractelement <4 x i32> %451, i32 0
  store i32 %452, i32* %140, align 1
  %453 = bitcast <8 x i16> %430 to <16 x i8>
  %454 = shufflevector <16 x i8> %453, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %455 = getelementptr inbounds i8, i8* %139, i64 %45
  %456 = bitcast <16 x i8> %454 to <4 x i32>
  %457 = extractelement <4 x i32> %456, i32 0
  %458 = bitcast i8* %455 to i32*
  store i32 %457, i32* %458, align 1
  %459 = shufflevector <16 x i8> %454, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %460 = getelementptr inbounds i8, i8* %455, i64 %45
  %461 = bitcast <16 x i8> %459 to <4 x i32>
  %462 = extractelement <4 x i32> %461, i32 0
  %463 = bitcast i8* %460 to i32*
  store i32 %462, i32* %463, align 1
  %464 = shufflevector <16 x i8> %459, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %465 = getelementptr inbounds i8, i8* %460, i64 %45
  %466 = bitcast <16 x i8> %464 to <4 x i32>
  %467 = extractelement <4 x i32> %466, i32 0
  %468 = bitcast i8* %465 to i32*
  store i32 %467, i32* %468, align 1
  %469 = bitcast <8 x i16> %433 to <4 x i32>
  %470 = extractelement <4 x i32> %469, i32 0
  store i32 %470, i32* %187, align 1
  %471 = bitcast <8 x i16> %433 to <16 x i8>
  %472 = shufflevector <16 x i8> %471, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %473 = bitcast <16 x i8> %472 to <4 x i32>
  %474 = extractelement <4 x i32> %473, i32 0
  store i32 %474, i32* %203, align 1
  %475 = shufflevector <16 x i8> %472, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %476 = getelementptr inbounds i8, i8* %202, i64 %45
  %477 = bitcast <16 x i8> %475 to <4 x i32>
  %478 = extractelement <4 x i32> %477, i32 0
  %479 = bitcast i8* %476 to i32*
  store i32 %478, i32* %479, align 1
  %480 = shufflevector <16 x i8> %475, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %481 = getelementptr inbounds i8, i8* %476, i64 %45
  %482 = bitcast <16 x i8> %480 to <4 x i32>
  %483 = extractelement <4 x i32> %482, i32 0
  %484 = bitcast i8* %481 to i32*
  store i32 %483, i32* %484, align 1
  %485 = bitcast <8 x i16> %434 to <4 x i32>
  %486 = extractelement <4 x i32> %485, i32 0
  store i32 %486, i32* %185, align 1
  %487 = bitcast <8 x i16> %434 to <16 x i8>
  %488 = shufflevector <16 x i8> %487, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %489 = getelementptr inbounds i8, i8* %184, i64 %45
  %490 = bitcast <16 x i8> %488 to <4 x i32>
  %491 = extractelement <4 x i32> %490, i32 0
  %492 = bitcast i8* %489 to i32*
  store i32 %491, i32* %492, align 1
  %493 = shufflevector <16 x i8> %488, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %494 = getelementptr inbounds i8, i8* %489, i64 %45
  %495 = bitcast <16 x i8> %493 to <4 x i32>
  %496 = extractelement <4 x i32> %495, i32 0
  %497 = bitcast i8* %494 to i32*
  store i32 %496, i32* %497, align 1
  %498 = shufflevector <16 x i8> %493, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %499 = getelementptr inbounds i8, i8* %494, i64 %45
  %500 = bitcast <16 x i8> %498 to <4 x i32>
  %501 = extractelement <4 x i32> %500, i32 0
  %502 = bitcast i8* %499 to i32*
  store i32 %501, i32* %502, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @VFilter16i_SSE2(i8* nocapture, i32, i32, i32, i32) #1 {
  %6 = bitcast i8* %0 to <2 x i64>*
  %7 = load <2 x i64>, <2 x i64>* %6, align 1
  %8 = sext i32 %1 to i64
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = bitcast i8* %9 to <2 x i64>*
  %11 = load <2 x i64>, <2 x i64>* %10, align 1
  %12 = shl nsw i32 %1, 1
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i8, i8* %0, i64 %13
  %15 = bitcast i8* %14 to <2 x i64>*
  %16 = load <2 x i64>, <2 x i64>* %15, align 1
  %17 = mul nsw i32 %1, 3
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds i8, i8* %0, i64 %18
  %20 = bitcast i8* %19 to <2 x i64>*
  %21 = load <2 x i64>, <2 x i64>* %20, align 1
  %22 = shl nsw i32 %1, 2
  %23 = sext i32 %22 to i64
  %24 = trunc i32 %3 to i8
  %25 = insertelement <16 x i8> undef, i8 %24, i32 0
  %26 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> zeroinitializer
  %27 = trunc i32 %2 to i8
  %28 = insertelement <16 x i8> undef, i8 %27, i32 0
  %29 = shufflevector <16 x i8> %28, <16 x i8> undef, <16 x i32> zeroinitializer
  %30 = trunc i32 %4 to i8
  %31 = insertelement <16 x i8> undef, i8 %30, i32 0
  %32 = shufflevector <16 x i8> %31, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %33

33:                                               ; preds = %33, %5
  %34 = phi i8* [ %0, %5 ], [ %41, %33 ]
  %35 = phi i32 [ 3, %5 ], [ %160, %33 ]
  %36 = phi <2 x i64> [ %7, %5 ], [ %142, %33 ]
  %37 = phi <2 x i64> [ %21, %5 ], [ %69, %33 ]
  %38 = phi <2 x i64> [ %16, %5 ], [ %66, %33 ]
  %39 = phi <2 x i64> [ %11, %5 ], [ %152, %33 ]
  %40 = getelementptr inbounds i8, i8* %34, i64 %13
  %41 = getelementptr inbounds i8, i8* %34, i64 %23
  %42 = bitcast <2 x i64> %37 to <16 x i8>
  %43 = bitcast <2 x i64> %38 to <16 x i8>
  %44 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %42, <16 x i8> %43) #8
  %45 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %43, <16 x i8> %42) #8
  %46 = or <16 x i8> %45, %44
  %47 = bitcast <2 x i64> %39 to <16 x i8>
  %48 = bitcast <2 x i64> %36 to <16 x i8>
  %49 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %48) #8
  %50 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %48, <16 x i8> %47) #8
  %51 = or <16 x i8> %50, %49
  %52 = icmp ugt <16 x i8> %46, %51
  %53 = select <16 x i1> %52, <16 x i8> %46, <16 x i8> %51
  %54 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %43, <16 x i8> %47) #8
  %55 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %43) #8
  %56 = or <16 x i8> %55, %54
  %57 = icmp ugt <16 x i8> %53, %56
  %58 = select <16 x i1> %57, <16 x i8> %53, <16 x i8> %56
  %59 = bitcast i8* %41 to <16 x i8>*
  %60 = load <16 x i8>, <16 x i8>* %59, align 1
  %61 = getelementptr inbounds i8, i8* %41, i64 %8
  %62 = bitcast i8* %61 to <16 x i8>*
  %63 = load <16 x i8>, <16 x i8>* %62, align 1
  %64 = getelementptr inbounds i8, i8* %41, i64 %13
  %65 = bitcast i8* %64 to <2 x i64>*
  %66 = load <2 x i64>, <2 x i64>* %65, align 1
  %67 = getelementptr inbounds i8, i8* %41, i64 %18
  %68 = bitcast i8* %67 to <2 x i64>*
  %69 = load <2 x i64>, <2 x i64>* %68, align 1
  %70 = bitcast <2 x i64> %69 to <16 x i8>
  %71 = bitcast <2 x i64> %66 to <16 x i8>
  %72 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %70, <16 x i8> %71) #8
  %73 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %71, <16 x i8> %70) #8
  %74 = or <16 x i8> %73, %72
  %75 = icmp ugt <16 x i8> %58, %74
  %76 = select <16 x i1> %75, <16 x i8> %58, <16 x i8> %74
  %77 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %60) #8
  %78 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %63) #8
  %79 = or <16 x i8> %78, %77
  %80 = icmp ugt <16 x i8> %76, %79
  %81 = select <16 x i1> %80, <16 x i8> %76, <16 x i8> %79
  %82 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %71, <16 x i8> %63) #8
  %83 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %71) #8
  %84 = or <16 x i8> %83, %82
  %85 = icmp ugt <16 x i8> %81, %84
  %86 = select <16 x i1> %85, <16 x i8> %81, <16 x i8> %84
  %87 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %86, <16 x i8> %26) #8
  %88 = icmp eq <16 x i8> %87, zeroinitializer
  %89 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %43) #8
  %90 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %43, <16 x i8> %63) #8
  %91 = or <16 x i8> %90, %89
  %92 = bitcast <16 x i8> %91 to <8 x i16>
  %93 = lshr <8 x i16> %92, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %94 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %42) #8
  %95 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %42, <16 x i8> %60) #8
  %96 = or <16 x i8> %95, %94
  %97 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %96, <16 x i8> %96) #8
  %98 = bitcast <8 x i16> %93 to <16 x i8>
  %99 = and <16 x i8> %98, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %100 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %97, <16 x i8> %99) #8
  %101 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %100, <16 x i8> %29) #8
  %102 = icmp eq <16 x i8> %101, zeroinitializer
  %103 = and <16 x i1> %88, %102
  %104 = icmp ugt <16 x i8> %46, %79
  %105 = select <16 x i1> %104, <16 x i8> %46, <16 x i8> %79
  %106 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %105, <16 x i8> %32) #8
  %107 = icmp eq <16 x i8> %106, zeroinitializer
  %108 = sext <16 x i1> %107 to <16 x i8>
  %109 = xor <16 x i8> %43, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %110 = xor <16 x i8> %63, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %111 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %109, <16 x i8> %110) #8
  %112 = xor <16 x i8> %60, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %113 = xor <16 x i8> %42, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %114 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %112, <16 x i8> %113) #8
  %115 = xor <16 x i8> %108, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %116 = and <16 x i8> %111, %115
  %117 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %116, <16 x i8> %114) #8
  %118 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %117, <16 x i8> %114) #8
  %119 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %118, <16 x i8> %114) #8
  %120 = select <16 x i1> %103, <16 x i8> %119, <16 x i8> zeroinitializer
  %121 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %120, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %122 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %120, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %123 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %121, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %124 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %121, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %125 = bitcast <16 x i8> %123 to <8 x i16>
  %126 = ashr <8 x i16> %125, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %127 = bitcast <16 x i8> %124 to <8 x i16>
  %128 = ashr <8 x i16> %127, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %126, <8 x i16> %128) #8
  %130 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %122, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %131 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %122, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %132 = bitcast <16 x i8> %130 to <8 x i16>
  %133 = ashr <8 x i16> %132, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %134 = bitcast <16 x i8> %131 to <8 x i16>
  %135 = ashr <8 x i16> %134, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %133, <8 x i16> %135) #8
  %137 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %113, <16 x i8> %129) #8
  %138 = bitcast <16 x i8> %137 to <2 x i64>
  %139 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %112, <16 x i8> %136) #8
  %140 = bitcast <16 x i8> %139 to <2 x i64>
  %141 = xor <2 x i64> %138, <i64 -9187201950435737472, i64 -9187201950435737472>
  %142 = xor <2 x i64> %140, <i64 -9187201950435737472, i64 -9187201950435737472>
  %143 = xor <16 x i8> %136, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %144 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %143, <16 x i8> zeroinitializer) #8
  %145 = add <16 x i8> %144, <i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64>
  %146 = and <16 x i8> %145, %108
  %147 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %110, <16 x i8> %146) #8
  %148 = bitcast <16 x i8> %147 to <2 x i64>
  %149 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %109, <16 x i8> %146) #8
  %150 = bitcast <16 x i8> %149 to <2 x i64>
  %151 = xor <2 x i64> %150, <i64 -9187201950435737472, i64 -9187201950435737472>
  %152 = xor <2 x i64> %148, <i64 -9187201950435737472, i64 -9187201950435737472>
  %153 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %151, <2 x i64>* %153, align 1
  %154 = getelementptr inbounds i8, i8* %40, i64 %8
  %155 = bitcast i8* %154 to <2 x i64>*
  store <2 x i64> %141, <2 x i64>* %155, align 1
  %156 = getelementptr inbounds i8, i8* %40, i64 %13
  %157 = bitcast i8* %156 to <2 x i64>*
  store <2 x i64> %142, <2 x i64>* %157, align 1
  %158 = getelementptr inbounds i8, i8* %40, i64 %18
  %159 = bitcast i8* %158 to <2 x i64>*
  store <2 x i64> %152, <2 x i64>* %159, align 1
  %160 = add nsw i32 %35, -1
  %161 = icmp eq i32 %160, 0
  br i1 %161, label %162, label %33

162:                                              ; preds = %33
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @HFilter16i_SSE2(i8* nocapture, i32, i32, i32, i32) #1 {
  %6 = shl nsw i32 %1, 3
  %7 = sext i32 %6 to i64
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = mul nsw i32 %1, 6
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = bitcast i8* %11 to i32*
  %13 = load i32, i32* %12, align 1
  %14 = shl nsw i32 %1, 1
  %15 = sext i32 %14 to i64
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  %18 = load i32, i32* %17, align 1
  %19 = shl nsw i32 %1, 2
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 1
  %24 = bitcast i8* %0 to i32*
  %25 = load i32, i32* %24, align 1
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = insertelement <4 x i32> %26, i32 %23, i32 1
  %28 = insertelement <4 x i32> %27, i32 %18, i32 2
  %29 = insertelement <4 x i32> %28, i32 %13, i32 3
  %30 = mul nsw i32 %1, 7
  %31 = sext i32 %30 to i64
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = bitcast i8* %32 to i32*
  %34 = load i32, i32* %33, align 1
  %35 = mul nsw i32 %1, 3
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = bitcast i8* %37 to i32*
  %39 = load i32, i32* %38, align 1
  %40 = mul nsw i32 %1, 5
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  %43 = bitcast i8* %42 to i32*
  %44 = load i32, i32* %43, align 1
  %45 = sext i32 %1 to i64
  %46 = getelementptr inbounds i8, i8* %0, i64 %45
  %47 = bitcast i8* %46 to i32*
  %48 = load i32, i32* %47, align 1
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = insertelement <4 x i32> %49, i32 %44, i32 1
  %51 = insertelement <4 x i32> %50, i32 %39, i32 2
  %52 = insertelement <4 x i32> %51, i32 %34, i32 3
  %53 = bitcast <4 x i32> %29 to <16 x i8>
  %54 = bitcast <4 x i32> %52 to <16 x i8>
  %55 = shufflevector <16 x i8> %53, <16 x i8> %54, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %56 = shufflevector <16 x i8> %53, <16 x i8> %54, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = bitcast <16 x i8> %55 to <8 x i16>
  %58 = bitcast <16 x i8> %56 to <8 x i16>
  %59 = shufflevector <8 x i16> %57, <8 x i16> %58, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %60 = shufflevector <8 x i16> %57, <8 x i16> %58, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %61 = bitcast <8 x i16> %59 to <4 x i32>
  %62 = bitcast <8 x i16> %60 to <4 x i32>
  %63 = shufflevector <4 x i32> %61, <4 x i32> %62, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %64 = bitcast <4 x i32> %63 to <2 x i64>
  %65 = shufflevector <4 x i32> %61, <4 x i32> %62, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %66 = bitcast <4 x i32> %65 to <2 x i64>
  %67 = getelementptr inbounds i8, i8* %8, i64 %10
  %68 = bitcast i8* %67 to i32*
  %69 = load i32, i32* %68, align 1
  %70 = getelementptr inbounds i8, i8* %8, i64 %15
  %71 = bitcast i8* %70 to i32*
  %72 = load i32, i32* %71, align 1
  %73 = getelementptr inbounds i8, i8* %8, i64 %20
  %74 = bitcast i8* %73 to i32*
  %75 = load i32, i32* %74, align 1
  %76 = bitcast i8* %8 to i32*
  %77 = load i32, i32* %76, align 1
  %78 = insertelement <4 x i32> undef, i32 %77, i32 0
  %79 = insertelement <4 x i32> %78, i32 %75, i32 1
  %80 = insertelement <4 x i32> %79, i32 %72, i32 2
  %81 = insertelement <4 x i32> %80, i32 %69, i32 3
  %82 = getelementptr inbounds i8, i8* %8, i64 %31
  %83 = bitcast i8* %82 to i32*
  %84 = load i32, i32* %83, align 1
  %85 = getelementptr inbounds i8, i8* %8, i64 %36
  %86 = bitcast i8* %85 to i32*
  %87 = load i32, i32* %86, align 1
  %88 = getelementptr inbounds i8, i8* %8, i64 %41
  %89 = bitcast i8* %88 to i32*
  %90 = load i32, i32* %89, align 1
  %91 = getelementptr inbounds i8, i8* %8, i64 %45
  %92 = bitcast i8* %91 to i32*
  %93 = load i32, i32* %92, align 1
  %94 = insertelement <4 x i32> undef, i32 %93, i32 0
  %95 = insertelement <4 x i32> %94, i32 %90, i32 1
  %96 = insertelement <4 x i32> %95, i32 %87, i32 2
  %97 = insertelement <4 x i32> %96, i32 %84, i32 3
  %98 = bitcast <4 x i32> %81 to <16 x i8>
  %99 = bitcast <4 x i32> %97 to <16 x i8>
  %100 = shufflevector <16 x i8> %98, <16 x i8> %99, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %101 = shufflevector <16 x i8> %98, <16 x i8> %99, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %102 = bitcast <16 x i8> %100 to <8 x i16>
  %103 = bitcast <16 x i8> %101 to <8 x i16>
  %104 = shufflevector <8 x i16> %102, <8 x i16> %103, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %105 = shufflevector <8 x i16> %102, <8 x i16> %103, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %106 = bitcast <8 x i16> %104 to <4 x i32>
  %107 = bitcast <8 x i16> %105 to <4 x i32>
  %108 = shufflevector <4 x i32> %106, <4 x i32> %107, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %109 = bitcast <4 x i32> %108 to <2 x i64>
  %110 = shufflevector <4 x i32> %106, <4 x i32> %107, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %111 = bitcast <4 x i32> %110 to <2 x i64>
  %112 = shufflevector <2 x i64> %64, <2 x i64> %109, <2 x i32> <i32 0, i32 2>
  %113 = shufflevector <2 x i64> %64, <2 x i64> %109, <2 x i32> <i32 1, i32 3>
  %114 = shufflevector <2 x i64> %66, <2 x i64> %111, <2 x i32> <i32 0, i32 2>
  %115 = shufflevector <2 x i64> %66, <2 x i64> %111, <2 x i32> <i32 1, i32 3>
  %116 = trunc i32 %3 to i8
  %117 = insertelement <16 x i8> undef, i8 %116, i32 0
  %118 = shufflevector <16 x i8> %117, <16 x i8> undef, <16 x i32> zeroinitializer
  %119 = trunc i32 %2 to i8
  %120 = insertelement <16 x i8> undef, i8 %119, i32 0
  %121 = shufflevector <16 x i8> %120, <16 x i8> undef, <16 x i32> zeroinitializer
  %122 = trunc i32 %4 to i8
  %123 = insertelement <16 x i8> undef, i8 %122, i32 0
  %124 = shufflevector <16 x i8> %123, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %125

125:                                              ; preds = %125, %5
  %126 = phi i8* [ %0, %5 ], [ %133, %125 ]
  %127 = phi i32 [ 3, %5 ], [ %422, %125 ]
  %128 = phi <2 x i64> [ %112, %5 ], [ %318, %125 ]
  %129 = phi <2 x i64> [ %113, %5 ], [ %326, %125 ]
  %130 = phi <2 x i64> [ %114, %5 ], [ %244, %125 ]
  %131 = phi <2 x i64> [ %115, %5 ], [ %245, %125 ]
  %132 = getelementptr inbounds i8, i8* %126, i64 2
  %133 = getelementptr inbounds i8, i8* %126, i64 4
  %134 = bitcast <2 x i64> %131 to <16 x i8>
  %135 = bitcast <2 x i64> %130 to <16 x i8>
  %136 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %134, <16 x i8> %135) #8
  %137 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %135, <16 x i8> %134) #8
  %138 = or <16 x i8> %137, %136
  %139 = bitcast <2 x i64> %129 to <16 x i8>
  %140 = bitcast <2 x i64> %128 to <16 x i8>
  %141 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %139, <16 x i8> %140) #8
  %142 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %140, <16 x i8> %139) #8
  %143 = or <16 x i8> %142, %141
  %144 = icmp ugt <16 x i8> %138, %143
  %145 = select <16 x i1> %144, <16 x i8> %138, <16 x i8> %143
  %146 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %135, <16 x i8> %139) #8
  %147 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %139, <16 x i8> %135) #8
  %148 = or <16 x i8> %147, %146
  %149 = icmp ugt <16 x i8> %145, %148
  %150 = select <16 x i1> %149, <16 x i8> %145, <16 x i8> %148
  %151 = getelementptr inbounds i8, i8* %133, i64 %7
  %152 = getelementptr inbounds i8, i8* %133, i64 %10
  %153 = bitcast i8* %152 to i32*
  %154 = load i32, i32* %153, align 1
  %155 = getelementptr inbounds i8, i8* %133, i64 %15
  %156 = bitcast i8* %155 to i32*
  %157 = load i32, i32* %156, align 1
  %158 = getelementptr inbounds i8, i8* %133, i64 %20
  %159 = bitcast i8* %158 to i32*
  %160 = load i32, i32* %159, align 1
  %161 = bitcast i8* %133 to i32*
  %162 = load i32, i32* %161, align 1
  %163 = insertelement <4 x i32> undef, i32 %162, i32 0
  %164 = insertelement <4 x i32> %163, i32 %160, i32 1
  %165 = insertelement <4 x i32> %164, i32 %157, i32 2
  %166 = insertelement <4 x i32> %165, i32 %154, i32 3
  %167 = getelementptr inbounds i8, i8* %133, i64 %31
  %168 = bitcast i8* %167 to i32*
  %169 = load i32, i32* %168, align 1
  %170 = getelementptr inbounds i8, i8* %133, i64 %36
  %171 = bitcast i8* %170 to i32*
  %172 = load i32, i32* %171, align 1
  %173 = getelementptr inbounds i8, i8* %133, i64 %41
  %174 = bitcast i8* %173 to i32*
  %175 = load i32, i32* %174, align 1
  %176 = getelementptr inbounds i8, i8* %133, i64 %45
  %177 = bitcast i8* %176 to i32*
  %178 = load i32, i32* %177, align 1
  %179 = insertelement <4 x i32> undef, i32 %178, i32 0
  %180 = insertelement <4 x i32> %179, i32 %175, i32 1
  %181 = insertelement <4 x i32> %180, i32 %172, i32 2
  %182 = insertelement <4 x i32> %181, i32 %169, i32 3
  %183 = bitcast <4 x i32> %166 to <16 x i8>
  %184 = bitcast <4 x i32> %182 to <16 x i8>
  %185 = shufflevector <16 x i8> %183, <16 x i8> %184, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %186 = shufflevector <16 x i8> %183, <16 x i8> %184, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %187 = bitcast <16 x i8> %185 to <8 x i16>
  %188 = bitcast <16 x i8> %186 to <8 x i16>
  %189 = shufflevector <8 x i16> %187, <8 x i16> %188, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %190 = shufflevector <8 x i16> %187, <8 x i16> %188, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %191 = bitcast <8 x i16> %189 to <4 x i32>
  %192 = bitcast <8 x i16> %190 to <4 x i32>
  %193 = shufflevector <4 x i32> %191, <4 x i32> %192, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %194 = bitcast <4 x i32> %193 to <2 x i64>
  %195 = shufflevector <4 x i32> %191, <4 x i32> %192, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %196 = bitcast <4 x i32> %195 to <2 x i64>
  %197 = getelementptr inbounds i8, i8* %151, i64 %10
  %198 = bitcast i8* %197 to i32*
  %199 = load i32, i32* %198, align 1
  %200 = getelementptr inbounds i8, i8* %151, i64 %15
  %201 = bitcast i8* %200 to i32*
  %202 = load i32, i32* %201, align 1
  %203 = getelementptr inbounds i8, i8* %151, i64 %20
  %204 = bitcast i8* %203 to i32*
  %205 = load i32, i32* %204, align 1
  %206 = bitcast i8* %151 to i32*
  %207 = load i32, i32* %206, align 1
  %208 = insertelement <4 x i32> undef, i32 %207, i32 0
  %209 = insertelement <4 x i32> %208, i32 %205, i32 1
  %210 = insertelement <4 x i32> %209, i32 %202, i32 2
  %211 = insertelement <4 x i32> %210, i32 %199, i32 3
  %212 = getelementptr inbounds i8, i8* %151, i64 %31
  %213 = bitcast i8* %212 to i32*
  %214 = load i32, i32* %213, align 1
  %215 = getelementptr inbounds i8, i8* %151, i64 %36
  %216 = bitcast i8* %215 to i32*
  %217 = load i32, i32* %216, align 1
  %218 = getelementptr inbounds i8, i8* %151, i64 %41
  %219 = bitcast i8* %218 to i32*
  %220 = load i32, i32* %219, align 1
  %221 = getelementptr inbounds i8, i8* %151, i64 %45
  %222 = bitcast i8* %221 to i32*
  %223 = load i32, i32* %222, align 1
  %224 = insertelement <4 x i32> undef, i32 %223, i32 0
  %225 = insertelement <4 x i32> %224, i32 %220, i32 1
  %226 = insertelement <4 x i32> %225, i32 %217, i32 2
  %227 = insertelement <4 x i32> %226, i32 %214, i32 3
  %228 = bitcast <4 x i32> %211 to <16 x i8>
  %229 = bitcast <4 x i32> %227 to <16 x i8>
  %230 = shufflevector <16 x i8> %228, <16 x i8> %229, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %231 = shufflevector <16 x i8> %228, <16 x i8> %229, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %232 = bitcast <16 x i8> %230 to <8 x i16>
  %233 = bitcast <16 x i8> %231 to <8 x i16>
  %234 = shufflevector <8 x i16> %232, <8 x i16> %233, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %235 = shufflevector <8 x i16> %232, <8 x i16> %233, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %236 = bitcast <8 x i16> %234 to <4 x i32>
  %237 = bitcast <8 x i16> %235 to <4 x i32>
  %238 = shufflevector <4 x i32> %236, <4 x i32> %237, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %239 = bitcast <4 x i32> %238 to <2 x i64>
  %240 = shufflevector <4 x i32> %236, <4 x i32> %237, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %241 = bitcast <4 x i32> %240 to <2 x i64>
  %242 = shufflevector <2 x i64> %194, <2 x i64> %239, <2 x i32> <i32 0, i32 2>
  %243 = shufflevector <2 x i64> %194, <2 x i64> %239, <2 x i32> <i32 1, i32 3>
  %244 = shufflevector <2 x i64> %196, <2 x i64> %241, <2 x i32> <i32 0, i32 2>
  %245 = shufflevector <2 x i64> %196, <2 x i64> %241, <2 x i32> <i32 1, i32 3>
  %246 = bitcast <2 x i64> %245 to <16 x i8>
  %247 = bitcast <2 x i64> %244 to <16 x i8>
  %248 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %246, <16 x i8> %247) #8
  %249 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %247, <16 x i8> %246) #8
  %250 = or <16 x i8> %249, %248
  %251 = icmp ugt <16 x i8> %150, %250
  %252 = select <16 x i1> %251, <16 x i8> %150, <16 x i8> %250
  %253 = bitcast <2 x i64> %243 to <16 x i8>
  %254 = bitcast <2 x i64> %242 to <16 x i8>
  %255 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %253, <16 x i8> %254) #8
  %256 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %254, <16 x i8> %253) #8
  %257 = or <16 x i8> %256, %255
  %258 = icmp ugt <16 x i8> %252, %257
  %259 = select <16 x i1> %258, <16 x i8> %252, <16 x i8> %257
  %260 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %247, <16 x i8> %253) #8
  %261 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %253, <16 x i8> %247) #8
  %262 = or <16 x i8> %261, %260
  %263 = icmp ugt <16 x i8> %259, %262
  %264 = select <16 x i1> %263, <16 x i8> %259, <16 x i8> %262
  %265 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %264, <16 x i8> %118) #8
  %266 = icmp eq <16 x i8> %265, zeroinitializer
  %267 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %253, <16 x i8> %135) #8
  %268 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %135, <16 x i8> %253) #8
  %269 = or <16 x i8> %268, %267
  %270 = bitcast <16 x i8> %269 to <8 x i16>
  %271 = lshr <8 x i16> %270, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %272 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %254, <16 x i8> %134) #8
  %273 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %134, <16 x i8> %254) #8
  %274 = or <16 x i8> %273, %272
  %275 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %274, <16 x i8> %274) #8
  %276 = bitcast <8 x i16> %271 to <16 x i8>
  %277 = and <16 x i8> %276, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %278 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %275, <16 x i8> %277) #8
  %279 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %278, <16 x i8> %121) #8
  %280 = icmp eq <16 x i8> %279, zeroinitializer
  %281 = and <16 x i1> %266, %280
  %282 = icmp ugt <16 x i8> %138, %257
  %283 = select <16 x i1> %282, <16 x i8> %138, <16 x i8> %257
  %284 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %283, <16 x i8> %124) #8
  %285 = icmp eq <16 x i8> %284, zeroinitializer
  %286 = sext <16 x i1> %285 to <16 x i8>
  %287 = xor <16 x i8> %135, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %288 = xor <16 x i8> %253, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %289 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %287, <16 x i8> %288) #8
  %290 = xor <16 x i8> %254, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %291 = xor <16 x i8> %134, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %292 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %290, <16 x i8> %291) #8
  %293 = xor <16 x i8> %286, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %294 = and <16 x i8> %289, %293
  %295 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %294, <16 x i8> %292) #8
  %296 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %295, <16 x i8> %292) #8
  %297 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %296, <16 x i8> %292) #8
  %298 = select <16 x i1> %281, <16 x i8> %297, <16 x i8> zeroinitializer
  %299 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %298, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %300 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %298, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %301 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %299, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %302 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %299, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %303 = bitcast <16 x i8> %301 to <8 x i16>
  %304 = ashr <8 x i16> %303, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %305 = bitcast <16 x i8> %302 to <8 x i16>
  %306 = ashr <8 x i16> %305, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %307 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %304, <8 x i16> %306) #8
  %308 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %300, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %309 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %300, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %310 = bitcast <16 x i8> %308 to <8 x i16>
  %311 = ashr <8 x i16> %310, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %312 = bitcast <16 x i8> %309 to <8 x i16>
  %313 = ashr <8 x i16> %312, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %311, <8 x i16> %313) #8
  %315 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %291, <16 x i8> %307) #8
  %316 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %290, <16 x i8> %314) #8
  %317 = bitcast <16 x i8> %316 to <2 x i64>
  %318 = xor <2 x i64> %317, <i64 -9187201950435737472, i64 -9187201950435737472>
  %319 = xor <16 x i8> %314, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %320 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %319, <16 x i8> zeroinitializer) #8
  %321 = add <16 x i8> %320, <i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64>
  %322 = and <16 x i8> %321, %286
  %323 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %288, <16 x i8> %322) #8
  %324 = bitcast <16 x i8> %323 to <2 x i64>
  %325 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %287, <16 x i8> %322) #8
  %326 = xor <2 x i64> %324, <i64 -9187201950435737472, i64 -9187201950435737472>
  %327 = getelementptr inbounds i8, i8* %132, i64 %7
  %328 = xor <16 x i8> %315, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %329 = xor <16 x i8> %325, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %330 = shufflevector <16 x i8> %329, <16 x i8> %328, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %331 = shufflevector <16 x i8> %329, <16 x i8> %328, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %332 = bitcast <2 x i64> %318 to <16 x i8>
  %333 = bitcast <2 x i64> %326 to <16 x i8>
  %334 = shufflevector <16 x i8> %332, <16 x i8> %333, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %335 = shufflevector <16 x i8> %332, <16 x i8> %333, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %336 = bitcast <16 x i8> %330 to <8 x i16>
  %337 = bitcast <16 x i8> %334 to <8 x i16>
  %338 = shufflevector <8 x i16> %336, <8 x i16> %337, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %339 = shufflevector <8 x i16> %336, <8 x i16> %337, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %340 = bitcast <16 x i8> %331 to <8 x i16>
  %341 = bitcast <16 x i8> %335 to <8 x i16>
  %342 = shufflevector <8 x i16> %340, <8 x i16> %341, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %343 = shufflevector <8 x i16> %340, <8 x i16> %341, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %344 = bitcast <8 x i16> %338 to <4 x i32>
  %345 = extractelement <4 x i32> %344, i32 0
  %346 = bitcast i8* %132 to i32*
  store i32 %345, i32* %346, align 1
  %347 = bitcast <8 x i16> %338 to <16 x i8>
  %348 = shufflevector <16 x i8> %347, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %349 = getelementptr inbounds i8, i8* %132, i64 %45
  %350 = bitcast <16 x i8> %348 to <4 x i32>
  %351 = extractelement <4 x i32> %350, i32 0
  %352 = bitcast i8* %349 to i32*
  store i32 %351, i32* %352, align 1
  %353 = shufflevector <16 x i8> %348, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %354 = getelementptr inbounds i8, i8* %349, i64 %45
  %355 = bitcast <16 x i8> %353 to <4 x i32>
  %356 = extractelement <4 x i32> %355, i32 0
  %357 = bitcast i8* %354 to i32*
  store i32 %356, i32* %357, align 1
  %358 = shufflevector <16 x i8> %353, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %359 = getelementptr inbounds i8, i8* %354, i64 %45
  %360 = bitcast <16 x i8> %358 to <4 x i32>
  %361 = extractelement <4 x i32> %360, i32 0
  %362 = bitcast i8* %359 to i32*
  store i32 %361, i32* %362, align 1
  %363 = getelementptr inbounds i8, i8* %132, i64 %20
  %364 = bitcast <8 x i16> %339 to <4 x i32>
  %365 = extractelement <4 x i32> %364, i32 0
  %366 = bitcast i8* %363 to i32*
  store i32 %365, i32* %366, align 1
  %367 = bitcast <8 x i16> %339 to <16 x i8>
  %368 = shufflevector <16 x i8> %367, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %369 = getelementptr inbounds i8, i8* %363, i64 %45
  %370 = bitcast <16 x i8> %368 to <4 x i32>
  %371 = extractelement <4 x i32> %370, i32 0
  %372 = bitcast i8* %369 to i32*
  store i32 %371, i32* %372, align 1
  %373 = shufflevector <16 x i8> %368, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %374 = getelementptr inbounds i8, i8* %369, i64 %45
  %375 = bitcast <16 x i8> %373 to <4 x i32>
  %376 = extractelement <4 x i32> %375, i32 0
  %377 = bitcast i8* %374 to i32*
  store i32 %376, i32* %377, align 1
  %378 = shufflevector <16 x i8> %373, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %379 = getelementptr inbounds i8, i8* %374, i64 %45
  %380 = bitcast <16 x i8> %378 to <4 x i32>
  %381 = extractelement <4 x i32> %380, i32 0
  %382 = bitcast i8* %379 to i32*
  store i32 %381, i32* %382, align 1
  %383 = bitcast <8 x i16> %342 to <4 x i32>
  %384 = extractelement <4 x i32> %383, i32 0
  %385 = bitcast i8* %327 to i32*
  store i32 %384, i32* %385, align 1
  %386 = bitcast <8 x i16> %342 to <16 x i8>
  %387 = shufflevector <16 x i8> %386, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %388 = getelementptr inbounds i8, i8* %327, i64 %45
  %389 = bitcast <16 x i8> %387 to <4 x i32>
  %390 = extractelement <4 x i32> %389, i32 0
  %391 = bitcast i8* %388 to i32*
  store i32 %390, i32* %391, align 1
  %392 = shufflevector <16 x i8> %387, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %393 = getelementptr inbounds i8, i8* %388, i64 %45
  %394 = bitcast <16 x i8> %392 to <4 x i32>
  %395 = extractelement <4 x i32> %394, i32 0
  %396 = bitcast i8* %393 to i32*
  store i32 %395, i32* %396, align 1
  %397 = shufflevector <16 x i8> %392, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %398 = getelementptr inbounds i8, i8* %393, i64 %45
  %399 = bitcast <16 x i8> %397 to <4 x i32>
  %400 = extractelement <4 x i32> %399, i32 0
  %401 = bitcast i8* %398 to i32*
  store i32 %400, i32* %401, align 1
  %402 = getelementptr inbounds i8, i8* %327, i64 %20
  %403 = bitcast <8 x i16> %343 to <4 x i32>
  %404 = extractelement <4 x i32> %403, i32 0
  %405 = bitcast i8* %402 to i32*
  store i32 %404, i32* %405, align 1
  %406 = bitcast <8 x i16> %343 to <16 x i8>
  %407 = shufflevector <16 x i8> %406, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %408 = getelementptr inbounds i8, i8* %402, i64 %45
  %409 = bitcast <16 x i8> %407 to <4 x i32>
  %410 = extractelement <4 x i32> %409, i32 0
  %411 = bitcast i8* %408 to i32*
  store i32 %410, i32* %411, align 1
  %412 = shufflevector <16 x i8> %407, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %413 = getelementptr inbounds i8, i8* %408, i64 %45
  %414 = bitcast <16 x i8> %412 to <4 x i32>
  %415 = extractelement <4 x i32> %414, i32 0
  %416 = bitcast i8* %413 to i32*
  store i32 %415, i32* %416, align 1
  %417 = shufflevector <16 x i8> %412, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %418 = getelementptr inbounds i8, i8* %413, i64 %45
  %419 = bitcast <16 x i8> %417 to <4 x i32>
  %420 = extractelement <4 x i32> %419, i32 0
  %421 = bitcast i8* %418 to i32*
  store i32 %420, i32* %421, align 1
  %422 = add nsw i32 %127, -1
  %423 = icmp eq i32 %422, 0
  br i1 %423, label %424, label %125

424:                                              ; preds = %125
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @VFilter8i_SSE2(i8* nocapture, i8* nocapture, i32, i32, i32, i32) #1 {
  %7 = bitcast i8* %0 to i64*
  %8 = load i64, i64* %7, align 1
  %9 = insertelement <2 x i64> undef, i64 %8, i32 0
  %10 = bitcast i8* %1 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> %9, i64 %11, i32 1
  %13 = sext i32 %2 to i64
  %14 = getelementptr inbounds i8, i8* %0, i64 %13
  %15 = bitcast i8* %14 to i64*
  %16 = load i64, i64* %15, align 1
  %17 = insertelement <2 x i64> undef, i64 %16, i32 0
  %18 = getelementptr inbounds i8, i8* %1, i64 %13
  %19 = bitcast i8* %18 to i64*
  %20 = load i64, i64* %19, align 1
  %21 = insertelement <2 x i64> %17, i64 %20, i32 1
  %22 = shl nsw i32 %2, 1
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = bitcast i8* %24 to i64*
  %26 = load i64, i64* %25, align 1
  %27 = insertelement <2 x i64> undef, i64 %26, i32 0
  %28 = getelementptr inbounds i8, i8* %1, i64 %23
  %29 = bitcast i8* %28 to i64*
  %30 = load i64, i64* %29, align 1
  %31 = insertelement <2 x i64> %27, i64 %30, i32 1
  %32 = mul nsw i32 %2, 3
  %33 = sext i32 %32 to i64
  %34 = getelementptr inbounds i8, i8* %0, i64 %33
  %35 = bitcast i8* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = getelementptr inbounds i8, i8* %1, i64 %33
  %39 = bitcast i8* %38 to i64*
  %40 = load i64, i64* %39, align 1
  %41 = insertelement <2 x i64> %37, i64 %40, i32 1
  %42 = bitcast <2 x i64> %41 to <16 x i8>
  %43 = bitcast <2 x i64> %31 to <16 x i8>
  %44 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %42, <16 x i8> %43) #8
  %45 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %43, <16 x i8> %42) #8
  %46 = or <16 x i8> %45, %44
  %47 = bitcast <2 x i64> %21 to <16 x i8>
  %48 = bitcast <2 x i64> %12 to <16 x i8>
  %49 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %48) #8
  %50 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %48, <16 x i8> %47) #8
  %51 = or <16 x i8> %50, %49
  %52 = icmp ugt <16 x i8> %46, %51
  %53 = select <16 x i1> %52, <16 x i8> %46, <16 x i8> %51
  %54 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %43, <16 x i8> %47) #8
  %55 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %43) #8
  %56 = or <16 x i8> %55, %54
  %57 = icmp ugt <16 x i8> %53, %56
  %58 = select <16 x i1> %57, <16 x i8> %53, <16 x i8> %56
  %59 = shl nsw i32 %2, 2
  %60 = sext i32 %59 to i64
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  %62 = getelementptr inbounds i8, i8* %1, i64 %60
  %63 = bitcast i8* %61 to i64*
  %64 = load i64, i64* %63, align 1
  %65 = insertelement <2 x i64> undef, i64 %64, i32 0
  %66 = bitcast i8* %62 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> %65, i64 %67, i32 1
  %69 = getelementptr inbounds i8, i8* %61, i64 %13
  %70 = bitcast i8* %69 to i64*
  %71 = load i64, i64* %70, align 1
  %72 = insertelement <2 x i64> undef, i64 %71, i32 0
  %73 = getelementptr inbounds i8, i8* %62, i64 %13
  %74 = bitcast i8* %73 to i64*
  %75 = load i64, i64* %74, align 1
  %76 = insertelement <2 x i64> %72, i64 %75, i32 1
  %77 = getelementptr inbounds i8, i8* %61, i64 %23
  %78 = bitcast i8* %77 to i64*
  %79 = load i64, i64* %78, align 1
  %80 = insertelement <2 x i64> undef, i64 %79, i32 0
  %81 = getelementptr inbounds i8, i8* %62, i64 %23
  %82 = bitcast i8* %81 to i64*
  %83 = load i64, i64* %82, align 1
  %84 = insertelement <2 x i64> %80, i64 %83, i32 1
  %85 = getelementptr inbounds i8, i8* %61, i64 %33
  %86 = bitcast i8* %85 to i64*
  %87 = load i64, i64* %86, align 1
  %88 = insertelement <2 x i64> undef, i64 %87, i32 0
  %89 = getelementptr inbounds i8, i8* %62, i64 %33
  %90 = bitcast i8* %89 to i64*
  %91 = load i64, i64* %90, align 1
  %92 = insertelement <2 x i64> %88, i64 %91, i32 1
  %93 = bitcast <2 x i64> %68 to <16 x i8>
  %94 = bitcast <2 x i64> %76 to <16 x i8>
  %95 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %93, <16 x i8> %94) #8
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %94, <16 x i8> %93) #8
  %97 = or <16 x i8> %96, %95
  %98 = icmp ugt <16 x i8> %58, %97
  %99 = select <16 x i1> %98, <16 x i8> %58, <16 x i8> %97
  %100 = bitcast <2 x i64> %84 to <16 x i8>
  %101 = bitcast <2 x i64> %92 to <16 x i8>
  %102 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %100, <16 x i8> %101) #8
  %103 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %101, <16 x i8> %100) #8
  %104 = or <16 x i8> %103, %102
  %105 = icmp ugt <16 x i8> %99, %104
  %106 = select <16 x i1> %105, <16 x i8> %99, <16 x i8> %104
  %107 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %94, <16 x i8> %100) #8
  %108 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %100, <16 x i8> %94) #8
  %109 = or <16 x i8> %108, %107
  %110 = icmp ugt <16 x i8> %106, %109
  %111 = select <16 x i1> %110, <16 x i8> %106, <16 x i8> %109
  %112 = trunc i32 %4 to i8
  %113 = insertelement <16 x i8> undef, i8 %112, i32 0
  %114 = shufflevector <16 x i8> %113, <16 x i8> undef, <16 x i32> zeroinitializer
  %115 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %114) #8
  %116 = icmp eq <16 x i8> %115, zeroinitializer
  %117 = trunc i32 %3 to i8
  %118 = insertelement <16 x i8> undef, i8 %117, i32 0
  %119 = shufflevector <16 x i8> %118, <16 x i8> undef, <16 x i32> zeroinitializer
  %120 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %94, <16 x i8> %43) #8
  %121 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %43, <16 x i8> %94) #8
  %122 = or <16 x i8> %121, %120
  %123 = bitcast <16 x i8> %122 to <8 x i16>
  %124 = lshr <8 x i16> %123, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %125 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %93, <16 x i8> %42) #8
  %126 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %42, <16 x i8> %93) #8
  %127 = or <16 x i8> %126, %125
  %128 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %127, <16 x i8> %127) #8
  %129 = bitcast <8 x i16> %124 to <16 x i8>
  %130 = and <16 x i8> %129, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %131 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> %130) #8
  %132 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %131, <16 x i8> %119) #8
  %133 = icmp eq <16 x i8> %132, zeroinitializer
  %134 = and <16 x i1> %116, %133
  %135 = trunc i32 %5 to i8
  %136 = insertelement <16 x i8> undef, i8 %135, i32 0
  %137 = shufflevector <16 x i8> %136, <16 x i8> undef, <16 x i32> zeroinitializer
  %138 = icmp ugt <16 x i8> %46, %97
  %139 = select <16 x i1> %138, <16 x i8> %46, <16 x i8> %97
  %140 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %139, <16 x i8> %137) #8
  %141 = icmp eq <16 x i8> %140, zeroinitializer
  %142 = sext <16 x i1> %141 to <16 x i8>
  %143 = xor <16 x i8> %43, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %144 = xor <16 x i8> %94, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %145 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %143, <16 x i8> %144) #8
  %146 = xor <16 x i8> %93, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %147 = xor <16 x i8> %42, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %148 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %146, <16 x i8> %147) #8
  %149 = xor <16 x i8> %142, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %150 = and <16 x i8> %145, %149
  %151 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %150, <16 x i8> %148) #8
  %152 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %151, <16 x i8> %148) #8
  %153 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %152, <16 x i8> %148) #8
  %154 = select <16 x i1> %134, <16 x i8> %153, <16 x i8> zeroinitializer
  %155 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %154, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %156 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %154, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %157 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %155, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %158 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %155, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %159 = bitcast <16 x i8> %157 to <8 x i16>
  %160 = ashr <8 x i16> %159, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %161 = bitcast <16 x i8> %158 to <8 x i16>
  %162 = ashr <8 x i16> %161, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %163 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %160, <8 x i16> %162) #8
  %164 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %156, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %165 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %156, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %166 = bitcast <16 x i8> %164 to <8 x i16>
  %167 = ashr <8 x i16> %166, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %168 = bitcast <16 x i8> %165 to <8 x i16>
  %169 = ashr <8 x i16> %168, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %170 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %167, <8 x i16> %169) #8
  %171 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %147, <16 x i8> %163) #8
  %172 = bitcast <16 x i8> %171 to <2 x i64>
  %173 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %146, <16 x i8> %170) #8
  %174 = bitcast <16 x i8> %173 to <2 x i64>
  %175 = xor <2 x i64> %172, <i64 -9187201950435737472, i64 -9187201950435737472>
  %176 = xor <2 x i64> %174, <i64 -9187201950435737472, i64 -9187201950435737472>
  %177 = xor <16 x i8> %170, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %178 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %177, <16 x i8> zeroinitializer) #8
  %179 = add <16 x i8> %178, <i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64>
  %180 = and <16 x i8> %179, %142
  %181 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %144, <16 x i8> %180) #8
  %182 = bitcast <16 x i8> %181 to <2 x i64>
  %183 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %143, <16 x i8> %180) #8
  %184 = bitcast <16 x i8> %183 to <2 x i64>
  %185 = xor <2 x i64> %184, <i64 -9187201950435737472, i64 -9187201950435737472>
  %186 = xor <2 x i64> %182, <i64 -9187201950435737472, i64 -9187201950435737472>
  %187 = mul nsw i32 %2, -2
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds i8, i8* %61, i64 %188
  %190 = extractelement <2 x i64> %185, i32 0
  %191 = bitcast i8* %189 to i64*
  store i64 %190, i64* %191, align 1
  %192 = bitcast <2 x i64> %185 to <16 x i8>
  %193 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %194 = bitcast <16 x i8> %193 to <2 x i64>
  %195 = getelementptr inbounds i8, i8* %62, i64 %188
  %196 = extractelement <2 x i64> %194, i32 0
  %197 = bitcast i8* %195 to i64*
  store i64 %196, i64* %197, align 1
  %198 = sub nsw i32 0, %2
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds i8, i8* %61, i64 %199
  %201 = extractelement <2 x i64> %175, i32 0
  %202 = bitcast i8* %200 to i64*
  store i64 %201, i64* %202, align 1
  %203 = bitcast <2 x i64> %175 to <16 x i8>
  %204 = shufflevector <16 x i8> %203, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %205 = bitcast <16 x i8> %204 to <2 x i64>
  %206 = getelementptr inbounds i8, i8* %62, i64 %199
  %207 = extractelement <2 x i64> %205, i32 0
  %208 = bitcast i8* %206 to i64*
  store i64 %207, i64* %208, align 1
  %209 = extractelement <2 x i64> %176, i32 0
  store i64 %209, i64* %63, align 1
  %210 = bitcast <2 x i64> %176 to <16 x i8>
  %211 = shufflevector <16 x i8> %210, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %212 = bitcast <16 x i8> %211 to <2 x i64>
  %213 = extractelement <2 x i64> %212, i32 0
  store i64 %213, i64* %66, align 1
  %214 = extractelement <2 x i64> %186, i32 0
  store i64 %214, i64* %70, align 1
  %215 = bitcast <2 x i64> %186 to <16 x i8>
  %216 = shufflevector <16 x i8> %215, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %217 = bitcast <16 x i8> %216 to <2 x i64>
  %218 = extractelement <2 x i64> %217, i32 0
  store i64 %218, i64* %74, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @HFilter8i_SSE2(i8* nocapture, i8* nocapture, i32, i32, i32, i32) #1 {
  %7 = mul nsw i32 %2, 6
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = bitcast i8* %9 to i32*
  %11 = load i32, i32* %10, align 1
  %12 = shl nsw i32 %2, 1
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i8, i8* %0, i64 %13
  %15 = bitcast i8* %14 to i32*
  %16 = load i32, i32* %15, align 1
  %17 = shl nsw i32 %2, 2
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds i8, i8* %0, i64 %18
  %20 = bitcast i8* %19 to i32*
  %21 = load i32, i32* %20, align 1
  %22 = bitcast i8* %0 to i32*
  %23 = load i32, i32* %22, align 1
  %24 = insertelement <4 x i32> undef, i32 %23, i32 0
  %25 = insertelement <4 x i32> %24, i32 %21, i32 1
  %26 = insertelement <4 x i32> %25, i32 %16, i32 2
  %27 = insertelement <4 x i32> %26, i32 %11, i32 3
  %28 = mul nsw i32 %2, 7
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = bitcast i8* %30 to i32*
  %32 = load i32, i32* %31, align 1
  %33 = mul nsw i32 %2, 3
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds i8, i8* %0, i64 %34
  %36 = bitcast i8* %35 to i32*
  %37 = load i32, i32* %36, align 1
  %38 = mul nsw i32 %2, 5
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds i8, i8* %0, i64 %39
  %41 = bitcast i8* %40 to i32*
  %42 = load i32, i32* %41, align 1
  %43 = sext i32 %2 to i64
  %44 = getelementptr inbounds i8, i8* %0, i64 %43
  %45 = bitcast i8* %44 to i32*
  %46 = load i32, i32* %45, align 1
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = insertelement <4 x i32> %47, i32 %42, i32 1
  %49 = insertelement <4 x i32> %48, i32 %37, i32 2
  %50 = insertelement <4 x i32> %49, i32 %32, i32 3
  %51 = bitcast <4 x i32> %27 to <16 x i8>
  %52 = bitcast <4 x i32> %50 to <16 x i8>
  %53 = shufflevector <16 x i8> %51, <16 x i8> %52, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %54 = shufflevector <16 x i8> %51, <16 x i8> %52, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = bitcast <16 x i8> %53 to <8 x i16>
  %56 = bitcast <16 x i8> %54 to <8 x i16>
  %57 = shufflevector <8 x i16> %55, <8 x i16> %56, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %58 = shufflevector <8 x i16> %55, <8 x i16> %56, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %59 = bitcast <8 x i16> %57 to <4 x i32>
  %60 = bitcast <8 x i16> %58 to <4 x i32>
  %61 = shufflevector <4 x i32> %59, <4 x i32> %60, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %62 = bitcast <4 x i32> %61 to <2 x i64>
  %63 = shufflevector <4 x i32> %59, <4 x i32> %60, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %64 = bitcast <4 x i32> %63 to <2 x i64>
  %65 = getelementptr inbounds i8, i8* %1, i64 %8
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 1
  %68 = getelementptr inbounds i8, i8* %1, i64 %13
  %69 = bitcast i8* %68 to i32*
  %70 = load i32, i32* %69, align 1
  %71 = getelementptr inbounds i8, i8* %1, i64 %18
  %72 = bitcast i8* %71 to i32*
  %73 = load i32, i32* %72, align 1
  %74 = bitcast i8* %1 to i32*
  %75 = load i32, i32* %74, align 1
  %76 = insertelement <4 x i32> undef, i32 %75, i32 0
  %77 = insertelement <4 x i32> %76, i32 %73, i32 1
  %78 = insertelement <4 x i32> %77, i32 %70, i32 2
  %79 = insertelement <4 x i32> %78, i32 %67, i32 3
  %80 = getelementptr inbounds i8, i8* %1, i64 %29
  %81 = bitcast i8* %80 to i32*
  %82 = load i32, i32* %81, align 1
  %83 = getelementptr inbounds i8, i8* %1, i64 %34
  %84 = bitcast i8* %83 to i32*
  %85 = load i32, i32* %84, align 1
  %86 = getelementptr inbounds i8, i8* %1, i64 %39
  %87 = bitcast i8* %86 to i32*
  %88 = load i32, i32* %87, align 1
  %89 = getelementptr inbounds i8, i8* %1, i64 %43
  %90 = bitcast i8* %89 to i32*
  %91 = load i32, i32* %90, align 1
  %92 = insertelement <4 x i32> undef, i32 %91, i32 0
  %93 = insertelement <4 x i32> %92, i32 %88, i32 1
  %94 = insertelement <4 x i32> %93, i32 %85, i32 2
  %95 = insertelement <4 x i32> %94, i32 %82, i32 3
  %96 = bitcast <4 x i32> %79 to <16 x i8>
  %97 = bitcast <4 x i32> %95 to <16 x i8>
  %98 = shufflevector <16 x i8> %96, <16 x i8> %97, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %99 = shufflevector <16 x i8> %96, <16 x i8> %97, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %100 = bitcast <16 x i8> %98 to <8 x i16>
  %101 = bitcast <16 x i8> %99 to <8 x i16>
  %102 = shufflevector <8 x i16> %100, <8 x i16> %101, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %103 = shufflevector <8 x i16> %100, <8 x i16> %101, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %104 = bitcast <8 x i16> %102 to <4 x i32>
  %105 = bitcast <8 x i16> %103 to <4 x i32>
  %106 = shufflevector <4 x i32> %104, <4 x i32> %105, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %107 = bitcast <4 x i32> %106 to <2 x i64>
  %108 = shufflevector <4 x i32> %104, <4 x i32> %105, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %109 = bitcast <4 x i32> %108 to <2 x i64>
  %110 = shufflevector <2 x i64> %62, <2 x i64> %107, <2 x i32> <i32 0, i32 2>
  %111 = shufflevector <2 x i64> %62, <2 x i64> %107, <2 x i32> <i32 1, i32 3>
  %112 = shufflevector <2 x i64> %64, <2 x i64> %109, <2 x i32> <i32 0, i32 2>
  %113 = shufflevector <2 x i64> %64, <2 x i64> %109, <2 x i32> <i32 1, i32 3>
  %114 = bitcast <2 x i64> %113 to <16 x i8>
  %115 = bitcast <2 x i64> %112 to <16 x i8>
  %116 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %114, <16 x i8> %115) #8
  %117 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %115, <16 x i8> %114) #8
  %118 = or <16 x i8> %117, %116
  %119 = bitcast <2 x i64> %111 to <16 x i8>
  %120 = bitcast <2 x i64> %110 to <16 x i8>
  %121 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %119, <16 x i8> %120) #8
  %122 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %120, <16 x i8> %119) #8
  %123 = or <16 x i8> %122, %121
  %124 = icmp ugt <16 x i8> %118, %123
  %125 = select <16 x i1> %124, <16 x i8> %118, <16 x i8> %123
  %126 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %115, <16 x i8> %119) #8
  %127 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %119, <16 x i8> %115) #8
  %128 = or <16 x i8> %127, %126
  %129 = icmp ugt <16 x i8> %125, %128
  %130 = select <16 x i1> %129, <16 x i8> %125, <16 x i8> %128
  %131 = getelementptr inbounds i8, i8* %0, i64 4
  %132 = getelementptr inbounds i8, i8* %1, i64 4
  %133 = getelementptr inbounds i8, i8* %131, i64 %8
  %134 = bitcast i8* %133 to i32*
  %135 = load i32, i32* %134, align 1
  %136 = getelementptr inbounds i8, i8* %131, i64 %13
  %137 = bitcast i8* %136 to i32*
  %138 = load i32, i32* %137, align 1
  %139 = getelementptr inbounds i8, i8* %131, i64 %18
  %140 = bitcast i8* %139 to i32*
  %141 = load i32, i32* %140, align 1
  %142 = bitcast i8* %131 to i32*
  %143 = load i32, i32* %142, align 1
  %144 = insertelement <4 x i32> undef, i32 %143, i32 0
  %145 = insertelement <4 x i32> %144, i32 %141, i32 1
  %146 = insertelement <4 x i32> %145, i32 %138, i32 2
  %147 = insertelement <4 x i32> %146, i32 %135, i32 3
  %148 = getelementptr inbounds i8, i8* %131, i64 %29
  %149 = bitcast i8* %148 to i32*
  %150 = load i32, i32* %149, align 1
  %151 = getelementptr inbounds i8, i8* %131, i64 %34
  %152 = bitcast i8* %151 to i32*
  %153 = load i32, i32* %152, align 1
  %154 = getelementptr inbounds i8, i8* %131, i64 %39
  %155 = bitcast i8* %154 to i32*
  %156 = load i32, i32* %155, align 1
  %157 = getelementptr inbounds i8, i8* %131, i64 %43
  %158 = bitcast i8* %157 to i32*
  %159 = load i32, i32* %158, align 1
  %160 = insertelement <4 x i32> undef, i32 %159, i32 0
  %161 = insertelement <4 x i32> %160, i32 %156, i32 1
  %162 = insertelement <4 x i32> %161, i32 %153, i32 2
  %163 = insertelement <4 x i32> %162, i32 %150, i32 3
  %164 = bitcast <4 x i32> %147 to <16 x i8>
  %165 = bitcast <4 x i32> %163 to <16 x i8>
  %166 = shufflevector <16 x i8> %164, <16 x i8> %165, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %167 = shufflevector <16 x i8> %164, <16 x i8> %165, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %168 = bitcast <16 x i8> %166 to <8 x i16>
  %169 = bitcast <16 x i8> %167 to <8 x i16>
  %170 = shufflevector <8 x i16> %168, <8 x i16> %169, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %171 = shufflevector <8 x i16> %168, <8 x i16> %169, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %172 = bitcast <8 x i16> %170 to <4 x i32>
  %173 = bitcast <8 x i16> %171 to <4 x i32>
  %174 = shufflevector <4 x i32> %172, <4 x i32> %173, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %175 = bitcast <4 x i32> %174 to <2 x i64>
  %176 = shufflevector <4 x i32> %172, <4 x i32> %173, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = getelementptr inbounds i8, i8* %132, i64 %8
  %179 = bitcast i8* %178 to i32*
  %180 = load i32, i32* %179, align 1
  %181 = getelementptr inbounds i8, i8* %132, i64 %13
  %182 = bitcast i8* %181 to i32*
  %183 = load i32, i32* %182, align 1
  %184 = getelementptr inbounds i8, i8* %132, i64 %18
  %185 = bitcast i8* %184 to i32*
  %186 = load i32, i32* %185, align 1
  %187 = bitcast i8* %132 to i32*
  %188 = load i32, i32* %187, align 1
  %189 = insertelement <4 x i32> undef, i32 %188, i32 0
  %190 = insertelement <4 x i32> %189, i32 %186, i32 1
  %191 = insertelement <4 x i32> %190, i32 %183, i32 2
  %192 = insertelement <4 x i32> %191, i32 %180, i32 3
  %193 = getelementptr inbounds i8, i8* %132, i64 %29
  %194 = bitcast i8* %193 to i32*
  %195 = load i32, i32* %194, align 1
  %196 = getelementptr inbounds i8, i8* %132, i64 %34
  %197 = bitcast i8* %196 to i32*
  %198 = load i32, i32* %197, align 1
  %199 = getelementptr inbounds i8, i8* %132, i64 %39
  %200 = bitcast i8* %199 to i32*
  %201 = load i32, i32* %200, align 1
  %202 = getelementptr inbounds i8, i8* %132, i64 %43
  %203 = bitcast i8* %202 to i32*
  %204 = load i32, i32* %203, align 1
  %205 = insertelement <4 x i32> undef, i32 %204, i32 0
  %206 = insertelement <4 x i32> %205, i32 %201, i32 1
  %207 = insertelement <4 x i32> %206, i32 %198, i32 2
  %208 = insertelement <4 x i32> %207, i32 %195, i32 3
  %209 = bitcast <4 x i32> %192 to <16 x i8>
  %210 = bitcast <4 x i32> %208 to <16 x i8>
  %211 = shufflevector <16 x i8> %209, <16 x i8> %210, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %212 = shufflevector <16 x i8> %209, <16 x i8> %210, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %213 = bitcast <16 x i8> %211 to <8 x i16>
  %214 = bitcast <16 x i8> %212 to <8 x i16>
  %215 = shufflevector <8 x i16> %213, <8 x i16> %214, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %216 = shufflevector <8 x i16> %213, <8 x i16> %214, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = shufflevector <4 x i32> %217, <4 x i32> %218, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %220 = bitcast <4 x i32> %219 to <2 x i64>
  %221 = shufflevector <4 x i32> %217, <4 x i32> %218, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %222 = bitcast <4 x i32> %221 to <2 x i64>
  %223 = shufflevector <2 x i64> %175, <2 x i64> %220, <2 x i32> <i32 0, i32 2>
  %224 = shufflevector <2 x i64> %175, <2 x i64> %220, <2 x i32> <i32 1, i32 3>
  %225 = shufflevector <2 x i64> %177, <2 x i64> %222, <2 x i32> <i32 0, i32 2>
  %226 = shufflevector <2 x i64> %177, <2 x i64> %222, <2 x i32> <i32 1, i32 3>
  %227 = bitcast <2 x i64> %223 to <16 x i8>
  %228 = bitcast <2 x i64> %224 to <16 x i8>
  %229 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %227, <16 x i8> %228) #8
  %230 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %228, <16 x i8> %227) #8
  %231 = or <16 x i8> %230, %229
  %232 = icmp ugt <16 x i8> %130, %231
  %233 = select <16 x i1> %232, <16 x i8> %130, <16 x i8> %231
  %234 = bitcast <2 x i64> %225 to <16 x i8>
  %235 = bitcast <2 x i64> %226 to <16 x i8>
  %236 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %234, <16 x i8> %235) #8
  %237 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %235, <16 x i8> %234) #8
  %238 = or <16 x i8> %237, %236
  %239 = icmp ugt <16 x i8> %233, %238
  %240 = select <16 x i1> %239, <16 x i8> %233, <16 x i8> %238
  %241 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %228, <16 x i8> %234) #8
  %242 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %234, <16 x i8> %228) #8
  %243 = or <16 x i8> %242, %241
  %244 = icmp ugt <16 x i8> %240, %243
  %245 = select <16 x i1> %244, <16 x i8> %240, <16 x i8> %243
  %246 = trunc i32 %4 to i8
  %247 = insertelement <16 x i8> undef, i8 %246, i32 0
  %248 = shufflevector <16 x i8> %247, <16 x i8> undef, <16 x i32> zeroinitializer
  %249 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %245, <16 x i8> %248) #8
  %250 = icmp eq <16 x i8> %249, zeroinitializer
  %251 = trunc i32 %3 to i8
  %252 = insertelement <16 x i8> undef, i8 %251, i32 0
  %253 = shufflevector <16 x i8> %252, <16 x i8> undef, <16 x i32> zeroinitializer
  %254 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %228, <16 x i8> %115) #8
  %255 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %115, <16 x i8> %228) #8
  %256 = or <16 x i8> %255, %254
  %257 = bitcast <16 x i8> %256 to <8 x i16>
  %258 = lshr <8 x i16> %257, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %259 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %227, <16 x i8> %114) #8
  %260 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %114, <16 x i8> %227) #8
  %261 = or <16 x i8> %260, %259
  %262 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %261, <16 x i8> %261) #8
  %263 = bitcast <8 x i16> %258 to <16 x i8>
  %264 = and <16 x i8> %263, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %265 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %262, <16 x i8> %264) #8
  %266 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %265, <16 x i8> %253) #8
  %267 = icmp eq <16 x i8> %266, zeroinitializer
  %268 = and <16 x i1> %250, %267
  %269 = trunc i32 %5 to i8
  %270 = insertelement <16 x i8> undef, i8 %269, i32 0
  %271 = shufflevector <16 x i8> %270, <16 x i8> undef, <16 x i32> zeroinitializer
  %272 = icmp ugt <16 x i8> %118, %231
  %273 = select <16 x i1> %272, <16 x i8> %118, <16 x i8> %231
  %274 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %273, <16 x i8> %271) #8
  %275 = icmp eq <16 x i8> %274, zeroinitializer
  %276 = sext <16 x i1> %275 to <16 x i8>
  %277 = xor <16 x i8> %115, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %278 = xor <16 x i8> %228, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %279 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %277, <16 x i8> %278) #8
  %280 = xor <16 x i8> %227, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %281 = xor <16 x i8> %114, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %282 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %280, <16 x i8> %281) #8
  %283 = xor <16 x i8> %276, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %284 = and <16 x i8> %279, %283
  %285 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %284, <16 x i8> %282) #8
  %286 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %285, <16 x i8> %282) #8
  %287 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %286, <16 x i8> %282) #8
  %288 = select <16 x i1> %268, <16 x i8> %287, <16 x i8> zeroinitializer
  %289 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %288, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %290 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %288, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %291 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %289, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %292 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %289, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %293 = bitcast <16 x i8> %291 to <8 x i16>
  %294 = ashr <8 x i16> %293, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %295 = bitcast <16 x i8> %292 to <8 x i16>
  %296 = ashr <8 x i16> %295, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %297 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %294, <8 x i16> %296) #8
  %298 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %290, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %299 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %290, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %300 = bitcast <16 x i8> %298 to <8 x i16>
  %301 = ashr <8 x i16> %300, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %302 = bitcast <16 x i8> %299 to <8 x i16>
  %303 = ashr <8 x i16> %302, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %304 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %301, <8 x i16> %303) #8
  %305 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %281, <16 x i8> %297) #8
  %306 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %280, <16 x i8> %304) #8
  %307 = xor <16 x i8> %304, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %308 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %307, <16 x i8> zeroinitializer) #8
  %309 = add <16 x i8> %308, <i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64>
  %310 = and <16 x i8> %309, %276
  %311 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %278, <16 x i8> %310) #8
  %312 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %277, <16 x i8> %310) #8
  %313 = getelementptr inbounds i8, i8* %0, i64 2
  %314 = getelementptr inbounds i8, i8* %1, i64 2
  %315 = xor <16 x i8> %305, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %316 = xor <16 x i8> %312, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %317 = shufflevector <16 x i8> %316, <16 x i8> %315, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %318 = shufflevector <16 x i8> %316, <16 x i8> %315, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %319 = xor <16 x i8> %306, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %320 = xor <16 x i8> %311, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %321 = shufflevector <16 x i8> %319, <16 x i8> %320, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %322 = shufflevector <16 x i8> %319, <16 x i8> %320, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %323 = bitcast <16 x i8> %317 to <8 x i16>
  %324 = bitcast <16 x i8> %321 to <8 x i16>
  %325 = shufflevector <8 x i16> %323, <8 x i16> %324, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %326 = shufflevector <8 x i16> %323, <8 x i16> %324, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %327 = bitcast <16 x i8> %318 to <8 x i16>
  %328 = bitcast <16 x i8> %322 to <8 x i16>
  %329 = shufflevector <8 x i16> %327, <8 x i16> %328, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %330 = shufflevector <8 x i16> %327, <8 x i16> %328, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %331 = bitcast <8 x i16> %325 to <4 x i32>
  %332 = extractelement <4 x i32> %331, i32 0
  %333 = bitcast i8* %313 to i32*
  store i32 %332, i32* %333, align 1
  %334 = bitcast <8 x i16> %325 to <16 x i8>
  %335 = shufflevector <16 x i8> %334, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %336 = getelementptr inbounds i8, i8* %313, i64 %43
  %337 = bitcast <16 x i8> %335 to <4 x i32>
  %338 = extractelement <4 x i32> %337, i32 0
  %339 = bitcast i8* %336 to i32*
  store i32 %338, i32* %339, align 1
  %340 = shufflevector <16 x i8> %335, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %341 = getelementptr inbounds i8, i8* %336, i64 %43
  %342 = bitcast <16 x i8> %340 to <4 x i32>
  %343 = extractelement <4 x i32> %342, i32 0
  %344 = bitcast i8* %341 to i32*
  store i32 %343, i32* %344, align 1
  %345 = shufflevector <16 x i8> %340, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %346 = getelementptr inbounds i8, i8* %341, i64 %43
  %347 = bitcast <16 x i8> %345 to <4 x i32>
  %348 = extractelement <4 x i32> %347, i32 0
  %349 = bitcast i8* %346 to i32*
  store i32 %348, i32* %349, align 1
  %350 = getelementptr inbounds i8, i8* %313, i64 %18
  %351 = bitcast <8 x i16> %326 to <4 x i32>
  %352 = extractelement <4 x i32> %351, i32 0
  %353 = bitcast i8* %350 to i32*
  store i32 %352, i32* %353, align 1
  %354 = bitcast <8 x i16> %326 to <16 x i8>
  %355 = shufflevector <16 x i8> %354, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %356 = getelementptr inbounds i8, i8* %350, i64 %43
  %357 = bitcast <16 x i8> %355 to <4 x i32>
  %358 = extractelement <4 x i32> %357, i32 0
  %359 = bitcast i8* %356 to i32*
  store i32 %358, i32* %359, align 1
  %360 = shufflevector <16 x i8> %355, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %361 = getelementptr inbounds i8, i8* %356, i64 %43
  %362 = bitcast <16 x i8> %360 to <4 x i32>
  %363 = extractelement <4 x i32> %362, i32 0
  %364 = bitcast i8* %361 to i32*
  store i32 %363, i32* %364, align 1
  %365 = shufflevector <16 x i8> %360, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %366 = getelementptr inbounds i8, i8* %361, i64 %43
  %367 = bitcast <16 x i8> %365 to <4 x i32>
  %368 = extractelement <4 x i32> %367, i32 0
  %369 = bitcast i8* %366 to i32*
  store i32 %368, i32* %369, align 1
  %370 = bitcast <8 x i16> %329 to <4 x i32>
  %371 = extractelement <4 x i32> %370, i32 0
  %372 = bitcast i8* %314 to i32*
  store i32 %371, i32* %372, align 1
  %373 = bitcast <8 x i16> %329 to <16 x i8>
  %374 = shufflevector <16 x i8> %373, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %375 = getelementptr inbounds i8, i8* %314, i64 %43
  %376 = bitcast <16 x i8> %374 to <4 x i32>
  %377 = extractelement <4 x i32> %376, i32 0
  %378 = bitcast i8* %375 to i32*
  store i32 %377, i32* %378, align 1
  %379 = shufflevector <16 x i8> %374, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %380 = getelementptr inbounds i8, i8* %375, i64 %43
  %381 = bitcast <16 x i8> %379 to <4 x i32>
  %382 = extractelement <4 x i32> %381, i32 0
  %383 = bitcast i8* %380 to i32*
  store i32 %382, i32* %383, align 1
  %384 = shufflevector <16 x i8> %379, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %385 = getelementptr inbounds i8, i8* %380, i64 %43
  %386 = bitcast <16 x i8> %384 to <4 x i32>
  %387 = extractelement <4 x i32> %386, i32 0
  %388 = bitcast i8* %385 to i32*
  store i32 %387, i32* %388, align 1
  %389 = getelementptr inbounds i8, i8* %314, i64 %18
  %390 = bitcast <8 x i16> %330 to <4 x i32>
  %391 = extractelement <4 x i32> %390, i32 0
  %392 = bitcast i8* %389 to i32*
  store i32 %391, i32* %392, align 1
  %393 = bitcast <8 x i16> %330 to <16 x i8>
  %394 = shufflevector <16 x i8> %393, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %395 = getelementptr inbounds i8, i8* %389, i64 %43
  %396 = bitcast <16 x i8> %394 to <4 x i32>
  %397 = extractelement <4 x i32> %396, i32 0
  %398 = bitcast i8* %395 to i32*
  store i32 %397, i32* %398, align 1
  %399 = shufflevector <16 x i8> %394, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %400 = getelementptr inbounds i8, i8* %395, i64 %43
  %401 = bitcast <16 x i8> %399 to <4 x i32>
  %402 = extractelement <4 x i32> %401, i32 0
  %403 = bitcast i8* %400 to i32*
  store i32 %402, i32* %403, align 1
  %404 = shufflevector <16 x i8> %399, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %405 = getelementptr inbounds i8, i8* %400, i64 %43
  %406 = bitcast <16 x i8> %404 to <4 x i32>
  %407 = extractelement <4 x i32> %406, i32 0
  %408 = bitcast i8* %405 to i32*
  store i32 %407, i32* %408, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @SimpleVFilter16_SSE2(i8* nocapture, i32, i32) #1 {
  %4 = mul nsw i32 %1, -2
  %5 = sext i32 %4 to i64
  %6 = getelementptr inbounds i8, i8* %0, i64 %5
  %7 = bitcast i8* %6 to <16 x i8>*
  %8 = load <16 x i8>, <16 x i8>* %7, align 1
  %9 = sub nsw i32 0, %1
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = bitcast i8* %11 to <2 x i64>*
  %13 = bitcast i8* %11 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = bitcast i8* %0 to <2 x i64>*
  %16 = bitcast i8* %0 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 1
  %18 = sext i32 %1 to i64
  %19 = getelementptr inbounds i8, i8* %0, i64 %18
  %20 = bitcast i8* %19 to <16 x i8>*
  %21 = load <16 x i8>, <16 x i8>* %20, align 1
  %22 = trunc i32 %2 to i8
  %23 = insertelement <16 x i8> undef, i8 %22, i32 0
  %24 = shufflevector <16 x i8> %23, <16 x i8> undef, <16 x i32> zeroinitializer
  %25 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %21, <16 x i8> %8) #8
  %26 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %8, <16 x i8> %21) #8
  %27 = or <16 x i8> %26, %25
  %28 = bitcast <16 x i8> %27 to <8 x i16>
  %29 = lshr <8 x i16> %28, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %30 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %17, <16 x i8> %14) #8
  %31 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %14, <16 x i8> %17) #8
  %32 = or <16 x i8> %31, %30
  %33 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %32, <16 x i8> %32) #8
  %34 = bitcast <8 x i16> %29 to <16 x i8>
  %35 = and <16 x i8> %34, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %36 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %33, <16 x i8> %35) #8
  %37 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %36, <16 x i8> %24) #8
  %38 = icmp eq <16 x i8> %37, zeroinitializer
  %39 = xor <16 x i8> %8, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %40 = xor <16 x i8> %21, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %41 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %39, <16 x i8> %40) #8
  %42 = xor <16 x i8> %17, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %43 = xor <16 x i8> %14, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %44 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %42, <16 x i8> %43) #8
  %45 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %41, <16 x i8> %44) #8
  %46 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %44, <16 x i8> %45) #8
  %47 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %44, <16 x i8> %46) #8
  %48 = select <16 x i1> %38, <16 x i8> %47, <16 x i8> zeroinitializer
  %49 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %48, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %50 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %48, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %51 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %50, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %52 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %50, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %53 = bitcast <16 x i8> %51 to <8 x i16>
  %54 = ashr <8 x i16> %53, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %55 = bitcast <16 x i8> %52 to <8 x i16>
  %56 = ashr <8 x i16> %55, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %57 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %54, <8 x i16> %56) #8
  %58 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %59 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %60 = bitcast <16 x i8> %58 to <8 x i16>
  %61 = ashr <8 x i16> %60, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %62 = bitcast <16 x i8> %59 to <8 x i16>
  %63 = ashr <8 x i16> %62, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %64 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %61, <8 x i16> %63) #8
  %65 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %42, <16 x i8> %57) #8
  %66 = bitcast <16 x i8> %65 to <2 x i64>
  %67 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %43, <16 x i8> %64) #8
  %68 = bitcast <16 x i8> %67 to <2 x i64>
  %69 = xor <2 x i64> %68, <i64 -9187201950435737472, i64 -9187201950435737472>
  %70 = xor <2 x i64> %66, <i64 -9187201950435737472, i64 -9187201950435737472>
  store <2 x i64> %69, <2 x i64>* %12, align 1
  store <2 x i64> %70, <2 x i64>* %15, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @SimpleHFilter16_SSE2(i8* nocapture, i32, i32) #1 {
  %4 = getelementptr inbounds i8, i8* %0, i64 -2
  %5 = shl nsw i32 %1, 3
  %6 = sext i32 %5 to i64
  %7 = getelementptr inbounds i8, i8* %4, i64 %6
  %8 = mul nsw i32 %1, 6
  %9 = sext i32 %8 to i64
  %10 = getelementptr inbounds i8, i8* %4, i64 %9
  %11 = bitcast i8* %10 to i32*
  %12 = load i32, i32* %11, align 1
  %13 = shl nsw i32 %1, 1
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %4, i64 %14
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 1
  %18 = shl nsw i32 %1, 2
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i8, i8* %4, i64 %19
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 1
  %23 = bitcast i8* %4 to i32*
  %24 = load i32, i32* %23, align 1
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = insertelement <4 x i32> %25, i32 %22, i32 1
  %27 = insertelement <4 x i32> %26, i32 %17, i32 2
  %28 = insertelement <4 x i32> %27, i32 %12, i32 3
  %29 = mul nsw i32 %1, 7
  %30 = sext i32 %29 to i64
  %31 = getelementptr inbounds i8, i8* %4, i64 %30
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 1
  %34 = mul nsw i32 %1, 3
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds i8, i8* %4, i64 %35
  %37 = bitcast i8* %36 to i32*
  %38 = load i32, i32* %37, align 1
  %39 = mul nsw i32 %1, 5
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i8, i8* %4, i64 %40
  %42 = bitcast i8* %41 to i32*
  %43 = load i32, i32* %42, align 1
  %44 = sext i32 %1 to i64
  %45 = getelementptr inbounds i8, i8* %4, i64 %44
  %46 = bitcast i8* %45 to i32*
  %47 = load i32, i32* %46, align 1
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = insertelement <4 x i32> %48, i32 %43, i32 1
  %50 = insertelement <4 x i32> %49, i32 %38, i32 2
  %51 = insertelement <4 x i32> %50, i32 %33, i32 3
  %52 = bitcast <4 x i32> %28 to <16 x i8>
  %53 = bitcast <4 x i32> %51 to <16 x i8>
  %54 = shufflevector <16 x i8> %52, <16 x i8> %53, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> %52, <16 x i8> %53, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = bitcast <16 x i8> %54 to <8 x i16>
  %57 = bitcast <16 x i8> %55 to <8 x i16>
  %58 = shufflevector <8 x i16> %56, <8 x i16> %57, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %59 = shufflevector <8 x i16> %56, <8 x i16> %57, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %60 = bitcast <8 x i16> %58 to <4 x i32>
  %61 = bitcast <8 x i16> %59 to <4 x i32>
  %62 = shufflevector <4 x i32> %60, <4 x i32> %61, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %63 = bitcast <4 x i32> %62 to <2 x i64>
  %64 = shufflevector <4 x i32> %60, <4 x i32> %61, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %65 = bitcast <4 x i32> %64 to <2 x i64>
  %66 = getelementptr inbounds i8, i8* %7, i64 %9
  %67 = bitcast i8* %66 to i32*
  %68 = load i32, i32* %67, align 1
  %69 = getelementptr inbounds i8, i8* %7, i64 %14
  %70 = bitcast i8* %69 to i32*
  %71 = load i32, i32* %70, align 1
  %72 = getelementptr inbounds i8, i8* %7, i64 %19
  %73 = bitcast i8* %72 to i32*
  %74 = load i32, i32* %73, align 1
  %75 = bitcast i8* %7 to i32*
  %76 = load i32, i32* %75, align 1
  %77 = insertelement <4 x i32> undef, i32 %76, i32 0
  %78 = insertelement <4 x i32> %77, i32 %74, i32 1
  %79 = insertelement <4 x i32> %78, i32 %71, i32 2
  %80 = insertelement <4 x i32> %79, i32 %68, i32 3
  %81 = getelementptr inbounds i8, i8* %7, i64 %30
  %82 = bitcast i8* %81 to i32*
  %83 = load i32, i32* %82, align 1
  %84 = getelementptr inbounds i8, i8* %7, i64 %35
  %85 = bitcast i8* %84 to i32*
  %86 = load i32, i32* %85, align 1
  %87 = getelementptr inbounds i8, i8* %7, i64 %40
  %88 = bitcast i8* %87 to i32*
  %89 = load i32, i32* %88, align 1
  %90 = getelementptr inbounds i8, i8* %7, i64 %44
  %91 = bitcast i8* %90 to i32*
  %92 = load i32, i32* %91, align 1
  %93 = insertelement <4 x i32> undef, i32 %92, i32 0
  %94 = insertelement <4 x i32> %93, i32 %89, i32 1
  %95 = insertelement <4 x i32> %94, i32 %86, i32 2
  %96 = insertelement <4 x i32> %95, i32 %83, i32 3
  %97 = bitcast <4 x i32> %80 to <16 x i8>
  %98 = bitcast <4 x i32> %96 to <16 x i8>
  %99 = shufflevector <16 x i8> %97, <16 x i8> %98, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %100 = shufflevector <16 x i8> %97, <16 x i8> %98, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %101 = bitcast <16 x i8> %99 to <8 x i16>
  %102 = bitcast <16 x i8> %100 to <8 x i16>
  %103 = shufflevector <8 x i16> %101, <8 x i16> %102, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %104 = shufflevector <8 x i16> %101, <8 x i16> %102, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %105 = bitcast <8 x i16> %103 to <4 x i32>
  %106 = bitcast <8 x i16> %104 to <4 x i32>
  %107 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %108 = bitcast <4 x i32> %107 to <2 x i64>
  %109 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %110 = bitcast <4 x i32> %109 to <2 x i64>
  %111 = shufflevector <2 x i64> %63, <2 x i64> %108, <2 x i32> <i32 0, i32 2>
  %112 = shufflevector <2 x i64> %63, <2 x i64> %108, <2 x i32> <i32 1, i32 3>
  %113 = shufflevector <2 x i64> %65, <2 x i64> %110, <2 x i32> <i32 0, i32 2>
  %114 = shufflevector <2 x i64> %65, <2 x i64> %110, <2 x i32> <i32 1, i32 3>
  %115 = bitcast <2 x i64> %111 to <16 x i8>
  %116 = bitcast <2 x i64> %114 to <16 x i8>
  %117 = trunc i32 %2 to i8
  %118 = insertelement <16 x i8> undef, i8 %117, i32 0
  %119 = shufflevector <16 x i8> %118, <16 x i8> undef, <16 x i32> zeroinitializer
  %120 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %116, <16 x i8> %115) #8
  %121 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %115, <16 x i8> %116) #8
  %122 = or <16 x i8> %121, %120
  %123 = bitcast <16 x i8> %122 to <8 x i16>
  %124 = lshr <8 x i16> %123, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %125 = bitcast <2 x i64> %113 to <16 x i8>
  %126 = bitcast <2 x i64> %112 to <16 x i8>
  %127 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %125, <16 x i8> %126) #8
  %128 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %126, <16 x i8> %125) #8
  %129 = or <16 x i8> %128, %127
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> %129) #8
  %131 = bitcast <8 x i16> %124 to <16 x i8>
  %132 = and <16 x i8> %131, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %130, <16 x i8> %132) #8
  %134 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %133, <16 x i8> %119) #8
  %135 = icmp eq <16 x i8> %134, zeroinitializer
  %136 = xor <16 x i8> %115, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %137 = xor <16 x i8> %116, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %138 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %136, <16 x i8> %137) #8
  %139 = xor <16 x i8> %125, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %140 = xor <16 x i8> %126, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %141 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %139, <16 x i8> %140) #8
  %142 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %138, <16 x i8> %141) #8
  %143 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %141, <16 x i8> %142) #8
  %144 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %141, <16 x i8> %143) #8
  %145 = select <16 x i1> %135, <16 x i8> %144, <16 x i8> zeroinitializer
  %146 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %145, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %147 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %145, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %148 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %147, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %149 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %147, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %150 = bitcast <16 x i8> %148 to <8 x i16>
  %151 = ashr <8 x i16> %150, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %152 = bitcast <16 x i8> %149 to <8 x i16>
  %153 = ashr <8 x i16> %152, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %154 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %151, <8 x i16> %153) #8
  %155 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %146, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %156 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %146, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %157 = bitcast <16 x i8> %155 to <8 x i16>
  %158 = ashr <8 x i16> %157, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %159 = bitcast <16 x i8> %156 to <8 x i16>
  %160 = ashr <8 x i16> %159, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %161 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %158, <8 x i16> %160) #8
  %162 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %139, <16 x i8> %154) #8
  %163 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %140, <16 x i8> %161) #8
  %164 = xor <16 x i8> %163, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %165 = shufflevector <16 x i8> %115, <16 x i8> %164, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %166 = shufflevector <16 x i8> %115, <16 x i8> %164, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %167 = xor <16 x i8> %162, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %168 = shufflevector <16 x i8> %167, <16 x i8> %116, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %169 = shufflevector <16 x i8> %167, <16 x i8> %116, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %170 = bitcast <16 x i8> %165 to <8 x i16>
  %171 = bitcast <16 x i8> %168 to <8 x i16>
  %172 = shufflevector <8 x i16> %170, <8 x i16> %171, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %173 = shufflevector <8 x i16> %170, <8 x i16> %171, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %174 = bitcast <16 x i8> %166 to <8 x i16>
  %175 = bitcast <16 x i8> %169 to <8 x i16>
  %176 = shufflevector <8 x i16> %174, <8 x i16> %175, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %177 = shufflevector <8 x i16> %174, <8 x i16> %175, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %178 = bitcast <8 x i16> %172 to <4 x i32>
  %179 = extractelement <4 x i32> %178, i32 0
  store i32 %179, i32* %23, align 1
  %180 = bitcast <8 x i16> %172 to <16 x i8>
  %181 = shufflevector <16 x i8> %180, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %182 = bitcast <16 x i8> %181 to <4 x i32>
  %183 = extractelement <4 x i32> %182, i32 0
  store i32 %183, i32* %46, align 1
  %184 = shufflevector <16 x i8> %181, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %185 = getelementptr inbounds i8, i8* %45, i64 %44
  %186 = bitcast <16 x i8> %184 to <4 x i32>
  %187 = extractelement <4 x i32> %186, i32 0
  %188 = bitcast i8* %185 to i32*
  store i32 %187, i32* %188, align 1
  %189 = shufflevector <16 x i8> %184, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %190 = getelementptr inbounds i8, i8* %185, i64 %44
  %191 = bitcast <16 x i8> %189 to <4 x i32>
  %192 = extractelement <4 x i32> %191, i32 0
  %193 = bitcast i8* %190 to i32*
  store i32 %192, i32* %193, align 1
  %194 = bitcast <8 x i16> %173 to <4 x i32>
  %195 = extractelement <4 x i32> %194, i32 0
  store i32 %195, i32* %21, align 1
  %196 = bitcast <8 x i16> %173 to <16 x i8>
  %197 = shufflevector <16 x i8> %196, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %198 = getelementptr inbounds i8, i8* %20, i64 %44
  %199 = bitcast <16 x i8> %197 to <4 x i32>
  %200 = extractelement <4 x i32> %199, i32 0
  %201 = bitcast i8* %198 to i32*
  store i32 %200, i32* %201, align 1
  %202 = shufflevector <16 x i8> %197, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %203 = getelementptr inbounds i8, i8* %198, i64 %44
  %204 = bitcast <16 x i8> %202 to <4 x i32>
  %205 = extractelement <4 x i32> %204, i32 0
  %206 = bitcast i8* %203 to i32*
  store i32 %205, i32* %206, align 1
  %207 = shufflevector <16 x i8> %202, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %208 = getelementptr inbounds i8, i8* %203, i64 %44
  %209 = bitcast <16 x i8> %207 to <4 x i32>
  %210 = extractelement <4 x i32> %209, i32 0
  %211 = bitcast i8* %208 to i32*
  store i32 %210, i32* %211, align 1
  %212 = bitcast <8 x i16> %176 to <4 x i32>
  %213 = extractelement <4 x i32> %212, i32 0
  store i32 %213, i32* %75, align 1
  %214 = bitcast <8 x i16> %176 to <16 x i8>
  %215 = shufflevector <16 x i8> %214, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %216 = bitcast <16 x i8> %215 to <4 x i32>
  %217 = extractelement <4 x i32> %216, i32 0
  store i32 %217, i32* %91, align 1
  %218 = shufflevector <16 x i8> %215, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %219 = getelementptr inbounds i8, i8* %90, i64 %44
  %220 = bitcast <16 x i8> %218 to <4 x i32>
  %221 = extractelement <4 x i32> %220, i32 0
  %222 = bitcast i8* %219 to i32*
  store i32 %221, i32* %222, align 1
  %223 = shufflevector <16 x i8> %218, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %224 = getelementptr inbounds i8, i8* %219, i64 %44
  %225 = bitcast <16 x i8> %223 to <4 x i32>
  %226 = extractelement <4 x i32> %225, i32 0
  %227 = bitcast i8* %224 to i32*
  store i32 %226, i32* %227, align 1
  %228 = bitcast <8 x i16> %177 to <4 x i32>
  %229 = extractelement <4 x i32> %228, i32 0
  store i32 %229, i32* %73, align 1
  %230 = bitcast <8 x i16> %177 to <16 x i8>
  %231 = shufflevector <16 x i8> %230, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %232 = getelementptr inbounds i8, i8* %72, i64 %44
  %233 = bitcast <16 x i8> %231 to <4 x i32>
  %234 = extractelement <4 x i32> %233, i32 0
  %235 = bitcast i8* %232 to i32*
  store i32 %234, i32* %235, align 1
  %236 = shufflevector <16 x i8> %231, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %237 = getelementptr inbounds i8, i8* %232, i64 %44
  %238 = bitcast <16 x i8> %236 to <4 x i32>
  %239 = extractelement <4 x i32> %238, i32 0
  %240 = bitcast i8* %237 to i32*
  store i32 %239, i32* %240, align 1
  %241 = shufflevector <16 x i8> %236, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %242 = getelementptr inbounds i8, i8* %237, i64 %44
  %243 = bitcast <16 x i8> %241 to <4 x i32>
  %244 = extractelement <4 x i32> %243, i32 0
  %245 = bitcast i8* %242 to i32*
  store i32 %244, i32* %245, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @SimpleVFilter16i_SSE2(i8* nocapture, i32, i32) #2 {
  %4 = shl nsw i32 %1, 2
  %5 = sext i32 %4 to i64
  %6 = mul nsw i32 %1, -2
  %7 = sext i32 %6 to i64
  %8 = sub nsw i32 0, %1
  %9 = sext i32 %8 to i64
  %10 = sext i32 %1 to i64
  %11 = trunc i32 %2 to i8
  %12 = insertelement <16 x i8> undef, i8 %11, i32 0
  %13 = shufflevector <16 x i8> %12, <16 x i8> undef, <16 x i32> zeroinitializer
  %14 = getelementptr inbounds i8, i8* %0, i64 %5
  %15 = getelementptr inbounds i8, i8* %14, i64 %7
  %16 = bitcast i8* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 1
  %18 = getelementptr inbounds i8, i8* %14, i64 %9
  %19 = bitcast i8* %18 to <2 x i64>*
  %20 = bitcast i8* %18 to <16 x i8>*
  %21 = load <16 x i8>, <16 x i8>* %20, align 1
  %22 = bitcast i8* %14 to <2 x i64>*
  %23 = bitcast i8* %14 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 1
  %25 = getelementptr inbounds i8, i8* %14, i64 %10
  %26 = bitcast i8* %25 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 1
  %28 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %27, <16 x i8> %17) #8
  %29 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %17, <16 x i8> %27) #8
  %30 = or <16 x i8> %29, %28
  %31 = bitcast <16 x i8> %30 to <8 x i16>
  %32 = lshr <8 x i16> %31, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %33 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %24, <16 x i8> %21) #8
  %34 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %21, <16 x i8> %24) #8
  %35 = or <16 x i8> %34, %33
  %36 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %35, <16 x i8> %35) #8
  %37 = bitcast <8 x i16> %32 to <16 x i8>
  %38 = and <16 x i8> %37, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %39 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> %38) #8
  %40 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %39, <16 x i8> %13) #8
  %41 = icmp eq <16 x i8> %40, zeroinitializer
  %42 = xor <16 x i8> %17, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %43 = xor <16 x i8> %27, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %44 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %42, <16 x i8> %43) #8
  %45 = xor <16 x i8> %24, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %46 = xor <16 x i8> %21, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %47 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %45, <16 x i8> %46) #8
  %48 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %44, <16 x i8> %47) #8
  %49 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %47, <16 x i8> %48) #8
  %50 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %47, <16 x i8> %49) #8
  %51 = select <16 x i1> %41, <16 x i8> %50, <16 x i8> zeroinitializer
  %52 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %51, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %53 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %51, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %54 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %53, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %53, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = bitcast <16 x i8> %54 to <8 x i16>
  %57 = ashr <8 x i16> %56, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %58 = bitcast <16 x i8> %55 to <8 x i16>
  %59 = ashr <8 x i16> %58, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %60 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %57, <8 x i16> %59) #8
  %61 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %52, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %62 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %52, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %63 = bitcast <16 x i8> %61 to <8 x i16>
  %64 = ashr <8 x i16> %63, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %65 = bitcast <16 x i8> %62 to <8 x i16>
  %66 = ashr <8 x i16> %65, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %64, <8 x i16> %66) #8
  %68 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %45, <16 x i8> %60) #8
  %69 = bitcast <16 x i8> %68 to <2 x i64>
  %70 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %46, <16 x i8> %67) #8
  %71 = bitcast <16 x i8> %70 to <2 x i64>
  %72 = xor <2 x i64> %71, <i64 -9187201950435737472, i64 -9187201950435737472>
  %73 = xor <2 x i64> %69, <i64 -9187201950435737472, i64 -9187201950435737472>
  store <2 x i64> %72, <2 x i64>* %19, align 1
  store <2 x i64> %73, <2 x i64>* %22, align 1
  %74 = getelementptr inbounds i8, i8* %14, i64 %5
  %75 = getelementptr inbounds i8, i8* %74, i64 %7
  %76 = bitcast i8* %75 to <16 x i8>*
  %77 = load <16 x i8>, <16 x i8>* %76, align 1
  %78 = getelementptr inbounds i8, i8* %74, i64 %9
  %79 = bitcast i8* %78 to <2 x i64>*
  %80 = bitcast i8* %78 to <16 x i8>*
  %81 = load <16 x i8>, <16 x i8>* %80, align 1
  %82 = bitcast i8* %74 to <2 x i64>*
  %83 = bitcast i8* %74 to <16 x i8>*
  %84 = load <16 x i8>, <16 x i8>* %83, align 1
  %85 = getelementptr inbounds i8, i8* %74, i64 %10
  %86 = bitcast i8* %85 to <16 x i8>*
  %87 = load <16 x i8>, <16 x i8>* %86, align 1
  %88 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %87, <16 x i8> %77) #8
  %89 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %77, <16 x i8> %87) #8
  %90 = or <16 x i8> %89, %88
  %91 = bitcast <16 x i8> %90 to <8 x i16>
  %92 = lshr <8 x i16> %91, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %93 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %84, <16 x i8> %81) #8
  %94 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %81, <16 x i8> %84) #8
  %95 = or <16 x i8> %94, %93
  %96 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %95, <16 x i8> %95) #8
  %97 = bitcast <8 x i16> %92 to <16 x i8>
  %98 = and <16 x i8> %97, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %99 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %96, <16 x i8> %98) #8
  %100 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %99, <16 x i8> %13) #8
  %101 = icmp eq <16 x i8> %100, zeroinitializer
  %102 = xor <16 x i8> %77, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %103 = xor <16 x i8> %87, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %104 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %102, <16 x i8> %103) #8
  %105 = xor <16 x i8> %84, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %106 = xor <16 x i8> %81, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %107 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %105, <16 x i8> %106) #8
  %108 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %104, <16 x i8> %107) #8
  %109 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %107, <16 x i8> %108) #8
  %110 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %107, <16 x i8> %109) #8
  %111 = select <16 x i1> %101, <16 x i8> %110, <16 x i8> zeroinitializer
  %112 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %111, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %113 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %111, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %114 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %113, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %115 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %113, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %116 = bitcast <16 x i8> %114 to <8 x i16>
  %117 = ashr <8 x i16> %116, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %118 = bitcast <16 x i8> %115 to <8 x i16>
  %119 = ashr <8 x i16> %118, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %120 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %117, <8 x i16> %119) #8
  %121 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %112, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %122 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %112, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %123 = bitcast <16 x i8> %121 to <8 x i16>
  %124 = ashr <8 x i16> %123, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %125 = bitcast <16 x i8> %122 to <8 x i16>
  %126 = ashr <8 x i16> %125, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %127 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %124, <8 x i16> %126) #8
  %128 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %105, <16 x i8> %120) #8
  %129 = bitcast <16 x i8> %128 to <2 x i64>
  %130 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %106, <16 x i8> %127) #8
  %131 = bitcast <16 x i8> %130 to <2 x i64>
  %132 = xor <2 x i64> %131, <i64 -9187201950435737472, i64 -9187201950435737472>
  %133 = xor <2 x i64> %129, <i64 -9187201950435737472, i64 -9187201950435737472>
  store <2 x i64> %132, <2 x i64>* %79, align 1
  store <2 x i64> %133, <2 x i64>* %82, align 1
  %134 = getelementptr inbounds i8, i8* %74, i64 %5
  %135 = getelementptr inbounds i8, i8* %134, i64 %7
  %136 = bitcast i8* %135 to <16 x i8>*
  %137 = load <16 x i8>, <16 x i8>* %136, align 1
  %138 = getelementptr inbounds i8, i8* %134, i64 %9
  %139 = bitcast i8* %138 to <2 x i64>*
  %140 = bitcast i8* %138 to <16 x i8>*
  %141 = load <16 x i8>, <16 x i8>* %140, align 1
  %142 = bitcast i8* %134 to <2 x i64>*
  %143 = bitcast i8* %134 to <16 x i8>*
  %144 = load <16 x i8>, <16 x i8>* %143, align 1
  %145 = getelementptr inbounds i8, i8* %134, i64 %10
  %146 = bitcast i8* %145 to <16 x i8>*
  %147 = load <16 x i8>, <16 x i8>* %146, align 1
  %148 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %147, <16 x i8> %137) #8
  %149 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %137, <16 x i8> %147) #8
  %150 = or <16 x i8> %149, %148
  %151 = bitcast <16 x i8> %150 to <8 x i16>
  %152 = lshr <8 x i16> %151, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %153 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %144, <16 x i8> %141) #8
  %154 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %141, <16 x i8> %144) #8
  %155 = or <16 x i8> %154, %153
  %156 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %155, <16 x i8> %155) #8
  %157 = bitcast <8 x i16> %152 to <16 x i8>
  %158 = and <16 x i8> %157, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %159 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %156, <16 x i8> %158) #8
  %160 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %159, <16 x i8> %13) #8
  %161 = icmp eq <16 x i8> %160, zeroinitializer
  %162 = xor <16 x i8> %137, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %163 = xor <16 x i8> %147, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %164 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %162, <16 x i8> %163) #8
  %165 = xor <16 x i8> %144, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %166 = xor <16 x i8> %141, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %167 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %165, <16 x i8> %166) #8
  %168 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %164, <16 x i8> %167) #8
  %169 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %167, <16 x i8> %168) #8
  %170 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %167, <16 x i8> %169) #8
  %171 = select <16 x i1> %161, <16 x i8> %170, <16 x i8> zeroinitializer
  %172 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %171, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #8
  %173 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %171, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #8
  %174 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %173, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %175 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %173, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %176 = bitcast <16 x i8> %174 to <8 x i16>
  %177 = ashr <8 x i16> %176, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %178 = bitcast <16 x i8> %175 to <8 x i16>
  %179 = ashr <8 x i16> %178, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %180 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %177, <8 x i16> %179) #8
  %181 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %172, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %182 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %172, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %183 = bitcast <16 x i8> %181 to <8 x i16>
  %184 = ashr <8 x i16> %183, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %185 = bitcast <16 x i8> %182 to <8 x i16>
  %186 = ashr <8 x i16> %185, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %187 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %184, <8 x i16> %186) #8
  %188 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %165, <16 x i8> %180) #8
  %189 = bitcast <16 x i8> %188 to <2 x i64>
  %190 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %166, <16 x i8> %187) #8
  %191 = bitcast <16 x i8> %190 to <2 x i64>
  %192 = xor <2 x i64> %191, <i64 -9187201950435737472, i64 -9187201950435737472>
  %193 = xor <2 x i64> %189, <i64 -9187201950435737472, i64 -9187201950435737472>
  store <2 x i64> %192, <2 x i64>* %139, align 1
  store <2 x i64> %193, <2 x i64>* %142, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @SimpleHFilter16i_SSE2(i8* nocapture, i32, i32) #3 {
  %4 = getelementptr inbounds i8, i8* %0, i64 4
  tail call void @SimpleHFilter16_SSE2(i8* %4, i32 %1, i32 %2)
  %5 = getelementptr inbounds i8, i8* %0, i64 8
  tail call void @SimpleHFilter16_SSE2(i8* %5, i32 %1, i32 %2)
  %6 = getelementptr inbounds i8, i8* %0, i64 12
  tail call void @SimpleHFilter16_SSE2(i8* %6, i32 %1, i32 %2)
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @TM4_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to i32*
  %4 = load i32, i32* %3, align 1
  %5 = insertelement <4 x i32> undef, i32 %4, i32 0
  %6 = bitcast <4 x i32> %5 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %8 = getelementptr inbounds i8, i8* %0, i64 -33
  %9 = bitcast <16 x i8> %7 to <8 x i16>
  %10 = getelementptr inbounds i8, i8* %0, i64 -1
  %11 = load i8, i8* %10, align 1
  %12 = zext i8 %11 to i16
  %13 = load i8, i8* %8, align 1
  %14 = zext i8 %13 to i16
  %15 = sub nsw i16 %12, %14
  %16 = insertelement <8 x i16> undef, i16 %15, i32 0
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %18 = add <8 x i16> %17, %9
  %19 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %18, <8 x i16> undef) #8
  %20 = bitcast <16 x i8> %19 to <4 x i32>
  %21 = extractelement <4 x i32> %20, i32 0
  %22 = bitcast i8* %0 to i32*
  store i32 %21, i32* %22, align 1
  %23 = getelementptr inbounds i8, i8* %0, i64 32
  %24 = getelementptr inbounds i8, i8* %0, i64 31
  %25 = load i8, i8* %24, align 1
  %26 = zext i8 %25 to i16
  %27 = sub nsw i16 %26, %14
  %28 = insertelement <8 x i16> undef, i16 %27, i32 0
  %29 = shufflevector <8 x i16> %28, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %30 = add <8 x i16> %29, %9
  %31 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> undef) #8
  %32 = bitcast <16 x i8> %31 to <4 x i32>
  %33 = extractelement <4 x i32> %32, i32 0
  %34 = bitcast i8* %23 to i32*
  store i32 %33, i32* %34, align 1
  %35 = getelementptr inbounds i8, i8* %0, i64 64
  %36 = getelementptr inbounds i8, i8* %0, i64 63
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i16
  %39 = sub nsw i16 %38, %14
  %40 = insertelement <8 x i16> undef, i16 %39, i32 0
  %41 = shufflevector <8 x i16> %40, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %42 = add <8 x i16> %41, %9
  %43 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %42, <8 x i16> undef) #8
  %44 = bitcast <16 x i8> %43 to <4 x i32>
  %45 = extractelement <4 x i32> %44, i32 0
  %46 = bitcast i8* %35 to i32*
  store i32 %45, i32* %46, align 1
  %47 = getelementptr inbounds i8, i8* %0, i64 96
  %48 = getelementptr inbounds i8, i8* %0, i64 95
  %49 = load i8, i8* %48, align 1
  %50 = zext i8 %49 to i16
  %51 = sub nsw i16 %50, %14
  %52 = insertelement <8 x i16> undef, i16 %51, i32 0
  %53 = shufflevector <8 x i16> %52, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %54 = add <8 x i16> %53, %9
  %55 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> undef) #8
  %56 = bitcast <16 x i8> %55 to <4 x i32>
  %57 = extractelement <4 x i32> %56, i32 0
  %58 = bitcast i8* %47 to i32*
  store i32 %57, i32* %58, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @VE4_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -33
  %3 = bitcast i8* %2 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %8 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %9 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %6, <16 x i8> %8) #8
  %10 = xor <16 x i8> %8, %6
  %11 = and <16 x i8> %10, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %12 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %9, <16 x i8> %11) #8
  %13 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %12, <16 x i8> %7) #8
  %14 = bitcast <16 x i8> %13 to <4 x i32>
  %15 = extractelement <4 x i32> %14, i32 0
  %16 = bitcast i8* %0 to i32*
  store i32 %15, i32* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 32
  %18 = bitcast i8* %17 to i32*
  store i32 %15, i32* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 64
  %20 = bitcast i8* %19 to i32*
  store i32 %15, i32* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 96
  %22 = bitcast i8* %21 to i32*
  store i32 %15, i32* %22, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @RD4_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -33
  %3 = bitcast i8* %2 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %6, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8 = getelementptr inbounds i8, i8* %0, i64 -1
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = getelementptr inbounds i8, i8* %0, i64 31
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = getelementptr inbounds i8, i8* %0, i64 63
  %15 = load i8, i8* %14, align 1
  %16 = zext i8 %15 to i32
  %17 = getelementptr inbounds i8, i8* %0, i64 95
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = shl nuw nsw i32 %16, 8
  %21 = shl nuw nsw i32 %13, 16
  %22 = shl nuw i32 %10, 24
  %23 = or i32 %21, %22
  %24 = or i32 %23, %19
  %25 = or i32 %24, %20
  %26 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %25, i32 0
  %27 = bitcast <4 x i32> %26 to <16 x i8>
  %28 = or <16 x i8> %7, %27
  %29 = shufflevector <16 x i8> %28, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %30 = shufflevector <16 x i8> %28, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %31 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %30, <16 x i8> %28) #8
  %32 = xor <16 x i8> %30, %28
  %33 = and <16 x i8> %32, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %34 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %31, <16 x i8> %33) #8
  %35 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %34, <16 x i8> %29) #8
  %36 = getelementptr inbounds i8, i8* %0, i64 96
  %37 = bitcast <16 x i8> %35 to <4 x i32>
  %38 = extractelement <4 x i32> %37, i32 0
  %39 = bitcast i8* %36 to i32*
  store i32 %38, i32* %39, align 1
  %40 = getelementptr inbounds i8, i8* %0, i64 64
  %41 = shufflevector <16 x i8> %35, <16 x i8> undef, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %42 = bitcast <16 x i8> %41 to <4 x i32>
  %43 = extractelement <4 x i32> %42, i32 0
  %44 = bitcast i8* %40 to i32*
  store i32 %43, i32* %44, align 1
  %45 = getelementptr inbounds i8, i8* %0, i64 32
  %46 = shufflevector <16 x i8> %35, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %47 = bitcast <16 x i8> %46 to <4 x i32>
  %48 = extractelement <4 x i32> %47, i32 0
  %49 = bitcast i8* %45 to i32*
  store i32 %48, i32* %49, align 1
  %50 = shufflevector <16 x i8> %35, <16 x i8> undef, <16 x i32> <i32 3, i32 4, i32 5, i32 6, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %51 = bitcast <16 x i8> %50 to <4 x i32>
  %52 = extractelement <4 x i32> %51, i32 0
  %53 = bitcast i8* %0 to i32*
  store i32 %52, i32* %53, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @VR4_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -1
  %3 = load i8, i8* %2, align 1
  %4 = zext i8 %3 to i32
  %5 = getelementptr inbounds i8, i8* %0, i64 31
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = getelementptr inbounds i8, i8* %0, i64 63
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = getelementptr inbounds i8, i8* %0, i64 -33
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = bitcast i8* %11 to i64*
  %15 = load i64, i64* %14, align 1
  %16 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %15, i32 0
  %17 = bitcast <2 x i64> %16 to <16 x i8>
  %18 = shufflevector <16 x i8> %17, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %19 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %17, <16 x i8> %18) #8
  %20 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14>
  %21 = bitcast <16 x i8> %20 to <8 x i16>
  %22 = shl nuw nsw i32 %13, 8
  %23 = or i32 %22, %4
  %24 = trunc i32 %23 to i16
  %25 = insertelement <8 x i16> %21, i16 %24, i64 0
  %26 = bitcast <8 x i16> %25 to <16 x i8>
  %27 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %26, <16 x i8> %18) #8
  %28 = xor <16 x i8> %18, %26
  %29 = and <16 x i8> %28, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %30 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %27, <16 x i8> %29) #8
  %31 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %30, <16 x i8> %17) #8
  %32 = bitcast <16 x i8> %19 to <4 x i32>
  %33 = extractelement <4 x i32> %32, i32 0
  %34 = bitcast i8* %0 to i32*
  store i32 %33, i32* %34, align 1
  %35 = getelementptr inbounds i8, i8* %0, i64 32
  %36 = bitcast <16 x i8> %31 to <4 x i32>
  %37 = extractelement <4 x i32> %36, i32 0
  %38 = bitcast i8* %35 to i32*
  store i32 %37, i32* %38, align 1
  %39 = getelementptr inbounds i8, i8* %0, i64 64
  %40 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0>, <16 x i8> %19, <16 x i32> <i32 15, i32 16, i32 17, i32 18, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %41 = bitcast <16 x i8> %40 to <4 x i32>
  %42 = extractelement <4 x i32> %41, i32 0
  %43 = bitcast i8* %39 to i32*
  store i32 %42, i32* %43, align 1
  %44 = getelementptr inbounds i8, i8* %0, i64 96
  %45 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0>, <16 x i8> %31, <16 x i32> <i32 15, i32 16, i32 17, i32 18, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %46 = bitcast <16 x i8> %45 to <4 x i32>
  %47 = extractelement <4 x i32> %46, i32 0
  %48 = bitcast i8* %44 to i32*
  store i32 %47, i32* %48, align 1
  %49 = shl nuw nsw i32 %4, 1
  %50 = add nuw nsw i32 %7, 2
  %51 = add nuw nsw i32 %50, %49
  %52 = add nuw nsw i32 %51, %13
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i8
  store i8 %54, i8* %39, align 1
  %55 = shl nuw nsw i32 %7, 1
  %56 = add nuw nsw i32 %4, 2
  %57 = add nuw nsw i32 %56, %10
  %58 = add nuw nsw i32 %57, %55
  %59 = lshr i32 %58, 2
  %60 = trunc i32 %59 to i8
  store i8 %60, i8* %44, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @LD4_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %8 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %9 = bitcast <16 x i8> %8 to <8 x i16>
  %10 = getelementptr inbounds i8, i8* %0, i64 -25
  %11 = load i8, i8* %10, align 1
  %12 = zext i8 %11 to i16
  %13 = insertelement <8 x i16> %9, i16 %12, i64 3
  %14 = bitcast <8 x i16> %13 to <2 x i64>
  %15 = bitcast <8 x i16> %13 to <16 x i8>
  %16 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %6, <16 x i8> %15) #8
  %17 = xor <2 x i64> %5, %14
  %18 = bitcast <2 x i64> %17 to <16 x i8>
  %19 = and <16 x i8> %18, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %20 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %16, <16 x i8> %19) #8
  %21 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %20, <16 x i8> %7) #8
  %22 = bitcast <16 x i8> %21 to <4 x i32>
  %23 = extractelement <4 x i32> %22, i32 0
  %24 = bitcast i8* %0 to i32*
  store i32 %23, i32* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 32
  %26 = shufflevector <16 x i8> %21, <16 x i8> undef, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %27 = bitcast <16 x i8> %26 to <4 x i32>
  %28 = extractelement <4 x i32> %27, i32 0
  %29 = bitcast i8* %25 to i32*
  store i32 %28, i32* %29, align 1
  %30 = getelementptr inbounds i8, i8* %0, i64 64
  %31 = shufflevector <16 x i8> %21, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %32 = bitcast <16 x i8> %31 to <4 x i32>
  %33 = extractelement <4 x i32> %32, i32 0
  %34 = bitcast i8* %30 to i32*
  store i32 %33, i32* %34, align 1
  %35 = getelementptr inbounds i8, i8* %0, i64 96
  %36 = shufflevector <16 x i8> %21, <16 x i8> undef, <16 x i32> <i32 3, i32 4, i32 5, i32 6, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %37 = bitcast <16 x i8> %36 to <4 x i32>
  %38 = extractelement <4 x i32> %37, i32 0
  %39 = bitcast i8* %35 to i32*
  store i32 %38, i32* %39, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @VL4_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %8 = bitcast <16 x i8> %7 to <2 x i64>
  %9 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %10 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %6, <16 x i8> %7) #8
  %11 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %9, <16 x i8> %7) #8
  %12 = tail call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %10, <16 x i8> %11) #8
  %13 = xor <16 x i8> %11, %10
  %14 = bitcast <16 x i8> %13 to <2 x i64>
  %15 = and <2 x i64> %14, <i64 72340172838076673, i64 72340172838076673>
  %16 = xor <2 x i64> %5, %8
  %17 = xor <16 x i8> %7, %9
  %18 = bitcast <16 x i8> %17 to <2 x i64>
  %19 = or <2 x i64> %16, %18
  %20 = and <2 x i64> %15, %19
  %21 = bitcast <2 x i64> %20 to <16 x i8>
  %22 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %12, <16 x i8> %21) #8
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %24 = bitcast <16 x i8> %23 to <4 x i32>
  %25 = extractelement <4 x i32> %24, i32 0
  %26 = bitcast <16 x i8> %10 to <4 x i32>
  %27 = extractelement <4 x i32> %26, i32 0
  %28 = bitcast i8* %0 to i32*
  store i32 %27, i32* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 32
  %30 = bitcast <16 x i8> %22 to <4 x i32>
  %31 = extractelement <4 x i32> %30, i32 0
  %32 = bitcast i8* %29 to i32*
  store i32 %31, i32* %32, align 1
  %33 = getelementptr inbounds i8, i8* %0, i64 64
  %34 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %35 = bitcast <16 x i8> %34 to <4 x i32>
  %36 = extractelement <4 x i32> %35, i32 0
  %37 = bitcast i8* %33 to i32*
  store i32 %36, i32* %37, align 1
  %38 = getelementptr inbounds i8, i8* %0, i64 96
  %39 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i8* %38 to i32*
  store i32 %41, i32* %42, align 1
  %43 = trunc i32 %25 to i8
  %44 = getelementptr inbounds i8, i8* %0, i64 67
  store i8 %43, i8* %44, align 1
  %45 = lshr i32 %25, 8
  %46 = trunc i32 %45 to i8
  %47 = getelementptr inbounds i8, i8* %0, i64 99
  store i8 %46, i8* %47, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @DC16_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 1
  %5 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %4, <16 x i8> zeroinitializer) #8
  %6 = bitcast <2 x i64> %5 to <4 x i32>
  %7 = shufflevector <4 x i32> %6, <4 x i32> undef, <4 x i32> <i32 2, i32 undef, i32 undef, i32 undef>
  %8 = bitcast <4 x i32> %7 to <8 x i16>
  %9 = getelementptr inbounds i8, i8* %0, i64 -1
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = getelementptr inbounds i8, i8* %0, i64 31
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = add nuw nsw i32 %11, %14
  %16 = getelementptr inbounds i8, i8* %0, i64 63
  %17 = load i8, i8* %16, align 1
  %18 = zext i8 %17 to i32
  %19 = add nuw nsw i32 %15, %18
  %20 = getelementptr inbounds i8, i8* %0, i64 95
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = add nuw nsw i32 %19, %22
  %24 = getelementptr inbounds i8, i8* %0, i64 127
  %25 = load i8, i8* %24, align 1
  %26 = zext i8 %25 to i32
  %27 = add nuw nsw i32 %23, %26
  %28 = getelementptr inbounds i8, i8* %0, i64 159
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = add nuw nsw i32 %27, %30
  %32 = getelementptr inbounds i8, i8* %0, i64 191
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = add nuw nsw i32 %31, %34
  %36 = getelementptr inbounds i8, i8* %0, i64 223
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = add nuw nsw i32 %35, %38
  %40 = getelementptr inbounds i8, i8* %0, i64 255
  %41 = load i8, i8* %40, align 1
  %42 = zext i8 %41 to i32
  %43 = add nuw nsw i32 %39, %42
  %44 = getelementptr inbounds i8, i8* %0, i64 287
  %45 = load i8, i8* %44, align 1
  %46 = zext i8 %45 to i32
  %47 = add nuw nsw i32 %43, %46
  %48 = getelementptr inbounds i8, i8* %0, i64 319
  %49 = load i8, i8* %48, align 1
  %50 = zext i8 %49 to i32
  %51 = add nuw nsw i32 %47, %50
  %52 = getelementptr inbounds i8, i8* %0, i64 351
  %53 = load i8, i8* %52, align 1
  %54 = zext i8 %53 to i32
  %55 = add nuw nsw i32 %51, %54
  %56 = getelementptr inbounds i8, i8* %0, i64 383
  %57 = load i8, i8* %56, align 1
  %58 = zext i8 %57 to i32
  %59 = add nuw nsw i32 %55, %58
  %60 = getelementptr inbounds i8, i8* %0, i64 415
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i32
  %63 = add nuw nsw i32 %59, %62
  %64 = getelementptr inbounds i8, i8* %0, i64 447
  %65 = load i8, i8* %64, align 1
  %66 = zext i8 %65 to i32
  %67 = add nuw nsw i32 %63, %66
  %68 = getelementptr inbounds i8, i8* %0, i64 479
  %69 = load i8, i8* %68, align 1
  %70 = zext i8 %69 to i32
  %71 = add nuw nsw i32 %67, %70
  %72 = bitcast <2 x i64> %5 to <8 x i16>
  %73 = add <8 x i16> %8, %72
  %74 = bitcast <8 x i16> %73 to <4 x i32>
  %75 = extractelement <4 x i32> %74, i32 0
  %76 = add i32 %75, 16
  %77 = add i32 %76, %71
  %78 = lshr i32 %77, 5
  %79 = trunc i32 %78 to i8
  %80 = insertelement <16 x i8> undef, i8 %79, i32 0
  %81 = shufflevector <16 x i8> %80, <16 x i8> undef, <16 x i32> zeroinitializer
  %82 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %0, i64 32
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %0, i64 64
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %0, i64 96
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %0, i64 128
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %0, i64 160
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %0, i64 192
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %0, i64 224
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %0, i64 256
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %0, i64 288
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %0, i64 320
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %0, i64 352
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %0, i64 384
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %0, i64 416
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %0, i64 448
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %0, i64 480
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %81, <16 x i8>* %112, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @TM16_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 1
  %5 = shufflevector <16 x i8> %4, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6 = shufflevector <16 x i8> %4, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7 = getelementptr inbounds i8, i8* %0, i64 -33
  %8 = bitcast <16 x i8> %5 to <8 x i16>
  %9 = bitcast <16 x i8> %6 to <8 x i16>
  br label %10

10:                                               ; preds = %10, %1
  %11 = phi i8* [ %0, %1 ], [ %39, %10 ]
  %12 = phi i32 [ 0, %1 ], [ %38, %10 ]
  %13 = getelementptr inbounds i8, i8* %11, i64 -1
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i16
  %16 = load i8, i8* %7, align 1
  %17 = zext i8 %16 to i16
  %18 = sub nsw i16 %15, %17
  %19 = insertelement <8 x i16> undef, i16 %18, i32 0
  %20 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> zeroinitializer
  %21 = add <8 x i16> %20, %8
  %22 = add <8 x i16> %20, %9
  %23 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %21, <8 x i16> %22) #8
  %24 = bitcast i8* %11 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %11, i64 32
  %26 = getelementptr inbounds i8, i8* %11, i64 31
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i16
  %29 = load i8, i8* %7, align 1
  %30 = zext i8 %29 to i16
  %31 = sub nsw i16 %28, %30
  %32 = insertelement <8 x i16> undef, i16 %31, i32 0
  %33 = shufflevector <8 x i16> %32, <8 x i16> undef, <8 x i32> zeroinitializer
  %34 = add <8 x i16> %33, %8
  %35 = add <8 x i16> %33, %9
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> %35) #8
  %37 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %36, <16 x i8>* %37, align 1
  %38 = add nuw nsw i32 %12, 2
  %39 = getelementptr inbounds i8, i8* %11, i64 64
  %40 = icmp eq i32 %38, 16
  br i1 %40, label %41, label %10

41:                                               ; preds = %10
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @VE16_SSE2(i8* nocapture) #4 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to <2 x i64>*
  %4 = load <2 x i64>, <2 x i64>* %3, align 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %5, align 1
  %6 = getelementptr inbounds i8, i8* %0, i64 32
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %7, align 1
  %8 = getelementptr inbounds i8, i8* %0, i64 64
  %9 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %9, align 1
  %10 = getelementptr inbounds i8, i8* %0, i64 96
  %11 = bitcast i8* %10 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %11, align 1
  %12 = getelementptr inbounds i8, i8* %0, i64 128
  %13 = bitcast i8* %12 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %13, align 1
  %14 = getelementptr inbounds i8, i8* %0, i64 160
  %15 = bitcast i8* %14 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 192
  %17 = bitcast i8* %16 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 224
  %19 = bitcast i8* %18 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %0, i64 256
  %21 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %0, i64 288
  %23 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %0, i64 320
  %25 = bitcast i8* %24 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %0, i64 352
  %27 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 384
  %29 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %0, i64 416
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %0, i64 448
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %0, i64 480
  %35 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %4, <2 x i64>* %35, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @HE16_SSE2(i8* nocapture) #4 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -1
  %3 = load i8, i8* %2, align 1
  %4 = insertelement <16 x i8> undef, i8 %3, i32 0
  %5 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> zeroinitializer
  %6 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %5, <16 x i8>* %6, align 1
  %7 = getelementptr inbounds i8, i8* %0, i64 32
  %8 = getelementptr inbounds i8, i8* %0, i64 31
  %9 = load i8, i8* %8, align 1
  %10 = insertelement <16 x i8> undef, i8 %9, i32 0
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <16 x i32> zeroinitializer
  %12 = bitcast i8* %7 to <16 x i8>*
  store <16 x i8> %11, <16 x i8>* %12, align 1
  %13 = getelementptr inbounds i8, i8* %0, i64 64
  %14 = getelementptr inbounds i8, i8* %0, i64 63
  %15 = load i8, i8* %14, align 1
  %16 = insertelement <16 x i8> undef, i8 %15, i32 0
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %13 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 96
  %20 = getelementptr inbounds i8, i8* %0, i64 95
  %21 = load i8, i8* %20, align 1
  %22 = insertelement <16 x i8> undef, i8 %21, i32 0
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  %24 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 128
  %26 = getelementptr inbounds i8, i8* %0, i64 127
  %27 = load i8, i8* %26, align 1
  %28 = insertelement <16 x i8> undef, i8 %27, i32 0
  %29 = shufflevector <16 x i8> %28, <16 x i8> undef, <16 x i32> zeroinitializer
  %30 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %29, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 160
  %32 = getelementptr inbounds i8, i8* %0, i64 159
  %33 = load i8, i8* %32, align 1
  %34 = insertelement <16 x i8> undef, i8 %33, i32 0
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  %36 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 192
  %38 = getelementptr inbounds i8, i8* %0, i64 191
  %39 = load i8, i8* %38, align 1
  %40 = insertelement <16 x i8> undef, i8 %39, i32 0
  %41 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> zeroinitializer
  %42 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %41, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %0, i64 224
  %44 = getelementptr inbounds i8, i8* %0, i64 223
  %45 = load i8, i8* %44, align 1
  %46 = insertelement <16 x i8> undef, i8 %45, i32 0
  %47 = shufflevector <16 x i8> %46, <16 x i8> undef, <16 x i32> zeroinitializer
  %48 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %0, i64 256
  %50 = getelementptr inbounds i8, i8* %0, i64 255
  %51 = load i8, i8* %50, align 1
  %52 = insertelement <16 x i8> undef, i8 %51, i32 0
  %53 = shufflevector <16 x i8> %52, <16 x i8> undef, <16 x i32> zeroinitializer
  %54 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %0, i64 288
  %56 = getelementptr inbounds i8, i8* %0, i64 287
  %57 = load i8, i8* %56, align 1
  %58 = insertelement <16 x i8> undef, i8 %57, i32 0
  %59 = shufflevector <16 x i8> %58, <16 x i8> undef, <16 x i32> zeroinitializer
  %60 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %59, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %0, i64 320
  %62 = getelementptr inbounds i8, i8* %0, i64 319
  %63 = load i8, i8* %62, align 1
  %64 = insertelement <16 x i8> undef, i8 %63, i32 0
  %65 = shufflevector <16 x i8> %64, <16 x i8> undef, <16 x i32> zeroinitializer
  %66 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %65, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %0, i64 352
  %68 = getelementptr inbounds i8, i8* %0, i64 351
  %69 = load i8, i8* %68, align 1
  %70 = insertelement <16 x i8> undef, i8 %69, i32 0
  %71 = shufflevector <16 x i8> %70, <16 x i8> undef, <16 x i32> zeroinitializer
  %72 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %0, i64 384
  %74 = getelementptr inbounds i8, i8* %0, i64 383
  %75 = load i8, i8* %74, align 1
  %76 = insertelement <16 x i8> undef, i8 %75, i32 0
  %77 = shufflevector <16 x i8> %76, <16 x i8> undef, <16 x i32> zeroinitializer
  %78 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %0, i64 416
  %80 = getelementptr inbounds i8, i8* %0, i64 415
  %81 = load i8, i8* %80, align 1
  %82 = insertelement <16 x i8> undef, i8 %81, i32 0
  %83 = shufflevector <16 x i8> %82, <16 x i8> undef, <16 x i32> zeroinitializer
  %84 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %83, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %0, i64 448
  %86 = getelementptr inbounds i8, i8* %0, i64 447
  %87 = load i8, i8* %86, align 1
  %88 = insertelement <16 x i8> undef, i8 %87, i32 0
  %89 = shufflevector <16 x i8> %88, <16 x i8> undef, <16 x i32> zeroinitializer
  %90 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %89, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %0, i64 480
  %92 = getelementptr inbounds i8, i8* %0, i64 479
  %93 = load i8, i8* %92, align 1
  %94 = insertelement <16 x i8> undef, i8 %93, i32 0
  %95 = shufflevector <16 x i8> %94, <16 x i8> undef, <16 x i32> zeroinitializer
  %96 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %95, <16 x i8>* %96, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @DC16NoTop_SSE2(i8* nocapture) #4 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -1
  %3 = load i8, i8* %2, align 1
  %4 = zext i8 %3 to i32
  %5 = add nuw nsw i32 %4, 8
  %6 = getelementptr inbounds i8, i8* %0, i64 31
  %7 = load i8, i8* %6, align 1
  %8 = zext i8 %7 to i32
  %9 = add nuw nsw i32 %5, %8
  %10 = getelementptr inbounds i8, i8* %0, i64 63
  %11 = load i8, i8* %10, align 1
  %12 = zext i8 %11 to i32
  %13 = add nuw nsw i32 %9, %12
  %14 = getelementptr inbounds i8, i8* %0, i64 95
  %15 = load i8, i8* %14, align 1
  %16 = zext i8 %15 to i32
  %17 = add nuw nsw i32 %13, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 127
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = add nuw nsw i32 %17, %20
  %22 = getelementptr inbounds i8, i8* %0, i64 159
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %21, %24
  %26 = getelementptr inbounds i8, i8* %0, i64 191
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i32
  %29 = add nuw nsw i32 %25, %28
  %30 = getelementptr inbounds i8, i8* %0, i64 223
  %31 = load i8, i8* %30, align 1
  %32 = zext i8 %31 to i32
  %33 = add nuw nsw i32 %29, %32
  %34 = getelementptr inbounds i8, i8* %0, i64 255
  %35 = load i8, i8* %34, align 1
  %36 = zext i8 %35 to i32
  %37 = add nuw nsw i32 %33, %36
  %38 = getelementptr inbounds i8, i8* %0, i64 287
  %39 = load i8, i8* %38, align 1
  %40 = zext i8 %39 to i32
  %41 = add nuw nsw i32 %37, %40
  %42 = getelementptr inbounds i8, i8* %0, i64 319
  %43 = load i8, i8* %42, align 1
  %44 = zext i8 %43 to i32
  %45 = add nuw nsw i32 %41, %44
  %46 = getelementptr inbounds i8, i8* %0, i64 351
  %47 = load i8, i8* %46, align 1
  %48 = zext i8 %47 to i32
  %49 = add nuw nsw i32 %45, %48
  %50 = getelementptr inbounds i8, i8* %0, i64 383
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = add nuw nsw i32 %49, %52
  %54 = getelementptr inbounds i8, i8* %0, i64 415
  %55 = load i8, i8* %54, align 1
  %56 = zext i8 %55 to i32
  %57 = add nuw nsw i32 %53, %56
  %58 = getelementptr inbounds i8, i8* %0, i64 447
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %57, %60
  %62 = getelementptr inbounds i8, i8* %0, i64 479
  %63 = load i8, i8* %62, align 1
  %64 = zext i8 %63 to i32
  %65 = add nuw nsw i32 %61, %64
  %66 = lshr i32 %65, 4
  %67 = trunc i32 %66 to i8
  %68 = insertelement <16 x i8> undef, i8 %67, i32 0
  %69 = shufflevector <16 x i8> %68, <16 x i8> undef, <16 x i32> zeroinitializer
  %70 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %0, i64 32
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %0, i64 64
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %0, i64 96
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %0, i64 128
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %0, i64 160
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %0, i64 192
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %0, i64 224
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %0, i64 256
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %0, i64 288
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %0, i64 320
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %0, i64 352
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %0, i64 384
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %0, i64 416
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %0, i64 448
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %0, i64 480
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %100, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @DC16NoLeft_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 1
  %5 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %4, <16 x i8> zeroinitializer) #8
  %6 = bitcast <2 x i64> %5 to <4 x i32>
  %7 = shufflevector <4 x i32> %6, <4 x i32> undef, <4 x i32> <i32 2, i32 undef, i32 undef, i32 undef>
  %8 = bitcast <2 x i64> %5 to <8 x i16>
  %9 = bitcast <4 x i32> %7 to <8 x i16>
  %10 = add <8 x i16> %9, %8
  %11 = bitcast <8 x i16> %10 to <4 x i32>
  %12 = extractelement <4 x i32> %11, i32 0
  %13 = add nsw i32 %12, 8
  %14 = lshr i32 %13, 4
  %15 = trunc i32 %14 to i8
  %16 = insertelement <16 x i8> undef, i8 %15, i32 0
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 32
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 64
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %0, i64 96
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 128
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 160
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 192
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 224
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %0, i64 256
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %0, i64 288
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 320
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %0, i64 352
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %0, i64 384
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %0, i64 416
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %0, i64 448
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %0, i64 480
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %48, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @DC16NoTopLeft_SSE2(i8* nocapture) #5 {
  %2 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %2, align 1
  %3 = getelementptr inbounds i8, i8* %0, i64 32
  %4 = bitcast i8* %3 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %4, align 1
  %5 = getelementptr inbounds i8, i8* %0, i64 64
  %6 = bitcast i8* %5 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %6, align 1
  %7 = getelementptr inbounds i8, i8* %0, i64 96
  %8 = bitcast i8* %7 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %8, align 1
  %9 = getelementptr inbounds i8, i8* %0, i64 128
  %10 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %10, align 1
  %11 = getelementptr inbounds i8, i8* %0, i64 160
  %12 = bitcast i8* %11 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %12, align 1
  %13 = getelementptr inbounds i8, i8* %0, i64 192
  %14 = bitcast i8* %13 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 224
  %16 = bitcast i8* %15 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 256
  %18 = bitcast i8* %17 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 288
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 320
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %0, i64 352
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 384
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 416
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 448
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 480
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>, <16 x i8>* %32, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @DC8uv_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = getelementptr inbounds i8, i8* %0, i64 -1
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = getelementptr inbounds i8, i8* %0, i64 31
  %11 = load i8, i8* %10, align 1
  %12 = zext i8 %11 to i32
  %13 = add nuw nsw i32 %9, %12
  %14 = getelementptr inbounds i8, i8* %0, i64 63
  %15 = load i8, i8* %14, align 1
  %16 = zext i8 %15 to i32
  %17 = add nuw nsw i32 %13, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 95
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = add nuw nsw i32 %17, %20
  %22 = getelementptr inbounds i8, i8* %0, i64 127
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %21, %24
  %26 = getelementptr inbounds i8, i8* %0, i64 159
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i32
  %29 = add nuw nsw i32 %25, %28
  %30 = getelementptr inbounds i8, i8* %0, i64 191
  %31 = load i8, i8* %30, align 1
  %32 = zext i8 %31 to i32
  %33 = add nuw nsw i32 %29, %32
  %34 = getelementptr inbounds i8, i8* %0, i64 223
  %35 = load i8, i8* %34, align 1
  %36 = zext i8 %35 to i32
  %37 = add nuw nsw i32 %33, %36
  %38 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #8
  %39 = bitcast <2 x i64> %38 to <4 x i32>
  %40 = extractelement <4 x i32> %39, i32 0
  %41 = add i32 %40, 8
  %42 = add i32 %41, %37
  %43 = lshr i32 %42, 4
  %44 = trunc i32 %43 to i8
  %45 = insertelement <16 x i8> undef, i8 %44, i32 0
  %46 = shufflevector <16 x i8> %45, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %47 = bitcast <16 x i8> %46 to <2 x i64>
  %48 = extractelement <2 x i64> %47, i32 0
  %49 = bitcast i8* %0 to i64*
  store i64 %48, i64* %49, align 1
  %50 = getelementptr inbounds i8, i8* %0, i64 32
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 1
  %52 = getelementptr inbounds i8, i8* %0, i64 64
  %53 = bitcast i8* %52 to i64*
  store i64 %48, i64* %53, align 1
  %54 = getelementptr inbounds i8, i8* %0, i64 96
  %55 = bitcast i8* %54 to i64*
  store i64 %48, i64* %55, align 1
  %56 = getelementptr inbounds i8, i8* %0, i64 128
  %57 = bitcast i8* %56 to i64*
  store i64 %48, i64* %57, align 1
  %58 = getelementptr inbounds i8, i8* %0, i64 160
  %59 = bitcast i8* %58 to i64*
  store i64 %48, i64* %59, align 1
  %60 = getelementptr inbounds i8, i8* %0, i64 192
  %61 = bitcast i8* %60 to i64*
  store i64 %48, i64* %61, align 1
  %62 = getelementptr inbounds i8, i8* %0, i64 224
  %63 = bitcast i8* %62 to i64*
  store i64 %48, i64* %63, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @TM8uv_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> undef, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8 = getelementptr inbounds i8, i8* %0, i64 -33
  %9 = bitcast <16 x i8> %7 to <8 x i16>
  %10 = getelementptr inbounds i8, i8* %0, i64 -1
  %11 = load i8, i8* %10, align 1
  %12 = zext i8 %11 to i16
  %13 = load i8, i8* %8, align 1
  %14 = zext i8 %13 to i16
  %15 = sub nsw i16 %12, %14
  %16 = insertelement <8 x i16> undef, i16 %15, i32 0
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <8 x i32> zeroinitializer
  %18 = add <8 x i16> %17, %9
  %19 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %18, <8 x i16> undef) #8
  %20 = bitcast <16 x i8> %19 to <2 x i64>
  %21 = extractelement <2 x i64> %20, i32 0
  %22 = bitcast i8* %0 to i64*
  store i64 %21, i64* %22, align 1
  %23 = getelementptr inbounds i8, i8* %0, i64 32
  %24 = getelementptr inbounds i8, i8* %0, i64 31
  %25 = load i8, i8* %24, align 1
  %26 = zext i8 %25 to i16
  %27 = sub nsw i16 %26, %14
  %28 = insertelement <8 x i16> undef, i16 %27, i32 0
  %29 = shufflevector <8 x i16> %28, <8 x i16> undef, <8 x i32> zeroinitializer
  %30 = add <8 x i16> %29, %9
  %31 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> undef) #8
  %32 = bitcast <16 x i8> %31 to <2 x i64>
  %33 = extractelement <2 x i64> %32, i32 0
  %34 = bitcast i8* %23 to i64*
  store i64 %33, i64* %34, align 1
  %35 = getelementptr inbounds i8, i8* %0, i64 64
  %36 = getelementptr inbounds i8, i8* %0, i64 63
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i16
  %39 = sub nsw i16 %38, %14
  %40 = insertelement <8 x i16> undef, i16 %39, i32 0
  %41 = shufflevector <8 x i16> %40, <8 x i16> undef, <8 x i32> zeroinitializer
  %42 = add <8 x i16> %41, %9
  %43 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %42, <8 x i16> undef) #8
  %44 = bitcast <16 x i8> %43 to <2 x i64>
  %45 = extractelement <2 x i64> %44, i32 0
  %46 = bitcast i8* %35 to i64*
  store i64 %45, i64* %46, align 1
  %47 = getelementptr inbounds i8, i8* %0, i64 96
  %48 = getelementptr inbounds i8, i8* %0, i64 95
  %49 = load i8, i8* %48, align 1
  %50 = zext i8 %49 to i16
  %51 = sub nsw i16 %50, %14
  %52 = insertelement <8 x i16> undef, i16 %51, i32 0
  %53 = shufflevector <8 x i16> %52, <8 x i16> undef, <8 x i32> zeroinitializer
  %54 = add <8 x i16> %53, %9
  %55 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> undef) #8
  %56 = bitcast <16 x i8> %55 to <2 x i64>
  %57 = extractelement <2 x i64> %56, i32 0
  %58 = bitcast i8* %47 to i64*
  store i64 %57, i64* %58, align 1
  %59 = getelementptr inbounds i8, i8* %0, i64 128
  %60 = getelementptr inbounds i8, i8* %0, i64 127
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i16
  %63 = sub nsw i16 %62, %14
  %64 = insertelement <8 x i16> undef, i16 %63, i32 0
  %65 = shufflevector <8 x i16> %64, <8 x i16> undef, <8 x i32> zeroinitializer
  %66 = add <8 x i16> %65, %9
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %66, <8 x i16> undef) #8
  %68 = bitcast <16 x i8> %67 to <2 x i64>
  %69 = extractelement <2 x i64> %68, i32 0
  %70 = bitcast i8* %59 to i64*
  store i64 %69, i64* %70, align 1
  %71 = getelementptr inbounds i8, i8* %0, i64 160
  %72 = getelementptr inbounds i8, i8* %0, i64 159
  %73 = load i8, i8* %72, align 1
  %74 = zext i8 %73 to i16
  %75 = sub nsw i16 %74, %14
  %76 = insertelement <8 x i16> undef, i16 %75, i32 0
  %77 = shufflevector <8 x i16> %76, <8 x i16> undef, <8 x i32> zeroinitializer
  %78 = add <8 x i16> %77, %9
  %79 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %78, <8 x i16> undef) #8
  %80 = bitcast <16 x i8> %79 to <2 x i64>
  %81 = extractelement <2 x i64> %80, i32 0
  %82 = bitcast i8* %71 to i64*
  store i64 %81, i64* %82, align 1
  %83 = getelementptr inbounds i8, i8* %0, i64 192
  %84 = getelementptr inbounds i8, i8* %0, i64 191
  %85 = load i8, i8* %84, align 1
  %86 = zext i8 %85 to i16
  %87 = sub nsw i16 %86, %14
  %88 = insertelement <8 x i16> undef, i16 %87, i32 0
  %89 = shufflevector <8 x i16> %88, <8 x i16> undef, <8 x i32> zeroinitializer
  %90 = add <8 x i16> %89, %9
  %91 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> undef) #8
  %92 = bitcast <16 x i8> %91 to <2 x i64>
  %93 = extractelement <2 x i64> %92, i32 0
  %94 = bitcast i8* %83 to i64*
  store i64 %93, i64* %94, align 1
  %95 = getelementptr inbounds i8, i8* %0, i64 224
  %96 = getelementptr inbounds i8, i8* %0, i64 223
  %97 = load i8, i8* %96, align 1
  %98 = zext i8 %97 to i16
  %99 = sub nsw i16 %98, %14
  %100 = insertelement <8 x i16> undef, i16 %99, i32 0
  %101 = shufflevector <8 x i16> %100, <8 x i16> undef, <8 x i32> zeroinitializer
  %102 = add <8 x i16> %101, %9
  %103 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %102, <8 x i16> undef) #8
  %104 = bitcast <16 x i8> %103 to <2 x i64>
  %105 = extractelement <2 x i64> %104, i32 0
  %106 = bitcast i8* %95 to i64*
  store i64 %105, i64* %106, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @VE8uv_SSE2(i8* nocapture) #4 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = bitcast i8* %0 to i64*
  store i64 %4, i64* %5, align 1
  %6 = getelementptr inbounds i8, i8* %0, i64 32
  %7 = bitcast i8* %6 to i64*
  store i64 %4, i64* %7, align 1
  %8 = getelementptr inbounds i8, i8* %0, i64 64
  %9 = bitcast i8* %8 to i64*
  store i64 %4, i64* %9, align 1
  %10 = getelementptr inbounds i8, i8* %0, i64 96
  %11 = bitcast i8* %10 to i64*
  store i64 %4, i64* %11, align 1
  %12 = getelementptr inbounds i8, i8* %0, i64 128
  %13 = bitcast i8* %12 to i64*
  store i64 %4, i64* %13, align 1
  %14 = getelementptr inbounds i8, i8* %0, i64 160
  %15 = bitcast i8* %14 to i64*
  store i64 %4, i64* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 192
  %17 = bitcast i8* %16 to i64*
  store i64 %4, i64* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 224
  %19 = bitcast i8* %18 to i64*
  store i64 %4, i64* %19, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @DC8uvNoTop_SSE2(i8* nocapture) #4 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -1
  %3 = load i8, i8* %2, align 1
  %4 = zext i8 %3 to i32
  %5 = add nuw nsw i32 %4, 4
  %6 = getelementptr inbounds i8, i8* %0, i64 31
  %7 = load i8, i8* %6, align 1
  %8 = zext i8 %7 to i32
  %9 = add nuw nsw i32 %5, %8
  %10 = getelementptr inbounds i8, i8* %0, i64 63
  %11 = load i8, i8* %10, align 1
  %12 = zext i8 %11 to i32
  %13 = add nuw nsw i32 %9, %12
  %14 = getelementptr inbounds i8, i8* %0, i64 95
  %15 = load i8, i8* %14, align 1
  %16 = zext i8 %15 to i32
  %17 = add nuw nsw i32 %13, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 127
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = add nuw nsw i32 %17, %20
  %22 = getelementptr inbounds i8, i8* %0, i64 159
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %21, %24
  %26 = getelementptr inbounds i8, i8* %0, i64 191
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i32
  %29 = add nuw nsw i32 %25, %28
  %30 = getelementptr inbounds i8, i8* %0, i64 223
  %31 = load i8, i8* %30, align 1
  %32 = zext i8 %31 to i32
  %33 = add nuw nsw i32 %29, %32
  %34 = lshr i32 %33, 3
  %35 = trunc i32 %34 to i8
  %36 = insertelement <16 x i8> undef, i8 %35, i32 0
  %37 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %38 = bitcast <16 x i8> %37 to <2 x i64>
  %39 = extractelement <2 x i64> %38, i32 0
  %40 = bitcast i8* %0 to i64*
  store i64 %39, i64* %40, align 1
  %41 = getelementptr inbounds i8, i8* %0, i64 32
  %42 = bitcast i8* %41 to i64*
  store i64 %39, i64* %42, align 1
  %43 = getelementptr inbounds i8, i8* %0, i64 64
  %44 = bitcast i8* %43 to i64*
  store i64 %39, i64* %44, align 1
  %45 = getelementptr inbounds i8, i8* %0, i64 96
  %46 = bitcast i8* %45 to i64*
  store i64 %39, i64* %46, align 1
  %47 = getelementptr inbounds i8, i8* %0, i64 128
  %48 = bitcast i8* %47 to i64*
  store i64 %39, i64* %48, align 1
  %49 = getelementptr inbounds i8, i8* %0, i64 160
  %50 = bitcast i8* %49 to i64*
  store i64 %39, i64* %50, align 1
  %51 = getelementptr inbounds i8, i8* %0, i64 192
  %52 = bitcast i8* %51 to i64*
  store i64 %39, i64* %52, align 1
  %53 = getelementptr inbounds i8, i8* %0, i64 224
  %54 = bitcast i8* %53 to i64*
  store i64 %39, i64* %54, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @DC8uvNoLeft_SSE2(i8* nocapture) #2 {
  %2 = getelementptr inbounds i8, i8* %0, i64 -32
  %3 = bitcast i8* %2 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #8
  %8 = bitcast <2 x i64> %7 to <4 x i32>
  %9 = extractelement <4 x i32> %8, i32 0
  %10 = add nsw i32 %9, 4
  %11 = lshr i32 %10, 3
  %12 = trunc i32 %11 to i8
  %13 = insertelement <16 x i8> undef, i8 %12, i32 0
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <2 x i64>
  %16 = extractelement <2 x i64> %15, i32 0
  %17 = bitcast i8* %0 to i64*
  store i64 %16, i64* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 32
  %19 = bitcast i8* %18 to i64*
  store i64 %16, i64* %19, align 1
  %20 = getelementptr inbounds i8, i8* %0, i64 64
  %21 = bitcast i8* %20 to i64*
  store i64 %16, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %0, i64 96
  %23 = bitcast i8* %22 to i64*
  store i64 %16, i64* %23, align 1
  %24 = getelementptr inbounds i8, i8* %0, i64 128
  %25 = bitcast i8* %24 to i64*
  store i64 %16, i64* %25, align 1
  %26 = getelementptr inbounds i8, i8* %0, i64 160
  %27 = bitcast i8* %26 to i64*
  store i64 %16, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 192
  %29 = bitcast i8* %28 to i64*
  store i64 %16, i64* %29, align 1
  %30 = getelementptr inbounds i8, i8* %0, i64 224
  %31 = bitcast i8* %30 to i64*
  store i64 %16, i64* %31, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @DC8uvNoTopLeft_SSE2(i8* nocapture) #5 {
  %2 = bitcast i8* %0 to i64*
  store i64 -9187201950435737472, i64* %2, align 1
  %3 = getelementptr inbounds i8, i8* %0, i64 32
  %4 = bitcast i8* %3 to i64*
  store i64 -9187201950435737472, i64* %4, align 1
  %5 = getelementptr inbounds i8, i8* %0, i64 64
  %6 = bitcast i8* %5 to i64*
  store i64 -9187201950435737472, i64* %6, align 1
  %7 = getelementptr inbounds i8, i8* %0, i64 96
  %8 = bitcast i8* %7 to i64*
  store i64 -9187201950435737472, i64* %8, align 1
  %9 = getelementptr inbounds i8, i8* %0, i64 128
  %10 = bitcast i8* %9 to i64*
  store i64 -9187201950435737472, i64* %10, align 1
  %11 = getelementptr inbounds i8, i8* %0, i64 160
  %12 = bitcast i8* %11 to i64*
  store i64 -9187201950435737472, i64* %12, align 1
  %13 = getelementptr inbounds i8, i8* %0, i64 192
  %14 = bitcast i8* %13 to i64*
  store i64 -9187201950435737472, i64* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 224
  %16 = bitcast i8* %15 to i64*
  store i64 -9187201950435737472, i64* %16, align 1
  ret void
}

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.usub.sat.v16i8(<16 x i8>, <16 x i8>) #7

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8>, <16 x i8>) #7

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8>, <16 x i8>) #7

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8>, <16 x i8>) #7

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8>, <16 x i8>) #6

; Function Attrs: nounwind readnone
declare <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8>, <16 x i8>) #6

attributes #0 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind readnone }
attributes #7 = { nounwind readnone speculatable }
attributes #8 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
