; ModuleID = '../../third_party/swiftshader/src/Vulkan/VkQueryPool.cpp'
source_filename = "../../third_party/swiftshader/src/Vulkan/VkQueryPool.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.marl::Allocator" = type { i32 (...)** }
%"struct.std::__1::__function::__policy" = type { i8* (i8*)*, void (i8*)*, i8, %"class.std::type_info"* }
%"class.std::type_info" = type { i32 (...)**, i8* }
%"class.vk::Query" = type { %"class.marl::WaitGroup", %"class.marl::Event", %"struct.std::__1::atomic.45", %"struct.std::__1::atomic.49", %"struct.std::__1::atomic.53" }
%"class.marl::WaitGroup" = type { %"class.std::__1::shared_ptr" }
%"class.std::__1::shared_ptr" = type { %"struct.marl::WaitGroup::Data"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::WaitGroup::Data" = type { %"struct.std::__1::atomic", %"class.marl::ConditionVariable", %"class.marl::mutex" }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.36" }
%"struct.std::__1::__atomic_base.36" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"class.marl::ConditionVariable" = type { %"class.marl::mutex", %"class.marl::containers::list", %"class.std::__1::condition_variable", %"struct.std::__1::atomic.39", %"struct.std::__1::atomic.39" }
%"class.marl::containers::list" = type { %"class.marl::Allocator"*, i64, i64, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain" = type { %"struct.marl::Allocation", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* }
%"struct.marl::Allocation" = type { i8*, %"struct.marl::Allocation::Request" }
%"struct.marl::Allocation::Request" = type <{ i64, i64, i8, i8, [6 x i8] }>
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry" = type { %"class.marl::Scheduler::Fiber"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"class.marl::Scheduler::Fiber" = type <{ i32, [4 x i8], %"class.std::__1::unique_ptr", %"class.marl::Scheduler::Worker"*, i32, [4 x i8] }>
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem", %"struct.std::__1::__compressed_pair_elem.58" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.marl::OSFiber"* }
%"class.marl::OSFiber" = type opaque
%"struct.std::__1::__compressed_pair_elem.58" = type { %"struct.marl::Allocator::Deleter" }
%"struct.marl::Allocator::Deleter" = type { %"class.marl::Allocator"*, i64 }
%"class.marl::Scheduler::Worker" = type <{ i32, i32, %"class.marl::Scheduler"*, %"class.std::__1::unique_ptr.78", %"class.marl::Scheduler::Fiber"*, %"class.marl::Thread", %"struct.marl::Scheduler::Worker::Work", %"class.std::__1::unordered_set", %"class.marl::containers::vector.160", %"class.marl::Scheduler::Worker::FastRnd", i8, [7 x i8] }>
%"class.marl::Scheduler" = type { %"struct.marl::Scheduler::Config", %"struct.std::__1::array", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"struct.std::__1::array.60", %"struct.marl::Scheduler::SingleThreadedWorkers" }
%"struct.marl::Scheduler::Config" = type { %"struct.marl::Scheduler::Config::WorkerThread", %"class.marl::Allocator"*, i64 }
%"struct.marl::Scheduler::Config::WorkerThread" = type { i32, %"class.std::__1::function", %"class.std::__1::shared_ptr.59" }
%"class.std::__1::function" = type { %"class.std::__1::__function::__policy_func" }
%"class.std::__1::__function::__policy_func" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker", %"struct.std::__1::__function::__policy"* }
%"union.std::__1::__function::__policy_storage" = type { i8*, [8 x i8] }
%"struct.std::__1::__function::__policy_invoker" = type { void (%"union.std::__1::__function::__policy_storage"*, i32)* }
%"class.std::__1::shared_ptr.59" = type { %"class.marl::Thread::Affinity::Policy"*, %"class.std::__1::__shared_weak_count"* }
%"class.marl::Thread::Affinity::Policy" = type { i32 (...)** }
%"struct.std::__1::array" = type { [8 x %"struct.std::__1::atomic.39"] }
%"struct.std::__1::array.60" = type { [256 x %"class.marl::Scheduler::Worker"*] }
%"struct.marl::Scheduler::SingleThreadedWorkers" = type { %"class.marl::mutex", %"class.std::__1::condition_variable", %"class.std::__1::unordered_map" }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.61", %"class.std::__1::__compressed_pair.68", %"class.std::__1::__compressed_pair.72", %"class.std::__1::__compressed_pair.75", [4 x i8] }>
%"class.std::__1::unique_ptr.61" = type { %"class.std::__1::__compressed_pair.62" }
%"class.std::__1::__compressed_pair.62" = type { %"struct.std::__1::__compressed_pair_elem.63", %"struct.std::__1::__compressed_pair_elem.64" }
%"struct.std::__1::__compressed_pair_elem.63" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.64" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.65" }
%"class.std::__1::__compressed_pair.65" = type { %"struct.std::__1::__compressed_pair_elem.66", %"struct.std::__1::__compressed_pair_elem.67" }
%"struct.std::__1::__compressed_pair_elem.66" = type { i64 }
%"struct.std::__1::__compressed_pair_elem.67" = type { %"struct.marl::StlAllocator" }
%"struct.marl::StlAllocator" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.68" = type { %"struct.std::__1::__compressed_pair_elem.69", %"struct.std::__1::__compressed_pair_elem.70" }
%"struct.std::__1::__compressed_pair_elem.69" = type { %"struct.std::__1::__hash_node_base" }
%"struct.std::__1::__compressed_pair_elem.70" = type { %"struct.marl::StlAllocator.71" }
%"struct.marl::StlAllocator.71" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.72" = type { %"struct.std::__1::__compressed_pair_elem.66" }
%"class.std::__1::__compressed_pair.75" = type { %"struct.std::__1::__compressed_pair_elem.76" }
%"struct.std::__1::__compressed_pair_elem.76" = type { float }
%"class.std::__1::unique_ptr.78" = type { %"class.std::__1::__compressed_pair.79" }
%"class.std::__1::__compressed_pair.79" = type { %"struct.std::__1::__compressed_pair_elem.80", %"struct.std::__1::__compressed_pair_elem.58" }
%"struct.std::__1::__compressed_pair_elem.80" = type { %"class.marl::Scheduler::Fiber"* }
%"class.marl::Thread" = type { %"class.marl::Thread::Impl"* }
%"class.marl::Thread::Impl" = type opaque
%"struct.marl::Scheduler::Worker::Work" = type { %"struct.std::__1::atomic.81", i64, %"class.std::__1::deque", %"class.std::__1::deque.98", %"struct.marl::Scheduler::WaitingFibers", i8, %"class.std::__1::condition_variable", %"class.marl::mutex" }
%"struct.std::__1::atomic.81" = type { %"struct.std::__1::__atomic_base.82" }
%"struct.std::__1::__atomic_base.82" = type { %"struct.std::__1::__atomic_base.83" }
%"struct.std::__1::__atomic_base.83" = type { %"struct.std::__1::__cxx_atomic_impl.84" }
%"struct.std::__1::__cxx_atomic_impl.84" = type { %"struct.std::__1::__cxx_atomic_base_impl.85" }
%"struct.std::__1::__cxx_atomic_base_impl.85" = type { i64 }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.95" }
%"struct.std::__1::__split_buffer" = type { %"class.marl::Task"**, %"class.marl::Task"**, %"class.marl::Task"**, %"class.std::__1::__compressed_pair.91" }
%"class.marl::Task" = type <{ %"class.std::__1::function.86", i32, [4 x i8] }>
%"class.std::__1::function.86" = type { %"class.std::__1::__function::__policy_func.89" }
%"class.std::__1::__function::__policy_func.89" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker.90", %"struct.std::__1::__function::__policy"* }
%"struct.std::__1::__function::__policy_invoker.90" = type { void (%"union.std::__1::__function::__policy_storage"*)* }
%"class.std::__1::__compressed_pair.91" = type { %"struct.std::__1::__compressed_pair_elem.92", %"struct.std::__1::__compressed_pair_elem.93" }
%"struct.std::__1::__compressed_pair_elem.92" = type { %"class.marl::Task"** }
%"struct.std::__1::__compressed_pair_elem.93" = type { %"struct.marl::StlAllocator.94" }
%"struct.marl::StlAllocator.94" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.95" = type { %"struct.std::__1::__compressed_pair_elem.66", %"struct.std::__1::__compressed_pair_elem.96" }
%"struct.std::__1::__compressed_pair_elem.96" = type { %"struct.marl::StlAllocator.97" }
%"struct.marl::StlAllocator.97" = type { %"class.marl::Allocator"* }
%"class.std::__1::deque.98" = type { %"class.std::__1::__deque_base.99" }
%"class.std::__1::__deque_base.99" = type { %"struct.std::__1::__split_buffer.100", i64, %"class.std::__1::__compressed_pair.105" }
%"struct.std::__1::__split_buffer.100" = type { %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.std::__1::__compressed_pair.101" }
%"class.std::__1::__compressed_pair.101" = type { %"struct.std::__1::__compressed_pair_elem.102", %"struct.std::__1::__compressed_pair_elem.103" }
%"struct.std::__1::__compressed_pair_elem.102" = type { %"class.marl::Scheduler::Fiber"*** }
%"struct.std::__1::__compressed_pair_elem.103" = type { %"struct.marl::StlAllocator.104" }
%"struct.marl::StlAllocator.104" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.105" = type { %"struct.std::__1::__compressed_pair_elem.66", %"struct.std::__1::__compressed_pair_elem.106" }
%"struct.std::__1::__compressed_pair_elem.106" = type { %"struct.marl::StlAllocator.107" }
%"struct.marl::StlAllocator.107" = type { %"class.marl::Allocator"* }
%"struct.marl::Scheduler::WaitingFibers" = type { %"class.std::__1::set", %"class.std::__1::unordered_map.115" }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.108", %"class.std::__1::__compressed_pair.112" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type opaque
%"class.std::__1::__compressed_pair.108" = type { %"struct.std::__1::__compressed_pair_elem.109", %"struct.std::__1::__compressed_pair_elem.110" }
%"struct.std::__1::__compressed_pair_elem.109" = type { %"class.std::__1::__tree_end_node" }
%"struct.std::__1::__compressed_pair_elem.110" = type { %"struct.marl::StlAllocator.111" }
%"struct.marl::StlAllocator.111" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.112" = type { %"struct.std::__1::__compressed_pair_elem.66" }
%"class.std::__1::unordered_map.115" = type { %"class.std::__1::__hash_table.116" }
%"class.std::__1::__hash_table.116" = type <{ %"class.std::__1::unique_ptr.117", %"class.std::__1::__compressed_pair.126", %"class.std::__1::__compressed_pair.130", %"class.std::__1::__compressed_pair.135", [4 x i8] }>
%"class.std::__1::unique_ptr.117" = type { %"class.std::__1::__compressed_pair.118" }
%"class.std::__1::__compressed_pair.118" = type { %"struct.std::__1::__compressed_pair_elem.119", %"struct.std::__1::__compressed_pair_elem.121" }
%"struct.std::__1::__compressed_pair_elem.119" = type { %"struct.std::__1::__hash_node_base.120"** }
%"struct.std::__1::__hash_node_base.120" = type { %"struct.std::__1::__hash_node_base.120"* }
%"struct.std::__1::__compressed_pair_elem.121" = type { %"class.std::__1::__bucket_list_deallocator.122" }
%"class.std::__1::__bucket_list_deallocator.122" = type { %"class.std::__1::__compressed_pair.123" }
%"class.std::__1::__compressed_pair.123" = type { %"struct.std::__1::__compressed_pair_elem.66", %"struct.std::__1::__compressed_pair_elem.124" }
%"struct.std::__1::__compressed_pair_elem.124" = type { %"struct.marl::StlAllocator.125" }
%"struct.marl::StlAllocator.125" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.126" = type { %"struct.std::__1::__compressed_pair_elem.127", %"struct.std::__1::__compressed_pair_elem.128" }
%"struct.std::__1::__compressed_pair_elem.127" = type { %"struct.std::__1::__hash_node_base.120" }
%"struct.std::__1::__compressed_pair_elem.128" = type { %"struct.marl::StlAllocator.129" }
%"struct.marl::StlAllocator.129" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.130" = type { %"struct.std::__1::__compressed_pair_elem.66" }
%"class.std::__1::__compressed_pair.135" = type { %"struct.std::__1::__compressed_pair_elem.76" }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.141" }
%"class.std::__1::__hash_table.141" = type <{ %"class.std::__1::unique_ptr.142", %"class.std::__1::__compressed_pair.151", %"class.std::__1::__compressed_pair.155", %"class.std::__1::__compressed_pair.157", [4 x i8] }>
%"class.std::__1::unique_ptr.142" = type { %"class.std::__1::__compressed_pair.143" }
%"class.std::__1::__compressed_pair.143" = type { %"struct.std::__1::__compressed_pair_elem.144", %"struct.std::__1::__compressed_pair_elem.146" }
%"struct.std::__1::__compressed_pair_elem.144" = type { %"struct.std::__1::__hash_node_base.145"** }
%"struct.std::__1::__hash_node_base.145" = type { %"struct.std::__1::__hash_node_base.145"* }
%"struct.std::__1::__compressed_pair_elem.146" = type { %"class.std::__1::__bucket_list_deallocator.147" }
%"class.std::__1::__bucket_list_deallocator.147" = type { %"class.std::__1::__compressed_pair.148" }
%"class.std::__1::__compressed_pair.148" = type { %"struct.std::__1::__compressed_pair_elem.66", %"struct.std::__1::__compressed_pair_elem.149" }
%"struct.std::__1::__compressed_pair_elem.149" = type { %"struct.marl::StlAllocator.150" }
%"struct.marl::StlAllocator.150" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.151" = type { %"struct.std::__1::__compressed_pair_elem.152", %"struct.std::__1::__compressed_pair_elem.153" }
%"struct.std::__1::__compressed_pair_elem.152" = type { %"struct.std::__1::__hash_node_base.145" }
%"struct.std::__1::__compressed_pair_elem.153" = type { %"struct.marl::StlAllocator.154" }
%"struct.marl::StlAllocator.154" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.155" = type { %"struct.std::__1::__compressed_pair_elem.66" }
%"class.std::__1::__compressed_pair.157" = type { %"struct.std::__1::__compressed_pair_elem.76" }
%"class.marl::containers::vector.160" = type { %"class.marl::Allocator"*, i64, i64, [16 x %"struct.marl::aligned_storage<24, 8>::type"], %"struct.marl::aligned_storage<24, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<24, 8>::type" = type { [24 x i8] }
%"class.marl::Scheduler::Worker::FastRnd" = type { i64 }
%"class.std::__1::condition_variable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon, %union.anon.37, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon = type { i64 }
%union.anon.37 = type { i64 }
%"struct.std::__1::atomic.39" = type { %"struct.std::__1::__atomic_base.40" }
%"struct.std::__1::__atomic_base.40" = type { %"struct.std::__1::__atomic_base.41" }
%"struct.std::__1::__atomic_base.41" = type { %"struct.std::__1::__cxx_atomic_impl.42" }
%"struct.std::__1::__cxx_atomic_impl.42" = type { %"struct.std::__1::__cxx_atomic_base_impl.43" }
%"struct.std::__1::__cxx_atomic_base_impl.43" = type { i32 }
%"class.marl::mutex" = type { %"class.std::__1::mutex" }
%"class.std::__1::mutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.marl::Event" = type { %"class.std::__1::shared_ptr.44" }
%"class.std::__1::shared_ptr.44" = type { %"struct.marl::Event::Shared"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::Event::Shared" = type <{ %"class.marl::mutex", %"class.marl::ConditionVariable", %"class.marl::containers::vector", i8, i8, [6 x i8] }>
%"class.marl::containers::vector" = type { %"class.marl::Allocator"*, i64, i64, [1 x %"struct.marl::aligned_storage<16, 8>::type"], %"struct.marl::aligned_storage<16, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<16, 8>::type" = type { [16 x i8] }
%"struct.std::__1::atomic.45" = type { %"struct.std::__1::__atomic_base.46" }
%"struct.std::__1::__atomic_base.46" = type { %"struct.std::__1::__cxx_atomic_impl.47" }
%"struct.std::__1::__cxx_atomic_impl.47" = type { %"struct.std::__1::__cxx_atomic_base_impl.48" }
%"struct.std::__1::__cxx_atomic_base_impl.48" = type { i32 }
%"struct.std::__1::atomic.49" = type { %"struct.std::__1::__atomic_base.50" }
%"struct.std::__1::__atomic_base.50" = type { %"struct.std::__1::__cxx_atomic_impl.51" }
%"struct.std::__1::__cxx_atomic_impl.51" = type { %"struct.std::__1::__cxx_atomic_base_impl.52" }
%"struct.std::__1::__cxx_atomic_base_impl.52" = type { i32 }
%"struct.std::__1::atomic.53" = type { %"struct.std::__1::__atomic_base.54" }
%"struct.std::__1::__atomic_base.54" = type { %"struct.std::__1::__atomic_base.55" }
%"struct.std::__1::__atomic_base.55" = type { %"struct.std::__1::__cxx_atomic_impl.56" }
%"struct.std::__1::__cxx_atomic_impl.56" = type { %"struct.std::__1::__cxx_atomic_base_impl.57" }
%"struct.std::__1::__cxx_atomic_base_impl.57" = type { i64 }
%"class.vk::QueryPool" = type { %"class.vk::Query"*, i32, i32 }
%struct.VkQueryPoolCreateInfo = type { i32, i8*, i32, i32, i32, i32 }
%class.VkNonDispatchableHandle = type { i64 }
%class.VkNonDispatchableHandle.0 = type { i64 }
%class.VkNonDispatchableHandle.1 = type { i64 }
%class.VkNonDispatchableHandle.2 = type { i64 }
%class.VkNonDispatchableHandle.3 = type { i64 }
%class.VkNonDispatchableHandle.4 = type { i64 }
%class.VkNonDispatchableHandle.5 = type { i64 }
%class.VkNonDispatchableHandle.6 = type { i64 }
%class.VkNonDispatchableHandle.7 = type { i64 }
%class.VkNonDispatchableHandle.8 = type { i64 }
%class.VkNonDispatchableHandle.9 = type { i64 }
%class.VkNonDispatchableHandle.10 = type { i64 }
%class.VkNonDispatchableHandle.11 = type { i64 }
%class.VkNonDispatchableHandle.12 = type { i64 }
%class.VkNonDispatchableHandle.13 = type { i64 }
%class.VkNonDispatchableHandle.14 = type { i64 }
%class.VkNonDispatchableHandle.15 = type { i64 }
%class.VkNonDispatchableHandle.16 = type { i64 }
%class.VkNonDispatchableHandle.17 = type { i64 }
%class.VkNonDispatchableHandle.18 = type { i64 }
%class.VkNonDispatchableHandle.19 = type { i64 }
%class.VkNonDispatchableHandle.20 = type { i64 }
%class.VkNonDispatchableHandle.21 = type { i64 }
%class.VkNonDispatchableHandle.22 = type { i64 }
%class.VkNonDispatchableHandle.23 = type { i64 }
%class.VkNonDispatchableHandle.24 = type { i64 }
%class.VkNonDispatchableHandle.25 = type { i64 }
%class.VkNonDispatchableHandle.26 = type { i64 }
%class.VkNonDispatchableHandle.27 = type { i64 }
%class.VkNonDispatchableHandle.28 = type { i64 }
%class.VkNonDispatchableHandle.29 = type { i64 }
%class.VkNonDispatchableHandle.30 = type { i64 }
%class.VkNonDispatchableHandle.31 = type { i64 }
%class.VkNonDispatchableHandle.32 = type { i64 }
%class.VkNonDispatchableHandle.33 = type { i64 }
%class.VkNonDispatchableHandle.34 = type { i64 }
%class.VkNonDispatchableHandle.35 = type { i64 }
%"class.marl::lock" = type { %"class.std::__1::unique_lock" }
%"class.std::__1::unique_lock" = type <{ %"class.std::__1::mutex"*, i8, [7 x i8] }>
%class.anon = type { %"struct.marl::Event::Shared"* }
%struct.VkAllocationCallbacks = type { i8*, i8* (i8*, i64, i64, i32)*, i8* (i8*, i8*, i64, i64, i32)*, void (i8*, i8*)*, void (i8*, i64, i32, i32)*, void (i8*, i64, i32, i32)* }
%"struct.std::__1::__shared_ptr_emplace" = type { %"class.std::__1::__shared_weak_count", %"struct.std::__1::__shared_ptr_emplace<marl::WaitGroup::Data, std::__1::allocator<marl::WaitGroup::Data> >::_Storage" }
%"struct.std::__1::__shared_ptr_emplace<marl::WaitGroup::Data, std::__1::allocator<marl::WaitGroup::Data> >::_Storage" = type { [192 x i8] }
%"class.std::__1::__shared_ptr_pointer" = type { %"class.std::__1::__shared_weak_count", %"class.std::__1::__compressed_pair.166" }
%"class.std::__1::__compressed_pair.166" = type { %"struct.std::__1::__compressed_pair_elem.167" }
%"struct.std::__1::__compressed_pair_elem.167" = type { %"class.std::__1::__compressed_pair.168" }
%"class.std::__1::__compressed_pair.168" = type { %"struct.std::__1::__compressed_pair_elem.169", %"struct.std::__1::__compressed_pair_elem.58" }
%"struct.std::__1::__compressed_pair_elem.169" = type { %"struct.marl::Event::Shared"* }
%"class.std::__1::function.175" = type { %"class.std::__1::__function::__policy_func.178" }
%"class.std::__1::__function::__policy_func.178" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker.179", %"struct.std::__1::__function::__policy"* }
%"struct.std::__1::__function::__policy_invoker.179" = type { i1 (%"union.std::__1::__function::__policy_storage"*)* }

$_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm = comdat any

$_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED2Ev = comdat any

$_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED0Ev = comdat any

$_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE16__on_zero_sharedEv = comdat any

$_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE21__on_zero_shared_weakEv = comdat any

$_ZNSt3__110shared_ptrIN4marl9WaitGroup4DataEED2Ev = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEED0Ev = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv = comdat any

$_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev = comdat any

$_ZN4marl5Event6Shared6signalEv = comdat any

$_ZN4marl17ConditionVariable4waitIZNS_5Event6Shared4waitEvEUlvE_EEvRNS_4lockEOT_ = comdat any

$_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE = comdat any

$_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE = comdat any

$_ZTVNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEEE = comdat any

$_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_ = comdat any

@_ZN4marl9Allocator7DefaultE = external local_unnamed_addr global %"class.marl::Allocator"*, align 8
@.str = private unnamed_addr constant [79 x i8] c"%s:%d WARNING: UNSUPPORTED: VkPhysicalDeviceFeatures::pipelineStatisticsQuery\0A\00", align 1
@.str.1 = private unnamed_addr constant [57 x i8] c"../../third_party/swiftshader/src/Vulkan/VkQueryPool.cpp\00", align 1
@.str.2 = private unnamed_addr constant [55 x i8] c"%s:%d WARNING: UNSUPPORTED: vkCmdBeginQuery::flags %d\0A\00", align 1
@_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE = linkonce_odr hidden unnamed_addr constant { [7 x i8*] } { [7 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.std::__1::__shared_ptr_emplace"*)* @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED2Ev to i8*), i8* bitcast (void (%"struct.std::__1::__shared_ptr_emplace"*)* @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED0Ev to i8*), i8* bitcast (void (%"struct.std::__1::__shared_ptr_emplace"*)* @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE16__on_zero_sharedEv to i8*), i8* bitcast (i8* (%"class.std::__1::__shared_weak_count"*, %"class.std::type_info"*)* @_ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info to i8*), i8* bitcast (void (%"struct.std::__1::__shared_ptr_emplace"*)* @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE21__on_zero_shared_weakEv to i8*)] }, comdat, align 8
@_ZTVNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEEE = linkonce_odr hidden unnamed_addr constant { [7 x i8*] } { [7 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.std::__1::__shared_weak_count"*)* @_ZNSt3__119__shared_weak_countD2Ev to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEED0Ev to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv to i8*), i8* bitcast (i8* (%"class.std::__1::__shared_weak_count"*, %"class.std::type_info"*)* @_ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv to i8*)] }, comdat, align 8
@_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_ = linkonce_odr hidden constant %"struct.std::__1::__function::__policy" zeroinitializer, comdat, align 8

@_ZN2vk5QueryC1E11VkQueryType = hidden unnamed_addr alias void (%"class.vk::Query"*, i32), void (%"class.vk::Query"*, i32)* @_ZN2vk5QueryC2E11VkQueryType
@_ZN2vk9QueryPoolC1EPK21VkQueryPoolCreateInfoPv = hidden unnamed_addr alias void (%"class.vk::QueryPool"*, %struct.VkQueryPoolCreateInfo*, i8*), void (%"class.vk::QueryPool"*, %struct.VkQueryPoolCreateInfo*, i8*)* @_ZN2vk9QueryPoolC2EPK21VkQueryPoolCreateInfoPv

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv(%class.VkNonDispatchableHandle*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm(%class.VkNonDispatchableHandle*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle, %class.VkNonDispatchableHandle* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv(%class.VkNonDispatchableHandle.0*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.0* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm(%class.VkNonDispatchableHandle.0*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.0, %class.VkNonDispatchableHandle.0* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv(%class.VkNonDispatchableHandle.1*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.1* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm(%class.VkNonDispatchableHandle.1*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.1, %class.VkNonDispatchableHandle.1* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv(%class.VkNonDispatchableHandle.2*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.2* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm(%class.VkNonDispatchableHandle.2*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.2, %class.VkNonDispatchableHandle.2* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv(%class.VkNonDispatchableHandle.3*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.3* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm(%class.VkNonDispatchableHandle.3*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.3, %class.VkNonDispatchableHandle.3* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv(%class.VkNonDispatchableHandle.4*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.4* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm(%class.VkNonDispatchableHandle.4*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.4, %class.VkNonDispatchableHandle.4* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv(%class.VkNonDispatchableHandle.5*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.5* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm(%class.VkNonDispatchableHandle.5*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.5, %class.VkNonDispatchableHandle.5* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv(%class.VkNonDispatchableHandle.6*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.6* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm(%class.VkNonDispatchableHandle.6*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.6, %class.VkNonDispatchableHandle.6* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv(%class.VkNonDispatchableHandle.7*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.7* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm(%class.VkNonDispatchableHandle.7*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.7, %class.VkNonDispatchableHandle.7* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv(%class.VkNonDispatchableHandle.8*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.8* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm(%class.VkNonDispatchableHandle.8*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.8, %class.VkNonDispatchableHandle.8* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv(%class.VkNonDispatchableHandle.9*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.9* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm(%class.VkNonDispatchableHandle.9*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.9, %class.VkNonDispatchableHandle.9* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv(%class.VkNonDispatchableHandle.10*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.10* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm(%class.VkNonDispatchableHandle.10*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.10, %class.VkNonDispatchableHandle.10* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv(%class.VkNonDispatchableHandle.11*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.11* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm(%class.VkNonDispatchableHandle.11*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.11, %class.VkNonDispatchableHandle.11* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv(%class.VkNonDispatchableHandle.12*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.12* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm(%class.VkNonDispatchableHandle.12*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.12, %class.VkNonDispatchableHandle.12* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv(%class.VkNonDispatchableHandle.13*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.13* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm(%class.VkNonDispatchableHandle.13*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.13, %class.VkNonDispatchableHandle.13* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv(%class.VkNonDispatchableHandle.14*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.14* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm(%class.VkNonDispatchableHandle.14*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.14, %class.VkNonDispatchableHandle.14* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv(%class.VkNonDispatchableHandle.15*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.15* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm(%class.VkNonDispatchableHandle.15*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.15, %class.VkNonDispatchableHandle.15* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv(%class.VkNonDispatchableHandle.16*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.16* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm(%class.VkNonDispatchableHandle.16*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.16, %class.VkNonDispatchableHandle.16* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv(%class.VkNonDispatchableHandle.17*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.17* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm(%class.VkNonDispatchableHandle.17*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.17, %class.VkNonDispatchableHandle.17* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv(%class.VkNonDispatchableHandle.18*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.18* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm(%class.VkNonDispatchableHandle.18*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.18, %class.VkNonDispatchableHandle.18* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv(%class.VkNonDispatchableHandle.19*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.19* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm(%class.VkNonDispatchableHandle.19*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.19, %class.VkNonDispatchableHandle.19* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv(%class.VkNonDispatchableHandle.20*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.20* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm(%class.VkNonDispatchableHandle.20*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.20, %class.VkNonDispatchableHandle.20* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv(%class.VkNonDispatchableHandle.21*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.21* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm(%class.VkNonDispatchableHandle.21*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.21, %class.VkNonDispatchableHandle.21* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv(%class.VkNonDispatchableHandle.22*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.22* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm(%class.VkNonDispatchableHandle.22*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.22, %class.VkNonDispatchableHandle.22* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv(%class.VkNonDispatchableHandle.23*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.23* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm(%class.VkNonDispatchableHandle.23*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.23, %class.VkNonDispatchableHandle.23* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv(%class.VkNonDispatchableHandle.24*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.24* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm(%class.VkNonDispatchableHandle.24*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.24, %class.VkNonDispatchableHandle.24* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv(%class.VkNonDispatchableHandle.25*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.25* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm(%class.VkNonDispatchableHandle.25*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.25, %class.VkNonDispatchableHandle.25* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv(%class.VkNonDispatchableHandle.26*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.26* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm(%class.VkNonDispatchableHandle.26*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.26, %class.VkNonDispatchableHandle.26* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv(%class.VkNonDispatchableHandle.27*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.27* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm(%class.VkNonDispatchableHandle.27*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.27, %class.VkNonDispatchableHandle.27* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv(%class.VkNonDispatchableHandle.28*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.28* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm(%class.VkNonDispatchableHandle.28*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.28, %class.VkNonDispatchableHandle.28* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv(%class.VkNonDispatchableHandle.29*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.29* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm(%class.VkNonDispatchableHandle.29*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.29, %class.VkNonDispatchableHandle.29* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv(%class.VkNonDispatchableHandle.30*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.30* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm(%class.VkNonDispatchableHandle.30*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.30, %class.VkNonDispatchableHandle.30* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv(%class.VkNonDispatchableHandle.31*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.31* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm(%class.VkNonDispatchableHandle.31*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.31, %class.VkNonDispatchableHandle.31* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv(%class.VkNonDispatchableHandle.32*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.32* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm(%class.VkNonDispatchableHandle.32*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.32, %class.VkNonDispatchableHandle.32* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv(%class.VkNonDispatchableHandle.33*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.33* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm(%class.VkNonDispatchableHandle.33*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.33, %class.VkNonDispatchableHandle.33* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv(%class.VkNonDispatchableHandle.34*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.34* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm(%class.VkNonDispatchableHandle.34*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.34, %class.VkNonDispatchableHandle.34* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv(%class.VkNonDispatchableHandle.35*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.35* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm(%class.VkNonDispatchableHandle.35*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.35, %class.VkNonDispatchableHandle.35* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk5QueryC2E11VkQueryType(%"class.vk::Query"* nocapture, i32) unnamed_addr #0 align 2 {
  %3 = alloca %"struct.marl::Allocation::Request", align 16
  %4 = alloca %"struct.marl::Allocation", align 8
  %5 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %6 = tail call i8* @_Znwm(i64 216) #9
  %7 = bitcast i8* %6 to i32 (...)***
  %8 = getelementptr inbounds i8, i8* %6, i64 8
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %8, i8 0, i64 16, i1 false) #10
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %7, align 8
  %9 = getelementptr inbounds i8, i8* %6, i64 24
  %10 = bitcast i8* %9 to i32*
  store i32 0, i32* %10, align 4
  %11 = getelementptr inbounds i8, i8* %6, i64 32
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %11, i8 0, i64 40, i1 false) #10
  %12 = getelementptr inbounds i8, i8* %6, i64 72
  %13 = bitcast i8* %12 to i64*
  store i64 %5, i64* %13, align 8
  %14 = getelementptr inbounds i8, i8* %6, i64 80
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %14, i8 0, i64 136, i1 false) #10
  %15 = bitcast %"class.vk::Query"* %0 to i8**
  store i8* %9, i8** %15, align 8
  %16 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 0, i32 0, i32 1
  %17 = bitcast %"class.std::__1::__shared_weak_count"** %16 to i8**
  store i8* %6, i8** %17, align 8
  store atomic i32 0, i32* %10 seq_cst, align 4
  %18 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE, align 8
  %19 = ptrtoint %"class.marl::Allocator"* %18 to i64
  %20 = bitcast %"struct.marl::Allocation::Request"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %20) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 24, i1 false) #10
  %21 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %3, i64 0, i32 2
  %22 = bitcast i8* %21 to i16*
  store i16 512, i16* %22, align 16
  %23 = bitcast %"struct.marl::Allocation::Request"* %3 to <2 x i64>*
  store <2 x i64> <i64 272, i64 8>, <2 x i64>* %23, align 16
  %24 = bitcast %"struct.marl::Allocation"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %24) #10
  %25 = bitcast %"class.marl::Allocator"* %18 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %24, i8 -86, i64 32, i1 false) #10
  %26 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %25, align 8
  %27 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %26, i64 2
  %28 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %27, align 8
  call void %28(%"struct.marl::Allocation"* nonnull sret %4, %"class.marl::Allocator"* %18, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %3) #11
  %29 = bitcast %"struct.marl::Allocation"* %4 to %"struct.marl::Event::Shared"**
  %30 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %29, align 8
  %31 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 1, i32 1, i32 0
  %32 = bitcast %"struct.marl::Event::Shared"* %30 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %32, i8 0, i64 80, i1 false) #10
  %33 = bitcast %"class.marl::Allocator"** %31 to i64*
  store i64 %19, i64* %33, align 8
  %34 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 1, i32 1, i32 1
  %35 = bitcast i64* %34 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %35, i8 0, i64 96, i1 false) #10
  %36 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 2
  %37 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %38 = bitcast %"class.marl::containers::vector"* %36 to i64*
  store i64 %37, i64* %38, align 8
  %39 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 2, i32 1
  %40 = bitcast i64* %39 to <2 x i64>*
  store <2 x i64> <i64 0, i64 1>, <2 x i64>* %40, align 8
  %41 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 2, i32 4
  %42 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 2, i32 3, i64 0
  store %"struct.marl::aligned_storage<16, 8>::type"* %42, %"struct.marl::aligned_storage<16, 8>::type"** %41, align 8
  %43 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 2, i32 5
  %44 = bitcast %"struct.marl::Allocation"* %43 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %44, i8 0, i64 26, i1 false) #10
  %45 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 3
  store i8 1, i8* %45, align 8
  %46 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 4
  store i8 0, i8* %46, align 1
  %47 = call i8* @_Znwm(i64 48) #9
  %48 = ptrtoint %"struct.marl::Event::Shared"* %30 to i64
  %49 = bitcast i8* %47 to i32 (...)***
  %50 = getelementptr inbounds i8, i8* %47, i64 8
  call void @llvm.memset.p0i8.i64(i8* align 8 %50, i8 0, i64 16, i1 false) #10
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %49, align 8
  %51 = getelementptr inbounds i8, i8* %47, i64 24
  %52 = bitcast i8* %51 to i64*
  store i64 %48, i64* %52, align 8
  %53 = getelementptr inbounds i8, i8* %47, i64 32
  %54 = bitcast i8* %53 to %"class.marl::Allocator"**
  store %"class.marl::Allocator"* %18, %"class.marl::Allocator"** %54, align 8
  %55 = getelementptr inbounds i8, i8* %47, i64 40
  %56 = bitcast i8* %55 to i64*
  store i64 1, i64* %56, align 8
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %24) #10
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %20) #10
  %57 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 1, i32 0, i32 0
  store %"struct.marl::Event::Shared"* %30, %"struct.marl::Event::Shared"** %57, align 8
  %58 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 1, i32 0, i32 1
  %59 = bitcast %"class.std::__1::__shared_weak_count"** %58 to i8**
  store i8* %47, i8** %59, align 8
  %60 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  store i32 0, i32* %60, align 4
  %61 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0
  store i32 %1, i32* %61, align 4
  %62 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %62, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk5Query5resetEv(%"class.vk::Query"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 1, i32 0, i32 0
  %3 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %2, align 8
  %4 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %3, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %4) #11
  %5 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %2, align 8
  %6 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %5, i64 0, i32 4
  store i8 0, i8* %6, align 1
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %4) #11
  %7 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %8 = atomicrmw xchg i32* %7, i32 0 seq_cst
  %9 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %9 seq_cst, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable
define hidden void @_ZN2vk5Query5startEv(%"class.vk::Query"* nocapture) local_unnamed_addr #2 align 2 {
  %2 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %3 = atomicrmw xchg i32* %2, i32 1 seq_cst
  %4 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 0, i32 0, i32 0
  %5 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %4, align 8
  %6 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = atomicrmw add i32* %6, i32 1 seq_cst
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk5Query6finishEv(%"class.vk::Query"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 0, i32 0, i32 0
  %3 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %2, align 8
  %4 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %5 = atomicrmw sub i32* %4, i32 1 seq_cst
  %6 = icmp eq i32 %5, 1
  br i1 %6, label %7, label %37

7:                                                ; preds = %1
  %8 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %2, align 8
  %9 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %8, i64 0, i32 2, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %9) #11
  %10 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %2, align 8
  %11 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %10, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = load atomic i32, i32* %11 seq_cst, align 4
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %32, label %14

14:                                               ; preds = %7
  %15 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %10, i64 0, i32 1, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %15) #11
  %16 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %10, i64 0, i32 1, i32 1, i32 5
  %17 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %16, align 8
  %18 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %17, null
  br i1 %18, label %19, label %23

19:                                               ; preds = %23, %14
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %15) #11
  %20 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %10, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %21 = load atomic i32, i32* %20 seq_cst, align 4
  %22 = icmp sgt i32 %21, 0
  br i1 %22, label %30, label %32

23:                                               ; preds = %14, %23
  %24 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %28, %23 ], [ %17, %14 ]
  %25 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %24, i64 0, i32 0
  %26 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %25, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %26) #11
  %27 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %24, i64 0, i32 1
  %28 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %27, align 8
  %29 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %28, null
  br i1 %29, label %19, label %23

30:                                               ; preds = %19
  %31 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %10, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"* %31) #11
  br label %32

32:                                               ; preds = %7, %19, %30
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %9) #11
  %33 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %34 = atomicrmw xchg i32* %33, i32 2 seq_cst
  %35 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 1, i32 0, i32 0
  %36 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %35, align 8
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %36) #11
  br label %37

37:                                               ; preds = %1, %32
  ret void
}

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable
define hidden { i32, i64 } @_ZNK2vk5Query7getDataEv(%"class.vk::Query"* nocapture readonly) local_unnamed_addr #2 align 2 {
  %2 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i32, i32* %2 seq_cst, align 4
  %4 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %5 = load atomic i64, i64* %4 seq_cst, align 8
  %6 = insertvalue { i32, i64 } undef, i32 %3, 0
  %7 = insertvalue { i32, i64 } %6, i64 %5, 1
  ret { i32, i64 } %7
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable
define hidden i32 @_ZNK2vk5Query7getTypeEv(%"class.vk::Query"* nocapture readonly) local_unnamed_addr #2 align 2 {
  %2 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i32, i32* %2 seq_cst, align 4
  ret i32 %3
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk5Query4waitEv(%"class.vk::Query"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = alloca %"class.marl::lock", align 8
  %3 = alloca %class.anon, align 8
  %4 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 1, i32 0, i32 0
  %5 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %4, align 8
  %6 = bitcast %"class.marl::lock"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %6) #10
  %7 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %2, i64 0, i32 0, i32 0
  %8 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %2, i64 0, i32 0, i32 1
  %9 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %5, i64 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %6, i8 -86, i64 16, i1 false) #10
  store %"class.std::__1::mutex"* %9, %"class.std::__1::mutex"** %7, align 8
  store i8 1, i8* %8, align 8
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %9) #11
  %10 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %5, i64 0, i32 1
  %11 = bitcast %class.anon* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %11) #10
  %12 = getelementptr inbounds %class.anon, %class.anon* %3, i64 0, i32 0
  store %"struct.marl::Event::Shared"* %5, %"struct.marl::Event::Shared"** %12, align 8
  call void @_ZN4marl17ConditionVariable4waitIZNS_5Event6Shared4waitEvEUlvE_EEvRNS_4lockEOT_(%"class.marl::ConditionVariable"* %10, %"class.marl::lock"* nonnull dereferenceable(16) %2, %class.anon* nonnull dereferenceable(8) %3) #11
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %11) #10
  %13 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %5, i64 0, i32 3
  %14 = load i8, i8* %13, align 8
  %15 = icmp eq i8 %14, 0
  br i1 %15, label %16, label %18

16:                                               ; preds = %1
  %17 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %5, i64 0, i32 4
  store i8 0, i8* %17, align 1
  br label %18

18:                                               ; preds = %16, %1
  %19 = load i8, i8* %8, align 8, !range !2
  %20 = icmp eq i8 %19, 0
  br i1 %20, label %23, label %21

21:                                               ; preds = %18
  %22 = load %"class.std::__1::mutex"*, %"class.std::__1::mutex"** %7, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %22) #11
  br label %23

23:                                               ; preds = %18, %21
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %6) #10
  ret void
}

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable
define hidden void @_ZN2vk5Query3setEl(%"class.vk::Query"* nocapture, i64) local_unnamed_addr #2 align 2 {
  %3 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %1, i64* %3 seq_cst, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable
define hidden void @_ZN2vk5Query3addEl(%"class.vk::Query"* nocapture, i64) local_unnamed_addr #2 align 2 {
  %3 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %4 = atomicrmw add i64* %3, i64 %1 seq_cst
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk9QueryPoolC2EPK21VkQueryPoolCreateInfoPv(%"class.vk::QueryPool"* nocapture, %struct.VkQueryPoolCreateInfo* nocapture readonly, i8*) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 0
  %5 = bitcast %"class.vk::QueryPool"* %0 to i8**
  store i8* %2, i8** %5, align 8
  %6 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 1
  %7 = getelementptr inbounds %struct.VkQueryPoolCreateInfo, %struct.VkQueryPoolCreateInfo* %1, i64 0, i32 3
  %8 = load i32, i32* %7, align 4
  store i32 %8, i32* %6, align 8
  %9 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 2
  %10 = getelementptr inbounds %struct.VkQueryPoolCreateInfo, %struct.VkQueryPoolCreateInfo* %1, i64 0, i32 4
  %11 = load i32, i32* %10, align 8
  store i32 %11, i32* %9, align 4
  %12 = icmp eq i32 %8, 1
  br i1 %12, label %13, label %15

13:                                               ; preds = %3
  tail call void (i8*, ...) @_ZN2sw4warnEPKcz(i8* getelementptr inbounds ([79 x i8], [79 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.1, i64 0, i64 0), i32 96) #11
  %14 = load i32, i32* %9, align 4
  br label %15

15:                                               ; preds = %13, %3
  %16 = phi i32 [ %14, %13 ], [ %11, %3 ]
  %17 = icmp eq i32 %16, 0
  br i1 %17, label %18, label %19

18:                                               ; preds = %19, %15
  ret void

19:                                               ; preds = %15, %19
  %20 = phi i64 [ %24, %19 ], [ 0, %15 ]
  %21 = load %"class.vk::Query"*, %"class.vk::Query"** %4, align 8
  %22 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %21, i64 %20
  %23 = load i32, i32* %6, align 8
  tail call void @_ZN2vk5QueryC2E11VkQueryType(%"class.vk::Query"* %22, i32 %23) #12
  %24 = add nuw nsw i64 %20, 1
  %25 = load i32, i32* %9, align 4
  %26 = zext i32 %25 to i64
  %27 = icmp ult i64 %24, %26
  br i1 %27, label %19, label %18
}

; Function Attrs: optsize
declare void @_ZN2sw4warnEPKcz(i8*, ...) local_unnamed_addr #3

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk9QueryPool7destroyEPK21VkAllocationCallbacks(%"class.vk::QueryPool"* nocapture readonly, %struct.VkAllocationCallbacks*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 2
  %4 = load i32, i32* %3, align 4
  %5 = icmp eq i32 %4, 0
  br i1 %5, label %8, label %6

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 0
  br label %11

8:                                                ; preds = %11, %2
  %9 = bitcast %"class.vk::QueryPool"* %0 to i8**
  %10 = load i8*, i8** %9, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* %10, %struct.VkAllocationCallbacks* %1) #11
  ret void

11:                                               ; preds = %6, %11
  %12 = phi i64 [ 0, %6 ], [ %16, %11 ]
  %13 = load %"class.vk::Query"*, %"class.vk::Query"** %7, align 8
  %14 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %13, i64 %12, i32 1, i32 0
  tail call void @_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev(%"class.std::__1::shared_ptr.44"* %14) #11
  %15 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %13, i64 %12, i32 0, i32 0
  tail call void @_ZNSt3__110shared_ptrIN4marl9WaitGroup4DataEED2Ev(%"class.std::__1::shared_ptr"* %15) #11
  %16 = add nuw nsw i64 %12, 1
  %17 = load i32, i32* %3, align 4
  %18 = zext i32 %17 to i64
  %19 = icmp ult i64 %16, %18
  br i1 %19, label %11, label %8
}

; Function Attrs: optsize
declare void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8*, %struct.VkAllocationCallbacks*) local_unnamed_addr #3

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i64 @_ZN2vk9QueryPool29ComputeRequiredAllocationSizeEPK21VkQueryPoolCreateInfo(%struct.VkQueryPoolCreateInfo* nocapture readonly) local_unnamed_addr #4 align 2 {
  %2 = getelementptr inbounds %struct.VkQueryPoolCreateInfo, %struct.VkQueryPoolCreateInfo* %0, i64 0, i32 4
  %3 = load i32, i32* %2, align 8
  %4 = zext i32 %3 to i64
  %5 = mul nuw nsw i64 %4, 48
  ret i64 %5
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZNK2vk9QueryPool10getResultsEjjmPvmj(%"class.vk::QueryPool"* nocapture readonly, i32, i32, i64, i8* nocapture, i64, i32) local_unnamed_addr #0 align 2 {
  %8 = add i32 %2, %1
  %9 = icmp ugt i32 %8, %1
  br i1 %9, label %10, label %22

10:                                               ; preds = %7
  %11 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 0
  %12 = and i32 %6, 2
  %13 = icmp ne i32 %12, 0
  %14 = lshr i32 %6, 3
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = and i32 %6, 1
  %18 = icmp eq i32 %17, 0
  %19 = and i32 %6, 4
  %20 = icmp eq i32 %19, 0
  %21 = zext i32 %1 to i64
  br label %24

22:                                               ; preds = %58, %7
  %23 = phi i32 [ 0, %7 ], [ %39, %58 ]
  ret i32 %23

24:                                               ; preds = %58, %10
  %25 = phi i64 [ %21, %10 ], [ %59, %58 ]
  %26 = phi i32 [ 0, %10 ], [ %39, %58 ]
  %27 = phi i8* [ %4, %10 ], [ %60, %58 ]
  %28 = load %"class.vk::Query"*, %"class.vk::Query"** %11, align 8
  br i1 %13, label %29, label %31

29:                                               ; preds = %24
  %30 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %28, i64 %25
  tail call void @_ZN2vk5Query4waitEv(%"class.vk::Query"* %30) #12
  br label %31

31:                                               ; preds = %29, %24
  %32 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %28, i64 %25, i32 2, i32 0, i32 0, i32 0, i32 0
  %33 = load atomic i32, i32* %32 seq_cst, align 4
  %34 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %28, i64 %25, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %35 = load atomic i64, i64* %34 seq_cst, align 8
  switch i32 %33, label %38 [
    i32 1, label %37
    i32 0, label %36
  ]

36:                                               ; preds = %31
  br i1 %13, label %38, label %37

37:                                               ; preds = %31, %36
  br label %38

38:                                               ; preds = %31, %37, %36
  %39 = phi i32 [ 1, %37 ], [ %26, %36 ], [ %26, %31 ]
  %40 = phi i8 [ %16, %37 ], [ 1, %36 ], [ 1, %31 ]
  %41 = icmp eq i8 %40, 0
  br i1 %18, label %50, label %42

42:                                               ; preds = %38
  br i1 %41, label %45, label %43

43:                                               ; preds = %42
  %44 = bitcast i8* %27 to i64*
  store i64 %35, i64* %44, align 8
  br label %45

45:                                               ; preds = %42, %43
  br i1 %20, label %58, label %46

46:                                               ; preds = %45
  %47 = zext i32 %33 to i64
  %48 = getelementptr inbounds i8, i8* %27, i64 8
  %49 = bitcast i8* %48 to i64*
  store i64 %47, i64* %49, align 8
  br label %58

50:                                               ; preds = %38
  br i1 %41, label %54, label %51

51:                                               ; preds = %50
  %52 = bitcast i8* %27 to i32*
  %53 = trunc i64 %35 to i32
  store i32 %53, i32* %52, align 4
  br label %54

54:                                               ; preds = %50, %51
  br i1 %20, label %58, label %55

55:                                               ; preds = %54
  %56 = getelementptr inbounds i8, i8* %27, i64 4
  %57 = bitcast i8* %56 to i32*
  store i32 %33, i32* %57, align 4
  br label %58

58:                                               ; preds = %55, %54, %46, %45
  %59 = add nuw nsw i64 %25, 1
  %60 = getelementptr inbounds i8, i8* %27, i64 %5
  %61 = trunc i64 %59 to i32
  %62 = icmp eq i32 %8, %61
  br i1 %62, label %22, label %24
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk9QueryPool5beginEjj(%"class.vk::QueryPool"* nocapture readonly, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = icmp ugt i32 %2, 1
  br i1 %4, label %5, label %6

5:                                                ; preds = %3
  tail call void (i8*, ...) @_ZN2sw4warnEPKcz(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.2, i64 0, i64 0), i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.1, i64 0, i64 0), i32 191, i32 %2) #11
  br label %6

6:                                                ; preds = %5, %3
  %7 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 0
  %8 = load %"class.vk::Query"*, %"class.vk::Query"** %7, align 8
  %9 = zext i32 %1 to i64
  %10 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %8, i64 %9, i32 2, i32 0, i32 0, i32 0, i32 0
  %11 = atomicrmw xchg i32* %10, i32 1 seq_cst
  %12 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %8, i64 %9, i32 0, i32 0, i32 0
  %13 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %12, align 8
  %14 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %15 = atomicrmw add i32* %14, i32 1 seq_cst
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk9QueryPool3endEj(%"class.vk::QueryPool"* nocapture readonly, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 0
  %4 = load %"class.vk::Query"*, %"class.vk::Query"** %3, align 8
  %5 = zext i32 %1 to i64
  %6 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %4, i64 %5
  tail call void @_ZN2vk5Query6finishEv(%"class.vk::Query"* %6) #12
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk9QueryPool5resetEjj(%"class.vk::QueryPool"* nocapture readonly, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = add i32 %2, %1
  %5 = icmp ugt i32 %4, %1
  br i1 %5, label %6, label %9

6:                                                ; preds = %3
  %7 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 0
  %8 = zext i32 %1 to i64
  br label %10

9:                                                ; preds = %10, %3
  ret void

10:                                               ; preds = %10, %6
  %11 = phi i64 [ %8, %6 ], [ %21, %10 ]
  %12 = load %"class.vk::Query"*, %"class.vk::Query"** %7, align 8
  %13 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %12, i64 %11, i32 1, i32 0, i32 0
  %14 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %13, align 8
  %15 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %14, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %15) #11
  %16 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %13, align 8
  %17 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %16, i64 0, i32 4
  store i8 0, i8* %17, align 1
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %15) #11
  %18 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %12, i64 %11, i32 2, i32 0, i32 0, i32 0, i32 0
  %19 = atomicrmw xchg i32* %18, i32 0 seq_cst
  %20 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %12, i64 %11, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %20 seq_cst, align 8
  %21 = add nuw nsw i64 %11, 1
  %22 = trunc i64 %21 to i32
  %23 = icmp eq i32 %4, %22
  br i1 %23, label %9, label %10
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk9QueryPool14writeTimestampEj(%"class.vk::QueryPool"* nocapture readonly, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::QueryPool", %"class.vk::QueryPool"* %0, i64 0, i32 0
  %4 = load %"class.vk::Query"*, %"class.vk::Query"** %3, align 8
  %5 = zext i32 %1 to i64
  %6 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %4, i64 %5, i32 2, i32 0, i32 0, i32 0, i32 0
  %7 = atomicrmw xchg i32* %6, i32 1 seq_cst
  %8 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %4, i64 %5, i32 0, i32 0, i32 0
  %9 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %8, align 8
  %10 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %9, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %11 = atomicrmw add i32* %10, i32 1 seq_cst
  %12 = load %"class.vk::Query"*, %"class.vk::Query"** %3, align 8
  %13 = tail call i64 @_ZNSt3__16chrono12steady_clock3nowEv() #11
  %14 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %12, i64 %5, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %13, i64* %14 seq_cst, align 8
  %15 = load %"class.vk::Query"*, %"class.vk::Query"** %3, align 8
  %16 = getelementptr inbounds %"class.vk::Query", %"class.vk::Query"* %15, i64 %5
  tail call void @_ZN2vk5Query6finishEv(%"class.vk::Query"* %16) #12
  ret void
}

; Function Attrs: nounwind optsize
declare i64 @_ZNSt3__16chrono12steady_clock3nowEv() local_unnamed_addr #5

; Function Attrs: nobuiltin nofree optsize
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #6

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED2Ev(%"struct.std::__1::__shared_ptr_emplace"*) unnamed_addr #7 comdat align 2 {
  %2 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 0
  tail call void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"* %3) #11
  ret void
}

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED0Ev(%"struct.std::__1::__shared_ptr_emplace"*) unnamed_addr #7 comdat align 2 {
  %2 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 0
  tail call void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"* %3) #11
  %4 = bitcast %"struct.std::__1::__shared_ptr_emplace"* %0 to i8*
  tail call void @_ZdlPv(i8* %4) #9
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE16__on_zero_sharedEv(%"struct.std::__1::__shared_ptr_emplace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 1, i32 0, i64 96
  %3 = bitcast i8* %2 to %"class.std::__1::condition_variable"*
  tail call void @_ZNSt3__118condition_variableD1Ev(%"class.std::__1::condition_variable"* %3) #11
  %4 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 1, i32 0, i64 88
  %5 = bitcast i8* %4 to %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"**
  br label %6

6:                                                ; preds = %6, %1
  %7 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** [ %5, %1 ], [ %10, %6 ]
  %8 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %7, align 8
  %9 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %8, null
  %10 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %8, i64 0, i32 1
  br i1 %9, label %11, label %6

11:                                               ; preds = %6
  %12 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 1, i32 0, i64 72
  %13 = bitcast i8* %12 to %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"**
  %14 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %13, align 8
  %15 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %14, null
  br i1 %15, label %30, label %16

16:                                               ; preds = %11
  %17 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 1, i32 0, i64 48
  %18 = bitcast i8* %17 to %"class.marl::Allocator"**
  br label %19

19:                                               ; preds = %19, %16
  %20 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* [ %14, %16 ], [ %22, %19 ]
  %21 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %20, i64 0, i32 1
  %22 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %21, align 8
  %23 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %18, align 8
  %24 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %20, i64 0, i32 0
  %25 = bitcast %"class.marl::Allocator"* %23 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %26 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %25, align 8
  %27 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %26, i64 3
  %28 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %27, align 8
  tail call void %28(%"class.marl::Allocator"* %23, %"struct.marl::Allocation"* dereferenceable(32) %24) #11
  %29 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %22, null
  br i1 %29, label %30, label %19

30:                                               ; preds = %19, %11
  ret void
}

; Function Attrs: nounwind optsize
declare i8* @_ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info(%"class.std::__1::__shared_weak_count"*, %"class.std::type_info"* dereferenceable(16)) unnamed_addr #5

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE21__on_zero_shared_weakEv(%"struct.std::__1::__shared_ptr_emplace"*) unnamed_addr #0 comdat align 2 {
  %2 = bitcast %"struct.std::__1::__shared_ptr_emplace"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #9
  ret void
}

; Function Attrs: nobuiltin nounwind optsize
declare void @_ZdlPv(i8*) local_unnamed_addr #8

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variableD1Ev(%"class.std::__1::condition_variable"*) unnamed_addr #5

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__110shared_ptrIN4marl9WaitGroup4DataEED2Ev(%"class.std::__1::shared_ptr"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %0, i64 0, i32 1
  %3 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %2, align 8
  %4 = icmp eq %"class.std::__1::__shared_weak_count"* %3, null
  br i1 %4, label %15, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0, i32 1
  %7 = atomicrmw add i64* %6, i64 -1 acq_rel
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %9, label %15

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0
  %11 = bitcast %"class.std::__1::__shared_weak_count"* %3 to void (%"class.std::__1::__shared_count"*)***
  %12 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %11, align 8
  %13 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %12, i64 2
  %14 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %13, align 8
  tail call void %14(%"class.std::__1::__shared_count"* %10) #11
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %3) #11
  br label %15

15:                                               ; preds = %9, %5, %1
  ret void
}

; Function Attrs: nounwind optsize
declare void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"*) local_unnamed_addr #5

; Function Attrs: nounwind optsize
declare void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"*) unnamed_addr #5

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEED0Ev(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #7 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 0
  tail call void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"* %2) #11
  %3 = bitcast %"class.std::__1::__shared_ptr_pointer"* %0 to i8*
  tail call void @_ZdlPv(i8* %3) #9
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #0 comdat align 2 {
  %2 = alloca %"struct.marl::Allocation", align 8
  %3 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %4 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %3, align 8
  %5 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = icmp eq i64 %6, 0
  br i1 %7, label %11, label %8

8:                                                ; preds = %1
  %9 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 4
  %10 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %9 to %"class.std::__1::shared_ptr.44"**
  br label %16

11:                                               ; preds = %16, %1
  %12 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 5
  %13 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %12, i64 0, i32 0
  %14 = load i8*, i8** %13, align 8
  %15 = icmp eq i8* %14, null
  br i1 %15, label %32, label %23

16:                                               ; preds = %16, %8
  %17 = phi i64 [ 0, %8 ], [ %20, %16 ]
  %18 = load %"class.std::__1::shared_ptr.44"*, %"class.std::__1::shared_ptr.44"** %10, align 8
  %19 = getelementptr inbounds %"class.std::__1::shared_ptr.44", %"class.std::__1::shared_ptr.44"* %18, i64 %17
  tail call void @_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev(%"class.std::__1::shared_ptr.44"* %19) #11
  %20 = add nuw i64 %17, 1
  %21 = load i64, i64* %5, align 8
  %22 = icmp ult i64 %20, %21
  br i1 %22, label %16, label %11

23:                                               ; preds = %11
  %24 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 0
  %25 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %24, align 8
  %26 = bitcast %"class.marl::Allocator"* %25 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %27 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %26, align 8
  %28 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %27, i64 3
  %29 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %28, align 8
  tail call void %29(%"class.marl::Allocator"* %25, %"struct.marl::Allocation"* dereferenceable(32) %12) #11
  %30 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 4
  %31 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %30 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %31, i8 0, i64 34, i1 false) #10
  br label %32

32:                                               ; preds = %23, %11
  %33 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variableD1Ev(%"class.std::__1::condition_variable"* %33) #11
  %34 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 1, i32 1, i32 5
  br label %35

35:                                               ; preds = %35, %32
  %36 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** [ %34, %32 ], [ %39, %35 ]
  %37 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %36, align 8
  %38 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %37, null
  %39 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %37, i64 0, i32 1
  br i1 %38, label %40, label %35

40:                                               ; preds = %35
  %41 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 1, i32 1, i32 3
  %42 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %41, align 8
  %43 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %42, null
  br i1 %43, label %57, label %44

44:                                               ; preds = %40
  %45 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 1, i32 1, i32 0
  br label %46

46:                                               ; preds = %46, %44
  %47 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* [ %42, %44 ], [ %49, %46 ]
  %48 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %47, i64 0, i32 1
  %49 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %48, align 8
  %50 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %45, align 8
  %51 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %47, i64 0, i32 0
  %52 = bitcast %"class.marl::Allocator"* %50 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %53 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %52, align 8
  %54 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %53, i64 3
  %55 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %54, align 8
  tail call void %55(%"class.marl::Allocator"* %50, %"struct.marl::Allocation"* dereferenceable(32) %51) #11
  %56 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %49, null
  br i1 %56, label %57, label %46

57:                                               ; preds = %46, %40
  %58 = bitcast %"struct.marl::Allocation"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %58) #10
  %59 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 0
  %60 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %58, i8 -86, i64 32, i1 false) #10
  %61 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 2
  %62 = bitcast i8* %61 to i16*
  store i16 512, i16* %62, align 8
  %63 = bitcast %"struct.marl::Allocation"* %2 to %"struct.marl::Event::Shared"**
  store %"struct.marl::Event::Shared"* %4, %"struct.marl::Event::Shared"** %63, align 8
  %64 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 1, i32 0, i32 1
  %65 = load i64, i64* %64, align 8
  %66 = mul i64 %65, 272
  store i64 %66, i64* %59, align 8
  store i64 8, i64* %60, align 8
  %67 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 1, i32 0, i32 0
  %68 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %67, align 8
  %69 = bitcast %"class.marl::Allocator"* %68 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %70 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %69, align 8
  %71 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %70, i64 3
  %72 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %71, align 8
  call void %72(%"class.marl::Allocator"* %68, %"struct.marl::Allocation"* nonnull dereferenceable(32) %2) #11
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %58) #10
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #0 comdat align 2 {
  %2 = bitcast %"class.std::__1::__shared_ptr_pointer"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #9
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev(%"class.std::__1::shared_ptr.44"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::shared_ptr.44", %"class.std::__1::shared_ptr.44"* %0, i64 0, i32 1
  %3 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %2, align 8
  %4 = icmp eq %"class.std::__1::__shared_weak_count"* %3, null
  br i1 %4, label %15, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0, i32 1
  %7 = atomicrmw add i64* %6, i64 -1 acq_rel
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %9, label %15

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0
  %11 = bitcast %"class.std::__1::__shared_weak_count"* %3 to void (%"class.std::__1::__shared_count"*)***
  %12 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %11, align 8
  %13 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %12, i64 2
  %14 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %13, align 8
  tail call void %14(%"class.std::__1::__shared_count"* %10) #11
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %3) #11
  br label %15

15:                                               ; preds = %9, %5, %1
  ret void
}

; Function Attrs: optsize
declare void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"*) local_unnamed_addr #3

; Function Attrs: nounwind optsize
declare void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"*) local_unnamed_addr #5

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"*) local_unnamed_addr #3

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"*) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"*) local_unnamed_addr #7 comdat align 2 {
  %2 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %2) #11
  %3 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 4
  %4 = load i8, i8* %3, align 1, !range !2
  %5 = icmp eq i8 %4, 0
  br i1 %5, label %6, label %82

6:                                                ; preds = %1
  store i8 1, i8* %3, align 1
  %7 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 3
  %8 = load i8, i8* %7, align 8
  %9 = icmp eq i8 %8, 0
  %10 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1
  %11 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = load atomic i32, i32* %11 seq_cst, align 4
  %13 = icmp eq i32 %12, 0
  br i1 %9, label %14, label %31

14:                                               ; preds = %6
  br i1 %13, label %50, label %15

15:                                               ; preds = %14
  %16 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %10, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %16) #11
  %17 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 1
  %18 = load i64, i64* %17, align 8
  %19 = icmp eq i64 %18, 0
  br i1 %19, label %25, label %20

20:                                               ; preds = %15
  %21 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %22 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %21, align 8
  %23 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %22, i64 0, i32 0
  %24 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %23, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %24) #11
  br label %25

25:                                               ; preds = %20, %15
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %16) #11
  %26 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %27 = load atomic i32, i32* %26 seq_cst, align 4
  %28 = icmp sgt i32 %27, 0
  br i1 %28, label %29, label %50

29:                                               ; preds = %25
  %30 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_oneEv(%"class.std::__1::condition_variable"* %30) #11
  br label %50

31:                                               ; preds = %6
  br i1 %13, label %50, label %32

32:                                               ; preds = %31
  %33 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %10, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %33) #11
  %34 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %35 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %34, align 8
  %36 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %35, null
  br i1 %36, label %37, label %41

37:                                               ; preds = %41, %32
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %33) #11
  %38 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %39 = load atomic i32, i32* %38 seq_cst, align 4
  %40 = icmp sgt i32 %39, 0
  br i1 %40, label %48, label %50

41:                                               ; preds = %32, %41
  %42 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %46, %41 ], [ %35, %32 ]
  %43 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %42, i64 0, i32 0
  %44 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %43, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %44) #11
  %45 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %42, i64 0, i32 1
  %46 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %45, align 8
  %47 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %46, null
  br i1 %47, label %37, label %41

48:                                               ; preds = %37
  %49 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"* %49) #11
  br label %50

50:                                               ; preds = %48, %37, %31, %29, %25, %14
  %51 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 2, i32 4
  %52 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %51 to %"class.std::__1::shared_ptr.44"**
  %53 = load %"class.std::__1::shared_ptr.44"*, %"class.std::__1::shared_ptr.44"** %52, align 8
  %54 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 2, i32 1
  %55 = load i64, i64* %54, align 8
  %56 = getelementptr inbounds %"class.std::__1::shared_ptr.44", %"class.std::__1::shared_ptr.44"* %53, i64 %55
  %57 = icmp eq i64 %55, 0
  br i1 %57, label %82, label %58

58:                                               ; preds = %50, %79
  %59 = phi %"class.std::__1::shared_ptr.44"* [ %80, %79 ], [ %53, %50 ]
  %60 = bitcast %"class.std::__1::shared_ptr.44"* %59 to i64*
  %61 = load i64, i64* %60, align 8
  %62 = getelementptr inbounds %"class.std::__1::shared_ptr.44", %"class.std::__1::shared_ptr.44"* %59, i64 0, i32 1
  %63 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %62, align 8
  %64 = icmp eq %"class.std::__1::__shared_weak_count"* %63, null
  br i1 %64, label %65, label %67

65:                                               ; preds = %58
  %66 = inttoptr i64 %61 to %"struct.marl::Event::Shared"*
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %66) #12
  br label %79

67:                                               ; preds = %58
  %68 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %63, i64 0, i32 0, i32 1
  %69 = atomicrmw add i64* %68, i64 1 monotonic
  %70 = inttoptr i64 %61 to %"struct.marl::Event::Shared"*
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %70) #12
  %71 = atomicrmw add i64* %68, i64 -1 acq_rel
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %73, label %79

73:                                               ; preds = %67
  %74 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %63, i64 0, i32 0
  %75 = bitcast %"class.std::__1::__shared_weak_count"* %63 to void (%"class.std::__1::__shared_count"*)***
  %76 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %75, align 8
  %77 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %76, i64 2
  %78 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %77, align 8
  tail call void %78(%"class.std::__1::__shared_count"* %74) #11
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %63) #11
  br label %79

79:                                               ; preds = %65, %67, %73
  %80 = getelementptr inbounds %"class.std::__1::shared_ptr.44", %"class.std::__1::shared_ptr.44"* %59, i64 1
  %81 = icmp eq %"class.std::__1::shared_ptr.44"* %80, %56
  br i1 %81, label %82, label %58

82:                                               ; preds = %79, %50, %1
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %2) #11
  ret void
}

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable10notify_oneEv(%"class.std::__1::condition_variable"*) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN4marl17ConditionVariable4waitIZNS_5Event6Shared4waitEvEUlvE_EEvRNS_4lockEOT_(%"class.marl::ConditionVariable"*, %"class.marl::lock"* dereferenceable(16), %class.anon* dereferenceable(8)) local_unnamed_addr #7 comdat align 2 {
  %4 = alloca %"struct.marl::Allocation::Request", align 8
  %5 = alloca %"struct.marl::Allocation", align 8
  %6 = alloca %"class.std::__1::function.175", align 8
  %7 = getelementptr inbounds %class.anon, %class.anon* %2, i64 0, i32 0
  %8 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %7, align 8
  %9 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %8, i64 0, i32 4
  %10 = load i8, i8* %9, align 1, !range !2
  %11 = icmp eq i8 %10, 0
  br i1 %11, label %12, label %167

12:                                               ; preds = %3
  %13 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %14 = atomicrmw add i32* %13, i32 1 seq_cst
  %15 = tail call %"class.marl::Scheduler::Fiber"* @_ZN4marl9Scheduler5Fiber7currentEv() #11
  %16 = ptrtoint %"class.marl::Scheduler::Fiber"* %15 to i64
  %17 = icmp eq %"class.marl::Scheduler::Fiber"* %15, null
  br i1 %17, label %151, label %18

18:                                               ; preds = %12
  %19 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %19) #11
  %20 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 4
  %21 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %22 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %21, null
  br i1 %22, label %25, label %23

23:                                               ; preds = %18
  %24 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20 to i64*
  br label %74

25:                                               ; preds = %18
  %26 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 2
  %27 = load i64, i64* %26, align 8
  %28 = icmp ugt i64 %27, 8
  %29 = select i1 %28, i64 %27, i64 8
  %30 = mul i64 %29, 24
  %31 = add i64 %30, 40
  %32 = bitcast %"struct.marl::Allocation::Request"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %32) #10
  %33 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 0
  %34 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %32, i8 -86, i64 24, i1 false) #10
  %35 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 2
  %36 = bitcast i8* %35 to i16*
  store i16 1024, i16* %36, align 8
  store i64 %31, i64* %33, align 8
  store i64 8, i64* %34, align 8
  %37 = bitcast %"struct.marl::Allocation"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %37) #10
  %38 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %37, i8 -86, i64 32, i1 false) #10
  %39 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %38, align 8
  %40 = bitcast %"class.marl::Allocator"* %39 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  %41 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %40, align 8
  %42 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %41, i64 2
  %43 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %42, align 8
  call void %43(%"struct.marl::Allocation"* nonnull sret %5, %"class.marl::Allocator"* %39, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %4) #11
  %44 = bitcast %"struct.marl::Allocation"* %5 to %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"**
  %45 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %44, align 8
  %46 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20 to i64*
  br label %47

47:                                               ; preds = %58, %25
  %48 = phi i64 [ 0, %25 ], [ %59, %58 ]
  %49 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %45, i64 %48
  %50 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %45, i64 %48, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* null, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %50, align 8
  %51 = load i64, i64* %46, align 8
  %52 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %45, i64 %48, i32 1
  %53 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %52 to i64*
  store i64 %51, i64* %53, align 8
  %54 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %55 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %54, null
  br i1 %55, label %58, label %56

56:                                               ; preds = %47
  %57 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %54, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %49, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %57, align 8
  br label %58

58:                                               ; preds = %56, %47
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %49, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %59 = add nuw i64 %48, 1
  %60 = icmp eq i64 %59, %29
  br i1 %60, label %61, label %47

61:                                               ; preds = %58
  %62 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %5, i64 0, i32 0
  %63 = load i8*, i8** %62, align 8
  %64 = getelementptr inbounds i8, i8* %63, i64 %30
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %64, i8* nonnull align 8 %37, i64 32, i1 false) #10
  %65 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 3
  %66 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %65 to i64*
  %67 = load i64, i64* %66, align 8
  %68 = getelementptr inbounds i8, i8* %64, i64 32
  %69 = bitcast i8* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %65 to i8**
  store i8* %64, i8** %70, align 8
  %71 = load i64, i64* %26, align 8
  %72 = add i64 %71, %29
  store i64 %72, i64* %26, align 8
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %37) #10
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %32) #10
  %73 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  br label %74

74:                                               ; preds = %61, %23
  %75 = phi i64* [ %24, %23 ], [ %46, %61 ]
  %76 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %21, %23 ], [ %73, %61 ]
  %77 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, i64 0, i32 1
  %78 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77 to i64*
  %79 = load i64, i64* %78, align 8
  store i64 %79, i64* %75, align 8
  %80 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, i64 0, i32 2
  %81 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %80, align 8
  %82 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %81, null
  br i1 %82, label %87, label %83

83:                                               ; preds = %74
  %84 = load i64, i64* %78, align 8
  %85 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %81, i64 0, i32 1
  %86 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %85 to i64*
  store i64 %84, i64* %86, align 8
  br label %87

87:                                               ; preds = %83, %74
  %88 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77, align 8
  %89 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %88, null
  br i1 %89, label %95, label %90

90:                                               ; preds = %87
  %91 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %80 to i64*
  %92 = load i64, i64* %91, align 8
  %93 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %88, i64 0, i32 2
  %94 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %93 to i64*
  store i64 %92, i64* %94, align 8
  br label %95

95:                                               ; preds = %90, %87
  %96 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %96, i8 0, i64 16, i1 false) #10
  %97 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 5
  %98 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97, align 8
  %99 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %98, null
  br i1 %99, label %103, label %100

100:                                              ; preds = %95
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %98, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77, align 8
  %101 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97, align 8
  %102 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %101, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %102, align 8
  br label %103

103:                                              ; preds = %95, %100
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97, align 8
  %104 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76 to i64*
  store i64 %16, i64* %104, align 8
  %105 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 1
  %106 = load i64, i64* %105, align 8
  %107 = add i64 %106, 1
  store i64 %107, i64* %105, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %19) #11
  %108 = bitcast %"class.std::__1::function.175"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %108) #10
  %109 = bitcast %class.anon* %2 to i64*
  %110 = load i64, i64* %109, align 8
  %111 = getelementptr inbounds %"class.std::__1::function.175", %"class.std::__1::function.175"* %6, i64 0, i32 0, i32 1, i32 0
  %112 = getelementptr inbounds %"class.std::__1::function.175", %"class.std::__1::function.175"* %6, i64 0, i32 0, i32 2
  store i1 (%"union.std::__1::__function::__policy_storage"*)* @_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE, i1 (%"union.std::__1::__function::__policy_storage"*)** %111, align 8
  store %"struct.std::__1::__function::__policy"* @_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_, %"struct.std::__1::__function::__policy"** %112, align 8
  %113 = bitcast %"class.std::__1::function.175"* %6 to i64*
  store i64 %110, i64* %113, align 8
  call void @_ZN4marl9Scheduler5Fiber4waitERNS_4lockERKNSt3__18functionIFbvEEE(%"class.marl::Scheduler::Fiber"* nonnull %15, %"class.marl::lock"* dereferenceable(16) %1, %"class.std::__1::function.175"* nonnull dereferenceable(32) %6) #11
  %114 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %112, align 8
  %115 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %114, i64 0, i32 1
  %116 = load void (i8*)*, void (i8*)** %115, align 8
  %117 = icmp eq void (i8*)* %116, null
  br i1 %117, label %121, label %118

118:                                              ; preds = %103
  %119 = getelementptr inbounds %"class.std::__1::function.175", %"class.std::__1::function.175"* %6, i64 0, i32 0, i32 0, i32 0
  %120 = load i8*, i8** %119, align 8
  call void %116(i8* %120) #11
  br label %121

121:                                              ; preds = %103, %118
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %108) #10
  call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %19) #11
  %122 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97, align 8
  %123 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %122, %76
  br i1 %123, label %124, label %127

124:                                              ; preds = %121
  %125 = load i64, i64* %78, align 8
  %126 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97 to i64*
  store i64 %125, i64* %126, align 8
  br label %127

127:                                              ; preds = %124, %121
  %128 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %80, align 8
  %129 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %128, null
  br i1 %129, label %134, label %130

130:                                              ; preds = %127
  %131 = load i64, i64* %78, align 8
  %132 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %128, i64 0, i32 1
  %133 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %132 to i64*
  store i64 %131, i64* %133, align 8
  br label %134

134:                                              ; preds = %130, %127
  %135 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77, align 8
  %136 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %135, null
  br i1 %136, label %142, label %137

137:                                              ; preds = %134
  %138 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %80 to i64*
  %139 = load i64, i64* %138, align 8
  %140 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %135, i64 0, i32 2
  %141 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %140 to i64*
  store i64 %139, i64* %141, align 8
  br label %142

142:                                              ; preds = %137, %134
  call void @llvm.memset.p0i8.i64(i8* align 8 %96, i8 0, i64 16, i1 false) #10
  %143 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %144 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %143, null
  br i1 %144, label %148, label %145

145:                                              ; preds = %142
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %143, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77, align 8
  %146 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %147 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %146, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %147, align 8
  br label %148

148:                                              ; preds = %142, %145
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %149 = load i64, i64* %105, align 8
  %150 = add i64 %149, -1
  store i64 %150, i64* %105, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %19) #11
  br label %165

151:                                              ; preds = %12
  %152 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %153 = atomicrmw add i32* %152, i32 1 seq_cst
  %154 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 2
  %155 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %1, i64 0, i32 0
  %156 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %7, align 8
  %157 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %156, i64 0, i32 4
  %158 = load i8, i8* %157, align 1, !range !2
  %159 = icmp eq i8 %158, 0
  br i1 %159, label %160, label %163

160:                                              ; preds = %151, %160
  tail call void @_ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE(%"class.std::__1::condition_variable"* %154, %"class.std::__1::unique_lock"* dereferenceable(16) %155) #11
  %161 = load i8, i8* %157, align 1, !range !2
  %162 = icmp eq i8 %161, 0
  br i1 %162, label %160, label %163

163:                                              ; preds = %160, %151
  %164 = atomicrmw sub i32* %152, i32 1 seq_cst
  br label %165

165:                                              ; preds = %163, %148
  %166 = atomicrmw sub i32* %13, i32 1 seq_cst
  br label %167

167:                                              ; preds = %3, %165
  ret void
}

; Function Attrs: optsize
declare %"class.marl::Scheduler::Fiber"* @_ZN4marl9Scheduler5Fiber7currentEv() local_unnamed_addr #3

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler5Fiber4waitERNS_4lockERKNSt3__18functionIFbvEEE(%"class.marl::Scheduler::Fiber"*, %"class.marl::lock"* dereferenceable(16), %"class.std::__1::function.175"* dereferenceable(32)) local_unnamed_addr #3

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE(%"union.std::__1::__function::__policy_storage"*) #0 comdat align 2 {
  %2 = bitcast %"union.std::__1::__function::__policy_storage"* %0 to %"struct.marl::Event::Shared"**
  %3 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %2, align 8
  %4 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %3, i64 0, i32 4
  %5 = load i8, i8* %4, align 1, !range !2
  %6 = icmp ne i8 %5, 0
  ret i1 %6
}

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE(%"class.std::__1::condition_variable"*, %"class.std::__1::unique_lock"* dereferenceable(16)) local_unnamed_addr #5

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

attributes #0 = { nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nofree norecurse nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { norecurse nounwind optsize readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nobuiltin nofree optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { inlinehint nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nobuiltin nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { builtin nounwind optsize }
attributes #10 = { nounwind }
attributes #11 = { nounwind optsize }
attributes #12 = { optsize }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i8 0, i8 2}
