; ModuleID = '../../third_party/swiftshader/src/WSI/VkSwapchainKHR.cpp'
source_filename = "../../third_party/swiftshader/src/WSI/VkSwapchainKHR.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.vk::SwapchainKHR" = type <{ %"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*, i32, i8, [3 x i8] }>
%"class.vk::SurfaceKHR" = type { i32 (...)**, %"class.vk::SwapchainKHR"* }
%"class.vk::PresentImage" = type <{ %"class.vk::Image"*, %"class.vk::DeviceMemory"*, i32, [4 x i8] }>
%"class.vk::Image" = type { %"class.vk::DeviceMemory"*, %"class.vk::Device"*, i64, i32, i32, %"class.vk::Format", %struct.VkExtent3D, i32, i32, i32, i32, i32, %"class.vk::Image"*, i32, %"class.marl::mutex", %"class.std::__1::unordered_set" }
%"class.vk::Device" = type opaque
%"class.vk::Format" = type { i32 }
%struct.VkExtent3D = type { i32, i32, i32 }
%"class.marl::mutex" = type { %"class.std::__1::mutex" }
%"class.std::__1::mutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr", %"class.std::__1::__compressed_pair.44", %"class.std::__1::__compressed_pair.49", %"class.std::__1::__compressed_pair.51", [4 x i8] }>
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem", %"struct.std::__1::__compressed_pair_elem.40" }
%"struct.std::__1::__compressed_pair_elem" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.40" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.41" }
%"class.std::__1::__compressed_pair.41" = type { %"struct.std::__1::__compressed_pair_elem.42" }
%"struct.std::__1::__compressed_pair_elem.42" = type { i64 }
%"class.std::__1::__compressed_pair.44" = type { %"struct.std::__1::__compressed_pair_elem.45" }
%"struct.std::__1::__compressed_pair_elem.45" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.49" = type <{ %"struct.std::__1::__compressed_pair_elem.42", %"struct.std::__1::__compressed_pair_elem.50", [4 x i8] }>
%"struct.std::__1::__compressed_pair_elem.50" = type { %"class.vk::Image::Subresource" }
%"class.vk::Image::Subresource" = type { %struct.VkImageSubresource }
%struct.VkImageSubresource = type { i32, i32, i32 }
%"class.std::__1::__compressed_pair.51" = type { %"struct.std::__1::__compressed_pair_elem.52" }
%"struct.std::__1::__compressed_pair_elem.52" = type { float }
%"class.vk::DeviceMemory" = type { i8*, i64, i32, %"class.vk::DeviceMemory::ExternalBase"*, %"class.vk::Device"* }
%"class.vk::DeviceMemory::ExternalBase" = type opaque
%struct.VkSwapchainCreateInfoKHR = type { i32, i8*, i32, %class.VkNonDispatchableHandle.21, i32, i32, i32, %struct.VkExtent2D, i32, i32, i32, i32, i32*, i32, i32, i32, i32, %class.VkNonDispatchableHandle.22 }
%class.VkNonDispatchableHandle.21 = type { i64 }
%struct.VkExtent2D = type { i32, i32 }
%class.VkNonDispatchableHandle.22 = type { i64 }
%class.VkNonDispatchableHandle = type { i64 }
%class.VkNonDispatchableHandle.0 = type { i64 }
%class.VkNonDispatchableHandle.1 = type { i64 }
%class.VkNonDispatchableHandle.2 = type { i64 }
%class.VkNonDispatchableHandle.3 = type { i64 }
%class.VkNonDispatchableHandle.4 = type { i64 }
%class.VkNonDispatchableHandle.5 = type { i64 }
%class.VkNonDispatchableHandle.6 = type { i64 }
%class.VkNonDispatchableHandle.7 = type { i64 }
%class.VkNonDispatchableHandle.8 = type { i64 }
%class.VkNonDispatchableHandle.9 = type { i64 }
%class.VkNonDispatchableHandle.10 = type { i64 }
%class.VkNonDispatchableHandle.11 = type { i64 }
%class.VkNonDispatchableHandle.12 = type { i64 }
%class.VkNonDispatchableHandle.13 = type { i64 }
%class.VkNonDispatchableHandle.14 = type { i64 }
%class.VkNonDispatchableHandle.15 = type { i64 }
%class.VkNonDispatchableHandle.16 = type { i64 }
%class.VkNonDispatchableHandle.17 = type { i64 }
%class.VkNonDispatchableHandle.18 = type { i64 }
%class.VkNonDispatchableHandle.19 = type { i64 }
%class.VkNonDispatchableHandle.20 = type { i64 }
%class.VkNonDispatchableHandle.23 = type { i64 }
%class.VkNonDispatchableHandle.24 = type { i64 }
%class.VkNonDispatchableHandle.25 = type { i64 }
%class.VkNonDispatchableHandle.26 = type { i64 }
%class.VkNonDispatchableHandle.27 = type { i64 }
%class.VkNonDispatchableHandle.28 = type { i64 }
%class.VkNonDispatchableHandle.29 = type { i64 }
%class.VkNonDispatchableHandle.30 = type { i64 }
%class.VkNonDispatchableHandle.31 = type { i64 }
%class.VkNonDispatchableHandle.32 = type { i64 }
%class.VkNonDispatchableHandle.33 = type { i64 }
%class.VkNonDispatchableHandle.34 = type { i64 }
%class.VkNonDispatchableHandle.35 = type { i64 }
%struct.VkAllocationCallbacks = type { i8*, i8* (i8*, i64, i64, i32)*, i8* (i8*, i8*, i64, i64, i32)*, void (i8*, i8*)*, void (i8*, i64, i32, i32)*, void (i8*, i64, i32, i32)* }
%struct.VkDevice_T = type opaque
%struct.VkImageCreateInfo = type { i32, i8*, i32, i32, i32, %struct.VkExtent3D, i32, i32, i32, i32, i32, i32, i32, i32*, i32 }
%struct.VkMemoryAllocateInfo = type { i32, i8*, i64, i32 }
%struct.VkMemoryRequirements = type { i64, i64, i32 }
%"class.vk::BinarySemaphore" = type { %"class.vk::Semaphore", %struct.VkAllocationCallbacks*, i32, %"class.marl::Event", %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"* }
%"class.vk::Semaphore" = type { i32 (...)**, i32, %"class.marl::mutex" }
%"class.marl::Event" = type { %"class.std::__1::shared_ptr" }
%"class.std::__1::shared_ptr" = type { %"struct.marl::Event::Shared"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::Event::Shared" = type <{ %"class.marl::mutex", %"class.marl::ConditionVariable", %"class.marl::containers::vector", i8, i8, [6 x i8] }>
%"class.marl::ConditionVariable" = type { %"class.marl::mutex", %"class.marl::containers::list", %"class.std::__1::condition_variable", %"struct.std::__1::atomic", %"struct.std::__1::atomic" }
%"class.marl::containers::list" = type { %"class.marl::Allocator"*, i64, i64, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"class.marl::Allocator" = type { i32 (...)** }
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain" = type { %"struct.marl::Allocation", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* }
%"struct.marl::Allocation" = type { i8*, %"struct.marl::Allocation::Request" }
%"struct.marl::Allocation::Request" = type <{ i64, i64, i8, i8, [6 x i8] }>
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry" = type { %"class.marl::Scheduler::Fiber"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"class.marl::Scheduler::Fiber" = type <{ i32, [4 x i8], %"class.std::__1::unique_ptr.68", %"class.marl::Scheduler::Worker"*, i32, [4 x i8] }>
%"class.std::__1::unique_ptr.68" = type { %"class.std::__1::__compressed_pair.69" }
%"class.std::__1::__compressed_pair.69" = type { %"struct.std::__1::__compressed_pair_elem.70", %"struct.std::__1::__compressed_pair_elem.71" }
%"struct.std::__1::__compressed_pair_elem.70" = type { %"class.marl::OSFiber"* }
%"class.marl::OSFiber" = type opaque
%"struct.std::__1::__compressed_pair_elem.71" = type { %"struct.marl::Allocator::Deleter" }
%"struct.marl::Allocator::Deleter" = type { %"class.marl::Allocator"*, i64 }
%"class.marl::Scheduler::Worker" = type <{ i32, i32, %"class.marl::Scheduler"*, %"class.std::__1::unique_ptr.95", %"class.marl::Scheduler::Fiber"*, %"class.marl::Thread", %"struct.marl::Scheduler::Worker::Work", %"class.std::__1::unordered_set.158", %"class.marl::containers::vector.178", %"class.marl::Scheduler::Worker::FastRnd", i8, [7 x i8] }>
%"class.marl::Scheduler" = type { %"struct.marl::Scheduler::Config", %"struct.std::__1::array", %"struct.std::__1::atomic.63", %"struct.std::__1::atomic.63", %"struct.std::__1::array.73", %"struct.marl::Scheduler::SingleThreadedWorkers" }
%"struct.marl::Scheduler::Config" = type { %"struct.marl::Scheduler::Config::WorkerThread", %"class.marl::Allocator"*, i64 }
%"struct.marl::Scheduler::Config::WorkerThread" = type { i32, %"class.std::__1::function", %"class.std::__1::shared_ptr.72" }
%"class.std::__1::function" = type { %"class.std::__1::__function::__policy_func" }
%"class.std::__1::__function::__policy_func" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker", %"struct.std::__1::__function::__policy"* }
%"union.std::__1::__function::__policy_storage" = type { i8*, [8 x i8] }
%"struct.std::__1::__function::__policy_invoker" = type { void (%"union.std::__1::__function::__policy_storage"*, i32)* }
%"struct.std::__1::__function::__policy" = type { i8* (i8*)*, void (i8*)*, i8, %"class.std::type_info"* }
%"class.std::type_info" = type { i32 (...)**, i8* }
%"class.std::__1::shared_ptr.72" = type { %"class.marl::Thread::Affinity::Policy"*, %"class.std::__1::__shared_weak_count"* }
%"class.marl::Thread::Affinity::Policy" = type { i32 (...)** }
%"struct.std::__1::array" = type { [8 x %"struct.std::__1::atomic"] }
%"struct.std::__1::atomic.63" = type { %"struct.std::__1::__atomic_base.64" }
%"struct.std::__1::__atomic_base.64" = type { %"struct.std::__1::__atomic_base.65" }
%"struct.std::__1::__atomic_base.65" = type { %"struct.std::__1::__cxx_atomic_impl.66" }
%"struct.std::__1::__cxx_atomic_impl.66" = type { %"struct.std::__1::__cxx_atomic_base_impl.67" }
%"struct.std::__1::__cxx_atomic_base_impl.67" = type { i32 }
%"struct.std::__1::array.73" = type { [256 x %"class.marl::Scheduler::Worker"*] }
%"struct.marl::Scheduler::SingleThreadedWorkers" = type { %"class.marl::mutex", %"class.std::__1::condition_variable", %"class.std::__1::unordered_map" }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table.74" }
%"class.std::__1::__hash_table.74" = type <{ %"class.std::__1::unique_ptr.75", %"class.std::__1::__compressed_pair.83", %"class.std::__1::__compressed_pair.87", %"class.std::__1::__compressed_pair.90", [4 x i8] }>
%"class.std::__1::unique_ptr.75" = type { %"class.std::__1::__compressed_pair.76" }
%"class.std::__1::__compressed_pair.76" = type { %"struct.std::__1::__compressed_pair_elem.77", %"struct.std::__1::__compressed_pair_elem.79" }
%"struct.std::__1::__compressed_pair_elem.77" = type { %"struct.std::__1::__hash_node_base.78"** }
%"struct.std::__1::__hash_node_base.78" = type { %"struct.std::__1::__hash_node_base.78"* }
%"struct.std::__1::__compressed_pair_elem.79" = type { %"class.std::__1::__bucket_list_deallocator.80" }
%"class.std::__1::__bucket_list_deallocator.80" = type { %"class.std::__1::__compressed_pair.81" }
%"class.std::__1::__compressed_pair.81" = type { %"struct.std::__1::__compressed_pair_elem.42", %"struct.std::__1::__compressed_pair_elem.82" }
%"struct.std::__1::__compressed_pair_elem.82" = type { %"struct.marl::StlAllocator" }
%"struct.marl::StlAllocator" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.83" = type { %"struct.std::__1::__compressed_pair_elem.84", %"struct.std::__1::__compressed_pair_elem.85" }
%"struct.std::__1::__compressed_pair_elem.84" = type { %"struct.std::__1::__hash_node_base.78" }
%"struct.std::__1::__compressed_pair_elem.85" = type { %"struct.marl::StlAllocator.86" }
%"struct.marl::StlAllocator.86" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.87" = type { %"struct.std::__1::__compressed_pair_elem.42" }
%"class.std::__1::__compressed_pair.90" = type { %"struct.std::__1::__compressed_pair_elem.52" }
%"class.std::__1::unique_ptr.95" = type { %"class.std::__1::__compressed_pair.96" }
%"class.std::__1::__compressed_pair.96" = type { %"struct.std::__1::__compressed_pair_elem.97", %"struct.std::__1::__compressed_pair_elem.71" }
%"struct.std::__1::__compressed_pair_elem.97" = type { %"class.marl::Scheduler::Fiber"* }
%"class.marl::Thread" = type { %"class.marl::Thread::Impl"* }
%"class.marl::Thread::Impl" = type opaque
%"struct.marl::Scheduler::Worker::Work" = type { %"struct.std::__1::atomic.98", i64, %"class.std::__1::deque", %"class.std::__1::deque.115", %"struct.marl::Scheduler::WaitingFibers", i8, %"class.std::__1::condition_variable", %"class.marl::mutex" }
%"struct.std::__1::atomic.98" = type { %"struct.std::__1::__atomic_base.99" }
%"struct.std::__1::__atomic_base.99" = type { %"struct.std::__1::__atomic_base.100" }
%"struct.std::__1::__atomic_base.100" = type { %"struct.std::__1::__cxx_atomic_impl.101" }
%"struct.std::__1::__cxx_atomic_impl.101" = type { %"struct.std::__1::__cxx_atomic_base_impl.102" }
%"struct.std::__1::__cxx_atomic_base_impl.102" = type { i64 }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.112" }
%"struct.std::__1::__split_buffer" = type { %"class.marl::Task"**, %"class.marl::Task"**, %"class.marl::Task"**, %"class.std::__1::__compressed_pair.108" }
%"class.marl::Task" = type <{ %"class.std::__1::function.103", i32, [4 x i8] }>
%"class.std::__1::function.103" = type { %"class.std::__1::__function::__policy_func.106" }
%"class.std::__1::__function::__policy_func.106" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker.107", %"struct.std::__1::__function::__policy"* }
%"struct.std::__1::__function::__policy_invoker.107" = type { void (%"union.std::__1::__function::__policy_storage"*)* }
%"class.std::__1::__compressed_pair.108" = type { %"struct.std::__1::__compressed_pair_elem.109", %"struct.std::__1::__compressed_pair_elem.110" }
%"struct.std::__1::__compressed_pair_elem.109" = type { %"class.marl::Task"** }
%"struct.std::__1::__compressed_pair_elem.110" = type { %"struct.marl::StlAllocator.111" }
%"struct.marl::StlAllocator.111" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.112" = type { %"struct.std::__1::__compressed_pair_elem.42", %"struct.std::__1::__compressed_pair_elem.113" }
%"struct.std::__1::__compressed_pair_elem.113" = type { %"struct.marl::StlAllocator.114" }
%"struct.marl::StlAllocator.114" = type { %"class.marl::Allocator"* }
%"class.std::__1::deque.115" = type { %"class.std::__1::__deque_base.116" }
%"class.std::__1::__deque_base.116" = type { %"struct.std::__1::__split_buffer.117", i64, %"class.std::__1::__compressed_pair.122" }
%"struct.std::__1::__split_buffer.117" = type { %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.std::__1::__compressed_pair.118" }
%"class.std::__1::__compressed_pair.118" = type { %"struct.std::__1::__compressed_pair_elem.119", %"struct.std::__1::__compressed_pair_elem.120" }
%"struct.std::__1::__compressed_pair_elem.119" = type { %"class.marl::Scheduler::Fiber"*** }
%"struct.std::__1::__compressed_pair_elem.120" = type { %"struct.marl::StlAllocator.121" }
%"struct.marl::StlAllocator.121" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.122" = type { %"struct.std::__1::__compressed_pair_elem.42", %"struct.std::__1::__compressed_pair_elem.123" }
%"struct.std::__1::__compressed_pair_elem.123" = type { %"struct.marl::StlAllocator.124" }
%"struct.marl::StlAllocator.124" = type { %"class.marl::Allocator"* }
%"struct.marl::Scheduler::WaitingFibers" = type { %"class.std::__1::set", %"class.std::__1::unordered_map.132" }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.125", %"class.std::__1::__compressed_pair.129" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type opaque
%"class.std::__1::__compressed_pair.125" = type { %"struct.std::__1::__compressed_pair_elem.126", %"struct.std::__1::__compressed_pair_elem.127" }
%"struct.std::__1::__compressed_pair_elem.126" = type { %"class.std::__1::__tree_end_node" }
%"struct.std::__1::__compressed_pair_elem.127" = type { %"struct.marl::StlAllocator.128" }
%"struct.marl::StlAllocator.128" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.129" = type { %"struct.std::__1::__compressed_pair_elem.42" }
%"class.std::__1::unordered_map.132" = type { %"class.std::__1::__hash_table.133" }
%"class.std::__1::__hash_table.133" = type <{ %"class.std::__1::unique_ptr.134", %"class.std::__1::__compressed_pair.143", %"class.std::__1::__compressed_pair.147", %"class.std::__1::__compressed_pair.152", [4 x i8] }>
%"class.std::__1::unique_ptr.134" = type { %"class.std::__1::__compressed_pair.135" }
%"class.std::__1::__compressed_pair.135" = type { %"struct.std::__1::__compressed_pair_elem.136", %"struct.std::__1::__compressed_pair_elem.138" }
%"struct.std::__1::__compressed_pair_elem.136" = type { %"struct.std::__1::__hash_node_base.137"** }
%"struct.std::__1::__hash_node_base.137" = type { %"struct.std::__1::__hash_node_base.137"* }
%"struct.std::__1::__compressed_pair_elem.138" = type { %"class.std::__1::__bucket_list_deallocator.139" }
%"class.std::__1::__bucket_list_deallocator.139" = type { %"class.std::__1::__compressed_pair.140" }
%"class.std::__1::__compressed_pair.140" = type { %"struct.std::__1::__compressed_pair_elem.42", %"struct.std::__1::__compressed_pair_elem.141" }
%"struct.std::__1::__compressed_pair_elem.141" = type { %"struct.marl::StlAllocator.142" }
%"struct.marl::StlAllocator.142" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.143" = type { %"struct.std::__1::__compressed_pair_elem.144", %"struct.std::__1::__compressed_pair_elem.145" }
%"struct.std::__1::__compressed_pair_elem.144" = type { %"struct.std::__1::__hash_node_base.137" }
%"struct.std::__1::__compressed_pair_elem.145" = type { %"struct.marl::StlAllocator.146" }
%"struct.marl::StlAllocator.146" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.147" = type { %"struct.std::__1::__compressed_pair_elem.42" }
%"class.std::__1::__compressed_pair.152" = type { %"struct.std::__1::__compressed_pair_elem.52" }
%"class.std::__1::unordered_set.158" = type { %"class.std::__1::__hash_table.159" }
%"class.std::__1::__hash_table.159" = type <{ %"class.std::__1::unique_ptr.160", %"class.std::__1::__compressed_pair.169", %"class.std::__1::__compressed_pair.173", %"class.std::__1::__compressed_pair.175", [4 x i8] }>
%"class.std::__1::unique_ptr.160" = type { %"class.std::__1::__compressed_pair.161" }
%"class.std::__1::__compressed_pair.161" = type { %"struct.std::__1::__compressed_pair_elem.162", %"struct.std::__1::__compressed_pair_elem.164" }
%"struct.std::__1::__compressed_pair_elem.162" = type { %"struct.std::__1::__hash_node_base.163"** }
%"struct.std::__1::__hash_node_base.163" = type { %"struct.std::__1::__hash_node_base.163"* }
%"struct.std::__1::__compressed_pair_elem.164" = type { %"class.std::__1::__bucket_list_deallocator.165" }
%"class.std::__1::__bucket_list_deallocator.165" = type { %"class.std::__1::__compressed_pair.166" }
%"class.std::__1::__compressed_pair.166" = type { %"struct.std::__1::__compressed_pair_elem.42", %"struct.std::__1::__compressed_pair_elem.167" }
%"struct.std::__1::__compressed_pair_elem.167" = type { %"struct.marl::StlAllocator.168" }
%"struct.marl::StlAllocator.168" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.169" = type { %"struct.std::__1::__compressed_pair_elem.170", %"struct.std::__1::__compressed_pair_elem.171" }
%"struct.std::__1::__compressed_pair_elem.170" = type { %"struct.std::__1::__hash_node_base.163" }
%"struct.std::__1::__compressed_pair_elem.171" = type { %"struct.marl::StlAllocator.172" }
%"struct.marl::StlAllocator.172" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.173" = type { %"struct.std::__1::__compressed_pair_elem.42" }
%"class.std::__1::__compressed_pair.175" = type { %"struct.std::__1::__compressed_pair_elem.52" }
%"class.marl::containers::vector.178" = type { %"class.marl::Allocator"*, i64, i64, [16 x %"struct.marl::aligned_storage<24, 8>::type"], %"struct.marl::aligned_storage<24, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<24, 8>::type" = type { [24 x i8] }
%"class.marl::Scheduler::Worker::FastRnd" = type { i64 }
%"class.std::__1::condition_variable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon, %union.anon.56, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon = type { i64 }
%union.anon.56 = type { i64 }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.58" }
%"struct.std::__1::__atomic_base.58" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"class.marl::containers::vector" = type { %"class.marl::Allocator"*, i64, i64, [1 x %"struct.marl::aligned_storage<16, 8>::type"], %"struct.marl::aligned_storage<16, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<16, 8>::type" = type { [16 x i8] }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.vk::BinarySemaphore::External" = type opaque
%"class.vk::Fence" = type { %"class.std::__1::shared_ptr.61" }
%"class.std::__1::shared_ptr.61" = type { %"class.sw::CountedEvent"*, %"class.std::__1::__shared_weak_count"* }
%"class.sw::CountedEvent" = type { %"class.marl::WaitGroup", %"class.marl::Event" }
%"class.marl::WaitGroup" = type { %"class.std::__1::shared_ptr.62" }
%"class.std::__1::shared_ptr.62" = type { %"struct.marl::WaitGroup::Data"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::WaitGroup::Data" = type { %"struct.std::__1::atomic.63", %"class.marl::ConditionVariable", %"class.marl::mutex" }

$_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm = comdat any

$_ZN2vk5Fence8completeEv = comdat any

$_ZN4marl5Event6Shared6signalEv = comdat any

@_ZN2vk12SwapchainKHRC1EPK24VkSwapchainCreateInfoKHRPv = hidden unnamed_addr alias void (%"class.vk::SwapchainKHR"*, %struct.VkSwapchainCreateInfoKHR*, i8*), void (%"class.vk::SwapchainKHR"*, %struct.VkSwapchainCreateInfoKHR*, i8*)* @_ZN2vk12SwapchainKHRC2EPK24VkSwapchainCreateInfoKHRPv

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv(%class.VkNonDispatchableHandle*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm(%class.VkNonDispatchableHandle*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle, %class.VkNonDispatchableHandle* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv(%class.VkNonDispatchableHandle.0*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.0* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm(%class.VkNonDispatchableHandle.0*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.0, %class.VkNonDispatchableHandle.0* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv(%class.VkNonDispatchableHandle.1*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.1* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm(%class.VkNonDispatchableHandle.1*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.1, %class.VkNonDispatchableHandle.1* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv(%class.VkNonDispatchableHandle.2*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.2* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm(%class.VkNonDispatchableHandle.2*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.2, %class.VkNonDispatchableHandle.2* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv(%class.VkNonDispatchableHandle.3*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.3* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm(%class.VkNonDispatchableHandle.3*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.3, %class.VkNonDispatchableHandle.3* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv(%class.VkNonDispatchableHandle.4*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.4* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm(%class.VkNonDispatchableHandle.4*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.4, %class.VkNonDispatchableHandle.4* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv(%class.VkNonDispatchableHandle.5*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.5* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm(%class.VkNonDispatchableHandle.5*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.5, %class.VkNonDispatchableHandle.5* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv(%class.VkNonDispatchableHandle.6*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.6* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm(%class.VkNonDispatchableHandle.6*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.6, %class.VkNonDispatchableHandle.6* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv(%class.VkNonDispatchableHandle.7*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.7* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm(%class.VkNonDispatchableHandle.7*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.7, %class.VkNonDispatchableHandle.7* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv(%class.VkNonDispatchableHandle.8*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.8* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm(%class.VkNonDispatchableHandle.8*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.8, %class.VkNonDispatchableHandle.8* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv(%class.VkNonDispatchableHandle.9*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.9* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm(%class.VkNonDispatchableHandle.9*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.9, %class.VkNonDispatchableHandle.9* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv(%class.VkNonDispatchableHandle.10*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.10* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm(%class.VkNonDispatchableHandle.10*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.10, %class.VkNonDispatchableHandle.10* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv(%class.VkNonDispatchableHandle.11*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.11* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm(%class.VkNonDispatchableHandle.11*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.11, %class.VkNonDispatchableHandle.11* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv(%class.VkNonDispatchableHandle.12*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.12* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm(%class.VkNonDispatchableHandle.12*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.12, %class.VkNonDispatchableHandle.12* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv(%class.VkNonDispatchableHandle.13*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.13* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm(%class.VkNonDispatchableHandle.13*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.13, %class.VkNonDispatchableHandle.13* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv(%class.VkNonDispatchableHandle.14*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.14* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm(%class.VkNonDispatchableHandle.14*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.14, %class.VkNonDispatchableHandle.14* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv(%class.VkNonDispatchableHandle.15*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.15* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm(%class.VkNonDispatchableHandle.15*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.15, %class.VkNonDispatchableHandle.15* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv(%class.VkNonDispatchableHandle.16*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.16* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm(%class.VkNonDispatchableHandle.16*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.16, %class.VkNonDispatchableHandle.16* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv(%class.VkNonDispatchableHandle.17*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.17* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm(%class.VkNonDispatchableHandle.17*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.17, %class.VkNonDispatchableHandle.17* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv(%class.VkNonDispatchableHandle.18*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.18* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm(%class.VkNonDispatchableHandle.18*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.18, %class.VkNonDispatchableHandle.18* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv(%class.VkNonDispatchableHandle.19*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.19* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm(%class.VkNonDispatchableHandle.19*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.19, %class.VkNonDispatchableHandle.19* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv(%class.VkNonDispatchableHandle.20*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.20* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm(%class.VkNonDispatchableHandle.20*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.20, %class.VkNonDispatchableHandle.20* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv(%class.VkNonDispatchableHandle.21*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.21* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm(%class.VkNonDispatchableHandle.21*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.21, %class.VkNonDispatchableHandle.21* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv(%class.VkNonDispatchableHandle.22*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.22* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm(%class.VkNonDispatchableHandle.22*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.22, %class.VkNonDispatchableHandle.22* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv(%class.VkNonDispatchableHandle.23*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.23* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm(%class.VkNonDispatchableHandle.23*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.23, %class.VkNonDispatchableHandle.23* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv(%class.VkNonDispatchableHandle.24*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.24* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm(%class.VkNonDispatchableHandle.24*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.24, %class.VkNonDispatchableHandle.24* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv(%class.VkNonDispatchableHandle.25*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.25* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm(%class.VkNonDispatchableHandle.25*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.25, %class.VkNonDispatchableHandle.25* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv(%class.VkNonDispatchableHandle.26*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.26* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm(%class.VkNonDispatchableHandle.26*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.26, %class.VkNonDispatchableHandle.26* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv(%class.VkNonDispatchableHandle.27*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.27* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm(%class.VkNonDispatchableHandle.27*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.27, %class.VkNonDispatchableHandle.27* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv(%class.VkNonDispatchableHandle.28*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.28* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm(%class.VkNonDispatchableHandle.28*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.28, %class.VkNonDispatchableHandle.28* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv(%class.VkNonDispatchableHandle.29*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.29* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm(%class.VkNonDispatchableHandle.29*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.29, %class.VkNonDispatchableHandle.29* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv(%class.VkNonDispatchableHandle.30*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.30* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm(%class.VkNonDispatchableHandle.30*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.30, %class.VkNonDispatchableHandle.30* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv(%class.VkNonDispatchableHandle.31*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.31* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm(%class.VkNonDispatchableHandle.31*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.31, %class.VkNonDispatchableHandle.31* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv(%class.VkNonDispatchableHandle.32*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.32* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm(%class.VkNonDispatchableHandle.32*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.32, %class.VkNonDispatchableHandle.32* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv(%class.VkNonDispatchableHandle.33*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.33* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm(%class.VkNonDispatchableHandle.33*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.33, %class.VkNonDispatchableHandle.33* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv(%class.VkNonDispatchableHandle.34*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.34* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm(%class.VkNonDispatchableHandle.34*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.34, %class.VkNonDispatchableHandle.34* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv(%class.VkNonDispatchableHandle.35*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.35* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm(%class.VkNonDispatchableHandle.35*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.35, %class.VkNonDispatchableHandle.35* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk12SwapchainKHRC2EPK24VkSwapchainCreateInfoKHRPv(%"class.vk::SwapchainKHR"* nocapture, %struct.VkSwapchainCreateInfoKHR* nocapture readonly, i8*) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %1, i64 0, i32 3, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.vk::SwapchainKHR"* %0 to i64*
  store i64 %5, i64* %6, align 8
  %7 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  %8 = bitcast %"class.vk::PresentImage"** %7 to i8**
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 2
  %10 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %1, i64 0, i32 4
  %11 = load i32, i32* %10, align 8
  store i32 %11, i32* %9, align 8
  %12 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 3
  store i8 0, i8* %12, align 4
  %13 = zext i32 %11 to i64
  %14 = mul nuw nsw i64 %13, 24
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2, i8 0, i64 %14, i1 false)
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk12SwapchainKHR7destroyEPK21VkAllocationCallbacks(%"class.vk::SwapchainKHR"* nocapture readonly, %struct.VkAllocationCallbacks*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 2
  %4 = load i32, i32* %3, align 8
  %5 = icmp eq i32 %4, 0
  br i1 %5, label %9, label %6

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  %8 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 0
  br label %13

9:                                                ; preds = %28, %2
  %10 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 3
  %11 = load i8, i8* %10, align 4, !range !2
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %33, label %36

13:                                               ; preds = %6, %28
  %14 = phi i32 [ %4, %6 ], [ %29, %28 ]
  %15 = phi i64 [ 0, %6 ], [ %30, %28 ]
  %16 = load %"class.vk::PresentImage"*, %"class.vk::PresentImage"** %7, align 8
  %17 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %16, i64 %15
  %18 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %16, i64 %15, i32 2
  %19 = load i32, i32* %18, align 8
  %20 = icmp eq i32 %19, 0
  br i1 %20, label %28, label %21

21:                                               ; preds = %13
  %22 = load %"class.vk::SurfaceKHR"*, %"class.vk::SurfaceKHR"** %8, align 8
  %23 = bitcast %"class.vk::SurfaceKHR"* %22 to void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)***
  %24 = load void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)**, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*** %23, align 8
  %25 = getelementptr inbounds void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %24, i64 5
  %26 = load void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %25, align 8
  tail call void %26(%"class.vk::SurfaceKHR"* %22, %"class.vk::PresentImage"* %17) #6
  tail call void @_ZN2vk12PresentImage5clearEv(%"class.vk::PresentImage"* %17) #6
  %27 = load i32, i32* %3, align 8
  br label %28

28:                                               ; preds = %13, %21
  %29 = phi i32 [ %14, %13 ], [ %27, %21 ]
  %30 = add nuw nsw i64 %15, 1
  %31 = zext i32 %29 to i64
  %32 = icmp ult i64 %30, %31
  br i1 %32, label %13, label %9

33:                                               ; preds = %9
  %34 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 0
  %35 = load %"class.vk::SurfaceKHR"*, %"class.vk::SurfaceKHR"** %34, align 8
  tail call void @_ZN2vk10SurfaceKHR21disassociateSwapchainEv(%"class.vk::SurfaceKHR"* %35) #6
  br label %36

36:                                               ; preds = %9, %33
  %37 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  %38 = bitcast %"class.vk::PresentImage"** %37 to i8**
  %39 = load i8*, i8** %38, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* %39, %struct.VkAllocationCallbacks* %1) #6
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: optsize
declare void @_ZN2vk12PresentImage5clearEv(%"class.vk::PresentImage"*) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: optsize
declare void @_ZN2vk10SurfaceKHR21disassociateSwapchainEv(%"class.vk::SurfaceKHR"*) local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8*, %struct.VkAllocationCallbacks*) local_unnamed_addr #2

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i64 @_ZN2vk12SwapchainKHR29ComputeRequiredAllocationSizeEPK24VkSwapchainCreateInfoKHR(%struct.VkSwapchainCreateInfoKHR* nocapture readonly) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %0, i64 0, i32 4
  %3 = load i32, i32* %2, align 8
  %4 = zext i32 %3 to i64
  %5 = mul nuw nsw i64 %4, 24
  ret i64 %5
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk12SwapchainKHR6retireEv(%"class.vk::SwapchainKHR"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 3
  %3 = load i8, i8* %2, align 4, !range !2
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %33

5:                                                ; preds = %1
  store i8 1, i8* %2, align 4
  %6 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 0
  %7 = load %"class.vk::SurfaceKHR"*, %"class.vk::SurfaceKHR"** %6, align 8
  tail call void @_ZN2vk10SurfaceKHR21disassociateSwapchainEv(%"class.vk::SurfaceKHR"* %7) #6
  %8 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 2
  %9 = load i32, i32* %8, align 8
  %10 = icmp eq i32 %9, 0
  br i1 %10, label %33, label %11

11:                                               ; preds = %5
  %12 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  br label %13

13:                                               ; preds = %11, %28
  %14 = phi i32 [ %9, %11 ], [ %29, %28 ]
  %15 = phi i64 [ 0, %11 ], [ %30, %28 ]
  %16 = load %"class.vk::PresentImage"*, %"class.vk::PresentImage"** %12, align 8
  %17 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %16, i64 %15
  %18 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %16, i64 %15, i32 2
  %19 = load i32, i32* %18, align 8
  %20 = icmp eq i32 %19, 1
  br i1 %20, label %21, label %28

21:                                               ; preds = %13
  %22 = load %"class.vk::SurfaceKHR"*, %"class.vk::SurfaceKHR"** %6, align 8
  %23 = bitcast %"class.vk::SurfaceKHR"* %22 to void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)***
  %24 = load void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)**, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*** %23, align 8
  %25 = getelementptr inbounds void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %24, i64 5
  %26 = load void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %25, align 8
  tail call void %26(%"class.vk::SurfaceKHR"* %22, %"class.vk::PresentImage"* %17) #6
  tail call void @_ZN2vk12PresentImage5clearEv(%"class.vk::PresentImage"* %17) #6
  %27 = load i32, i32* %8, align 8
  br label %28

28:                                               ; preds = %21, %13
  %29 = phi i32 [ %27, %21 ], [ %14, %13 ]
  %30 = add nuw nsw i64 %15, 1
  %31 = zext i32 %29 to i64
  %32 = icmp ult i64 %30, %31
  br i1 %32, label %13, label %33

33:                                               ; preds = %28, %5, %1
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk12SwapchainKHR11resetImagesEv(%"class.vk::SwapchainKHR"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 2
  %3 = load i32, i32* %2, align 8
  %4 = icmp eq i32 %3, 0
  br i1 %4, label %7, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  br label %8

7:                                                ; preds = %8, %1
  ret void

8:                                                ; preds = %5, %8
  %9 = phi i64 [ 0, %5 ], [ %12, %8 ]
  %10 = load %"class.vk::PresentImage"*, %"class.vk::PresentImage"** %6, align 8
  %11 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %10, i64 %9
  tail call void @_ZN2vk12PresentImage5clearEv(%"class.vk::PresentImage"* %11) #6
  %12 = add nuw nsw i64 %9, 1
  %13 = load i32, i32* %2, align 8
  %14 = zext i32 %13 to i64
  %15 = icmp ult i64 %12, %14
  br i1 %15, label %8, label %7
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk12SwapchainKHR12createImagesEP10VkDevice_TPK24VkSwapchainCreateInfoKHR(%"class.vk::SwapchainKHR"* nocapture readonly, %struct.VkDevice_T*, %struct.VkSwapchainCreateInfoKHR* nocapture readonly) local_unnamed_addr #0 align 2 {
  %4 = alloca %struct.VkImageCreateInfo, align 8
  %5 = alloca %struct.VkMemoryAllocateInfo, align 8
  %6 = alloca %struct.VkMemoryRequirements, align 8
  %7 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 2
  %8 = load i32, i32* %7, align 8
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %20, label %10

10:                                               ; preds = %3
  %11 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  br label %12

12:                                               ; preds = %12, %10
  %13 = phi i64 [ 0, %10 ], [ %16, %12 ]
  %14 = load %"class.vk::PresentImage"*, %"class.vk::PresentImage"** %11, align 8
  %15 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %14, i64 %13
  tail call void @_ZN2vk12PresentImage5clearEv(%"class.vk::PresentImage"* %15) #6
  %16 = add nuw nsw i64 %13, 1
  %17 = load i32, i32* %7, align 8
  %18 = zext i32 %17 to i64
  %19 = icmp ult i64 %16, %18
  br i1 %19, label %12, label %20

20:                                               ; preds = %12, %3
  %21 = phi i32 [ 0, %3 ], [ %17, %12 ]
  %22 = bitcast %struct.VkImageCreateInfo* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 88, i8* nonnull %22) #7
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %22, i8 0, i64 88, i1 false)
  %23 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 0
  store i32 14, i32* %23, align 8
  %24 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 2
  %25 = load i32, i32* %24, align 8
  %26 = and i32 %25, 1
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %30, label %28

28:                                               ; preds = %20
  %29 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 2
  store i32 64, i32* %29, align 8
  br label %30

30:                                               ; preds = %20, %28
  %31 = phi i32 [ 2048, %20 ], [ 2112, %28 ]
  %32 = and i32 %25, 2
  %33 = icmp eq i32 %32, 0
  br i1 %33, label %36, label %34

34:                                               ; preds = %30
  %35 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 2
  store i32 %31, i32* %35, align 8
  br label %36

36:                                               ; preds = %30, %34
  %37 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 3
  store i32 1, i32* %37, align 4
  %38 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 5
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 4
  store i32 %39, i32* %40, align 8
  %41 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 7, i32 1
  %42 = load i32, i32* %41, align 4
  %43 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 5, i32 1
  store i32 %42, i32* %43, align 4
  %44 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 7, i32 0
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 5, i32 0
  store i32 %45, i32* %46, align 4
  %47 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 5, i32 2
  store i32 1, i32* %47, align 4
  %48 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 6
  store i32 1, i32* %48, align 8
  %49 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 8
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 7
  store i32 %50, i32* %51, align 4
  %52 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 8
  store i32 1, i32* %52, align 8
  %53 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 9
  store i32 0, i32* %53, align 4
  %54 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 9
  %55 = load i32, i32* %54, align 8
  %56 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 10
  store i32 %55, i32* %56, align 8
  %57 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 10
  %58 = load i32, i32* %57, align 4
  %59 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 11
  store i32 %58, i32* %59, align 4
  %60 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 12
  %61 = bitcast i32** %60 to i64*
  %62 = load i64, i64* %61, align 8
  %63 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 13
  %64 = bitcast i32** %63 to i64*
  store i64 %62, i64* %64, align 8
  %65 = getelementptr inbounds %struct.VkSwapchainCreateInfoKHR, %struct.VkSwapchainCreateInfoKHR* %2, i64 0, i32 11
  %66 = load i32, i32* %65, align 8
  %67 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 12
  store i32 %66, i32* %67, align 8
  %68 = getelementptr inbounds %struct.VkImageCreateInfo, %struct.VkImageCreateInfo* %4, i64 0, i32 14
  store i32 1, i32* %68, align 8
  %69 = bitcast %struct.VkMemoryAllocateInfo* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %69) #7
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %69, i8 0, i64 32, i1 false)
  %70 = getelementptr inbounds %struct.VkMemoryAllocateInfo, %struct.VkMemoryAllocateInfo* %5, i64 0, i32 0
  store i32 5, i32* %70, align 8
  %71 = getelementptr inbounds %struct.VkMemoryAllocateInfo, %struct.VkMemoryAllocateInfo* %5, i64 0, i32 2
  store i64 0, i64* %71, align 8
  %72 = getelementptr inbounds %struct.VkMemoryAllocateInfo, %struct.VkMemoryAllocateInfo* %5, i64 0, i32 3
  store i32 0, i32* %72, align 8
  %73 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  %74 = bitcast %struct.VkMemoryRequirements* %6 to i8*
  %75 = icmp eq i32 %21, 0
  br i1 %75, label %101, label %76

76:                                               ; preds = %36
  %77 = getelementptr inbounds %struct.VkMemoryRequirements, %struct.VkMemoryRequirements* %6, i64 0, i32 0
  %78 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 0
  br label %79

79:                                               ; preds = %76, %91
  %80 = phi i64 [ 0, %76 ], [ %97, %91 ]
  %81 = load %"class.vk::PresentImage"*, %"class.vk::PresentImage"** %73, align 8
  %82 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %81, i64 %80
  %83 = call i32 @_ZN2vk12PresentImage13allocateImageEP10VkDevice_TRK17VkImageCreateInfo(%"class.vk::PresentImage"* %82, %struct.VkDevice_T* %1, %struct.VkImageCreateInfo* nonnull dereferenceable(88) %4) #6
  %84 = icmp eq i32 %83, 0
  br i1 %84, label %85, label %101

85:                                               ; preds = %79
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %74) #7
  %86 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %82, i64 0, i32 0
  %87 = load %"class.vk::Image"*, %"class.vk::Image"** %86, align 8
  call void @_ZNK2vk5Image21getMemoryRequirementsEv(%struct.VkMemoryRequirements* nonnull sret %6, %"class.vk::Image"* %87) #6
  %88 = load i64, i64* %77, align 8
  store i64 %88, i64* %71, align 8
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %74) #7
  %89 = call i32 @_ZN2vk12PresentImage26allocateAndBindImageMemoryEP10VkDevice_TRK20VkMemoryAllocateInfo(%"class.vk::PresentImage"* %82, %struct.VkDevice_T* %1, %struct.VkMemoryAllocateInfo* nonnull dereferenceable(32) %5) #6
  %90 = icmp eq i32 %89, 0
  br i1 %90, label %91, label %101

91:                                               ; preds = %85
  %92 = load %"class.vk::SurfaceKHR"*, %"class.vk::SurfaceKHR"** %78, align 8
  %93 = bitcast %"class.vk::SurfaceKHR"* %92 to void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)***
  %94 = load void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)**, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*** %93, align 8
  %95 = getelementptr inbounds void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %94, i64 4
  %96 = load void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %95, align 8
  call void %96(%"class.vk::SurfaceKHR"* %92, %"class.vk::PresentImage"* %82) #6
  %97 = add nuw nsw i64 %80, 1
  %98 = load i32, i32* %7, align 8
  %99 = zext i32 %98 to i64
  %100 = icmp ult i64 %97, %99
  br i1 %100, label %79, label %101

101:                                              ; preds = %79, %85, %91, %36
  %102 = phi i32 [ 0, %36 ], [ 0, %91 ], [ %89, %85 ], [ %83, %79 ]
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %69) #7
  call void @llvm.lifetime.end.p0i8(i64 88, i8* nonnull %22) #7
  ret i32 %102
}

; Function Attrs: optsize
declare i32 @_ZN2vk12PresentImage13allocateImageEP10VkDevice_TRK17VkImageCreateInfo(%"class.vk::PresentImage"*, %struct.VkDevice_T*, %struct.VkImageCreateInfo* dereferenceable(88)) local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZNK2vk5Image21getMemoryRequirementsEv(%struct.VkMemoryRequirements* sret, %"class.vk::Image"*) local_unnamed_addr #2

; Function Attrs: optsize
declare i32 @_ZN2vk12PresentImage26allocateAndBindImageMemoryEP10VkDevice_TRK20VkMemoryAllocateInfo(%"class.vk::PresentImage"*, %struct.VkDevice_T*, %struct.VkMemoryAllocateInfo* dereferenceable(32)) local_unnamed_addr #2

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i32 @_ZNK2vk12SwapchainKHR13getImageCountEv(%"class.vk::SwapchainKHR"* nocapture readonly) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 2
  %3 = load i32, i32* %2, align 8
  ret i32 %3
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZNK2vk12SwapchainKHR9getImagesEPjP23VkNonDispatchableHandleIP9VkImage_TE(%"class.vk::SwapchainKHR"* nocapture readonly, i32* nocapture, %class.VkNonDispatchableHandle.0* nocapture) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 2
  %5 = load i32, i32* %4, align 4
  %6 = load i32, i32* %1, align 4
  %7 = icmp ult i32 %5, %6
  %8 = select i1 %7, i32 %5, i32 %6
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %27, label %10

10:                                               ; preds = %3
  %11 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  br label %12

12:                                               ; preds = %10, %12
  %13 = phi i64 [ 0, %10 ], [ %18, %12 ]
  %14 = load %"class.vk::PresentImage"*, %"class.vk::PresentImage"** %11, align 8
  %15 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %14, i64 %13
  %16 = tail call i64 @_ZNK2vk12PresentImage9asVkImageEv(%"class.vk::PresentImage"* %15) #6
  %17 = getelementptr inbounds %class.VkNonDispatchableHandle.0, %class.VkNonDispatchableHandle.0* %2, i64 %13, i32 0
  store i64 %16, i64* %17, align 8
  %18 = add nuw nsw i64 %13, 1
  %19 = load i32, i32* %4, align 4
  %20 = load i32, i32* %1, align 4
  %21 = icmp ult i32 %19, %20
  %22 = select i1 %21, i32 %19, i32 %20
  %23 = zext i32 %22 to i64
  %24 = icmp ult i64 %18, %23
  br i1 %24, label %12, label %25

25:                                               ; preds = %12
  %26 = trunc i64 %18 to i32
  br label %27

27:                                               ; preds = %25, %3
  %28 = phi i32 [ 0, %3 ], [ %26, %25 ]
  store i32 %28, i32* %1, align 4
  %29 = load i32, i32* %4, align 8
  %30 = icmp ult i32 %28, %29
  %31 = select i1 %30, i32 5, i32 0
  ret i32 %31
}

; Function Attrs: optsize
declare i64 @_ZNK2vk12PresentImage9asVkImageEv(%"class.vk::PresentImage"*) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk12SwapchainKHR12getNextImageEmPNS_15BinarySemaphoreEPNS_5FenceEPj(%"class.vk::SwapchainKHR"* nocapture readonly, i64, %"class.vk::BinarySemaphore"*, %"class.vk::Fence"*, i32* nocapture) local_unnamed_addr #0 align 2 {
  %6 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 2
  %7 = load i32, i32* %6, align 8
  %8 = icmp eq i32 %7, 0
  br i1 %8, label %28, label %9

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  %11 = load %"class.vk::PresentImage"*, %"class.vk::PresentImage"** %10, align 8
  %12 = zext i32 %7 to i64
  br label %13

13:                                               ; preds = %9, %25
  %14 = phi i64 [ 0, %9 ], [ %26, %25 ]
  %15 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %11, i64 %14, i32 2
  %16 = load i32, i32* %15, align 8
  %17 = icmp eq i32 %16, 1
  br i1 %17, label %18, label %25

18:                                               ; preds = %13
  %19 = trunc i64 %14 to i32
  store i32 2, i32* %15, align 8
  store i32 %19, i32* %4, align 4
  %20 = icmp eq %"class.vk::BinarySemaphore"* %2, null
  br i1 %20, label %22, label %21

21:                                               ; preds = %18
  tail call void @_ZN2vk15BinarySemaphore6signalEv(%"class.vk::BinarySemaphore"* nonnull %2) #6
  br label %22

22:                                               ; preds = %18, %21
  %23 = icmp eq %"class.vk::Fence"* %3, null
  br i1 %23, label %31, label %24

24:                                               ; preds = %22
  tail call void @_ZN2vk5Fence8completeEv(%"class.vk::Fence"* nonnull %3) #8
  br label %31

25:                                               ; preds = %13
  %26 = add nuw nsw i64 %14, 1
  %27 = icmp ult i64 %26, %12
  br i1 %27, label %13, label %28

28:                                               ; preds = %25, %5
  %29 = icmp eq i64 %1, 0
  %30 = select i1 %29, i32 1, i32 2
  br label %31

31:                                               ; preds = %24, %22, %28
  %32 = phi i32 [ %30, %28 ], [ 0, %22 ], [ 0, %24 ]
  ret i32 %32
}

; Function Attrs: optsize
declare void @_ZN2vk15BinarySemaphore6signalEv(%"class.vk::BinarySemaphore"*) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk5Fence8completeEv(%"class.vk::Fence"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::Fence", %"class.vk::Fence"* %0, i64 0, i32 0, i32 0
  %3 = load %"class.sw::CountedEvent"*, %"class.sw::CountedEvent"** %2, align 8
  %4 = getelementptr inbounds %"class.sw::CountedEvent", %"class.sw::CountedEvent"* %3, i64 0, i32 0, i32 0, i32 0
  %5 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %4, align 8
  %6 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = atomicrmw add i32* %6, i32 1 seq_cst
  %8 = load %"class.sw::CountedEvent"*, %"class.sw::CountedEvent"** %2, align 8
  %9 = getelementptr inbounds %"class.sw::CountedEvent", %"class.sw::CountedEvent"* %8, i64 0, i32 0, i32 0, i32 0
  %10 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %9, align 8
  %11 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %10, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = atomicrmw sub i32* %11, i32 1 seq_cst
  %13 = icmp eq i32 %12, 1
  br i1 %13, label %14, label %42

14:                                               ; preds = %1
  %15 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %9, align 8
  %16 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %15, i64 0, i32 2, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %16) #6
  %17 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %9, align 8
  %18 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %17, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %19 = load atomic i32, i32* %18 seq_cst, align 4
  %20 = icmp eq i32 %19, 0
  br i1 %20, label %39, label %21

21:                                               ; preds = %14
  %22 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %17, i64 0, i32 1, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %22) #6
  %23 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %17, i64 0, i32 1, i32 1, i32 5
  %24 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %23, align 8
  %25 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %24, null
  br i1 %25, label %26, label %30

26:                                               ; preds = %30, %21
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %22) #6
  %27 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %17, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %28 = load atomic i32, i32* %27 seq_cst, align 4
  %29 = icmp sgt i32 %28, 0
  br i1 %29, label %37, label %39

30:                                               ; preds = %21, %30
  %31 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %35, %30 ], [ %24, %21 ]
  %32 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %31, i64 0, i32 0
  %33 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %32, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %33) #6
  %34 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %31, i64 0, i32 1
  %35 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %34, align 8
  %36 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %35, null
  br i1 %36, label %26, label %30

37:                                               ; preds = %26
  %38 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %17, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"* %38) #6
  br label %39

39:                                               ; preds = %14, %26, %37
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %16) #6
  %40 = getelementptr inbounds %"class.sw::CountedEvent", %"class.sw::CountedEvent"* %8, i64 0, i32 1, i32 0, i32 0
  %41 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %40, align 8
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %41) #6
  br label %42

42:                                               ; preds = %1, %39
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk12SwapchainKHR7presentEj(%"class.vk::SwapchainKHR"* nocapture readonly, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 1
  %4 = load %"class.vk::PresentImage"*, %"class.vk::PresentImage"** %3, align 8
  %5 = zext i32 %1 to i64
  %6 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %4, i64 %5
  %7 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %4, i64 %5, i32 2
  store i32 3, i32* %7, align 8
  %8 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 0
  %9 = load %"class.vk::SurfaceKHR"*, %"class.vk::SurfaceKHR"** %8, align 8
  %10 = bitcast %"class.vk::SurfaceKHR"* %9 to i32 (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)***
  %11 = load i32 (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)**, i32 (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*** %10, align 8
  %12 = getelementptr inbounds i32 (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, i32 (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %11, i64 6
  %13 = load i32 (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, i32 (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %12, align 8
  %14 = tail call i32 %13(%"class.vk::SurfaceKHR"* %9, %"class.vk::PresentImage"* %6) #6
  store i32 1, i32* %7, align 8
  %15 = getelementptr inbounds %"class.vk::SwapchainKHR", %"class.vk::SwapchainKHR"* %0, i64 0, i32 3
  %16 = load i8, i8* %15, align 4, !range !2
  %17 = icmp eq i8 %16, 0
  br i1 %17, label %24, label %18

18:                                               ; preds = %2
  %19 = load %"class.vk::SurfaceKHR"*, %"class.vk::SurfaceKHR"** %8, align 8
  %20 = bitcast %"class.vk::SurfaceKHR"* %19 to void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)***
  %21 = load void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)**, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*** %20, align 8
  %22 = getelementptr inbounds void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %21, i64 5
  %23 = load void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)*, void (%"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*)** %22, align 8
  tail call void %23(%"class.vk::SurfaceKHR"* %19, %"class.vk::PresentImage"* %6) #6
  tail call void @_ZN2vk12PresentImage5clearEv(%"class.vk::PresentImage"* %6) #6
  br label %24

24:                                               ; preds = %2, %18
  ret i32 %14
}

; Function Attrs: optsize
declare void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"*) local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"*) local_unnamed_addr #2

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"*) local_unnamed_addr #4

; Function Attrs: nounwind optsize
declare void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"*) local_unnamed_addr #4

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"*) local_unnamed_addr #5 comdat align 2 {
  %2 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %2) #6
  %3 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 4
  %4 = load i8, i8* %3, align 1, !range !2
  %5 = icmp eq i8 %4, 0
  br i1 %5, label %6, label %82

6:                                                ; preds = %1
  store i8 1, i8* %3, align 1
  %7 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 3
  %8 = load i8, i8* %7, align 8
  %9 = icmp eq i8 %8, 0
  %10 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1
  %11 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = load atomic i32, i32* %11 seq_cst, align 4
  %13 = icmp eq i32 %12, 0
  br i1 %9, label %14, label %31

14:                                               ; preds = %6
  br i1 %13, label %50, label %15

15:                                               ; preds = %14
  %16 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %10, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %16) #6
  %17 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 1
  %18 = load i64, i64* %17, align 8
  %19 = icmp eq i64 %18, 0
  br i1 %19, label %25, label %20

20:                                               ; preds = %15
  %21 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %22 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %21, align 8
  %23 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %22, i64 0, i32 0
  %24 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %23, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %24) #6
  br label %25

25:                                               ; preds = %20, %15
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %16) #6
  %26 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %27 = load atomic i32, i32* %26 seq_cst, align 4
  %28 = icmp sgt i32 %27, 0
  br i1 %28, label %29, label %50

29:                                               ; preds = %25
  %30 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_oneEv(%"class.std::__1::condition_variable"* %30) #6
  br label %50

31:                                               ; preds = %6
  br i1 %13, label %50, label %32

32:                                               ; preds = %31
  %33 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %10, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %33) #6
  %34 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %35 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %34, align 8
  %36 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %35, null
  br i1 %36, label %37, label %41

37:                                               ; preds = %41, %32
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %33) #6
  %38 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %39 = load atomic i32, i32* %38 seq_cst, align 4
  %40 = icmp sgt i32 %39, 0
  br i1 %40, label %48, label %50

41:                                               ; preds = %32, %41
  %42 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %46, %41 ], [ %35, %32 ]
  %43 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %42, i64 0, i32 0
  %44 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %43, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %44) #6
  %45 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %42, i64 0, i32 1
  %46 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %45, align 8
  %47 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %46, null
  br i1 %47, label %37, label %41

48:                                               ; preds = %37
  %49 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"* %49) #6
  br label %50

50:                                               ; preds = %48, %37, %31, %29, %25, %14
  %51 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 2, i32 4
  %52 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %51 to %"class.std::__1::shared_ptr"**
  %53 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %52, align 8
  %54 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 2, i32 1
  %55 = load i64, i64* %54, align 8
  %56 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %53, i64 %55
  %57 = icmp eq i64 %55, 0
  br i1 %57, label %82, label %58

58:                                               ; preds = %50, %79
  %59 = phi %"class.std::__1::shared_ptr"* [ %80, %79 ], [ %53, %50 ]
  %60 = bitcast %"class.std::__1::shared_ptr"* %59 to i64*
  %61 = load i64, i64* %60, align 8
  %62 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %59, i64 0, i32 1
  %63 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %62, align 8
  %64 = icmp eq %"class.std::__1::__shared_weak_count"* %63, null
  br i1 %64, label %65, label %67

65:                                               ; preds = %58
  %66 = inttoptr i64 %61 to %"struct.marl::Event::Shared"*
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %66) #8
  br label %79

67:                                               ; preds = %58
  %68 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %63, i64 0, i32 0, i32 1
  %69 = atomicrmw add i64* %68, i64 1 monotonic
  %70 = inttoptr i64 %61 to %"struct.marl::Event::Shared"*
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %70) #8
  %71 = atomicrmw add i64* %68, i64 -1 acq_rel
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %73, label %79

73:                                               ; preds = %67
  %74 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %63, i64 0, i32 0
  %75 = bitcast %"class.std::__1::__shared_weak_count"* %63 to void (%"class.std::__1::__shared_count"*)***
  %76 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %75, align 8
  %77 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %76, i64 2
  %78 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %77, align 8
  tail call void %78(%"class.std::__1::__shared_count"* %74) #6
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %63) #6
  br label %79

79:                                               ; preds = %65, %67, %73
  %80 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %59, i64 1
  %81 = icmp eq %"class.std::__1::shared_ptr"* %80, %56
  br i1 %81, label %82, label %58

82:                                               ; preds = %79, %50, %1
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %2) #6
  ret void
}

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable10notify_oneEv(%"class.std::__1::condition_variable"*) local_unnamed_addr #4

; Function Attrs: nounwind optsize
declare void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"*) local_unnamed_addr #4

attributes #0 = { nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { norecurse nounwind optsize readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { inlinehint nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind optsize }
attributes #7 = { nounwind }
attributes #8 = { optsize }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i8 0, i8 2}
