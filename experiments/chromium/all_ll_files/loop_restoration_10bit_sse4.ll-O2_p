; ModuleID = '../../third_party/libgav1/src/src/dsp/x86/loop_restoration_10bit_sse4.cc'
source_filename = "../../third_party/libgav1/src/src/dsp/x86/loop_restoration_10bit_sse4.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.libgav1::dsp::Dsp" = type { void (i8*, i8*, i32, i32, i8*, i64)*, void (i8*, i64, i8*, i32*)*, [2 x [3 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*]], [19 x void (i8*, i64, [32 x i16]*, i32)*], [19 x [3 x void ([32 x i16]*, i32, i32, i8*, i64)*]], [2 x [2 x [2 x [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i8*, i64)*]]]], [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i64)*], void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)*, void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i8*, i8, i8, i32, i32, i8*, i64)*, %"struct.libgav1::dsp::FilmGrainFuncs", void (i8*, i64, i8*, i8*, i8, i32, i32)*, [3 x void (i8*, i8*, i64, i8*, i64, i32, i32)*], void (i8*, i32, i32)*, void (i8*, i32)*, [19 x [10 x void (i8*, i64, i8*, i8*)*]], [4 x [5 x [2 x void (i8, i8, i32, i8*, i32, i32, i8*)*]]], [4 x [2 x void (i8*, i64, i32, i32, i32)*]], [2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*], [3 x [2 x void (i8*, i8*, i64, i8*, i64, i32, i32, i8*, i64)*]], void (%"struct.libgav1::ReferenceInfo"*, i32, i32, i32, i32, i32, i32, %"struct.libgav1::TemporalMotionField"*)*, [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32*, i32, %"union.libgav1::CompoundMotionVector"*)*], [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32, i32, %"struct.libgav1::MotionVector"*)*], [2 x void (i8*, i64, i32, i32, i8*, i64)*], void (i32, i32, i32, i8*)*, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, [6 x [6 x [2 x void (i8*, i8*, i8*, i64)*]]] }
%"struct.libgav1::dsp::FilmGrainFuncs" = type { [3 x void (%"struct.libgav1::FilmGrainParams"*, i8*)*], [2 x [4 x void (%"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i8*, i8*)*]], [2 x void (i8*, i32, i32, i32, i32, i32, i8*)*], void (i8*, i32, i32, i32, i32, i8*)*, void (i32, i8*, i8*, i8*)*, void (i8*, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64)*, [2 x void (i8, %"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64, i8*, i64)*] }
%"struct.libgav1::FilmGrainParams" = type { i8, i8, i8, i8, i8, i8, i8, i8, [14 x i8], [14 x i8], [10 x i8], [10 x i8], [10 x i8], [10 x i8], i8, i8, [24 x i8], [25 x i8], [25 x i8], i8, i16, i32, i32, i8, i8, i16, i8, i8, i16 }
%"struct.libgav1::RestorationUnitInfo" = type { i8, %"struct.libgav1::SgrProjInfo", [16 x i8], %"struct.libgav1::WienerInfo" }
%"struct.libgav1::SgrProjInfo" = type { i32, [2 x i32] }
%"struct.libgav1::WienerInfo" = type { [2 x i16], [28 x i8], [2 x [4 x i16]], [16 x i8] }
%"union.libgav1::RestorationBuffer" = type { %"struct.libgav1::SgrBuffer", [5024 x i8] }
%"struct.libgav1::SgrBuffer" = type { [1152 x i16], [1440 x i16], [1152 x i32], [1440 x i32], [1024 x i16], [768 x i16], [512 x i16], [1024 x i32], [768 x i32], [512 x i32], [288 x i8], [288 x i32] }
%"struct.libgav1::ReferenceInfo" = type { %"struct.std::__1::array", %"struct.std::__1::array.0", %"struct.std::__1::array.0", %"struct.std::__1::array.1", %"struct.std::__1::array.2", %"class.libgav1::Array2D", %"class.libgav1::Array2D.4" }
%"struct.std::__1::array" = type { [8 x i8] }
%"struct.std::__1::array.0" = type { [8 x i8] }
%"struct.std::__1::array.1" = type { [8 x i8] }
%"struct.std::__1::array.2" = type { [8 x i16] }
%"class.libgav1::Array2D" = type { %"class.std::__1::unique_ptr", i64, i64, %"class.libgav1::Array2DView" }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i8* }
%"class.libgav1::Array2DView" = type { i32, i32, i8* }
%"class.libgav1::Array2D.4" = type { %"class.std::__1::unique_ptr.5", i64, i64, %"class.libgav1::Array2DView.11" }
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.libgav1::MotionVector"* }
%"struct.libgav1::MotionVector" = type { %union.anon }
%union.anon = type { i32 }
%"class.libgav1::Array2DView.11" = type { i32, i32, %"struct.libgav1::MotionVector"* }
%"struct.libgav1::TemporalMotionField" = type { %"class.libgav1::Array2D.4", %"class.libgav1::Array2D.12" }
%"class.libgav1::Array2D.12" = type { %"class.std::__1::unique_ptr.13", i64, i64, %"class.libgav1::Array2DView.19" }
%"class.std::__1::unique_ptr.13" = type { %"class.std::__1::__compressed_pair.14" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.15" }
%"struct.std::__1::__compressed_pair_elem.15" = type { i8* }
%"class.libgav1::Array2DView.19" = type { i32, i32, i8* }
%"union.libgav1::CompoundMotionVector" = type { i64 }

@_ZN7libgav114kSgrProjParamsE = external local_unnamed_addr constant [16 x [4 x i8]], align 16
@_ZN7libgav118kSgrScaleParameterE = external local_unnamed_addr constant [16 x [2 x i16]], align 16
@_ZN7libgav13dsp12kSgrMaLookupE = external local_unnamed_addr constant [256 x i8], align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN7libgav13dsp31LoopRestorationInit10bpp_SSE4_1Ev() local_unnamed_addr #0 {
  %1 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 10) #5
  %2 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 19, i64 0
  %3 = bitcast void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)** %2 to <2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*>*
  store <2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*> <void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_119WienerFilter_SSE4_1ERKNS_19RestorationUnitInfoEPKvlS6_lS6_liiPNS_17RestorationBufferEPv, void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_123SelfGuidedFilter_SSE4_1ERKNS_19RestorationUnitInfoEPKvlS6_lS6_liiPNS_17RestorationBufferEPv>, <2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*>* %3, align 8
  ret void
}

declare %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_119WienerFilter_SSE4_1ERKNS_19RestorationUnitInfoEPKvlS6_lS6_liiPNS_17RestorationBufferEPv(%"struct.libgav1::RestorationUnitInfo"* nocapture readonly dereferenceable(96), i8* nocapture readonly, i64, i8* nocapture readonly, i64, i8* nocapture readonly, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8* nocapture) #2 {
  %12 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 3, i32 0, i64 0
  %13 = load i16, i16* %12, align 2
  %14 = sext i16 %13 to i32
  %15 = icmp sgt i32 %14, 1
  %16 = select i1 %15, i32 %14, i32 1
  %17 = add i32 %7, 15
  %18 = and i32 %17, -16
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 0
  %21 = zext i32 %16 to i64
  %22 = mul nsw i64 %21, %19
  %23 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %22
  %24 = shl nuw nsw i32 %16, 1
  %25 = sub nsw i32 6, %24
  %26 = ashr exact i32 %25, 1
  %27 = bitcast i8* %1 to i16*
  %28 = bitcast i8* %3 to i16*
  %29 = bitcast i8* %5 to i16*
  %30 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 3, i32 2, i64 1, i64 0
  %31 = bitcast i16* %30 to i64*
  %32 = load i64, i64* %31, align 1
  %33 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %32, i32 0
  %34 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 3, i32 0, i64 1
  %35 = load i16, i16* %34, align 2
  switch i16 %35, label %438 [
    i16 0, label %36
    i16 1, label %242
  ]

36:                                               ; preds = %11
  %37 = bitcast <2 x i64> %33 to <4 x i32>
  %38 = icmp eq i32 %25, 0
  br i1 %38, label %107, label %39

39:                                               ; preds = %36
  %40 = sub nsw i32 2, %26
  %41 = sext i32 %40 to i64
  %42 = mul nsw i64 %41, %4
  %43 = getelementptr inbounds i16, i16* %28, i64 %42
  %44 = getelementptr inbounds i16, i16* %43, i64 -3
  %45 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %46 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = bitcast <4 x i32> %46 to <8 x i16>
  %48 = bitcast <4 x i32> %45 to <8 x i16>
  br label %49

49:                                               ; preds = %102, %39
  %50 = phi i16* [ %23, %39 ], [ %104, %102 ]
  %51 = phi i16* [ %44, %39 ], [ %103, %102 ]
  %52 = phi i32 [ %26, %39 ], [ %105, %102 ]
  br label %53

53:                                               ; preds = %53, %49
  %54 = phi i64 [ %100, %53 ], [ 0, %49 ]
  %55 = getelementptr inbounds i16, i16* %51, i64 %54
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 1
  %58 = getelementptr inbounds i16, i16* %55, i64 1
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 1
  %61 = getelementptr inbounds i16, i16* %55, i64 2
  %62 = bitcast i16* %61 to <8 x i16>*
  %63 = load <8 x i16>, <8 x i16>* %62, align 1
  %64 = getelementptr inbounds i16, i16* %55, i64 3
  %65 = bitcast i16* %64 to <8 x i16>*
  %66 = load <8 x i16>, <8 x i16>* %65, align 1
  %67 = getelementptr inbounds i16, i16* %55, i64 4
  %68 = bitcast i16* %67 to <8 x i16>*
  %69 = load <8 x i16>, <8 x i16>* %68, align 1
  %70 = getelementptr inbounds i16, i16* %55, i64 5
  %71 = bitcast i16* %70 to <8 x i16>*
  %72 = load <8 x i16>, <8 x i16>* %71, align 1
  %73 = getelementptr inbounds i16, i16* %55, i64 6
  %74 = bitcast i16* %73 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 1
  %76 = add <8 x i16> %75, %57
  %77 = add <8 x i16> %72, %60
  %78 = add <8 x i16> %69, %63
  %79 = shufflevector <8 x i16> %76, <8 x i16> %77, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %80 = shufflevector <8 x i16> %76, <8 x i16> %77, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %81 = shufflevector <8 x i16> %78, <8 x i16> %66, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %82 = shufflevector <8 x i16> %78, <8 x i16> %66, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %83 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %79, <8 x i16> %47) #5
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> %47) #5
  %85 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %81, <8 x i16> %48) #5
  %86 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %82, <8 x i16> %48) #5
  %87 = getelementptr inbounds i16, i16* %50, i64 %54
  %88 = add <4 x i32> %83, <i32 4, i32 4, i32 4, i32 4>
  %89 = add <4 x i32> %88, %85
  %90 = add <4 x i32> %84, <i32 4, i32 4, i32 4, i32 4>
  %91 = add <4 x i32> %90, %86
  %92 = ashr <4 x i32> %89, <i32 3, i32 3, i32 3, i32 3>
  %93 = ashr <4 x i32> %91, <i32 3, i32 3, i32 3, i32 3>
  %94 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %92, <4 x i32> %93) #5
  %95 = icmp sgt <8 x i16> %94, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %97 = icmp slt <8 x i16> %96, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %99 = bitcast i16* %87 to <8 x i16>*
  store <8 x i16> %98, <8 x i16>* %99, align 16
  %100 = add nuw nsw i64 %54, 8
  %101 = icmp slt i64 %100, %19
  br i1 %101, label %53, label %102

102:                                              ; preds = %53
  %103 = getelementptr inbounds i16, i16* %51, i64 %4
  %104 = getelementptr inbounds i16, i16* %50, i64 %19
  %105 = add nsw i32 %52, -1
  %106 = icmp eq i32 %105, 0
  br i1 %106, label %107, label %49

107:                                              ; preds = %102, %36
  %108 = phi i16* [ %23, %36 ], [ %104, %102 ]
  %109 = icmp eq i32 %8, 0
  br i1 %109, label %175, label %110

110:                                              ; preds = %107
  %111 = getelementptr inbounds i8, i8* %1, i64 -6
  %112 = bitcast i8* %111 to i16*
  %113 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %114 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> zeroinitializer
  %115 = bitcast <4 x i32> %114 to <8 x i16>
  %116 = bitcast <4 x i32> %113 to <8 x i16>
  br label %117

117:                                              ; preds = %170, %110
  %118 = phi i16* [ %108, %110 ], [ %172, %170 ]
  %119 = phi i16* [ %112, %110 ], [ %171, %170 ]
  %120 = phi i32 [ %8, %110 ], [ %173, %170 ]
  br label %121

121:                                              ; preds = %121, %117
  %122 = phi i64 [ %168, %121 ], [ 0, %117 ]
  %123 = getelementptr inbounds i16, i16* %119, i64 %122
  %124 = bitcast i16* %123 to <8 x i16>*
  %125 = load <8 x i16>, <8 x i16>* %124, align 1
  %126 = getelementptr inbounds i16, i16* %123, i64 1
  %127 = bitcast i16* %126 to <8 x i16>*
  %128 = load <8 x i16>, <8 x i16>* %127, align 1
  %129 = getelementptr inbounds i16, i16* %123, i64 2
  %130 = bitcast i16* %129 to <8 x i16>*
  %131 = load <8 x i16>, <8 x i16>* %130, align 1
  %132 = getelementptr inbounds i16, i16* %123, i64 3
  %133 = bitcast i16* %132 to <8 x i16>*
  %134 = load <8 x i16>, <8 x i16>* %133, align 1
  %135 = getelementptr inbounds i16, i16* %123, i64 4
  %136 = bitcast i16* %135 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 1
  %138 = getelementptr inbounds i16, i16* %123, i64 5
  %139 = bitcast i16* %138 to <8 x i16>*
  %140 = load <8 x i16>, <8 x i16>* %139, align 1
  %141 = getelementptr inbounds i16, i16* %123, i64 6
  %142 = bitcast i16* %141 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 1
  %144 = add <8 x i16> %143, %125
  %145 = add <8 x i16> %140, %128
  %146 = add <8 x i16> %137, %131
  %147 = shufflevector <8 x i16> %144, <8 x i16> %145, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %148 = shufflevector <8 x i16> %144, <8 x i16> %145, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %149 = shufflevector <8 x i16> %146, <8 x i16> %134, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %150 = shufflevector <8 x i16> %146, <8 x i16> %134, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> %115) #5
  %152 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> %115) #5
  %153 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> %116) #5
  %154 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %150, <8 x i16> %116) #5
  %155 = getelementptr inbounds i16, i16* %118, i64 %122
  %156 = add <4 x i32> %151, <i32 4, i32 4, i32 4, i32 4>
  %157 = add <4 x i32> %156, %153
  %158 = add <4 x i32> %152, <i32 4, i32 4, i32 4, i32 4>
  %159 = add <4 x i32> %158, %154
  %160 = ashr <4 x i32> %157, <i32 3, i32 3, i32 3, i32 3>
  %161 = ashr <4 x i32> %159, <i32 3, i32 3, i32 3, i32 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %160, <4 x i32> %161) #5
  %163 = icmp sgt <8 x i16> %162, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %165 = icmp slt <8 x i16> %164, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %166 = select <8 x i1> %165, <8 x i16> %164, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %167 = bitcast i16* %155 to <8 x i16>*
  store <8 x i16> %166, <8 x i16>* %167, align 16
  %168 = add nuw nsw i64 %122, 8
  %169 = icmp slt i64 %168, %19
  br i1 %169, label %121, label %170

170:                                              ; preds = %121
  %171 = getelementptr inbounds i16, i16* %119, i64 %2
  %172 = getelementptr inbounds i16, i16* %118, i64 %19
  %173 = add nsw i32 %120, -1
  %174 = icmp eq i32 %173, 0
  br i1 %174, label %175, label %117

175:                                              ; preds = %170, %107
  %176 = phi i16* [ %108, %107 ], [ %172, %170 ]
  br i1 %38, label %708, label %177

177:                                              ; preds = %175
  %178 = getelementptr inbounds i8, i8* %5, i64 -6
  %179 = bitcast i8* %178 to i16*
  %180 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %181 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> zeroinitializer
  %182 = bitcast <4 x i32> %181 to <8 x i16>
  %183 = bitcast <4 x i32> %180 to <8 x i16>
  br label %184

184:                                              ; preds = %237, %177
  %185 = phi i16* [ %176, %177 ], [ %239, %237 ]
  %186 = phi i16* [ %179, %177 ], [ %238, %237 ]
  %187 = phi i32 [ %26, %177 ], [ %240, %237 ]
  br label %188

188:                                              ; preds = %188, %184
  %189 = phi i64 [ %235, %188 ], [ 0, %184 ]
  %190 = getelementptr inbounds i16, i16* %186, i64 %189
  %191 = bitcast i16* %190 to <8 x i16>*
  %192 = load <8 x i16>, <8 x i16>* %191, align 1
  %193 = getelementptr inbounds i16, i16* %190, i64 1
  %194 = bitcast i16* %193 to <8 x i16>*
  %195 = load <8 x i16>, <8 x i16>* %194, align 1
  %196 = getelementptr inbounds i16, i16* %190, i64 2
  %197 = bitcast i16* %196 to <8 x i16>*
  %198 = load <8 x i16>, <8 x i16>* %197, align 1
  %199 = getelementptr inbounds i16, i16* %190, i64 3
  %200 = bitcast i16* %199 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 1
  %202 = getelementptr inbounds i16, i16* %190, i64 4
  %203 = bitcast i16* %202 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 1
  %205 = getelementptr inbounds i16, i16* %190, i64 5
  %206 = bitcast i16* %205 to <8 x i16>*
  %207 = load <8 x i16>, <8 x i16>* %206, align 1
  %208 = getelementptr inbounds i16, i16* %190, i64 6
  %209 = bitcast i16* %208 to <8 x i16>*
  %210 = load <8 x i16>, <8 x i16>* %209, align 1
  %211 = add <8 x i16> %210, %192
  %212 = add <8 x i16> %207, %195
  %213 = add <8 x i16> %204, %198
  %214 = shufflevector <8 x i16> %211, <8 x i16> %212, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %215 = shufflevector <8 x i16> %211, <8 x i16> %212, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %213, <8 x i16> %201, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %217 = shufflevector <8 x i16> %213, <8 x i16> %201, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %218 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %214, <8 x i16> %182) #5
  %219 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %215, <8 x i16> %182) #5
  %220 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %216, <8 x i16> %183) #5
  %221 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %217, <8 x i16> %183) #5
  %222 = getelementptr inbounds i16, i16* %185, i64 %189
  %223 = add <4 x i32> %218, <i32 4, i32 4, i32 4, i32 4>
  %224 = add <4 x i32> %223, %220
  %225 = add <4 x i32> %219, <i32 4, i32 4, i32 4, i32 4>
  %226 = add <4 x i32> %225, %221
  %227 = ashr <4 x i32> %224, <i32 3, i32 3, i32 3, i32 3>
  %228 = ashr <4 x i32> %226, <i32 3, i32 3, i32 3, i32 3>
  %229 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %227, <4 x i32> %228) #5
  %230 = icmp sgt <8 x i16> %229, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %231 = select <8 x i1> %230, <8 x i16> %229, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %232 = icmp slt <8 x i16> %231, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %233 = select <8 x i1> %232, <8 x i16> %231, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %234 = bitcast i16* %222 to <8 x i16>*
  store <8 x i16> %233, <8 x i16>* %234, align 16
  %235 = add nuw nsw i64 %189, 8
  %236 = icmp slt i64 %235, %19
  br i1 %236, label %188, label %237

237:                                              ; preds = %188
  %238 = getelementptr inbounds i16, i16* %186, i64 %6
  %239 = getelementptr inbounds i16, i16* %185, i64 %19
  %240 = add nsw i32 %187, -1
  %241 = icmp eq i32 %240, 0
  br i1 %241, label %708, label %184

242:                                              ; preds = %11
  %243 = icmp eq i32 %25, 0
  br i1 %243, label %309, label %244

244:                                              ; preds = %242
  %245 = sub nsw i32 2, %26
  %246 = sext i32 %245 to i64
  %247 = mul nsw i64 %246, %4
  %248 = getelementptr inbounds i16, i16* %28, i64 %247
  %249 = getelementptr inbounds i16, i16* %248, i64 -2
  %250 = bitcast <2 x i64> %33 to <16 x i8>
  %251 = shufflevector <16 x i8> %250, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5>
  %252 = bitcast <16 x i8> %251 to <8 x i16>
  br label %253

253:                                              ; preds = %304, %244
  %254 = phi i16* [ %23, %244 ], [ %306, %304 ]
  %255 = phi i16* [ %249, %244 ], [ %305, %304 ]
  %256 = phi i32 [ %26, %244 ], [ %307, %304 ]
  br label %257

257:                                              ; preds = %257, %253
  %258 = phi i64 [ %302, %257 ], [ 0, %253 ]
  %259 = getelementptr inbounds i16, i16* %255, i64 %258
  %260 = bitcast i16* %259 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 1
  %262 = getelementptr inbounds i16, i16* %259, i64 1
  %263 = bitcast i16* %262 to <8 x i16>*
  %264 = load <8 x i16>, <8 x i16>* %263, align 1
  %265 = getelementptr inbounds i16, i16* %259, i64 2
  %266 = bitcast i16* %265 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 1
  %268 = getelementptr inbounds i16, i16* %259, i64 3
  %269 = bitcast i16* %268 to <8 x i16>*
  %270 = load <8 x i16>, <8 x i16>* %269, align 1
  %271 = getelementptr inbounds i16, i16* %259, i64 4
  %272 = bitcast i16* %271 to <8 x i16>*
  %273 = load <8 x i16>, <8 x i16>* %272, align 1
  %274 = add <8 x i16> %270, %264
  %275 = shl <8 x i16> %267, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %276 = sub <8 x i16> %261, %275
  %277 = add <8 x i16> %276, %273
  %278 = sub <8 x i16> %274, %275
  %279 = shufflevector <8 x i16> %277, <8 x i16> %278, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %280 = shufflevector <8 x i16> %277, <8 x i16> %278, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %281 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %279, <8 x i16> %252) #5
  %282 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %280, <8 x i16> %252) #5
  %283 = shufflevector <8 x i16> %267, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %284 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %285 = bitcast <8 x i16> %283 to <4 x i32>
  %286 = shl <4 x i32> %285, <i32 7, i32 7, i32 7, i32 7>
  %287 = bitcast <8 x i16> %284 to <4 x i32>
  %288 = shl <4 x i32> %287, <i32 7, i32 7, i32 7, i32 7>
  %289 = getelementptr inbounds i16, i16* %254, i64 %258
  %290 = add <4 x i32> %281, <i32 4, i32 4, i32 4, i32 4>
  %291 = add <4 x i32> %290, %286
  %292 = or <4 x i32> %288, <i32 4, i32 4, i32 4, i32 4>
  %293 = add <4 x i32> %292, %282
  %294 = ashr <4 x i32> %291, <i32 3, i32 3, i32 3, i32 3>
  %295 = ashr <4 x i32> %293, <i32 3, i32 3, i32 3, i32 3>
  %296 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %294, <4 x i32> %295) #5
  %297 = icmp sgt <8 x i16> %296, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %298 = select <8 x i1> %297, <8 x i16> %296, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %299 = icmp slt <8 x i16> %298, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %300 = select <8 x i1> %299, <8 x i16> %298, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %301 = bitcast i16* %289 to <8 x i16>*
  store <8 x i16> %300, <8 x i16>* %301, align 16
  %302 = add nuw nsw i64 %258, 8
  %303 = icmp slt i64 %302, %19
  br i1 %303, label %257, label %304

304:                                              ; preds = %257
  %305 = getelementptr inbounds i16, i16* %255, i64 %4
  %306 = getelementptr inbounds i16, i16* %254, i64 %19
  %307 = add nsw i32 %256, -1
  %308 = icmp eq i32 %307, 0
  br i1 %308, label %309, label %253

309:                                              ; preds = %304, %242
  %310 = phi i16* [ %23, %242 ], [ %306, %304 ]
  %311 = icmp eq i32 %8, 0
  br i1 %311, label %374, label %312

312:                                              ; preds = %309
  %313 = getelementptr inbounds i8, i8* %1, i64 -4
  %314 = bitcast i8* %313 to i16*
  %315 = bitcast <2 x i64> %33 to <16 x i8>
  %316 = shufflevector <16 x i8> %315, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5>
  %317 = bitcast <16 x i8> %316 to <8 x i16>
  br label %318

318:                                              ; preds = %369, %312
  %319 = phi i16* [ %310, %312 ], [ %371, %369 ]
  %320 = phi i16* [ %314, %312 ], [ %370, %369 ]
  %321 = phi i32 [ %8, %312 ], [ %372, %369 ]
  br label %322

322:                                              ; preds = %322, %318
  %323 = phi i64 [ %367, %322 ], [ 0, %318 ]
  %324 = getelementptr inbounds i16, i16* %320, i64 %323
  %325 = bitcast i16* %324 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 1
  %327 = getelementptr inbounds i16, i16* %324, i64 1
  %328 = bitcast i16* %327 to <8 x i16>*
  %329 = load <8 x i16>, <8 x i16>* %328, align 1
  %330 = getelementptr inbounds i16, i16* %324, i64 2
  %331 = bitcast i16* %330 to <8 x i16>*
  %332 = load <8 x i16>, <8 x i16>* %331, align 1
  %333 = getelementptr inbounds i16, i16* %324, i64 3
  %334 = bitcast i16* %333 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 1
  %336 = getelementptr inbounds i16, i16* %324, i64 4
  %337 = bitcast i16* %336 to <8 x i16>*
  %338 = load <8 x i16>, <8 x i16>* %337, align 1
  %339 = add <8 x i16> %335, %329
  %340 = shl <8 x i16> %332, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %341 = sub <8 x i16> %326, %340
  %342 = add <8 x i16> %341, %338
  %343 = sub <8 x i16> %339, %340
  %344 = shufflevector <8 x i16> %342, <8 x i16> %343, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %345 = shufflevector <8 x i16> %342, <8 x i16> %343, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %346 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %344, <8 x i16> %317) #5
  %347 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %345, <8 x i16> %317) #5
  %348 = shufflevector <8 x i16> %332, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %349 = shufflevector <8 x i16> %332, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %350 = bitcast <8 x i16> %348 to <4 x i32>
  %351 = shl <4 x i32> %350, <i32 7, i32 7, i32 7, i32 7>
  %352 = bitcast <8 x i16> %349 to <4 x i32>
  %353 = shl <4 x i32> %352, <i32 7, i32 7, i32 7, i32 7>
  %354 = getelementptr inbounds i16, i16* %319, i64 %323
  %355 = add <4 x i32> %346, <i32 4, i32 4, i32 4, i32 4>
  %356 = add <4 x i32> %355, %351
  %357 = or <4 x i32> %353, <i32 4, i32 4, i32 4, i32 4>
  %358 = add <4 x i32> %357, %347
  %359 = ashr <4 x i32> %356, <i32 3, i32 3, i32 3, i32 3>
  %360 = ashr <4 x i32> %358, <i32 3, i32 3, i32 3, i32 3>
  %361 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %359, <4 x i32> %360) #5
  %362 = icmp sgt <8 x i16> %361, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %363 = select <8 x i1> %362, <8 x i16> %361, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %364 = icmp slt <8 x i16> %363, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %365 = select <8 x i1> %364, <8 x i16> %363, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %366 = bitcast i16* %354 to <8 x i16>*
  store <8 x i16> %365, <8 x i16>* %366, align 16
  %367 = add nuw nsw i64 %323, 8
  %368 = icmp slt i64 %367, %19
  br i1 %368, label %322, label %369

369:                                              ; preds = %322
  %370 = getelementptr inbounds i16, i16* %320, i64 %2
  %371 = getelementptr inbounds i16, i16* %319, i64 %19
  %372 = add nsw i32 %321, -1
  %373 = icmp eq i32 %372, 0
  br i1 %373, label %374, label %318

374:                                              ; preds = %369, %309
  %375 = phi i16* [ %310, %309 ], [ %371, %369 ]
  br i1 %243, label %708, label %376

376:                                              ; preds = %374
  %377 = getelementptr inbounds i8, i8* %5, i64 -4
  %378 = bitcast i8* %377 to i16*
  %379 = bitcast <2 x i64> %33 to <16 x i8>
  %380 = shufflevector <16 x i8> %379, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5>
  %381 = bitcast <16 x i8> %380 to <8 x i16>
  br label %382

382:                                              ; preds = %433, %376
  %383 = phi i16* [ %375, %376 ], [ %435, %433 ]
  %384 = phi i16* [ %378, %376 ], [ %434, %433 ]
  %385 = phi i32 [ %26, %376 ], [ %436, %433 ]
  br label %386

386:                                              ; preds = %386, %382
  %387 = phi i64 [ %431, %386 ], [ 0, %382 ]
  %388 = getelementptr inbounds i16, i16* %384, i64 %387
  %389 = bitcast i16* %388 to <8 x i16>*
  %390 = load <8 x i16>, <8 x i16>* %389, align 1
  %391 = getelementptr inbounds i16, i16* %388, i64 1
  %392 = bitcast i16* %391 to <8 x i16>*
  %393 = load <8 x i16>, <8 x i16>* %392, align 1
  %394 = getelementptr inbounds i16, i16* %388, i64 2
  %395 = bitcast i16* %394 to <8 x i16>*
  %396 = load <8 x i16>, <8 x i16>* %395, align 1
  %397 = getelementptr inbounds i16, i16* %388, i64 3
  %398 = bitcast i16* %397 to <8 x i16>*
  %399 = load <8 x i16>, <8 x i16>* %398, align 1
  %400 = getelementptr inbounds i16, i16* %388, i64 4
  %401 = bitcast i16* %400 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 1
  %403 = add <8 x i16> %399, %393
  %404 = shl <8 x i16> %396, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %405 = sub <8 x i16> %390, %404
  %406 = add <8 x i16> %405, %402
  %407 = sub <8 x i16> %403, %404
  %408 = shufflevector <8 x i16> %406, <8 x i16> %407, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %409 = shufflevector <8 x i16> %406, <8 x i16> %407, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %410 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %408, <8 x i16> %381) #5
  %411 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %409, <8 x i16> %381) #5
  %412 = shufflevector <8 x i16> %396, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %413 = shufflevector <8 x i16> %396, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %414 = bitcast <8 x i16> %412 to <4 x i32>
  %415 = shl <4 x i32> %414, <i32 7, i32 7, i32 7, i32 7>
  %416 = bitcast <8 x i16> %413 to <4 x i32>
  %417 = shl <4 x i32> %416, <i32 7, i32 7, i32 7, i32 7>
  %418 = getelementptr inbounds i16, i16* %383, i64 %387
  %419 = add <4 x i32> %410, <i32 4, i32 4, i32 4, i32 4>
  %420 = add <4 x i32> %419, %415
  %421 = or <4 x i32> %417, <i32 4, i32 4, i32 4, i32 4>
  %422 = add <4 x i32> %421, %411
  %423 = ashr <4 x i32> %420, <i32 3, i32 3, i32 3, i32 3>
  %424 = ashr <4 x i32> %422, <i32 3, i32 3, i32 3, i32 3>
  %425 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %423, <4 x i32> %424) #5
  %426 = icmp sgt <8 x i16> %425, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %427 = select <8 x i1> %426, <8 x i16> %425, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %428 = icmp slt <8 x i16> %427, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %429 = select <8 x i1> %428, <8 x i16> %427, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %430 = bitcast i16* %418 to <8 x i16>*
  store <8 x i16> %429, <8 x i16>* %430, align 16
  %431 = add nuw nsw i64 %387, 8
  %432 = icmp slt i64 %431, %19
  br i1 %432, label %386, label %433

433:                                              ; preds = %386
  %434 = getelementptr inbounds i16, i16* %384, i64 %6
  %435 = getelementptr inbounds i16, i16* %383, i64 %19
  %436 = add nsw i32 %385, -1
  %437 = icmp eq i32 %436, 0
  br i1 %437, label %708, label %382

438:                                              ; preds = %11
  %439 = icmp eq i16 %35, 2
  %440 = sub nsw i32 2, %26
  %441 = sext i32 %440 to i64
  %442 = mul nsw i64 %441, %4
  %443 = getelementptr inbounds i16, i16* %28, i64 %442
  %444 = icmp eq i32 %25, 0
  br i1 %439, label %445, label %582

445:                                              ; preds = %438
  br i1 %444, label %489, label %446

446:                                              ; preds = %445
  %447 = getelementptr inbounds i16, i16* %443, i64 -1
  %448 = bitcast <2 x i64> %33 to <4 x i32>
  %449 = shufflevector <4 x i32> %448, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %450 = bitcast <4 x i32> %449 to <8 x i16>
  br label %451

451:                                              ; preds = %484, %446
  %452 = phi i16* [ %23, %446 ], [ %486, %484 ]
  %453 = phi i16* [ %447, %446 ], [ %485, %484 ]
  %454 = phi i32 [ %26, %446 ], [ %487, %484 ]
  br label %455

455:                                              ; preds = %455, %451
  %456 = phi i64 [ %482, %455 ], [ 0, %451 ]
  %457 = getelementptr inbounds i16, i16* %453, i64 %456
  %458 = bitcast i16* %457 to <8 x i16>*
  %459 = load <8 x i16>, <8 x i16>* %458, align 1
  %460 = getelementptr inbounds i16, i16* %457, i64 1
  %461 = bitcast i16* %460 to <8 x i16>*
  %462 = load <8 x i16>, <8 x i16>* %461, align 1
  %463 = getelementptr inbounds i16, i16* %457, i64 2
  %464 = bitcast i16* %463 to <8 x i16>*
  %465 = load <8 x i16>, <8 x i16>* %464, align 1
  %466 = add <8 x i16> %465, %459
  %467 = shufflevector <8 x i16> %466, <8 x i16> %462, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %468 = shufflevector <8 x i16> %466, <8 x i16> %462, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %467, <8 x i16> %450) #5
  %470 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %468, <8 x i16> %450) #5
  %471 = getelementptr inbounds i16, i16* %452, i64 %456
  %472 = add <4 x i32> %469, <i32 4, i32 4, i32 4, i32 4>
  %473 = add <4 x i32> %470, <i32 4, i32 4, i32 4, i32 4>
  %474 = ashr <4 x i32> %472, <i32 3, i32 3, i32 3, i32 3>
  %475 = ashr <4 x i32> %473, <i32 3, i32 3, i32 3, i32 3>
  %476 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %474, <4 x i32> %475) #5
  %477 = icmp sgt <8 x i16> %476, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %478 = select <8 x i1> %477, <8 x i16> %476, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %479 = icmp slt <8 x i16> %478, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %480 = select <8 x i1> %479, <8 x i16> %478, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %481 = bitcast i16* %471 to <8 x i16>*
  store <8 x i16> %480, <8 x i16>* %481, align 16
  %482 = add nuw nsw i64 %456, 8
  %483 = icmp slt i64 %482, %19
  br i1 %483, label %455, label %484

484:                                              ; preds = %455
  %485 = getelementptr inbounds i16, i16* %453, i64 %4
  %486 = getelementptr inbounds i16, i16* %452, i64 %19
  %487 = add nsw i32 %454, -1
  %488 = icmp eq i32 %487, 0
  br i1 %488, label %489, label %451

489:                                              ; preds = %484, %445
  %490 = phi i16* [ %23, %445 ], [ %486, %484 ]
  %491 = icmp eq i32 %8, 0
  br i1 %491, label %536, label %492

492:                                              ; preds = %489
  %493 = getelementptr inbounds i8, i8* %1, i64 -2
  %494 = bitcast i8* %493 to i16*
  %495 = bitcast <2 x i64> %33 to <4 x i32>
  %496 = shufflevector <4 x i32> %495, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %497 = bitcast <4 x i32> %496 to <8 x i16>
  br label %498

498:                                              ; preds = %531, %492
  %499 = phi i16* [ %490, %492 ], [ %533, %531 ]
  %500 = phi i16* [ %494, %492 ], [ %532, %531 ]
  %501 = phi i32 [ %8, %492 ], [ %534, %531 ]
  br label %502

502:                                              ; preds = %502, %498
  %503 = phi i64 [ %529, %502 ], [ 0, %498 ]
  %504 = getelementptr inbounds i16, i16* %500, i64 %503
  %505 = bitcast i16* %504 to <8 x i16>*
  %506 = load <8 x i16>, <8 x i16>* %505, align 1
  %507 = getelementptr inbounds i16, i16* %504, i64 1
  %508 = bitcast i16* %507 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 1
  %510 = getelementptr inbounds i16, i16* %504, i64 2
  %511 = bitcast i16* %510 to <8 x i16>*
  %512 = load <8 x i16>, <8 x i16>* %511, align 1
  %513 = add <8 x i16> %512, %506
  %514 = shufflevector <8 x i16> %513, <8 x i16> %509, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %515 = shufflevector <8 x i16> %513, <8 x i16> %509, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %516 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %514, <8 x i16> %497) #5
  %517 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %515, <8 x i16> %497) #5
  %518 = getelementptr inbounds i16, i16* %499, i64 %503
  %519 = add <4 x i32> %516, <i32 4, i32 4, i32 4, i32 4>
  %520 = add <4 x i32> %517, <i32 4, i32 4, i32 4, i32 4>
  %521 = ashr <4 x i32> %519, <i32 3, i32 3, i32 3, i32 3>
  %522 = ashr <4 x i32> %520, <i32 3, i32 3, i32 3, i32 3>
  %523 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %521, <4 x i32> %522) #5
  %524 = icmp sgt <8 x i16> %523, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %525 = select <8 x i1> %524, <8 x i16> %523, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %526 = icmp slt <8 x i16> %525, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %527 = select <8 x i1> %526, <8 x i16> %525, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %528 = bitcast i16* %518 to <8 x i16>*
  store <8 x i16> %527, <8 x i16>* %528, align 16
  %529 = add nuw nsw i64 %503, 8
  %530 = icmp slt i64 %529, %19
  br i1 %530, label %502, label %531

531:                                              ; preds = %502
  %532 = getelementptr inbounds i16, i16* %500, i64 %2
  %533 = getelementptr inbounds i16, i16* %499, i64 %19
  %534 = add nsw i32 %501, -1
  %535 = icmp eq i32 %534, 0
  br i1 %535, label %536, label %498

536:                                              ; preds = %531, %489
  %537 = phi i16* [ %490, %489 ], [ %533, %531 ]
  br i1 %444, label %708, label %538

538:                                              ; preds = %536
  %539 = getelementptr inbounds i8, i8* %5, i64 -2
  %540 = bitcast i8* %539 to i16*
  %541 = bitcast <2 x i64> %33 to <4 x i32>
  %542 = shufflevector <4 x i32> %541, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %543 = bitcast <4 x i32> %542 to <8 x i16>
  br label %544

544:                                              ; preds = %577, %538
  %545 = phi i16* [ %537, %538 ], [ %579, %577 ]
  %546 = phi i16* [ %540, %538 ], [ %578, %577 ]
  %547 = phi i32 [ %26, %538 ], [ %580, %577 ]
  br label %548

548:                                              ; preds = %548, %544
  %549 = phi i64 [ %575, %548 ], [ 0, %544 ]
  %550 = getelementptr inbounds i16, i16* %546, i64 %549
  %551 = bitcast i16* %550 to <8 x i16>*
  %552 = load <8 x i16>, <8 x i16>* %551, align 1
  %553 = getelementptr inbounds i16, i16* %550, i64 1
  %554 = bitcast i16* %553 to <8 x i16>*
  %555 = load <8 x i16>, <8 x i16>* %554, align 1
  %556 = getelementptr inbounds i16, i16* %550, i64 2
  %557 = bitcast i16* %556 to <8 x i16>*
  %558 = load <8 x i16>, <8 x i16>* %557, align 1
  %559 = add <8 x i16> %558, %552
  %560 = shufflevector <8 x i16> %559, <8 x i16> %555, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %561 = shufflevector <8 x i16> %559, <8 x i16> %555, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %562 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %560, <8 x i16> %543) #5
  %563 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %561, <8 x i16> %543) #5
  %564 = getelementptr inbounds i16, i16* %545, i64 %549
  %565 = add <4 x i32> %562, <i32 4, i32 4, i32 4, i32 4>
  %566 = add <4 x i32> %563, <i32 4, i32 4, i32 4, i32 4>
  %567 = ashr <4 x i32> %565, <i32 3, i32 3, i32 3, i32 3>
  %568 = ashr <4 x i32> %566, <i32 3, i32 3, i32 3, i32 3>
  %569 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %567, <4 x i32> %568) #5
  %570 = icmp sgt <8 x i16> %569, <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %571 = select <8 x i1> %570, <8 x i16> %569, <8 x i16> <i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192, i16 -8192>
  %572 = icmp slt <8 x i16> %571, <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %573 = select <8 x i1> %572, <8 x i16> %571, <8 x i16> <i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575, i16 24575>
  %574 = bitcast i16* %564 to <8 x i16>*
  store <8 x i16> %573, <8 x i16>* %574, align 16
  %575 = add nuw nsw i64 %549, 8
  %576 = icmp slt i64 %575, %19
  br i1 %576, label %548, label %577

577:                                              ; preds = %548
  %578 = getelementptr inbounds i16, i16* %546, i64 %6
  %579 = getelementptr inbounds i16, i16* %545, i64 %19
  %580 = add nsw i32 %547, -1
  %581 = icmp eq i32 %580, 0
  br i1 %581, label %708, label %544

582:                                              ; preds = %438
  br i1 %444, label %623, label %583

583:                                              ; preds = %582
  %584 = and i32 %25, 2
  %585 = icmp eq i32 %584, 0
  br i1 %585, label %600, label %586

586:                                              ; preds = %583, %586
  %587 = phi i64 [ %594, %586 ], [ 0, %583 ]
  %588 = getelementptr inbounds i16, i16* %443, i64 %587
  %589 = bitcast i16* %588 to <8 x i16>*
  %590 = load <8 x i16>, <8 x i16>* %589, align 1
  %591 = shl <8 x i16> %590, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %592 = getelementptr inbounds i16, i16* %23, i64 %587
  %593 = bitcast i16* %592 to <8 x i16>*
  store <8 x i16> %591, <8 x i16>* %593, align 16
  %594 = add nuw nsw i64 %587, 8
  %595 = icmp slt i64 %594, %19
  br i1 %595, label %586, label %596

596:                                              ; preds = %586
  %597 = getelementptr inbounds i16, i16* %443, i64 %4
  %598 = getelementptr inbounds i16, i16* %23, i64 %19
  %599 = add nsw i32 %26, -1
  br label %600

600:                                              ; preds = %583, %596
  %601 = phi i16* [ undef, %583 ], [ %598, %596 ]
  %602 = phi i16* [ %23, %583 ], [ %598, %596 ]
  %603 = phi i16* [ %443, %583 ], [ %597, %596 ]
  %604 = phi i32 [ %26, %583 ], [ %599, %596 ]
  %605 = icmp eq i32 %25, 2
  br i1 %605, label %623, label %606

606:                                              ; preds = %600, %1293
  %607 = phi i16* [ %1295, %1293 ], [ %602, %600 ]
  %608 = phi i16* [ %1294, %1293 ], [ %603, %600 ]
  %609 = phi i32 [ %1296, %1293 ], [ %604, %600 ]
  br label %610

610:                                              ; preds = %610, %606
  %611 = phi i64 [ %618, %610 ], [ 0, %606 ]
  %612 = getelementptr inbounds i16, i16* %608, i64 %611
  %613 = bitcast i16* %612 to <8 x i16>*
  %614 = load <8 x i16>, <8 x i16>* %613, align 1
  %615 = shl <8 x i16> %614, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %616 = getelementptr inbounds i16, i16* %607, i64 %611
  %617 = bitcast i16* %616 to <8 x i16>*
  store <8 x i16> %615, <8 x i16>* %617, align 16
  %618 = add nuw nsw i64 %611, 8
  %619 = icmp slt i64 %618, %19
  br i1 %619, label %610, label %620

620:                                              ; preds = %610
  %621 = getelementptr inbounds i16, i16* %608, i64 %4
  %622 = getelementptr inbounds i16, i16* %607, i64 %19
  br label %1283

623:                                              ; preds = %600, %1293, %582
  %624 = phi i16* [ %23, %582 ], [ %601, %600 ], [ %1295, %1293 ]
  %625 = icmp eq i32 %8, 0
  br i1 %625, label %666, label %626

626:                                              ; preds = %623
  %627 = and i32 %8, 1
  %628 = icmp eq i32 %627, 0
  br i1 %628, label %643, label %629

629:                                              ; preds = %626, %629
  %630 = phi i64 [ %637, %629 ], [ 0, %626 ]
  %631 = getelementptr inbounds i16, i16* %27, i64 %630
  %632 = bitcast i16* %631 to <8 x i16>*
  %633 = load <8 x i16>, <8 x i16>* %632, align 1
  %634 = shl <8 x i16> %633, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %635 = getelementptr inbounds i16, i16* %624, i64 %630
  %636 = bitcast i16* %635 to <8 x i16>*
  store <8 x i16> %634, <8 x i16>* %636, align 16
  %637 = add nuw nsw i64 %630, 8
  %638 = icmp slt i64 %637, %19
  br i1 %638, label %629, label %639

639:                                              ; preds = %629
  %640 = getelementptr inbounds i16, i16* %27, i64 %2
  %641 = getelementptr inbounds i16, i16* %624, i64 %19
  %642 = add nsw i32 %8, -1
  br label %643

643:                                              ; preds = %626, %639
  %644 = phi i16* [ undef, %626 ], [ %641, %639 ]
  %645 = phi i16* [ %624, %626 ], [ %641, %639 ]
  %646 = phi i16* [ %27, %626 ], [ %640, %639 ]
  %647 = phi i32 [ %8, %626 ], [ %642, %639 ]
  %648 = icmp eq i32 %8, 1
  br i1 %648, label %666, label %649

649:                                              ; preds = %643, %1278
  %650 = phi i16* [ %1280, %1278 ], [ %645, %643 ]
  %651 = phi i16* [ %1279, %1278 ], [ %646, %643 ]
  %652 = phi i32 [ %1281, %1278 ], [ %647, %643 ]
  br label %653

653:                                              ; preds = %653, %649
  %654 = phi i64 [ %661, %653 ], [ 0, %649 ]
  %655 = getelementptr inbounds i16, i16* %651, i64 %654
  %656 = bitcast i16* %655 to <8 x i16>*
  %657 = load <8 x i16>, <8 x i16>* %656, align 1
  %658 = shl <8 x i16> %657, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %659 = getelementptr inbounds i16, i16* %650, i64 %654
  %660 = bitcast i16* %659 to <8 x i16>*
  store <8 x i16> %658, <8 x i16>* %660, align 16
  %661 = add nuw nsw i64 %654, 8
  %662 = icmp slt i64 %661, %19
  br i1 %662, label %653, label %663

663:                                              ; preds = %653
  %664 = getelementptr inbounds i16, i16* %651, i64 %2
  %665 = getelementptr inbounds i16, i16* %650, i64 %19
  br label %1268

666:                                              ; preds = %643, %1278, %623
  %667 = phi i16* [ %624, %623 ], [ %644, %643 ], [ %1280, %1278 ]
  br i1 %444, label %708, label %668

668:                                              ; preds = %666
  %669 = and i32 %25, 2
  %670 = icmp eq i32 %669, 0
  br i1 %670, label %685, label %671

671:                                              ; preds = %668, %671
  %672 = phi i64 [ %679, %671 ], [ 0, %668 ]
  %673 = getelementptr inbounds i16, i16* %29, i64 %672
  %674 = bitcast i16* %673 to <8 x i16>*
  %675 = load <8 x i16>, <8 x i16>* %674, align 1
  %676 = shl <8 x i16> %675, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %677 = getelementptr inbounds i16, i16* %667, i64 %672
  %678 = bitcast i16* %677 to <8 x i16>*
  store <8 x i16> %676, <8 x i16>* %678, align 16
  %679 = add nuw nsw i64 %672, 8
  %680 = icmp slt i64 %679, %19
  br i1 %680, label %671, label %681

681:                                              ; preds = %671
  %682 = getelementptr inbounds i16, i16* %29, i64 %6
  %683 = getelementptr inbounds i16, i16* %667, i64 %19
  %684 = add nsw i32 %26, -1
  br label %685

685:                                              ; preds = %668, %681
  %686 = phi i16* [ undef, %668 ], [ %683, %681 ]
  %687 = phi i16* [ %667, %668 ], [ %683, %681 ]
  %688 = phi i16* [ %29, %668 ], [ %682, %681 ]
  %689 = phi i32 [ %26, %668 ], [ %684, %681 ]
  %690 = icmp eq i32 %25, 2
  br i1 %690, label %708, label %691

691:                                              ; preds = %685, %1263
  %692 = phi i16* [ %1265, %1263 ], [ %687, %685 ]
  %693 = phi i16* [ %1264, %1263 ], [ %688, %685 ]
  %694 = phi i32 [ %1266, %1263 ], [ %689, %685 ]
  br label %695

695:                                              ; preds = %695, %691
  %696 = phi i64 [ %703, %695 ], [ 0, %691 ]
  %697 = getelementptr inbounds i16, i16* %693, i64 %696
  %698 = bitcast i16* %697 to <8 x i16>*
  %699 = load <8 x i16>, <8 x i16>* %698, align 1
  %700 = shl <8 x i16> %699, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %701 = getelementptr inbounds i16, i16* %692, i64 %696
  %702 = bitcast i16* %701 to <8 x i16>*
  store <8 x i16> %700, <8 x i16>* %702, align 16
  %703 = add nuw nsw i64 %696, 8
  %704 = icmp slt i64 %703, %19
  br i1 %704, label %695, label %705

705:                                              ; preds = %695
  %706 = getelementptr inbounds i16, i16* %693, i64 %6
  %707 = getelementptr inbounds i16, i16* %692, i64 %19
  br label %1253

708:                                              ; preds = %433, %237, %685, %1263, %577, %666, %536, %374, %175
  %709 = phi i16* [ %176, %175 ], [ %375, %374 ], [ %537, %536 ], [ %667, %666 ], [ %579, %577 ], [ %686, %685 ], [ %1265, %1263 ], [ %239, %237 ], [ %435, %433 ]
  %710 = bitcast i8* %10 to i16*
  %711 = load i16, i16* %12, align 2
  switch i16 %711, label %1187 [
    i16 0, label %712
    i16 1, label %912
    i16 2, label %1070
  ]

712:                                              ; preds = %708
  %713 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 3, i32 2, i64 0, i64 0
  %714 = bitcast i16* %709 to i8*
  %715 = sub nsw i64 0, %19
  %716 = getelementptr inbounds i16, i16* %709, i64 %715
  %717 = bitcast i16* %716 to i8*
  %718 = shl nsw i64 %19, 1
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %714, i8* align 2 %717, i64 %718, i1 false)
  %719 = bitcast %"union.libgav1::RestorationBuffer"* %9 to i8*
  %720 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %19
  %721 = bitcast i16* %720 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 32 %719, i8* align 2 %721, i64 %718, i1 false)
  %722 = bitcast i16* %713 to i64*
  %723 = load i64, i64* %722, align 1
  %724 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %723, i32 0
  %725 = bitcast <2 x i64> %724 to <4 x i32>
  %726 = shufflevector <4 x i32> %725, <4 x i32> undef, <4 x i32> zeroinitializer
  %727 = shufflevector <4 x i32> %725, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %728 = bitcast <2 x i64> %724 to <16 x i8>
  %729 = shufflevector <16 x i8> %728, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3>
  %730 = trunc i64 %723 to i32
  %731 = and i32 %730, 65535
  %732 = or i32 %731, 65536
  %733 = insertelement <4 x i32> undef, i32 %732, i32 0
  %734 = shufflevector <4 x i32> %733, <4 x i32> undef, <4 x i32> zeroinitializer
  %735 = icmp sgt i32 %8, 1
  br i1 %735, label %736, label %753

736:                                              ; preds = %712
  %737 = lshr i32 %8, 1
  %738 = mul nsw i64 %19, 3
  %739 = shl nsw i64 %19, 2
  %740 = mul nsw i64 %19, 5
  %741 = mul nsw i64 %19, 6
  %742 = bitcast <4 x i32> %726 to <8 x i16>
  %743 = bitcast <4 x i32> %727 to <8 x i16>
  %744 = bitcast <16 x i8> %729 to <8 x i16>
  %745 = bitcast <4 x i32> %734 to <8 x i16>
  %746 = mul nsw i64 %19, 7
  %747 = shl nsw i64 %2, 1
  br label %748

748:                                              ; preds = %853, %736
  %749 = phi i16* [ %20, %736 ], [ %855, %853 ]
  %750 = phi i16* [ %710, %736 ], [ %854, %853 ]
  %751 = phi i32 [ %737, %736 ], [ %856, %853 ]
  %752 = getelementptr inbounds i16, i16* %750, i64 %2
  br label %767

753:                                              ; preds = %853, %712
  %754 = phi i16* [ %710, %712 ], [ %854, %853 ]
  %755 = phi i16* [ %20, %712 ], [ %855, %853 ]
  %756 = and i32 %8, 1
  %757 = icmp eq i32 %756, 0
  br i1 %757, label %1252, label %758

758:                                              ; preds = %753
  %759 = mul nsw i64 %19, 3
  %760 = shl nsw i64 %19, 2
  %761 = mul nsw i64 %19, 5
  %762 = mul nsw i64 %19, 6
  %763 = bitcast <4 x i32> %726 to <8 x i16>
  %764 = bitcast <4 x i32> %727 to <8 x i16>
  %765 = bitcast <16 x i8> %729 to <8 x i16>
  %766 = bitcast <4 x i32> %734 to <8 x i16>
  br label %858

767:                                              ; preds = %767, %748
  %768 = phi i64 [ %851, %767 ], [ 0, %748 ]
  %769 = getelementptr inbounds i16, i16* %749, i64 %768
  %770 = bitcast i16* %769 to <8 x i16>*
  %771 = load <8 x i16>, <8 x i16>* %770, align 16
  %772 = getelementptr inbounds i16, i16* %769, i64 %19
  %773 = bitcast i16* %772 to <8 x i16>*
  %774 = load <8 x i16>, <8 x i16>* %773, align 16
  %775 = getelementptr inbounds i16, i16* %769, i64 %718
  %776 = bitcast i16* %775 to <8 x i16>*
  %777 = load <8 x i16>, <8 x i16>* %776, align 16
  %778 = getelementptr inbounds i16, i16* %769, i64 %738
  %779 = bitcast i16* %778 to <8 x i16>*
  %780 = load <8 x i16>, <8 x i16>* %779, align 16
  %781 = getelementptr inbounds i16, i16* %769, i64 %739
  %782 = bitcast i16* %781 to <8 x i16>*
  %783 = load <8 x i16>, <8 x i16>* %782, align 16
  %784 = getelementptr inbounds i16, i16* %769, i64 %740
  %785 = bitcast i16* %784 to <8 x i16>*
  %786 = load <8 x i16>, <8 x i16>* %785, align 16
  %787 = getelementptr inbounds i16, i16* %769, i64 %741
  %788 = bitcast i16* %787 to <8 x i16>*
  %789 = load <8 x i16>, <8 x i16>* %788, align 16
  %790 = shufflevector <8 x i16> %771, <8 x i16> %774, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %791 = shufflevector <8 x i16> %777, <8 x i16> %780, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %792 = shufflevector <8 x i16> %783, <8 x i16> %786, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %793 = shufflevector <8 x i16> %789, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %794 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %790, <8 x i16> %742) #5
  %795 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %791, <8 x i16> %743) #5
  %796 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %792, <8 x i16> %744) #5
  %797 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %793, <8 x i16> %745) #5
  %798 = add <4 x i32> %795, %794
  %799 = add <4 x i32> %798, %796
  %800 = add <4 x i32> %799, %797
  %801 = ashr <4 x i32> %800, <i32 11, i32 11, i32 11, i32 11>
  %802 = shufflevector <8 x i16> %771, <8 x i16> %774, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %803 = shufflevector <8 x i16> %777, <8 x i16> %780, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %804 = shufflevector <8 x i16> %783, <8 x i16> %786, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %805 = shufflevector <8 x i16> %789, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %806 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %802, <8 x i16> %742) #5
  %807 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %803, <8 x i16> %743) #5
  %808 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %804, <8 x i16> %744) #5
  %809 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %805, <8 x i16> %745) #5
  %810 = add <4 x i32> %807, %806
  %811 = add <4 x i32> %810, %808
  %812 = add <4 x i32> %811, %809
  %813 = ashr <4 x i32> %812, <i32 11, i32 11, i32 11, i32 11>
  %814 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %801, <4 x i32> %813) #5
  %815 = icmp ult <8 x i16> %814, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %816 = select <8 x i1> %815, <8 x i16> %814, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %817 = getelementptr inbounds i16, i16* %769, i64 %746
  %818 = bitcast i16* %817 to <8 x i16>*
  %819 = load <8 x i16>, <8 x i16>* %818, align 16
  %820 = shufflevector <8 x i16> %774, <8 x i16> %777, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %821 = shufflevector <8 x i16> %780, <8 x i16> %783, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %822 = shufflevector <8 x i16> %786, <8 x i16> %789, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %823 = shufflevector <8 x i16> %819, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %824 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %820, <8 x i16> %742) #5
  %825 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %821, <8 x i16> %743) #5
  %826 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %822, <8 x i16> %744) #5
  %827 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %823, <8 x i16> %745) #5
  %828 = add <4 x i32> %825, %824
  %829 = add <4 x i32> %828, %826
  %830 = add <4 x i32> %829, %827
  %831 = ashr <4 x i32> %830, <i32 11, i32 11, i32 11, i32 11>
  %832 = shufflevector <8 x i16> %774, <8 x i16> %777, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %833 = shufflevector <8 x i16> %780, <8 x i16> %783, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %834 = shufflevector <8 x i16> %786, <8 x i16> %789, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %835 = shufflevector <8 x i16> %819, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %836 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %832, <8 x i16> %742) #5
  %837 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %833, <8 x i16> %743) #5
  %838 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %834, <8 x i16> %744) #5
  %839 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %835, <8 x i16> %745) #5
  %840 = add <4 x i32> %837, %836
  %841 = add <4 x i32> %840, %838
  %842 = add <4 x i32> %841, %839
  %843 = ashr <4 x i32> %842, <i32 11, i32 11, i32 11, i32 11>
  %844 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %831, <4 x i32> %843) #5
  %845 = icmp ult <8 x i16> %844, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %846 = select <8 x i1> %845, <8 x i16> %844, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %847 = getelementptr inbounds i16, i16* %750, i64 %768
  %848 = bitcast i16* %847 to <8 x i16>*
  store <8 x i16> %816, <8 x i16>* %848, align 16
  %849 = getelementptr inbounds i16, i16* %752, i64 %768
  %850 = bitcast i16* %849 to <8 x i16>*
  store <8 x i16> %846, <8 x i16>* %850, align 16
  %851 = add nuw nsw i64 %768, 8
  %852 = icmp slt i64 %851, %19
  br i1 %852, label %767, label %853

853:                                              ; preds = %767
  %854 = getelementptr inbounds i16, i16* %750, i64 %747
  %855 = getelementptr inbounds i16, i16* %749, i64 %718
  %856 = add nsw i32 %751, -1
  %857 = icmp sgt i32 %856, 0
  br i1 %857, label %748, label %753

858:                                              ; preds = %858, %758
  %859 = phi i64 [ %910, %858 ], [ 0, %758 ]
  %860 = getelementptr inbounds i16, i16* %755, i64 %859
  %861 = bitcast i16* %860 to <8 x i16>*
  %862 = load <8 x i16>, <8 x i16>* %861, align 16
  %863 = getelementptr inbounds i16, i16* %860, i64 %19
  %864 = bitcast i16* %863 to <8 x i16>*
  %865 = load <8 x i16>, <8 x i16>* %864, align 16
  %866 = getelementptr inbounds i16, i16* %860, i64 %718
  %867 = bitcast i16* %866 to <8 x i16>*
  %868 = load <8 x i16>, <8 x i16>* %867, align 16
  %869 = getelementptr inbounds i16, i16* %860, i64 %759
  %870 = bitcast i16* %869 to <8 x i16>*
  %871 = load <8 x i16>, <8 x i16>* %870, align 16
  %872 = getelementptr inbounds i16, i16* %860, i64 %760
  %873 = bitcast i16* %872 to <8 x i16>*
  %874 = load <8 x i16>, <8 x i16>* %873, align 16
  %875 = getelementptr inbounds i16, i16* %860, i64 %761
  %876 = bitcast i16* %875 to <8 x i16>*
  %877 = load <8 x i16>, <8 x i16>* %876, align 16
  %878 = getelementptr inbounds i16, i16* %860, i64 %762
  %879 = bitcast i16* %878 to <8 x i16>*
  %880 = load <8 x i16>, <8 x i16>* %879, align 16
  %881 = shufflevector <8 x i16> %862, <8 x i16> %865, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %882 = shufflevector <8 x i16> %868, <8 x i16> %871, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %883 = shufflevector <8 x i16> %874, <8 x i16> %877, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %884 = shufflevector <8 x i16> %880, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %885 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %881, <8 x i16> %763) #5
  %886 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %882, <8 x i16> %764) #5
  %887 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %883, <8 x i16> %765) #5
  %888 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %884, <8 x i16> %766) #5
  %889 = add <4 x i32> %886, %885
  %890 = add <4 x i32> %889, %887
  %891 = add <4 x i32> %890, %888
  %892 = ashr <4 x i32> %891, <i32 11, i32 11, i32 11, i32 11>
  %893 = shufflevector <8 x i16> %862, <8 x i16> %865, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %894 = shufflevector <8 x i16> %868, <8 x i16> %871, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %895 = shufflevector <8 x i16> %874, <8 x i16> %877, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %896 = shufflevector <8 x i16> %880, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %897 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %893, <8 x i16> %763) #5
  %898 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %894, <8 x i16> %764) #5
  %899 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %895, <8 x i16> %765) #5
  %900 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %896, <8 x i16> %766) #5
  %901 = add <4 x i32> %898, %897
  %902 = add <4 x i32> %901, %899
  %903 = add <4 x i32> %902, %900
  %904 = ashr <4 x i32> %903, <i32 11, i32 11, i32 11, i32 11>
  %905 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %892, <4 x i32> %904) #5
  %906 = icmp ult <8 x i16> %905, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %907 = select <8 x i1> %906, <8 x i16> %905, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %908 = getelementptr inbounds i16, i16* %754, i64 %859
  %909 = bitcast i16* %908 to <8 x i16>*
  store <8 x i16> %907, <8 x i16>* %909, align 16
  %910 = add nuw nsw i64 %859, 8
  %911 = icmp slt i64 %910, %19
  br i1 %911, label %858, label %1252

912:                                              ; preds = %708
  %913 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %19
  %914 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 3, i32 2, i64 0, i64 1
  %915 = bitcast i16* %914 to i64*
  %916 = load i64, i64* %915, align 1
  %917 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %916, i32 0
  %918 = bitcast <2 x i64> %917 to <4 x i32>
  %919 = shufflevector <4 x i32> %918, <4 x i32> undef, <4 x i32> zeroinitializer
  %920 = bitcast <2 x i64> %917 to <16 x i8>
  %921 = shufflevector <16 x i8> %920, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3, i32 4, i32 5, i32 2, i32 3>
  %922 = trunc i64 %916 to i32
  %923 = and i32 %922, 65535
  %924 = or i32 %923, 65536
  %925 = insertelement <4 x i32> undef, i32 %924, i32 0
  %926 = shufflevector <4 x i32> %925, <4 x i32> undef, <4 x i32> zeroinitializer
  %927 = icmp sgt i32 %8, 1
  br i1 %927, label %928, label %943

928:                                              ; preds = %912
  %929 = lshr i32 %8, 1
  %930 = shl nsw i64 %19, 1
  %931 = mul nsw i64 %19, 3
  %932 = shl nsw i64 %19, 2
  %933 = bitcast <4 x i32> %919 to <8 x i16>
  %934 = bitcast <16 x i8> %921 to <8 x i16>
  %935 = bitcast <4 x i32> %926 to <8 x i16>
  %936 = mul nsw i64 %19, 5
  %937 = shl nsw i64 %2, 1
  br label %938

938:                                              ; preds = %1023, %928
  %939 = phi i16* [ %913, %928 ], [ %1025, %1023 ]
  %940 = phi i16* [ %710, %928 ], [ %1024, %1023 ]
  %941 = phi i32 [ %929, %928 ], [ %1026, %1023 ]
  %942 = getelementptr inbounds i16, i16* %940, i64 %2
  br label %955

943:                                              ; preds = %1023, %912
  %944 = phi i16* [ %710, %912 ], [ %1024, %1023 ]
  %945 = phi i16* [ %913, %912 ], [ %1025, %1023 ]
  %946 = and i32 %8, 1
  %947 = icmp eq i32 %946, 0
  br i1 %947, label %1252, label %948

948:                                              ; preds = %943
  %949 = shl nsw i64 %19, 1
  %950 = mul nsw i64 %19, 3
  %951 = shl nsw i64 %19, 2
  %952 = bitcast <4 x i32> %919 to <8 x i16>
  %953 = bitcast <16 x i8> %921 to <8 x i16>
  %954 = bitcast <4 x i32> %926 to <8 x i16>
  br label %1028

955:                                              ; preds = %955, %938
  %956 = phi i64 [ %1021, %955 ], [ 0, %938 ]
  %957 = getelementptr inbounds i16, i16* %939, i64 %956
  %958 = bitcast i16* %957 to <8 x i16>*
  %959 = load <8 x i16>, <8 x i16>* %958, align 16
  %960 = getelementptr inbounds i16, i16* %957, i64 %19
  %961 = bitcast i16* %960 to <8 x i16>*
  %962 = load <8 x i16>, <8 x i16>* %961, align 16
  %963 = getelementptr inbounds i16, i16* %957, i64 %930
  %964 = bitcast i16* %963 to <8 x i16>*
  %965 = load <8 x i16>, <8 x i16>* %964, align 16
  %966 = getelementptr inbounds i16, i16* %957, i64 %931
  %967 = bitcast i16* %966 to <8 x i16>*
  %968 = load <8 x i16>, <8 x i16>* %967, align 16
  %969 = getelementptr inbounds i16, i16* %957, i64 %932
  %970 = bitcast i16* %969 to <8 x i16>*
  %971 = load <8 x i16>, <8 x i16>* %970, align 16
  %972 = shufflevector <8 x i16> %959, <8 x i16> %962, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %973 = shufflevector <8 x i16> %965, <8 x i16> %968, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %974 = shufflevector <8 x i16> %971, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %975 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %972, <8 x i16> %933) #5
  %976 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %973, <8 x i16> %934) #5
  %977 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %974, <8 x i16> %935) #5
  %978 = add <4 x i32> %976, %975
  %979 = add <4 x i32> %978, %977
  %980 = ashr <4 x i32> %979, <i32 11, i32 11, i32 11, i32 11>
  %981 = shufflevector <8 x i16> %959, <8 x i16> %962, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %982 = shufflevector <8 x i16> %965, <8 x i16> %968, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %983 = shufflevector <8 x i16> %971, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %984 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %981, <8 x i16> %933) #5
  %985 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %982, <8 x i16> %934) #5
  %986 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %983, <8 x i16> %935) #5
  %987 = add <4 x i32> %985, %984
  %988 = add <4 x i32> %987, %986
  %989 = ashr <4 x i32> %988, <i32 11, i32 11, i32 11, i32 11>
  %990 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %980, <4 x i32> %989) #5
  %991 = icmp ult <8 x i16> %990, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %992 = select <8 x i1> %991, <8 x i16> %990, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %993 = getelementptr inbounds i16, i16* %957, i64 %936
  %994 = bitcast i16* %993 to <8 x i16>*
  %995 = load <8 x i16>, <8 x i16>* %994, align 16
  %996 = shufflevector <8 x i16> %962, <8 x i16> %965, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %997 = shufflevector <8 x i16> %968, <8 x i16> %971, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %998 = shufflevector <8 x i16> %995, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %999 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %996, <8 x i16> %933) #5
  %1000 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %997, <8 x i16> %934) #5
  %1001 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %998, <8 x i16> %935) #5
  %1002 = add <4 x i32> %1000, %999
  %1003 = add <4 x i32> %1002, %1001
  %1004 = ashr <4 x i32> %1003, <i32 11, i32 11, i32 11, i32 11>
  %1005 = shufflevector <8 x i16> %962, <8 x i16> %965, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1006 = shufflevector <8 x i16> %968, <8 x i16> %971, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1007 = shufflevector <8 x i16> %995, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1008 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1005, <8 x i16> %933) #5
  %1009 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1006, <8 x i16> %934) #5
  %1010 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1007, <8 x i16> %935) #5
  %1011 = add <4 x i32> %1009, %1008
  %1012 = add <4 x i32> %1011, %1010
  %1013 = ashr <4 x i32> %1012, <i32 11, i32 11, i32 11, i32 11>
  %1014 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1004, <4 x i32> %1013) #5
  %1015 = icmp ult <8 x i16> %1014, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1016 = select <8 x i1> %1015, <8 x i16> %1014, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1017 = getelementptr inbounds i16, i16* %940, i64 %956
  %1018 = bitcast i16* %1017 to <8 x i16>*
  store <8 x i16> %992, <8 x i16>* %1018, align 16
  %1019 = getelementptr inbounds i16, i16* %942, i64 %956
  %1020 = bitcast i16* %1019 to <8 x i16>*
  store <8 x i16> %1016, <8 x i16>* %1020, align 16
  %1021 = add nuw nsw i64 %956, 8
  %1022 = icmp slt i64 %1021, %19
  br i1 %1022, label %955, label %1023

1023:                                             ; preds = %955
  %1024 = getelementptr inbounds i16, i16* %940, i64 %937
  %1025 = getelementptr inbounds i16, i16* %939, i64 %930
  %1026 = add nsw i32 %941, -1
  %1027 = icmp sgt i32 %1026, 0
  br i1 %1027, label %938, label %943

1028:                                             ; preds = %1028, %948
  %1029 = phi i64 [ %1068, %1028 ], [ 0, %948 ]
  %1030 = getelementptr inbounds i16, i16* %945, i64 %1029
  %1031 = bitcast i16* %1030 to <8 x i16>*
  %1032 = load <8 x i16>, <8 x i16>* %1031, align 16
  %1033 = getelementptr inbounds i16, i16* %1030, i64 %19
  %1034 = bitcast i16* %1033 to <8 x i16>*
  %1035 = load <8 x i16>, <8 x i16>* %1034, align 16
  %1036 = getelementptr inbounds i16, i16* %1030, i64 %949
  %1037 = bitcast i16* %1036 to <8 x i16>*
  %1038 = load <8 x i16>, <8 x i16>* %1037, align 16
  %1039 = getelementptr inbounds i16, i16* %1030, i64 %950
  %1040 = bitcast i16* %1039 to <8 x i16>*
  %1041 = load <8 x i16>, <8 x i16>* %1040, align 16
  %1042 = getelementptr inbounds i16, i16* %1030, i64 %951
  %1043 = bitcast i16* %1042 to <8 x i16>*
  %1044 = load <8 x i16>, <8 x i16>* %1043, align 16
  %1045 = shufflevector <8 x i16> %1032, <8 x i16> %1035, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1046 = shufflevector <8 x i16> %1038, <8 x i16> %1041, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1047 = shufflevector <8 x i16> %1044, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1048 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1045, <8 x i16> %952) #5
  %1049 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1046, <8 x i16> %953) #5
  %1050 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1047, <8 x i16> %954) #5
  %1051 = add <4 x i32> %1049, %1048
  %1052 = add <4 x i32> %1051, %1050
  %1053 = ashr <4 x i32> %1052, <i32 11, i32 11, i32 11, i32 11>
  %1054 = shufflevector <8 x i16> %1032, <8 x i16> %1035, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1055 = shufflevector <8 x i16> %1038, <8 x i16> %1041, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1056 = shufflevector <8 x i16> %1044, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1057 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1054, <8 x i16> %952) #5
  %1058 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1055, <8 x i16> %953) #5
  %1059 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1056, <8 x i16> %954) #5
  %1060 = add <4 x i32> %1058, %1057
  %1061 = add <4 x i32> %1060, %1059
  %1062 = ashr <4 x i32> %1061, <i32 11, i32 11, i32 11, i32 11>
  %1063 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1053, <4 x i32> %1062) #5
  %1064 = icmp ult <8 x i16> %1063, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1065 = select <8 x i1> %1064, <8 x i16> %1063, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1066 = getelementptr inbounds i16, i16* %944, i64 %1029
  %1067 = bitcast i16* %1066 to <8 x i16>*
  store <8 x i16> %1065, <8 x i16>* %1067, align 16
  %1068 = add nuw nsw i64 %1029, 8
  %1069 = icmp slt i64 %1068, %19
  br i1 %1069, label %1028, label %1252

1070:                                             ; preds = %708
  %1071 = shl nsw i64 %19, 1
  %1072 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %1071
  %1073 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 3, i32 2, i64 0, i64 2
  %1074 = bitcast i16* %1073 to i32*
  %1075 = load i32, i32* %1074, align 4
  %1076 = insertelement <4 x i32> undef, i32 %1075, i32 0
  %1077 = shufflevector <4 x i32> %1076, <4 x i32> undef, <4 x i32> zeroinitializer
  %1078 = and i32 %1075, 65535
  %1079 = or i32 %1078, 65536
  %1080 = insertelement <4 x i32> undef, i32 %1079, i32 0
  %1081 = shufflevector <4 x i32> %1080, <4 x i32> undef, <4 x i32> zeroinitializer
  %1082 = icmp sgt i32 %8, 1
  br i1 %1082, label %1083, label %1094

1083:                                             ; preds = %1070
  %1084 = lshr i32 %8, 1
  %1085 = bitcast <4 x i32> %1077 to <8 x i16>
  %1086 = bitcast <4 x i32> %1081 to <8 x i16>
  %1087 = mul nsw i64 %19, 3
  %1088 = shl nsw i64 %2, 1
  br label %1089

1089:                                             ; preds = %1152, %1083
  %1090 = phi i16* [ %1072, %1083 ], [ %1154, %1152 ]
  %1091 = phi i16* [ %710, %1083 ], [ %1153, %1152 ]
  %1092 = phi i32 [ %1084, %1083 ], [ %1155, %1152 ]
  %1093 = getelementptr inbounds i16, i16* %1091, i64 %2
  br label %1102

1094:                                             ; preds = %1152, %1070
  %1095 = phi i16* [ %710, %1070 ], [ %1153, %1152 ]
  %1096 = phi i16* [ %1072, %1070 ], [ %1154, %1152 ]
  %1097 = and i32 %8, 1
  %1098 = icmp eq i32 %1097, 0
  br i1 %1098, label %1252, label %1099

1099:                                             ; preds = %1094
  %1100 = bitcast <4 x i32> %1077 to <8 x i16>
  %1101 = bitcast <4 x i32> %1081 to <8 x i16>
  br label %1157

1102:                                             ; preds = %1102, %1089
  %1103 = phi i64 [ %1150, %1102 ], [ 0, %1089 ]
  %1104 = getelementptr inbounds i16, i16* %1090, i64 %1103
  %1105 = bitcast i16* %1104 to <8 x i16>*
  %1106 = load <8 x i16>, <8 x i16>* %1105, align 16
  %1107 = getelementptr inbounds i16, i16* %1104, i64 %19
  %1108 = bitcast i16* %1107 to <8 x i16>*
  %1109 = load <8 x i16>, <8 x i16>* %1108, align 16
  %1110 = getelementptr inbounds i16, i16* %1104, i64 %1071
  %1111 = bitcast i16* %1110 to <8 x i16>*
  %1112 = load <8 x i16>, <8 x i16>* %1111, align 16
  %1113 = shufflevector <8 x i16> %1106, <8 x i16> %1109, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1114 = shufflevector <8 x i16> %1112, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1115 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1113, <8 x i16> %1085) #5
  %1116 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1114, <8 x i16> %1086) #5
  %1117 = add <4 x i32> %1116, %1115
  %1118 = ashr <4 x i32> %1117, <i32 11, i32 11, i32 11, i32 11>
  %1119 = shufflevector <8 x i16> %1106, <8 x i16> %1109, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1120 = shufflevector <8 x i16> %1112, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1119, <8 x i16> %1085) #5
  %1122 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1120, <8 x i16> %1086) #5
  %1123 = add <4 x i32> %1122, %1121
  %1124 = ashr <4 x i32> %1123, <i32 11, i32 11, i32 11, i32 11>
  %1125 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1118, <4 x i32> %1124) #5
  %1126 = icmp ult <8 x i16> %1125, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1127 = select <8 x i1> %1126, <8 x i16> %1125, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1128 = getelementptr inbounds i16, i16* %1104, i64 %1087
  %1129 = bitcast i16* %1128 to <8 x i16>*
  %1130 = load <8 x i16>, <8 x i16>* %1129, align 16
  %1131 = shufflevector <8 x i16> %1109, <8 x i16> %1112, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1132 = shufflevector <8 x i16> %1130, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1133 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1131, <8 x i16> %1085) #5
  %1134 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1132, <8 x i16> %1086) #5
  %1135 = add <4 x i32> %1134, %1133
  %1136 = ashr <4 x i32> %1135, <i32 11, i32 11, i32 11, i32 11>
  %1137 = shufflevector <8 x i16> %1109, <8 x i16> %1112, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1138 = shufflevector <8 x i16> %1130, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1139 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1137, <8 x i16> %1085) #5
  %1140 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1138, <8 x i16> %1086) #5
  %1141 = add <4 x i32> %1140, %1139
  %1142 = ashr <4 x i32> %1141, <i32 11, i32 11, i32 11, i32 11>
  %1143 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1136, <4 x i32> %1142) #5
  %1144 = icmp ult <8 x i16> %1143, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1145 = select <8 x i1> %1144, <8 x i16> %1143, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1146 = getelementptr inbounds i16, i16* %1091, i64 %1103
  %1147 = bitcast i16* %1146 to <8 x i16>*
  store <8 x i16> %1127, <8 x i16>* %1147, align 16
  %1148 = getelementptr inbounds i16, i16* %1093, i64 %1103
  %1149 = bitcast i16* %1148 to <8 x i16>*
  store <8 x i16> %1145, <8 x i16>* %1149, align 16
  %1150 = add nuw nsw i64 %1103, 8
  %1151 = icmp slt i64 %1150, %19
  br i1 %1151, label %1102, label %1152

1152:                                             ; preds = %1102
  %1153 = getelementptr inbounds i16, i16* %1091, i64 %1088
  %1154 = getelementptr inbounds i16, i16* %1090, i64 %1071
  %1155 = add nsw i32 %1092, -1
  %1156 = icmp sgt i32 %1155, 0
  br i1 %1156, label %1089, label %1094

1157:                                             ; preds = %1157, %1099
  %1158 = phi i64 [ %1185, %1157 ], [ 0, %1099 ]
  %1159 = getelementptr inbounds i16, i16* %1096, i64 %1158
  %1160 = bitcast i16* %1159 to <8 x i16>*
  %1161 = load <8 x i16>, <8 x i16>* %1160, align 16
  %1162 = getelementptr inbounds i16, i16* %1159, i64 %19
  %1163 = bitcast i16* %1162 to <8 x i16>*
  %1164 = load <8 x i16>, <8 x i16>* %1163, align 16
  %1165 = getelementptr inbounds i16, i16* %1159, i64 %1071
  %1166 = bitcast i16* %1165 to <8 x i16>*
  %1167 = load <8 x i16>, <8 x i16>* %1166, align 16
  %1168 = shufflevector <8 x i16> %1161, <8 x i16> %1164, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1169 = shufflevector <8 x i16> %1167, <8 x i16> <i16 1024, i16 1024, i16 1024, i16 1024, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1170 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1168, <8 x i16> %1100) #5
  %1171 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1169, <8 x i16> %1101) #5
  %1172 = add <4 x i32> %1171, %1170
  %1173 = ashr <4 x i32> %1172, <i32 11, i32 11, i32 11, i32 11>
  %1174 = shufflevector <8 x i16> %1161, <8 x i16> %1164, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1175 = shufflevector <8 x i16> %1167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1024, i16 1024, i16 1024, i16 1024>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1176 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1174, <8 x i16> %1100) #5
  %1177 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1175, <8 x i16> %1101) #5
  %1178 = add <4 x i32> %1177, %1176
  %1179 = ashr <4 x i32> %1178, <i32 11, i32 11, i32 11, i32 11>
  %1180 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1173, <4 x i32> %1179) #5
  %1181 = icmp ult <8 x i16> %1180, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1182 = select <8 x i1> %1181, <8 x i16> %1180, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1183 = getelementptr inbounds i16, i16* %1095, i64 %1158
  %1184 = bitcast i16* %1183 to <8 x i16>*
  store <8 x i16> %1182, <8 x i16>* %1184, align 16
  %1185 = add nuw nsw i64 %1158, 8
  %1186 = icmp slt i64 %1185, %19
  br i1 %1186, label %1157, label %1252

1187:                                             ; preds = %708
  %1188 = mul nsw i64 %19, 3
  %1189 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %1188
  %1190 = icmp sgt i32 %8, 1
  br i1 %1190, label %1191, label %1201

1191:                                             ; preds = %1187
  %1192 = lshr i32 %8, 1
  %1193 = shl nsw i64 %2, 1
  %1194 = shl nsw i64 %19, 1
  br label %1195

1195:                                             ; preds = %1232, %1191
  %1196 = phi i32 [ %1192, %1191 ], [ %1235, %1232 ]
  %1197 = phi i16* [ %1189, %1191 ], [ %1234, %1232 ]
  %1198 = phi i16* [ %710, %1191 ], [ %1233, %1232 ]
  %1199 = getelementptr inbounds i16, i16* %1197, i64 %19
  %1200 = getelementptr inbounds i16, i16* %1198, i64 %2
  br label %1206

1201:                                             ; preds = %1232, %1187
  %1202 = phi i16* [ %710, %1187 ], [ %1233, %1232 ]
  %1203 = phi i16* [ %1189, %1187 ], [ %1234, %1232 ]
  %1204 = and i32 %8, 1
  %1205 = icmp eq i32 %1204, 0
  br i1 %1205, label %1252, label %1237

1206:                                             ; preds = %1206, %1195
  %1207 = phi i64 [ %1230, %1206 ], [ 0, %1195 ]
  %1208 = getelementptr inbounds i16, i16* %1197, i64 %1207
  %1209 = getelementptr inbounds i16, i16* %1198, i64 %1207
  %1210 = bitcast i16* %1208 to <8 x i16>*
  %1211 = load <8 x i16>, <8 x i16>* %1210, align 16
  %1212 = add <8 x i16> %1211, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %1213 = ashr <8 x i16> %1212, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1214 = icmp sgt <8 x i16> %1213, zeroinitializer
  %1215 = select <8 x i1> %1214, <8 x i16> %1213, <8 x i16> zeroinitializer
  %1216 = icmp slt <8 x i16> %1215, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1217 = select <8 x i1> %1216, <8 x i16> %1215, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1218 = bitcast i16* %1209 to <8 x i16>*
  store <8 x i16> %1217, <8 x i16>* %1218, align 16
  %1219 = getelementptr inbounds i16, i16* %1199, i64 %1207
  %1220 = getelementptr inbounds i16, i16* %1200, i64 %1207
  %1221 = bitcast i16* %1219 to <8 x i16>*
  %1222 = load <8 x i16>, <8 x i16>* %1221, align 16
  %1223 = add <8 x i16> %1222, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %1224 = ashr <8 x i16> %1223, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1225 = icmp sgt <8 x i16> %1224, zeroinitializer
  %1226 = select <8 x i1> %1225, <8 x i16> %1224, <8 x i16> zeroinitializer
  %1227 = icmp slt <8 x i16> %1226, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1228 = select <8 x i1> %1227, <8 x i16> %1226, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1229 = bitcast i16* %1220 to <8 x i16>*
  store <8 x i16> %1228, <8 x i16>* %1229, align 16
  %1230 = add nuw nsw i64 %1207, 8
  %1231 = icmp slt i64 %1230, %19
  br i1 %1231, label %1206, label %1232

1232:                                             ; preds = %1206
  %1233 = getelementptr inbounds i16, i16* %1198, i64 %1193
  %1234 = getelementptr inbounds i16, i16* %1197, i64 %1194
  %1235 = add nsw i32 %1196, -1
  %1236 = icmp sgt i32 %1235, 0
  br i1 %1236, label %1195, label %1201

1237:                                             ; preds = %1201, %1237
  %1238 = phi i64 [ %1250, %1237 ], [ 0, %1201 ]
  %1239 = getelementptr inbounds i16, i16* %1203, i64 %1238
  %1240 = getelementptr inbounds i16, i16* %1202, i64 %1238
  %1241 = bitcast i16* %1239 to <8 x i16>*
  %1242 = load <8 x i16>, <8 x i16>* %1241, align 16
  %1243 = add <8 x i16> %1242, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %1244 = ashr <8 x i16> %1243, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1245 = icmp sgt <8 x i16> %1244, zeroinitializer
  %1246 = select <8 x i1> %1245, <8 x i16> %1244, <8 x i16> zeroinitializer
  %1247 = icmp slt <8 x i16> %1246, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1248 = select <8 x i1> %1247, <8 x i16> %1246, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1249 = bitcast i16* %1240 to <8 x i16>*
  store <8 x i16> %1248, <8 x i16>* %1249, align 16
  %1250 = add nuw nsw i64 %1238, 8
  %1251 = icmp slt i64 %1250, %19
  br i1 %1251, label %1237, label %1252

1252:                                             ; preds = %1157, %1028, %858, %1237, %1201, %1094, %943, %753
  ret void

1253:                                             ; preds = %1253, %705
  %1254 = phi i64 [ %1261, %1253 ], [ 0, %705 ]
  %1255 = getelementptr inbounds i16, i16* %706, i64 %1254
  %1256 = bitcast i16* %1255 to <8 x i16>*
  %1257 = load <8 x i16>, <8 x i16>* %1256, align 1
  %1258 = shl <8 x i16> %1257, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1259 = getelementptr inbounds i16, i16* %707, i64 %1254
  %1260 = bitcast i16* %1259 to <8 x i16>*
  store <8 x i16> %1258, <8 x i16>* %1260, align 16
  %1261 = add nuw nsw i64 %1254, 8
  %1262 = icmp slt i64 %1261, %19
  br i1 %1262, label %1253, label %1263

1263:                                             ; preds = %1253
  %1264 = getelementptr inbounds i16, i16* %706, i64 %6
  %1265 = getelementptr inbounds i16, i16* %707, i64 %19
  %1266 = add nsw i32 %694, -2
  %1267 = icmp eq i32 %1266, 0
  br i1 %1267, label %708, label %691

1268:                                             ; preds = %1268, %663
  %1269 = phi i64 [ %1276, %1268 ], [ 0, %663 ]
  %1270 = getelementptr inbounds i16, i16* %664, i64 %1269
  %1271 = bitcast i16* %1270 to <8 x i16>*
  %1272 = load <8 x i16>, <8 x i16>* %1271, align 1
  %1273 = shl <8 x i16> %1272, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1274 = getelementptr inbounds i16, i16* %665, i64 %1269
  %1275 = bitcast i16* %1274 to <8 x i16>*
  store <8 x i16> %1273, <8 x i16>* %1275, align 16
  %1276 = add nuw nsw i64 %1269, 8
  %1277 = icmp slt i64 %1276, %19
  br i1 %1277, label %1268, label %1278

1278:                                             ; preds = %1268
  %1279 = getelementptr inbounds i16, i16* %664, i64 %2
  %1280 = getelementptr inbounds i16, i16* %665, i64 %19
  %1281 = add nsw i32 %652, -2
  %1282 = icmp eq i32 %1281, 0
  br i1 %1282, label %666, label %649

1283:                                             ; preds = %1283, %620
  %1284 = phi i64 [ %1291, %1283 ], [ 0, %620 ]
  %1285 = getelementptr inbounds i16, i16* %621, i64 %1284
  %1286 = bitcast i16* %1285 to <8 x i16>*
  %1287 = load <8 x i16>, <8 x i16>* %1286, align 1
  %1288 = shl <8 x i16> %1287, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1289 = getelementptr inbounds i16, i16* %622, i64 %1284
  %1290 = bitcast i16* %1289 to <8 x i16>*
  store <8 x i16> %1288, <8 x i16>* %1290, align 16
  %1291 = add nuw nsw i64 %1284, 8
  %1292 = icmp slt i64 %1291, %19
  br i1 %1292, label %1283, label %1293

1293:                                             ; preds = %1283
  %1294 = getelementptr inbounds i16, i16* %621, i64 %4
  %1295 = getelementptr inbounds i16, i16* %622, i64 %19
  %1296 = add nsw i32 %609, -2
  %1297 = icmp eq i32 %1296, 0
  br i1 %1297, label %623, label %606
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_123SelfGuidedFilter_SSE4_1ERKNS_19RestorationUnitInfoEPKvlS6_lS6_liiPNS_17RestorationBufferEPv(%"struct.libgav1::RestorationUnitInfo"* nocapture readonly dereferenceable(96), i8* nocapture readonly, i64, i8* nocapture readonly, i64, i8* nocapture readonly, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8* nocapture) #2 {
  %12 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 1, i32 0
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds [16 x [4 x i8]], [16 x [4 x i8]]* @_ZN7libgav114kSgrProjParamsE, i64 0, i64 %14, i64 2
  %16 = load i8, i8* %15, align 2
  %17 = bitcast i8* %10 to i16*
  %18 = icmp eq i8 %16, 0
  br i1 %18, label %19, label %3497

19:                                               ; preds = %11
  %20 = getelementptr inbounds i8, i8* %1, i64 -6
  %21 = getelementptr inbounds i8, i8* %3, i64 -6
  %22 = bitcast i8* %21 to i16*
  %23 = getelementptr inbounds i8, i8* %5, i64 -6
  %24 = sext i32 %7 to i64
  %25 = add nsw i64 %24, 15
  %26 = and i64 %25, -16
  %27 = add nsw i64 %24, 23
  %28 = add nsw i64 %26, 16
  %29 = getelementptr inbounds [16 x [2 x i16]], [16 x [2 x i16]]* @_ZN7libgav118kSgrScaleParameterE, i64 0, i64 %14, i64 0
  %30 = load i16, i16* %29, align 4
  %31 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 1, i32 1, i64 0
  %32 = load i32, i32* %31, align 4
  %33 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 1, i64 0
  %34 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 1, i64 %28
  %35 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 3, i64 %28
  %36 = getelementptr inbounds i16, i16* %34, i64 %28
  %37 = getelementptr inbounds i32, i32* %35, i64 %28
  %38 = getelementptr inbounds i16, i16* %36, i64 %28
  %39 = getelementptr inbounds i32, i32* %37, i64 %28
  %40 = getelementptr inbounds i16, i16* %38, i64 %28
  %41 = getelementptr inbounds i32, i32* %39, i64 %28
  %42 = and i64 %27, -16
  %43 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 6, i64 0
  %44 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 9, i64 0
  %45 = sub nsw i64 %4, %42
  %46 = sub nsw i64 %28, %42
  br label %47

47:                                               ; preds = %170, %19
  %48 = phi i16* [ %22, %19 ], [ %171, %170 ]
  %49 = phi i16* [ %34, %19 ], [ %172, %170 ]
  %50 = phi i32* [ %35, %19 ], [ %173, %170 ]
  %51 = phi i32 [ 2, %19 ], [ %174, %170 ]
  %52 = bitcast i16* %48 to <2 x i64>*
  %53 = load <2 x i64>, <2 x i64>* %52, align 1
  %54 = bitcast <2 x i64> %53 to <8 x i16>
  %55 = shufflevector <8 x i16> %54, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %56 = shufflevector <8 x i16> %54, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %55, <8 x i16> %55) #5
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %56) #5
  br label %59

59:                                               ; preds = %59, %47
  %60 = phi <2 x i64> [ %53, %47 ], [ %73, %59 ]
  %61 = phi <4 x i32> [ %58, %47 ], [ %83, %59 ]
  %62 = phi <4 x i32> [ %57, %47 ], [ %82, %59 ]
  %63 = phi i16* [ %48, %47 ], [ %71, %59 ]
  %64 = phi i16* [ %49, %47 ], [ %167, %59 ]
  %65 = phi i32* [ %50, %47 ], [ %168, %59 ]
  %66 = phi i64 [ %42, %47 ], [ %70, %59 ]
  %67 = getelementptr inbounds i16, i16* %63, i64 8
  %68 = bitcast i16* %67 to <2 x i64>*
  %69 = load <2 x i64>, <2 x i64>* %68, align 1
  %70 = add nsw i64 %66, -16
  %71 = getelementptr inbounds i16, i16* %63, i64 16
  %72 = bitcast i16* %71 to <2 x i64>*
  %73 = load <2 x i64>, <2 x i64>* %72, align 1
  %74 = bitcast <2 x i64> %69 to <8 x i16>
  %75 = shufflevector <8 x i16> %74, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %76 = shufflevector <8 x i16> %74, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> %75) #5
  %78 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> %76) #5
  %79 = bitcast <2 x i64> %73 to <8 x i16>
  %80 = shufflevector <8 x i16> %79, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %81 = shufflevector <8 x i16> %79, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> %80) #5
  %83 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %81, <8 x i16> %81) #5
  %84 = bitcast <2 x i64> %60 to <8 x i16>
  %85 = bitcast <2 x i64> %69 to <16 x i8>
  %86 = bitcast <2 x i64> %60 to <16 x i8>
  %87 = shufflevector <16 x i8> %86, <16 x i8> %85, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %88 = bitcast <16 x i8> %87 to <8 x i16>
  %89 = shufflevector <16 x i8> %86, <16 x i8> %85, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %90 = bitcast <16 x i8> %89 to <8 x i16>
  %91 = shufflevector <16 x i8> %86, <16 x i8> %85, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %92 = bitcast <16 x i8> %91 to <8 x i16>
  %93 = shufflevector <16 x i8> %86, <16 x i8> %85, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %94 = bitcast <16 x i8> %93 to <8 x i16>
  %95 = add <8 x i16> %88, %84
  %96 = add <8 x i16> %95, %90
  %97 = add <8 x i16> %96, %92
  %98 = add <8 x i16> %97, %94
  %99 = bitcast <2 x i64> %73 to <16 x i8>
  %100 = shufflevector <16 x i8> %85, <16 x i8> %99, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %101 = bitcast <16 x i8> %100 to <8 x i16>
  %102 = shufflevector <16 x i8> %85, <16 x i8> %99, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %103 = bitcast <16 x i8> %102 to <8 x i16>
  %104 = shufflevector <16 x i8> %85, <16 x i8> %99, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %105 = bitcast <16 x i8> %104 to <8 x i16>
  %106 = shufflevector <16 x i8> %85, <16 x i8> %99, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %107 = bitcast <16 x i8> %106 to <8 x i16>
  %108 = add <8 x i16> %101, %74
  %109 = add <8 x i16> %108, %103
  %110 = add <8 x i16> %109, %105
  %111 = add <8 x i16> %110, %107
  %112 = bitcast <4 x i32> %61 to <16 x i8>
  %113 = bitcast <4 x i32> %62 to <16 x i8>
  %114 = shufflevector <16 x i8> %113, <16 x i8> %112, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %115 = bitcast <16 x i8> %114 to <4 x i32>
  %116 = shufflevector <16 x i8> %113, <16 x i8> %112, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %117 = bitcast <16 x i8> %116 to <4 x i32>
  %118 = shufflevector <16 x i8> %113, <16 x i8> %112, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %119 = bitcast <16 x i8> %118 to <4 x i32>
  %120 = add <4 x i32> %62, %61
  %121 = add <4 x i32> %120, %115
  %122 = add <4 x i32> %121, %117
  %123 = add <4 x i32> %122, %119
  %124 = bitcast <4 x i32> %77 to <16 x i8>
  %125 = shufflevector <16 x i8> %112, <16 x i8> %124, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %126 = bitcast <16 x i8> %125 to <4 x i32>
  %127 = shufflevector <16 x i8> %112, <16 x i8> %124, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %128 = bitcast <16 x i8> %127 to <4 x i32>
  %129 = shufflevector <16 x i8> %112, <16 x i8> %124, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %130 = bitcast <16 x i8> %129 to <4 x i32>
  %131 = add <4 x i32> %77, %61
  %132 = add <4 x i32> %131, %126
  %133 = add <4 x i32> %132, %128
  %134 = add <4 x i32> %133, %130
  %135 = bitcast <4 x i32> %78 to <16 x i8>
  %136 = shufflevector <16 x i8> %124, <16 x i8> %135, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %137 = bitcast <16 x i8> %136 to <4 x i32>
  %138 = shufflevector <16 x i8> %124, <16 x i8> %135, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %139 = bitcast <16 x i8> %138 to <4 x i32>
  %140 = shufflevector <16 x i8> %124, <16 x i8> %135, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %141 = bitcast <16 x i8> %140 to <4 x i32>
  %142 = add <4 x i32> %78, %77
  %143 = add <4 x i32> %142, %137
  %144 = add <4 x i32> %143, %139
  %145 = add <4 x i32> %144, %141
  %146 = bitcast <4 x i32> %82 to <16 x i8>
  %147 = shufflevector <16 x i8> %135, <16 x i8> %146, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %148 = bitcast <16 x i8> %147 to <4 x i32>
  %149 = shufflevector <16 x i8> %135, <16 x i8> %146, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %150 = bitcast <16 x i8> %149 to <4 x i32>
  %151 = shufflevector <16 x i8> %135, <16 x i8> %146, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %152 = bitcast <16 x i8> %151 to <4 x i32>
  %153 = add <4 x i32> %82, %78
  %154 = add <4 x i32> %153, %148
  %155 = add <4 x i32> %154, %150
  %156 = add <4 x i32> %155, %152
  %157 = bitcast i16* %64 to <8 x i16>*
  store <8 x i16> %98, <8 x i16>* %157, align 16
  %158 = getelementptr inbounds i16, i16* %64, i64 8
  %159 = bitcast i16* %158 to <8 x i16>*
  store <8 x i16> %111, <8 x i16>* %159, align 16
  %160 = bitcast i32* %65 to <4 x i32>*
  store <4 x i32> %123, <4 x i32>* %160, align 16
  %161 = getelementptr inbounds i32, i32* %65, i64 4
  %162 = bitcast i32* %161 to <4 x i32>*
  store <4 x i32> %134, <4 x i32>* %162, align 16
  %163 = getelementptr inbounds i32, i32* %65, i64 8
  %164 = bitcast i32* %163 to <4 x i32>*
  store <4 x i32> %145, <4 x i32>* %164, align 16
  %165 = getelementptr inbounds i32, i32* %65, i64 12
  %166 = bitcast i32* %165 to <4 x i32>*
  store <4 x i32> %156, <4 x i32>* %166, align 16
  %167 = getelementptr inbounds i16, i16* %64, i64 16
  %168 = getelementptr inbounds i32, i32* %65, i64 16
  %169 = icmp eq i64 %70, 0
  br i1 %169, label %170, label %59

170:                                              ; preds = %59
  %171 = getelementptr inbounds i16, i16* %71, i64 %45
  %172 = getelementptr inbounds i16, i16* %167, i64 %46
  %173 = getelementptr inbounds i32, i32* %168, i64 %46
  %174 = add nsw i32 %51, -1
  %175 = icmp eq i32 %174, 0
  br i1 %175, label %176, label %47

176:                                              ; preds = %170
  %177 = bitcast i8* %20 to i16*
  %178 = bitcast i8* %23 to i16*
  %179 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 3, i64 0
  %180 = ptrtoint i16* %34 to i64
  %181 = ptrtoint i32* %35 to i64
  %182 = ptrtoint i16* %36 to i64
  %183 = ptrtoint i32* %37 to i64
  %184 = ptrtoint i16* %38 to i64
  %185 = ptrtoint i32* %39 to i64
  %186 = ptrtoint i16* %40 to i64
  %187 = ptrtoint i32* %41 to i64
  %188 = zext i16 %30 to i32
  %189 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 6, i64 %26
  %190 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 9, i64 %26
  %191 = ptrtoint i16* %43 to i64
  %192 = ptrtoint i32* %44 to i64
  %193 = icmp sgt i32 %8, 1
  %194 = getelementptr inbounds i16, i16* %177, i64 %2
  %195 = select i1 %193, i16* %194, i16* %178
  %196 = bitcast i8* %20 to <8 x i16>*
  %197 = load <8 x i16>, <8 x i16>* %196, align 1
  %198 = getelementptr inbounds i8, i8* %1, i64 10
  %199 = bitcast i8* %198 to <2 x i64>*
  %200 = load <2 x i64>, <2 x i64>* %199, align 1
  %201 = bitcast i16* %195 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 1
  %203 = getelementptr inbounds i16, i16* %195, i64 8
  %204 = bitcast i16* %203 to <2 x i64>*
  %205 = load <2 x i64>, <2 x i64>* %204, align 1
  %206 = shufflevector <8 x i16> %197, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %207 = shufflevector <8 x i16> %197, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %208 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %206, <8 x i16> %206) #5
  %209 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %207, <8 x i16> %207) #5
  %210 = shufflevector <8 x i16> %202, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %211 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %212 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %210, <8 x i16> %210) #5
  %213 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %211, <8 x i16> %211) #5
  %214 = bitcast <2 x i64> %200 to <8 x i16>
  %215 = shufflevector <8 x i16> %214, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %216 = shufflevector <8 x i16> %214, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %215, <8 x i16> %215) #5
  %218 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %216, <8 x i16> %216) #5
  %219 = bitcast <2 x i64> %205 to <8 x i16>
  %220 = shufflevector <8 x i16> %219, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %221 = shufflevector <8 x i16> %219, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %222 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %220, <8 x i16> %220) #5
  %223 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %221, <8 x i16> %221) #5
  %224 = bitcast <2 x i64> %200 to <16 x i8>
  %225 = bitcast <8 x i16> %197 to <16 x i8>
  %226 = shufflevector <16 x i8> %225, <16 x i8> %224, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %227 = bitcast <16 x i8> %226 to <8 x i16>
  %228 = shufflevector <16 x i8> %225, <16 x i8> %224, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %229 = bitcast <16 x i8> %228 to <8 x i16>
  %230 = shufflevector <16 x i8> %225, <16 x i8> %224, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %231 = bitcast <16 x i8> %230 to <8 x i16>
  %232 = shufflevector <16 x i8> %225, <16 x i8> %224, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %233 = bitcast <16 x i8> %232 to <8 x i16>
  %234 = add <8 x i16> %197, %227
  %235 = add <8 x i16> %234, %229
  %236 = add <8 x i16> %235, %231
  %237 = add <8 x i16> %236, %233
  %238 = bitcast i16* %38 to <8 x i16>*
  store <8 x i16> %237, <8 x i16>* %238, align 16
  %239 = bitcast <2 x i64> %205 to <16 x i8>
  %240 = bitcast <8 x i16> %202 to <16 x i8>
  %241 = shufflevector <16 x i8> %240, <16 x i8> %239, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %242 = bitcast <16 x i8> %241 to <8 x i16>
  %243 = shufflevector <16 x i8> %240, <16 x i8> %239, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %244 = bitcast <16 x i8> %243 to <8 x i16>
  %245 = shufflevector <16 x i8> %240, <16 x i8> %239, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %246 = bitcast <16 x i8> %245 to <8 x i16>
  %247 = shufflevector <16 x i8> %240, <16 x i8> %239, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %248 = bitcast <16 x i8> %247 to <8 x i16>
  %249 = add <8 x i16> %202, %242
  %250 = add <8 x i16> %249, %244
  %251 = add <8 x i16> %250, %246
  %252 = add <8 x i16> %251, %248
  %253 = bitcast i16* %40 to <8 x i16>*
  store <8 x i16> %252, <8 x i16>* %253, align 16
  %254 = bitcast <4 x i32> %209 to <16 x i8>
  %255 = bitcast <4 x i32> %208 to <16 x i8>
  %256 = shufflevector <16 x i8> %255, <16 x i8> %254, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %257 = bitcast <16 x i8> %256 to <4 x i32>
  %258 = shufflevector <16 x i8> %255, <16 x i8> %254, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %259 = bitcast <16 x i8> %258 to <4 x i32>
  %260 = shufflevector <16 x i8> %255, <16 x i8> %254, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %261 = bitcast <16 x i8> %260 to <4 x i32>
  %262 = add <4 x i32> %209, %208
  %263 = add <4 x i32> %262, %257
  %264 = add <4 x i32> %263, %259
  %265 = add <4 x i32> %264, %261
  %266 = bitcast <4 x i32> %217 to <16 x i8>
  %267 = shufflevector <16 x i8> %254, <16 x i8> %266, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %268 = bitcast <16 x i8> %267 to <4 x i32>
  %269 = shufflevector <16 x i8> %254, <16 x i8> %266, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %270 = bitcast <16 x i8> %269 to <4 x i32>
  %271 = shufflevector <16 x i8> %254, <16 x i8> %266, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %272 = bitcast <16 x i8> %271 to <4 x i32>
  %273 = add <4 x i32> %217, %209
  %274 = add <4 x i32> %273, %268
  %275 = add <4 x i32> %274, %270
  %276 = add <4 x i32> %275, %272
  %277 = bitcast i32* %39 to <4 x i32>*
  store <4 x i32> %265, <4 x i32>* %277, align 16
  %278 = getelementptr inbounds i32, i32* %39, i64 4
  %279 = bitcast i32* %278 to <4 x i32>*
  store <4 x i32> %276, <4 x i32>* %279, align 16
  %280 = bitcast <4 x i32> %213 to <16 x i8>
  %281 = bitcast <4 x i32> %212 to <16 x i8>
  %282 = shufflevector <16 x i8> %281, <16 x i8> %280, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %283 = bitcast <16 x i8> %282 to <4 x i32>
  %284 = shufflevector <16 x i8> %281, <16 x i8> %280, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %285 = bitcast <16 x i8> %284 to <4 x i32>
  %286 = shufflevector <16 x i8> %281, <16 x i8> %280, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %287 = bitcast <16 x i8> %286 to <4 x i32>
  %288 = add <4 x i32> %213, %212
  %289 = add <4 x i32> %288, %283
  %290 = add <4 x i32> %289, %285
  %291 = add <4 x i32> %290, %287
  %292 = bitcast <4 x i32> %222 to <16 x i8>
  %293 = shufflevector <16 x i8> %280, <16 x i8> %292, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %294 = bitcast <16 x i8> %293 to <4 x i32>
  %295 = shufflevector <16 x i8> %280, <16 x i8> %292, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %296 = bitcast <16 x i8> %295 to <4 x i32>
  %297 = shufflevector <16 x i8> %280, <16 x i8> %292, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %298 = bitcast <16 x i8> %297 to <4 x i32>
  %299 = add <4 x i32> %222, %213
  %300 = add <4 x i32> %299, %294
  %301 = add <4 x i32> %300, %296
  %302 = add <4 x i32> %301, %298
  %303 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %291, <4 x i32>* %303, align 16
  %304 = getelementptr inbounds i32, i32* %41, i64 4
  %305 = bitcast i32* %304 to <4 x i32>*
  store <4 x i32> %302, <4 x i32>* %305, align 16
  %306 = bitcast i16* %34 to <8 x i16>*
  %307 = load <8 x i16>, <8 x i16>* %306, align 16
  %308 = bitcast i16* %36 to <8 x i16>*
  %309 = load <8 x i16>, <8 x i16>* %308, align 16
  %310 = bitcast i32* %35 to <4 x i32>*
  %311 = load <4 x i32>, <4 x i32>* %310, align 16
  %312 = getelementptr inbounds i32, i32* %35, i64 4
  %313 = bitcast i32* %312 to <4 x i32>*
  %314 = load <4 x i32>, <4 x i32>* %313, align 16
  %315 = bitcast i32* %37 to <4 x i32>*
  %316 = load <4 x i32>, <4 x i32>* %315, align 16
  %317 = getelementptr inbounds i32, i32* %37, i64 4
  %318 = bitcast i32* %317 to <4 x i32>*
  %319 = load <4 x i32>, <4 x i32>* %318, align 16
  %320 = shl <8 x i16> %307, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %321 = add <8 x i16> %252, %237
  %322 = add <8 x i16> %321, %309
  %323 = add <8 x i16> %322, %320
  %324 = add <8 x i16> %323, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %325 = lshr <8 x i16> %324, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %326 = shufflevector <8 x i16> %325, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %327 = shufflevector <8 x i16> %325, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %328 = shl <4 x i32> %311, <i32 1, i32 1, i32 1, i32 1>
  %329 = add <4 x i32> %265, <i32 8, i32 8, i32 8, i32 8>
  %330 = add <4 x i32> %329, %291
  %331 = add <4 x i32> %330, %328
  %332 = add <4 x i32> %331, %316
  %333 = lshr <4 x i32> %332, <i32 4, i32 4, i32 4, i32 4>
  %334 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %326, <8 x i16> %326) #5
  %335 = mul <4 x i32> %333, <i32 25, i32 25, i32 25, i32 25>
  %336 = sub <4 x i32> %335, %334
  %337 = icmp sgt <4 x i32> %336, zeroinitializer
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> zeroinitializer
  %339 = insertelement <4 x i32> undef, i32 %188, i32 0
  %340 = shufflevector <4 x i32> %339, <4 x i32> undef, <4 x i32> zeroinitializer
  %341 = mul <4 x i32> %338, %340
  %342 = add <4 x i32> %341, <i32 524288, i32 524288, i32 524288, i32 524288>
  %343 = lshr <4 x i32> %342, <i32 20, i32 20, i32 20, i32 20>
  %344 = shl <4 x i32> %314, <i32 1, i32 1, i32 1, i32 1>
  %345 = add <4 x i32> %276, <i32 8, i32 8, i32 8, i32 8>
  %346 = add <4 x i32> %345, %302
  %347 = add <4 x i32> %346, %344
  %348 = add <4 x i32> %347, %319
  %349 = lshr <4 x i32> %348, <i32 4, i32 4, i32 4, i32 4>
  %350 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %327, <8 x i16> %327) #5
  %351 = mul <4 x i32> %349, <i32 25, i32 25, i32 25, i32 25>
  %352 = sub <4 x i32> %351, %350
  %353 = icmp sgt <4 x i32> %352, zeroinitializer
  %354 = select <4 x i1> %353, <4 x i32> %352, <4 x i32> zeroinitializer
  %355 = mul <4 x i32> %354, %340
  %356 = add <4 x i32> %355, <i32 524288, i32 524288, i32 524288, i32 524288>
  %357 = lshr <4 x i32> %356, <i32 20, i32 20, i32 20, i32 20>
  %358 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %343, <4 x i32> %357) #5
  %359 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %358, <8 x i16> undef) #5
  %360 = bitcast <16 x i8> %359 to <2 x i64>
  %361 = extractelement <2 x i64> %360, i32 0
  %362 = lshr i64 %361, 8
  %363 = lshr i64 %361, 16
  %364 = lshr i64 %361, 24
  %365 = lshr i64 %361, 32
  %366 = lshr i64 %361, 40
  %367 = lshr i64 %361, 48
  %368 = lshr i64 %361, 56
  %369 = and i64 %361, 255
  %370 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %369
  %371 = load i8, i8* %370, align 1
  %372 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %371, i64 0
  %373 = and i64 %362, 255
  %374 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %373
  %375 = load i8, i8* %374, align 1
  %376 = insertelement <16 x i8> %372, i8 %375, i64 1
  %377 = and i64 %363, 255
  %378 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %377
  %379 = load i8, i8* %378, align 1
  %380 = insertelement <16 x i8> %376, i8 %379, i64 2
  %381 = and i64 %364, 255
  %382 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %381
  %383 = load i8, i8* %382, align 1
  %384 = insertelement <16 x i8> %380, i8 %383, i64 3
  %385 = and i64 %365, 255
  %386 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %385
  %387 = load i8, i8* %386, align 1
  %388 = insertelement <16 x i8> %384, i8 %387, i64 4
  %389 = and i64 %366, 255
  %390 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %389
  %391 = load i8, i8* %390, align 1
  %392 = insertelement <16 x i8> %388, i8 %391, i64 5
  %393 = and i64 %367, 255
  %394 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %393
  %395 = load i8, i8* %394, align 1
  %396 = insertelement <16 x i8> %392, i8 %395, i64 6
  %397 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %368
  %398 = load i8, i8* %397, align 1
  %399 = insertelement <16 x i8> %396, i8 %398, i64 7
  %400 = shufflevector <16 x i8> %399, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %401 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %400, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %402 = shufflevector <8 x i16> %401, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %403 = shufflevector <8 x i16> %323, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %404 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %402, <8 x i16> %403) #5
  %405 = shufflevector <8 x i16> %401, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> %406) #5
  %408 = add <4 x i32> %404, <i32 512, i32 512, i32 512, i32 512>
  %409 = lshr <4 x i32> %408, <i32 10, i32 10, i32 10, i32 10>
  %410 = getelementptr inbounds i16, i16* %38, i64 8
  %411 = getelementptr inbounds i16, i16* %40, i64 8
  %412 = getelementptr inbounds i32, i32* %39, i64 8
  %413 = getelementptr inbounds i32, i32* %41, i64 8
  br label %414

414:                                              ; preds = %414, %176
  %415 = phi i64 [ %432, %414 ], [ 0, %176 ]
  %416 = phi <2 x i64> [ %444, %414 ], [ %205, %176 ]
  %417 = phi <2 x i64> [ %437, %414 ], [ %200, %176 ]
  %418 = phi <16 x i8> [ %840, %414 ], [ <i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, %176 ]
  %419 = phi <16 x i8> [ %840, %414 ], [ %399, %176 ]
  %420 = phi <4 x i32> [ %691, %414 ], [ %223, %176 ]
  %421 = phi <4 x i32> [ %690, %414 ], [ %222, %176 ]
  %422 = phi <4 x i32> [ %686, %414 ], [ %218, %176 ]
  %423 = phi <4 x i32> [ %685, %414 ], [ %217, %176 ]
  %424 = phi <4 x i32> [ %848, %414 ], [ %407, %176 ]
  %425 = phi <4 x i32> [ %850, %414 ], [ %409, %176 ]
  %426 = phi i16* [ %919, %414 ], [ %43, %176 ]
  %427 = phi i32* [ %920, %414 ], [ %44, %176 ]
  %428 = add <4 x i32> %424, <i32 512, i32 512, i32 512, i32 512>
  %429 = lshr <4 x i32> %428, <i32 10, i32 10, i32 10, i32 10>
  %430 = getelementptr inbounds i16, i16* %177, i64 %415
  %431 = getelementptr inbounds i16, i16* %430, i64 16
  %432 = add nuw nsw i64 %415, 16
  %433 = bitcast i16* %431 to <2 x i64>*
  %434 = load <2 x i64>, <2 x i64>* %433, align 1
  %435 = getelementptr inbounds i16, i16* %430, i64 24
  %436 = bitcast i16* %435 to <2 x i64>*
  %437 = load <2 x i64>, <2 x i64>* %436, align 1
  %438 = getelementptr inbounds i16, i16* %195, i64 %415
  %439 = getelementptr inbounds i16, i16* %438, i64 16
  %440 = bitcast i16* %439 to <2 x i64>*
  %441 = load <2 x i64>, <2 x i64>* %440, align 1
  %442 = getelementptr inbounds i16, i16* %438, i64 24
  %443 = bitcast i16* %442 to <2 x i64>*
  %444 = load <2 x i64>, <2 x i64>* %443, align 1
  %445 = or i64 %415, 8
  %446 = bitcast <2 x i64> %434 to <8 x i16>
  %447 = shufflevector <8 x i16> %446, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %448 = shufflevector <8 x i16> %446, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %449 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %447, <8 x i16> %447) #5
  %450 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %448, <8 x i16> %448) #5
  %451 = bitcast <2 x i64> %441 to <8 x i16>
  %452 = shufflevector <8 x i16> %451, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %453 = shufflevector <8 x i16> %451, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %454 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %452, <8 x i16> %452) #5
  %455 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %453, <8 x i16> %453) #5
  %456 = bitcast <2 x i64> %417 to <8 x i16>
  %457 = bitcast <2 x i64> %434 to <16 x i8>
  %458 = bitcast <2 x i64> %417 to <16 x i8>
  %459 = shufflevector <16 x i8> %458, <16 x i8> %457, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %460 = bitcast <16 x i8> %459 to <8 x i16>
  %461 = shufflevector <16 x i8> %458, <16 x i8> %457, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %462 = bitcast <16 x i8> %461 to <8 x i16>
  %463 = shufflevector <16 x i8> %458, <16 x i8> %457, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %464 = bitcast <16 x i8> %463 to <8 x i16>
  %465 = shufflevector <16 x i8> %458, <16 x i8> %457, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %466 = bitcast <16 x i8> %465 to <8 x i16>
  %467 = add <8 x i16> %460, %456
  %468 = add <8 x i16> %467, %462
  %469 = add <8 x i16> %468, %464
  %470 = add <8 x i16> %469, %466
  %471 = bitcast <2 x i64> %437 to <16 x i8>
  %472 = shufflevector <16 x i8> %457, <16 x i8> %471, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %473 = bitcast <16 x i8> %472 to <8 x i16>
  %474 = shufflevector <16 x i8> %457, <16 x i8> %471, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %475 = bitcast <16 x i8> %474 to <8 x i16>
  %476 = shufflevector <16 x i8> %457, <16 x i8> %471, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %477 = bitcast <16 x i8> %476 to <8 x i16>
  %478 = shufflevector <16 x i8> %457, <16 x i8> %471, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %479 = bitcast <16 x i8> %478 to <8 x i16>
  %480 = add <8 x i16> %473, %446
  %481 = add <8 x i16> %480, %475
  %482 = add <8 x i16> %481, %477
  %483 = add <8 x i16> %482, %479
  %484 = getelementptr inbounds i16, i16* %38, i64 %445
  %485 = bitcast i16* %484 to <8 x i16>*
  store <8 x i16> %470, <8 x i16>* %485, align 16
  %486 = getelementptr inbounds i16, i16* %410, i64 %445
  %487 = bitcast i16* %486 to <8 x i16>*
  store <8 x i16> %483, <8 x i16>* %487, align 16
  %488 = bitcast <2 x i64> %416 to <8 x i16>
  %489 = bitcast <2 x i64> %441 to <16 x i8>
  %490 = bitcast <2 x i64> %416 to <16 x i8>
  %491 = shufflevector <16 x i8> %490, <16 x i8> %489, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %492 = bitcast <16 x i8> %491 to <8 x i16>
  %493 = shufflevector <16 x i8> %490, <16 x i8> %489, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %494 = bitcast <16 x i8> %493 to <8 x i16>
  %495 = shufflevector <16 x i8> %490, <16 x i8> %489, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %496 = bitcast <16 x i8> %495 to <8 x i16>
  %497 = shufflevector <16 x i8> %490, <16 x i8> %489, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %498 = bitcast <16 x i8> %497 to <8 x i16>
  %499 = add <8 x i16> %492, %488
  %500 = add <8 x i16> %499, %494
  %501 = add <8 x i16> %500, %496
  %502 = add <8 x i16> %501, %498
  %503 = bitcast <2 x i64> %444 to <16 x i8>
  %504 = shufflevector <16 x i8> %489, <16 x i8> %503, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %505 = bitcast <16 x i8> %504 to <8 x i16>
  %506 = shufflevector <16 x i8> %489, <16 x i8> %503, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %507 = bitcast <16 x i8> %506 to <8 x i16>
  %508 = shufflevector <16 x i8> %489, <16 x i8> %503, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %509 = bitcast <16 x i8> %508 to <8 x i16>
  %510 = shufflevector <16 x i8> %489, <16 x i8> %503, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %511 = bitcast <16 x i8> %510 to <8 x i16>
  %512 = add <8 x i16> %505, %451
  %513 = add <8 x i16> %512, %507
  %514 = add <8 x i16> %513, %509
  %515 = add <8 x i16> %514, %511
  %516 = getelementptr inbounds i16, i16* %40, i64 %445
  %517 = bitcast i16* %516 to <8 x i16>*
  store <8 x i16> %502, <8 x i16>* %517, align 16
  %518 = getelementptr inbounds i16, i16* %411, i64 %445
  %519 = bitcast i16* %518 to <8 x i16>*
  store <8 x i16> %515, <8 x i16>* %519, align 16
  %520 = bitcast <4 x i32> %422 to <16 x i8>
  %521 = bitcast <4 x i32> %423 to <16 x i8>
  %522 = shufflevector <16 x i8> %521, <16 x i8> %520, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %523 = bitcast <16 x i8> %522 to <4 x i32>
  %524 = shufflevector <16 x i8> %521, <16 x i8> %520, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %525 = bitcast <16 x i8> %524 to <4 x i32>
  %526 = shufflevector <16 x i8> %521, <16 x i8> %520, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %527 = bitcast <16 x i8> %526 to <4 x i32>
  %528 = add <4 x i32> %423, %422
  %529 = add <4 x i32> %528, %523
  %530 = add <4 x i32> %529, %525
  %531 = add <4 x i32> %530, %527
  %532 = bitcast <4 x i32> %449 to <16 x i8>
  %533 = shufflevector <16 x i8> %520, <16 x i8> %532, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %534 = bitcast <16 x i8> %533 to <4 x i32>
  %535 = shufflevector <16 x i8> %520, <16 x i8> %532, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %536 = bitcast <16 x i8> %535 to <4 x i32>
  %537 = shufflevector <16 x i8> %520, <16 x i8> %532, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %538 = bitcast <16 x i8> %537 to <4 x i32>
  %539 = add <4 x i32> %449, %422
  %540 = add <4 x i32> %539, %534
  %541 = add <4 x i32> %540, %536
  %542 = add <4 x i32> %541, %538
  %543 = getelementptr inbounds i32, i32* %39, i64 %445
  %544 = bitcast i32* %543 to <4 x i32>*
  store <4 x i32> %531, <4 x i32>* %544, align 16
  %545 = getelementptr inbounds i32, i32* %543, i64 4
  %546 = bitcast i32* %545 to <4 x i32>*
  store <4 x i32> %542, <4 x i32>* %546, align 16
  %547 = bitcast <4 x i32> %420 to <16 x i8>
  %548 = bitcast <4 x i32> %421 to <16 x i8>
  %549 = shufflevector <16 x i8> %548, <16 x i8> %547, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %550 = bitcast <16 x i8> %549 to <4 x i32>
  %551 = shufflevector <16 x i8> %548, <16 x i8> %547, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %552 = bitcast <16 x i8> %551 to <4 x i32>
  %553 = shufflevector <16 x i8> %548, <16 x i8> %547, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %554 = bitcast <16 x i8> %553 to <4 x i32>
  %555 = add <4 x i32> %421, %420
  %556 = add <4 x i32> %555, %550
  %557 = add <4 x i32> %556, %552
  %558 = add <4 x i32> %557, %554
  %559 = bitcast <4 x i32> %454 to <16 x i8>
  %560 = shufflevector <16 x i8> %547, <16 x i8> %559, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %561 = bitcast <16 x i8> %560 to <4 x i32>
  %562 = shufflevector <16 x i8> %547, <16 x i8> %559, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %563 = bitcast <16 x i8> %562 to <4 x i32>
  %564 = shufflevector <16 x i8> %547, <16 x i8> %559, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %565 = bitcast <16 x i8> %564 to <4 x i32>
  %566 = add <4 x i32> %454, %420
  %567 = add <4 x i32> %566, %561
  %568 = add <4 x i32> %567, %563
  %569 = add <4 x i32> %568, %565
  %570 = getelementptr inbounds i32, i32* %41, i64 %445
  %571 = bitcast i32* %570 to <4 x i32>*
  store <4 x i32> %558, <4 x i32>* %571, align 16
  %572 = getelementptr inbounds i32, i32* %570, i64 4
  %573 = bitcast i32* %572 to <4 x i32>*
  store <4 x i32> %569, <4 x i32>* %573, align 16
  %574 = getelementptr inbounds i16, i16* %34, i64 %445
  %575 = bitcast i16* %574 to <8 x i16>*
  %576 = load <8 x i16>, <8 x i16>* %575, align 16
  %577 = getelementptr inbounds i16, i16* %36, i64 %445
  %578 = bitcast i16* %577 to <8 x i16>*
  %579 = load <8 x i16>, <8 x i16>* %578, align 16
  %580 = getelementptr inbounds i32, i32* %35, i64 %445
  %581 = bitcast i32* %580 to <4 x i32>*
  %582 = load <4 x i32>, <4 x i32>* %581, align 16
  %583 = getelementptr inbounds i32, i32* %580, i64 4
  %584 = bitcast i32* %583 to <4 x i32>*
  %585 = load <4 x i32>, <4 x i32>* %584, align 16
  %586 = getelementptr inbounds i32, i32* %37, i64 %445
  %587 = bitcast i32* %586 to <4 x i32>*
  %588 = load <4 x i32>, <4 x i32>* %587, align 16
  %589 = getelementptr inbounds i32, i32* %586, i64 4
  %590 = bitcast i32* %589 to <4 x i32>*
  %591 = load <4 x i32>, <4 x i32>* %590, align 16
  %592 = shl <8 x i16> %576, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %593 = add <8 x i16> %502, %470
  %594 = add <8 x i16> %593, %579
  %595 = add <8 x i16> %594, %592
  %596 = add <8 x i16> %595, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %597 = lshr <8 x i16> %596, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %598 = shufflevector <8 x i16> %597, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %599 = shufflevector <8 x i16> %597, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %600 = shl <4 x i32> %582, <i32 1, i32 1, i32 1, i32 1>
  %601 = add <4 x i32> %558, <i32 8, i32 8, i32 8, i32 8>
  %602 = add <4 x i32> %601, %531
  %603 = add <4 x i32> %602, %600
  %604 = add <4 x i32> %603, %588
  %605 = lshr <4 x i32> %604, <i32 4, i32 4, i32 4, i32 4>
  %606 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %598, <8 x i16> %598) #5
  %607 = mul <4 x i32> %605, <i32 25, i32 25, i32 25, i32 25>
  %608 = sub <4 x i32> %607, %606
  %609 = icmp sgt <4 x i32> %608, zeroinitializer
  %610 = select <4 x i1> %609, <4 x i32> %608, <4 x i32> zeroinitializer
  %611 = mul <4 x i32> %610, %340
  %612 = add <4 x i32> %611, <i32 524288, i32 524288, i32 524288, i32 524288>
  %613 = lshr <4 x i32> %612, <i32 20, i32 20, i32 20, i32 20>
  %614 = shl <4 x i32> %585, <i32 1, i32 1, i32 1, i32 1>
  %615 = add <4 x i32> %542, <i32 8, i32 8, i32 8, i32 8>
  %616 = add <4 x i32> %615, %569
  %617 = add <4 x i32> %616, %614
  %618 = add <4 x i32> %617, %591
  %619 = lshr <4 x i32> %618, <i32 4, i32 4, i32 4, i32 4>
  %620 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %599, <8 x i16> %599) #5
  %621 = mul <4 x i32> %619, <i32 25, i32 25, i32 25, i32 25>
  %622 = sub <4 x i32> %621, %620
  %623 = icmp sgt <4 x i32> %622, zeroinitializer
  %624 = select <4 x i1> %623, <4 x i32> %622, <4 x i32> zeroinitializer
  %625 = mul <4 x i32> %624, %340
  %626 = add <4 x i32> %625, <i32 524288, i32 524288, i32 524288, i32 524288>
  %627 = lshr <4 x i32> %626, <i32 20, i32 20, i32 20, i32 20>
  %628 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %613, <4 x i32> %627) #5
  %629 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %628, <8 x i16> undef) #5
  %630 = bitcast <16 x i8> %629 to <2 x i64>
  %631 = extractelement <2 x i64> %630, i32 0
  %632 = lshr i64 %631, 8
  %633 = lshr i64 %631, 16
  %634 = lshr i64 %631, 24
  %635 = lshr i64 %631, 32
  %636 = lshr i64 %631, 40
  %637 = lshr i64 %631, 48
  %638 = lshr i64 %631, 56
  %639 = and i64 %631, 255
  %640 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %639
  %641 = load i8, i8* %640, align 1
  %642 = insertelement <16 x i8> %419, i8 %641, i64 8
  %643 = and i64 %632, 255
  %644 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %643
  %645 = load i8, i8* %644, align 1
  %646 = insertelement <16 x i8> %642, i8 %645, i64 9
  %647 = and i64 %633, 255
  %648 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %647
  %649 = load i8, i8* %648, align 1
  %650 = insertelement <16 x i8> %646, i8 %649, i64 10
  %651 = and i64 %634, 255
  %652 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %651
  %653 = load i8, i8* %652, align 1
  %654 = insertelement <16 x i8> %650, i8 %653, i64 11
  %655 = and i64 %635, 255
  %656 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %655
  %657 = load i8, i8* %656, align 1
  %658 = insertelement <16 x i8> %654, i8 %657, i64 12
  %659 = and i64 %636, 255
  %660 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %659
  %661 = load i8, i8* %660, align 1
  %662 = insertelement <16 x i8> %658, i8 %661, i64 13
  %663 = and i64 %637, 255
  %664 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %663
  %665 = load i8, i8* %664, align 1
  %666 = insertelement <16 x i8> %662, i8 %665, i64 14
  %667 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %638
  %668 = load i8, i8* %667, align 1
  %669 = insertelement <16 x i8> %666, i8 %668, i64 15
  %670 = shufflevector <16 x i8> %669, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %671 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %670, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %672 = shufflevector <8 x i16> %671, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %673 = shufflevector <8 x i16> %595, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %674 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %672, <8 x i16> %673) #5
  %675 = shufflevector <8 x i16> %671, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %676 = shufflevector <8 x i16> %595, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %677 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %675, <8 x i16> %676) #5
  %678 = add <4 x i32> %674, <i32 512, i32 512, i32 512, i32 512>
  %679 = lshr <4 x i32> %678, <i32 10, i32 10, i32 10, i32 10>
  %680 = add <4 x i32> %677, <i32 512, i32 512, i32 512, i32 512>
  %681 = lshr <4 x i32> %680, <i32 10, i32 10, i32 10, i32 10>
  %682 = bitcast <2 x i64> %437 to <8 x i16>
  %683 = shufflevector <8 x i16> %682, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %684 = shufflevector <8 x i16> %682, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %685 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %683, <8 x i16> %683) #5
  %686 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %684, <8 x i16> %684) #5
  %687 = bitcast <2 x i64> %444 to <8 x i16>
  %688 = shufflevector <8 x i16> %687, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %689 = shufflevector <8 x i16> %687, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %690 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %688, <8 x i16> %688) #5
  %691 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %689, <8 x i16> %689) #5
  %692 = bitcast <4 x i32> %450 to <16 x i8>
  %693 = shufflevector <16 x i8> %532, <16 x i8> %692, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %694 = bitcast <16 x i8> %693 to <4 x i32>
  %695 = shufflevector <16 x i8> %532, <16 x i8> %692, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %696 = bitcast <16 x i8> %695 to <4 x i32>
  %697 = shufflevector <16 x i8> %532, <16 x i8> %692, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %698 = bitcast <16 x i8> %697 to <4 x i32>
  %699 = add <4 x i32> %450, %449
  %700 = add <4 x i32> %699, %694
  %701 = add <4 x i32> %700, %696
  %702 = add <4 x i32> %701, %698
  %703 = bitcast <4 x i32> %685 to <16 x i8>
  %704 = shufflevector <16 x i8> %692, <16 x i8> %703, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %705 = bitcast <16 x i8> %704 to <4 x i32>
  %706 = shufflevector <16 x i8> %692, <16 x i8> %703, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %707 = bitcast <16 x i8> %706 to <4 x i32>
  %708 = shufflevector <16 x i8> %692, <16 x i8> %703, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %709 = bitcast <16 x i8> %708 to <4 x i32>
  %710 = add <4 x i32> %685, %450
  %711 = add <4 x i32> %710, %705
  %712 = add <4 x i32> %711, %707
  %713 = add <4 x i32> %712, %709
  %714 = getelementptr inbounds i32, i32* %412, i64 %445
  %715 = bitcast i32* %714 to <4 x i32>*
  store <4 x i32> %702, <4 x i32>* %715, align 16
  %716 = getelementptr inbounds i32, i32* %714, i64 4
  %717 = bitcast i32* %716 to <4 x i32>*
  store <4 x i32> %713, <4 x i32>* %717, align 16
  %718 = bitcast <4 x i32> %455 to <16 x i8>
  %719 = shufflevector <16 x i8> %559, <16 x i8> %718, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %720 = bitcast <16 x i8> %719 to <4 x i32>
  %721 = shufflevector <16 x i8> %559, <16 x i8> %718, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %722 = bitcast <16 x i8> %721 to <4 x i32>
  %723 = shufflevector <16 x i8> %559, <16 x i8> %718, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %724 = bitcast <16 x i8> %723 to <4 x i32>
  %725 = add <4 x i32> %455, %454
  %726 = add <4 x i32> %725, %720
  %727 = add <4 x i32> %726, %722
  %728 = add <4 x i32> %727, %724
  %729 = bitcast <4 x i32> %690 to <16 x i8>
  %730 = shufflevector <16 x i8> %718, <16 x i8> %729, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %731 = bitcast <16 x i8> %730 to <4 x i32>
  %732 = shufflevector <16 x i8> %718, <16 x i8> %729, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %733 = bitcast <16 x i8> %732 to <4 x i32>
  %734 = shufflevector <16 x i8> %718, <16 x i8> %729, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %735 = bitcast <16 x i8> %734 to <4 x i32>
  %736 = add <4 x i32> %690, %455
  %737 = add <4 x i32> %736, %731
  %738 = add <4 x i32> %737, %733
  %739 = add <4 x i32> %738, %735
  %740 = getelementptr inbounds i32, i32* %413, i64 %445
  %741 = bitcast i32* %740 to <4 x i32>*
  store <4 x i32> %728, <4 x i32>* %741, align 16
  %742 = getelementptr inbounds i32, i32* %740, i64 4
  %743 = bitcast i32* %742 to <4 x i32>*
  store <4 x i32> %739, <4 x i32>* %743, align 16
  %744 = add nuw nsw i64 %445, 8
  %745 = getelementptr inbounds i16, i16* %34, i64 %744
  %746 = bitcast i16* %745 to <8 x i16>*
  %747 = load <8 x i16>, <8 x i16>* %746, align 16
  %748 = getelementptr inbounds i16, i16* %36, i64 %744
  %749 = bitcast i16* %748 to <8 x i16>*
  %750 = load <8 x i16>, <8 x i16>* %749, align 16
  %751 = getelementptr inbounds i32, i32* %35, i64 %744
  %752 = bitcast i32* %751 to <4 x i32>*
  %753 = load <4 x i32>, <4 x i32>* %752, align 16
  %754 = getelementptr inbounds i32, i32* %751, i64 4
  %755 = bitcast i32* %754 to <4 x i32>*
  %756 = load <4 x i32>, <4 x i32>* %755, align 16
  %757 = getelementptr inbounds i32, i32* %37, i64 %744
  %758 = bitcast i32* %757 to <4 x i32>*
  %759 = load <4 x i32>, <4 x i32>* %758, align 16
  %760 = getelementptr inbounds i32, i32* %757, i64 4
  %761 = bitcast i32* %760 to <4 x i32>*
  %762 = load <4 x i32>, <4 x i32>* %761, align 16
  %763 = shl <8 x i16> %747, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %764 = add <8 x i16> %515, %483
  %765 = add <8 x i16> %764, %750
  %766 = add <8 x i16> %765, %763
  %767 = add <8 x i16> %766, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %768 = lshr <8 x i16> %767, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %769 = shufflevector <8 x i16> %768, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %770 = shufflevector <8 x i16> %768, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %771 = shl <4 x i32> %753, <i32 1, i32 1, i32 1, i32 1>
  %772 = add <4 x i32> %702, <i32 8, i32 8, i32 8, i32 8>
  %773 = add <4 x i32> %772, %728
  %774 = add <4 x i32> %773, %771
  %775 = add <4 x i32> %774, %759
  %776 = lshr <4 x i32> %775, <i32 4, i32 4, i32 4, i32 4>
  %777 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %769, <8 x i16> %769) #5
  %778 = mul <4 x i32> %776, <i32 25, i32 25, i32 25, i32 25>
  %779 = sub <4 x i32> %778, %777
  %780 = icmp sgt <4 x i32> %779, zeroinitializer
  %781 = select <4 x i1> %780, <4 x i32> %779, <4 x i32> zeroinitializer
  %782 = mul <4 x i32> %781, %340
  %783 = add <4 x i32> %782, <i32 524288, i32 524288, i32 524288, i32 524288>
  %784 = lshr <4 x i32> %783, <i32 20, i32 20, i32 20, i32 20>
  %785 = shl <4 x i32> %756, <i32 1, i32 1, i32 1, i32 1>
  %786 = add <4 x i32> %713, <i32 8, i32 8, i32 8, i32 8>
  %787 = add <4 x i32> %786, %739
  %788 = add <4 x i32> %787, %785
  %789 = add <4 x i32> %788, %762
  %790 = lshr <4 x i32> %789, <i32 4, i32 4, i32 4, i32 4>
  %791 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %770, <8 x i16> %770) #5
  %792 = mul <4 x i32> %790, <i32 25, i32 25, i32 25, i32 25>
  %793 = sub <4 x i32> %792, %791
  %794 = icmp sgt <4 x i32> %793, zeroinitializer
  %795 = select <4 x i1> %794, <4 x i32> %793, <4 x i32> zeroinitializer
  %796 = mul <4 x i32> %795, %340
  %797 = add <4 x i32> %796, <i32 524288, i32 524288, i32 524288, i32 524288>
  %798 = lshr <4 x i32> %797, <i32 20, i32 20, i32 20, i32 20>
  %799 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %784, <4 x i32> %798) #5
  %800 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %799, <8 x i16> undef) #5
  %801 = bitcast <16 x i8> %800 to <2 x i64>
  %802 = extractelement <2 x i64> %801, i32 0
  %803 = lshr i64 %802, 8
  %804 = lshr i64 %802, 16
  %805 = lshr i64 %802, 24
  %806 = lshr i64 %802, 32
  %807 = lshr i64 %802, 40
  %808 = lshr i64 %802, 48
  %809 = lshr i64 %802, 56
  %810 = and i64 %802, 255
  %811 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %810
  %812 = load i8, i8* %811, align 1
  %813 = insertelement <16 x i8> %418, i8 %812, i64 0
  %814 = and i64 %803, 255
  %815 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %814
  %816 = load i8, i8* %815, align 1
  %817 = insertelement <16 x i8> %813, i8 %816, i64 1
  %818 = and i64 %804, 255
  %819 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %818
  %820 = load i8, i8* %819, align 1
  %821 = insertelement <16 x i8> %817, i8 %820, i64 2
  %822 = and i64 %805, 255
  %823 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %822
  %824 = load i8, i8* %823, align 1
  %825 = insertelement <16 x i8> %821, i8 %824, i64 3
  %826 = and i64 %806, 255
  %827 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %826
  %828 = load i8, i8* %827, align 1
  %829 = insertelement <16 x i8> %825, i8 %828, i64 4
  %830 = and i64 %807, 255
  %831 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %830
  %832 = load i8, i8* %831, align 1
  %833 = insertelement <16 x i8> %829, i8 %832, i64 5
  %834 = and i64 %808, 255
  %835 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %834
  %836 = load i8, i8* %835, align 1
  %837 = insertelement <16 x i8> %833, i8 %836, i64 6
  %838 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %809
  %839 = load i8, i8* %838, align 1
  %840 = insertelement <16 x i8> %837, i8 %839, i64 7
  %841 = shufflevector <16 x i8> %840, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %842 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %841, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %843 = shufflevector <8 x i16> %842, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %844 = shufflevector <8 x i16> %766, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %845 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %843, <8 x i16> %844) #5
  %846 = shufflevector <8 x i16> %842, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %847 = shufflevector <8 x i16> %766, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %848 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %846, <8 x i16> %847) #5
  %849 = add <4 x i32> %845, <i32 512, i32 512, i32 512, i32 512>
  %850 = lshr <4 x i32> %849, <i32 10, i32 10, i32 10, i32 10>
  %851 = shufflevector <16 x i8> %669, <16 x i8> %840, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %852 = shufflevector <16 x i8> %669, <16 x i8> %840, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %853 = shufflevector <16 x i8> %669, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %854 = shufflevector <16 x i8> %851, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %855 = bitcast <16 x i8> %853 to <8 x i16>
  %856 = bitcast <16 x i8> %854 to <8 x i16>
  %857 = add <8 x i16> %856, %855
  %858 = shufflevector <16 x i8> %852, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %859 = bitcast <16 x i8> %858 to <8 x i16>
  %860 = add <8 x i16> %857, %859
  %861 = mul <8 x i16> %860, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %862 = add <8 x i16> %861, %856
  %863 = shufflevector <16 x i8> %851, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %864 = bitcast <16 x i8> %670 to <8 x i16>
  %865 = bitcast <16 x i8> %863 to <8 x i16>
  %866 = add <8 x i16> %865, %864
  %867 = shufflevector <16 x i8> %852, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %868 = bitcast <16 x i8> %867 to <8 x i16>
  %869 = add <8 x i16> %866, %868
  %870 = mul <8 x i16> %869, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %871 = add <8 x i16> %870, %865
  %872 = bitcast i16* %426 to <8 x i16>*
  store <8 x i16> %862, <8 x i16>* %872, align 16
  %873 = getelementptr inbounds i16, i16* %426, i64 8
  %874 = bitcast i16* %873 to <8 x i16>*
  store <8 x i16> %871, <8 x i16>* %874, align 16
  %875 = bitcast <4 x i32> %429 to <16 x i8>
  %876 = bitcast <4 x i32> %425 to <16 x i8>
  %877 = shufflevector <16 x i8> %876, <16 x i8> %875, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %878 = bitcast <16 x i8> %877 to <4 x i32>
  %879 = shufflevector <16 x i8> %876, <16 x i8> %875, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %880 = bitcast <16 x i8> %879 to <4 x i32>
  %881 = add <4 x i32> %425, %878
  %882 = add <4 x i32> %881, %880
  %883 = mul <4 x i32> %882, <i32 5, i32 5, i32 5, i32 5>
  %884 = add <4 x i32> %883, %878
  %885 = bitcast <4 x i32> %679 to <16 x i8>
  %886 = shufflevector <16 x i8> %875, <16 x i8> %885, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %887 = bitcast <16 x i8> %886 to <4 x i32>
  %888 = shufflevector <16 x i8> %875, <16 x i8> %885, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %889 = bitcast <16 x i8> %888 to <4 x i32>
  %890 = add <4 x i32> %429, %887
  %891 = add <4 x i32> %890, %889
  %892 = mul <4 x i32> %891, <i32 5, i32 5, i32 5, i32 5>
  %893 = add <4 x i32> %892, %887
  %894 = bitcast <4 x i32> %681 to <16 x i8>
  %895 = shufflevector <16 x i8> %885, <16 x i8> %894, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %896 = bitcast <16 x i8> %895 to <4 x i32>
  %897 = shufflevector <16 x i8> %885, <16 x i8> %894, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %898 = bitcast <16 x i8> %897 to <4 x i32>
  %899 = add <4 x i32> %679, %896
  %900 = add <4 x i32> %899, %898
  %901 = mul <4 x i32> %900, <i32 5, i32 5, i32 5, i32 5>
  %902 = add <4 x i32> %901, %896
  %903 = bitcast <4 x i32> %850 to <16 x i8>
  %904 = shufflevector <16 x i8> %894, <16 x i8> %903, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %905 = bitcast <16 x i8> %904 to <4 x i32>
  %906 = shufflevector <16 x i8> %894, <16 x i8> %903, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %907 = bitcast <16 x i8> %906 to <4 x i32>
  %908 = add <4 x i32> %681, %905
  %909 = add <4 x i32> %908, %907
  %910 = mul <4 x i32> %909, <i32 5, i32 5, i32 5, i32 5>
  %911 = add <4 x i32> %910, %905
  %912 = bitcast i32* %427 to <4 x i32>*
  store <4 x i32> %884, <4 x i32>* %912, align 16
  %913 = getelementptr inbounds i32, i32* %427, i64 4
  %914 = bitcast i32* %913 to <4 x i32>*
  store <4 x i32> %893, <4 x i32>* %914, align 16
  %915 = getelementptr inbounds i32, i32* %427, i64 8
  %916 = bitcast i32* %915 to <4 x i32>*
  store <4 x i32> %902, <4 x i32>* %916, align 16
  %917 = getelementptr inbounds i32, i32* %427, i64 12
  %918 = bitcast i32* %917 to <4 x i32>*
  store <4 x i32> %911, <4 x i32>* %918, align 16
  %919 = getelementptr inbounds i16, i16* %426, i64 16
  %920 = getelementptr inbounds i32, i32* %427, i64 16
  %921 = icmp slt i64 %432, %24
  br i1 %921, label %414, label %922

922:                                              ; preds = %414
  %923 = ptrtoint i16* %189 to i64
  %924 = ptrtoint i32* %190 to i64
  %925 = ashr i32 %8, 1
  %926 = shl nsw i64 %2, 1
  %927 = mul nsw i64 %2, 3
  %928 = shl i32 %32, 16
  %929 = ashr exact i32 %928, 16
  %930 = insertelement <4 x i32> undef, i32 %929, i32 0
  %931 = shufflevector <4 x i32> %930, <4 x i32> undef, <4 x i32> zeroinitializer
  %932 = bitcast <4 x i32> %931 to <8 x i16>
  %933 = ptrtoint i16* %33 to i64
  %934 = ptrtoint i32* %179 to i64
  %935 = add nsw i32 %925, -1
  %936 = icmp sgt i32 %935, 0
  br i1 %936, label %957, label %937

937:                                              ; preds = %1897, %922
  %938 = phi i64 [ %186, %922 ], [ %971, %1897 ]
  %939 = phi i64 [ %184, %922 ], [ %965, %1897 ]
  %940 = phi i64 [ %182, %922 ], [ %974, %1897 ]
  %941 = phi i64 [ %180, %922 ], [ %973, %1897 ]
  %942 = phi i64 [ %187, %922 ], [ %967, %1897 ]
  %943 = phi i64 [ %185, %922 ], [ %966, %1897 ]
  %944 = phi i64 [ %183, %922 ], [ %970, %1897 ]
  %945 = phi i64 [ %181, %922 ], [ %969, %1897 ]
  %946 = phi i64 [ %934, %922 ], [ %968, %1897 ]
  %947 = phi i64 [ %933, %922 ], [ %972, %1897 ]
  %948 = phi i64 [ %923, %922 ], [ %963, %1897 ]
  %949 = phi i64 [ %191, %922 ], [ %964, %1897 ]
  %950 = phi i64 [ %924, %922 ], [ %961, %1897 ]
  %951 = phi i64 [ %192, %922 ], [ %962, %1897 ]
  %952 = phi i16* [ %17, %922 ], [ %1898, %1897 ]
  %953 = phi i16* [ %177, %922 ], [ %977, %1897 ]
  %954 = and i32 %8, 1
  %955 = icmp eq i32 %954, 0
  %956 = or i1 %193, %955
  br i1 %956, label %1901, label %2826

957:                                              ; preds = %922, %1897
  %958 = phi i32 [ %1899, %1897 ], [ %935, %922 ]
  %959 = phi i16* [ %977, %1897 ], [ %177, %922 ]
  %960 = phi i16* [ %1898, %1897 ], [ %17, %922 ]
  %961 = phi i64 [ %962, %1897 ], [ %192, %922 ]
  %962 = phi i64 [ %961, %1897 ], [ %924, %922 ]
  %963 = phi i64 [ %964, %1897 ], [ %191, %922 ]
  %964 = phi i64 [ %963, %1897 ], [ %923, %922 ]
  %965 = phi i64 [ %972, %1897 ], [ %933, %922 ]
  %966 = phi i64 [ %968, %1897 ], [ %934, %922 ]
  %967 = phi i64 [ %969, %1897 ], [ %181, %922 ]
  %968 = phi i64 [ %970, %1897 ], [ %183, %922 ]
  %969 = phi i64 [ %966, %1897 ], [ %185, %922 ]
  %970 = phi i64 [ %967, %1897 ], [ %187, %922 ]
  %971 = phi i64 [ %973, %1897 ], [ %180, %922 ]
  %972 = phi i64 [ %974, %1897 ], [ %182, %922 ]
  %973 = phi i64 [ %965, %1897 ], [ %184, %922 ]
  %974 = phi i64 [ %971, %1897 ], [ %186, %922 ]
  %975 = inttoptr i64 %965 to <8 x i16>*
  %976 = getelementptr inbounds i16, i16* %959, i64 3
  %977 = getelementptr inbounds i16, i16* %959, i64 %926
  %978 = getelementptr inbounds i16, i16* %959, i64 %927
  %979 = bitcast i16* %977 to <8 x i16>*
  %980 = load <8 x i16>, <8 x i16>* %979, align 1
  %981 = getelementptr inbounds i16, i16* %977, i64 8
  %982 = bitcast i16* %981 to <2 x i64>*
  %983 = load <2 x i64>, <2 x i64>* %982, align 1
  %984 = bitcast i16* %978 to <8 x i16>*
  %985 = load <8 x i16>, <8 x i16>* %984, align 1
  %986 = getelementptr inbounds i16, i16* %978, i64 8
  %987 = bitcast i16* %986 to <2 x i64>*
  %988 = load <2 x i64>, <2 x i64>* %987, align 1
  %989 = shufflevector <8 x i16> %980, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %990 = shufflevector <8 x i16> %980, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %991 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %989, <8 x i16> %989) #5
  %992 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %990, <8 x i16> %990) #5
  %993 = shufflevector <8 x i16> %985, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %994 = shufflevector <8 x i16> %985, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %995 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %993, <8 x i16> %993) #5
  %996 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %994, <8 x i16> %994) #5
  %997 = bitcast <2 x i64> %983 to <8 x i16>
  %998 = shufflevector <8 x i16> %997, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %999 = shufflevector <8 x i16> %997, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1000 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %998, <8 x i16> %998) #5
  %1001 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %999, <8 x i16> %999) #5
  %1002 = bitcast <2 x i64> %988 to <8 x i16>
  %1003 = shufflevector <8 x i16> %1002, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1004 = shufflevector <8 x i16> %1002, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1005 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1003, <8 x i16> %1003) #5
  %1006 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1004, <8 x i16> %1004) #5
  %1007 = bitcast <2 x i64> %983 to <16 x i8>
  %1008 = bitcast <8 x i16> %980 to <16 x i8>
  %1009 = shufflevector <16 x i8> %1008, <16 x i8> %1007, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1010 = bitcast <16 x i8> %1009 to <8 x i16>
  %1011 = shufflevector <16 x i8> %1008, <16 x i8> %1007, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1012 = bitcast <16 x i8> %1011 to <8 x i16>
  %1013 = shufflevector <16 x i8> %1008, <16 x i8> %1007, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %1014 = bitcast <16 x i8> %1013 to <8 x i16>
  %1015 = shufflevector <16 x i8> %1008, <16 x i8> %1007, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1016 = bitcast <16 x i8> %1015 to <8 x i16>
  %1017 = add <8 x i16> %980, %1010
  %1018 = add <8 x i16> %1017, %1012
  %1019 = add <8 x i16> %1018, %1014
  %1020 = add <8 x i16> %1019, %1016
  store <8 x i16> %1020, <8 x i16>* %975, align 16
  %1021 = bitcast <2 x i64> %988 to <16 x i8>
  %1022 = bitcast <8 x i16> %985 to <16 x i8>
  %1023 = shufflevector <16 x i8> %1022, <16 x i8> %1021, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1024 = bitcast <16 x i8> %1023 to <8 x i16>
  %1025 = shufflevector <16 x i8> %1022, <16 x i8> %1021, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1026 = bitcast <16 x i8> %1025 to <8 x i16>
  %1027 = shufflevector <16 x i8> %1022, <16 x i8> %1021, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %1028 = bitcast <16 x i8> %1027 to <8 x i16>
  %1029 = shufflevector <16 x i8> %1022, <16 x i8> %1021, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1030 = bitcast <16 x i8> %1029 to <8 x i16>
  %1031 = add <8 x i16> %985, %1024
  %1032 = add <8 x i16> %1031, %1026
  %1033 = add <8 x i16> %1032, %1028
  %1034 = add <8 x i16> %1033, %1030
  %1035 = inttoptr i64 %971 to <8 x i16>*
  store <8 x i16> %1034, <8 x i16>* %1035, align 16
  %1036 = bitcast <4 x i32> %992 to <16 x i8>
  %1037 = bitcast <4 x i32> %991 to <16 x i8>
  %1038 = shufflevector <16 x i8> %1037, <16 x i8> %1036, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1039 = bitcast <16 x i8> %1038 to <4 x i32>
  %1040 = shufflevector <16 x i8> %1037, <16 x i8> %1036, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1041 = bitcast <16 x i8> %1040 to <4 x i32>
  %1042 = shufflevector <16 x i8> %1037, <16 x i8> %1036, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1043 = bitcast <16 x i8> %1042 to <4 x i32>
  %1044 = add <4 x i32> %992, %991
  %1045 = add <4 x i32> %1044, %1039
  %1046 = add <4 x i32> %1045, %1041
  %1047 = add <4 x i32> %1046, %1043
  %1048 = bitcast <4 x i32> %1000 to <16 x i8>
  %1049 = shufflevector <16 x i8> %1036, <16 x i8> %1048, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1050 = bitcast <16 x i8> %1049 to <4 x i32>
  %1051 = shufflevector <16 x i8> %1036, <16 x i8> %1048, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1052 = bitcast <16 x i8> %1051 to <4 x i32>
  %1053 = shufflevector <16 x i8> %1036, <16 x i8> %1048, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1054 = bitcast <16 x i8> %1053 to <4 x i32>
  %1055 = add <4 x i32> %1000, %992
  %1056 = add <4 x i32> %1055, %1050
  %1057 = add <4 x i32> %1056, %1052
  %1058 = add <4 x i32> %1057, %1054
  %1059 = inttoptr i64 %966 to i32*
  %1060 = inttoptr i64 %966 to <4 x i32>*
  store <4 x i32> %1047, <4 x i32>* %1060, align 16
  %1061 = getelementptr inbounds i32, i32* %1059, i64 4
  %1062 = bitcast i32* %1061 to <4 x i32>*
  store <4 x i32> %1058, <4 x i32>* %1062, align 16
  %1063 = bitcast <4 x i32> %996 to <16 x i8>
  %1064 = bitcast <4 x i32> %995 to <16 x i8>
  %1065 = shufflevector <16 x i8> %1064, <16 x i8> %1063, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1066 = bitcast <16 x i8> %1065 to <4 x i32>
  %1067 = shufflevector <16 x i8> %1064, <16 x i8> %1063, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1068 = bitcast <16 x i8> %1067 to <4 x i32>
  %1069 = shufflevector <16 x i8> %1064, <16 x i8> %1063, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1070 = bitcast <16 x i8> %1069 to <4 x i32>
  %1071 = add <4 x i32> %996, %995
  %1072 = add <4 x i32> %1071, %1066
  %1073 = add <4 x i32> %1072, %1068
  %1074 = add <4 x i32> %1073, %1070
  %1075 = bitcast <4 x i32> %1005 to <16 x i8>
  %1076 = shufflevector <16 x i8> %1063, <16 x i8> %1075, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1077 = bitcast <16 x i8> %1076 to <4 x i32>
  %1078 = shufflevector <16 x i8> %1063, <16 x i8> %1075, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1079 = bitcast <16 x i8> %1078 to <4 x i32>
  %1080 = shufflevector <16 x i8> %1063, <16 x i8> %1075, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1081 = bitcast <16 x i8> %1080 to <4 x i32>
  %1082 = add <4 x i32> %1005, %996
  %1083 = add <4 x i32> %1082, %1077
  %1084 = add <4 x i32> %1083, %1079
  %1085 = add <4 x i32> %1084, %1081
  %1086 = inttoptr i64 %967 to i32*
  %1087 = inttoptr i64 %967 to <4 x i32>*
  store <4 x i32> %1074, <4 x i32>* %1087, align 16
  %1088 = getelementptr inbounds i32, i32* %1086, i64 4
  %1089 = bitcast i32* %1088 to <4 x i32>*
  store <4 x i32> %1085, <4 x i32>* %1089, align 16
  %1090 = inttoptr i64 %972 to <8 x i16>*
  %1091 = load <8 x i16>, <8 x i16>* %1090, align 16
  %1092 = inttoptr i64 %973 to <8 x i16>*
  %1093 = load <8 x i16>, <8 x i16>* %1092, align 16
  %1094 = inttoptr i64 %974 to <8 x i16>*
  %1095 = load <8 x i16>, <8 x i16>* %1094, align 16
  %1096 = inttoptr i64 %968 to i32*
  %1097 = inttoptr i64 %968 to <4 x i32>*
  %1098 = load <4 x i32>, <4 x i32>* %1097, align 16
  %1099 = getelementptr inbounds i32, i32* %1096, i64 4
  %1100 = bitcast i32* %1099 to <4 x i32>*
  %1101 = load <4 x i32>, <4 x i32>* %1100, align 16
  %1102 = inttoptr i64 %969 to i32*
  %1103 = inttoptr i64 %969 to <4 x i32>*
  %1104 = load <4 x i32>, <4 x i32>* %1103, align 16
  %1105 = getelementptr inbounds i32, i32* %1102, i64 4
  %1106 = bitcast i32* %1105 to <4 x i32>*
  %1107 = load <4 x i32>, <4 x i32>* %1106, align 16
  %1108 = inttoptr i64 %970 to i32*
  %1109 = inttoptr i64 %970 to <4 x i32>*
  %1110 = load <4 x i32>, <4 x i32>* %1109, align 16
  %1111 = getelementptr inbounds i32, i32* %1108, i64 4
  %1112 = bitcast i32* %1111 to <4 x i32>*
  %1113 = load <4 x i32>, <4 x i32>* %1112, align 16
  %1114 = add <8 x i16> %1034, %1020
  %1115 = add <8 x i16> %1114, %1091
  %1116 = add <8 x i16> %1115, %1093
  %1117 = add <8 x i16> %1116, %1095
  %1118 = add <8 x i16> %1117, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %1119 = lshr <8 x i16> %1118, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %1120 = shufflevector <8 x i16> %1119, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1121 = shufflevector <8 x i16> %1119, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1122 = add <4 x i32> %1047, <i32 8, i32 8, i32 8, i32 8>
  %1123 = add <4 x i32> %1122, %1074
  %1124 = add <4 x i32> %1123, %1098
  %1125 = add <4 x i32> %1124, %1104
  %1126 = add <4 x i32> %1125, %1110
  %1127 = lshr <4 x i32> %1126, <i32 4, i32 4, i32 4, i32 4>
  %1128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1120, <8 x i16> %1120) #5
  %1129 = mul <4 x i32> %1127, <i32 25, i32 25, i32 25, i32 25>
  %1130 = sub <4 x i32> %1129, %1128
  %1131 = icmp sgt <4 x i32> %1130, zeroinitializer
  %1132 = select <4 x i1> %1131, <4 x i32> %1130, <4 x i32> zeroinitializer
  %1133 = mul <4 x i32> %1132, %340
  %1134 = add <4 x i32> %1133, <i32 524288, i32 524288, i32 524288, i32 524288>
  %1135 = lshr <4 x i32> %1134, <i32 20, i32 20, i32 20, i32 20>
  %1136 = add <4 x i32> %1058, <i32 8, i32 8, i32 8, i32 8>
  %1137 = add <4 x i32> %1136, %1085
  %1138 = add <4 x i32> %1137, %1101
  %1139 = add <4 x i32> %1138, %1107
  %1140 = add <4 x i32> %1139, %1113
  %1141 = lshr <4 x i32> %1140, <i32 4, i32 4, i32 4, i32 4>
  %1142 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1121, <8 x i16> %1121) #5
  %1143 = mul <4 x i32> %1141, <i32 25, i32 25, i32 25, i32 25>
  %1144 = sub <4 x i32> %1143, %1142
  %1145 = icmp sgt <4 x i32> %1144, zeroinitializer
  %1146 = select <4 x i1> %1145, <4 x i32> %1144, <4 x i32> zeroinitializer
  %1147 = mul <4 x i32> %1146, %340
  %1148 = add <4 x i32> %1147, <i32 524288, i32 524288, i32 524288, i32 524288>
  %1149 = lshr <4 x i32> %1148, <i32 20, i32 20, i32 20, i32 20>
  %1150 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1135, <4 x i32> %1149) #5
  %1151 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1150, <8 x i16> undef) #5
  %1152 = bitcast <16 x i8> %1151 to <2 x i64>
  %1153 = extractelement <2 x i64> %1152, i32 0
  %1154 = lshr i64 %1153, 8
  %1155 = lshr i64 %1153, 16
  %1156 = lshr i64 %1153, 24
  %1157 = lshr i64 %1153, 32
  %1158 = lshr i64 %1153, 40
  %1159 = lshr i64 %1153, 48
  %1160 = lshr i64 %1153, 56
  %1161 = and i64 %1153, 255
  %1162 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1161
  %1163 = load i8, i8* %1162, align 1
  %1164 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %1163, i64 0
  %1165 = and i64 %1154, 255
  %1166 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1165
  %1167 = load i8, i8* %1166, align 1
  %1168 = insertelement <16 x i8> %1164, i8 %1167, i64 1
  %1169 = and i64 %1155, 255
  %1170 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1169
  %1171 = load i8, i8* %1170, align 1
  %1172 = insertelement <16 x i8> %1168, i8 %1171, i64 2
  %1173 = and i64 %1156, 255
  %1174 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1173
  %1175 = load i8, i8* %1174, align 1
  %1176 = insertelement <16 x i8> %1172, i8 %1175, i64 3
  %1177 = and i64 %1157, 255
  %1178 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1177
  %1179 = load i8, i8* %1178, align 1
  %1180 = insertelement <16 x i8> %1176, i8 %1179, i64 4
  %1181 = and i64 %1158, 255
  %1182 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1181
  %1183 = load i8, i8* %1182, align 1
  %1184 = insertelement <16 x i8> %1180, i8 %1183, i64 5
  %1185 = and i64 %1159, 255
  %1186 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1185
  %1187 = load i8, i8* %1186, align 1
  %1188 = insertelement <16 x i8> %1184, i8 %1187, i64 6
  %1189 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1160
  %1190 = load i8, i8* %1189, align 1
  %1191 = insertelement <16 x i8> %1188, i8 %1190, i64 7
  %1192 = shufflevector <16 x i8> %1191, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1193 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1192, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %1194 = shufflevector <8 x i16> %1193, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1195 = shufflevector <8 x i16> %1117, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1196 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1194, <8 x i16> %1195) #5
  %1197 = shufflevector <8 x i16> %1193, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1198 = shufflevector <8 x i16> %1117, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1199 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1197, <8 x i16> %1198) #5
  %1200 = add <4 x i32> %1196, <i32 512, i32 512, i32 512, i32 512>
  %1201 = lshr <4 x i32> %1200, <i32 10, i32 10, i32 10, i32 10>
  %1202 = getelementptr inbounds i16, i16* %976, i64 %2
  %1203 = getelementptr inbounds i16, i16* %960, i64 %2
  %1204 = inttoptr i64 %964 to i16*
  %1205 = inttoptr i64 %962 to i32*
  %1206 = inttoptr i64 %963 to i16*
  %1207 = inttoptr i64 %961 to i32*
  %1208 = getelementptr inbounds i16, i16* %1204, i64 8
  %1209 = getelementptr inbounds i32, i32* %1205, i64 8
  %1210 = getelementptr inbounds i16, i16* %1206, i64 8
  %1211 = getelementptr inbounds i32, i32* %1207, i64 8
  %1212 = inttoptr i64 %965 to i16*
  %1213 = getelementptr inbounds i16, i16* %1212, i64 8
  %1214 = inttoptr i64 %971 to i16*
  %1215 = getelementptr inbounds i16, i16* %1214, i64 8
  %1216 = inttoptr i64 %972 to i16*
  %1217 = inttoptr i64 %973 to i16*
  %1218 = inttoptr i64 %974 to i16*
  %1219 = getelementptr inbounds i32, i32* %1059, i64 8
  %1220 = getelementptr inbounds i32, i32* %1086, i64 8
  br label %1221

1221:                                             ; preds = %1221, %957
  %1222 = phi i64 [ %1237, %1221 ], [ 0, %957 ]
  %1223 = phi <2 x i64> [ %1249, %1221 ], [ %988, %957 ]
  %1224 = phi <2 x i64> [ %1242, %1221 ], [ %983, %957 ]
  %1225 = phi <16 x i8> [ %1663, %1221 ], [ <i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, %957 ]
  %1226 = phi <16 x i8> [ %1663, %1221 ], [ %1191, %957 ]
  %1227 = phi <4 x i32> [ %1505, %1221 ], [ %1006, %957 ]
  %1228 = phi <4 x i32> [ %1504, %1221 ], [ %1005, %957 ]
  %1229 = phi <4 x i32> [ %1500, %1221 ], [ %1001, %957 ]
  %1230 = phi <4 x i32> [ %1499, %1221 ], [ %1000, %957 ]
  %1231 = phi <4 x i32> [ %1671, %1221 ], [ %1199, %957 ]
  %1232 = phi <4 x i32> [ %1673, %1221 ], [ %1201, %957 ]
  %1233 = add <4 x i32> %1231, <i32 512, i32 512, i32 512, i32 512>
  %1234 = lshr <4 x i32> %1233, <i32 10, i32 10, i32 10, i32 10>
  %1235 = getelementptr inbounds i16, i16* %977, i64 %1222
  %1236 = getelementptr inbounds i16, i16* %1235, i64 16
  %1237 = add nuw nsw i64 %1222, 16
  %1238 = bitcast i16* %1236 to <2 x i64>*
  %1239 = load <2 x i64>, <2 x i64>* %1238, align 1
  %1240 = getelementptr inbounds i16, i16* %1235, i64 24
  %1241 = bitcast i16* %1240 to <2 x i64>*
  %1242 = load <2 x i64>, <2 x i64>* %1241, align 1
  %1243 = getelementptr inbounds i16, i16* %978, i64 %1222
  %1244 = getelementptr inbounds i16, i16* %1243, i64 16
  %1245 = bitcast i16* %1244 to <2 x i64>*
  %1246 = load <2 x i64>, <2 x i64>* %1245, align 1
  %1247 = getelementptr inbounds i16, i16* %1243, i64 24
  %1248 = bitcast i16* %1247 to <2 x i64>*
  %1249 = load <2 x i64>, <2 x i64>* %1248, align 1
  %1250 = or i64 %1222, 8
  %1251 = bitcast <2 x i64> %1239 to <8 x i16>
  %1252 = shufflevector <8 x i16> %1251, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1253 = shufflevector <8 x i16> %1251, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1254 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1252, <8 x i16> %1252) #5
  %1255 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1253, <8 x i16> %1253) #5
  %1256 = bitcast <2 x i64> %1246 to <8 x i16>
  %1257 = shufflevector <8 x i16> %1256, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1258 = shufflevector <8 x i16> %1256, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1259 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1257, <8 x i16> %1257) #5
  %1260 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1258, <8 x i16> %1258) #5
  %1261 = bitcast <2 x i64> %1224 to <8 x i16>
  %1262 = bitcast <2 x i64> %1239 to <16 x i8>
  %1263 = bitcast <2 x i64> %1224 to <16 x i8>
  %1264 = shufflevector <16 x i8> %1263, <16 x i8> %1262, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1265 = bitcast <16 x i8> %1264 to <8 x i16>
  %1266 = shufflevector <16 x i8> %1263, <16 x i8> %1262, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1267 = bitcast <16 x i8> %1266 to <8 x i16>
  %1268 = shufflevector <16 x i8> %1263, <16 x i8> %1262, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %1269 = bitcast <16 x i8> %1268 to <8 x i16>
  %1270 = shufflevector <16 x i8> %1263, <16 x i8> %1262, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1271 = bitcast <16 x i8> %1270 to <8 x i16>
  %1272 = add <8 x i16> %1265, %1261
  %1273 = add <8 x i16> %1272, %1267
  %1274 = add <8 x i16> %1273, %1269
  %1275 = add <8 x i16> %1274, %1271
  %1276 = bitcast <2 x i64> %1242 to <16 x i8>
  %1277 = shufflevector <16 x i8> %1262, <16 x i8> %1276, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1278 = bitcast <16 x i8> %1277 to <8 x i16>
  %1279 = shufflevector <16 x i8> %1262, <16 x i8> %1276, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1280 = bitcast <16 x i8> %1279 to <8 x i16>
  %1281 = shufflevector <16 x i8> %1262, <16 x i8> %1276, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %1282 = bitcast <16 x i8> %1281 to <8 x i16>
  %1283 = shufflevector <16 x i8> %1262, <16 x i8> %1276, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1284 = bitcast <16 x i8> %1283 to <8 x i16>
  %1285 = add <8 x i16> %1278, %1251
  %1286 = add <8 x i16> %1285, %1280
  %1287 = add <8 x i16> %1286, %1282
  %1288 = add <8 x i16> %1287, %1284
  %1289 = getelementptr inbounds i16, i16* %1212, i64 %1250
  %1290 = bitcast i16* %1289 to <8 x i16>*
  store <8 x i16> %1275, <8 x i16>* %1290, align 16
  %1291 = getelementptr inbounds i16, i16* %1213, i64 %1250
  %1292 = bitcast i16* %1291 to <8 x i16>*
  store <8 x i16> %1288, <8 x i16>* %1292, align 16
  %1293 = bitcast <2 x i64> %1223 to <8 x i16>
  %1294 = bitcast <2 x i64> %1246 to <16 x i8>
  %1295 = bitcast <2 x i64> %1223 to <16 x i8>
  %1296 = shufflevector <16 x i8> %1295, <16 x i8> %1294, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1297 = bitcast <16 x i8> %1296 to <8 x i16>
  %1298 = shufflevector <16 x i8> %1295, <16 x i8> %1294, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1299 = bitcast <16 x i8> %1298 to <8 x i16>
  %1300 = shufflevector <16 x i8> %1295, <16 x i8> %1294, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %1301 = bitcast <16 x i8> %1300 to <8 x i16>
  %1302 = shufflevector <16 x i8> %1295, <16 x i8> %1294, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1303 = bitcast <16 x i8> %1302 to <8 x i16>
  %1304 = add <8 x i16> %1297, %1293
  %1305 = add <8 x i16> %1304, %1299
  %1306 = add <8 x i16> %1305, %1301
  %1307 = add <8 x i16> %1306, %1303
  %1308 = bitcast <2 x i64> %1249 to <16 x i8>
  %1309 = shufflevector <16 x i8> %1294, <16 x i8> %1308, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1310 = bitcast <16 x i8> %1309 to <8 x i16>
  %1311 = shufflevector <16 x i8> %1294, <16 x i8> %1308, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1312 = bitcast <16 x i8> %1311 to <8 x i16>
  %1313 = shufflevector <16 x i8> %1294, <16 x i8> %1308, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %1314 = bitcast <16 x i8> %1313 to <8 x i16>
  %1315 = shufflevector <16 x i8> %1294, <16 x i8> %1308, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1316 = bitcast <16 x i8> %1315 to <8 x i16>
  %1317 = add <8 x i16> %1310, %1256
  %1318 = add <8 x i16> %1317, %1312
  %1319 = add <8 x i16> %1318, %1314
  %1320 = add <8 x i16> %1319, %1316
  %1321 = getelementptr inbounds i16, i16* %1214, i64 %1250
  %1322 = bitcast i16* %1321 to <8 x i16>*
  store <8 x i16> %1307, <8 x i16>* %1322, align 16
  %1323 = getelementptr inbounds i16, i16* %1215, i64 %1250
  %1324 = bitcast i16* %1323 to <8 x i16>*
  store <8 x i16> %1320, <8 x i16>* %1324, align 16
  %1325 = bitcast <4 x i32> %1229 to <16 x i8>
  %1326 = bitcast <4 x i32> %1230 to <16 x i8>
  %1327 = shufflevector <16 x i8> %1326, <16 x i8> %1325, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1328 = bitcast <16 x i8> %1327 to <4 x i32>
  %1329 = shufflevector <16 x i8> %1326, <16 x i8> %1325, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1330 = bitcast <16 x i8> %1329 to <4 x i32>
  %1331 = shufflevector <16 x i8> %1326, <16 x i8> %1325, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1332 = bitcast <16 x i8> %1331 to <4 x i32>
  %1333 = add <4 x i32> %1230, %1229
  %1334 = add <4 x i32> %1333, %1328
  %1335 = add <4 x i32> %1334, %1330
  %1336 = add <4 x i32> %1335, %1332
  %1337 = bitcast <4 x i32> %1254 to <16 x i8>
  %1338 = shufflevector <16 x i8> %1325, <16 x i8> %1337, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1339 = bitcast <16 x i8> %1338 to <4 x i32>
  %1340 = shufflevector <16 x i8> %1325, <16 x i8> %1337, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1341 = bitcast <16 x i8> %1340 to <4 x i32>
  %1342 = shufflevector <16 x i8> %1325, <16 x i8> %1337, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1343 = bitcast <16 x i8> %1342 to <4 x i32>
  %1344 = add <4 x i32> %1254, %1229
  %1345 = add <4 x i32> %1344, %1339
  %1346 = add <4 x i32> %1345, %1341
  %1347 = add <4 x i32> %1346, %1343
  %1348 = getelementptr inbounds i32, i32* %1059, i64 %1250
  %1349 = bitcast i32* %1348 to <4 x i32>*
  store <4 x i32> %1336, <4 x i32>* %1349, align 16
  %1350 = getelementptr inbounds i32, i32* %1348, i64 4
  %1351 = bitcast i32* %1350 to <4 x i32>*
  store <4 x i32> %1347, <4 x i32>* %1351, align 16
  %1352 = bitcast <4 x i32> %1227 to <16 x i8>
  %1353 = bitcast <4 x i32> %1228 to <16 x i8>
  %1354 = shufflevector <16 x i8> %1353, <16 x i8> %1352, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1355 = bitcast <16 x i8> %1354 to <4 x i32>
  %1356 = shufflevector <16 x i8> %1353, <16 x i8> %1352, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1357 = bitcast <16 x i8> %1356 to <4 x i32>
  %1358 = shufflevector <16 x i8> %1353, <16 x i8> %1352, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1359 = bitcast <16 x i8> %1358 to <4 x i32>
  %1360 = add <4 x i32> %1228, %1227
  %1361 = add <4 x i32> %1360, %1355
  %1362 = add <4 x i32> %1361, %1357
  %1363 = add <4 x i32> %1362, %1359
  %1364 = bitcast <4 x i32> %1259 to <16 x i8>
  %1365 = shufflevector <16 x i8> %1352, <16 x i8> %1364, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1366 = bitcast <16 x i8> %1365 to <4 x i32>
  %1367 = shufflevector <16 x i8> %1352, <16 x i8> %1364, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1368 = bitcast <16 x i8> %1367 to <4 x i32>
  %1369 = shufflevector <16 x i8> %1352, <16 x i8> %1364, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1370 = bitcast <16 x i8> %1369 to <4 x i32>
  %1371 = add <4 x i32> %1259, %1227
  %1372 = add <4 x i32> %1371, %1366
  %1373 = add <4 x i32> %1372, %1368
  %1374 = add <4 x i32> %1373, %1370
  %1375 = getelementptr inbounds i32, i32* %1086, i64 %1250
  %1376 = bitcast i32* %1375 to <4 x i32>*
  store <4 x i32> %1363, <4 x i32>* %1376, align 16
  %1377 = getelementptr inbounds i32, i32* %1375, i64 4
  %1378 = bitcast i32* %1377 to <4 x i32>*
  store <4 x i32> %1374, <4 x i32>* %1378, align 16
  %1379 = getelementptr inbounds i16, i16* %1216, i64 %1250
  %1380 = bitcast i16* %1379 to <8 x i16>*
  %1381 = load <8 x i16>, <8 x i16>* %1380, align 16
  %1382 = getelementptr inbounds i16, i16* %1217, i64 %1250
  %1383 = bitcast i16* %1382 to <8 x i16>*
  %1384 = load <8 x i16>, <8 x i16>* %1383, align 16
  %1385 = getelementptr inbounds i16, i16* %1218, i64 %1250
  %1386 = bitcast i16* %1385 to <8 x i16>*
  %1387 = load <8 x i16>, <8 x i16>* %1386, align 16
  %1388 = getelementptr inbounds i32, i32* %1096, i64 %1250
  %1389 = bitcast i32* %1388 to <4 x i32>*
  %1390 = load <4 x i32>, <4 x i32>* %1389, align 16
  %1391 = getelementptr inbounds i32, i32* %1388, i64 4
  %1392 = bitcast i32* %1391 to <4 x i32>*
  %1393 = load <4 x i32>, <4 x i32>* %1392, align 16
  %1394 = getelementptr inbounds i32, i32* %1102, i64 %1250
  %1395 = bitcast i32* %1394 to <4 x i32>*
  %1396 = load <4 x i32>, <4 x i32>* %1395, align 16
  %1397 = getelementptr inbounds i32, i32* %1394, i64 4
  %1398 = bitcast i32* %1397 to <4 x i32>*
  %1399 = load <4 x i32>, <4 x i32>* %1398, align 16
  %1400 = getelementptr inbounds i32, i32* %1108, i64 %1250
  %1401 = bitcast i32* %1400 to <4 x i32>*
  %1402 = load <4 x i32>, <4 x i32>* %1401, align 16
  %1403 = getelementptr inbounds i32, i32* %1400, i64 4
  %1404 = bitcast i32* %1403 to <4 x i32>*
  %1405 = load <4 x i32>, <4 x i32>* %1404, align 16
  %1406 = add <8 x i16> %1307, %1275
  %1407 = add <8 x i16> %1406, %1381
  %1408 = add <8 x i16> %1407, %1384
  %1409 = add <8 x i16> %1408, %1387
  %1410 = add <8 x i16> %1409, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %1411 = lshr <8 x i16> %1410, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %1412 = shufflevector <8 x i16> %1411, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1413 = shufflevector <8 x i16> %1411, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1414 = add <4 x i32> %1363, <i32 8, i32 8, i32 8, i32 8>
  %1415 = add <4 x i32> %1414, %1336
  %1416 = add <4 x i32> %1415, %1390
  %1417 = add <4 x i32> %1416, %1396
  %1418 = add <4 x i32> %1417, %1402
  %1419 = lshr <4 x i32> %1418, <i32 4, i32 4, i32 4, i32 4>
  %1420 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1412, <8 x i16> %1412) #5
  %1421 = mul <4 x i32> %1419, <i32 25, i32 25, i32 25, i32 25>
  %1422 = sub <4 x i32> %1421, %1420
  %1423 = icmp sgt <4 x i32> %1422, zeroinitializer
  %1424 = select <4 x i1> %1423, <4 x i32> %1422, <4 x i32> zeroinitializer
  %1425 = mul <4 x i32> %1424, %340
  %1426 = add <4 x i32> %1425, <i32 524288, i32 524288, i32 524288, i32 524288>
  %1427 = lshr <4 x i32> %1426, <i32 20, i32 20, i32 20, i32 20>
  %1428 = add <4 x i32> %1347, <i32 8, i32 8, i32 8, i32 8>
  %1429 = add <4 x i32> %1428, %1374
  %1430 = add <4 x i32> %1429, %1393
  %1431 = add <4 x i32> %1430, %1399
  %1432 = add <4 x i32> %1431, %1405
  %1433 = lshr <4 x i32> %1432, <i32 4, i32 4, i32 4, i32 4>
  %1434 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1413, <8 x i16> %1413) #5
  %1435 = mul <4 x i32> %1433, <i32 25, i32 25, i32 25, i32 25>
  %1436 = sub <4 x i32> %1435, %1434
  %1437 = icmp sgt <4 x i32> %1436, zeroinitializer
  %1438 = select <4 x i1> %1437, <4 x i32> %1436, <4 x i32> zeroinitializer
  %1439 = mul <4 x i32> %1438, %340
  %1440 = add <4 x i32> %1439, <i32 524288, i32 524288, i32 524288, i32 524288>
  %1441 = lshr <4 x i32> %1440, <i32 20, i32 20, i32 20, i32 20>
  %1442 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1427, <4 x i32> %1441) #5
  %1443 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1442, <8 x i16> undef) #5
  %1444 = bitcast <16 x i8> %1443 to <2 x i64>
  %1445 = extractelement <2 x i64> %1444, i32 0
  %1446 = lshr i64 %1445, 8
  %1447 = lshr i64 %1445, 16
  %1448 = lshr i64 %1445, 24
  %1449 = lshr i64 %1445, 32
  %1450 = lshr i64 %1445, 40
  %1451 = lshr i64 %1445, 48
  %1452 = lshr i64 %1445, 56
  %1453 = and i64 %1445, 255
  %1454 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1453
  %1455 = load i8, i8* %1454, align 1
  %1456 = insertelement <16 x i8> %1226, i8 %1455, i64 8
  %1457 = and i64 %1446, 255
  %1458 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1457
  %1459 = load i8, i8* %1458, align 1
  %1460 = insertelement <16 x i8> %1456, i8 %1459, i64 9
  %1461 = and i64 %1447, 255
  %1462 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1461
  %1463 = load i8, i8* %1462, align 1
  %1464 = insertelement <16 x i8> %1460, i8 %1463, i64 10
  %1465 = and i64 %1448, 255
  %1466 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1465
  %1467 = load i8, i8* %1466, align 1
  %1468 = insertelement <16 x i8> %1464, i8 %1467, i64 11
  %1469 = and i64 %1449, 255
  %1470 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1469
  %1471 = load i8, i8* %1470, align 1
  %1472 = insertelement <16 x i8> %1468, i8 %1471, i64 12
  %1473 = and i64 %1450, 255
  %1474 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1473
  %1475 = load i8, i8* %1474, align 1
  %1476 = insertelement <16 x i8> %1472, i8 %1475, i64 13
  %1477 = and i64 %1451, 255
  %1478 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1477
  %1479 = load i8, i8* %1478, align 1
  %1480 = insertelement <16 x i8> %1476, i8 %1479, i64 14
  %1481 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1452
  %1482 = load i8, i8* %1481, align 1
  %1483 = insertelement <16 x i8> %1480, i8 %1482, i64 15
  %1484 = shufflevector <16 x i8> %1483, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %1485 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1484, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %1486 = shufflevector <8 x i16> %1485, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1487 = shufflevector <8 x i16> %1409, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1488 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1486, <8 x i16> %1487) #5
  %1489 = shufflevector <8 x i16> %1485, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1490 = shufflevector <8 x i16> %1409, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1491 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1489, <8 x i16> %1490) #5
  %1492 = add <4 x i32> %1488, <i32 512, i32 512, i32 512, i32 512>
  %1493 = lshr <4 x i32> %1492, <i32 10, i32 10, i32 10, i32 10>
  %1494 = add <4 x i32> %1491, <i32 512, i32 512, i32 512, i32 512>
  %1495 = lshr <4 x i32> %1494, <i32 10, i32 10, i32 10, i32 10>
  %1496 = bitcast <2 x i64> %1242 to <8 x i16>
  %1497 = shufflevector <8 x i16> %1496, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1498 = shufflevector <8 x i16> %1496, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1499 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1497, <8 x i16> %1497) #5
  %1500 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1498, <8 x i16> %1498) #5
  %1501 = bitcast <2 x i64> %1249 to <8 x i16>
  %1502 = shufflevector <8 x i16> %1501, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1503 = shufflevector <8 x i16> %1501, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1504 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1502, <8 x i16> %1502) #5
  %1505 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1503, <8 x i16> %1503) #5
  %1506 = bitcast <4 x i32> %1255 to <16 x i8>
  %1507 = shufflevector <16 x i8> %1337, <16 x i8> %1506, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1508 = bitcast <16 x i8> %1507 to <4 x i32>
  %1509 = shufflevector <16 x i8> %1337, <16 x i8> %1506, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1510 = bitcast <16 x i8> %1509 to <4 x i32>
  %1511 = shufflevector <16 x i8> %1337, <16 x i8> %1506, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1512 = bitcast <16 x i8> %1511 to <4 x i32>
  %1513 = add <4 x i32> %1255, %1254
  %1514 = add <4 x i32> %1513, %1508
  %1515 = add <4 x i32> %1514, %1510
  %1516 = add <4 x i32> %1515, %1512
  %1517 = bitcast <4 x i32> %1499 to <16 x i8>
  %1518 = shufflevector <16 x i8> %1506, <16 x i8> %1517, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1519 = bitcast <16 x i8> %1518 to <4 x i32>
  %1520 = shufflevector <16 x i8> %1506, <16 x i8> %1517, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1521 = bitcast <16 x i8> %1520 to <4 x i32>
  %1522 = shufflevector <16 x i8> %1506, <16 x i8> %1517, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1523 = bitcast <16 x i8> %1522 to <4 x i32>
  %1524 = add <4 x i32> %1499, %1255
  %1525 = add <4 x i32> %1524, %1519
  %1526 = add <4 x i32> %1525, %1521
  %1527 = add <4 x i32> %1526, %1523
  %1528 = getelementptr inbounds i32, i32* %1219, i64 %1250
  %1529 = bitcast i32* %1528 to <4 x i32>*
  store <4 x i32> %1516, <4 x i32>* %1529, align 16
  %1530 = getelementptr inbounds i32, i32* %1528, i64 4
  %1531 = bitcast i32* %1530 to <4 x i32>*
  store <4 x i32> %1527, <4 x i32>* %1531, align 16
  %1532 = bitcast <4 x i32> %1260 to <16 x i8>
  %1533 = shufflevector <16 x i8> %1364, <16 x i8> %1532, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1534 = bitcast <16 x i8> %1533 to <4 x i32>
  %1535 = shufflevector <16 x i8> %1364, <16 x i8> %1532, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1536 = bitcast <16 x i8> %1535 to <4 x i32>
  %1537 = shufflevector <16 x i8> %1364, <16 x i8> %1532, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1538 = bitcast <16 x i8> %1537 to <4 x i32>
  %1539 = add <4 x i32> %1260, %1259
  %1540 = add <4 x i32> %1539, %1534
  %1541 = add <4 x i32> %1540, %1536
  %1542 = add <4 x i32> %1541, %1538
  %1543 = bitcast <4 x i32> %1504 to <16 x i8>
  %1544 = shufflevector <16 x i8> %1532, <16 x i8> %1543, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1545 = bitcast <16 x i8> %1544 to <4 x i32>
  %1546 = shufflevector <16 x i8> %1532, <16 x i8> %1543, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1547 = bitcast <16 x i8> %1546 to <4 x i32>
  %1548 = shufflevector <16 x i8> %1532, <16 x i8> %1543, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1549 = bitcast <16 x i8> %1548 to <4 x i32>
  %1550 = add <4 x i32> %1504, %1260
  %1551 = add <4 x i32> %1550, %1545
  %1552 = add <4 x i32> %1551, %1547
  %1553 = add <4 x i32> %1552, %1549
  %1554 = getelementptr inbounds i32, i32* %1220, i64 %1250
  %1555 = bitcast i32* %1554 to <4 x i32>*
  store <4 x i32> %1542, <4 x i32>* %1555, align 16
  %1556 = getelementptr inbounds i32, i32* %1554, i64 4
  %1557 = bitcast i32* %1556 to <4 x i32>*
  store <4 x i32> %1553, <4 x i32>* %1557, align 16
  %1558 = add nuw nsw i64 %1250, 8
  %1559 = getelementptr inbounds i16, i16* %1216, i64 %1558
  %1560 = bitcast i16* %1559 to <8 x i16>*
  %1561 = load <8 x i16>, <8 x i16>* %1560, align 16
  %1562 = getelementptr inbounds i16, i16* %1217, i64 %1558
  %1563 = bitcast i16* %1562 to <8 x i16>*
  %1564 = load <8 x i16>, <8 x i16>* %1563, align 16
  %1565 = getelementptr inbounds i16, i16* %1218, i64 %1558
  %1566 = bitcast i16* %1565 to <8 x i16>*
  %1567 = load <8 x i16>, <8 x i16>* %1566, align 16
  %1568 = getelementptr inbounds i32, i32* %1096, i64 %1558
  %1569 = bitcast i32* %1568 to <4 x i32>*
  %1570 = load <4 x i32>, <4 x i32>* %1569, align 16
  %1571 = getelementptr inbounds i32, i32* %1568, i64 4
  %1572 = bitcast i32* %1571 to <4 x i32>*
  %1573 = load <4 x i32>, <4 x i32>* %1572, align 16
  %1574 = getelementptr inbounds i32, i32* %1102, i64 %1558
  %1575 = bitcast i32* %1574 to <4 x i32>*
  %1576 = load <4 x i32>, <4 x i32>* %1575, align 16
  %1577 = getelementptr inbounds i32, i32* %1574, i64 4
  %1578 = bitcast i32* %1577 to <4 x i32>*
  %1579 = load <4 x i32>, <4 x i32>* %1578, align 16
  %1580 = getelementptr inbounds i32, i32* %1108, i64 %1558
  %1581 = bitcast i32* %1580 to <4 x i32>*
  %1582 = load <4 x i32>, <4 x i32>* %1581, align 16
  %1583 = getelementptr inbounds i32, i32* %1580, i64 4
  %1584 = bitcast i32* %1583 to <4 x i32>*
  %1585 = load <4 x i32>, <4 x i32>* %1584, align 16
  %1586 = add <8 x i16> %1320, %1288
  %1587 = add <8 x i16> %1586, %1561
  %1588 = add <8 x i16> %1587, %1564
  %1589 = add <8 x i16> %1588, %1567
  %1590 = add <8 x i16> %1589, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %1591 = lshr <8 x i16> %1590, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %1592 = shufflevector <8 x i16> %1591, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1593 = shufflevector <8 x i16> %1591, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1594 = add <4 x i32> %1516, <i32 8, i32 8, i32 8, i32 8>
  %1595 = add <4 x i32> %1594, %1542
  %1596 = add <4 x i32> %1595, %1570
  %1597 = add <4 x i32> %1596, %1576
  %1598 = add <4 x i32> %1597, %1582
  %1599 = lshr <4 x i32> %1598, <i32 4, i32 4, i32 4, i32 4>
  %1600 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1592, <8 x i16> %1592) #5
  %1601 = mul <4 x i32> %1599, <i32 25, i32 25, i32 25, i32 25>
  %1602 = sub <4 x i32> %1601, %1600
  %1603 = icmp sgt <4 x i32> %1602, zeroinitializer
  %1604 = select <4 x i1> %1603, <4 x i32> %1602, <4 x i32> zeroinitializer
  %1605 = mul <4 x i32> %1604, %340
  %1606 = add <4 x i32> %1605, <i32 524288, i32 524288, i32 524288, i32 524288>
  %1607 = lshr <4 x i32> %1606, <i32 20, i32 20, i32 20, i32 20>
  %1608 = add <4 x i32> %1527, <i32 8, i32 8, i32 8, i32 8>
  %1609 = add <4 x i32> %1608, %1553
  %1610 = add <4 x i32> %1609, %1573
  %1611 = add <4 x i32> %1610, %1579
  %1612 = add <4 x i32> %1611, %1585
  %1613 = lshr <4 x i32> %1612, <i32 4, i32 4, i32 4, i32 4>
  %1614 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1593, <8 x i16> %1593) #5
  %1615 = mul <4 x i32> %1613, <i32 25, i32 25, i32 25, i32 25>
  %1616 = sub <4 x i32> %1615, %1614
  %1617 = icmp sgt <4 x i32> %1616, zeroinitializer
  %1618 = select <4 x i1> %1617, <4 x i32> %1616, <4 x i32> zeroinitializer
  %1619 = mul <4 x i32> %1618, %340
  %1620 = add <4 x i32> %1619, <i32 524288, i32 524288, i32 524288, i32 524288>
  %1621 = lshr <4 x i32> %1620, <i32 20, i32 20, i32 20, i32 20>
  %1622 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1607, <4 x i32> %1621) #5
  %1623 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1622, <8 x i16> undef) #5
  %1624 = bitcast <16 x i8> %1623 to <2 x i64>
  %1625 = extractelement <2 x i64> %1624, i32 0
  %1626 = lshr i64 %1625, 8
  %1627 = lshr i64 %1625, 16
  %1628 = lshr i64 %1625, 24
  %1629 = lshr i64 %1625, 32
  %1630 = lshr i64 %1625, 40
  %1631 = lshr i64 %1625, 48
  %1632 = lshr i64 %1625, 56
  %1633 = and i64 %1625, 255
  %1634 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1633
  %1635 = load i8, i8* %1634, align 1
  %1636 = insertelement <16 x i8> %1225, i8 %1635, i64 0
  %1637 = and i64 %1626, 255
  %1638 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1637
  %1639 = load i8, i8* %1638, align 1
  %1640 = insertelement <16 x i8> %1636, i8 %1639, i64 1
  %1641 = and i64 %1627, 255
  %1642 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1641
  %1643 = load i8, i8* %1642, align 1
  %1644 = insertelement <16 x i8> %1640, i8 %1643, i64 2
  %1645 = and i64 %1628, 255
  %1646 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1645
  %1647 = load i8, i8* %1646, align 1
  %1648 = insertelement <16 x i8> %1644, i8 %1647, i64 3
  %1649 = and i64 %1629, 255
  %1650 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1649
  %1651 = load i8, i8* %1650, align 1
  %1652 = insertelement <16 x i8> %1648, i8 %1651, i64 4
  %1653 = and i64 %1630, 255
  %1654 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1653
  %1655 = load i8, i8* %1654, align 1
  %1656 = insertelement <16 x i8> %1652, i8 %1655, i64 5
  %1657 = and i64 %1631, 255
  %1658 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1657
  %1659 = load i8, i8* %1658, align 1
  %1660 = insertelement <16 x i8> %1656, i8 %1659, i64 6
  %1661 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %1632
  %1662 = load i8, i8* %1661, align 1
  %1663 = insertelement <16 x i8> %1660, i8 %1662, i64 7
  %1664 = shufflevector <16 x i8> %1663, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1665 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1664, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %1666 = shufflevector <8 x i16> %1665, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1667 = shufflevector <8 x i16> %1589, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1668 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1666, <8 x i16> %1667) #5
  %1669 = shufflevector <8 x i16> %1665, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1670 = shufflevector <8 x i16> %1589, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1671 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1669, <8 x i16> %1670) #5
  %1672 = add <4 x i32> %1668, <i32 512, i32 512, i32 512, i32 512>
  %1673 = lshr <4 x i32> %1672, <i32 10, i32 10, i32 10, i32 10>
  %1674 = shufflevector <16 x i8> %1483, <16 x i8> %1663, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %1675 = shufflevector <16 x i8> %1483, <16 x i8> %1663, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1676 = shufflevector <16 x i8> %1483, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1677 = shufflevector <16 x i8> %1674, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1678 = bitcast <16 x i8> %1676 to <8 x i16>
  %1679 = bitcast <16 x i8> %1677 to <8 x i16>
  %1680 = add <8 x i16> %1679, %1678
  %1681 = shufflevector <16 x i8> %1675, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1682 = bitcast <16 x i8> %1681 to <8 x i16>
  %1683 = add <8 x i16> %1680, %1682
  %1684 = mul <8 x i16> %1683, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %1685 = add <8 x i16> %1684, %1679
  %1686 = getelementptr inbounds i16, i16* %1204, i64 %1222
  %1687 = bitcast i16* %1686 to <8 x i16>*
  store <8 x i16> %1685, <8 x i16>* %1687, align 16
  %1688 = bitcast <4 x i32> %1234 to <16 x i8>
  %1689 = bitcast <4 x i32> %1232 to <16 x i8>
  %1690 = shufflevector <16 x i8> %1689, <16 x i8> %1688, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1691 = bitcast <16 x i8> %1690 to <4 x i32>
  %1692 = shufflevector <16 x i8> %1689, <16 x i8> %1688, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1693 = bitcast <16 x i8> %1692 to <4 x i32>
  %1694 = add <4 x i32> %1232, %1691
  %1695 = add <4 x i32> %1694, %1693
  %1696 = mul <4 x i32> %1695, <i32 5, i32 5, i32 5, i32 5>
  %1697 = add <4 x i32> %1696, %1691
  %1698 = bitcast <4 x i32> %1493 to <16 x i8>
  %1699 = shufflevector <16 x i8> %1688, <16 x i8> %1698, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1700 = bitcast <16 x i8> %1699 to <4 x i32>
  %1701 = shufflevector <16 x i8> %1688, <16 x i8> %1698, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1702 = bitcast <16 x i8> %1701 to <4 x i32>
  %1703 = add <4 x i32> %1234, %1700
  %1704 = add <4 x i32> %1703, %1702
  %1705 = mul <4 x i32> %1704, <i32 5, i32 5, i32 5, i32 5>
  %1706 = add <4 x i32> %1705, %1700
  %1707 = getelementptr inbounds i32, i32* %1205, i64 %1222
  %1708 = bitcast i32* %1707 to <4 x i32>*
  store <4 x i32> %1697, <4 x i32>* %1708, align 16
  %1709 = getelementptr inbounds i32, i32* %1707, i64 4
  %1710 = bitcast i32* %1709 to <4 x i32>*
  store <4 x i32> %1706, <4 x i32>* %1710, align 16
  %1711 = getelementptr inbounds i16, i16* %976, i64 %1222
  %1712 = bitcast i16* %1711 to <8 x i16>*
  %1713 = load <8 x i16>, <8 x i16>* %1712, align 16
  %1714 = getelementptr inbounds i16, i16* %1202, i64 %1222
  %1715 = bitcast i16* %1714 to <8 x i16>*
  %1716 = load <8 x i16>, <8 x i16>* %1715, align 16
  %1717 = getelementptr inbounds i16, i16* %1206, i64 %1222
  %1718 = bitcast i16* %1717 to <8 x i16>*
  %1719 = load <8 x i16>, <8 x i16>* %1718, align 16
  %1720 = getelementptr inbounds i32, i32* %1207, i64 %1222
  %1721 = bitcast i32* %1720 to <4 x i32>*
  %1722 = load <4 x i32>, <4 x i32>* %1721, align 16
  %1723 = getelementptr inbounds i32, i32* %1720, i64 4
  %1724 = bitcast i32* %1723 to <4 x i32>*
  %1725 = load <4 x i32>, <4 x i32>* %1724, align 16
  %1726 = add <8 x i16> %1719, %1685
  %1727 = shufflevector <8 x i16> %1726, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1728 = shufflevector <8 x i16> %1713, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1729 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1727, <8 x i16> %1728) #5
  %1730 = shufflevector <8 x i16> %1726, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1731 = shufflevector <8 x i16> %1713, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1732 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1730, <8 x i16> %1731) #5
  %1733 = add <4 x i32> %1697, <i32 256, i32 256, i32 256, i32 256>
  %1734 = add <4 x i32> %1733, %1722
  %1735 = sub <4 x i32> %1734, %1729
  %1736 = ashr <4 x i32> %1735, <i32 9, i32 9, i32 9, i32 9>
  %1737 = add <4 x i32> %1706, <i32 256, i32 256, i32 256, i32 256>
  %1738 = add <4 x i32> %1737, %1725
  %1739 = sub <4 x i32> %1738, %1732
  %1740 = ashr <4 x i32> %1739, <i32 9, i32 9, i32 9, i32 9>
  %1741 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1736, <4 x i32> %1740) #5
  %1742 = shufflevector <8 x i16> %1685, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1743 = shufflevector <8 x i16> %1716, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1744 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1742, <8 x i16> %1743) #5
  %1745 = shufflevector <8 x i16> %1685, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1746 = shufflevector <8 x i16> %1716, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1747 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1745, <8 x i16> %1746) #5
  %1748 = add <4 x i32> %1697, <i32 128, i32 128, i32 128, i32 128>
  %1749 = sub <4 x i32> %1748, %1744
  %1750 = ashr <4 x i32> %1749, <i32 8, i32 8, i32 8, i32 8>
  %1751 = add <4 x i32> %1706, <i32 128, i32 128, i32 128, i32 128>
  %1752 = sub <4 x i32> %1751, %1747
  %1753 = ashr <4 x i32> %1752, <i32 8, i32 8, i32 8, i32 8>
  %1754 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1750, <4 x i32> %1753) #5
  %1755 = shufflevector <8 x i16> %1741, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1756 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1755, <8 x i16> %932) #5
  %1757 = shufflevector <8 x i16> %1741, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1758 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1757, <8 x i16> %932) #5
  %1759 = add <4 x i32> %1756, <i32 1024, i32 1024, i32 1024, i32 1024>
  %1760 = ashr <4 x i32> %1759, <i32 11, i32 11, i32 11, i32 11>
  %1761 = add <4 x i32> %1758, <i32 1024, i32 1024, i32 1024, i32 1024>
  %1762 = ashr <4 x i32> %1761, <i32 11, i32 11, i32 11, i32 11>
  %1763 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1760, <4 x i32> %1762) #5
  %1764 = add <8 x i16> %1763, %1713
  %1765 = shufflevector <8 x i16> %1754, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1766 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1765, <8 x i16> %932) #5
  %1767 = shufflevector <8 x i16> %1754, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1768 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1767, <8 x i16> %932) #5
  %1769 = add <4 x i32> %1766, <i32 1024, i32 1024, i32 1024, i32 1024>
  %1770 = ashr <4 x i32> %1769, <i32 11, i32 11, i32 11, i32 11>
  %1771 = add <4 x i32> %1768, <i32 1024, i32 1024, i32 1024, i32 1024>
  %1772 = ashr <4 x i32> %1771, <i32 11, i32 11, i32 11, i32 11>
  %1773 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1770, <4 x i32> %1772) #5
  %1774 = add <8 x i16> %1773, %1716
  %1775 = shufflevector <16 x i8> %1674, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %1776 = bitcast <16 x i8> %1484 to <8 x i16>
  %1777 = bitcast <16 x i8> %1775 to <8 x i16>
  %1778 = add <8 x i16> %1777, %1776
  %1779 = shufflevector <16 x i8> %1675, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %1780 = bitcast <16 x i8> %1779 to <8 x i16>
  %1781 = add <8 x i16> %1778, %1780
  %1782 = mul <8 x i16> %1781, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %1783 = add <8 x i16> %1782, %1777
  %1784 = getelementptr inbounds i16, i16* %1208, i64 %1222
  %1785 = bitcast i16* %1784 to <8 x i16>*
  store <8 x i16> %1783, <8 x i16>* %1785, align 16
  %1786 = bitcast <4 x i32> %1495 to <16 x i8>
  %1787 = shufflevector <16 x i8> %1698, <16 x i8> %1786, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1788 = bitcast <16 x i8> %1787 to <4 x i32>
  %1789 = shufflevector <16 x i8> %1698, <16 x i8> %1786, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1790 = bitcast <16 x i8> %1789 to <4 x i32>
  %1791 = add <4 x i32> %1493, %1788
  %1792 = add <4 x i32> %1791, %1790
  %1793 = mul <4 x i32> %1792, <i32 5, i32 5, i32 5, i32 5>
  %1794 = add <4 x i32> %1793, %1788
  %1795 = bitcast <4 x i32> %1673 to <16 x i8>
  %1796 = shufflevector <16 x i8> %1786, <16 x i8> %1795, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1797 = bitcast <16 x i8> %1796 to <4 x i32>
  %1798 = shufflevector <16 x i8> %1786, <16 x i8> %1795, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1799 = bitcast <16 x i8> %1798 to <4 x i32>
  %1800 = add <4 x i32> %1495, %1797
  %1801 = add <4 x i32> %1800, %1799
  %1802 = mul <4 x i32> %1801, <i32 5, i32 5, i32 5, i32 5>
  %1803 = add <4 x i32> %1802, %1797
  %1804 = getelementptr inbounds i32, i32* %1209, i64 %1222
  %1805 = bitcast i32* %1804 to <4 x i32>*
  store <4 x i32> %1794, <4 x i32>* %1805, align 16
  %1806 = getelementptr inbounds i32, i32* %1804, i64 4
  %1807 = bitcast i32* %1806 to <4 x i32>*
  store <4 x i32> %1803, <4 x i32>* %1807, align 16
  %1808 = getelementptr inbounds i16, i16* %1711, i64 8
  %1809 = bitcast i16* %1808 to <8 x i16>*
  %1810 = load <8 x i16>, <8 x i16>* %1809, align 16
  %1811 = getelementptr inbounds i16, i16* %1714, i64 8
  %1812 = bitcast i16* %1811 to <8 x i16>*
  %1813 = load <8 x i16>, <8 x i16>* %1812, align 16
  %1814 = getelementptr inbounds i16, i16* %1210, i64 %1222
  %1815 = bitcast i16* %1814 to <8 x i16>*
  %1816 = load <8 x i16>, <8 x i16>* %1815, align 16
  %1817 = getelementptr inbounds i32, i32* %1211, i64 %1222
  %1818 = bitcast i32* %1817 to <4 x i32>*
  %1819 = load <4 x i32>, <4 x i32>* %1818, align 16
  %1820 = getelementptr inbounds i32, i32* %1817, i64 4
  %1821 = bitcast i32* %1820 to <4 x i32>*
  %1822 = load <4 x i32>, <4 x i32>* %1821, align 16
  %1823 = add <8 x i16> %1816, %1783
  %1824 = shufflevector <8 x i16> %1823, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1825 = shufflevector <8 x i16> %1810, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1826 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1824, <8 x i16> %1825) #5
  %1827 = shufflevector <8 x i16> %1823, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1828 = shufflevector <8 x i16> %1810, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1829 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1827, <8 x i16> %1828) #5
  %1830 = add <4 x i32> %1794, <i32 256, i32 256, i32 256, i32 256>
  %1831 = add <4 x i32> %1830, %1819
  %1832 = sub <4 x i32> %1831, %1826
  %1833 = ashr <4 x i32> %1832, <i32 9, i32 9, i32 9, i32 9>
  %1834 = add <4 x i32> %1803, <i32 256, i32 256, i32 256, i32 256>
  %1835 = add <4 x i32> %1834, %1822
  %1836 = sub <4 x i32> %1835, %1829
  %1837 = ashr <4 x i32> %1836, <i32 9, i32 9, i32 9, i32 9>
  %1838 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1833, <4 x i32> %1837) #5
  %1839 = shufflevector <8 x i16> %1783, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1840 = shufflevector <8 x i16> %1813, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1841 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1839, <8 x i16> %1840) #5
  %1842 = shufflevector <8 x i16> %1783, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1843 = shufflevector <8 x i16> %1813, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1844 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1842, <8 x i16> %1843) #5
  %1845 = add <4 x i32> %1794, <i32 128, i32 128, i32 128, i32 128>
  %1846 = sub <4 x i32> %1845, %1841
  %1847 = ashr <4 x i32> %1846, <i32 8, i32 8, i32 8, i32 8>
  %1848 = add <4 x i32> %1803, <i32 128, i32 128, i32 128, i32 128>
  %1849 = sub <4 x i32> %1848, %1844
  %1850 = ashr <4 x i32> %1849, <i32 8, i32 8, i32 8, i32 8>
  %1851 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1847, <4 x i32> %1850) #5
  %1852 = shufflevector <8 x i16> %1838, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1853 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1852, <8 x i16> %932) #5
  %1854 = shufflevector <8 x i16> %1838, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1855 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1854, <8 x i16> %932) #5
  %1856 = add <4 x i32> %1853, <i32 1024, i32 1024, i32 1024, i32 1024>
  %1857 = ashr <4 x i32> %1856, <i32 11, i32 11, i32 11, i32 11>
  %1858 = add <4 x i32> %1855, <i32 1024, i32 1024, i32 1024, i32 1024>
  %1859 = ashr <4 x i32> %1858, <i32 11, i32 11, i32 11, i32 11>
  %1860 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1857, <4 x i32> %1859) #5
  %1861 = add <8 x i16> %1860, %1810
  %1862 = getelementptr inbounds i16, i16* %960, i64 %1222
  %1863 = icmp sgt <8 x i16> %1764, zeroinitializer
  %1864 = select <8 x i1> %1863, <8 x i16> %1764, <8 x i16> zeroinitializer
  %1865 = icmp slt <8 x i16> %1864, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1866 = select <8 x i1> %1865, <8 x i16> %1864, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1867 = bitcast i16* %1862 to <8 x i16>*
  store <8 x i16> %1866, <8 x i16>* %1867, align 16
  %1868 = getelementptr inbounds i16, i16* %1862, i64 8
  %1869 = icmp sgt <8 x i16> %1861, zeroinitializer
  %1870 = select <8 x i1> %1869, <8 x i16> %1861, <8 x i16> zeroinitializer
  %1871 = icmp slt <8 x i16> %1870, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1872 = select <8 x i1> %1871, <8 x i16> %1870, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1873 = bitcast i16* %1868 to <8 x i16>*
  store <8 x i16> %1872, <8 x i16>* %1873, align 16
  %1874 = shufflevector <8 x i16> %1851, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1875 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1874, <8 x i16> %932) #5
  %1876 = shufflevector <8 x i16> %1851, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1877 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1876, <8 x i16> %932) #5
  %1878 = add <4 x i32> %1875, <i32 1024, i32 1024, i32 1024, i32 1024>
  %1879 = ashr <4 x i32> %1878, <i32 11, i32 11, i32 11, i32 11>
  %1880 = add <4 x i32> %1877, <i32 1024, i32 1024, i32 1024, i32 1024>
  %1881 = ashr <4 x i32> %1880, <i32 11, i32 11, i32 11, i32 11>
  %1882 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1879, <4 x i32> %1881) #5
  %1883 = add <8 x i16> %1882, %1813
  %1884 = getelementptr inbounds i16, i16* %1203, i64 %1222
  %1885 = icmp sgt <8 x i16> %1774, zeroinitializer
  %1886 = select <8 x i1> %1885, <8 x i16> %1774, <8 x i16> zeroinitializer
  %1887 = icmp slt <8 x i16> %1886, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1888 = select <8 x i1> %1887, <8 x i16> %1886, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1889 = bitcast i16* %1884 to <8 x i16>*
  store <8 x i16> %1888, <8 x i16>* %1889, align 16
  %1890 = getelementptr inbounds i16, i16* %1884, i64 8
  %1891 = icmp sgt <8 x i16> %1883, zeroinitializer
  %1892 = select <8 x i1> %1891, <8 x i16> %1883, <8 x i16> zeroinitializer
  %1893 = icmp slt <8 x i16> %1892, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1894 = select <8 x i1> %1893, <8 x i16> %1892, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %1895 = bitcast i16* %1890 to <8 x i16>*
  store <8 x i16> %1894, <8 x i16>* %1895, align 16
  %1896 = icmp slt i64 %1237, %24
  br i1 %1896, label %1221, label %1897

1897:                                             ; preds = %1221
  %1898 = getelementptr inbounds i16, i16* %960, i64 %926
  %1899 = add nsw i32 %958, -1
  %1900 = icmp sgt i32 %1899, 0
  br i1 %1900, label %957, label %937

1901:                                             ; preds = %937
  %1902 = inttoptr i64 %947 to <8 x i16>*
  %1903 = getelementptr inbounds i16, i16* %178, i64 %6
  %1904 = getelementptr inbounds i16, i16* %953, i64 %926
  %1905 = select i1 %955, i16* %1903, i16* %178
  %1906 = select i1 %955, i16* %178, i16* %1904
  %1907 = getelementptr inbounds i16, i16* %953, i64 3
  %1908 = bitcast i16* %1906 to <8 x i16>*
  %1909 = load <8 x i16>, <8 x i16>* %1908, align 1
  %1910 = getelementptr inbounds i16, i16* %1906, i64 8
  %1911 = bitcast i16* %1910 to <2 x i64>*
  %1912 = load <2 x i64>, <2 x i64>* %1911, align 1
  %1913 = bitcast i16* %1905 to <8 x i16>*
  %1914 = load <8 x i16>, <8 x i16>* %1913, align 1
  %1915 = getelementptr inbounds i16, i16* %1905, i64 8
  %1916 = bitcast i16* %1915 to <2 x i64>*
  %1917 = load <2 x i64>, <2 x i64>* %1916, align 1
  %1918 = shufflevector <8 x i16> %1909, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1919 = shufflevector <8 x i16> %1909, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1920 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1918, <8 x i16> %1918) #5
  %1921 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1919, <8 x i16> %1919) #5
  %1922 = shufflevector <8 x i16> %1914, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1923 = shufflevector <8 x i16> %1914, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1924 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1922, <8 x i16> %1922) #5
  %1925 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1923, <8 x i16> %1923) #5
  %1926 = bitcast <2 x i64> %1912 to <8 x i16>
  %1927 = shufflevector <8 x i16> %1926, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1928 = shufflevector <8 x i16> %1926, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1929 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1927, <8 x i16> %1927) #5
  %1930 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1928, <8 x i16> %1928) #5
  %1931 = bitcast <2 x i64> %1917 to <8 x i16>
  %1932 = shufflevector <8 x i16> %1931, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1933 = shufflevector <8 x i16> %1931, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1934 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1932, <8 x i16> %1932) #5
  %1935 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1933, <8 x i16> %1933) #5
  %1936 = bitcast <2 x i64> %1912 to <16 x i8>
  %1937 = bitcast <8 x i16> %1909 to <16 x i8>
  %1938 = shufflevector <16 x i8> %1937, <16 x i8> %1936, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1939 = bitcast <16 x i8> %1938 to <8 x i16>
  %1940 = shufflevector <16 x i8> %1937, <16 x i8> %1936, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1941 = bitcast <16 x i8> %1940 to <8 x i16>
  %1942 = shufflevector <16 x i8> %1937, <16 x i8> %1936, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %1943 = bitcast <16 x i8> %1942 to <8 x i16>
  %1944 = shufflevector <16 x i8> %1937, <16 x i8> %1936, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1945 = bitcast <16 x i8> %1944 to <8 x i16>
  %1946 = add <8 x i16> %1909, %1939
  %1947 = add <8 x i16> %1946, %1941
  %1948 = add <8 x i16> %1947, %1943
  %1949 = add <8 x i16> %1948, %1945
  store <8 x i16> %1949, <8 x i16>* %1902, align 16
  %1950 = bitcast <2 x i64> %1917 to <16 x i8>
  %1951 = bitcast <8 x i16> %1914 to <16 x i8>
  %1952 = shufflevector <16 x i8> %1951, <16 x i8> %1950, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1953 = bitcast <16 x i8> %1952 to <8 x i16>
  %1954 = shufflevector <16 x i8> %1951, <16 x i8> %1950, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1955 = bitcast <16 x i8> %1954 to <8 x i16>
  %1956 = shufflevector <16 x i8> %1951, <16 x i8> %1950, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %1957 = bitcast <16 x i8> %1956 to <8 x i16>
  %1958 = shufflevector <16 x i8> %1951, <16 x i8> %1950, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1959 = bitcast <16 x i8> %1958 to <8 x i16>
  %1960 = add <8 x i16> %1914, %1953
  %1961 = add <8 x i16> %1960, %1955
  %1962 = add <8 x i16> %1961, %1957
  %1963 = add <8 x i16> %1962, %1959
  %1964 = inttoptr i64 %941 to <8 x i16>*
  store <8 x i16> %1963, <8 x i16>* %1964, align 16
  %1965 = bitcast <4 x i32> %1921 to <16 x i8>
  %1966 = bitcast <4 x i32> %1920 to <16 x i8>
  %1967 = shufflevector <16 x i8> %1966, <16 x i8> %1965, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1968 = bitcast <16 x i8> %1967 to <4 x i32>
  %1969 = shufflevector <16 x i8> %1966, <16 x i8> %1965, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1970 = bitcast <16 x i8> %1969 to <4 x i32>
  %1971 = shufflevector <16 x i8> %1966, <16 x i8> %1965, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1972 = bitcast <16 x i8> %1971 to <4 x i32>
  %1973 = add <4 x i32> %1921, %1920
  %1974 = add <4 x i32> %1973, %1968
  %1975 = add <4 x i32> %1974, %1970
  %1976 = add <4 x i32> %1975, %1972
  %1977 = bitcast <4 x i32> %1929 to <16 x i8>
  %1978 = shufflevector <16 x i8> %1965, <16 x i8> %1977, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1979 = bitcast <16 x i8> %1978 to <4 x i32>
  %1980 = shufflevector <16 x i8> %1965, <16 x i8> %1977, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1981 = bitcast <16 x i8> %1980 to <4 x i32>
  %1982 = shufflevector <16 x i8> %1965, <16 x i8> %1977, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1983 = bitcast <16 x i8> %1982 to <4 x i32>
  %1984 = add <4 x i32> %1929, %1921
  %1985 = add <4 x i32> %1984, %1979
  %1986 = add <4 x i32> %1985, %1981
  %1987 = add <4 x i32> %1986, %1983
  %1988 = inttoptr i64 %946 to i32*
  %1989 = inttoptr i64 %946 to <4 x i32>*
  store <4 x i32> %1976, <4 x i32>* %1989, align 16
  %1990 = getelementptr inbounds i32, i32* %1988, i64 4
  %1991 = bitcast i32* %1990 to <4 x i32>*
  store <4 x i32> %1987, <4 x i32>* %1991, align 16
  %1992 = bitcast <4 x i32> %1925 to <16 x i8>
  %1993 = bitcast <4 x i32> %1924 to <16 x i8>
  %1994 = shufflevector <16 x i8> %1993, <16 x i8> %1992, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1995 = bitcast <16 x i8> %1994 to <4 x i32>
  %1996 = shufflevector <16 x i8> %1993, <16 x i8> %1992, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %1997 = bitcast <16 x i8> %1996 to <4 x i32>
  %1998 = shufflevector <16 x i8> %1993, <16 x i8> %1992, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %1999 = bitcast <16 x i8> %1998 to <4 x i32>
  %2000 = add <4 x i32> %1925, %1924
  %2001 = add <4 x i32> %2000, %1995
  %2002 = add <4 x i32> %2001, %1997
  %2003 = add <4 x i32> %2002, %1999
  %2004 = bitcast <4 x i32> %1934 to <16 x i8>
  %2005 = shufflevector <16 x i8> %1992, <16 x i8> %2004, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2006 = bitcast <16 x i8> %2005 to <4 x i32>
  %2007 = shufflevector <16 x i8> %1992, <16 x i8> %2004, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2008 = bitcast <16 x i8> %2007 to <4 x i32>
  %2009 = shufflevector <16 x i8> %1992, <16 x i8> %2004, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2010 = bitcast <16 x i8> %2009 to <4 x i32>
  %2011 = add <4 x i32> %1934, %1925
  %2012 = add <4 x i32> %2011, %2006
  %2013 = add <4 x i32> %2012, %2008
  %2014 = add <4 x i32> %2013, %2010
  %2015 = inttoptr i64 %945 to i32*
  %2016 = inttoptr i64 %945 to <4 x i32>*
  store <4 x i32> %2003, <4 x i32>* %2016, align 16
  %2017 = getelementptr inbounds i32, i32* %2015, i64 4
  %2018 = bitcast i32* %2017 to <4 x i32>*
  store <4 x i32> %2014, <4 x i32>* %2018, align 16
  %2019 = inttoptr i64 %940 to <8 x i16>*
  %2020 = load <8 x i16>, <8 x i16>* %2019, align 16
  %2021 = inttoptr i64 %939 to <8 x i16>*
  %2022 = load <8 x i16>, <8 x i16>* %2021, align 16
  %2023 = inttoptr i64 %938 to <8 x i16>*
  %2024 = load <8 x i16>, <8 x i16>* %2023, align 16
  %2025 = inttoptr i64 %944 to i32*
  %2026 = inttoptr i64 %944 to <4 x i32>*
  %2027 = load <4 x i32>, <4 x i32>* %2026, align 16
  %2028 = getelementptr inbounds i32, i32* %2025, i64 4
  %2029 = bitcast i32* %2028 to <4 x i32>*
  %2030 = load <4 x i32>, <4 x i32>* %2029, align 16
  %2031 = inttoptr i64 %943 to i32*
  %2032 = inttoptr i64 %943 to <4 x i32>*
  %2033 = load <4 x i32>, <4 x i32>* %2032, align 16
  %2034 = getelementptr inbounds i32, i32* %2031, i64 4
  %2035 = bitcast i32* %2034 to <4 x i32>*
  %2036 = load <4 x i32>, <4 x i32>* %2035, align 16
  %2037 = inttoptr i64 %942 to i32*
  %2038 = inttoptr i64 %942 to <4 x i32>*
  %2039 = load <4 x i32>, <4 x i32>* %2038, align 16
  %2040 = getelementptr inbounds i32, i32* %2037, i64 4
  %2041 = bitcast i32* %2040 to <4 x i32>*
  %2042 = load <4 x i32>, <4 x i32>* %2041, align 16
  %2043 = add <8 x i16> %1963, %1949
  %2044 = add <8 x i16> %2043, %2020
  %2045 = add <8 x i16> %2044, %2022
  %2046 = add <8 x i16> %2045, %2024
  %2047 = add <8 x i16> %2046, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %2048 = lshr <8 x i16> %2047, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %2049 = shufflevector <8 x i16> %2048, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2050 = shufflevector <8 x i16> %2048, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2051 = add <4 x i32> %1976, <i32 8, i32 8, i32 8, i32 8>
  %2052 = add <4 x i32> %2051, %2003
  %2053 = add <4 x i32> %2052, %2027
  %2054 = add <4 x i32> %2053, %2033
  %2055 = add <4 x i32> %2054, %2039
  %2056 = lshr <4 x i32> %2055, <i32 4, i32 4, i32 4, i32 4>
  %2057 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2049, <8 x i16> %2049) #5
  %2058 = mul <4 x i32> %2056, <i32 25, i32 25, i32 25, i32 25>
  %2059 = sub <4 x i32> %2058, %2057
  %2060 = icmp sgt <4 x i32> %2059, zeroinitializer
  %2061 = select <4 x i1> %2060, <4 x i32> %2059, <4 x i32> zeroinitializer
  %2062 = mul <4 x i32> %2061, %340
  %2063 = add <4 x i32> %2062, <i32 524288, i32 524288, i32 524288, i32 524288>
  %2064 = lshr <4 x i32> %2063, <i32 20, i32 20, i32 20, i32 20>
  %2065 = add <4 x i32> %1987, <i32 8, i32 8, i32 8, i32 8>
  %2066 = add <4 x i32> %2065, %2014
  %2067 = add <4 x i32> %2066, %2030
  %2068 = add <4 x i32> %2067, %2036
  %2069 = add <4 x i32> %2068, %2042
  %2070 = lshr <4 x i32> %2069, <i32 4, i32 4, i32 4, i32 4>
  %2071 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2050, <8 x i16> %2050) #5
  %2072 = mul <4 x i32> %2070, <i32 25, i32 25, i32 25, i32 25>
  %2073 = sub <4 x i32> %2072, %2071
  %2074 = icmp sgt <4 x i32> %2073, zeroinitializer
  %2075 = select <4 x i1> %2074, <4 x i32> %2073, <4 x i32> zeroinitializer
  %2076 = mul <4 x i32> %2075, %340
  %2077 = add <4 x i32> %2076, <i32 524288, i32 524288, i32 524288, i32 524288>
  %2078 = lshr <4 x i32> %2077, <i32 20, i32 20, i32 20, i32 20>
  %2079 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2064, <4 x i32> %2078) #5
  %2080 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2079, <8 x i16> undef) #5
  %2081 = bitcast <16 x i8> %2080 to <2 x i64>
  %2082 = extractelement <2 x i64> %2081, i32 0
  %2083 = lshr i64 %2082, 8
  %2084 = lshr i64 %2082, 16
  %2085 = lshr i64 %2082, 24
  %2086 = lshr i64 %2082, 32
  %2087 = lshr i64 %2082, 40
  %2088 = lshr i64 %2082, 48
  %2089 = lshr i64 %2082, 56
  %2090 = and i64 %2082, 255
  %2091 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2090
  %2092 = load i8, i8* %2091, align 1
  %2093 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %2092, i64 0
  %2094 = and i64 %2083, 255
  %2095 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2094
  %2096 = load i8, i8* %2095, align 1
  %2097 = insertelement <16 x i8> %2093, i8 %2096, i64 1
  %2098 = and i64 %2084, 255
  %2099 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2098
  %2100 = load i8, i8* %2099, align 1
  %2101 = insertelement <16 x i8> %2097, i8 %2100, i64 2
  %2102 = and i64 %2085, 255
  %2103 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2102
  %2104 = load i8, i8* %2103, align 1
  %2105 = insertelement <16 x i8> %2101, i8 %2104, i64 3
  %2106 = and i64 %2086, 255
  %2107 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2106
  %2108 = load i8, i8* %2107, align 1
  %2109 = insertelement <16 x i8> %2105, i8 %2108, i64 4
  %2110 = and i64 %2087, 255
  %2111 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2110
  %2112 = load i8, i8* %2111, align 1
  %2113 = insertelement <16 x i8> %2109, i8 %2112, i64 5
  %2114 = and i64 %2088, 255
  %2115 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2114
  %2116 = load i8, i8* %2115, align 1
  %2117 = insertelement <16 x i8> %2113, i8 %2116, i64 6
  %2118 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2089
  %2119 = load i8, i8* %2118, align 1
  %2120 = insertelement <16 x i8> %2117, i8 %2119, i64 7
  %2121 = shufflevector <16 x i8> %2120, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2122 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2121, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %2123 = shufflevector <8 x i16> %2122, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2124 = shufflevector <8 x i16> %2046, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2125 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2123, <8 x i16> %2124) #5
  %2126 = shufflevector <8 x i16> %2122, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2127 = shufflevector <8 x i16> %2046, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2126, <8 x i16> %2127) #5
  %2129 = add <4 x i32> %2125, <i32 512, i32 512, i32 512, i32 512>
  %2130 = lshr <4 x i32> %2129, <i32 10, i32 10, i32 10, i32 10>
  %2131 = getelementptr inbounds i16, i16* %1907, i64 %2
  %2132 = getelementptr inbounds i16, i16* %952, i64 %2
  %2133 = inttoptr i64 %948 to i16*
  %2134 = inttoptr i64 %950 to i32*
  %2135 = inttoptr i64 %949 to i16*
  %2136 = inttoptr i64 %951 to i32*
  %2137 = getelementptr inbounds i16, i16* %2133, i64 8
  %2138 = getelementptr inbounds i32, i32* %2134, i64 8
  %2139 = getelementptr inbounds i16, i16* %2135, i64 8
  %2140 = getelementptr inbounds i32, i32* %2136, i64 8
  %2141 = inttoptr i64 %947 to i16*
  %2142 = getelementptr inbounds i16, i16* %2141, i64 8
  %2143 = inttoptr i64 %941 to i16*
  %2144 = getelementptr inbounds i16, i16* %2143, i64 8
  %2145 = inttoptr i64 %940 to i16*
  %2146 = inttoptr i64 %939 to i16*
  %2147 = inttoptr i64 %938 to i16*
  %2148 = getelementptr inbounds i32, i32* %1988, i64 8
  %2149 = getelementptr inbounds i32, i32* %2015, i64 8
  br label %2150

2150:                                             ; preds = %2150, %1901
  %2151 = phi i64 [ %2166, %2150 ], [ 0, %1901 ]
  %2152 = phi <2 x i64> [ %2178, %2150 ], [ %1917, %1901 ]
  %2153 = phi <2 x i64> [ %2171, %2150 ], [ %1912, %1901 ]
  %2154 = phi <16 x i8> [ %2592, %2150 ], [ <i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, %1901 ]
  %2155 = phi <16 x i8> [ %2592, %2150 ], [ %2120, %1901 ]
  %2156 = phi <4 x i32> [ %2434, %2150 ], [ %1935, %1901 ]
  %2157 = phi <4 x i32> [ %2433, %2150 ], [ %1934, %1901 ]
  %2158 = phi <4 x i32> [ %2429, %2150 ], [ %1930, %1901 ]
  %2159 = phi <4 x i32> [ %2428, %2150 ], [ %1929, %1901 ]
  %2160 = phi <4 x i32> [ %2600, %2150 ], [ %2128, %1901 ]
  %2161 = phi <4 x i32> [ %2602, %2150 ], [ %2130, %1901 ]
  %2162 = add <4 x i32> %2160, <i32 512, i32 512, i32 512, i32 512>
  %2163 = lshr <4 x i32> %2162, <i32 10, i32 10, i32 10, i32 10>
  %2164 = getelementptr inbounds i16, i16* %1906, i64 %2151
  %2165 = getelementptr inbounds i16, i16* %2164, i64 16
  %2166 = add nuw nsw i64 %2151, 16
  %2167 = bitcast i16* %2165 to <2 x i64>*
  %2168 = load <2 x i64>, <2 x i64>* %2167, align 1
  %2169 = getelementptr inbounds i16, i16* %2164, i64 24
  %2170 = bitcast i16* %2169 to <2 x i64>*
  %2171 = load <2 x i64>, <2 x i64>* %2170, align 1
  %2172 = getelementptr inbounds i16, i16* %1905, i64 %2151
  %2173 = getelementptr inbounds i16, i16* %2172, i64 16
  %2174 = bitcast i16* %2173 to <2 x i64>*
  %2175 = load <2 x i64>, <2 x i64>* %2174, align 1
  %2176 = getelementptr inbounds i16, i16* %2172, i64 24
  %2177 = bitcast i16* %2176 to <2 x i64>*
  %2178 = load <2 x i64>, <2 x i64>* %2177, align 1
  %2179 = or i64 %2151, 8
  %2180 = bitcast <2 x i64> %2168 to <8 x i16>
  %2181 = shufflevector <8 x i16> %2180, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2182 = shufflevector <8 x i16> %2180, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2183 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2181, <8 x i16> %2181) #5
  %2184 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2182, <8 x i16> %2182) #5
  %2185 = bitcast <2 x i64> %2175 to <8 x i16>
  %2186 = shufflevector <8 x i16> %2185, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2187 = shufflevector <8 x i16> %2185, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2188 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2186, <8 x i16> %2186) #5
  %2189 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2187, <8 x i16> %2187) #5
  %2190 = bitcast <2 x i64> %2153 to <8 x i16>
  %2191 = bitcast <2 x i64> %2168 to <16 x i8>
  %2192 = bitcast <2 x i64> %2153 to <16 x i8>
  %2193 = shufflevector <16 x i8> %2192, <16 x i8> %2191, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2194 = bitcast <16 x i8> %2193 to <8 x i16>
  %2195 = shufflevector <16 x i8> %2192, <16 x i8> %2191, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2196 = bitcast <16 x i8> %2195 to <8 x i16>
  %2197 = shufflevector <16 x i8> %2192, <16 x i8> %2191, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %2198 = bitcast <16 x i8> %2197 to <8 x i16>
  %2199 = shufflevector <16 x i8> %2192, <16 x i8> %2191, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2200 = bitcast <16 x i8> %2199 to <8 x i16>
  %2201 = add <8 x i16> %2194, %2190
  %2202 = add <8 x i16> %2201, %2196
  %2203 = add <8 x i16> %2202, %2198
  %2204 = add <8 x i16> %2203, %2200
  %2205 = bitcast <2 x i64> %2171 to <16 x i8>
  %2206 = shufflevector <16 x i8> %2191, <16 x i8> %2205, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2207 = bitcast <16 x i8> %2206 to <8 x i16>
  %2208 = shufflevector <16 x i8> %2191, <16 x i8> %2205, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2209 = bitcast <16 x i8> %2208 to <8 x i16>
  %2210 = shufflevector <16 x i8> %2191, <16 x i8> %2205, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %2211 = bitcast <16 x i8> %2210 to <8 x i16>
  %2212 = shufflevector <16 x i8> %2191, <16 x i8> %2205, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2213 = bitcast <16 x i8> %2212 to <8 x i16>
  %2214 = add <8 x i16> %2207, %2180
  %2215 = add <8 x i16> %2214, %2209
  %2216 = add <8 x i16> %2215, %2211
  %2217 = add <8 x i16> %2216, %2213
  %2218 = getelementptr inbounds i16, i16* %2141, i64 %2179
  %2219 = bitcast i16* %2218 to <8 x i16>*
  store <8 x i16> %2204, <8 x i16>* %2219, align 16
  %2220 = getelementptr inbounds i16, i16* %2142, i64 %2179
  %2221 = bitcast i16* %2220 to <8 x i16>*
  store <8 x i16> %2217, <8 x i16>* %2221, align 16
  %2222 = bitcast <2 x i64> %2152 to <8 x i16>
  %2223 = bitcast <2 x i64> %2175 to <16 x i8>
  %2224 = bitcast <2 x i64> %2152 to <16 x i8>
  %2225 = shufflevector <16 x i8> %2224, <16 x i8> %2223, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2226 = bitcast <16 x i8> %2225 to <8 x i16>
  %2227 = shufflevector <16 x i8> %2224, <16 x i8> %2223, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2228 = bitcast <16 x i8> %2227 to <8 x i16>
  %2229 = shufflevector <16 x i8> %2224, <16 x i8> %2223, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %2230 = bitcast <16 x i8> %2229 to <8 x i16>
  %2231 = shufflevector <16 x i8> %2224, <16 x i8> %2223, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2232 = bitcast <16 x i8> %2231 to <8 x i16>
  %2233 = add <8 x i16> %2226, %2222
  %2234 = add <8 x i16> %2233, %2228
  %2235 = add <8 x i16> %2234, %2230
  %2236 = add <8 x i16> %2235, %2232
  %2237 = bitcast <2 x i64> %2178 to <16 x i8>
  %2238 = shufflevector <16 x i8> %2223, <16 x i8> %2237, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2239 = bitcast <16 x i8> %2238 to <8 x i16>
  %2240 = shufflevector <16 x i8> %2223, <16 x i8> %2237, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2241 = bitcast <16 x i8> %2240 to <8 x i16>
  %2242 = shufflevector <16 x i8> %2223, <16 x i8> %2237, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %2243 = bitcast <16 x i8> %2242 to <8 x i16>
  %2244 = shufflevector <16 x i8> %2223, <16 x i8> %2237, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2245 = bitcast <16 x i8> %2244 to <8 x i16>
  %2246 = add <8 x i16> %2239, %2185
  %2247 = add <8 x i16> %2246, %2241
  %2248 = add <8 x i16> %2247, %2243
  %2249 = add <8 x i16> %2248, %2245
  %2250 = getelementptr inbounds i16, i16* %2143, i64 %2179
  %2251 = bitcast i16* %2250 to <8 x i16>*
  store <8 x i16> %2236, <8 x i16>* %2251, align 16
  %2252 = getelementptr inbounds i16, i16* %2144, i64 %2179
  %2253 = bitcast i16* %2252 to <8 x i16>*
  store <8 x i16> %2249, <8 x i16>* %2253, align 16
  %2254 = bitcast <4 x i32> %2158 to <16 x i8>
  %2255 = bitcast <4 x i32> %2159 to <16 x i8>
  %2256 = shufflevector <16 x i8> %2255, <16 x i8> %2254, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2257 = bitcast <16 x i8> %2256 to <4 x i32>
  %2258 = shufflevector <16 x i8> %2255, <16 x i8> %2254, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2259 = bitcast <16 x i8> %2258 to <4 x i32>
  %2260 = shufflevector <16 x i8> %2255, <16 x i8> %2254, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2261 = bitcast <16 x i8> %2260 to <4 x i32>
  %2262 = add <4 x i32> %2159, %2158
  %2263 = add <4 x i32> %2262, %2257
  %2264 = add <4 x i32> %2263, %2259
  %2265 = add <4 x i32> %2264, %2261
  %2266 = bitcast <4 x i32> %2183 to <16 x i8>
  %2267 = shufflevector <16 x i8> %2254, <16 x i8> %2266, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2268 = bitcast <16 x i8> %2267 to <4 x i32>
  %2269 = shufflevector <16 x i8> %2254, <16 x i8> %2266, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2270 = bitcast <16 x i8> %2269 to <4 x i32>
  %2271 = shufflevector <16 x i8> %2254, <16 x i8> %2266, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2272 = bitcast <16 x i8> %2271 to <4 x i32>
  %2273 = add <4 x i32> %2183, %2158
  %2274 = add <4 x i32> %2273, %2268
  %2275 = add <4 x i32> %2274, %2270
  %2276 = add <4 x i32> %2275, %2272
  %2277 = getelementptr inbounds i32, i32* %1988, i64 %2179
  %2278 = bitcast i32* %2277 to <4 x i32>*
  store <4 x i32> %2265, <4 x i32>* %2278, align 16
  %2279 = getelementptr inbounds i32, i32* %2277, i64 4
  %2280 = bitcast i32* %2279 to <4 x i32>*
  store <4 x i32> %2276, <4 x i32>* %2280, align 16
  %2281 = bitcast <4 x i32> %2156 to <16 x i8>
  %2282 = bitcast <4 x i32> %2157 to <16 x i8>
  %2283 = shufflevector <16 x i8> %2282, <16 x i8> %2281, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2284 = bitcast <16 x i8> %2283 to <4 x i32>
  %2285 = shufflevector <16 x i8> %2282, <16 x i8> %2281, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2286 = bitcast <16 x i8> %2285 to <4 x i32>
  %2287 = shufflevector <16 x i8> %2282, <16 x i8> %2281, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2288 = bitcast <16 x i8> %2287 to <4 x i32>
  %2289 = add <4 x i32> %2157, %2156
  %2290 = add <4 x i32> %2289, %2284
  %2291 = add <4 x i32> %2290, %2286
  %2292 = add <4 x i32> %2291, %2288
  %2293 = bitcast <4 x i32> %2188 to <16 x i8>
  %2294 = shufflevector <16 x i8> %2281, <16 x i8> %2293, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2295 = bitcast <16 x i8> %2294 to <4 x i32>
  %2296 = shufflevector <16 x i8> %2281, <16 x i8> %2293, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2297 = bitcast <16 x i8> %2296 to <4 x i32>
  %2298 = shufflevector <16 x i8> %2281, <16 x i8> %2293, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2299 = bitcast <16 x i8> %2298 to <4 x i32>
  %2300 = add <4 x i32> %2188, %2156
  %2301 = add <4 x i32> %2300, %2295
  %2302 = add <4 x i32> %2301, %2297
  %2303 = add <4 x i32> %2302, %2299
  %2304 = getelementptr inbounds i32, i32* %2015, i64 %2179
  %2305 = bitcast i32* %2304 to <4 x i32>*
  store <4 x i32> %2292, <4 x i32>* %2305, align 16
  %2306 = getelementptr inbounds i32, i32* %2304, i64 4
  %2307 = bitcast i32* %2306 to <4 x i32>*
  store <4 x i32> %2303, <4 x i32>* %2307, align 16
  %2308 = getelementptr inbounds i16, i16* %2145, i64 %2179
  %2309 = bitcast i16* %2308 to <8 x i16>*
  %2310 = load <8 x i16>, <8 x i16>* %2309, align 16
  %2311 = getelementptr inbounds i16, i16* %2146, i64 %2179
  %2312 = bitcast i16* %2311 to <8 x i16>*
  %2313 = load <8 x i16>, <8 x i16>* %2312, align 16
  %2314 = getelementptr inbounds i16, i16* %2147, i64 %2179
  %2315 = bitcast i16* %2314 to <8 x i16>*
  %2316 = load <8 x i16>, <8 x i16>* %2315, align 16
  %2317 = getelementptr inbounds i32, i32* %2025, i64 %2179
  %2318 = bitcast i32* %2317 to <4 x i32>*
  %2319 = load <4 x i32>, <4 x i32>* %2318, align 16
  %2320 = getelementptr inbounds i32, i32* %2317, i64 4
  %2321 = bitcast i32* %2320 to <4 x i32>*
  %2322 = load <4 x i32>, <4 x i32>* %2321, align 16
  %2323 = getelementptr inbounds i32, i32* %2031, i64 %2179
  %2324 = bitcast i32* %2323 to <4 x i32>*
  %2325 = load <4 x i32>, <4 x i32>* %2324, align 16
  %2326 = getelementptr inbounds i32, i32* %2323, i64 4
  %2327 = bitcast i32* %2326 to <4 x i32>*
  %2328 = load <4 x i32>, <4 x i32>* %2327, align 16
  %2329 = getelementptr inbounds i32, i32* %2037, i64 %2179
  %2330 = bitcast i32* %2329 to <4 x i32>*
  %2331 = load <4 x i32>, <4 x i32>* %2330, align 16
  %2332 = getelementptr inbounds i32, i32* %2329, i64 4
  %2333 = bitcast i32* %2332 to <4 x i32>*
  %2334 = load <4 x i32>, <4 x i32>* %2333, align 16
  %2335 = add <8 x i16> %2236, %2204
  %2336 = add <8 x i16> %2335, %2310
  %2337 = add <8 x i16> %2336, %2313
  %2338 = add <8 x i16> %2337, %2316
  %2339 = add <8 x i16> %2338, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %2340 = lshr <8 x i16> %2339, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %2341 = shufflevector <8 x i16> %2340, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2342 = shufflevector <8 x i16> %2340, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2343 = add <4 x i32> %2292, <i32 8, i32 8, i32 8, i32 8>
  %2344 = add <4 x i32> %2343, %2265
  %2345 = add <4 x i32> %2344, %2319
  %2346 = add <4 x i32> %2345, %2325
  %2347 = add <4 x i32> %2346, %2331
  %2348 = lshr <4 x i32> %2347, <i32 4, i32 4, i32 4, i32 4>
  %2349 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2341, <8 x i16> %2341) #5
  %2350 = mul <4 x i32> %2348, <i32 25, i32 25, i32 25, i32 25>
  %2351 = sub <4 x i32> %2350, %2349
  %2352 = icmp sgt <4 x i32> %2351, zeroinitializer
  %2353 = select <4 x i1> %2352, <4 x i32> %2351, <4 x i32> zeroinitializer
  %2354 = mul <4 x i32> %2353, %340
  %2355 = add <4 x i32> %2354, <i32 524288, i32 524288, i32 524288, i32 524288>
  %2356 = lshr <4 x i32> %2355, <i32 20, i32 20, i32 20, i32 20>
  %2357 = add <4 x i32> %2276, <i32 8, i32 8, i32 8, i32 8>
  %2358 = add <4 x i32> %2357, %2303
  %2359 = add <4 x i32> %2358, %2322
  %2360 = add <4 x i32> %2359, %2328
  %2361 = add <4 x i32> %2360, %2334
  %2362 = lshr <4 x i32> %2361, <i32 4, i32 4, i32 4, i32 4>
  %2363 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2342, <8 x i16> %2342) #5
  %2364 = mul <4 x i32> %2362, <i32 25, i32 25, i32 25, i32 25>
  %2365 = sub <4 x i32> %2364, %2363
  %2366 = icmp sgt <4 x i32> %2365, zeroinitializer
  %2367 = select <4 x i1> %2366, <4 x i32> %2365, <4 x i32> zeroinitializer
  %2368 = mul <4 x i32> %2367, %340
  %2369 = add <4 x i32> %2368, <i32 524288, i32 524288, i32 524288, i32 524288>
  %2370 = lshr <4 x i32> %2369, <i32 20, i32 20, i32 20, i32 20>
  %2371 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2356, <4 x i32> %2370) #5
  %2372 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2371, <8 x i16> undef) #5
  %2373 = bitcast <16 x i8> %2372 to <2 x i64>
  %2374 = extractelement <2 x i64> %2373, i32 0
  %2375 = lshr i64 %2374, 8
  %2376 = lshr i64 %2374, 16
  %2377 = lshr i64 %2374, 24
  %2378 = lshr i64 %2374, 32
  %2379 = lshr i64 %2374, 40
  %2380 = lshr i64 %2374, 48
  %2381 = lshr i64 %2374, 56
  %2382 = and i64 %2374, 255
  %2383 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2382
  %2384 = load i8, i8* %2383, align 1
  %2385 = insertelement <16 x i8> %2155, i8 %2384, i64 8
  %2386 = and i64 %2375, 255
  %2387 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2386
  %2388 = load i8, i8* %2387, align 1
  %2389 = insertelement <16 x i8> %2385, i8 %2388, i64 9
  %2390 = and i64 %2376, 255
  %2391 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2390
  %2392 = load i8, i8* %2391, align 1
  %2393 = insertelement <16 x i8> %2389, i8 %2392, i64 10
  %2394 = and i64 %2377, 255
  %2395 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2394
  %2396 = load i8, i8* %2395, align 1
  %2397 = insertelement <16 x i8> %2393, i8 %2396, i64 11
  %2398 = and i64 %2378, 255
  %2399 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2398
  %2400 = load i8, i8* %2399, align 1
  %2401 = insertelement <16 x i8> %2397, i8 %2400, i64 12
  %2402 = and i64 %2379, 255
  %2403 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2402
  %2404 = load i8, i8* %2403, align 1
  %2405 = insertelement <16 x i8> %2401, i8 %2404, i64 13
  %2406 = and i64 %2380, 255
  %2407 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2406
  %2408 = load i8, i8* %2407, align 1
  %2409 = insertelement <16 x i8> %2405, i8 %2408, i64 14
  %2410 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2381
  %2411 = load i8, i8* %2410, align 1
  %2412 = insertelement <16 x i8> %2409, i8 %2411, i64 15
  %2413 = shufflevector <16 x i8> %2412, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %2414 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2413, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %2415 = shufflevector <8 x i16> %2414, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2416 = shufflevector <8 x i16> %2338, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2417 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2415, <8 x i16> %2416) #5
  %2418 = shufflevector <8 x i16> %2414, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2419 = shufflevector <8 x i16> %2338, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2420 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2418, <8 x i16> %2419) #5
  %2421 = add <4 x i32> %2417, <i32 512, i32 512, i32 512, i32 512>
  %2422 = lshr <4 x i32> %2421, <i32 10, i32 10, i32 10, i32 10>
  %2423 = add <4 x i32> %2420, <i32 512, i32 512, i32 512, i32 512>
  %2424 = lshr <4 x i32> %2423, <i32 10, i32 10, i32 10, i32 10>
  %2425 = bitcast <2 x i64> %2171 to <8 x i16>
  %2426 = shufflevector <8 x i16> %2425, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2427 = shufflevector <8 x i16> %2425, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2428 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2426, <8 x i16> %2426) #5
  %2429 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2427, <8 x i16> %2427) #5
  %2430 = bitcast <2 x i64> %2178 to <8 x i16>
  %2431 = shufflevector <8 x i16> %2430, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2432 = shufflevector <8 x i16> %2430, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2433 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2431, <8 x i16> %2431) #5
  %2434 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2432, <8 x i16> %2432) #5
  %2435 = bitcast <4 x i32> %2184 to <16 x i8>
  %2436 = shufflevector <16 x i8> %2266, <16 x i8> %2435, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2437 = bitcast <16 x i8> %2436 to <4 x i32>
  %2438 = shufflevector <16 x i8> %2266, <16 x i8> %2435, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2439 = bitcast <16 x i8> %2438 to <4 x i32>
  %2440 = shufflevector <16 x i8> %2266, <16 x i8> %2435, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2441 = bitcast <16 x i8> %2440 to <4 x i32>
  %2442 = add <4 x i32> %2184, %2183
  %2443 = add <4 x i32> %2442, %2437
  %2444 = add <4 x i32> %2443, %2439
  %2445 = add <4 x i32> %2444, %2441
  %2446 = bitcast <4 x i32> %2428 to <16 x i8>
  %2447 = shufflevector <16 x i8> %2435, <16 x i8> %2446, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2448 = bitcast <16 x i8> %2447 to <4 x i32>
  %2449 = shufflevector <16 x i8> %2435, <16 x i8> %2446, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2450 = bitcast <16 x i8> %2449 to <4 x i32>
  %2451 = shufflevector <16 x i8> %2435, <16 x i8> %2446, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2452 = bitcast <16 x i8> %2451 to <4 x i32>
  %2453 = add <4 x i32> %2428, %2184
  %2454 = add <4 x i32> %2453, %2448
  %2455 = add <4 x i32> %2454, %2450
  %2456 = add <4 x i32> %2455, %2452
  %2457 = getelementptr inbounds i32, i32* %2148, i64 %2179
  %2458 = bitcast i32* %2457 to <4 x i32>*
  store <4 x i32> %2445, <4 x i32>* %2458, align 16
  %2459 = getelementptr inbounds i32, i32* %2457, i64 4
  %2460 = bitcast i32* %2459 to <4 x i32>*
  store <4 x i32> %2456, <4 x i32>* %2460, align 16
  %2461 = bitcast <4 x i32> %2189 to <16 x i8>
  %2462 = shufflevector <16 x i8> %2293, <16 x i8> %2461, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2463 = bitcast <16 x i8> %2462 to <4 x i32>
  %2464 = shufflevector <16 x i8> %2293, <16 x i8> %2461, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2465 = bitcast <16 x i8> %2464 to <4 x i32>
  %2466 = shufflevector <16 x i8> %2293, <16 x i8> %2461, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2467 = bitcast <16 x i8> %2466 to <4 x i32>
  %2468 = add <4 x i32> %2189, %2188
  %2469 = add <4 x i32> %2468, %2463
  %2470 = add <4 x i32> %2469, %2465
  %2471 = add <4 x i32> %2470, %2467
  %2472 = bitcast <4 x i32> %2433 to <16 x i8>
  %2473 = shufflevector <16 x i8> %2461, <16 x i8> %2472, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2474 = bitcast <16 x i8> %2473 to <4 x i32>
  %2475 = shufflevector <16 x i8> %2461, <16 x i8> %2472, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2476 = bitcast <16 x i8> %2475 to <4 x i32>
  %2477 = shufflevector <16 x i8> %2461, <16 x i8> %2472, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2478 = bitcast <16 x i8> %2477 to <4 x i32>
  %2479 = add <4 x i32> %2433, %2189
  %2480 = add <4 x i32> %2479, %2474
  %2481 = add <4 x i32> %2480, %2476
  %2482 = add <4 x i32> %2481, %2478
  %2483 = getelementptr inbounds i32, i32* %2149, i64 %2179
  %2484 = bitcast i32* %2483 to <4 x i32>*
  store <4 x i32> %2471, <4 x i32>* %2484, align 16
  %2485 = getelementptr inbounds i32, i32* %2483, i64 4
  %2486 = bitcast i32* %2485 to <4 x i32>*
  store <4 x i32> %2482, <4 x i32>* %2486, align 16
  %2487 = add nuw nsw i64 %2179, 8
  %2488 = getelementptr inbounds i16, i16* %2145, i64 %2487
  %2489 = bitcast i16* %2488 to <8 x i16>*
  %2490 = load <8 x i16>, <8 x i16>* %2489, align 16
  %2491 = getelementptr inbounds i16, i16* %2146, i64 %2487
  %2492 = bitcast i16* %2491 to <8 x i16>*
  %2493 = load <8 x i16>, <8 x i16>* %2492, align 16
  %2494 = getelementptr inbounds i16, i16* %2147, i64 %2487
  %2495 = bitcast i16* %2494 to <8 x i16>*
  %2496 = load <8 x i16>, <8 x i16>* %2495, align 16
  %2497 = getelementptr inbounds i32, i32* %2025, i64 %2487
  %2498 = bitcast i32* %2497 to <4 x i32>*
  %2499 = load <4 x i32>, <4 x i32>* %2498, align 16
  %2500 = getelementptr inbounds i32, i32* %2497, i64 4
  %2501 = bitcast i32* %2500 to <4 x i32>*
  %2502 = load <4 x i32>, <4 x i32>* %2501, align 16
  %2503 = getelementptr inbounds i32, i32* %2031, i64 %2487
  %2504 = bitcast i32* %2503 to <4 x i32>*
  %2505 = load <4 x i32>, <4 x i32>* %2504, align 16
  %2506 = getelementptr inbounds i32, i32* %2503, i64 4
  %2507 = bitcast i32* %2506 to <4 x i32>*
  %2508 = load <4 x i32>, <4 x i32>* %2507, align 16
  %2509 = getelementptr inbounds i32, i32* %2037, i64 %2487
  %2510 = bitcast i32* %2509 to <4 x i32>*
  %2511 = load <4 x i32>, <4 x i32>* %2510, align 16
  %2512 = getelementptr inbounds i32, i32* %2509, i64 4
  %2513 = bitcast i32* %2512 to <4 x i32>*
  %2514 = load <4 x i32>, <4 x i32>* %2513, align 16
  %2515 = add <8 x i16> %2249, %2217
  %2516 = add <8 x i16> %2515, %2490
  %2517 = add <8 x i16> %2516, %2493
  %2518 = add <8 x i16> %2517, %2496
  %2519 = add <8 x i16> %2518, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %2520 = lshr <8 x i16> %2519, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %2521 = shufflevector <8 x i16> %2520, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2522 = shufflevector <8 x i16> %2520, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2523 = add <4 x i32> %2445, <i32 8, i32 8, i32 8, i32 8>
  %2524 = add <4 x i32> %2523, %2471
  %2525 = add <4 x i32> %2524, %2499
  %2526 = add <4 x i32> %2525, %2505
  %2527 = add <4 x i32> %2526, %2511
  %2528 = lshr <4 x i32> %2527, <i32 4, i32 4, i32 4, i32 4>
  %2529 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2521, <8 x i16> %2521) #5
  %2530 = mul <4 x i32> %2528, <i32 25, i32 25, i32 25, i32 25>
  %2531 = sub <4 x i32> %2530, %2529
  %2532 = icmp sgt <4 x i32> %2531, zeroinitializer
  %2533 = select <4 x i1> %2532, <4 x i32> %2531, <4 x i32> zeroinitializer
  %2534 = mul <4 x i32> %2533, %340
  %2535 = add <4 x i32> %2534, <i32 524288, i32 524288, i32 524288, i32 524288>
  %2536 = lshr <4 x i32> %2535, <i32 20, i32 20, i32 20, i32 20>
  %2537 = add <4 x i32> %2456, <i32 8, i32 8, i32 8, i32 8>
  %2538 = add <4 x i32> %2537, %2482
  %2539 = add <4 x i32> %2538, %2502
  %2540 = add <4 x i32> %2539, %2508
  %2541 = add <4 x i32> %2540, %2514
  %2542 = lshr <4 x i32> %2541, <i32 4, i32 4, i32 4, i32 4>
  %2543 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2522, <8 x i16> %2522) #5
  %2544 = mul <4 x i32> %2542, <i32 25, i32 25, i32 25, i32 25>
  %2545 = sub <4 x i32> %2544, %2543
  %2546 = icmp sgt <4 x i32> %2545, zeroinitializer
  %2547 = select <4 x i1> %2546, <4 x i32> %2545, <4 x i32> zeroinitializer
  %2548 = mul <4 x i32> %2547, %340
  %2549 = add <4 x i32> %2548, <i32 524288, i32 524288, i32 524288, i32 524288>
  %2550 = lshr <4 x i32> %2549, <i32 20, i32 20, i32 20, i32 20>
  %2551 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2536, <4 x i32> %2550) #5
  %2552 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2551, <8 x i16> undef) #5
  %2553 = bitcast <16 x i8> %2552 to <2 x i64>
  %2554 = extractelement <2 x i64> %2553, i32 0
  %2555 = lshr i64 %2554, 8
  %2556 = lshr i64 %2554, 16
  %2557 = lshr i64 %2554, 24
  %2558 = lshr i64 %2554, 32
  %2559 = lshr i64 %2554, 40
  %2560 = lshr i64 %2554, 48
  %2561 = lshr i64 %2554, 56
  %2562 = and i64 %2554, 255
  %2563 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2562
  %2564 = load i8, i8* %2563, align 1
  %2565 = insertelement <16 x i8> %2154, i8 %2564, i64 0
  %2566 = and i64 %2555, 255
  %2567 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2566
  %2568 = load i8, i8* %2567, align 1
  %2569 = insertelement <16 x i8> %2565, i8 %2568, i64 1
  %2570 = and i64 %2556, 255
  %2571 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2570
  %2572 = load i8, i8* %2571, align 1
  %2573 = insertelement <16 x i8> %2569, i8 %2572, i64 2
  %2574 = and i64 %2557, 255
  %2575 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2574
  %2576 = load i8, i8* %2575, align 1
  %2577 = insertelement <16 x i8> %2573, i8 %2576, i64 3
  %2578 = and i64 %2558, 255
  %2579 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2578
  %2580 = load i8, i8* %2579, align 1
  %2581 = insertelement <16 x i8> %2577, i8 %2580, i64 4
  %2582 = and i64 %2559, 255
  %2583 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2582
  %2584 = load i8, i8* %2583, align 1
  %2585 = insertelement <16 x i8> %2581, i8 %2584, i64 5
  %2586 = and i64 %2560, 255
  %2587 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2586
  %2588 = load i8, i8* %2587, align 1
  %2589 = insertelement <16 x i8> %2585, i8 %2588, i64 6
  %2590 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2561
  %2591 = load i8, i8* %2590, align 1
  %2592 = insertelement <16 x i8> %2589, i8 %2591, i64 7
  %2593 = shufflevector <16 x i8> %2592, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2594 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2593, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %2595 = shufflevector <8 x i16> %2594, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2596 = shufflevector <8 x i16> %2518, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2597 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2595, <8 x i16> %2596) #5
  %2598 = shufflevector <8 x i16> %2594, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2599 = shufflevector <8 x i16> %2518, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2600 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2598, <8 x i16> %2599) #5
  %2601 = add <4 x i32> %2597, <i32 512, i32 512, i32 512, i32 512>
  %2602 = lshr <4 x i32> %2601, <i32 10, i32 10, i32 10, i32 10>
  %2603 = shufflevector <16 x i8> %2412, <16 x i8> %2592, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %2604 = shufflevector <16 x i8> %2412, <16 x i8> %2592, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2605 = shufflevector <16 x i8> %2412, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2606 = shufflevector <16 x i8> %2603, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2607 = bitcast <16 x i8> %2605 to <8 x i16>
  %2608 = bitcast <16 x i8> %2606 to <8 x i16>
  %2609 = add <8 x i16> %2608, %2607
  %2610 = shufflevector <16 x i8> %2604, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2611 = bitcast <16 x i8> %2610 to <8 x i16>
  %2612 = add <8 x i16> %2609, %2611
  %2613 = mul <8 x i16> %2612, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %2614 = add <8 x i16> %2613, %2608
  %2615 = getelementptr inbounds i16, i16* %2133, i64 %2151
  %2616 = bitcast i16* %2615 to <8 x i16>*
  store <8 x i16> %2614, <8 x i16>* %2616, align 16
  %2617 = bitcast <4 x i32> %2163 to <16 x i8>
  %2618 = bitcast <4 x i32> %2161 to <16 x i8>
  %2619 = shufflevector <16 x i8> %2618, <16 x i8> %2617, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2620 = bitcast <16 x i8> %2619 to <4 x i32>
  %2621 = shufflevector <16 x i8> %2618, <16 x i8> %2617, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2622 = bitcast <16 x i8> %2621 to <4 x i32>
  %2623 = add <4 x i32> %2161, %2620
  %2624 = add <4 x i32> %2623, %2622
  %2625 = mul <4 x i32> %2624, <i32 5, i32 5, i32 5, i32 5>
  %2626 = add <4 x i32> %2625, %2620
  %2627 = bitcast <4 x i32> %2422 to <16 x i8>
  %2628 = shufflevector <16 x i8> %2617, <16 x i8> %2627, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2629 = bitcast <16 x i8> %2628 to <4 x i32>
  %2630 = shufflevector <16 x i8> %2617, <16 x i8> %2627, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2631 = bitcast <16 x i8> %2630 to <4 x i32>
  %2632 = add <4 x i32> %2163, %2629
  %2633 = add <4 x i32> %2632, %2631
  %2634 = mul <4 x i32> %2633, <i32 5, i32 5, i32 5, i32 5>
  %2635 = add <4 x i32> %2634, %2629
  %2636 = getelementptr inbounds i32, i32* %2134, i64 %2151
  %2637 = bitcast i32* %2636 to <4 x i32>*
  store <4 x i32> %2626, <4 x i32>* %2637, align 16
  %2638 = getelementptr inbounds i32, i32* %2636, i64 4
  %2639 = bitcast i32* %2638 to <4 x i32>*
  store <4 x i32> %2635, <4 x i32>* %2639, align 16
  %2640 = getelementptr inbounds i16, i16* %1907, i64 %2151
  %2641 = bitcast i16* %2640 to <8 x i16>*
  %2642 = load <8 x i16>, <8 x i16>* %2641, align 16
  %2643 = getelementptr inbounds i16, i16* %2131, i64 %2151
  %2644 = bitcast i16* %2643 to <8 x i16>*
  %2645 = load <8 x i16>, <8 x i16>* %2644, align 16
  %2646 = getelementptr inbounds i16, i16* %2135, i64 %2151
  %2647 = bitcast i16* %2646 to <8 x i16>*
  %2648 = load <8 x i16>, <8 x i16>* %2647, align 16
  %2649 = getelementptr inbounds i32, i32* %2136, i64 %2151
  %2650 = bitcast i32* %2649 to <4 x i32>*
  %2651 = load <4 x i32>, <4 x i32>* %2650, align 16
  %2652 = getelementptr inbounds i32, i32* %2649, i64 4
  %2653 = bitcast i32* %2652 to <4 x i32>*
  %2654 = load <4 x i32>, <4 x i32>* %2653, align 16
  %2655 = add <8 x i16> %2648, %2614
  %2656 = shufflevector <8 x i16> %2655, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2657 = shufflevector <8 x i16> %2642, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2658 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2656, <8 x i16> %2657) #5
  %2659 = shufflevector <8 x i16> %2655, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2660 = shufflevector <8 x i16> %2642, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2661 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2659, <8 x i16> %2660) #5
  %2662 = add <4 x i32> %2626, <i32 256, i32 256, i32 256, i32 256>
  %2663 = add <4 x i32> %2662, %2651
  %2664 = sub <4 x i32> %2663, %2658
  %2665 = ashr <4 x i32> %2664, <i32 9, i32 9, i32 9, i32 9>
  %2666 = add <4 x i32> %2635, <i32 256, i32 256, i32 256, i32 256>
  %2667 = add <4 x i32> %2666, %2654
  %2668 = sub <4 x i32> %2667, %2661
  %2669 = ashr <4 x i32> %2668, <i32 9, i32 9, i32 9, i32 9>
  %2670 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2665, <4 x i32> %2669) #5
  %2671 = shufflevector <8 x i16> %2614, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2672 = shufflevector <8 x i16> %2645, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2673 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2671, <8 x i16> %2672) #5
  %2674 = shufflevector <8 x i16> %2614, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2675 = shufflevector <8 x i16> %2645, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2676 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2674, <8 x i16> %2675) #5
  %2677 = add <4 x i32> %2626, <i32 128, i32 128, i32 128, i32 128>
  %2678 = sub <4 x i32> %2677, %2673
  %2679 = ashr <4 x i32> %2678, <i32 8, i32 8, i32 8, i32 8>
  %2680 = add <4 x i32> %2635, <i32 128, i32 128, i32 128, i32 128>
  %2681 = sub <4 x i32> %2680, %2676
  %2682 = ashr <4 x i32> %2681, <i32 8, i32 8, i32 8, i32 8>
  %2683 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2679, <4 x i32> %2682) #5
  %2684 = shufflevector <8 x i16> %2670, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2685 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2684, <8 x i16> %932) #5
  %2686 = shufflevector <8 x i16> %2670, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2687 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2686, <8 x i16> %932) #5
  %2688 = add <4 x i32> %2685, <i32 1024, i32 1024, i32 1024, i32 1024>
  %2689 = ashr <4 x i32> %2688, <i32 11, i32 11, i32 11, i32 11>
  %2690 = add <4 x i32> %2687, <i32 1024, i32 1024, i32 1024, i32 1024>
  %2691 = ashr <4 x i32> %2690, <i32 11, i32 11, i32 11, i32 11>
  %2692 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2689, <4 x i32> %2691) #5
  %2693 = add <8 x i16> %2692, %2642
  %2694 = shufflevector <8 x i16> %2683, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2695 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2694, <8 x i16> %932) #5
  %2696 = shufflevector <8 x i16> %2683, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2697 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2696, <8 x i16> %932) #5
  %2698 = add <4 x i32> %2695, <i32 1024, i32 1024, i32 1024, i32 1024>
  %2699 = ashr <4 x i32> %2698, <i32 11, i32 11, i32 11, i32 11>
  %2700 = add <4 x i32> %2697, <i32 1024, i32 1024, i32 1024, i32 1024>
  %2701 = ashr <4 x i32> %2700, <i32 11, i32 11, i32 11, i32 11>
  %2702 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2699, <4 x i32> %2701) #5
  %2703 = add <8 x i16> %2702, %2645
  %2704 = shufflevector <16 x i8> %2603, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %2705 = bitcast <16 x i8> %2413 to <8 x i16>
  %2706 = bitcast <16 x i8> %2704 to <8 x i16>
  %2707 = add <8 x i16> %2706, %2705
  %2708 = shufflevector <16 x i8> %2604, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %2709 = bitcast <16 x i8> %2708 to <8 x i16>
  %2710 = add <8 x i16> %2707, %2709
  %2711 = mul <8 x i16> %2710, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %2712 = add <8 x i16> %2711, %2706
  %2713 = getelementptr inbounds i16, i16* %2137, i64 %2151
  %2714 = bitcast i16* %2713 to <8 x i16>*
  store <8 x i16> %2712, <8 x i16>* %2714, align 16
  %2715 = bitcast <4 x i32> %2424 to <16 x i8>
  %2716 = shufflevector <16 x i8> %2627, <16 x i8> %2715, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2717 = bitcast <16 x i8> %2716 to <4 x i32>
  %2718 = shufflevector <16 x i8> %2627, <16 x i8> %2715, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2719 = bitcast <16 x i8> %2718 to <4 x i32>
  %2720 = add <4 x i32> %2422, %2717
  %2721 = add <4 x i32> %2720, %2719
  %2722 = mul <4 x i32> %2721, <i32 5, i32 5, i32 5, i32 5>
  %2723 = add <4 x i32> %2722, %2717
  %2724 = bitcast <4 x i32> %2602 to <16 x i8>
  %2725 = shufflevector <16 x i8> %2715, <16 x i8> %2724, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2726 = bitcast <16 x i8> %2725 to <4 x i32>
  %2727 = shufflevector <16 x i8> %2715, <16 x i8> %2724, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2728 = bitcast <16 x i8> %2727 to <4 x i32>
  %2729 = add <4 x i32> %2424, %2726
  %2730 = add <4 x i32> %2729, %2728
  %2731 = mul <4 x i32> %2730, <i32 5, i32 5, i32 5, i32 5>
  %2732 = add <4 x i32> %2731, %2726
  %2733 = getelementptr inbounds i32, i32* %2138, i64 %2151
  %2734 = bitcast i32* %2733 to <4 x i32>*
  store <4 x i32> %2723, <4 x i32>* %2734, align 16
  %2735 = getelementptr inbounds i32, i32* %2733, i64 4
  %2736 = bitcast i32* %2735 to <4 x i32>*
  store <4 x i32> %2732, <4 x i32>* %2736, align 16
  %2737 = getelementptr inbounds i16, i16* %2640, i64 8
  %2738 = bitcast i16* %2737 to <8 x i16>*
  %2739 = load <8 x i16>, <8 x i16>* %2738, align 16
  %2740 = getelementptr inbounds i16, i16* %2643, i64 8
  %2741 = bitcast i16* %2740 to <8 x i16>*
  %2742 = load <8 x i16>, <8 x i16>* %2741, align 16
  %2743 = getelementptr inbounds i16, i16* %2139, i64 %2151
  %2744 = bitcast i16* %2743 to <8 x i16>*
  %2745 = load <8 x i16>, <8 x i16>* %2744, align 16
  %2746 = getelementptr inbounds i32, i32* %2140, i64 %2151
  %2747 = bitcast i32* %2746 to <4 x i32>*
  %2748 = load <4 x i32>, <4 x i32>* %2747, align 16
  %2749 = getelementptr inbounds i32, i32* %2746, i64 4
  %2750 = bitcast i32* %2749 to <4 x i32>*
  %2751 = load <4 x i32>, <4 x i32>* %2750, align 16
  %2752 = add <8 x i16> %2745, %2712
  %2753 = shufflevector <8 x i16> %2752, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2754 = shufflevector <8 x i16> %2739, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2755 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2753, <8 x i16> %2754) #5
  %2756 = shufflevector <8 x i16> %2752, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2757 = shufflevector <8 x i16> %2739, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2758 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2756, <8 x i16> %2757) #5
  %2759 = add <4 x i32> %2723, <i32 256, i32 256, i32 256, i32 256>
  %2760 = add <4 x i32> %2759, %2748
  %2761 = sub <4 x i32> %2760, %2755
  %2762 = ashr <4 x i32> %2761, <i32 9, i32 9, i32 9, i32 9>
  %2763 = add <4 x i32> %2732, <i32 256, i32 256, i32 256, i32 256>
  %2764 = add <4 x i32> %2763, %2751
  %2765 = sub <4 x i32> %2764, %2758
  %2766 = ashr <4 x i32> %2765, <i32 9, i32 9, i32 9, i32 9>
  %2767 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2762, <4 x i32> %2766) #5
  %2768 = shufflevector <8 x i16> %2712, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2769 = shufflevector <8 x i16> %2742, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2770 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2768, <8 x i16> %2769) #5
  %2771 = shufflevector <8 x i16> %2712, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2772 = shufflevector <8 x i16> %2742, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2773 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2771, <8 x i16> %2772) #5
  %2774 = add <4 x i32> %2723, <i32 128, i32 128, i32 128, i32 128>
  %2775 = sub <4 x i32> %2774, %2770
  %2776 = ashr <4 x i32> %2775, <i32 8, i32 8, i32 8, i32 8>
  %2777 = add <4 x i32> %2732, <i32 128, i32 128, i32 128, i32 128>
  %2778 = sub <4 x i32> %2777, %2773
  %2779 = ashr <4 x i32> %2778, <i32 8, i32 8, i32 8, i32 8>
  %2780 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2776, <4 x i32> %2779) #5
  %2781 = shufflevector <8 x i16> %2767, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2782 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2781, <8 x i16> %932) #5
  %2783 = shufflevector <8 x i16> %2767, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2784 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2783, <8 x i16> %932) #5
  %2785 = add <4 x i32> %2782, <i32 1024, i32 1024, i32 1024, i32 1024>
  %2786 = ashr <4 x i32> %2785, <i32 11, i32 11, i32 11, i32 11>
  %2787 = add <4 x i32> %2784, <i32 1024, i32 1024, i32 1024, i32 1024>
  %2788 = ashr <4 x i32> %2787, <i32 11, i32 11, i32 11, i32 11>
  %2789 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2786, <4 x i32> %2788) #5
  %2790 = add <8 x i16> %2789, %2739
  %2791 = getelementptr inbounds i16, i16* %952, i64 %2151
  %2792 = icmp sgt <8 x i16> %2693, zeroinitializer
  %2793 = select <8 x i1> %2792, <8 x i16> %2693, <8 x i16> zeroinitializer
  %2794 = icmp slt <8 x i16> %2793, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %2795 = select <8 x i1> %2794, <8 x i16> %2793, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %2796 = bitcast i16* %2791 to <8 x i16>*
  store <8 x i16> %2795, <8 x i16>* %2796, align 16
  %2797 = getelementptr inbounds i16, i16* %2791, i64 8
  %2798 = icmp sgt <8 x i16> %2790, zeroinitializer
  %2799 = select <8 x i1> %2798, <8 x i16> %2790, <8 x i16> zeroinitializer
  %2800 = icmp slt <8 x i16> %2799, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %2801 = select <8 x i1> %2800, <8 x i16> %2799, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %2802 = bitcast i16* %2797 to <8 x i16>*
  store <8 x i16> %2801, <8 x i16>* %2802, align 16
  %2803 = shufflevector <8 x i16> %2780, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2804 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2803, <8 x i16> %932) #5
  %2805 = shufflevector <8 x i16> %2780, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2806 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2805, <8 x i16> %932) #5
  %2807 = add <4 x i32> %2804, <i32 1024, i32 1024, i32 1024, i32 1024>
  %2808 = ashr <4 x i32> %2807, <i32 11, i32 11, i32 11, i32 11>
  %2809 = add <4 x i32> %2806, <i32 1024, i32 1024, i32 1024, i32 1024>
  %2810 = ashr <4 x i32> %2809, <i32 11, i32 11, i32 11, i32 11>
  %2811 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2808, <4 x i32> %2810) #5
  %2812 = add <8 x i16> %2811, %2742
  %2813 = getelementptr inbounds i16, i16* %2132, i64 %2151
  %2814 = icmp sgt <8 x i16> %2703, zeroinitializer
  %2815 = select <8 x i1> %2814, <8 x i16> %2703, <8 x i16> zeroinitializer
  %2816 = icmp slt <8 x i16> %2815, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %2817 = select <8 x i1> %2816, <8 x i16> %2815, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %2818 = bitcast i16* %2813 to <8 x i16>*
  store <8 x i16> %2817, <8 x i16>* %2818, align 16
  %2819 = getelementptr inbounds i16, i16* %2813, i64 8
  %2820 = icmp sgt <8 x i16> %2812, zeroinitializer
  %2821 = select <8 x i1> %2820, <8 x i16> %2812, <8 x i16> zeroinitializer
  %2822 = icmp slt <8 x i16> %2821, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %2823 = select <8 x i1> %2822, <8 x i16> %2821, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %2824 = bitcast i16* %2819 to <8 x i16>*
  store <8 x i16> %2823, <8 x i16>* %2824, align 16
  %2825 = icmp slt i64 %2166, %24
  br i1 %2825, label %2150, label %2826

2826:                                             ; preds = %2150, %937
  br i1 %955, label %12087, label %2827

2827:                                             ; preds = %2826
  %2828 = getelementptr inbounds i16, i16* %953, i64 3
  br i1 %193, label %2829, label %2832

2829:                                             ; preds = %2827
  %2830 = getelementptr inbounds i16, i16* %2828, i64 %926
  %2831 = getelementptr inbounds i16, i16* %952, i64 %926
  br label %2832

2832:                                             ; preds = %2827, %2829
  %2833 = phi i64 [ %941, %2829 ], [ %938, %2827 ]
  %2834 = phi i64 [ %947, %2829 ], [ %939, %2827 ]
  %2835 = phi i64 [ %938, %2829 ], [ %940, %2827 ]
  %2836 = phi i64 [ %945, %2829 ], [ %942, %2827 ]
  %2837 = phi i64 [ %946, %2829 ], [ %943, %2827 ]
  %2838 = phi i64 [ %942, %2829 ], [ %944, %2827 ]
  %2839 = phi i64 [ %948, %2829 ], [ %949, %2827 ]
  %2840 = phi i64 [ %950, %2829 ], [ %951, %2827 ]
  %2841 = phi i16* [ %2831, %2829 ], [ %952, %2827 ]
  %2842 = phi i16* [ %2830, %2829 ], [ %2828, %2827 ]
  %2843 = inttoptr i64 %2835 to <8 x i16>*
  %2844 = inttoptr i64 %2834 to <8 x i16>*
  %2845 = inttoptr i64 %2833 to <8 x i16>*
  %2846 = inttoptr i64 %2838 to i32*
  %2847 = inttoptr i64 %2837 to i32*
  %2848 = inttoptr i64 %2836 to i32*
  %2849 = getelementptr inbounds i16, i16* %178, i64 %6
  %2850 = inttoptr i64 %2839 to i16*
  %2851 = inttoptr i64 %2840 to i32*
  %2852 = bitcast i16* %2849 to <8 x i16>*
  %2853 = load <8 x i16>, <8 x i16>* %2852, align 1
  %2854 = getelementptr inbounds i16, i16* %2849, i64 8
  %2855 = bitcast i16* %2854 to <2 x i64>*
  %2856 = load <2 x i64>, <2 x i64>* %2855, align 1
  %2857 = shufflevector <8 x i16> %2853, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2858 = shufflevector <8 x i16> %2853, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2859 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2857, <8 x i16> %2857) #5
  %2860 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2858, <8 x i16> %2858) #5
  %2861 = bitcast <2 x i64> %2856 to <8 x i16>
  %2862 = shufflevector <8 x i16> %2861, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2863 = shufflevector <8 x i16> %2861, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2864 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2862, <8 x i16> %2862) #5
  %2865 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2863, <8 x i16> %2863) #5
  %2866 = bitcast <2 x i64> %2856 to <16 x i8>
  %2867 = bitcast <8 x i16> %2853 to <16 x i8>
  %2868 = shufflevector <16 x i8> %2867, <16 x i8> %2866, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2869 = bitcast <16 x i8> %2868 to <8 x i16>
  %2870 = shufflevector <16 x i8> %2867, <16 x i8> %2866, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2871 = bitcast <16 x i8> %2870 to <8 x i16>
  %2872 = shufflevector <16 x i8> %2867, <16 x i8> %2866, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %2873 = bitcast <16 x i8> %2872 to <8 x i16>
  %2874 = shufflevector <16 x i8> %2867, <16 x i8> %2866, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2875 = bitcast <16 x i8> %2874 to <8 x i16>
  %2876 = add <8 x i16> %2853, %2869
  %2877 = add <8 x i16> %2876, %2871
  %2878 = add <8 x i16> %2877, %2873
  %2879 = add <8 x i16> %2878, %2875
  %2880 = bitcast <4 x i32> %2860 to <16 x i8>
  %2881 = bitcast <4 x i32> %2859 to <16 x i8>
  %2882 = shufflevector <16 x i8> %2881, <16 x i8> %2880, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2883 = bitcast <16 x i8> %2882 to <4 x i32>
  %2884 = shufflevector <16 x i8> %2881, <16 x i8> %2880, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2885 = bitcast <16 x i8> %2884 to <4 x i32>
  %2886 = shufflevector <16 x i8> %2881, <16 x i8> %2880, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2887 = bitcast <16 x i8> %2886 to <4 x i32>
  %2888 = add <4 x i32> %2860, %2859
  %2889 = add <4 x i32> %2888, %2883
  %2890 = add <4 x i32> %2889, %2885
  %2891 = add <4 x i32> %2890, %2887
  %2892 = bitcast <4 x i32> %2864 to <16 x i8>
  %2893 = shufflevector <16 x i8> %2880, <16 x i8> %2892, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2894 = bitcast <16 x i8> %2893 to <4 x i32>
  %2895 = shufflevector <16 x i8> %2880, <16 x i8> %2892, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %2896 = bitcast <16 x i8> %2895 to <4 x i32>
  %2897 = shufflevector <16 x i8> %2880, <16 x i8> %2892, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %2898 = bitcast <16 x i8> %2897 to <4 x i32>
  %2899 = add <4 x i32> %2864, %2860
  %2900 = add <4 x i32> %2899, %2894
  %2901 = add <4 x i32> %2900, %2896
  %2902 = add <4 x i32> %2901, %2898
  %2903 = load <8 x i16>, <8 x i16>* %2843, align 16
  %2904 = load <8 x i16>, <8 x i16>* %2844, align 16
  %2905 = load <8 x i16>, <8 x i16>* %2845, align 16
  %2906 = inttoptr i64 %2838 to <4 x i32>*
  %2907 = load <4 x i32>, <4 x i32>* %2906, align 16
  %2908 = getelementptr inbounds i32, i32* %2846, i64 4
  %2909 = bitcast i32* %2908 to <4 x i32>*
  %2910 = load <4 x i32>, <4 x i32>* %2909, align 16
  %2911 = inttoptr i64 %2837 to <4 x i32>*
  %2912 = load <4 x i32>, <4 x i32>* %2911, align 16
  %2913 = getelementptr inbounds i32, i32* %2847, i64 4
  %2914 = bitcast i32* %2913 to <4 x i32>*
  %2915 = load <4 x i32>, <4 x i32>* %2914, align 16
  %2916 = inttoptr i64 %2836 to <4 x i32>*
  %2917 = load <4 x i32>, <4 x i32>* %2916, align 16
  %2918 = getelementptr inbounds i32, i32* %2848, i64 4
  %2919 = bitcast i32* %2918 to <4 x i32>*
  %2920 = load <4 x i32>, <4 x i32>* %2919, align 16
  %2921 = shl <8 x i16> %2879, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %2922 = add <8 x i16> %2904, %2903
  %2923 = add <8 x i16> %2922, %2905
  %2924 = add <8 x i16> %2923, %2921
  %2925 = add <8 x i16> %2924, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %2926 = lshr <8 x i16> %2925, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %2927 = shufflevector <8 x i16> %2926, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2928 = shufflevector <8 x i16> %2926, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2929 = shl <4 x i32> %2891, <i32 1, i32 1, i32 1, i32 1>
  %2930 = add <4 x i32> %2907, <i32 8, i32 8, i32 8, i32 8>
  %2931 = add <4 x i32> %2930, %2929
  %2932 = add <4 x i32> %2931, %2912
  %2933 = add <4 x i32> %2932, %2917
  %2934 = lshr <4 x i32> %2933, <i32 4, i32 4, i32 4, i32 4>
  %2935 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2927, <8 x i16> %2927) #5
  %2936 = mul <4 x i32> %2934, <i32 25, i32 25, i32 25, i32 25>
  %2937 = sub <4 x i32> %2936, %2935
  %2938 = icmp sgt <4 x i32> %2937, zeroinitializer
  %2939 = select <4 x i1> %2938, <4 x i32> %2937, <4 x i32> zeroinitializer
  %2940 = mul <4 x i32> %2939, %340
  %2941 = add <4 x i32> %2940, <i32 524288, i32 524288, i32 524288, i32 524288>
  %2942 = lshr <4 x i32> %2941, <i32 20, i32 20, i32 20, i32 20>
  %2943 = shl <4 x i32> %2902, <i32 1, i32 1, i32 1, i32 1>
  %2944 = add <4 x i32> %2910, <i32 8, i32 8, i32 8, i32 8>
  %2945 = add <4 x i32> %2944, %2943
  %2946 = add <4 x i32> %2945, %2915
  %2947 = add <4 x i32> %2946, %2920
  %2948 = lshr <4 x i32> %2947, <i32 4, i32 4, i32 4, i32 4>
  %2949 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2928, <8 x i16> %2928) #5
  %2950 = mul <4 x i32> %2948, <i32 25, i32 25, i32 25, i32 25>
  %2951 = sub <4 x i32> %2950, %2949
  %2952 = icmp sgt <4 x i32> %2951, zeroinitializer
  %2953 = select <4 x i1> %2952, <4 x i32> %2951, <4 x i32> zeroinitializer
  %2954 = mul <4 x i32> %2953, %340
  %2955 = add <4 x i32> %2954, <i32 524288, i32 524288, i32 524288, i32 524288>
  %2956 = lshr <4 x i32> %2955, <i32 20, i32 20, i32 20, i32 20>
  %2957 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2942, <4 x i32> %2956) #5
  %2958 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2957, <8 x i16> undef) #5
  %2959 = bitcast <16 x i8> %2958 to <2 x i64>
  %2960 = extractelement <2 x i64> %2959, i32 0
  %2961 = lshr i64 %2960, 8
  %2962 = lshr i64 %2960, 16
  %2963 = lshr i64 %2960, 24
  %2964 = lshr i64 %2960, 32
  %2965 = lshr i64 %2960, 40
  %2966 = lshr i64 %2960, 48
  %2967 = lshr i64 %2960, 56
  %2968 = and i64 %2960, 255
  %2969 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2968
  %2970 = load i8, i8* %2969, align 1
  %2971 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %2970, i64 0
  %2972 = and i64 %2961, 255
  %2973 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2972
  %2974 = load i8, i8* %2973, align 1
  %2975 = insertelement <16 x i8> %2971, i8 %2974, i64 1
  %2976 = and i64 %2962, 255
  %2977 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2976
  %2978 = load i8, i8* %2977, align 1
  %2979 = insertelement <16 x i8> %2975, i8 %2978, i64 2
  %2980 = and i64 %2963, 255
  %2981 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2980
  %2982 = load i8, i8* %2981, align 1
  %2983 = insertelement <16 x i8> %2979, i8 %2982, i64 3
  %2984 = and i64 %2964, 255
  %2985 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2984
  %2986 = load i8, i8* %2985, align 1
  %2987 = insertelement <16 x i8> %2983, i8 %2986, i64 4
  %2988 = and i64 %2965, 255
  %2989 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2988
  %2990 = load i8, i8* %2989, align 1
  %2991 = insertelement <16 x i8> %2987, i8 %2990, i64 5
  %2992 = and i64 %2966, 255
  %2993 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2992
  %2994 = load i8, i8* %2993, align 1
  %2995 = insertelement <16 x i8> %2991, i8 %2994, i64 6
  %2996 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %2967
  %2997 = load i8, i8* %2996, align 1
  %2998 = insertelement <16 x i8> %2995, i8 %2997, i64 7
  %2999 = shufflevector <16 x i8> %2998, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3000 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2999, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %3001 = shufflevector <8 x i16> %3000, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3002 = shufflevector <8 x i16> %2924, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3003 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3001, <8 x i16> %3002) #5
  %3004 = shufflevector <8 x i16> %3000, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3005 = shufflevector <8 x i16> %2924, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3006 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3004, <8 x i16> %3005) #5
  %3007 = add <4 x i32> %3003, <i32 512, i32 512, i32 512, i32 512>
  %3008 = lshr <4 x i32> %3007, <i32 10, i32 10, i32 10, i32 10>
  %3009 = inttoptr i64 %2835 to i16*
  %3010 = inttoptr i64 %2834 to i16*
  %3011 = inttoptr i64 %2833 to i16*
  br label %3012

3012:                                             ; preds = %3012, %2832
  %3013 = phi i64 [ %3027, %3012 ], [ 0, %2832 ]
  %3014 = phi <2 x i64> [ %3032, %3012 ], [ %2856, %2832 ]
  %3015 = phi <16 x i8> [ %3339, %3012 ], [ <i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, %2832 ]
  %3016 = phi <16 x i8> [ %3339, %3012 ], [ %2998, %2832 ]
  %3017 = phi <4 x i32> [ %3211, %3012 ], [ %2865, %2832 ]
  %3018 = phi <4 x i32> [ %3210, %3012 ], [ %2864, %2832 ]
  %3019 = phi <4 x i32> [ %3347, %3012 ], [ %3006, %2832 ]
  %3020 = phi <4 x i32> [ %3349, %3012 ], [ %3008, %2832 ]
  %3021 = phi i32* [ %3495, %3012 ], [ %2851, %2832 ]
  %3022 = phi i16* [ %3494, %3012 ], [ %2850, %2832 ]
  %3023 = add <4 x i32> %3019, <i32 512, i32 512, i32 512, i32 512>
  %3024 = lshr <4 x i32> %3023, <i32 10, i32 10, i32 10, i32 10>
  %3025 = getelementptr inbounds i16, i16* %2849, i64 %3013
  %3026 = getelementptr inbounds i16, i16* %3025, i64 16
  %3027 = add nuw nsw i64 %3013, 16
  %3028 = bitcast i16* %3026 to <2 x i64>*
  %3029 = load <2 x i64>, <2 x i64>* %3028, align 1
  %3030 = getelementptr inbounds i16, i16* %3025, i64 24
  %3031 = bitcast i16* %3030 to <2 x i64>*
  %3032 = load <2 x i64>, <2 x i64>* %3031, align 1
  %3033 = or i64 %3013, 8
  %3034 = bitcast <2 x i64> %3029 to <8 x i16>
  %3035 = shufflevector <8 x i16> %3034, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3036 = shufflevector <8 x i16> %3034, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3037 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3035, <8 x i16> %3035) #5
  %3038 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3036, <8 x i16> %3036) #5
  %3039 = bitcast <2 x i64> %3014 to <8 x i16>
  %3040 = bitcast <2 x i64> %3029 to <16 x i8>
  %3041 = bitcast <2 x i64> %3014 to <16 x i8>
  %3042 = shufflevector <16 x i8> %3041, <16 x i8> %3040, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3043 = bitcast <16 x i8> %3042 to <8 x i16>
  %3044 = shufflevector <16 x i8> %3041, <16 x i8> %3040, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3045 = bitcast <16 x i8> %3044 to <8 x i16>
  %3046 = shufflevector <16 x i8> %3041, <16 x i8> %3040, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %3047 = bitcast <16 x i8> %3046 to <8 x i16>
  %3048 = shufflevector <16 x i8> %3041, <16 x i8> %3040, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3049 = bitcast <16 x i8> %3048 to <8 x i16>
  %3050 = add <8 x i16> %3043, %3039
  %3051 = add <8 x i16> %3050, %3045
  %3052 = add <8 x i16> %3051, %3047
  %3053 = add <8 x i16> %3052, %3049
  %3054 = bitcast <2 x i64> %3032 to <16 x i8>
  %3055 = shufflevector <16 x i8> %3040, <16 x i8> %3054, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3056 = bitcast <16 x i8> %3055 to <8 x i16>
  %3057 = shufflevector <16 x i8> %3040, <16 x i8> %3054, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3058 = bitcast <16 x i8> %3057 to <8 x i16>
  %3059 = shufflevector <16 x i8> %3040, <16 x i8> %3054, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %3060 = bitcast <16 x i8> %3059 to <8 x i16>
  %3061 = shufflevector <16 x i8> %3040, <16 x i8> %3054, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3062 = bitcast <16 x i8> %3061 to <8 x i16>
  %3063 = add <8 x i16> %3056, %3034
  %3064 = add <8 x i16> %3063, %3058
  %3065 = add <8 x i16> %3064, %3060
  %3066 = add <8 x i16> %3065, %3062
  %3067 = bitcast <4 x i32> %3017 to <16 x i8>
  %3068 = bitcast <4 x i32> %3018 to <16 x i8>
  %3069 = shufflevector <16 x i8> %3068, <16 x i8> %3067, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3070 = bitcast <16 x i8> %3069 to <4 x i32>
  %3071 = shufflevector <16 x i8> %3068, <16 x i8> %3067, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3072 = bitcast <16 x i8> %3071 to <4 x i32>
  %3073 = shufflevector <16 x i8> %3068, <16 x i8> %3067, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %3074 = bitcast <16 x i8> %3073 to <4 x i32>
  %3075 = add <4 x i32> %3018, %3017
  %3076 = add <4 x i32> %3075, %3070
  %3077 = add <4 x i32> %3076, %3072
  %3078 = add <4 x i32> %3077, %3074
  %3079 = bitcast <4 x i32> %3037 to <16 x i8>
  %3080 = shufflevector <16 x i8> %3067, <16 x i8> %3079, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3081 = bitcast <16 x i8> %3080 to <4 x i32>
  %3082 = shufflevector <16 x i8> %3067, <16 x i8> %3079, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3083 = bitcast <16 x i8> %3082 to <4 x i32>
  %3084 = shufflevector <16 x i8> %3067, <16 x i8> %3079, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %3085 = bitcast <16 x i8> %3084 to <4 x i32>
  %3086 = add <4 x i32> %3037, %3017
  %3087 = add <4 x i32> %3086, %3081
  %3088 = add <4 x i32> %3087, %3083
  %3089 = add <4 x i32> %3088, %3085
  %3090 = getelementptr inbounds i16, i16* %3009, i64 %3033
  %3091 = bitcast i16* %3090 to <8 x i16>*
  %3092 = load <8 x i16>, <8 x i16>* %3091, align 16
  %3093 = getelementptr inbounds i16, i16* %3010, i64 %3033
  %3094 = bitcast i16* %3093 to <8 x i16>*
  %3095 = load <8 x i16>, <8 x i16>* %3094, align 16
  %3096 = getelementptr inbounds i16, i16* %3011, i64 %3033
  %3097 = bitcast i16* %3096 to <8 x i16>*
  %3098 = load <8 x i16>, <8 x i16>* %3097, align 16
  %3099 = getelementptr inbounds i32, i32* %2846, i64 %3033
  %3100 = bitcast i32* %3099 to <4 x i32>*
  %3101 = load <4 x i32>, <4 x i32>* %3100, align 16
  %3102 = getelementptr inbounds i32, i32* %3099, i64 4
  %3103 = bitcast i32* %3102 to <4 x i32>*
  %3104 = load <4 x i32>, <4 x i32>* %3103, align 16
  %3105 = getelementptr inbounds i32, i32* %2847, i64 %3033
  %3106 = bitcast i32* %3105 to <4 x i32>*
  %3107 = load <4 x i32>, <4 x i32>* %3106, align 16
  %3108 = getelementptr inbounds i32, i32* %3105, i64 4
  %3109 = bitcast i32* %3108 to <4 x i32>*
  %3110 = load <4 x i32>, <4 x i32>* %3109, align 16
  %3111 = getelementptr inbounds i32, i32* %2848, i64 %3033
  %3112 = bitcast i32* %3111 to <4 x i32>*
  %3113 = load <4 x i32>, <4 x i32>* %3112, align 16
  %3114 = getelementptr inbounds i32, i32* %3111, i64 4
  %3115 = bitcast i32* %3114 to <4 x i32>*
  %3116 = load <4 x i32>, <4 x i32>* %3115, align 16
  %3117 = shl <8 x i16> %3053, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %3118 = add <8 x i16> %3095, %3092
  %3119 = add <8 x i16> %3118, %3098
  %3120 = add <8 x i16> %3119, %3117
  %3121 = add <8 x i16> %3120, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3122 = lshr <8 x i16> %3121, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3123 = shufflevector <8 x i16> %3122, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3124 = shufflevector <8 x i16> %3122, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3125 = shl <4 x i32> %3078, <i32 1, i32 1, i32 1, i32 1>
  %3126 = add <4 x i32> %3125, <i32 8, i32 8, i32 8, i32 8>
  %3127 = add <4 x i32> %3126, %3101
  %3128 = add <4 x i32> %3127, %3107
  %3129 = add <4 x i32> %3128, %3113
  %3130 = lshr <4 x i32> %3129, <i32 4, i32 4, i32 4, i32 4>
  %3131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3123, <8 x i16> %3123) #5
  %3132 = mul <4 x i32> %3130, <i32 25, i32 25, i32 25, i32 25>
  %3133 = sub <4 x i32> %3132, %3131
  %3134 = icmp sgt <4 x i32> %3133, zeroinitializer
  %3135 = select <4 x i1> %3134, <4 x i32> %3133, <4 x i32> zeroinitializer
  %3136 = mul <4 x i32> %3135, %340
  %3137 = add <4 x i32> %3136, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3138 = lshr <4 x i32> %3137, <i32 20, i32 20, i32 20, i32 20>
  %3139 = shl <4 x i32> %3089, <i32 1, i32 1, i32 1, i32 1>
  %3140 = add <4 x i32> %3104, <i32 8, i32 8, i32 8, i32 8>
  %3141 = add <4 x i32> %3140, %3139
  %3142 = add <4 x i32> %3141, %3110
  %3143 = add <4 x i32> %3142, %3116
  %3144 = lshr <4 x i32> %3143, <i32 4, i32 4, i32 4, i32 4>
  %3145 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3124, <8 x i16> %3124) #5
  %3146 = mul <4 x i32> %3144, <i32 25, i32 25, i32 25, i32 25>
  %3147 = sub <4 x i32> %3146, %3145
  %3148 = icmp sgt <4 x i32> %3147, zeroinitializer
  %3149 = select <4 x i1> %3148, <4 x i32> %3147, <4 x i32> zeroinitializer
  %3150 = mul <4 x i32> %3149, %340
  %3151 = add <4 x i32> %3150, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3152 = lshr <4 x i32> %3151, <i32 20, i32 20, i32 20, i32 20>
  %3153 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3138, <4 x i32> %3152) #5
  %3154 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3153, <8 x i16> undef) #5
  %3155 = bitcast <16 x i8> %3154 to <2 x i64>
  %3156 = extractelement <2 x i64> %3155, i32 0
  %3157 = lshr i64 %3156, 8
  %3158 = lshr i64 %3156, 16
  %3159 = lshr i64 %3156, 24
  %3160 = lshr i64 %3156, 32
  %3161 = lshr i64 %3156, 40
  %3162 = lshr i64 %3156, 48
  %3163 = lshr i64 %3156, 56
  %3164 = and i64 %3156, 255
  %3165 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3164
  %3166 = load i8, i8* %3165, align 1
  %3167 = insertelement <16 x i8> %3016, i8 %3166, i64 8
  %3168 = and i64 %3157, 255
  %3169 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3168
  %3170 = load i8, i8* %3169, align 1
  %3171 = insertelement <16 x i8> %3167, i8 %3170, i64 9
  %3172 = and i64 %3158, 255
  %3173 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3172
  %3174 = load i8, i8* %3173, align 1
  %3175 = insertelement <16 x i8> %3171, i8 %3174, i64 10
  %3176 = and i64 %3159, 255
  %3177 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3176
  %3178 = load i8, i8* %3177, align 1
  %3179 = insertelement <16 x i8> %3175, i8 %3178, i64 11
  %3180 = and i64 %3160, 255
  %3181 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3180
  %3182 = load i8, i8* %3181, align 1
  %3183 = insertelement <16 x i8> %3179, i8 %3182, i64 12
  %3184 = and i64 %3161, 255
  %3185 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3184
  %3186 = load i8, i8* %3185, align 1
  %3187 = insertelement <16 x i8> %3183, i8 %3186, i64 13
  %3188 = and i64 %3162, 255
  %3189 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3188
  %3190 = load i8, i8* %3189, align 1
  %3191 = insertelement <16 x i8> %3187, i8 %3190, i64 14
  %3192 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3163
  %3193 = load i8, i8* %3192, align 1
  %3194 = insertelement <16 x i8> %3191, i8 %3193, i64 15
  %3195 = shufflevector <16 x i8> %3194, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %3196 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3195, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %3197 = shufflevector <8 x i16> %3196, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3198 = shufflevector <8 x i16> %3120, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3199 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3197, <8 x i16> %3198) #5
  %3200 = shufflevector <8 x i16> %3196, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3201 = shufflevector <8 x i16> %3120, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3202 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3200, <8 x i16> %3201) #5
  %3203 = add <4 x i32> %3199, <i32 512, i32 512, i32 512, i32 512>
  %3204 = lshr <4 x i32> %3203, <i32 10, i32 10, i32 10, i32 10>
  %3205 = add <4 x i32> %3202, <i32 512, i32 512, i32 512, i32 512>
  %3206 = lshr <4 x i32> %3205, <i32 10, i32 10, i32 10, i32 10>
  %3207 = bitcast <2 x i64> %3032 to <8 x i16>
  %3208 = shufflevector <8 x i16> %3207, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3209 = shufflevector <8 x i16> %3207, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3210 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3208, <8 x i16> %3208) #5
  %3211 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3209, <8 x i16> %3209) #5
  %3212 = bitcast <4 x i32> %3038 to <16 x i8>
  %3213 = shufflevector <16 x i8> %3079, <16 x i8> %3212, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3214 = bitcast <16 x i8> %3213 to <4 x i32>
  %3215 = shufflevector <16 x i8> %3079, <16 x i8> %3212, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3216 = bitcast <16 x i8> %3215 to <4 x i32>
  %3217 = shufflevector <16 x i8> %3079, <16 x i8> %3212, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %3218 = bitcast <16 x i8> %3217 to <4 x i32>
  %3219 = add <4 x i32> %3038, %3037
  %3220 = add <4 x i32> %3219, %3214
  %3221 = add <4 x i32> %3220, %3216
  %3222 = add <4 x i32> %3221, %3218
  %3223 = bitcast <4 x i32> %3210 to <16 x i8>
  %3224 = shufflevector <16 x i8> %3212, <16 x i8> %3223, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3225 = bitcast <16 x i8> %3224 to <4 x i32>
  %3226 = shufflevector <16 x i8> %3212, <16 x i8> %3223, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3227 = bitcast <16 x i8> %3226 to <4 x i32>
  %3228 = shufflevector <16 x i8> %3212, <16 x i8> %3223, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %3229 = bitcast <16 x i8> %3228 to <4 x i32>
  %3230 = add <4 x i32> %3210, %3038
  %3231 = add <4 x i32> %3230, %3225
  %3232 = add <4 x i32> %3231, %3227
  %3233 = add <4 x i32> %3232, %3229
  %3234 = add nuw nsw i64 %3033, 8
  %3235 = getelementptr inbounds i16, i16* %3009, i64 %3234
  %3236 = bitcast i16* %3235 to <8 x i16>*
  %3237 = load <8 x i16>, <8 x i16>* %3236, align 16
  %3238 = getelementptr inbounds i16, i16* %3010, i64 %3234
  %3239 = bitcast i16* %3238 to <8 x i16>*
  %3240 = load <8 x i16>, <8 x i16>* %3239, align 16
  %3241 = getelementptr inbounds i16, i16* %3011, i64 %3234
  %3242 = bitcast i16* %3241 to <8 x i16>*
  %3243 = load <8 x i16>, <8 x i16>* %3242, align 16
  %3244 = getelementptr inbounds i32, i32* %2846, i64 %3234
  %3245 = bitcast i32* %3244 to <4 x i32>*
  %3246 = load <4 x i32>, <4 x i32>* %3245, align 16
  %3247 = getelementptr inbounds i32, i32* %3244, i64 4
  %3248 = bitcast i32* %3247 to <4 x i32>*
  %3249 = load <4 x i32>, <4 x i32>* %3248, align 16
  %3250 = getelementptr inbounds i32, i32* %2847, i64 %3234
  %3251 = bitcast i32* %3250 to <4 x i32>*
  %3252 = load <4 x i32>, <4 x i32>* %3251, align 16
  %3253 = getelementptr inbounds i32, i32* %3250, i64 4
  %3254 = bitcast i32* %3253 to <4 x i32>*
  %3255 = load <4 x i32>, <4 x i32>* %3254, align 16
  %3256 = getelementptr inbounds i32, i32* %2848, i64 %3234
  %3257 = bitcast i32* %3256 to <4 x i32>*
  %3258 = load <4 x i32>, <4 x i32>* %3257, align 16
  %3259 = getelementptr inbounds i32, i32* %3256, i64 4
  %3260 = bitcast i32* %3259 to <4 x i32>*
  %3261 = load <4 x i32>, <4 x i32>* %3260, align 16
  %3262 = shl <8 x i16> %3066, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %3263 = add <8 x i16> %3237, %3262
  %3264 = add <8 x i16> %3263, %3240
  %3265 = add <8 x i16> %3264, %3243
  %3266 = add <8 x i16> %3265, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3267 = lshr <8 x i16> %3266, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3268 = shufflevector <8 x i16> %3267, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3269 = shufflevector <8 x i16> %3267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3270 = shl <4 x i32> %3222, <i32 1, i32 1, i32 1, i32 1>
  %3271 = add <4 x i32> %3270, <i32 8, i32 8, i32 8, i32 8>
  %3272 = add <4 x i32> %3271, %3246
  %3273 = add <4 x i32> %3272, %3252
  %3274 = add <4 x i32> %3273, %3258
  %3275 = lshr <4 x i32> %3274, <i32 4, i32 4, i32 4, i32 4>
  %3276 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3268, <8 x i16> %3268) #5
  %3277 = mul <4 x i32> %3275, <i32 25, i32 25, i32 25, i32 25>
  %3278 = sub <4 x i32> %3277, %3276
  %3279 = icmp sgt <4 x i32> %3278, zeroinitializer
  %3280 = select <4 x i1> %3279, <4 x i32> %3278, <4 x i32> zeroinitializer
  %3281 = mul <4 x i32> %3280, %340
  %3282 = add <4 x i32> %3281, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3283 = lshr <4 x i32> %3282, <i32 20, i32 20, i32 20, i32 20>
  %3284 = shl <4 x i32> %3233, <i32 1, i32 1, i32 1, i32 1>
  %3285 = add <4 x i32> %3249, <i32 8, i32 8, i32 8, i32 8>
  %3286 = add <4 x i32> %3285, %3284
  %3287 = add <4 x i32> %3286, %3255
  %3288 = add <4 x i32> %3287, %3261
  %3289 = lshr <4 x i32> %3288, <i32 4, i32 4, i32 4, i32 4>
  %3290 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3269, <8 x i16> %3269) #5
  %3291 = mul <4 x i32> %3289, <i32 25, i32 25, i32 25, i32 25>
  %3292 = sub <4 x i32> %3291, %3290
  %3293 = icmp sgt <4 x i32> %3292, zeroinitializer
  %3294 = select <4 x i1> %3293, <4 x i32> %3292, <4 x i32> zeroinitializer
  %3295 = mul <4 x i32> %3294, %340
  %3296 = add <4 x i32> %3295, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3297 = lshr <4 x i32> %3296, <i32 20, i32 20, i32 20, i32 20>
  %3298 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3283, <4 x i32> %3297) #5
  %3299 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3298, <8 x i16> undef) #5
  %3300 = bitcast <16 x i8> %3299 to <2 x i64>
  %3301 = extractelement <2 x i64> %3300, i32 0
  %3302 = lshr i64 %3301, 8
  %3303 = lshr i64 %3301, 16
  %3304 = lshr i64 %3301, 24
  %3305 = lshr i64 %3301, 32
  %3306 = lshr i64 %3301, 40
  %3307 = lshr i64 %3301, 48
  %3308 = lshr i64 %3301, 56
  %3309 = and i64 %3301, 255
  %3310 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3309
  %3311 = load i8, i8* %3310, align 1
  %3312 = insertelement <16 x i8> %3015, i8 %3311, i64 0
  %3313 = and i64 %3302, 255
  %3314 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3313
  %3315 = load i8, i8* %3314, align 1
  %3316 = insertelement <16 x i8> %3312, i8 %3315, i64 1
  %3317 = and i64 %3303, 255
  %3318 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3317
  %3319 = load i8, i8* %3318, align 1
  %3320 = insertelement <16 x i8> %3316, i8 %3319, i64 2
  %3321 = and i64 %3304, 255
  %3322 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3321
  %3323 = load i8, i8* %3322, align 1
  %3324 = insertelement <16 x i8> %3320, i8 %3323, i64 3
  %3325 = and i64 %3305, 255
  %3326 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3325
  %3327 = load i8, i8* %3326, align 1
  %3328 = insertelement <16 x i8> %3324, i8 %3327, i64 4
  %3329 = and i64 %3306, 255
  %3330 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3329
  %3331 = load i8, i8* %3330, align 1
  %3332 = insertelement <16 x i8> %3328, i8 %3331, i64 5
  %3333 = and i64 %3307, 255
  %3334 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3333
  %3335 = load i8, i8* %3334, align 1
  %3336 = insertelement <16 x i8> %3332, i8 %3335, i64 6
  %3337 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3308
  %3338 = load i8, i8* %3337, align 1
  %3339 = insertelement <16 x i8> %3336, i8 %3338, i64 7
  %3340 = shufflevector <16 x i8> %3339, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3341 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3340, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %3342 = shufflevector <8 x i16> %3341, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3343 = shufflevector <8 x i16> %3265, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3344 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3342, <8 x i16> %3343) #5
  %3345 = shufflevector <8 x i16> %3341, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3346 = shufflevector <8 x i16> %3265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3347 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3345, <8 x i16> %3346) #5
  %3348 = add <4 x i32> %3344, <i32 512, i32 512, i32 512, i32 512>
  %3349 = lshr <4 x i32> %3348, <i32 10, i32 10, i32 10, i32 10>
  %3350 = shufflevector <16 x i8> %3194, <16 x i8> %3339, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %3351 = shufflevector <16 x i8> %3194, <16 x i8> %3339, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3352 = shufflevector <16 x i8> %3194, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3353 = shufflevector <16 x i8> %3350, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3354 = bitcast <16 x i8> %3352 to <8 x i16>
  %3355 = bitcast <16 x i8> %3353 to <8 x i16>
  %3356 = add <8 x i16> %3355, %3354
  %3357 = shufflevector <16 x i8> %3351, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3358 = bitcast <16 x i8> %3357 to <8 x i16>
  %3359 = add <8 x i16> %3356, %3358
  %3360 = mul <8 x i16> %3359, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %3361 = bitcast <4 x i32> %3024 to <16 x i8>
  %3362 = bitcast <4 x i32> %3020 to <16 x i8>
  %3363 = shufflevector <16 x i8> %3362, <16 x i8> %3361, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3364 = bitcast <16 x i8> %3363 to <4 x i32>
  %3365 = shufflevector <16 x i8> %3362, <16 x i8> %3361, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3366 = bitcast <16 x i8> %3365 to <4 x i32>
  %3367 = add <4 x i32> %3020, %3364
  %3368 = add <4 x i32> %3367, %3366
  %3369 = mul <4 x i32> %3368, <i32 5, i32 5, i32 5, i32 5>
  %3370 = bitcast <4 x i32> %3204 to <16 x i8>
  %3371 = shufflevector <16 x i8> %3361, <16 x i8> %3370, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3372 = bitcast <16 x i8> %3371 to <4 x i32>
  %3373 = shufflevector <16 x i8> %3361, <16 x i8> %3370, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3374 = bitcast <16 x i8> %3373 to <4 x i32>
  %3375 = add <4 x i32> %3024, %3372
  %3376 = add <4 x i32> %3375, %3374
  %3377 = mul <4 x i32> %3376, <i32 5, i32 5, i32 5, i32 5>
  %3378 = bitcast i16* %3022 to <8 x i16>*
  %3379 = load <8 x i16>, <8 x i16>* %3378, align 16
  %3380 = bitcast i32* %3021 to <4 x i32>*
  %3381 = load <4 x i32>, <4 x i32>* %3380, align 16
  %3382 = getelementptr inbounds i32, i32* %3021, i64 4
  %3383 = bitcast i32* %3382 to <4 x i32>*
  %3384 = load <4 x i32>, <4 x i32>* %3383, align 16
  %3385 = getelementptr inbounds i16, i16* %2842, i64 %3013
  %3386 = bitcast i16* %3385 to <8 x i16>*
  %3387 = load <8 x i16>, <8 x i16>* %3386, align 16
  %3388 = add <8 x i16> %3379, %3355
  %3389 = add <8 x i16> %3388, %3360
  %3390 = shufflevector <8 x i16> %3389, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3391 = shufflevector <8 x i16> %3387, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3392 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3390, <8 x i16> %3391) #5
  %3393 = shufflevector <8 x i16> %3389, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3394 = shufflevector <8 x i16> %3387, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3395 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3393, <8 x i16> %3394) #5
  %3396 = add <4 x i32> %3364, <i32 256, i32 256, i32 256, i32 256>
  %3397 = add <4 x i32> %3396, %3369
  %3398 = add <4 x i32> %3397, %3381
  %3399 = sub <4 x i32> %3398, %3392
  %3400 = ashr <4 x i32> %3399, <i32 9, i32 9, i32 9, i32 9>
  %3401 = add <4 x i32> %3372, <i32 256, i32 256, i32 256, i32 256>
  %3402 = add <4 x i32> %3401, %3377
  %3403 = add <4 x i32> %3402, %3384
  %3404 = sub <4 x i32> %3403, %3395
  %3405 = ashr <4 x i32> %3404, <i32 9, i32 9, i32 9, i32 9>
  %3406 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %3400, <4 x i32> %3405) #5
  %3407 = shufflevector <8 x i16> %3406, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3408 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3407, <8 x i16> %932) #5
  %3409 = shufflevector <8 x i16> %3406, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3410 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3409, <8 x i16> %932) #5
  %3411 = add <4 x i32> %3408, <i32 1024, i32 1024, i32 1024, i32 1024>
  %3412 = ashr <4 x i32> %3411, <i32 11, i32 11, i32 11, i32 11>
  %3413 = add <4 x i32> %3410, <i32 1024, i32 1024, i32 1024, i32 1024>
  %3414 = ashr <4 x i32> %3413, <i32 11, i32 11, i32 11, i32 11>
  %3415 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %3412, <4 x i32> %3414) #5
  %3416 = add <8 x i16> %3415, %3387
  %3417 = shufflevector <16 x i8> %3350, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %3418 = bitcast <16 x i8> %3195 to <8 x i16>
  %3419 = bitcast <16 x i8> %3417 to <8 x i16>
  %3420 = add <8 x i16> %3419, %3418
  %3421 = shufflevector <16 x i8> %3351, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %3422 = bitcast <16 x i8> %3421 to <8 x i16>
  %3423 = add <8 x i16> %3420, %3422
  %3424 = mul <8 x i16> %3423, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %3425 = add <8 x i16> %3424, %3419
  %3426 = bitcast <4 x i32> %3206 to <16 x i8>
  %3427 = shufflevector <16 x i8> %3370, <16 x i8> %3426, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3428 = bitcast <16 x i8> %3427 to <4 x i32>
  %3429 = shufflevector <16 x i8> %3370, <16 x i8> %3426, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3430 = bitcast <16 x i8> %3429 to <4 x i32>
  %3431 = add <4 x i32> %3204, %3428
  %3432 = add <4 x i32> %3431, %3430
  %3433 = mul <4 x i32> %3432, <i32 5, i32 5, i32 5, i32 5>
  %3434 = bitcast <4 x i32> %3349 to <16 x i8>
  %3435 = shufflevector <16 x i8> %3426, <16 x i8> %3434, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3436 = bitcast <16 x i8> %3435 to <4 x i32>
  %3437 = shufflevector <16 x i8> %3426, <16 x i8> %3434, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3438 = bitcast <16 x i8> %3437 to <4 x i32>
  %3439 = add <4 x i32> %3206, %3436
  %3440 = add <4 x i32> %3439, %3438
  %3441 = mul <4 x i32> %3440, <i32 5, i32 5, i32 5, i32 5>
  %3442 = getelementptr inbounds i16, i16* %3022, i64 8
  %3443 = bitcast i16* %3442 to <8 x i16>*
  %3444 = load <8 x i16>, <8 x i16>* %3443, align 16
  %3445 = getelementptr inbounds i32, i32* %3021, i64 8
  %3446 = bitcast i32* %3445 to <4 x i32>*
  %3447 = load <4 x i32>, <4 x i32>* %3446, align 16
  %3448 = getelementptr inbounds i32, i32* %3021, i64 12
  %3449 = bitcast i32* %3448 to <4 x i32>*
  %3450 = load <4 x i32>, <4 x i32>* %3449, align 16
  %3451 = getelementptr inbounds i16, i16* %3385, i64 8
  %3452 = bitcast i16* %3451 to <8 x i16>*
  %3453 = load <8 x i16>, <8 x i16>* %3452, align 16
  %3454 = add <8 x i16> %3425, %3444
  %3455 = shufflevector <8 x i16> %3454, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3456 = shufflevector <8 x i16> %3453, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3457 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3455, <8 x i16> %3456) #5
  %3458 = shufflevector <8 x i16> %3454, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3459 = shufflevector <8 x i16> %3453, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3460 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3458, <8 x i16> %3459) #5
  %3461 = add <4 x i32> %3428, <i32 256, i32 256, i32 256, i32 256>
  %3462 = add <4 x i32> %3461, %3433
  %3463 = add <4 x i32> %3462, %3447
  %3464 = sub <4 x i32> %3463, %3457
  %3465 = ashr <4 x i32> %3464, <i32 9, i32 9, i32 9, i32 9>
  %3466 = add <4 x i32> %3436, <i32 256, i32 256, i32 256, i32 256>
  %3467 = add <4 x i32> %3466, %3441
  %3468 = add <4 x i32> %3467, %3450
  %3469 = sub <4 x i32> %3468, %3460
  %3470 = ashr <4 x i32> %3469, <i32 9, i32 9, i32 9, i32 9>
  %3471 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %3465, <4 x i32> %3470) #5
  %3472 = shufflevector <8 x i16> %3471, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3473 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3472, <8 x i16> %932) #5
  %3474 = shufflevector <8 x i16> %3471, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3475 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3474, <8 x i16> %932) #5
  %3476 = add <4 x i32> %3473, <i32 1024, i32 1024, i32 1024, i32 1024>
  %3477 = ashr <4 x i32> %3476, <i32 11, i32 11, i32 11, i32 11>
  %3478 = add <4 x i32> %3475, <i32 1024, i32 1024, i32 1024, i32 1024>
  %3479 = ashr <4 x i32> %3478, <i32 11, i32 11, i32 11, i32 11>
  %3480 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %3477, <4 x i32> %3479) #5
  %3481 = add <8 x i16> %3480, %3453
  %3482 = getelementptr inbounds i16, i16* %2841, i64 %3013
  %3483 = icmp sgt <8 x i16> %3416, zeroinitializer
  %3484 = select <8 x i1> %3483, <8 x i16> %3416, <8 x i16> zeroinitializer
  %3485 = icmp slt <8 x i16> %3484, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %3486 = select <8 x i1> %3485, <8 x i16> %3484, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %3487 = bitcast i16* %3482 to <8 x i16>*
  store <8 x i16> %3486, <8 x i16>* %3487, align 16
  %3488 = getelementptr inbounds i16, i16* %3482, i64 8
  %3489 = icmp sgt <8 x i16> %3481, zeroinitializer
  %3490 = select <8 x i1> %3489, <8 x i16> %3481, <8 x i16> zeroinitializer
  %3491 = icmp slt <8 x i16> %3490, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %3492 = select <8 x i1> %3491, <8 x i16> %3490, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %3493 = bitcast i16* %3488 to <8 x i16>*
  store <8 x i16> %3492, <8 x i16>* %3493, align 16
  %3494 = getelementptr inbounds i16, i16* %3022, i64 16
  %3495 = getelementptr inbounds i32, i32* %3021, i64 16
  %3496 = icmp slt i64 %3027, %24
  br i1 %3496, label %3012, label %12087

3497:                                             ; preds = %11
  %3498 = getelementptr inbounds [16 x [4 x i8]], [16 x [4 x i8]]* @_ZN7libgav114kSgrProjParamsE, i64 0, i64 %14, i64 0
  %3499 = load i8, i8* %3498, align 4
  %3500 = icmp eq i8 %3499, 0
  br i1 %3500, label %3501, label %5913

3501:                                             ; preds = %3497
  %3502 = getelementptr inbounds i8, i8* %1, i64 -4
  %3503 = getelementptr inbounds i8, i8* %3, i64 -4
  %3504 = bitcast i8* %3503 to i16*
  %3505 = getelementptr inbounds i8, i8* %5, i64 -4
  %3506 = sext i32 %7 to i64
  %3507 = add nsw i64 %3506, 15
  %3508 = and i64 %3507, -16
  %3509 = add nsw i64 %3506, 23
  %3510 = add nsw i64 %3508, 16
  %3511 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 1, i32 1, i64 1
  %3512 = load i32, i32* %3511, align 4
  %3513 = trunc i32 %3512 to i16
  %3514 = getelementptr inbounds [16 x [2 x i16]], [16 x [2 x i16]]* @_ZN7libgav118kSgrScaleParameterE, i64 0, i64 %14, i64 1
  %3515 = load i16, i16* %3514, align 2
  %3516 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 0
  %3517 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 0
  %3518 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 4, i64 0
  %3519 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 7, i64 0
  %3520 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %3510
  %3521 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 %3510
  %3522 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 4, i64 %3508
  %3523 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 7, i64 %3508
  %3524 = getelementptr inbounds i16, i16* %3520, i64 %3510
  %3525 = getelementptr inbounds i32, i32* %3521, i64 %3510
  %3526 = getelementptr inbounds i16, i16* %3522, i64 %3508
  %3527 = getelementptr inbounds i32, i32* %3523, i64 %3508
  %3528 = and i64 %3509, -16
  %3529 = sub i16 128, %3513
  %3530 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 5, i64 0
  %3531 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 8, i64 0
  %3532 = sub nsw i64 %4, %3528
  %3533 = sub nsw i64 %3510, %3528
  br label %3534

3534:                                             ; preds = %3629, %3501
  %3535 = phi i16* [ %3504, %3501 ], [ %3630, %3629 ]
  %3536 = phi i16* [ %3516, %3501 ], [ %3631, %3629 ]
  %3537 = phi i32* [ %3517, %3501 ], [ %3632, %3629 ]
  %3538 = phi i32 [ 2, %3501 ], [ %3633, %3629 ]
  %3539 = bitcast i16* %3535 to <2 x i64>*
  %3540 = load <2 x i64>, <2 x i64>* %3539, align 1
  %3541 = bitcast <2 x i64> %3540 to <8 x i16>
  %3542 = shufflevector <8 x i16> %3541, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3543 = shufflevector <8 x i16> %3541, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3544 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3542, <8 x i16> %3542) #5
  %3545 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3543, <8 x i16> %3543) #5
  br label %3546

3546:                                             ; preds = %3546, %3534
  %3547 = phi <2 x i64> [ %3540, %3534 ], [ %3560, %3546 ]
  %3548 = phi <4 x i32> [ %3545, %3534 ], [ %3570, %3546 ]
  %3549 = phi <4 x i32> [ %3544, %3534 ], [ %3569, %3546 ]
  %3550 = phi i16* [ %3535, %3534 ], [ %3558, %3546 ]
  %3551 = phi i16* [ %3536, %3534 ], [ %3626, %3546 ]
  %3552 = phi i32* [ %3537, %3534 ], [ %3627, %3546 ]
  %3553 = phi i64 [ %3528, %3534 ], [ %3557, %3546 ]
  %3554 = getelementptr inbounds i16, i16* %3550, i64 8
  %3555 = bitcast i16* %3554 to <2 x i64>*
  %3556 = load <2 x i64>, <2 x i64>* %3555, align 1
  %3557 = add nsw i64 %3553, -16
  %3558 = getelementptr inbounds i16, i16* %3550, i64 16
  %3559 = bitcast i16* %3558 to <2 x i64>*
  %3560 = load <2 x i64>, <2 x i64>* %3559, align 1
  %3561 = bitcast <2 x i64> %3556 to <8 x i16>
  %3562 = shufflevector <8 x i16> %3561, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3563 = shufflevector <8 x i16> %3561, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3564 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3562, <8 x i16> %3562) #5
  %3565 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3563, <8 x i16> %3563) #5
  %3566 = bitcast <2 x i64> %3560 to <8 x i16>
  %3567 = shufflevector <8 x i16> %3566, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3568 = shufflevector <8 x i16> %3566, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3569 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3567, <8 x i16> %3567) #5
  %3570 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3568, <8 x i16> %3568) #5
  %3571 = bitcast <2 x i64> %3547 to <8 x i16>
  %3572 = bitcast <2 x i64> %3556 to <16 x i8>
  %3573 = bitcast <2 x i64> %3547 to <16 x i8>
  %3574 = shufflevector <16 x i8> %3573, <16 x i8> %3572, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3575 = bitcast <16 x i8> %3574 to <8 x i16>
  %3576 = shufflevector <16 x i8> %3573, <16 x i8> %3572, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3577 = bitcast <16 x i8> %3576 to <8 x i16>
  %3578 = add <8 x i16> %3575, %3571
  %3579 = add <8 x i16> %3578, %3577
  %3580 = bitcast <2 x i64> %3560 to <16 x i8>
  %3581 = shufflevector <16 x i8> %3572, <16 x i8> %3580, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3582 = bitcast <16 x i8> %3581 to <8 x i16>
  %3583 = shufflevector <16 x i8> %3572, <16 x i8> %3580, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3584 = bitcast <16 x i8> %3583 to <8 x i16>
  %3585 = add <8 x i16> %3582, %3561
  %3586 = add <8 x i16> %3585, %3584
  %3587 = bitcast <4 x i32> %3548 to <16 x i8>
  %3588 = bitcast <4 x i32> %3549 to <16 x i8>
  %3589 = shufflevector <16 x i8> %3588, <16 x i8> %3587, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3590 = bitcast <16 x i8> %3589 to <4 x i32>
  %3591 = shufflevector <16 x i8> %3588, <16 x i8> %3587, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3592 = bitcast <16 x i8> %3591 to <4 x i32>
  %3593 = add <4 x i32> %3549, %3590
  %3594 = add <4 x i32> %3593, %3592
  %3595 = bitcast <4 x i32> %3564 to <16 x i8>
  %3596 = shufflevector <16 x i8> %3587, <16 x i8> %3595, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3597 = bitcast <16 x i8> %3596 to <4 x i32>
  %3598 = shufflevector <16 x i8> %3587, <16 x i8> %3595, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3599 = bitcast <16 x i8> %3598 to <4 x i32>
  %3600 = add <4 x i32> %3548, %3597
  %3601 = add <4 x i32> %3600, %3599
  %3602 = bitcast <4 x i32> %3565 to <16 x i8>
  %3603 = shufflevector <16 x i8> %3595, <16 x i8> %3602, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3604 = bitcast <16 x i8> %3603 to <4 x i32>
  %3605 = shufflevector <16 x i8> %3595, <16 x i8> %3602, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3606 = bitcast <16 x i8> %3605 to <4 x i32>
  %3607 = add <4 x i32> %3564, %3604
  %3608 = add <4 x i32> %3607, %3606
  %3609 = bitcast <4 x i32> %3569 to <16 x i8>
  %3610 = shufflevector <16 x i8> %3602, <16 x i8> %3609, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3611 = bitcast <16 x i8> %3610 to <4 x i32>
  %3612 = shufflevector <16 x i8> %3602, <16 x i8> %3609, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3613 = bitcast <16 x i8> %3612 to <4 x i32>
  %3614 = add <4 x i32> %3565, %3611
  %3615 = add <4 x i32> %3614, %3613
  %3616 = bitcast i16* %3551 to <8 x i16>*
  store <8 x i16> %3579, <8 x i16>* %3616, align 16
  %3617 = getelementptr inbounds i16, i16* %3551, i64 8
  %3618 = bitcast i16* %3617 to <8 x i16>*
  store <8 x i16> %3586, <8 x i16>* %3618, align 16
  %3619 = bitcast i32* %3552 to <4 x i32>*
  store <4 x i32> %3594, <4 x i32>* %3619, align 16
  %3620 = getelementptr inbounds i32, i32* %3552, i64 4
  %3621 = bitcast i32* %3620 to <4 x i32>*
  store <4 x i32> %3601, <4 x i32>* %3621, align 16
  %3622 = getelementptr inbounds i32, i32* %3552, i64 8
  %3623 = bitcast i32* %3622 to <4 x i32>*
  store <4 x i32> %3608, <4 x i32>* %3623, align 16
  %3624 = getelementptr inbounds i32, i32* %3552, i64 12
  %3625 = bitcast i32* %3624 to <4 x i32>*
  store <4 x i32> %3615, <4 x i32>* %3625, align 16
  %3626 = getelementptr inbounds i16, i16* %3551, i64 16
  %3627 = getelementptr inbounds i32, i32* %3552, i64 16
  %3628 = icmp eq i64 %3557, 0
  br i1 %3628, label %3629, label %3546

3629:                                             ; preds = %3546
  %3630 = getelementptr inbounds i16, i16* %3558, i64 %3532
  %3631 = getelementptr inbounds i16, i16* %3626, i64 %3533
  %3632 = getelementptr inbounds i32, i32* %3627, i64 %3533
  %3633 = add nsw i32 %3538, -1
  %3634 = icmp eq i32 %3633, 0
  br i1 %3634, label %3635, label %3534

3635:                                             ; preds = %3629
  %3636 = bitcast i8* %3502 to i16*
  %3637 = bitcast i8* %3505 to i16*
  %3638 = ptrtoint %"union.libgav1::RestorationBuffer"* %9 to i64
  %3639 = ptrtoint i32* %3517 to i64
  %3640 = ptrtoint i16* %3518 to i64
  %3641 = ptrtoint i32* %3519 to i64
  %3642 = ptrtoint i16* %3520 to i64
  %3643 = ptrtoint i32* %3521 to i64
  %3644 = ptrtoint i16* %3522 to i64
  %3645 = ptrtoint i32* %3523 to i64
  %3646 = ptrtoint i16* %3524 to i64
  %3647 = ptrtoint i32* %3525 to i64
  %3648 = ptrtoint i16* %3526 to i64
  %3649 = ptrtoint i32* %3527 to i64
  %3650 = zext i16 %3515 to i32
  %3651 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 5, i64 %3508
  %3652 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 8, i64 %3508
  %3653 = ptrtoint i16* %3530 to i64
  %3654 = ptrtoint i32* %3531 to i64
  %3655 = bitcast i8* %3502 to <8 x i16>*
  %3656 = load <8 x i16>, <8 x i16>* %3655, align 1
  %3657 = getelementptr inbounds i8, i8* %1, i64 12
  %3658 = bitcast i8* %3657 to <2 x i64>*
  %3659 = load <2 x i64>, <2 x i64>* %3658, align 1
  %3660 = shufflevector <8 x i16> %3656, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3661 = shufflevector <8 x i16> %3656, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3662 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3660, <8 x i16> %3660) #5
  %3663 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3661, <8 x i16> %3661) #5
  %3664 = bitcast <2 x i64> %3659 to <8 x i16>
  %3665 = shufflevector <8 x i16> %3664, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3666 = shufflevector <8 x i16> %3664, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3667 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3665, <8 x i16> %3665) #5
  %3668 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3666, <8 x i16> %3666) #5
  %3669 = bitcast <2 x i64> %3659 to <16 x i8>
  %3670 = bitcast <8 x i16> %3656 to <16 x i8>
  %3671 = shufflevector <16 x i8> %3670, <16 x i8> %3669, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3672 = bitcast <16 x i8> %3671 to <8 x i16>
  %3673 = shufflevector <16 x i8> %3670, <16 x i8> %3669, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3674 = bitcast <16 x i8> %3673 to <8 x i16>
  %3675 = add <8 x i16> %3656, %3672
  %3676 = add <8 x i16> %3675, %3674
  %3677 = bitcast i16* %3524 to <8 x i16>*
  store <8 x i16> %3676, <8 x i16>* %3677, align 16
  %3678 = bitcast <4 x i32> %3663 to <16 x i8>
  %3679 = bitcast <4 x i32> %3662 to <16 x i8>
  %3680 = shufflevector <16 x i8> %3679, <16 x i8> %3678, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3681 = bitcast <16 x i8> %3680 to <4 x i32>
  %3682 = shufflevector <16 x i8> %3679, <16 x i8> %3678, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3683 = bitcast <16 x i8> %3682 to <4 x i32>
  %3684 = add <4 x i32> %3662, %3681
  %3685 = add <4 x i32> %3684, %3683
  %3686 = bitcast <4 x i32> %3667 to <16 x i8>
  %3687 = shufflevector <16 x i8> %3678, <16 x i8> %3686, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3688 = bitcast <16 x i8> %3687 to <4 x i32>
  %3689 = shufflevector <16 x i8> %3678, <16 x i8> %3686, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3690 = bitcast <16 x i8> %3689 to <4 x i32>
  %3691 = add <4 x i32> %3663, %3688
  %3692 = add <4 x i32> %3691, %3690
  %3693 = bitcast i32* %3525 to <4 x i32>*
  store <4 x i32> %3685, <4 x i32>* %3693, align 16
  %3694 = getelementptr inbounds i32, i32* %3525, i64 4
  %3695 = bitcast i32* %3694 to <4 x i32>*
  store <4 x i32> %3692, <4 x i32>* %3695, align 16
  %3696 = bitcast %"union.libgav1::RestorationBuffer"* %9 to <8 x i16>*
  %3697 = load <8 x i16>, <8 x i16>* %3696, align 16
  %3698 = bitcast i16* %3520 to <8 x i16>*
  %3699 = load <8 x i16>, <8 x i16>* %3698, align 16
  %3700 = bitcast i32* %3517 to <4 x i32>*
  %3701 = load <4 x i32>, <4 x i32>* %3700, align 16
  %3702 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 4
  %3703 = bitcast i32* %3702 to <4 x i32>*
  %3704 = load <4 x i32>, <4 x i32>* %3703, align 16
  %3705 = bitcast i32* %3521 to <4 x i32>*
  %3706 = load <4 x i32>, <4 x i32>* %3705, align 16
  %3707 = getelementptr inbounds i32, i32* %3521, i64 4
  %3708 = bitcast i32* %3707 to <4 x i32>*
  %3709 = load <4 x i32>, <4 x i32>* %3708, align 16
  %3710 = add <8 x i16> %3697, %3676
  %3711 = add <8 x i16> %3710, %3699
  %3712 = add <8 x i16> %3711, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3713 = lshr <8 x i16> %3712, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3714 = shufflevector <8 x i16> %3713, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3715 = shufflevector <8 x i16> %3713, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3716 = add <4 x i32> %3685, <i32 8, i32 8, i32 8, i32 8>
  %3717 = add <4 x i32> %3716, %3701
  %3718 = add <4 x i32> %3717, %3706
  %3719 = lshr <4 x i32> %3718, <i32 4, i32 4, i32 4, i32 4>
  %3720 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3714, <8 x i16> %3714) #5
  %3721 = mul nuw <4 x i32> %3719, <i32 9, i32 9, i32 9, i32 9>
  %3722 = sub <4 x i32> %3721, %3720
  %3723 = icmp sgt <4 x i32> %3722, zeroinitializer
  %3724 = select <4 x i1> %3723, <4 x i32> %3722, <4 x i32> zeroinitializer
  %3725 = insertelement <4 x i32> undef, i32 %3650, i32 0
  %3726 = shufflevector <4 x i32> %3725, <4 x i32> undef, <4 x i32> zeroinitializer
  %3727 = mul <4 x i32> %3724, %3726
  %3728 = add <4 x i32> %3727, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3729 = lshr <4 x i32> %3728, <i32 20, i32 20, i32 20, i32 20>
  %3730 = add <4 x i32> %3692, <i32 8, i32 8, i32 8, i32 8>
  %3731 = add <4 x i32> %3730, %3704
  %3732 = add <4 x i32> %3731, %3709
  %3733 = lshr <4 x i32> %3732, <i32 4, i32 4, i32 4, i32 4>
  %3734 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3715, <8 x i16> %3715) #5
  %3735 = mul nuw <4 x i32> %3733, <i32 9, i32 9, i32 9, i32 9>
  %3736 = sub <4 x i32> %3735, %3734
  %3737 = icmp sgt <4 x i32> %3736, zeroinitializer
  %3738 = select <4 x i1> %3737, <4 x i32> %3736, <4 x i32> zeroinitializer
  %3739 = mul <4 x i32> %3738, %3726
  %3740 = add <4 x i32> %3739, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3741 = lshr <4 x i32> %3740, <i32 20, i32 20, i32 20, i32 20>
  %3742 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3729, <4 x i32> %3741) #5
  %3743 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3742, <8 x i16> undef) #5
  %3744 = bitcast <16 x i8> %3743 to <2 x i64>
  %3745 = extractelement <2 x i64> %3744, i32 0
  %3746 = lshr i64 %3745, 8
  %3747 = lshr i64 %3745, 16
  %3748 = lshr i64 %3745, 24
  %3749 = lshr i64 %3745, 32
  %3750 = lshr i64 %3745, 40
  %3751 = lshr i64 %3745, 48
  %3752 = lshr i64 %3745, 56
  %3753 = and i64 %3745, 255
  %3754 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3753
  %3755 = load i8, i8* %3754, align 1
  %3756 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %3755, i64 0
  %3757 = and i64 %3746, 255
  %3758 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3757
  %3759 = load i8, i8* %3758, align 1
  %3760 = insertelement <16 x i8> %3756, i8 %3759, i64 1
  %3761 = and i64 %3747, 255
  %3762 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3761
  %3763 = load i8, i8* %3762, align 1
  %3764 = insertelement <16 x i8> %3760, i8 %3763, i64 2
  %3765 = and i64 %3748, 255
  %3766 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3765
  %3767 = load i8, i8* %3766, align 1
  %3768 = insertelement <16 x i8> %3764, i8 %3767, i64 3
  %3769 = and i64 %3749, 255
  %3770 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3769
  %3771 = load i8, i8* %3770, align 1
  %3772 = insertelement <16 x i8> %3768, i8 %3771, i64 4
  %3773 = and i64 %3750, 255
  %3774 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3773
  %3775 = load i8, i8* %3774, align 1
  %3776 = insertelement <16 x i8> %3772, i8 %3775, i64 5
  %3777 = and i64 %3751, 255
  %3778 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3777
  %3779 = load i8, i8* %3778, align 1
  %3780 = insertelement <16 x i8> %3776, i8 %3779, i64 6
  %3781 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %3752
  %3782 = load i8, i8* %3781, align 1
  %3783 = insertelement <16 x i8> %3780, i8 %3782, i64 7
  %3784 = shufflevector <16 x i8> %3783, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3785 = bitcast <16 x i8> %3784 to <8 x i16>
  %3786 = shufflevector <8 x i16> %3785, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3787 = shufflevector <8 x i16> %3711, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3788 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3786, <8 x i16> %3787) #5
  %3789 = shufflevector <8 x i16> %3785, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3790 = shufflevector <8 x i16> %3711, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3791 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3789, <8 x i16> %3790) #5
  %3792 = mul <4 x i32> %3788, <i32 455, i32 455, i32 455, i32 455>
  %3793 = add <4 x i32> %3792, <i32 2048, i32 2048, i32 2048, i32 2048>
  %3794 = lshr <4 x i32> %3793, <i32 12, i32 12, i32 12, i32 12>
  %3795 = load <16 x i8>, <16 x i8>* bitcast ([256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE to <16 x i8>*), align 16
  %3796 = load <16 x i8>, <16 x i8>* bitcast (i8* getelementptr inbounds ([256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 16) to <16 x i8>*), align 16
  %3797 = load <16 x i8>, <16 x i8>* bitcast (i8* getelementptr inbounds ([256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 32) to <16 x i8>*), align 16
  %3798 = getelementptr inbounds i32, i32* %3525, i64 8
  br label %3799

3799:                                             ; preds = %3799, %3635
  %3800 = phi i64 [ %3815, %3799 ], [ 0, %3635 ]
  %3801 = phi <2 x i64> [ %3820, %3799 ], [ %3659, %3635 ]
  %3802 = phi <16 x i8> [ %4049, %3799 ], [ %3783, %3635 ]
  %3803 = phi <4 x i32> [ %3919, %3799 ], [ %3668, %3635 ]
  %3804 = phi <4 x i32> [ %3918, %3799 ], [ %3667, %3635 ]
  %3805 = phi <4 x i32> [ %4044, %3799 ], [ %3791, %3635 ]
  %3806 = phi <4 x i32> [ %4047, %3799 ], [ %3794, %3635 ]
  %3807 = phi i32* [ %4121, %3799 ], [ %3519, %3635 ]
  %3808 = phi i16* [ %4120, %3799 ], [ %3518, %3635 ]
  %3809 = mul <4 x i32> %3805, <i32 455, i32 455, i32 455, i32 455>
  %3810 = add <4 x i32> %3809, <i32 2048, i32 2048, i32 2048, i32 2048>
  %3811 = lshr <4 x i32> %3810, <i32 12, i32 12, i32 12, i32 12>
  %3812 = bitcast <16 x i8> %3802 to <2 x i64>
  %3813 = getelementptr inbounds i16, i16* %3636, i64 %3800
  %3814 = getelementptr inbounds i16, i16* %3813, i64 16
  %3815 = add nuw nsw i64 %3800, 16
  %3816 = bitcast i16* %3814 to <2 x i64>*
  %3817 = load <2 x i64>, <2 x i64>* %3816, align 1
  %3818 = getelementptr inbounds i16, i16* %3813, i64 24
  %3819 = bitcast i16* %3818 to <2 x i64>*
  %3820 = load <2 x i64>, <2 x i64>* %3819, align 1
  %3821 = or i64 %3800, 8
  %3822 = bitcast <2 x i64> %3817 to <8 x i16>
  %3823 = shufflevector <8 x i16> %3822, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3824 = shufflevector <8 x i16> %3822, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3825 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3823, <8 x i16> %3823) #5
  %3826 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3824, <8 x i16> %3824) #5
  %3827 = bitcast <2 x i64> %3801 to <8 x i16>
  %3828 = bitcast <2 x i64> %3817 to <16 x i8>
  %3829 = bitcast <2 x i64> %3801 to <16 x i8>
  %3830 = shufflevector <16 x i8> %3829, <16 x i8> %3828, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3831 = bitcast <16 x i8> %3830 to <8 x i16>
  %3832 = shufflevector <16 x i8> %3829, <16 x i8> %3828, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3833 = bitcast <16 x i8> %3832 to <8 x i16>
  %3834 = add <8 x i16> %3831, %3827
  %3835 = add <8 x i16> %3834, %3833
  %3836 = bitcast <2 x i64> %3820 to <16 x i8>
  %3837 = shufflevector <16 x i8> %3828, <16 x i8> %3836, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3838 = bitcast <16 x i8> %3837 to <8 x i16>
  %3839 = shufflevector <16 x i8> %3828, <16 x i8> %3836, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3840 = bitcast <16 x i8> %3839 to <8 x i16>
  %3841 = add <8 x i16> %3838, %3822
  %3842 = add <8 x i16> %3841, %3840
  %3843 = getelementptr inbounds i16, i16* %3524, i64 %3821
  %3844 = bitcast i16* %3843 to <8 x i16>*
  store <8 x i16> %3835, <8 x i16>* %3844, align 16
  %3845 = getelementptr inbounds i16, i16* %3843, i64 8
  %3846 = bitcast i16* %3845 to <8 x i16>*
  store <8 x i16> %3842, <8 x i16>* %3846, align 16
  %3847 = bitcast <4 x i32> %3803 to <16 x i8>
  %3848 = bitcast <4 x i32> %3804 to <16 x i8>
  %3849 = shufflevector <16 x i8> %3848, <16 x i8> %3847, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3850 = bitcast <16 x i8> %3849 to <4 x i32>
  %3851 = shufflevector <16 x i8> %3848, <16 x i8> %3847, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3852 = bitcast <16 x i8> %3851 to <4 x i32>
  %3853 = add <4 x i32> %3804, %3850
  %3854 = add <4 x i32> %3853, %3852
  %3855 = bitcast <4 x i32> %3825 to <16 x i8>
  %3856 = shufflevector <16 x i8> %3847, <16 x i8> %3855, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3857 = bitcast <16 x i8> %3856 to <4 x i32>
  %3858 = shufflevector <16 x i8> %3847, <16 x i8> %3855, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3859 = bitcast <16 x i8> %3858 to <4 x i32>
  %3860 = add <4 x i32> %3803, %3857
  %3861 = add <4 x i32> %3860, %3859
  %3862 = getelementptr inbounds i32, i32* %3525, i64 %3821
  %3863 = bitcast i32* %3862 to <4 x i32>*
  store <4 x i32> %3854, <4 x i32>* %3863, align 16
  %3864 = getelementptr inbounds i32, i32* %3862, i64 4
  %3865 = bitcast i32* %3864 to <4 x i32>*
  store <4 x i32> %3861, <4 x i32>* %3865, align 16
  %3866 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %3821
  %3867 = bitcast i16* %3866 to <8 x i16>*
  %3868 = load <8 x i16>, <8 x i16>* %3867, align 16
  %3869 = getelementptr inbounds i16, i16* %3520, i64 %3821
  %3870 = bitcast i16* %3869 to <8 x i16>*
  %3871 = load <8 x i16>, <8 x i16>* %3870, align 16
  %3872 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 %3821
  %3873 = bitcast i32* %3872 to <4 x i32>*
  %3874 = load <4 x i32>, <4 x i32>* %3873, align 16
  %3875 = getelementptr inbounds i32, i32* %3872, i64 4
  %3876 = bitcast i32* %3875 to <4 x i32>*
  %3877 = load <4 x i32>, <4 x i32>* %3876, align 16
  %3878 = getelementptr inbounds i32, i32* %3521, i64 %3821
  %3879 = bitcast i32* %3878 to <4 x i32>*
  %3880 = load <4 x i32>, <4 x i32>* %3879, align 16
  %3881 = getelementptr inbounds i32, i32* %3878, i64 4
  %3882 = bitcast i32* %3881 to <4 x i32>*
  %3883 = load <4 x i32>, <4 x i32>* %3882, align 16
  %3884 = add <8 x i16> %3868, %3835
  %3885 = add <8 x i16> %3884, %3871
  %3886 = add <8 x i16> %3885, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3887 = lshr <8 x i16> %3886, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3888 = shufflevector <8 x i16> %3887, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3889 = shufflevector <8 x i16> %3887, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3890 = add <4 x i32> %3854, <i32 8, i32 8, i32 8, i32 8>
  %3891 = add <4 x i32> %3890, %3874
  %3892 = add <4 x i32> %3891, %3880
  %3893 = lshr <4 x i32> %3892, <i32 4, i32 4, i32 4, i32 4>
  %3894 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3888, <8 x i16> %3888) #5
  %3895 = mul nuw <4 x i32> %3893, <i32 9, i32 9, i32 9, i32 9>
  %3896 = sub <4 x i32> %3895, %3894
  %3897 = icmp sgt <4 x i32> %3896, zeroinitializer
  %3898 = select <4 x i1> %3897, <4 x i32> %3896, <4 x i32> zeroinitializer
  %3899 = mul <4 x i32> %3898, %3726
  %3900 = add <4 x i32> %3899, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3901 = lshr <4 x i32> %3900, <i32 20, i32 20, i32 20, i32 20>
  %3902 = add <4 x i32> %3861, <i32 8, i32 8, i32 8, i32 8>
  %3903 = add <4 x i32> %3902, %3877
  %3904 = add <4 x i32> %3903, %3883
  %3905 = lshr <4 x i32> %3904, <i32 4, i32 4, i32 4, i32 4>
  %3906 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3889, <8 x i16> %3889) #5
  %3907 = mul nuw <4 x i32> %3905, <i32 9, i32 9, i32 9, i32 9>
  %3908 = sub <4 x i32> %3907, %3906
  %3909 = icmp sgt <4 x i32> %3908, zeroinitializer
  %3910 = select <4 x i1> %3909, <4 x i32> %3908, <4 x i32> zeroinitializer
  %3911 = mul <4 x i32> %3910, %3726
  %3912 = add <4 x i32> %3911, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3913 = lshr <4 x i32> %3912, <i32 20, i32 20, i32 20, i32 20>
  %3914 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3901, <4 x i32> %3913) #5
  %3915 = bitcast <2 x i64> %3820 to <8 x i16>
  %3916 = shufflevector <8 x i16> %3915, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3917 = shufflevector <8 x i16> %3915, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3918 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3916, <8 x i16> %3916) #5
  %3919 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3917, <8 x i16> %3917) #5
  %3920 = bitcast <4 x i32> %3826 to <16 x i8>
  %3921 = shufflevector <16 x i8> %3855, <16 x i8> %3920, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3922 = bitcast <16 x i8> %3921 to <4 x i32>
  %3923 = shufflevector <16 x i8> %3855, <16 x i8> %3920, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3924 = bitcast <16 x i8> %3923 to <4 x i32>
  %3925 = add <4 x i32> %3825, %3922
  %3926 = add <4 x i32> %3925, %3924
  %3927 = bitcast <4 x i32> %3918 to <16 x i8>
  %3928 = shufflevector <16 x i8> %3920, <16 x i8> %3927, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3929 = bitcast <16 x i8> %3928 to <4 x i32>
  %3930 = shufflevector <16 x i8> %3920, <16 x i8> %3927, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %3931 = bitcast <16 x i8> %3930 to <4 x i32>
  %3932 = add <4 x i32> %3826, %3929
  %3933 = add <4 x i32> %3932, %3931
  %3934 = getelementptr inbounds i32, i32* %3798, i64 %3821
  %3935 = bitcast i32* %3934 to <4 x i32>*
  store <4 x i32> %3926, <4 x i32>* %3935, align 16
  %3936 = getelementptr inbounds i32, i32* %3934, i64 4
  %3937 = bitcast i32* %3936 to <4 x i32>*
  store <4 x i32> %3933, <4 x i32>* %3937, align 16
  %3938 = add nuw nsw i64 %3821, 8
  %3939 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %3938
  %3940 = bitcast i16* %3939 to <8 x i16>*
  %3941 = load <8 x i16>, <8 x i16>* %3940, align 16
  %3942 = getelementptr inbounds i16, i16* %3520, i64 %3938
  %3943 = bitcast i16* %3942 to <8 x i16>*
  %3944 = load <8 x i16>, <8 x i16>* %3943, align 16
  %3945 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 %3938
  %3946 = bitcast i32* %3945 to <4 x i32>*
  %3947 = load <4 x i32>, <4 x i32>* %3946, align 16
  %3948 = getelementptr inbounds i32, i32* %3945, i64 4
  %3949 = bitcast i32* %3948 to <4 x i32>*
  %3950 = load <4 x i32>, <4 x i32>* %3949, align 16
  %3951 = getelementptr inbounds i32, i32* %3521, i64 %3938
  %3952 = bitcast i32* %3951 to <4 x i32>*
  %3953 = load <4 x i32>, <4 x i32>* %3952, align 16
  %3954 = getelementptr inbounds i32, i32* %3951, i64 4
  %3955 = bitcast i32* %3954 to <4 x i32>*
  %3956 = load <4 x i32>, <4 x i32>* %3955, align 16
  %3957 = add <8 x i16> %3941, %3842
  %3958 = add <8 x i16> %3957, %3944
  %3959 = add <8 x i16> %3958, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3960 = lshr <8 x i16> %3959, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %3961 = shufflevector <8 x i16> %3960, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3962 = shufflevector <8 x i16> %3960, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3963 = add <4 x i32> %3926, <i32 8, i32 8, i32 8, i32 8>
  %3964 = add <4 x i32> %3963, %3947
  %3965 = add <4 x i32> %3964, %3953
  %3966 = lshr <4 x i32> %3965, <i32 4, i32 4, i32 4, i32 4>
  %3967 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3961, <8 x i16> %3961) #5
  %3968 = mul nuw <4 x i32> %3966, <i32 9, i32 9, i32 9, i32 9>
  %3969 = sub <4 x i32> %3968, %3967
  %3970 = icmp sgt <4 x i32> %3969, zeroinitializer
  %3971 = select <4 x i1> %3970, <4 x i32> %3969, <4 x i32> zeroinitializer
  %3972 = mul <4 x i32> %3971, %3726
  %3973 = add <4 x i32> %3972, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3974 = lshr <4 x i32> %3973, <i32 20, i32 20, i32 20, i32 20>
  %3975 = add <4 x i32> %3933, <i32 8, i32 8, i32 8, i32 8>
  %3976 = add <4 x i32> %3975, %3950
  %3977 = add <4 x i32> %3976, %3956
  %3978 = lshr <4 x i32> %3977, <i32 4, i32 4, i32 4, i32 4>
  %3979 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %3962, <8 x i16> %3962) #5
  %3980 = mul nuw <4 x i32> %3978, <i32 9, i32 9, i32 9, i32 9>
  %3981 = sub <4 x i32> %3980, %3979
  %3982 = icmp sgt <4 x i32> %3981, zeroinitializer
  %3983 = select <4 x i1> %3982, <4 x i32> %3981, <4 x i32> zeroinitializer
  %3984 = mul <4 x i32> %3983, %3726
  %3985 = add <4 x i32> %3984, <i32 524288, i32 524288, i32 524288, i32 524288>
  %3986 = lshr <4 x i32> %3985, <i32 20, i32 20, i32 20, i32 20>
  %3987 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3974, <4 x i32> %3986) #5
  %3988 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3914, <8 x i16> %3987) #5
  %3989 = icmp ult <16 x i8> %3988, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %3990 = select <16 x i1> %3989, <16 x i8> %3988, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %3991 = icmp sgt <16 x i8> %3990, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %3992 = select <16 x i1> %3991, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %3990
  %3993 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3795, <16 x i8> %3992) #5
  %3994 = add nsw <16 x i8> %3990, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %3995 = icmp sgt <16 x i8> %3994, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %3996 = select <16 x i1> %3995, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %3994
  %3997 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3796, <16 x i8> %3996) #5
  %3998 = or <16 x i8> %3997, %3993
  %3999 = add nsw <16 x i8> %3990, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %4000 = icmp sgt <16 x i8> %3999, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %4001 = select <16 x i1> %4000, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %3999
  %4002 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3797, <16 x i8> %4001) #5
  %4003 = or <16 x i8> %3998, %4002
  %4004 = xor <16 x i8> %3988, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %4005 = icmp ugt <16 x i8> %4003, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %4006 = select <16 x i1> %4005, <16 x i8> %4003, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %4007 = icmp sgt <16 x i8> %4004, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %4008 = icmp sgt <16 x i8> %4004, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %4009 = sext <16 x i1> %4008 to <16 x i8>
  %4010 = icmp sgt <16 x i8> %4004, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %4011 = icmp sgt <16 x i8> %4004, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %4012 = icmp eq <16 x i8> %4004, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %4013 = zext <16 x i1> %4007 to <16 x i8>
  %4014 = sub nsw <16 x i8> %4009, %4013
  %4015 = zext <16 x i1> %4010 to <16 x i8>
  %4016 = sub nsw <16 x i8> %4014, %4015
  %4017 = zext <16 x i1> %4011 to <16 x i8>
  %4018 = sub nsw <16 x i8> %4016, %4017
  %4019 = zext <16 x i1> %4012 to <16 x i8>
  %4020 = sub nsw <16 x i8> %4018, %4019
  %4021 = add <16 x i8> %4020, %4006
  %4022 = bitcast <16 x i8> %4021 to <2 x i64>
  %4023 = shufflevector <16 x i8> %4021, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4024 = bitcast <16 x i8> %4023 to <8 x i16>
  %4025 = shufflevector <8 x i16> %4024, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4026 = shufflevector <8 x i16> %3885, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4027 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4025, <8 x i16> %4026) #5
  %4028 = shufflevector <8 x i16> %4024, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4029 = shufflevector <8 x i16> %3885, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4030 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4028, <8 x i16> %4029) #5
  %4031 = mul <4 x i32> %4027, <i32 455, i32 455, i32 455, i32 455>
  %4032 = mul <4 x i32> %4030, <i32 455, i32 455, i32 455, i32 455>
  %4033 = add <4 x i32> %4031, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4034 = lshr <4 x i32> %4033, <i32 12, i32 12, i32 12, i32 12>
  %4035 = add <4 x i32> %4032, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4036 = lshr <4 x i32> %4035, <i32 12, i32 12, i32 12, i32 12>
  %4037 = shufflevector <16 x i8> %4021, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %4038 = bitcast <16 x i8> %4037 to <8 x i16>
  %4039 = shufflevector <8 x i16> %4038, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4040 = shufflevector <8 x i16> %3958, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4041 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4039, <8 x i16> %4040) #5
  %4042 = shufflevector <8 x i16> %4038, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4043 = shufflevector <8 x i16> %3958, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4044 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4042, <8 x i16> %4043) #5
  %4045 = mul <4 x i32> %4041, <i32 455, i32 455, i32 455, i32 455>
  %4046 = add <4 x i32> %4045, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4047 = lshr <4 x i32> %4046, <i32 12, i32 12, i32 12, i32 12>
  %4048 = shufflevector <2 x i64> %3812, <2 x i64> %4022, <2 x i32> <i32 0, i32 2>
  %4049 = shufflevector <16 x i8> %4021, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4050 = bitcast <2 x i64> %4048 to <16 x i8>
  %4051 = shufflevector <16 x i8> %4050, <16 x i8> %4049, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %4052 = shufflevector <16 x i8> %4050, <16 x i8> %4049, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4053 = shufflevector <16 x i8> %4050, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4054 = shufflevector <16 x i8> %4051, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4055 = bitcast <16 x i8> %4053 to <8 x i16>
  %4056 = bitcast <16 x i8> %4054 to <8 x i16>
  %4057 = add <8 x i16> %4056, %4055
  %4058 = shufflevector <16 x i8> %4052, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4059 = bitcast <16 x i8> %4058 to <8 x i16>
  %4060 = add <8 x i16> %4057, %4059
  %4061 = mul <8 x i16> %4060, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %4062 = add <8 x i16> %4061, %4056
  %4063 = shufflevector <16 x i8> %4050, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %4064 = shufflevector <16 x i8> %4051, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %4065 = bitcast <16 x i8> %4063 to <8 x i16>
  %4066 = bitcast <16 x i8> %4064 to <8 x i16>
  %4067 = add <8 x i16> %4066, %4065
  %4068 = shufflevector <16 x i8> %4052, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %4069 = bitcast <16 x i8> %4068 to <8 x i16>
  %4070 = add <8 x i16> %4067, %4069
  %4071 = mul <8 x i16> %4070, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %4072 = add <8 x i16> %4071, %4066
  %4073 = bitcast i16* %3808 to <8 x i16>*
  store <8 x i16> %4062, <8 x i16>* %4073, align 16
  %4074 = getelementptr inbounds i16, i16* %3808, i64 8
  %4075 = bitcast i16* %4074 to <8 x i16>*
  store <8 x i16> %4072, <8 x i16>* %4075, align 16
  %4076 = bitcast <4 x i32> %3811 to <16 x i8>
  %4077 = bitcast <4 x i32> %3806 to <16 x i8>
  %4078 = shufflevector <16 x i8> %4077, <16 x i8> %4076, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4079 = bitcast <16 x i8> %4078 to <4 x i32>
  %4080 = shufflevector <16 x i8> %4077, <16 x i8> %4076, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4081 = bitcast <16 x i8> %4080 to <4 x i32>
  %4082 = add <4 x i32> %3806, %4079
  %4083 = add <4 x i32> %4082, %4081
  %4084 = mul <4 x i32> %4083, <i32 3, i32 3, i32 3, i32 3>
  %4085 = add <4 x i32> %4084, %4079
  %4086 = bitcast <4 x i32> %4034 to <16 x i8>
  %4087 = shufflevector <16 x i8> %4076, <16 x i8> %4086, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4088 = bitcast <16 x i8> %4087 to <4 x i32>
  %4089 = shufflevector <16 x i8> %4076, <16 x i8> %4086, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4090 = bitcast <16 x i8> %4089 to <4 x i32>
  %4091 = add <4 x i32> %3811, %4088
  %4092 = add <4 x i32> %4091, %4090
  %4093 = mul <4 x i32> %4092, <i32 3, i32 3, i32 3, i32 3>
  %4094 = add <4 x i32> %4093, %4088
  %4095 = bitcast <4 x i32> %4036 to <16 x i8>
  %4096 = shufflevector <16 x i8> %4086, <16 x i8> %4095, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4097 = bitcast <16 x i8> %4096 to <4 x i32>
  %4098 = shufflevector <16 x i8> %4086, <16 x i8> %4095, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4099 = bitcast <16 x i8> %4098 to <4 x i32>
  %4100 = add <4 x i32> %4034, %4097
  %4101 = add <4 x i32> %4100, %4099
  %4102 = mul <4 x i32> %4101, <i32 3, i32 3, i32 3, i32 3>
  %4103 = add <4 x i32> %4102, %4097
  %4104 = bitcast <4 x i32> %4047 to <16 x i8>
  %4105 = shufflevector <16 x i8> %4095, <16 x i8> %4104, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4106 = bitcast <16 x i8> %4105 to <4 x i32>
  %4107 = shufflevector <16 x i8> %4095, <16 x i8> %4104, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4108 = bitcast <16 x i8> %4107 to <4 x i32>
  %4109 = add <4 x i32> %4036, %4106
  %4110 = add <4 x i32> %4109, %4108
  %4111 = mul <4 x i32> %4110, <i32 3, i32 3, i32 3, i32 3>
  %4112 = add <4 x i32> %4111, %4106
  %4113 = bitcast i32* %3807 to <4 x i32>*
  store <4 x i32> %4085, <4 x i32>* %4113, align 16
  %4114 = getelementptr inbounds i32, i32* %3807, i64 4
  %4115 = bitcast i32* %4114 to <4 x i32>*
  store <4 x i32> %4094, <4 x i32>* %4115, align 16
  %4116 = getelementptr inbounds i32, i32* %3807, i64 8
  %4117 = bitcast i32* %4116 to <4 x i32>*
  store <4 x i32> %4103, <4 x i32>* %4117, align 16
  %4118 = getelementptr inbounds i32, i32* %3807, i64 12
  %4119 = bitcast i32* %4118 to <4 x i32>*
  store <4 x i32> %4112, <4 x i32>* %4119, align 16
  %4120 = getelementptr inbounds i16, i16* %3808, i64 16
  %4121 = getelementptr inbounds i32, i32* %3807, i64 16
  %4122 = icmp slt i64 %3815, %3506
  br i1 %4122, label %3799, label %4123

4123:                                             ; preds = %3799
  %4124 = ptrtoint i16* %3651 to i64
  %4125 = ptrtoint i32* %3652 to i64
  %4126 = icmp sgt i32 %8, 1
  %4127 = getelementptr inbounds i16, i16* %3636, i64 %2
  %4128 = select i1 %4126, i16* %4127, i16* %3637
  %4129 = bitcast i16* %4128 to <8 x i16>*
  %4130 = load <8 x i16>, <8 x i16>* %4129, align 1
  %4131 = getelementptr inbounds i16, i16* %4128, i64 8
  %4132 = bitcast i16* %4131 to <2 x i64>*
  %4133 = load <2 x i64>, <2 x i64>* %4132, align 1
  %4134 = shufflevector <8 x i16> %4130, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4135 = shufflevector <8 x i16> %4130, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4136 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4134, <8 x i16> %4134) #5
  %4137 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4135, <8 x i16> %4135) #5
  %4138 = bitcast <2 x i64> %4133 to <8 x i16>
  %4139 = shufflevector <8 x i16> %4138, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4140 = shufflevector <8 x i16> %4138, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4141 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4139, <8 x i16> %4139) #5
  %4142 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4140, <8 x i16> %4140) #5
  %4143 = bitcast <2 x i64> %4133 to <16 x i8>
  %4144 = bitcast <8 x i16> %4130 to <16 x i8>
  %4145 = shufflevector <16 x i8> %4144, <16 x i8> %4143, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4146 = bitcast <16 x i8> %4145 to <8 x i16>
  %4147 = shufflevector <16 x i8> %4144, <16 x i8> %4143, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4148 = bitcast <16 x i8> %4147 to <8 x i16>
  %4149 = add <8 x i16> %4130, %4146
  %4150 = add <8 x i16> %4149, %4148
  store <8 x i16> %4150, <8 x i16>* %3696, align 16
  %4151 = bitcast <4 x i32> %4137 to <16 x i8>
  %4152 = bitcast <4 x i32> %4136 to <16 x i8>
  %4153 = shufflevector <16 x i8> %4152, <16 x i8> %4151, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4154 = bitcast <16 x i8> %4153 to <4 x i32>
  %4155 = shufflevector <16 x i8> %4152, <16 x i8> %4151, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4156 = bitcast <16 x i8> %4155 to <4 x i32>
  %4157 = add <4 x i32> %4136, %4154
  %4158 = add <4 x i32> %4157, %4156
  %4159 = bitcast <4 x i32> %4141 to <16 x i8>
  %4160 = shufflevector <16 x i8> %4151, <16 x i8> %4159, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4161 = bitcast <16 x i8> %4160 to <4 x i32>
  %4162 = shufflevector <16 x i8> %4151, <16 x i8> %4159, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4163 = bitcast <16 x i8> %4162 to <4 x i32>
  %4164 = add <4 x i32> %4137, %4161
  %4165 = add <4 x i32> %4164, %4163
  store <4 x i32> %4158, <4 x i32>* %3700, align 16
  store <4 x i32> %4165, <4 x i32>* %3703, align 16
  %4166 = load <8 x i16>, <8 x i16>* %3698, align 16
  %4167 = load <8 x i16>, <8 x i16>* %3677, align 16
  %4168 = load <4 x i32>, <4 x i32>* %3705, align 16
  %4169 = load <4 x i32>, <4 x i32>* %3708, align 16
  %4170 = load <4 x i32>, <4 x i32>* %3693, align 16
  %4171 = load <4 x i32>, <4 x i32>* %3695, align 16
  %4172 = add <8 x i16> %4166, %4150
  %4173 = add <8 x i16> %4172, %4167
  %4174 = add <8 x i16> %4173, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4175 = lshr <8 x i16> %4174, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4176 = shufflevector <8 x i16> %4175, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4177 = shufflevector <8 x i16> %4175, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4178 = add <4 x i32> %4158, <i32 8, i32 8, i32 8, i32 8>
  %4179 = add <4 x i32> %4178, %4168
  %4180 = add <4 x i32> %4179, %4170
  %4181 = lshr <4 x i32> %4180, <i32 4, i32 4, i32 4, i32 4>
  %4182 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4176, <8 x i16> %4176) #5
  %4183 = mul nuw <4 x i32> %4181, <i32 9, i32 9, i32 9, i32 9>
  %4184 = sub <4 x i32> %4183, %4182
  %4185 = icmp sgt <4 x i32> %4184, zeroinitializer
  %4186 = select <4 x i1> %4185, <4 x i32> %4184, <4 x i32> zeroinitializer
  %4187 = mul <4 x i32> %4186, %3726
  %4188 = add <4 x i32> %4187, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4189 = lshr <4 x i32> %4188, <i32 20, i32 20, i32 20, i32 20>
  %4190 = add <4 x i32> %4165, <i32 8, i32 8, i32 8, i32 8>
  %4191 = add <4 x i32> %4190, %4169
  %4192 = add <4 x i32> %4191, %4171
  %4193 = lshr <4 x i32> %4192, <i32 4, i32 4, i32 4, i32 4>
  %4194 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4177, <8 x i16> %4177) #5
  %4195 = mul nuw <4 x i32> %4193, <i32 9, i32 9, i32 9, i32 9>
  %4196 = sub <4 x i32> %4195, %4194
  %4197 = icmp sgt <4 x i32> %4196, zeroinitializer
  %4198 = select <4 x i1> %4197, <4 x i32> %4196, <4 x i32> zeroinitializer
  %4199 = mul <4 x i32> %4198, %3726
  %4200 = add <4 x i32> %4199, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4201 = lshr <4 x i32> %4200, <i32 20, i32 20, i32 20, i32 20>
  %4202 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4189, <4 x i32> %4201) #5
  %4203 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4202, <8 x i16> undef) #5
  %4204 = bitcast <16 x i8> %4203 to <2 x i64>
  %4205 = extractelement <2 x i64> %4204, i32 0
  %4206 = lshr i64 %4205, 8
  %4207 = lshr i64 %4205, 16
  %4208 = lshr i64 %4205, 24
  %4209 = lshr i64 %4205, 32
  %4210 = lshr i64 %4205, 40
  %4211 = lshr i64 %4205, 48
  %4212 = lshr i64 %4205, 56
  %4213 = and i64 %4205, 255
  %4214 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4213
  %4215 = load i8, i8* %4214, align 1
  %4216 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %4215, i64 0
  %4217 = and i64 %4206, 255
  %4218 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4217
  %4219 = load i8, i8* %4218, align 1
  %4220 = insertelement <16 x i8> %4216, i8 %4219, i64 1
  %4221 = and i64 %4207, 255
  %4222 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4221
  %4223 = load i8, i8* %4222, align 1
  %4224 = insertelement <16 x i8> %4220, i8 %4223, i64 2
  %4225 = and i64 %4208, 255
  %4226 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4225
  %4227 = load i8, i8* %4226, align 1
  %4228 = insertelement <16 x i8> %4224, i8 %4227, i64 3
  %4229 = and i64 %4209, 255
  %4230 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4229
  %4231 = load i8, i8* %4230, align 1
  %4232 = insertelement <16 x i8> %4228, i8 %4231, i64 4
  %4233 = and i64 %4210, 255
  %4234 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4233
  %4235 = load i8, i8* %4234, align 1
  %4236 = insertelement <16 x i8> %4232, i8 %4235, i64 5
  %4237 = and i64 %4211, 255
  %4238 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4237
  %4239 = load i8, i8* %4238, align 1
  %4240 = insertelement <16 x i8> %4236, i8 %4239, i64 6
  %4241 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4212
  %4242 = load i8, i8* %4241, align 1
  %4243 = insertelement <16 x i8> %4240, i8 %4242, i64 7
  %4244 = shufflevector <16 x i8> %4243, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4245 = bitcast <16 x i8> %4244 to <8 x i16>
  %4246 = shufflevector <8 x i16> %4245, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4247 = shufflevector <8 x i16> %4173, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4248 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4246, <8 x i16> %4247) #5
  %4249 = shufflevector <8 x i16> %4245, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4250 = shufflevector <8 x i16> %4173, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4251 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4249, <8 x i16> %4250) #5
  %4252 = mul <4 x i32> %4248, <i32 455, i32 455, i32 455, i32 455>
  %4253 = add <4 x i32> %4252, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4254 = lshr <4 x i32> %4253, <i32 12, i32 12, i32 12, i32 12>
  %4255 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 8
  br label %4256

4256:                                             ; preds = %4256, %4123
  %4257 = phi i64 [ %4274, %4256 ], [ 0, %4123 ]
  %4258 = phi <2 x i64> [ %4279, %4256 ], [ %4133, %4123 ]
  %4259 = phi <16 x i8> [ %4508, %4256 ], [ %4243, %4123 ]
  %4260 = phi <4 x i32> [ %4378, %4256 ], [ %4142, %4123 ]
  %4261 = phi <4 x i32> [ %4377, %4256 ], [ %4141, %4123 ]
  %4262 = phi <4 x i32> [ %4503, %4256 ], [ %4251, %4123 ]
  %4263 = phi <4 x i32> [ %4506, %4256 ], [ %4254, %4123 ]
  %4264 = phi i16* [ %4597, %4256 ], [ %3522, %4123 ]
  %4265 = phi i16* [ %4595, %4256 ], [ %3530, %4123 ]
  %4266 = phi i32* [ %4598, %4256 ], [ %3523, %4123 ]
  %4267 = phi i32* [ %4596, %4256 ], [ %3531, %4123 ]
  %4268 = mul <4 x i32> %4262, <i32 455, i32 455, i32 455, i32 455>
  %4269 = add <4 x i32> %4268, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4270 = lshr <4 x i32> %4269, <i32 12, i32 12, i32 12, i32 12>
  %4271 = bitcast <16 x i8> %4259 to <2 x i64>
  %4272 = getelementptr inbounds i16, i16* %4128, i64 %4257
  %4273 = getelementptr inbounds i16, i16* %4272, i64 16
  %4274 = add nuw nsw i64 %4257, 16
  %4275 = bitcast i16* %4273 to <2 x i64>*
  %4276 = load <2 x i64>, <2 x i64>* %4275, align 1
  %4277 = getelementptr inbounds i16, i16* %4272, i64 24
  %4278 = bitcast i16* %4277 to <2 x i64>*
  %4279 = load <2 x i64>, <2 x i64>* %4278, align 1
  %4280 = or i64 %4257, 8
  %4281 = bitcast <2 x i64> %4276 to <8 x i16>
  %4282 = shufflevector <8 x i16> %4281, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4283 = shufflevector <8 x i16> %4281, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4284 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4282, <8 x i16> %4282) #5
  %4285 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4283, <8 x i16> %4283) #5
  %4286 = bitcast <2 x i64> %4258 to <8 x i16>
  %4287 = bitcast <2 x i64> %4276 to <16 x i8>
  %4288 = bitcast <2 x i64> %4258 to <16 x i8>
  %4289 = shufflevector <16 x i8> %4288, <16 x i8> %4287, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4290 = bitcast <16 x i8> %4289 to <8 x i16>
  %4291 = shufflevector <16 x i8> %4288, <16 x i8> %4287, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4292 = bitcast <16 x i8> %4291 to <8 x i16>
  %4293 = add <8 x i16> %4290, %4286
  %4294 = add <8 x i16> %4293, %4292
  %4295 = bitcast <2 x i64> %4279 to <16 x i8>
  %4296 = shufflevector <16 x i8> %4287, <16 x i8> %4295, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4297 = bitcast <16 x i8> %4296 to <8 x i16>
  %4298 = shufflevector <16 x i8> %4287, <16 x i8> %4295, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4299 = bitcast <16 x i8> %4298 to <8 x i16>
  %4300 = add <8 x i16> %4297, %4281
  %4301 = add <8 x i16> %4300, %4299
  %4302 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %4280
  %4303 = bitcast i16* %4302 to <8 x i16>*
  store <8 x i16> %4294, <8 x i16>* %4303, align 16
  %4304 = getelementptr inbounds i16, i16* %4302, i64 8
  %4305 = bitcast i16* %4304 to <8 x i16>*
  store <8 x i16> %4301, <8 x i16>* %4305, align 16
  %4306 = bitcast <4 x i32> %4260 to <16 x i8>
  %4307 = bitcast <4 x i32> %4261 to <16 x i8>
  %4308 = shufflevector <16 x i8> %4307, <16 x i8> %4306, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4309 = bitcast <16 x i8> %4308 to <4 x i32>
  %4310 = shufflevector <16 x i8> %4307, <16 x i8> %4306, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4311 = bitcast <16 x i8> %4310 to <4 x i32>
  %4312 = add <4 x i32> %4261, %4309
  %4313 = add <4 x i32> %4312, %4311
  %4314 = bitcast <4 x i32> %4284 to <16 x i8>
  %4315 = shufflevector <16 x i8> %4306, <16 x i8> %4314, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4316 = bitcast <16 x i8> %4315 to <4 x i32>
  %4317 = shufflevector <16 x i8> %4306, <16 x i8> %4314, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4318 = bitcast <16 x i8> %4317 to <4 x i32>
  %4319 = add <4 x i32> %4260, %4316
  %4320 = add <4 x i32> %4319, %4318
  %4321 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 %4280
  %4322 = bitcast i32* %4321 to <4 x i32>*
  store <4 x i32> %4313, <4 x i32>* %4322, align 16
  %4323 = getelementptr inbounds i32, i32* %4321, i64 4
  %4324 = bitcast i32* %4323 to <4 x i32>*
  store <4 x i32> %4320, <4 x i32>* %4324, align 16
  %4325 = getelementptr inbounds <8 x i16>, <8 x i16>* %3698, i64 0, i64 %4280
  %4326 = bitcast i16* %4325 to <8 x i16>*
  %4327 = load <8 x i16>, <8 x i16>* %4326, align 16
  %4328 = getelementptr inbounds <8 x i16>, <8 x i16>* %3677, i64 0, i64 %4280
  %4329 = bitcast i16* %4328 to <8 x i16>*
  %4330 = load <8 x i16>, <8 x i16>* %4329, align 16
  %4331 = getelementptr inbounds i32, i32* %3521, i64 %4280
  %4332 = bitcast i32* %4331 to <4 x i32>*
  %4333 = load <4 x i32>, <4 x i32>* %4332, align 16
  %4334 = getelementptr inbounds i32, i32* %4331, i64 4
  %4335 = bitcast i32* %4334 to <4 x i32>*
  %4336 = load <4 x i32>, <4 x i32>* %4335, align 16
  %4337 = getelementptr inbounds i32, i32* %3525, i64 %4280
  %4338 = bitcast i32* %4337 to <4 x i32>*
  %4339 = load <4 x i32>, <4 x i32>* %4338, align 16
  %4340 = getelementptr inbounds i32, i32* %4337, i64 4
  %4341 = bitcast i32* %4340 to <4 x i32>*
  %4342 = load <4 x i32>, <4 x i32>* %4341, align 16
  %4343 = add <8 x i16> %4327, %4294
  %4344 = add <8 x i16> %4343, %4330
  %4345 = add <8 x i16> %4344, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4346 = lshr <8 x i16> %4345, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4347 = shufflevector <8 x i16> %4346, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4348 = shufflevector <8 x i16> %4346, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4349 = add <4 x i32> %4313, <i32 8, i32 8, i32 8, i32 8>
  %4350 = add <4 x i32> %4349, %4333
  %4351 = add <4 x i32> %4350, %4339
  %4352 = lshr <4 x i32> %4351, <i32 4, i32 4, i32 4, i32 4>
  %4353 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4347, <8 x i16> %4347) #5
  %4354 = mul nuw <4 x i32> %4352, <i32 9, i32 9, i32 9, i32 9>
  %4355 = sub <4 x i32> %4354, %4353
  %4356 = icmp sgt <4 x i32> %4355, zeroinitializer
  %4357 = select <4 x i1> %4356, <4 x i32> %4355, <4 x i32> zeroinitializer
  %4358 = mul <4 x i32> %4357, %3726
  %4359 = add <4 x i32> %4358, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4360 = lshr <4 x i32> %4359, <i32 20, i32 20, i32 20, i32 20>
  %4361 = add <4 x i32> %4320, <i32 8, i32 8, i32 8, i32 8>
  %4362 = add <4 x i32> %4361, %4336
  %4363 = add <4 x i32> %4362, %4342
  %4364 = lshr <4 x i32> %4363, <i32 4, i32 4, i32 4, i32 4>
  %4365 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4348, <8 x i16> %4348) #5
  %4366 = mul nuw <4 x i32> %4364, <i32 9, i32 9, i32 9, i32 9>
  %4367 = sub <4 x i32> %4366, %4365
  %4368 = icmp sgt <4 x i32> %4367, zeroinitializer
  %4369 = select <4 x i1> %4368, <4 x i32> %4367, <4 x i32> zeroinitializer
  %4370 = mul <4 x i32> %4369, %3726
  %4371 = add <4 x i32> %4370, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4372 = lshr <4 x i32> %4371, <i32 20, i32 20, i32 20, i32 20>
  %4373 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4360, <4 x i32> %4372) #5
  %4374 = bitcast <2 x i64> %4279 to <8 x i16>
  %4375 = shufflevector <8 x i16> %4374, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4376 = shufflevector <8 x i16> %4374, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4377 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4375, <8 x i16> %4375) #5
  %4378 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4376, <8 x i16> %4376) #5
  %4379 = bitcast <4 x i32> %4285 to <16 x i8>
  %4380 = shufflevector <16 x i8> %4314, <16 x i8> %4379, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4381 = bitcast <16 x i8> %4380 to <4 x i32>
  %4382 = shufflevector <16 x i8> %4314, <16 x i8> %4379, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4383 = bitcast <16 x i8> %4382 to <4 x i32>
  %4384 = add <4 x i32> %4284, %4381
  %4385 = add <4 x i32> %4384, %4383
  %4386 = bitcast <4 x i32> %4377 to <16 x i8>
  %4387 = shufflevector <16 x i8> %4379, <16 x i8> %4386, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4388 = bitcast <16 x i8> %4387 to <4 x i32>
  %4389 = shufflevector <16 x i8> %4379, <16 x i8> %4386, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4390 = bitcast <16 x i8> %4389 to <4 x i32>
  %4391 = add <4 x i32> %4285, %4388
  %4392 = add <4 x i32> %4391, %4390
  %4393 = getelementptr inbounds i32, i32* %4255, i64 %4280
  %4394 = bitcast i32* %4393 to <4 x i32>*
  store <4 x i32> %4385, <4 x i32>* %4394, align 16
  %4395 = getelementptr inbounds i32, i32* %4393, i64 4
  %4396 = bitcast i32* %4395 to <4 x i32>*
  store <4 x i32> %4392, <4 x i32>* %4396, align 16
  %4397 = add nuw nsw i64 %4280, 8
  %4398 = getelementptr inbounds <8 x i16>, <8 x i16>* %3698, i64 0, i64 %4397
  %4399 = bitcast i16* %4398 to <8 x i16>*
  %4400 = load <8 x i16>, <8 x i16>* %4399, align 16
  %4401 = getelementptr inbounds <8 x i16>, <8 x i16>* %3677, i64 0, i64 %4397
  %4402 = bitcast i16* %4401 to <8 x i16>*
  %4403 = load <8 x i16>, <8 x i16>* %4402, align 16
  %4404 = getelementptr inbounds i32, i32* %3521, i64 %4397
  %4405 = bitcast i32* %4404 to <4 x i32>*
  %4406 = load <4 x i32>, <4 x i32>* %4405, align 16
  %4407 = getelementptr inbounds i32, i32* %4404, i64 4
  %4408 = bitcast i32* %4407 to <4 x i32>*
  %4409 = load <4 x i32>, <4 x i32>* %4408, align 16
  %4410 = getelementptr inbounds i32, i32* %3525, i64 %4397
  %4411 = bitcast i32* %4410 to <4 x i32>*
  %4412 = load <4 x i32>, <4 x i32>* %4411, align 16
  %4413 = getelementptr inbounds i32, i32* %4410, i64 4
  %4414 = bitcast i32* %4413 to <4 x i32>*
  %4415 = load <4 x i32>, <4 x i32>* %4414, align 16
  %4416 = add <8 x i16> %4400, %4301
  %4417 = add <8 x i16> %4416, %4403
  %4418 = add <8 x i16> %4417, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4419 = lshr <8 x i16> %4418, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4420 = shufflevector <8 x i16> %4419, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4421 = shufflevector <8 x i16> %4419, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4422 = add <4 x i32> %4385, <i32 8, i32 8, i32 8, i32 8>
  %4423 = add <4 x i32> %4422, %4406
  %4424 = add <4 x i32> %4423, %4412
  %4425 = lshr <4 x i32> %4424, <i32 4, i32 4, i32 4, i32 4>
  %4426 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4420, <8 x i16> %4420) #5
  %4427 = mul nuw <4 x i32> %4425, <i32 9, i32 9, i32 9, i32 9>
  %4428 = sub <4 x i32> %4427, %4426
  %4429 = icmp sgt <4 x i32> %4428, zeroinitializer
  %4430 = select <4 x i1> %4429, <4 x i32> %4428, <4 x i32> zeroinitializer
  %4431 = mul <4 x i32> %4430, %3726
  %4432 = add <4 x i32> %4431, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4433 = lshr <4 x i32> %4432, <i32 20, i32 20, i32 20, i32 20>
  %4434 = add <4 x i32> %4392, <i32 8, i32 8, i32 8, i32 8>
  %4435 = add <4 x i32> %4434, %4409
  %4436 = add <4 x i32> %4435, %4415
  %4437 = lshr <4 x i32> %4436, <i32 4, i32 4, i32 4, i32 4>
  %4438 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4421, <8 x i16> %4421) #5
  %4439 = mul nuw <4 x i32> %4437, <i32 9, i32 9, i32 9, i32 9>
  %4440 = sub <4 x i32> %4439, %4438
  %4441 = icmp sgt <4 x i32> %4440, zeroinitializer
  %4442 = select <4 x i1> %4441, <4 x i32> %4440, <4 x i32> zeroinitializer
  %4443 = mul <4 x i32> %4442, %3726
  %4444 = add <4 x i32> %4443, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4445 = lshr <4 x i32> %4444, <i32 20, i32 20, i32 20, i32 20>
  %4446 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4433, <4 x i32> %4445) #5
  %4447 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4373, <8 x i16> %4446) #5
  %4448 = icmp ult <16 x i8> %4447, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %4449 = select <16 x i1> %4448, <16 x i8> %4447, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %4450 = icmp sgt <16 x i8> %4449, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %4451 = select <16 x i1> %4450, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %4449
  %4452 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3795, <16 x i8> %4451) #5
  %4453 = add nsw <16 x i8> %4449, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %4454 = icmp sgt <16 x i8> %4453, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %4455 = select <16 x i1> %4454, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %4453
  %4456 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3796, <16 x i8> %4455) #5
  %4457 = or <16 x i8> %4456, %4452
  %4458 = add nsw <16 x i8> %4449, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %4459 = icmp sgt <16 x i8> %4458, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %4460 = select <16 x i1> %4459, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %4458
  %4461 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3797, <16 x i8> %4460) #5
  %4462 = or <16 x i8> %4457, %4461
  %4463 = xor <16 x i8> %4447, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %4464 = icmp ugt <16 x i8> %4462, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %4465 = select <16 x i1> %4464, <16 x i8> %4462, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %4466 = icmp sgt <16 x i8> %4463, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %4467 = icmp sgt <16 x i8> %4463, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %4468 = sext <16 x i1> %4467 to <16 x i8>
  %4469 = icmp sgt <16 x i8> %4463, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %4470 = icmp sgt <16 x i8> %4463, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %4471 = icmp eq <16 x i8> %4463, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %4472 = zext <16 x i1> %4466 to <16 x i8>
  %4473 = sub nsw <16 x i8> %4468, %4472
  %4474 = zext <16 x i1> %4469 to <16 x i8>
  %4475 = sub nsw <16 x i8> %4473, %4474
  %4476 = zext <16 x i1> %4470 to <16 x i8>
  %4477 = sub nsw <16 x i8> %4475, %4476
  %4478 = zext <16 x i1> %4471 to <16 x i8>
  %4479 = sub nsw <16 x i8> %4477, %4478
  %4480 = add <16 x i8> %4479, %4465
  %4481 = bitcast <16 x i8> %4480 to <2 x i64>
  %4482 = shufflevector <16 x i8> %4480, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4483 = bitcast <16 x i8> %4482 to <8 x i16>
  %4484 = shufflevector <8 x i16> %4483, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4485 = shufflevector <8 x i16> %4344, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4486 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4484, <8 x i16> %4485) #5
  %4487 = shufflevector <8 x i16> %4483, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4488 = shufflevector <8 x i16> %4344, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4489 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4487, <8 x i16> %4488) #5
  %4490 = mul <4 x i32> %4486, <i32 455, i32 455, i32 455, i32 455>
  %4491 = mul <4 x i32> %4489, <i32 455, i32 455, i32 455, i32 455>
  %4492 = add <4 x i32> %4490, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4493 = lshr <4 x i32> %4492, <i32 12, i32 12, i32 12, i32 12>
  %4494 = add <4 x i32> %4491, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4495 = lshr <4 x i32> %4494, <i32 12, i32 12, i32 12, i32 12>
  %4496 = shufflevector <16 x i8> %4480, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %4497 = bitcast <16 x i8> %4496 to <8 x i16>
  %4498 = shufflevector <8 x i16> %4497, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4499 = shufflevector <8 x i16> %4417, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4500 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4498, <8 x i16> %4499) #5
  %4501 = shufflevector <8 x i16> %4497, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4502 = shufflevector <8 x i16> %4417, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4503 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4501, <8 x i16> %4502) #5
  %4504 = mul <4 x i32> %4500, <i32 455, i32 455, i32 455, i32 455>
  %4505 = add <4 x i32> %4504, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4506 = lshr <4 x i32> %4505, <i32 12, i32 12, i32 12, i32 12>
  %4507 = shufflevector <2 x i64> %4271, <2 x i64> %4481, <2 x i32> <i32 0, i32 2>
  %4508 = shufflevector <16 x i8> %4480, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4509 = bitcast <2 x i64> %4507 to <16 x i8>
  %4510 = shufflevector <16 x i8> %4509, <16 x i8> %4508, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %4511 = shufflevector <16 x i8> %4509, <16 x i8> %4508, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4512 = shufflevector <16 x i8> %4509, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4513 = shufflevector <16 x i8> %4510, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4514 = bitcast <16 x i8> %4512 to <8 x i16>
  %4515 = bitcast <16 x i8> %4513 to <8 x i16>
  %4516 = add <8 x i16> %4515, %4514
  %4517 = shufflevector <16 x i8> %4511, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4518 = bitcast <16 x i8> %4517 to <8 x i16>
  %4519 = add <8 x i16> %4516, %4518
  %4520 = shl <8 x i16> %4519, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4521 = bitcast i16* %4265 to <8 x i16>*
  store <8 x i16> %4520, <8 x i16>* %4521, align 16
  %4522 = mul <8 x i16> %4519, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %4523 = add <8 x i16> %4522, %4515
  %4524 = bitcast i16* %4264 to <8 x i16>*
  store <8 x i16> %4523, <8 x i16>* %4524, align 16
  %4525 = bitcast <4 x i32> %4270 to <16 x i8>
  %4526 = bitcast <4 x i32> %4263 to <16 x i8>
  %4527 = shufflevector <16 x i8> %4526, <16 x i8> %4525, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4528 = shufflevector <16 x i8> %4526, <16 x i8> %4525, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4529 = bitcast <16 x i8> %4528 to <4 x i32>
  %4530 = bitcast <16 x i8> %4527 to <4 x i32>
  %4531 = add <4 x i32> %4263, %4530
  %4532 = add <4 x i32> %4531, %4529
  %4533 = shl <4 x i32> %4532, <i32 2, i32 2, i32 2, i32 2>
  %4534 = mul <4 x i32> %4532, <i32 3, i32 3, i32 3, i32 3>
  %4535 = add <4 x i32> %4534, %4530
  %4536 = bitcast <4 x i32> %4493 to <16 x i8>
  %4537 = shufflevector <16 x i8> %4525, <16 x i8> %4536, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4538 = shufflevector <16 x i8> %4525, <16 x i8> %4536, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4539 = bitcast <16 x i8> %4538 to <4 x i32>
  %4540 = bitcast <16 x i8> %4537 to <4 x i32>
  %4541 = add <4 x i32> %4270, %4540
  %4542 = add <4 x i32> %4541, %4539
  %4543 = shl <4 x i32> %4542, <i32 2, i32 2, i32 2, i32 2>
  %4544 = mul <4 x i32> %4542, <i32 3, i32 3, i32 3, i32 3>
  %4545 = add <4 x i32> %4544, %4540
  %4546 = bitcast i32* %4267 to <4 x i32>*
  store <4 x i32> %4533, <4 x i32>* %4546, align 16
  %4547 = getelementptr inbounds i32, i32* %4267, i64 4
  %4548 = bitcast i32* %4547 to <4 x i32>*
  store <4 x i32> %4543, <4 x i32>* %4548, align 16
  %4549 = bitcast i32* %4266 to <4 x i32>*
  store <4 x i32> %4535, <4 x i32>* %4549, align 16
  %4550 = getelementptr inbounds i32, i32* %4266, i64 4
  %4551 = bitcast i32* %4550 to <4 x i32>*
  store <4 x i32> %4545, <4 x i32>* %4551, align 16
  %4552 = shufflevector <16 x i8> %4509, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %4553 = shufflevector <16 x i8> %4510, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %4554 = bitcast <16 x i8> %4552 to <8 x i16>
  %4555 = bitcast <16 x i8> %4553 to <8 x i16>
  %4556 = add <8 x i16> %4555, %4554
  %4557 = shufflevector <16 x i8> %4511, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %4558 = bitcast <16 x i8> %4557 to <8 x i16>
  %4559 = add <8 x i16> %4556, %4558
  %4560 = shl <8 x i16> %4559, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4561 = getelementptr inbounds i16, i16* %4265, i64 8
  %4562 = bitcast i16* %4561 to <8 x i16>*
  store <8 x i16> %4560, <8 x i16>* %4562, align 16
  %4563 = mul <8 x i16> %4559, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %4564 = add <8 x i16> %4563, %4555
  %4565 = getelementptr inbounds i16, i16* %4264, i64 8
  %4566 = bitcast i16* %4565 to <8 x i16>*
  store <8 x i16> %4564, <8 x i16>* %4566, align 16
  %4567 = bitcast <4 x i32> %4495 to <16 x i8>
  %4568 = shufflevector <16 x i8> %4536, <16 x i8> %4567, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4569 = shufflevector <16 x i8> %4536, <16 x i8> %4567, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4570 = bitcast <16 x i8> %4569 to <4 x i32>
  %4571 = bitcast <16 x i8> %4568 to <4 x i32>
  %4572 = add <4 x i32> %4493, %4571
  %4573 = add <4 x i32> %4572, %4570
  %4574 = shl <4 x i32> %4573, <i32 2, i32 2, i32 2, i32 2>
  %4575 = mul <4 x i32> %4573, <i32 3, i32 3, i32 3, i32 3>
  %4576 = add <4 x i32> %4575, %4571
  %4577 = bitcast <4 x i32> %4506 to <16 x i8>
  %4578 = shufflevector <16 x i8> %4567, <16 x i8> %4577, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4579 = shufflevector <16 x i8> %4567, <16 x i8> %4577, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4580 = bitcast <16 x i8> %4579 to <4 x i32>
  %4581 = bitcast <16 x i8> %4578 to <4 x i32>
  %4582 = add <4 x i32> %4495, %4581
  %4583 = add <4 x i32> %4582, %4580
  %4584 = shl <4 x i32> %4583, <i32 2, i32 2, i32 2, i32 2>
  %4585 = mul <4 x i32> %4583, <i32 3, i32 3, i32 3, i32 3>
  %4586 = add <4 x i32> %4585, %4581
  %4587 = getelementptr inbounds i32, i32* %4267, i64 8
  %4588 = bitcast i32* %4587 to <4 x i32>*
  store <4 x i32> %4574, <4 x i32>* %4588, align 16
  %4589 = getelementptr inbounds i32, i32* %4267, i64 12
  %4590 = bitcast i32* %4589 to <4 x i32>*
  store <4 x i32> %4584, <4 x i32>* %4590, align 16
  %4591 = getelementptr inbounds i32, i32* %4266, i64 8
  %4592 = bitcast i32* %4591 to <4 x i32>*
  store <4 x i32> %4576, <4 x i32>* %4592, align 16
  %4593 = getelementptr inbounds i32, i32* %4266, i64 12
  %4594 = bitcast i32* %4593 to <4 x i32>*
  store <4 x i32> %4586, <4 x i32>* %4594, align 16
  %4595 = getelementptr inbounds i16, i16* %4265, i64 16
  %4596 = getelementptr inbounds i32, i32* %4267, i64 16
  %4597 = getelementptr inbounds i16, i16* %4264, i64 16
  %4598 = getelementptr inbounds i32, i32* %4266, i64 16
  %4599 = icmp slt i64 %4274, %3506
  br i1 %4599, label %4256, label %4600

4600:                                             ; preds = %4256
  %4601 = getelementptr inbounds i16, i16* %3637, i64 %6
  %4602 = select i1 %4126, i16* %3637, i16* %4601
  %4603 = add nsw i32 %8, -2
  %4604 = icmp sgt i32 %4603, 0
  br i1 %4604, label %4610, label %4605

4605:                                             ; preds = %4600
  %4606 = sext i16 %3529 to i32
  %4607 = insertelement <4 x i32> undef, i32 %4606, i32 0
  %4608 = shufflevector <4 x i32> %4607, <4 x i32> undef, <4 x i32> zeroinitializer
  %4609 = bitcast <4 x i32> %4608 to <8 x i16>
  br label %4616

4610:                                             ; preds = %4600
  %4611 = shl nsw i64 %2, 1
  %4612 = sext i16 %3529 to i32
  %4613 = insertelement <4 x i32> undef, i32 %4612, i32 0
  %4614 = shufflevector <4 x i32> %4613, <4 x i32> undef, <4 x i32> zeroinitializer
  %4615 = bitcast <4 x i32> %4614 to <8 x i16>
  br label %4639

4616:                                             ; preds = %5271, %4605
  %4617 = phi i64 [ %3640, %4605 ], [ %4641, %5271 ]
  %4618 = phi i64 [ %3644, %4605 ], [ %4642, %5271 ]
  %4619 = phi i64 [ %3648, %4605 ], [ %4640, %5271 ]
  %4620 = phi i64 [ %3641, %4605 ], [ %4644, %5271 ]
  %4621 = phi i64 [ %3645, %4605 ], [ %4645, %5271 ]
  %4622 = phi i64 [ %3649, %4605 ], [ %4643, %5271 ]
  %4623 = phi i64 [ %3638, %4605 ], [ %4648, %5271 ]
  %4624 = phi i64 [ %3646, %4605 ], [ %4646, %5271 ]
  %4625 = phi i64 [ %3642, %4605 ], [ %4647, %5271 ]
  %4626 = phi i64 [ %3639, %4605 ], [ %4651, %5271 ]
  %4627 = phi i64 [ %3647, %4605 ], [ %4649, %5271 ]
  %4628 = phi i64 [ %3643, %4605 ], [ %4650, %5271 ]
  %4629 = phi <8 x i16> [ %4609, %4605 ], [ %4615, %5271 ]
  %4630 = phi i64 [ %3653, %4605 ], [ %4655, %5271 ]
  %4631 = phi i64 [ %4125, %4605 ], [ %4656, %5271 ]
  %4632 = phi i64 [ %3654, %4605 ], [ %4657, %5271 ]
  %4633 = phi i64 [ %4124, %4605 ], [ %4658, %5271 ]
  %4634 = phi i16* [ %17, %4605 ], [ %5273, %5271 ]
  %4635 = phi i16* [ %3636, %4605 ], [ %5272, %5271 ]
  %4636 = icmp slt i32 %8, 2
  %4637 = select i1 %4636, i32 %8, i32 2
  %4638 = getelementptr inbounds i16, i16* %4635, i64 2
  br label %5276

4639:                                             ; preds = %5271, %4610
  %4640 = phi i64 [ %3640, %4610 ], [ %4641, %5271 ]
  %4641 = phi i64 [ %3644, %4610 ], [ %4642, %5271 ]
  %4642 = phi i64 [ %3648, %4610 ], [ %4640, %5271 ]
  %4643 = phi i64 [ %3641, %4610 ], [ %4644, %5271 ]
  %4644 = phi i64 [ %3645, %4610 ], [ %4645, %5271 ]
  %4645 = phi i64 [ %3649, %4610 ], [ %4643, %5271 ]
  %4646 = phi i64 [ %3638, %4610 ], [ %4648, %5271 ]
  %4647 = phi i64 [ %3646, %4610 ], [ %4646, %5271 ]
  %4648 = phi i64 [ %3642, %4610 ], [ %4647, %5271 ]
  %4649 = phi i64 [ %3639, %4610 ], [ %4651, %5271 ]
  %4650 = phi i64 [ %3647, %4610 ], [ %4649, %5271 ]
  %4651 = phi i64 [ %3643, %4610 ], [ %4650, %5271 ]
  %4652 = phi i32 [ %4603, %4610 ], [ %5274, %5271 ]
  %4653 = phi i16* [ %3636, %4610 ], [ %5272, %5271 ]
  %4654 = phi i16* [ %17, %4610 ], [ %5273, %5271 ]
  %4655 = phi i64 [ %4124, %4610 ], [ %4658, %5271 ]
  %4656 = phi i64 [ %3654, %4610 ], [ %4657, %5271 ]
  %4657 = phi i64 [ %4125, %4610 ], [ %4656, %5271 ]
  %4658 = phi i64 [ %3653, %4610 ], [ %4655, %5271 ]
  %4659 = getelementptr inbounds i16, i16* %4653, i64 2
  %4660 = getelementptr inbounds i16, i16* %4653, i64 %4611
  %4661 = bitcast i16* %4660 to <8 x i16>*
  %4662 = load <8 x i16>, <8 x i16>* %4661, align 1
  %4663 = getelementptr inbounds i16, i16* %4660, i64 8
  %4664 = bitcast i16* %4663 to <2 x i64>*
  %4665 = load <2 x i64>, <2 x i64>* %4664, align 1
  %4666 = shufflevector <8 x i16> %4662, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4667 = shufflevector <8 x i16> %4662, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4668 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4666, <8 x i16> %4666) #5
  %4669 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4667, <8 x i16> %4667) #5
  %4670 = bitcast <2 x i64> %4665 to <8 x i16>
  %4671 = shufflevector <8 x i16> %4670, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4672 = shufflevector <8 x i16> %4670, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4673 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4671, <8 x i16> %4671) #5
  %4674 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4672, <8 x i16> %4672) #5
  %4675 = bitcast <2 x i64> %4665 to <16 x i8>
  %4676 = bitcast <8 x i16> %4662 to <16 x i8>
  %4677 = shufflevector <16 x i8> %4676, <16 x i8> %4675, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4678 = bitcast <16 x i8> %4677 to <8 x i16>
  %4679 = shufflevector <16 x i8> %4676, <16 x i8> %4675, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4680 = bitcast <16 x i8> %4679 to <8 x i16>
  %4681 = add <8 x i16> %4662, %4678
  %4682 = add <8 x i16> %4681, %4680
  %4683 = inttoptr i64 %4648 to <8 x i16>*
  store <8 x i16> %4682, <8 x i16>* %4683, align 16
  %4684 = bitcast <4 x i32> %4669 to <16 x i8>
  %4685 = bitcast <4 x i32> %4668 to <16 x i8>
  %4686 = shufflevector <16 x i8> %4685, <16 x i8> %4684, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4687 = bitcast <16 x i8> %4686 to <4 x i32>
  %4688 = shufflevector <16 x i8> %4685, <16 x i8> %4684, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4689 = bitcast <16 x i8> %4688 to <4 x i32>
  %4690 = add <4 x i32> %4668, %4687
  %4691 = add <4 x i32> %4690, %4689
  %4692 = bitcast <4 x i32> %4673 to <16 x i8>
  %4693 = shufflevector <16 x i8> %4684, <16 x i8> %4692, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4694 = bitcast <16 x i8> %4693 to <4 x i32>
  %4695 = shufflevector <16 x i8> %4684, <16 x i8> %4692, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4696 = bitcast <16 x i8> %4695 to <4 x i32>
  %4697 = add <4 x i32> %4669, %4694
  %4698 = add <4 x i32> %4697, %4696
  %4699 = inttoptr i64 %4651 to i32*
  %4700 = inttoptr i64 %4651 to <4 x i32>*
  store <4 x i32> %4691, <4 x i32>* %4700, align 16
  %4701 = getelementptr inbounds i32, i32* %4699, i64 4
  %4702 = bitcast i32* %4701 to <4 x i32>*
  store <4 x i32> %4698, <4 x i32>* %4702, align 16
  %4703 = inttoptr i64 %4647 to <8 x i16>*
  %4704 = load <8 x i16>, <8 x i16>* %4703, align 16
  %4705 = inttoptr i64 %4646 to <8 x i16>*
  %4706 = load <8 x i16>, <8 x i16>* %4705, align 16
  %4707 = inttoptr i64 %4650 to i32*
  %4708 = inttoptr i64 %4650 to <4 x i32>*
  %4709 = load <4 x i32>, <4 x i32>* %4708, align 16
  %4710 = getelementptr inbounds i32, i32* %4707, i64 4
  %4711 = bitcast i32* %4710 to <4 x i32>*
  %4712 = load <4 x i32>, <4 x i32>* %4711, align 16
  %4713 = inttoptr i64 %4649 to i32*
  %4714 = inttoptr i64 %4649 to <4 x i32>*
  %4715 = load <4 x i32>, <4 x i32>* %4714, align 16
  %4716 = getelementptr inbounds i32, i32* %4713, i64 4
  %4717 = bitcast i32* %4716 to <4 x i32>*
  %4718 = load <4 x i32>, <4 x i32>* %4717, align 16
  %4719 = add <8 x i16> %4704, %4682
  %4720 = add <8 x i16> %4719, %4706
  %4721 = add <8 x i16> %4720, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4722 = lshr <8 x i16> %4721, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4723 = shufflevector <8 x i16> %4722, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4724 = shufflevector <8 x i16> %4722, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4725 = add <4 x i32> %4691, <i32 8, i32 8, i32 8, i32 8>
  %4726 = add <4 x i32> %4725, %4709
  %4727 = add <4 x i32> %4726, %4715
  %4728 = lshr <4 x i32> %4727, <i32 4, i32 4, i32 4, i32 4>
  %4729 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4723, <8 x i16> %4723) #5
  %4730 = mul nuw <4 x i32> %4728, <i32 9, i32 9, i32 9, i32 9>
  %4731 = sub <4 x i32> %4730, %4729
  %4732 = icmp sgt <4 x i32> %4731, zeroinitializer
  %4733 = select <4 x i1> %4732, <4 x i32> %4731, <4 x i32> zeroinitializer
  %4734 = mul <4 x i32> %4733, %3726
  %4735 = add <4 x i32> %4734, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4736 = lshr <4 x i32> %4735, <i32 20, i32 20, i32 20, i32 20>
  %4737 = add <4 x i32> %4698, <i32 8, i32 8, i32 8, i32 8>
  %4738 = add <4 x i32> %4737, %4712
  %4739 = add <4 x i32> %4738, %4718
  %4740 = lshr <4 x i32> %4739, <i32 4, i32 4, i32 4, i32 4>
  %4741 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4724, <8 x i16> %4724) #5
  %4742 = mul nuw <4 x i32> %4740, <i32 9, i32 9, i32 9, i32 9>
  %4743 = sub <4 x i32> %4742, %4741
  %4744 = icmp sgt <4 x i32> %4743, zeroinitializer
  %4745 = select <4 x i1> %4744, <4 x i32> %4743, <4 x i32> zeroinitializer
  %4746 = mul <4 x i32> %4745, %3726
  %4747 = add <4 x i32> %4746, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4748 = lshr <4 x i32> %4747, <i32 20, i32 20, i32 20, i32 20>
  %4749 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4736, <4 x i32> %4748) #5
  %4750 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4749, <8 x i16> undef) #5
  %4751 = bitcast <16 x i8> %4750 to <2 x i64>
  %4752 = extractelement <2 x i64> %4751, i32 0
  %4753 = lshr i64 %4752, 8
  %4754 = lshr i64 %4752, 16
  %4755 = lshr i64 %4752, 24
  %4756 = lshr i64 %4752, 32
  %4757 = lshr i64 %4752, 40
  %4758 = lshr i64 %4752, 48
  %4759 = lshr i64 %4752, 56
  %4760 = and i64 %4752, 255
  %4761 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4760
  %4762 = load i8, i8* %4761, align 1
  %4763 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %4762, i64 0
  %4764 = and i64 %4753, 255
  %4765 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4764
  %4766 = load i8, i8* %4765, align 1
  %4767 = insertelement <16 x i8> %4763, i8 %4766, i64 1
  %4768 = and i64 %4754, 255
  %4769 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4768
  %4770 = load i8, i8* %4769, align 1
  %4771 = insertelement <16 x i8> %4767, i8 %4770, i64 2
  %4772 = and i64 %4755, 255
  %4773 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4772
  %4774 = load i8, i8* %4773, align 1
  %4775 = insertelement <16 x i8> %4771, i8 %4774, i64 3
  %4776 = and i64 %4756, 255
  %4777 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4776
  %4778 = load i8, i8* %4777, align 1
  %4779 = insertelement <16 x i8> %4775, i8 %4778, i64 4
  %4780 = and i64 %4757, 255
  %4781 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4780
  %4782 = load i8, i8* %4781, align 1
  %4783 = insertelement <16 x i8> %4779, i8 %4782, i64 5
  %4784 = and i64 %4758, 255
  %4785 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4784
  %4786 = load i8, i8* %4785, align 1
  %4787 = insertelement <16 x i8> %4783, i8 %4786, i64 6
  %4788 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %4759
  %4789 = load i8, i8* %4788, align 1
  %4790 = insertelement <16 x i8> %4787, i8 %4789, i64 7
  %4791 = shufflevector <16 x i8> %4790, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4792 = bitcast <16 x i8> %4791 to <8 x i16>
  %4793 = shufflevector <8 x i16> %4792, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4794 = shufflevector <8 x i16> %4720, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4795 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4793, <8 x i16> %4794) #5
  %4796 = shufflevector <8 x i16> %4792, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4797 = shufflevector <8 x i16> %4720, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4798 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4796, <8 x i16> %4797) #5
  %4799 = mul <4 x i32> %4795, <i32 455, i32 455, i32 455, i32 455>
  %4800 = add <4 x i32> %4799, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4801 = lshr <4 x i32> %4800, <i32 12, i32 12, i32 12, i32 12>
  %4802 = inttoptr i64 %4655 to i16*
  %4803 = inttoptr i64 %4657 to i32*
  %4804 = inttoptr i64 %4658 to i16*
  %4805 = inttoptr i64 %4656 to i32*
  %4806 = getelementptr inbounds i16, i16* %4804, i64 8
  %4807 = getelementptr inbounds i32, i32* %4805, i64 8
  %4808 = inttoptr i64 %4648 to i16*
  %4809 = inttoptr i64 %4647 to i16*
  %4810 = inttoptr i64 %4646 to i16*
  %4811 = getelementptr inbounds i32, i32* %4699, i64 8
  %4812 = inttoptr i64 %4642 to i16*
  %4813 = inttoptr i64 %4645 to i32*
  %4814 = inttoptr i64 %4640 to i16*
  %4815 = inttoptr i64 %4643 to i32*
  %4816 = getelementptr inbounds i16, i16* %4814, i64 8
  %4817 = getelementptr inbounds i32, i32* %4815, i64 8
  br label %4818

4818:                                             ; preds = %5266, %4639
  %4819 = phi i64 [ %4832, %5266 ], [ 0, %4639 ]
  %4820 = phi <2 x i64> [ %4837, %5266 ], [ %4665, %4639 ]
  %4821 = phi <16 x i8> [ %5062, %5266 ], [ %4790, %4639 ]
  %4822 = phi <4 x i32> [ %5270, %5266 ], [ %4674, %4639 ]
  %4823 = phi <4 x i32> [ %4935, %5266 ], [ %4673, %4639 ]
  %4824 = phi <4 x i32> [ %5269, %5266 ], [ %4798, %4639 ]
  %4825 = phi <4 x i32> [ %5060, %5266 ], [ %4801, %4639 ]
  %4826 = mul <4 x i32> %4824, <i32 455, i32 455, i32 455, i32 455>
  %4827 = add <4 x i32> %4826, <i32 2048, i32 2048, i32 2048, i32 2048>
  %4828 = lshr <4 x i32> %4827, <i32 12, i32 12, i32 12, i32 12>
  %4829 = bitcast <16 x i8> %4821 to <2 x i64>
  %4830 = getelementptr inbounds i16, i16* %4660, i64 %4819
  %4831 = getelementptr inbounds i16, i16* %4830, i64 16
  %4832 = add nuw nsw i64 %4819, 16
  %4833 = bitcast i16* %4831 to <2 x i64>*
  %4834 = load <2 x i64>, <2 x i64>* %4833, align 1
  %4835 = getelementptr inbounds i16, i16* %4830, i64 24
  %4836 = bitcast i16* %4835 to <2 x i64>*
  %4837 = load <2 x i64>, <2 x i64>* %4836, align 1
  %4838 = or i64 %4819, 8
  %4839 = bitcast <2 x i64> %4834 to <8 x i16>
  %4840 = shufflevector <8 x i16> %4839, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4841 = shufflevector <8 x i16> %4839, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4842 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4840, <8 x i16> %4840) #5
  %4843 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4841, <8 x i16> %4841) #5
  %4844 = bitcast <2 x i64> %4820 to <8 x i16>
  %4845 = bitcast <2 x i64> %4834 to <16 x i8>
  %4846 = bitcast <2 x i64> %4820 to <16 x i8>
  %4847 = shufflevector <16 x i8> %4846, <16 x i8> %4845, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4848 = bitcast <16 x i8> %4847 to <8 x i16>
  %4849 = shufflevector <16 x i8> %4846, <16 x i8> %4845, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4850 = bitcast <16 x i8> %4849 to <8 x i16>
  %4851 = add <8 x i16> %4848, %4844
  %4852 = add <8 x i16> %4851, %4850
  %4853 = bitcast <2 x i64> %4837 to <16 x i8>
  %4854 = shufflevector <16 x i8> %4845, <16 x i8> %4853, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4855 = bitcast <16 x i8> %4854 to <8 x i16>
  %4856 = shufflevector <16 x i8> %4845, <16 x i8> %4853, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4857 = bitcast <16 x i8> %4856 to <8 x i16>
  %4858 = add <8 x i16> %4855, %4839
  %4859 = add <8 x i16> %4858, %4857
  %4860 = getelementptr inbounds i16, i16* %4808, i64 %4838
  %4861 = bitcast i16* %4860 to <8 x i16>*
  store <8 x i16> %4852, <8 x i16>* %4861, align 16
  %4862 = getelementptr inbounds i16, i16* %4860, i64 8
  %4863 = bitcast i16* %4862 to <8 x i16>*
  store <8 x i16> %4859, <8 x i16>* %4863, align 16
  %4864 = bitcast <4 x i32> %4822 to <16 x i8>
  %4865 = bitcast <4 x i32> %4823 to <16 x i8>
  %4866 = shufflevector <16 x i8> %4865, <16 x i8> %4864, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4867 = bitcast <16 x i8> %4866 to <4 x i32>
  %4868 = shufflevector <16 x i8> %4865, <16 x i8> %4864, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4869 = bitcast <16 x i8> %4868 to <4 x i32>
  %4870 = add <4 x i32> %4823, %4867
  %4871 = add <4 x i32> %4870, %4869
  %4872 = bitcast <4 x i32> %4842 to <16 x i8>
  %4873 = shufflevector <16 x i8> %4864, <16 x i8> %4872, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4874 = bitcast <16 x i8> %4873 to <4 x i32>
  %4875 = shufflevector <16 x i8> %4864, <16 x i8> %4872, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4876 = bitcast <16 x i8> %4875 to <4 x i32>
  %4877 = add <4 x i32> %4822, %4874
  %4878 = add <4 x i32> %4877, %4876
  %4879 = getelementptr inbounds i32, i32* %4699, i64 %4838
  %4880 = bitcast i32* %4879 to <4 x i32>*
  store <4 x i32> %4871, <4 x i32>* %4880, align 16
  %4881 = getelementptr inbounds i32, i32* %4879, i64 4
  %4882 = bitcast i32* %4881 to <4 x i32>*
  store <4 x i32> %4878, <4 x i32>* %4882, align 16
  %4883 = getelementptr inbounds i16, i16* %4809, i64 %4838
  %4884 = bitcast i16* %4883 to <8 x i16>*
  %4885 = load <8 x i16>, <8 x i16>* %4884, align 16
  %4886 = getelementptr inbounds i16, i16* %4810, i64 %4838
  %4887 = bitcast i16* %4886 to <8 x i16>*
  %4888 = load <8 x i16>, <8 x i16>* %4887, align 16
  %4889 = getelementptr inbounds i32, i32* %4707, i64 %4838
  %4890 = bitcast i32* %4889 to <4 x i32>*
  %4891 = load <4 x i32>, <4 x i32>* %4890, align 16
  %4892 = getelementptr inbounds i32, i32* %4889, i64 4
  %4893 = bitcast i32* %4892 to <4 x i32>*
  %4894 = load <4 x i32>, <4 x i32>* %4893, align 16
  %4895 = getelementptr inbounds i32, i32* %4713, i64 %4838
  %4896 = bitcast i32* %4895 to <4 x i32>*
  %4897 = load <4 x i32>, <4 x i32>* %4896, align 16
  %4898 = getelementptr inbounds i32, i32* %4895, i64 4
  %4899 = bitcast i32* %4898 to <4 x i32>*
  %4900 = load <4 x i32>, <4 x i32>* %4899, align 16
  %4901 = add <8 x i16> %4885, %4852
  %4902 = add <8 x i16> %4901, %4888
  %4903 = add <8 x i16> %4902, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4904 = lshr <8 x i16> %4903, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4905 = shufflevector <8 x i16> %4904, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4906 = shufflevector <8 x i16> %4904, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4907 = add <4 x i32> %4871, <i32 8, i32 8, i32 8, i32 8>
  %4908 = add <4 x i32> %4907, %4891
  %4909 = add <4 x i32> %4908, %4897
  %4910 = lshr <4 x i32> %4909, <i32 4, i32 4, i32 4, i32 4>
  %4911 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4905, <8 x i16> %4905) #5
  %4912 = mul nuw <4 x i32> %4910, <i32 9, i32 9, i32 9, i32 9>
  %4913 = sub <4 x i32> %4912, %4911
  %4914 = icmp sgt <4 x i32> %4913, zeroinitializer
  %4915 = select <4 x i1> %4914, <4 x i32> %4913, <4 x i32> zeroinitializer
  %4916 = mul <4 x i32> %4915, %3726
  %4917 = add <4 x i32> %4916, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4918 = lshr <4 x i32> %4917, <i32 20, i32 20, i32 20, i32 20>
  %4919 = add <4 x i32> %4878, <i32 8, i32 8, i32 8, i32 8>
  %4920 = add <4 x i32> %4919, %4894
  %4921 = add <4 x i32> %4920, %4900
  %4922 = lshr <4 x i32> %4921, <i32 4, i32 4, i32 4, i32 4>
  %4923 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4906, <8 x i16> %4906) #5
  %4924 = mul nuw <4 x i32> %4922, <i32 9, i32 9, i32 9, i32 9>
  %4925 = sub <4 x i32> %4924, %4923
  %4926 = icmp sgt <4 x i32> %4925, zeroinitializer
  %4927 = select <4 x i1> %4926, <4 x i32> %4925, <4 x i32> zeroinitializer
  %4928 = mul <4 x i32> %4927, %3726
  %4929 = add <4 x i32> %4928, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4930 = lshr <4 x i32> %4929, <i32 20, i32 20, i32 20, i32 20>
  %4931 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4918, <4 x i32> %4930) #5
  %4932 = bitcast <2 x i64> %4837 to <8 x i16>
  %4933 = shufflevector <8 x i16> %4932, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4934 = shufflevector <8 x i16> %4932, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4935 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4933, <8 x i16> %4933) #5
  %4936 = bitcast <4 x i32> %4843 to <16 x i8>
  %4937 = shufflevector <16 x i8> %4872, <16 x i8> %4936, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4938 = bitcast <16 x i8> %4937 to <4 x i32>
  %4939 = shufflevector <16 x i8> %4872, <16 x i8> %4936, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4940 = bitcast <16 x i8> %4939 to <4 x i32>
  %4941 = add <4 x i32> %4842, %4938
  %4942 = add <4 x i32> %4941, %4940
  %4943 = bitcast <4 x i32> %4935 to <16 x i8>
  %4944 = shufflevector <16 x i8> %4936, <16 x i8> %4943, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4945 = bitcast <16 x i8> %4944 to <4 x i32>
  %4946 = shufflevector <16 x i8> %4936, <16 x i8> %4943, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %4947 = bitcast <16 x i8> %4946 to <4 x i32>
  %4948 = add <4 x i32> %4843, %4945
  %4949 = add <4 x i32> %4948, %4947
  %4950 = getelementptr inbounds i32, i32* %4811, i64 %4838
  %4951 = bitcast i32* %4950 to <4 x i32>*
  store <4 x i32> %4942, <4 x i32>* %4951, align 16
  %4952 = getelementptr inbounds i32, i32* %4950, i64 4
  %4953 = bitcast i32* %4952 to <4 x i32>*
  store <4 x i32> %4949, <4 x i32>* %4953, align 16
  %4954 = add nuw nsw i64 %4838, 8
  %4955 = getelementptr inbounds i16, i16* %4809, i64 %4954
  %4956 = bitcast i16* %4955 to <8 x i16>*
  %4957 = load <8 x i16>, <8 x i16>* %4956, align 16
  %4958 = getelementptr inbounds i16, i16* %4810, i64 %4954
  %4959 = bitcast i16* %4958 to <8 x i16>*
  %4960 = load <8 x i16>, <8 x i16>* %4959, align 16
  %4961 = getelementptr inbounds i32, i32* %4707, i64 %4954
  %4962 = bitcast i32* %4961 to <4 x i32>*
  %4963 = load <4 x i32>, <4 x i32>* %4962, align 16
  %4964 = getelementptr inbounds i32, i32* %4961, i64 4
  %4965 = bitcast i32* %4964 to <4 x i32>*
  %4966 = load <4 x i32>, <4 x i32>* %4965, align 16
  %4967 = getelementptr inbounds i32, i32* %4713, i64 %4954
  %4968 = bitcast i32* %4967 to <4 x i32>*
  %4969 = load <4 x i32>, <4 x i32>* %4968, align 16
  %4970 = getelementptr inbounds i32, i32* %4967, i64 4
  %4971 = bitcast i32* %4970 to <4 x i32>*
  %4972 = load <4 x i32>, <4 x i32>* %4971, align 16
  %4973 = add <8 x i16> %4957, %4859
  %4974 = add <8 x i16> %4973, %4960
  %4975 = add <8 x i16> %4974, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4976 = lshr <8 x i16> %4975, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %4977 = shufflevector <8 x i16> %4976, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4978 = shufflevector <8 x i16> %4976, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4979 = add <4 x i32> %4942, <i32 8, i32 8, i32 8, i32 8>
  %4980 = add <4 x i32> %4979, %4963
  %4981 = add <4 x i32> %4980, %4969
  %4982 = lshr <4 x i32> %4981, <i32 4, i32 4, i32 4, i32 4>
  %4983 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4977, <8 x i16> %4977) #5
  %4984 = mul nuw <4 x i32> %4982, <i32 9, i32 9, i32 9, i32 9>
  %4985 = sub <4 x i32> %4984, %4983
  %4986 = icmp sgt <4 x i32> %4985, zeroinitializer
  %4987 = select <4 x i1> %4986, <4 x i32> %4985, <4 x i32> zeroinitializer
  %4988 = mul <4 x i32> %4987, %3726
  %4989 = add <4 x i32> %4988, <i32 524288, i32 524288, i32 524288, i32 524288>
  %4990 = lshr <4 x i32> %4989, <i32 20, i32 20, i32 20, i32 20>
  %4991 = add <4 x i32> %4949, <i32 8, i32 8, i32 8, i32 8>
  %4992 = add <4 x i32> %4991, %4966
  %4993 = add <4 x i32> %4992, %4972
  %4994 = lshr <4 x i32> %4993, <i32 4, i32 4, i32 4, i32 4>
  %4995 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4978, <8 x i16> %4978) #5
  %4996 = mul nuw <4 x i32> %4994, <i32 9, i32 9, i32 9, i32 9>
  %4997 = sub <4 x i32> %4996, %4995
  %4998 = icmp sgt <4 x i32> %4997, zeroinitializer
  %4999 = select <4 x i1> %4998, <4 x i32> %4997, <4 x i32> zeroinitializer
  %5000 = mul <4 x i32> %4999, %3726
  %5001 = add <4 x i32> %5000, <i32 524288, i32 524288, i32 524288, i32 524288>
  %5002 = lshr <4 x i32> %5001, <i32 20, i32 20, i32 20, i32 20>
  %5003 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4990, <4 x i32> %5002) #5
  %5004 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4931, <8 x i16> %5003) #5
  %5005 = icmp ult <16 x i8> %5004, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %5006 = select <16 x i1> %5005, <16 x i8> %5004, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %5007 = icmp sgt <16 x i8> %5006, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %5008 = select <16 x i1> %5007, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %5006
  %5009 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3795, <16 x i8> %5008) #5
  %5010 = add nsw <16 x i8> %5006, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %5011 = icmp sgt <16 x i8> %5010, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %5012 = select <16 x i1> %5011, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %5010
  %5013 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3796, <16 x i8> %5012) #5
  %5014 = or <16 x i8> %5013, %5009
  %5015 = add nsw <16 x i8> %5006, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %5016 = icmp sgt <16 x i8> %5015, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %5017 = select <16 x i1> %5016, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %5015
  %5018 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3797, <16 x i8> %5017) #5
  %5019 = or <16 x i8> %5014, %5018
  %5020 = xor <16 x i8> %5004, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %5021 = icmp ugt <16 x i8> %5019, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %5022 = select <16 x i1> %5021, <16 x i8> %5019, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %5023 = icmp sgt <16 x i8> %5020, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %5024 = icmp sgt <16 x i8> %5020, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %5025 = sext <16 x i1> %5024 to <16 x i8>
  %5026 = icmp sgt <16 x i8> %5020, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %5027 = icmp sgt <16 x i8> %5020, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %5028 = icmp eq <16 x i8> %5020, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %5029 = zext <16 x i1> %5023 to <16 x i8>
  %5030 = sub nsw <16 x i8> %5025, %5029
  %5031 = zext <16 x i1> %5026 to <16 x i8>
  %5032 = sub nsw <16 x i8> %5030, %5031
  %5033 = zext <16 x i1> %5027 to <16 x i8>
  %5034 = sub nsw <16 x i8> %5032, %5033
  %5035 = zext <16 x i1> %5028 to <16 x i8>
  %5036 = sub nsw <16 x i8> %5034, %5035
  %5037 = add <16 x i8> %5036, %5022
  %5038 = bitcast <16 x i8> %5037 to <2 x i64>
  %5039 = shufflevector <16 x i8> %5037, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5040 = bitcast <16 x i8> %5039 to <8 x i16>
  %5041 = shufflevector <8 x i16> %5040, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5042 = shufflevector <8 x i16> %4902, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5043 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5041, <8 x i16> %5042) #5
  %5044 = shufflevector <8 x i16> %5040, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5045 = shufflevector <8 x i16> %4902, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5046 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5044, <8 x i16> %5045) #5
  %5047 = mul <4 x i32> %5043, <i32 455, i32 455, i32 455, i32 455>
  %5048 = mul <4 x i32> %5046, <i32 455, i32 455, i32 455, i32 455>
  %5049 = add <4 x i32> %5047, <i32 2048, i32 2048, i32 2048, i32 2048>
  %5050 = lshr <4 x i32> %5049, <i32 12, i32 12, i32 12, i32 12>
  %5051 = add <4 x i32> %5048, <i32 2048, i32 2048, i32 2048, i32 2048>
  %5052 = lshr <4 x i32> %5051, <i32 12, i32 12, i32 12, i32 12>
  %5053 = shufflevector <16 x i8> %5037, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %5054 = bitcast <16 x i8> %5053 to <8 x i16>
  %5055 = shufflevector <8 x i16> %5054, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5056 = shufflevector <8 x i16> %4974, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5057 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5055, <8 x i16> %5056) #5
  %5058 = mul <4 x i32> %5057, <i32 455, i32 455, i32 455, i32 455>
  %5059 = add <4 x i32> %5058, <i32 2048, i32 2048, i32 2048, i32 2048>
  %5060 = lshr <4 x i32> %5059, <i32 12, i32 12, i32 12, i32 12>
  %5061 = shufflevector <2 x i64> %4829, <2 x i64> %5038, <2 x i32> <i32 0, i32 2>
  %5062 = shufflevector <16 x i8> %5037, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5063 = bitcast <2 x i64> %5061 to <16 x i8>
  %5064 = shufflevector <16 x i8> %5063, <16 x i8> %5062, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %5065 = shufflevector <16 x i8> %5063, <16 x i8> %5062, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5066 = shufflevector <16 x i8> %5063, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5067 = shufflevector <16 x i8> %5064, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5068 = bitcast <16 x i8> %5066 to <8 x i16>
  %5069 = bitcast <16 x i8> %5067 to <8 x i16>
  %5070 = add <8 x i16> %5069, %5068
  %5071 = shufflevector <16 x i8> %5065, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5072 = bitcast <16 x i8> %5071 to <8 x i16>
  %5073 = add <8 x i16> %5070, %5072
  %5074 = shl <8 x i16> %5073, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5075 = getelementptr inbounds i16, i16* %4802, i64 %4819
  %5076 = bitcast i16* %5075 to <8 x i16>*
  store <8 x i16> %5074, <8 x i16>* %5076, align 16
  %5077 = mul <8 x i16> %5073, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %5078 = add <8 x i16> %5077, %5069
  %5079 = getelementptr inbounds i16, i16* %4812, i64 %4819
  %5080 = bitcast i16* %5079 to <8 x i16>*
  store <8 x i16> %5078, <8 x i16>* %5080, align 16
  %5081 = bitcast <4 x i32> %4828 to <16 x i8>
  %5082 = bitcast <4 x i32> %4825 to <16 x i8>
  %5083 = shufflevector <16 x i8> %5082, <16 x i8> %5081, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5084 = shufflevector <16 x i8> %5082, <16 x i8> %5081, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5085 = bitcast <16 x i8> %5084 to <4 x i32>
  %5086 = bitcast <16 x i8> %5083 to <4 x i32>
  %5087 = add <4 x i32> %4825, %5086
  %5088 = add <4 x i32> %5087, %5085
  %5089 = shl <4 x i32> %5088, <i32 2, i32 2, i32 2, i32 2>
  %5090 = mul <4 x i32> %5088, <i32 3, i32 3, i32 3, i32 3>
  %5091 = add <4 x i32> %5090, %5086
  %5092 = bitcast <4 x i32> %5050 to <16 x i8>
  %5093 = shufflevector <16 x i8> %5081, <16 x i8> %5092, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5094 = shufflevector <16 x i8> %5081, <16 x i8> %5092, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5095 = bitcast <16 x i8> %5094 to <4 x i32>
  %5096 = bitcast <16 x i8> %5093 to <4 x i32>
  %5097 = add <4 x i32> %4828, %5096
  %5098 = add <4 x i32> %5097, %5095
  %5099 = shl <4 x i32> %5098, <i32 2, i32 2, i32 2, i32 2>
  %5100 = mul <4 x i32> %5098, <i32 3, i32 3, i32 3, i32 3>
  %5101 = add <4 x i32> %5100, %5096
  %5102 = getelementptr inbounds i32, i32* %4803, i64 %4819
  %5103 = bitcast i32* %5102 to <4 x i32>*
  store <4 x i32> %5089, <4 x i32>* %5103, align 16
  %5104 = getelementptr inbounds i32, i32* %5102, i64 4
  %5105 = bitcast i32* %5104 to <4 x i32>*
  store <4 x i32> %5099, <4 x i32>* %5105, align 16
  %5106 = getelementptr inbounds i32, i32* %4813, i64 %4819
  %5107 = bitcast i32* %5106 to <4 x i32>*
  store <4 x i32> %5091, <4 x i32>* %5107, align 16
  %5108 = getelementptr inbounds i32, i32* %5106, i64 4
  %5109 = bitcast i32* %5108 to <4 x i32>*
  store <4 x i32> %5101, <4 x i32>* %5109, align 16
  %5110 = getelementptr inbounds i16, i16* %4659, i64 %4819
  %5111 = bitcast i16* %5110 to <8 x i16>*
  %5112 = load <8 x i16>, <8 x i16>* %5111, align 16
  %5113 = getelementptr inbounds i16, i16* %4814, i64 %4819
  %5114 = bitcast i16* %5113 to <8 x i16>*
  %5115 = load <8 x i16>, <8 x i16>* %5114, align 16
  %5116 = getelementptr inbounds i16, i16* %4804, i64 %4819
  %5117 = bitcast i16* %5116 to <8 x i16>*
  %5118 = load <8 x i16>, <8 x i16>* %5117, align 16
  %5119 = getelementptr inbounds i32, i32* %4815, i64 %4819
  %5120 = bitcast i32* %5119 to <4 x i32>*
  %5121 = load <4 x i32>, <4 x i32>* %5120, align 16
  %5122 = getelementptr inbounds i32, i32* %5119, i64 4
  %5123 = bitcast i32* %5122 to <4 x i32>*
  %5124 = load <4 x i32>, <4 x i32>* %5123, align 16
  %5125 = getelementptr inbounds i32, i32* %4805, i64 %4819
  %5126 = bitcast i32* %5125 to <4 x i32>*
  %5127 = load <4 x i32>, <4 x i32>* %5126, align 16
  %5128 = getelementptr inbounds i32, i32* %5125, i64 4
  %5129 = bitcast i32* %5128 to <4 x i32>*
  %5130 = load <4 x i32>, <4 x i32>* %5129, align 16
  %5131 = add <8 x i16> %5118, %5115
  %5132 = add <8 x i16> %5131, %5078
  %5133 = shufflevector <8 x i16> %5132, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5134 = shufflevector <8 x i16> %5112, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5135 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5133, <8 x i16> %5134) #5
  %5136 = shufflevector <8 x i16> %5132, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5137 = shufflevector <8 x i16> %5112, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5138 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5136, <8 x i16> %5137) #5
  %5139 = add <4 x i32> %5091, <i32 256, i32 256, i32 256, i32 256>
  %5140 = add <4 x i32> %5139, %5121
  %5141 = add <4 x i32> %5140, %5127
  %5142 = sub <4 x i32> %5141, %5135
  %5143 = ashr <4 x i32> %5142, <i32 9, i32 9, i32 9, i32 9>
  %5144 = add <4 x i32> %5101, <i32 256, i32 256, i32 256, i32 256>
  %5145 = add <4 x i32> %5144, %5124
  %5146 = add <4 x i32> %5145, %5130
  %5147 = sub <4 x i32> %5146, %5138
  %5148 = ashr <4 x i32> %5147, <i32 9, i32 9, i32 9, i32 9>
  %5149 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5143, <4 x i32> %5148) #5
  %5150 = shufflevector <16 x i8> %5063, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %5151 = shufflevector <16 x i8> %5064, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %5152 = bitcast <16 x i8> %5150 to <8 x i16>
  %5153 = bitcast <16 x i8> %5151 to <8 x i16>
  %5154 = add <8 x i16> %5153, %5152
  %5155 = shufflevector <16 x i8> %5065, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %5156 = bitcast <16 x i8> %5155 to <8 x i16>
  %5157 = add <8 x i16> %5154, %5156
  %5158 = shl <8 x i16> %5157, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5159 = getelementptr inbounds i16, i16* %4802, i64 %4838
  %5160 = bitcast i16* %5159 to <8 x i16>*
  store <8 x i16> %5158, <8 x i16>* %5160, align 16
  %5161 = mul <8 x i16> %5157, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %5162 = add <8 x i16> %5161, %5153
  %5163 = getelementptr inbounds i16, i16* %4812, i64 %4838
  %5164 = bitcast i16* %5163 to <8 x i16>*
  store <8 x i16> %5162, <8 x i16>* %5164, align 16
  %5165 = bitcast <4 x i32> %5052 to <16 x i8>
  %5166 = shufflevector <16 x i8> %5092, <16 x i8> %5165, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5167 = shufflevector <16 x i8> %5092, <16 x i8> %5165, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5168 = bitcast <16 x i8> %5167 to <4 x i32>
  %5169 = bitcast <16 x i8> %5166 to <4 x i32>
  %5170 = add <4 x i32> %5050, %5169
  %5171 = add <4 x i32> %5170, %5168
  %5172 = shl <4 x i32> %5171, <i32 2, i32 2, i32 2, i32 2>
  %5173 = mul <4 x i32> %5171, <i32 3, i32 3, i32 3, i32 3>
  %5174 = add <4 x i32> %5173, %5169
  %5175 = bitcast <4 x i32> %5060 to <16 x i8>
  %5176 = shufflevector <16 x i8> %5165, <16 x i8> %5175, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5177 = shufflevector <16 x i8> %5165, <16 x i8> %5175, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5178 = bitcast <16 x i8> %5177 to <4 x i32>
  %5179 = bitcast <16 x i8> %5176 to <4 x i32>
  %5180 = add <4 x i32> %5052, %5179
  %5181 = add <4 x i32> %5180, %5178
  %5182 = shl <4 x i32> %5181, <i32 2, i32 2, i32 2, i32 2>
  %5183 = mul <4 x i32> %5181, <i32 3, i32 3, i32 3, i32 3>
  %5184 = add <4 x i32> %5183, %5179
  %5185 = getelementptr inbounds i32, i32* %4803, i64 %4838
  %5186 = bitcast i32* %5185 to <4 x i32>*
  store <4 x i32> %5172, <4 x i32>* %5186, align 16
  %5187 = getelementptr inbounds i32, i32* %5185, i64 4
  %5188 = bitcast i32* %5187 to <4 x i32>*
  store <4 x i32> %5182, <4 x i32>* %5188, align 16
  %5189 = getelementptr inbounds i32, i32* %4813, i64 %4838
  %5190 = bitcast i32* %5189 to <4 x i32>*
  store <4 x i32> %5174, <4 x i32>* %5190, align 16
  %5191 = getelementptr inbounds i32, i32* %5189, i64 4
  %5192 = bitcast i32* %5191 to <4 x i32>*
  store <4 x i32> %5184, <4 x i32>* %5192, align 16
  %5193 = getelementptr inbounds i16, i16* %5110, i64 8
  %5194 = bitcast i16* %5193 to <8 x i16>*
  %5195 = load <8 x i16>, <8 x i16>* %5194, align 16
  %5196 = getelementptr inbounds i16, i16* %4816, i64 %4819
  %5197 = bitcast i16* %5196 to <8 x i16>*
  %5198 = load <8 x i16>, <8 x i16>* %5197, align 16
  %5199 = getelementptr inbounds i16, i16* %4806, i64 %4819
  %5200 = bitcast i16* %5199 to <8 x i16>*
  %5201 = load <8 x i16>, <8 x i16>* %5200, align 16
  %5202 = getelementptr inbounds i32, i32* %4817, i64 %4819
  %5203 = bitcast i32* %5202 to <4 x i32>*
  %5204 = load <4 x i32>, <4 x i32>* %5203, align 16
  %5205 = getelementptr inbounds i32, i32* %5202, i64 4
  %5206 = bitcast i32* %5205 to <4 x i32>*
  %5207 = load <4 x i32>, <4 x i32>* %5206, align 16
  %5208 = getelementptr inbounds i32, i32* %4807, i64 %4819
  %5209 = bitcast i32* %5208 to <4 x i32>*
  %5210 = load <4 x i32>, <4 x i32>* %5209, align 16
  %5211 = getelementptr inbounds i32, i32* %5208, i64 4
  %5212 = bitcast i32* %5211 to <4 x i32>*
  %5213 = load <4 x i32>, <4 x i32>* %5212, align 16
  %5214 = add <8 x i16> %5198, %5162
  %5215 = add <8 x i16> %5214, %5201
  %5216 = shufflevector <8 x i16> %5215, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5217 = shufflevector <8 x i16> %5195, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5218 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5216, <8 x i16> %5217) #5
  %5219 = shufflevector <8 x i16> %5215, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5220 = shufflevector <8 x i16> %5195, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5221 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5219, <8 x i16> %5220) #5
  %5222 = add <4 x i32> %5174, <i32 256, i32 256, i32 256, i32 256>
  %5223 = add <4 x i32> %5222, %5204
  %5224 = add <4 x i32> %5223, %5210
  %5225 = sub <4 x i32> %5224, %5218
  %5226 = ashr <4 x i32> %5225, <i32 9, i32 9, i32 9, i32 9>
  %5227 = add <4 x i32> %5184, <i32 256, i32 256, i32 256, i32 256>
  %5228 = add <4 x i32> %5227, %5207
  %5229 = add <4 x i32> %5228, %5213
  %5230 = sub <4 x i32> %5229, %5221
  %5231 = ashr <4 x i32> %5230, <i32 9, i32 9, i32 9, i32 9>
  %5232 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5226, <4 x i32> %5231) #5
  %5233 = shufflevector <8 x i16> %5149, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5234 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5233, <8 x i16> %4615) #5
  %5235 = shufflevector <8 x i16> %5149, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5236 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5235, <8 x i16> %4615) #5
  %5237 = add <4 x i32> %5234, <i32 1024, i32 1024, i32 1024, i32 1024>
  %5238 = ashr <4 x i32> %5237, <i32 11, i32 11, i32 11, i32 11>
  %5239 = add <4 x i32> %5236, <i32 1024, i32 1024, i32 1024, i32 1024>
  %5240 = ashr <4 x i32> %5239, <i32 11, i32 11, i32 11, i32 11>
  %5241 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5238, <4 x i32> %5240) #5
  %5242 = add <8 x i16> %5241, %5112
  %5243 = shufflevector <8 x i16> %5232, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5244 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5243, <8 x i16> %4615) #5
  %5245 = shufflevector <8 x i16> %5232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5246 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5245, <8 x i16> %4615) #5
  %5247 = add <4 x i32> %5244, <i32 1024, i32 1024, i32 1024, i32 1024>
  %5248 = ashr <4 x i32> %5247, <i32 11, i32 11, i32 11, i32 11>
  %5249 = add <4 x i32> %5246, <i32 1024, i32 1024, i32 1024, i32 1024>
  %5250 = ashr <4 x i32> %5249, <i32 11, i32 11, i32 11, i32 11>
  %5251 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5248, <4 x i32> %5250) #5
  %5252 = add <8 x i16> %5251, %5195
  %5253 = getelementptr inbounds i16, i16* %4654, i64 %4819
  %5254 = icmp sgt <8 x i16> %5242, zeroinitializer
  %5255 = select <8 x i1> %5254, <8 x i16> %5242, <8 x i16> zeroinitializer
  %5256 = icmp slt <8 x i16> %5255, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %5257 = select <8 x i1> %5256, <8 x i16> %5255, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %5258 = bitcast i16* %5253 to <8 x i16>*
  store <8 x i16> %5257, <8 x i16>* %5258, align 16
  %5259 = getelementptr inbounds i16, i16* %5253, i64 8
  %5260 = icmp sgt <8 x i16> %5252, zeroinitializer
  %5261 = select <8 x i1> %5260, <8 x i16> %5252, <8 x i16> zeroinitializer
  %5262 = icmp slt <8 x i16> %5261, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %5263 = select <8 x i1> %5262, <8 x i16> %5261, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %5264 = bitcast i16* %5259 to <8 x i16>*
  store <8 x i16> %5263, <8 x i16>* %5264, align 16
  %5265 = icmp slt i64 %4832, %3506
  br i1 %5265, label %5266, label %5271

5266:                                             ; preds = %4818
  %5267 = shufflevector <8 x i16> %5054, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5268 = shufflevector <8 x i16> %4974, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5269 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5267, <8 x i16> %5268) #5
  %5270 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %4934, <8 x i16> %4934) #5
  br label %4818

5271:                                             ; preds = %4818
  %5272 = getelementptr inbounds i16, i16* %4653, i64 %2
  %5273 = getelementptr inbounds i16, i16* %4654, i64 %2
  %5274 = add nsw i32 %4652, -1
  %5275 = icmp sgt i32 %5274, 0
  br i1 %5275, label %4639, label %4616

5276:                                             ; preds = %5907, %4616
  %5277 = phi i64 [ %4617, %4616 ], [ %5278, %5907 ]
  %5278 = phi i64 [ %4618, %4616 ], [ %5279, %5907 ]
  %5279 = phi i64 [ %4619, %4616 ], [ %5277, %5907 ]
  %5280 = phi i64 [ %4620, %4616 ], [ %5281, %5907 ]
  %5281 = phi i64 [ %4621, %4616 ], [ %5282, %5907 ]
  %5282 = phi i64 [ %4622, %4616 ], [ %5280, %5907 ]
  %5283 = phi i64 [ %4623, %4616 ], [ %5285, %5907 ]
  %5284 = phi i64 [ %4624, %4616 ], [ %5283, %5907 ]
  %5285 = phi i64 [ %4625, %4616 ], [ %5284, %5907 ]
  %5286 = phi i64 [ %4626, %4616 ], [ %5288, %5907 ]
  %5287 = phi i64 [ %4627, %4616 ], [ %5286, %5907 ]
  %5288 = phi i64 [ %4628, %4616 ], [ %5287, %5907 ]
  %5289 = phi i64 [ %4630, %4616 ], [ %5292, %5907 ]
  %5290 = phi i64 [ %4631, %4616 ], [ %5291, %5907 ]
  %5291 = phi i64 [ %4632, %4616 ], [ %5290, %5907 ]
  %5292 = phi i64 [ %4633, %4616 ], [ %5289, %5907 ]
  %5293 = phi i16* [ %4634, %4616 ], [ %5909, %5907 ]
  %5294 = phi i16* [ %4602, %4616 ], [ %5910, %5907 ]
  %5295 = phi i16* [ %4638, %4616 ], [ %5908, %5907 ]
  %5296 = phi i32 [ %4637, %4616 ], [ %5911, %5907 ]
  %5297 = bitcast i16* %5294 to <8 x i16>*
  %5298 = load <8 x i16>, <8 x i16>* %5297, align 1
  %5299 = getelementptr inbounds i16, i16* %5294, i64 8
  %5300 = bitcast i16* %5299 to <2 x i64>*
  %5301 = load <2 x i64>, <2 x i64>* %5300, align 1
  %5302 = shufflevector <8 x i16> %5298, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5303 = shufflevector <8 x i16> %5298, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5304 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5302, <8 x i16> %5302) #5
  %5305 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5303, <8 x i16> %5303) #5
  %5306 = bitcast <2 x i64> %5301 to <8 x i16>
  %5307 = shufflevector <8 x i16> %5306, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5308 = shufflevector <8 x i16> %5306, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5309 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5307, <8 x i16> %5307) #5
  %5310 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5308, <8 x i16> %5308) #5
  %5311 = bitcast <2 x i64> %5301 to <16 x i8>
  %5312 = bitcast <8 x i16> %5298 to <16 x i8>
  %5313 = shufflevector <16 x i8> %5312, <16 x i8> %5311, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5314 = bitcast <16 x i8> %5313 to <8 x i16>
  %5315 = shufflevector <16 x i8> %5312, <16 x i8> %5311, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5316 = bitcast <16 x i8> %5315 to <8 x i16>
  %5317 = add <8 x i16> %5298, %5314
  %5318 = add <8 x i16> %5317, %5316
  %5319 = inttoptr i64 %5285 to <8 x i16>*
  store <8 x i16> %5318, <8 x i16>* %5319, align 16
  %5320 = bitcast <4 x i32> %5305 to <16 x i8>
  %5321 = bitcast <4 x i32> %5304 to <16 x i8>
  %5322 = shufflevector <16 x i8> %5321, <16 x i8> %5320, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5323 = bitcast <16 x i8> %5322 to <4 x i32>
  %5324 = shufflevector <16 x i8> %5321, <16 x i8> %5320, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5325 = bitcast <16 x i8> %5324 to <4 x i32>
  %5326 = add <4 x i32> %5304, %5323
  %5327 = add <4 x i32> %5326, %5325
  %5328 = bitcast <4 x i32> %5309 to <16 x i8>
  %5329 = shufflevector <16 x i8> %5320, <16 x i8> %5328, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5330 = bitcast <16 x i8> %5329 to <4 x i32>
  %5331 = shufflevector <16 x i8> %5320, <16 x i8> %5328, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5332 = bitcast <16 x i8> %5331 to <4 x i32>
  %5333 = add <4 x i32> %5305, %5330
  %5334 = add <4 x i32> %5333, %5332
  %5335 = inttoptr i64 %5288 to i32*
  %5336 = inttoptr i64 %5288 to <4 x i32>*
  store <4 x i32> %5327, <4 x i32>* %5336, align 16
  %5337 = getelementptr inbounds i32, i32* %5335, i64 4
  %5338 = bitcast i32* %5337 to <4 x i32>*
  store <4 x i32> %5334, <4 x i32>* %5338, align 16
  %5339 = inttoptr i64 %5284 to <8 x i16>*
  %5340 = load <8 x i16>, <8 x i16>* %5339, align 16
  %5341 = inttoptr i64 %5283 to <8 x i16>*
  %5342 = load <8 x i16>, <8 x i16>* %5341, align 16
  %5343 = inttoptr i64 %5287 to i32*
  %5344 = inttoptr i64 %5287 to <4 x i32>*
  %5345 = load <4 x i32>, <4 x i32>* %5344, align 16
  %5346 = getelementptr inbounds i32, i32* %5343, i64 4
  %5347 = bitcast i32* %5346 to <4 x i32>*
  %5348 = load <4 x i32>, <4 x i32>* %5347, align 16
  %5349 = inttoptr i64 %5286 to i32*
  %5350 = inttoptr i64 %5286 to <4 x i32>*
  %5351 = load <4 x i32>, <4 x i32>* %5350, align 16
  %5352 = getelementptr inbounds i32, i32* %5349, i64 4
  %5353 = bitcast i32* %5352 to <4 x i32>*
  %5354 = load <4 x i32>, <4 x i32>* %5353, align 16
  %5355 = add <8 x i16> %5340, %5318
  %5356 = add <8 x i16> %5355, %5342
  %5357 = add <8 x i16> %5356, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5358 = lshr <8 x i16> %5357, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5359 = shufflevector <8 x i16> %5358, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5360 = shufflevector <8 x i16> %5358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5361 = add <4 x i32> %5327, <i32 8, i32 8, i32 8, i32 8>
  %5362 = add <4 x i32> %5361, %5345
  %5363 = add <4 x i32> %5362, %5351
  %5364 = lshr <4 x i32> %5363, <i32 4, i32 4, i32 4, i32 4>
  %5365 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5359, <8 x i16> %5359) #5
  %5366 = mul nuw <4 x i32> %5364, <i32 9, i32 9, i32 9, i32 9>
  %5367 = sub <4 x i32> %5366, %5365
  %5368 = icmp sgt <4 x i32> %5367, zeroinitializer
  %5369 = select <4 x i1> %5368, <4 x i32> %5367, <4 x i32> zeroinitializer
  %5370 = mul <4 x i32> %5369, %3726
  %5371 = add <4 x i32> %5370, <i32 524288, i32 524288, i32 524288, i32 524288>
  %5372 = lshr <4 x i32> %5371, <i32 20, i32 20, i32 20, i32 20>
  %5373 = add <4 x i32> %5334, <i32 8, i32 8, i32 8, i32 8>
  %5374 = add <4 x i32> %5373, %5348
  %5375 = add <4 x i32> %5374, %5354
  %5376 = lshr <4 x i32> %5375, <i32 4, i32 4, i32 4, i32 4>
  %5377 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5360, <8 x i16> %5360) #5
  %5378 = mul nuw <4 x i32> %5376, <i32 9, i32 9, i32 9, i32 9>
  %5379 = sub <4 x i32> %5378, %5377
  %5380 = icmp sgt <4 x i32> %5379, zeroinitializer
  %5381 = select <4 x i1> %5380, <4 x i32> %5379, <4 x i32> zeroinitializer
  %5382 = mul <4 x i32> %5381, %3726
  %5383 = add <4 x i32> %5382, <i32 524288, i32 524288, i32 524288, i32 524288>
  %5384 = lshr <4 x i32> %5383, <i32 20, i32 20, i32 20, i32 20>
  %5385 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %5372, <4 x i32> %5384) #5
  %5386 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5385, <8 x i16> undef) #5
  %5387 = bitcast <16 x i8> %5386 to <2 x i64>
  %5388 = extractelement <2 x i64> %5387, i32 0
  %5389 = lshr i64 %5388, 8
  %5390 = lshr i64 %5388, 16
  %5391 = lshr i64 %5388, 24
  %5392 = lshr i64 %5388, 32
  %5393 = lshr i64 %5388, 40
  %5394 = lshr i64 %5388, 48
  %5395 = lshr i64 %5388, 56
  %5396 = and i64 %5388, 255
  %5397 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %5396
  %5398 = load i8, i8* %5397, align 1
  %5399 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %5398, i64 0
  %5400 = and i64 %5389, 255
  %5401 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %5400
  %5402 = load i8, i8* %5401, align 1
  %5403 = insertelement <16 x i8> %5399, i8 %5402, i64 1
  %5404 = and i64 %5390, 255
  %5405 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %5404
  %5406 = load i8, i8* %5405, align 1
  %5407 = insertelement <16 x i8> %5403, i8 %5406, i64 2
  %5408 = and i64 %5391, 255
  %5409 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %5408
  %5410 = load i8, i8* %5409, align 1
  %5411 = insertelement <16 x i8> %5407, i8 %5410, i64 3
  %5412 = and i64 %5392, 255
  %5413 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %5412
  %5414 = load i8, i8* %5413, align 1
  %5415 = insertelement <16 x i8> %5411, i8 %5414, i64 4
  %5416 = and i64 %5393, 255
  %5417 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %5416
  %5418 = load i8, i8* %5417, align 1
  %5419 = insertelement <16 x i8> %5415, i8 %5418, i64 5
  %5420 = and i64 %5394, 255
  %5421 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %5420
  %5422 = load i8, i8* %5421, align 1
  %5423 = insertelement <16 x i8> %5419, i8 %5422, i64 6
  %5424 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %5395
  %5425 = load i8, i8* %5424, align 1
  %5426 = insertelement <16 x i8> %5423, i8 %5425, i64 7
  %5427 = shufflevector <16 x i8> %5426, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5428 = bitcast <16 x i8> %5427 to <8 x i16>
  %5429 = shufflevector <8 x i16> %5428, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5430 = shufflevector <8 x i16> %5356, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5431 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5429, <8 x i16> %5430) #5
  %5432 = shufflevector <8 x i16> %5428, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5433 = shufflevector <8 x i16> %5356, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5434 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5432, <8 x i16> %5433) #5
  %5435 = mul <4 x i32> %5431, <i32 455, i32 455, i32 455, i32 455>
  %5436 = add <4 x i32> %5435, <i32 2048, i32 2048, i32 2048, i32 2048>
  %5437 = lshr <4 x i32> %5436, <i32 12, i32 12, i32 12, i32 12>
  %5438 = inttoptr i64 %5292 to i16*
  %5439 = inttoptr i64 %5290 to i32*
  %5440 = inttoptr i64 %5289 to i16*
  %5441 = inttoptr i64 %5291 to i32*
  %5442 = getelementptr inbounds i16, i16* %5440, i64 8
  %5443 = getelementptr inbounds i32, i32* %5441, i64 8
  %5444 = inttoptr i64 %5285 to i16*
  %5445 = inttoptr i64 %5284 to i16*
  %5446 = inttoptr i64 %5283 to i16*
  %5447 = getelementptr inbounds i32, i32* %5335, i64 8
  %5448 = inttoptr i64 %5279 to i16*
  %5449 = inttoptr i64 %5282 to i32*
  %5450 = inttoptr i64 %5277 to i16*
  %5451 = inttoptr i64 %5280 to i32*
  %5452 = getelementptr inbounds i16, i16* %5450, i64 8
  %5453 = getelementptr inbounds i32, i32* %5451, i64 8
  br label %5454

5454:                                             ; preds = %5902, %5276
  %5455 = phi i64 [ %5468, %5902 ], [ 0, %5276 ]
  %5456 = phi <2 x i64> [ %5473, %5902 ], [ %5301, %5276 ]
  %5457 = phi <16 x i8> [ %5698, %5902 ], [ %5426, %5276 ]
  %5458 = phi <4 x i32> [ %5906, %5902 ], [ %5310, %5276 ]
  %5459 = phi <4 x i32> [ %5571, %5902 ], [ %5309, %5276 ]
  %5460 = phi <4 x i32> [ %5905, %5902 ], [ %5434, %5276 ]
  %5461 = phi <4 x i32> [ %5696, %5902 ], [ %5437, %5276 ]
  %5462 = mul <4 x i32> %5460, <i32 455, i32 455, i32 455, i32 455>
  %5463 = add <4 x i32> %5462, <i32 2048, i32 2048, i32 2048, i32 2048>
  %5464 = lshr <4 x i32> %5463, <i32 12, i32 12, i32 12, i32 12>
  %5465 = bitcast <16 x i8> %5457 to <2 x i64>
  %5466 = getelementptr inbounds i16, i16* %5294, i64 %5455
  %5467 = getelementptr inbounds i16, i16* %5466, i64 16
  %5468 = add nuw nsw i64 %5455, 16
  %5469 = bitcast i16* %5467 to <2 x i64>*
  %5470 = load <2 x i64>, <2 x i64>* %5469, align 1
  %5471 = getelementptr inbounds i16, i16* %5466, i64 24
  %5472 = bitcast i16* %5471 to <2 x i64>*
  %5473 = load <2 x i64>, <2 x i64>* %5472, align 1
  %5474 = or i64 %5455, 8
  %5475 = bitcast <2 x i64> %5470 to <8 x i16>
  %5476 = shufflevector <8 x i16> %5475, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5477 = shufflevector <8 x i16> %5475, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5478 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5476, <8 x i16> %5476) #5
  %5479 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5477, <8 x i16> %5477) #5
  %5480 = bitcast <2 x i64> %5456 to <8 x i16>
  %5481 = bitcast <2 x i64> %5470 to <16 x i8>
  %5482 = bitcast <2 x i64> %5456 to <16 x i8>
  %5483 = shufflevector <16 x i8> %5482, <16 x i8> %5481, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5484 = bitcast <16 x i8> %5483 to <8 x i16>
  %5485 = shufflevector <16 x i8> %5482, <16 x i8> %5481, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5486 = bitcast <16 x i8> %5485 to <8 x i16>
  %5487 = add <8 x i16> %5484, %5480
  %5488 = add <8 x i16> %5487, %5486
  %5489 = bitcast <2 x i64> %5473 to <16 x i8>
  %5490 = shufflevector <16 x i8> %5481, <16 x i8> %5489, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5491 = bitcast <16 x i8> %5490 to <8 x i16>
  %5492 = shufflevector <16 x i8> %5481, <16 x i8> %5489, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5493 = bitcast <16 x i8> %5492 to <8 x i16>
  %5494 = add <8 x i16> %5491, %5475
  %5495 = add <8 x i16> %5494, %5493
  %5496 = getelementptr inbounds i16, i16* %5444, i64 %5474
  %5497 = bitcast i16* %5496 to <8 x i16>*
  store <8 x i16> %5488, <8 x i16>* %5497, align 16
  %5498 = getelementptr inbounds i16, i16* %5496, i64 8
  %5499 = bitcast i16* %5498 to <8 x i16>*
  store <8 x i16> %5495, <8 x i16>* %5499, align 16
  %5500 = bitcast <4 x i32> %5458 to <16 x i8>
  %5501 = bitcast <4 x i32> %5459 to <16 x i8>
  %5502 = shufflevector <16 x i8> %5501, <16 x i8> %5500, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5503 = bitcast <16 x i8> %5502 to <4 x i32>
  %5504 = shufflevector <16 x i8> %5501, <16 x i8> %5500, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5505 = bitcast <16 x i8> %5504 to <4 x i32>
  %5506 = add <4 x i32> %5459, %5503
  %5507 = add <4 x i32> %5506, %5505
  %5508 = bitcast <4 x i32> %5478 to <16 x i8>
  %5509 = shufflevector <16 x i8> %5500, <16 x i8> %5508, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5510 = bitcast <16 x i8> %5509 to <4 x i32>
  %5511 = shufflevector <16 x i8> %5500, <16 x i8> %5508, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5512 = bitcast <16 x i8> %5511 to <4 x i32>
  %5513 = add <4 x i32> %5458, %5510
  %5514 = add <4 x i32> %5513, %5512
  %5515 = getelementptr inbounds i32, i32* %5335, i64 %5474
  %5516 = bitcast i32* %5515 to <4 x i32>*
  store <4 x i32> %5507, <4 x i32>* %5516, align 16
  %5517 = getelementptr inbounds i32, i32* %5515, i64 4
  %5518 = bitcast i32* %5517 to <4 x i32>*
  store <4 x i32> %5514, <4 x i32>* %5518, align 16
  %5519 = getelementptr inbounds i16, i16* %5445, i64 %5474
  %5520 = bitcast i16* %5519 to <8 x i16>*
  %5521 = load <8 x i16>, <8 x i16>* %5520, align 16
  %5522 = getelementptr inbounds i16, i16* %5446, i64 %5474
  %5523 = bitcast i16* %5522 to <8 x i16>*
  %5524 = load <8 x i16>, <8 x i16>* %5523, align 16
  %5525 = getelementptr inbounds i32, i32* %5343, i64 %5474
  %5526 = bitcast i32* %5525 to <4 x i32>*
  %5527 = load <4 x i32>, <4 x i32>* %5526, align 16
  %5528 = getelementptr inbounds i32, i32* %5525, i64 4
  %5529 = bitcast i32* %5528 to <4 x i32>*
  %5530 = load <4 x i32>, <4 x i32>* %5529, align 16
  %5531 = getelementptr inbounds i32, i32* %5349, i64 %5474
  %5532 = bitcast i32* %5531 to <4 x i32>*
  %5533 = load <4 x i32>, <4 x i32>* %5532, align 16
  %5534 = getelementptr inbounds i32, i32* %5531, i64 4
  %5535 = bitcast i32* %5534 to <4 x i32>*
  %5536 = load <4 x i32>, <4 x i32>* %5535, align 16
  %5537 = add <8 x i16> %5521, %5488
  %5538 = add <8 x i16> %5537, %5524
  %5539 = add <8 x i16> %5538, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5540 = lshr <8 x i16> %5539, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5541 = shufflevector <8 x i16> %5540, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5542 = shufflevector <8 x i16> %5540, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5543 = add <4 x i32> %5507, <i32 8, i32 8, i32 8, i32 8>
  %5544 = add <4 x i32> %5543, %5527
  %5545 = add <4 x i32> %5544, %5533
  %5546 = lshr <4 x i32> %5545, <i32 4, i32 4, i32 4, i32 4>
  %5547 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5541, <8 x i16> %5541) #5
  %5548 = mul nuw <4 x i32> %5546, <i32 9, i32 9, i32 9, i32 9>
  %5549 = sub <4 x i32> %5548, %5547
  %5550 = icmp sgt <4 x i32> %5549, zeroinitializer
  %5551 = select <4 x i1> %5550, <4 x i32> %5549, <4 x i32> zeroinitializer
  %5552 = mul <4 x i32> %5551, %3726
  %5553 = add <4 x i32> %5552, <i32 524288, i32 524288, i32 524288, i32 524288>
  %5554 = lshr <4 x i32> %5553, <i32 20, i32 20, i32 20, i32 20>
  %5555 = add <4 x i32> %5514, <i32 8, i32 8, i32 8, i32 8>
  %5556 = add <4 x i32> %5555, %5530
  %5557 = add <4 x i32> %5556, %5536
  %5558 = lshr <4 x i32> %5557, <i32 4, i32 4, i32 4, i32 4>
  %5559 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5542, <8 x i16> %5542) #5
  %5560 = mul nuw <4 x i32> %5558, <i32 9, i32 9, i32 9, i32 9>
  %5561 = sub <4 x i32> %5560, %5559
  %5562 = icmp sgt <4 x i32> %5561, zeroinitializer
  %5563 = select <4 x i1> %5562, <4 x i32> %5561, <4 x i32> zeroinitializer
  %5564 = mul <4 x i32> %5563, %3726
  %5565 = add <4 x i32> %5564, <i32 524288, i32 524288, i32 524288, i32 524288>
  %5566 = lshr <4 x i32> %5565, <i32 20, i32 20, i32 20, i32 20>
  %5567 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %5554, <4 x i32> %5566) #5
  %5568 = bitcast <2 x i64> %5473 to <8 x i16>
  %5569 = shufflevector <8 x i16> %5568, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5570 = shufflevector <8 x i16> %5568, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5571 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5569, <8 x i16> %5569) #5
  %5572 = bitcast <4 x i32> %5479 to <16 x i8>
  %5573 = shufflevector <16 x i8> %5508, <16 x i8> %5572, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5574 = bitcast <16 x i8> %5573 to <4 x i32>
  %5575 = shufflevector <16 x i8> %5508, <16 x i8> %5572, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5576 = bitcast <16 x i8> %5575 to <4 x i32>
  %5577 = add <4 x i32> %5478, %5574
  %5578 = add <4 x i32> %5577, %5576
  %5579 = bitcast <4 x i32> %5571 to <16 x i8>
  %5580 = shufflevector <16 x i8> %5572, <16 x i8> %5579, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5581 = bitcast <16 x i8> %5580 to <4 x i32>
  %5582 = shufflevector <16 x i8> %5572, <16 x i8> %5579, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5583 = bitcast <16 x i8> %5582 to <4 x i32>
  %5584 = add <4 x i32> %5479, %5581
  %5585 = add <4 x i32> %5584, %5583
  %5586 = getelementptr inbounds i32, i32* %5447, i64 %5474
  %5587 = bitcast i32* %5586 to <4 x i32>*
  store <4 x i32> %5578, <4 x i32>* %5587, align 16
  %5588 = getelementptr inbounds i32, i32* %5586, i64 4
  %5589 = bitcast i32* %5588 to <4 x i32>*
  store <4 x i32> %5585, <4 x i32>* %5589, align 16
  %5590 = add nuw nsw i64 %5474, 8
  %5591 = getelementptr inbounds i16, i16* %5445, i64 %5590
  %5592 = bitcast i16* %5591 to <8 x i16>*
  %5593 = load <8 x i16>, <8 x i16>* %5592, align 16
  %5594 = getelementptr inbounds i16, i16* %5446, i64 %5590
  %5595 = bitcast i16* %5594 to <8 x i16>*
  %5596 = load <8 x i16>, <8 x i16>* %5595, align 16
  %5597 = getelementptr inbounds i32, i32* %5343, i64 %5590
  %5598 = bitcast i32* %5597 to <4 x i32>*
  %5599 = load <4 x i32>, <4 x i32>* %5598, align 16
  %5600 = getelementptr inbounds i32, i32* %5597, i64 4
  %5601 = bitcast i32* %5600 to <4 x i32>*
  %5602 = load <4 x i32>, <4 x i32>* %5601, align 16
  %5603 = getelementptr inbounds i32, i32* %5349, i64 %5590
  %5604 = bitcast i32* %5603 to <4 x i32>*
  %5605 = load <4 x i32>, <4 x i32>* %5604, align 16
  %5606 = getelementptr inbounds i32, i32* %5603, i64 4
  %5607 = bitcast i32* %5606 to <4 x i32>*
  %5608 = load <4 x i32>, <4 x i32>* %5607, align 16
  %5609 = add <8 x i16> %5593, %5495
  %5610 = add <8 x i16> %5609, %5596
  %5611 = add <8 x i16> %5610, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5612 = lshr <8 x i16> %5611, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5613 = shufflevector <8 x i16> %5612, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5614 = shufflevector <8 x i16> %5612, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5615 = add <4 x i32> %5578, <i32 8, i32 8, i32 8, i32 8>
  %5616 = add <4 x i32> %5615, %5599
  %5617 = add <4 x i32> %5616, %5605
  %5618 = lshr <4 x i32> %5617, <i32 4, i32 4, i32 4, i32 4>
  %5619 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5613, <8 x i16> %5613) #5
  %5620 = mul nuw <4 x i32> %5618, <i32 9, i32 9, i32 9, i32 9>
  %5621 = sub <4 x i32> %5620, %5619
  %5622 = icmp sgt <4 x i32> %5621, zeroinitializer
  %5623 = select <4 x i1> %5622, <4 x i32> %5621, <4 x i32> zeroinitializer
  %5624 = mul <4 x i32> %5623, %3726
  %5625 = add <4 x i32> %5624, <i32 524288, i32 524288, i32 524288, i32 524288>
  %5626 = lshr <4 x i32> %5625, <i32 20, i32 20, i32 20, i32 20>
  %5627 = add <4 x i32> %5585, <i32 8, i32 8, i32 8, i32 8>
  %5628 = add <4 x i32> %5627, %5602
  %5629 = add <4 x i32> %5628, %5608
  %5630 = lshr <4 x i32> %5629, <i32 4, i32 4, i32 4, i32 4>
  %5631 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5614, <8 x i16> %5614) #5
  %5632 = mul nuw <4 x i32> %5630, <i32 9, i32 9, i32 9, i32 9>
  %5633 = sub <4 x i32> %5632, %5631
  %5634 = icmp sgt <4 x i32> %5633, zeroinitializer
  %5635 = select <4 x i1> %5634, <4 x i32> %5633, <4 x i32> zeroinitializer
  %5636 = mul <4 x i32> %5635, %3726
  %5637 = add <4 x i32> %5636, <i32 524288, i32 524288, i32 524288, i32 524288>
  %5638 = lshr <4 x i32> %5637, <i32 20, i32 20, i32 20, i32 20>
  %5639 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %5626, <4 x i32> %5638) #5
  %5640 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5567, <8 x i16> %5639) #5
  %5641 = icmp ult <16 x i8> %5640, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %5642 = select <16 x i1> %5641, <16 x i8> %5640, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %5643 = icmp sgt <16 x i8> %5642, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %5644 = select <16 x i1> %5643, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %5642
  %5645 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3795, <16 x i8> %5644) #5
  %5646 = add nsw <16 x i8> %5642, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %5647 = icmp sgt <16 x i8> %5646, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %5648 = select <16 x i1> %5647, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %5646
  %5649 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3796, <16 x i8> %5648) #5
  %5650 = or <16 x i8> %5649, %5645
  %5651 = add nsw <16 x i8> %5642, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %5652 = icmp sgt <16 x i8> %5651, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %5653 = select <16 x i1> %5652, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %5651
  %5654 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3797, <16 x i8> %5653) #5
  %5655 = or <16 x i8> %5650, %5654
  %5656 = xor <16 x i8> %5640, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %5657 = icmp ugt <16 x i8> %5655, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %5658 = select <16 x i1> %5657, <16 x i8> %5655, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %5659 = icmp sgt <16 x i8> %5656, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %5660 = icmp sgt <16 x i8> %5656, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %5661 = sext <16 x i1> %5660 to <16 x i8>
  %5662 = icmp sgt <16 x i8> %5656, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %5663 = icmp sgt <16 x i8> %5656, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %5664 = icmp eq <16 x i8> %5656, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %5665 = zext <16 x i1> %5659 to <16 x i8>
  %5666 = sub nsw <16 x i8> %5661, %5665
  %5667 = zext <16 x i1> %5662 to <16 x i8>
  %5668 = sub nsw <16 x i8> %5666, %5667
  %5669 = zext <16 x i1> %5663 to <16 x i8>
  %5670 = sub nsw <16 x i8> %5668, %5669
  %5671 = zext <16 x i1> %5664 to <16 x i8>
  %5672 = sub nsw <16 x i8> %5670, %5671
  %5673 = add <16 x i8> %5672, %5658
  %5674 = bitcast <16 x i8> %5673 to <2 x i64>
  %5675 = shufflevector <16 x i8> %5673, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5676 = bitcast <16 x i8> %5675 to <8 x i16>
  %5677 = shufflevector <8 x i16> %5676, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5678 = shufflevector <8 x i16> %5538, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5679 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5677, <8 x i16> %5678) #5
  %5680 = shufflevector <8 x i16> %5676, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5681 = shufflevector <8 x i16> %5538, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5682 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5680, <8 x i16> %5681) #5
  %5683 = mul <4 x i32> %5679, <i32 455, i32 455, i32 455, i32 455>
  %5684 = mul <4 x i32> %5682, <i32 455, i32 455, i32 455, i32 455>
  %5685 = add <4 x i32> %5683, <i32 2048, i32 2048, i32 2048, i32 2048>
  %5686 = lshr <4 x i32> %5685, <i32 12, i32 12, i32 12, i32 12>
  %5687 = add <4 x i32> %5684, <i32 2048, i32 2048, i32 2048, i32 2048>
  %5688 = lshr <4 x i32> %5687, <i32 12, i32 12, i32 12, i32 12>
  %5689 = shufflevector <16 x i8> %5673, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %5690 = bitcast <16 x i8> %5689 to <8 x i16>
  %5691 = shufflevector <8 x i16> %5690, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5692 = shufflevector <8 x i16> %5610, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5693 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5691, <8 x i16> %5692) #5
  %5694 = mul <4 x i32> %5693, <i32 455, i32 455, i32 455, i32 455>
  %5695 = add <4 x i32> %5694, <i32 2048, i32 2048, i32 2048, i32 2048>
  %5696 = lshr <4 x i32> %5695, <i32 12, i32 12, i32 12, i32 12>
  %5697 = shufflevector <2 x i64> %5465, <2 x i64> %5674, <2 x i32> <i32 0, i32 2>
  %5698 = shufflevector <16 x i8> %5673, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5699 = bitcast <2 x i64> %5697 to <16 x i8>
  %5700 = shufflevector <16 x i8> %5699, <16 x i8> %5698, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %5701 = shufflevector <16 x i8> %5699, <16 x i8> %5698, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5702 = shufflevector <16 x i8> %5699, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5703 = shufflevector <16 x i8> %5700, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5704 = bitcast <16 x i8> %5702 to <8 x i16>
  %5705 = bitcast <16 x i8> %5703 to <8 x i16>
  %5706 = add <8 x i16> %5705, %5704
  %5707 = shufflevector <16 x i8> %5701, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5708 = bitcast <16 x i8> %5707 to <8 x i16>
  %5709 = add <8 x i16> %5706, %5708
  %5710 = shl <8 x i16> %5709, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5711 = getelementptr inbounds i16, i16* %5438, i64 %5455
  %5712 = bitcast i16* %5711 to <8 x i16>*
  store <8 x i16> %5710, <8 x i16>* %5712, align 16
  %5713 = mul <8 x i16> %5709, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %5714 = add <8 x i16> %5713, %5705
  %5715 = getelementptr inbounds i16, i16* %5448, i64 %5455
  %5716 = bitcast i16* %5715 to <8 x i16>*
  store <8 x i16> %5714, <8 x i16>* %5716, align 16
  %5717 = bitcast <4 x i32> %5464 to <16 x i8>
  %5718 = bitcast <4 x i32> %5461 to <16 x i8>
  %5719 = shufflevector <16 x i8> %5718, <16 x i8> %5717, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5720 = shufflevector <16 x i8> %5718, <16 x i8> %5717, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5721 = bitcast <16 x i8> %5720 to <4 x i32>
  %5722 = bitcast <16 x i8> %5719 to <4 x i32>
  %5723 = add <4 x i32> %5461, %5722
  %5724 = add <4 x i32> %5723, %5721
  %5725 = shl <4 x i32> %5724, <i32 2, i32 2, i32 2, i32 2>
  %5726 = mul <4 x i32> %5724, <i32 3, i32 3, i32 3, i32 3>
  %5727 = add <4 x i32> %5726, %5722
  %5728 = bitcast <4 x i32> %5686 to <16 x i8>
  %5729 = shufflevector <16 x i8> %5717, <16 x i8> %5728, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5730 = shufflevector <16 x i8> %5717, <16 x i8> %5728, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5731 = bitcast <16 x i8> %5730 to <4 x i32>
  %5732 = bitcast <16 x i8> %5729 to <4 x i32>
  %5733 = add <4 x i32> %5464, %5732
  %5734 = add <4 x i32> %5733, %5731
  %5735 = shl <4 x i32> %5734, <i32 2, i32 2, i32 2, i32 2>
  %5736 = mul <4 x i32> %5734, <i32 3, i32 3, i32 3, i32 3>
  %5737 = add <4 x i32> %5736, %5732
  %5738 = getelementptr inbounds i32, i32* %5439, i64 %5455
  %5739 = bitcast i32* %5738 to <4 x i32>*
  store <4 x i32> %5725, <4 x i32>* %5739, align 16
  %5740 = getelementptr inbounds i32, i32* %5738, i64 4
  %5741 = bitcast i32* %5740 to <4 x i32>*
  store <4 x i32> %5735, <4 x i32>* %5741, align 16
  %5742 = getelementptr inbounds i32, i32* %5449, i64 %5455
  %5743 = bitcast i32* %5742 to <4 x i32>*
  store <4 x i32> %5727, <4 x i32>* %5743, align 16
  %5744 = getelementptr inbounds i32, i32* %5742, i64 4
  %5745 = bitcast i32* %5744 to <4 x i32>*
  store <4 x i32> %5737, <4 x i32>* %5745, align 16
  %5746 = getelementptr inbounds i16, i16* %5295, i64 %5455
  %5747 = bitcast i16* %5746 to <8 x i16>*
  %5748 = load <8 x i16>, <8 x i16>* %5747, align 16
  %5749 = getelementptr inbounds i16, i16* %5450, i64 %5455
  %5750 = bitcast i16* %5749 to <8 x i16>*
  %5751 = load <8 x i16>, <8 x i16>* %5750, align 16
  %5752 = getelementptr inbounds i16, i16* %5440, i64 %5455
  %5753 = bitcast i16* %5752 to <8 x i16>*
  %5754 = load <8 x i16>, <8 x i16>* %5753, align 16
  %5755 = getelementptr inbounds i32, i32* %5451, i64 %5455
  %5756 = bitcast i32* %5755 to <4 x i32>*
  %5757 = load <4 x i32>, <4 x i32>* %5756, align 16
  %5758 = getelementptr inbounds i32, i32* %5755, i64 4
  %5759 = bitcast i32* %5758 to <4 x i32>*
  %5760 = load <4 x i32>, <4 x i32>* %5759, align 16
  %5761 = getelementptr inbounds i32, i32* %5441, i64 %5455
  %5762 = bitcast i32* %5761 to <4 x i32>*
  %5763 = load <4 x i32>, <4 x i32>* %5762, align 16
  %5764 = getelementptr inbounds i32, i32* %5761, i64 4
  %5765 = bitcast i32* %5764 to <4 x i32>*
  %5766 = load <4 x i32>, <4 x i32>* %5765, align 16
  %5767 = add <8 x i16> %5754, %5751
  %5768 = add <8 x i16> %5767, %5714
  %5769 = shufflevector <8 x i16> %5768, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5770 = shufflevector <8 x i16> %5748, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5771 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5769, <8 x i16> %5770) #5
  %5772 = shufflevector <8 x i16> %5768, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5773 = shufflevector <8 x i16> %5748, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5774 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5772, <8 x i16> %5773) #5
  %5775 = add <4 x i32> %5727, <i32 256, i32 256, i32 256, i32 256>
  %5776 = add <4 x i32> %5775, %5757
  %5777 = add <4 x i32> %5776, %5763
  %5778 = sub <4 x i32> %5777, %5771
  %5779 = ashr <4 x i32> %5778, <i32 9, i32 9, i32 9, i32 9>
  %5780 = add <4 x i32> %5737, <i32 256, i32 256, i32 256, i32 256>
  %5781 = add <4 x i32> %5780, %5760
  %5782 = add <4 x i32> %5781, %5766
  %5783 = sub <4 x i32> %5782, %5774
  %5784 = ashr <4 x i32> %5783, <i32 9, i32 9, i32 9, i32 9>
  %5785 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5779, <4 x i32> %5784) #5
  %5786 = shufflevector <16 x i8> %5699, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %5787 = shufflevector <16 x i8> %5700, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %5788 = bitcast <16 x i8> %5786 to <8 x i16>
  %5789 = bitcast <16 x i8> %5787 to <8 x i16>
  %5790 = add <8 x i16> %5789, %5788
  %5791 = shufflevector <16 x i8> %5701, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %5792 = bitcast <16 x i8> %5791 to <8 x i16>
  %5793 = add <8 x i16> %5790, %5792
  %5794 = shl <8 x i16> %5793, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %5795 = getelementptr inbounds i16, i16* %5438, i64 %5474
  %5796 = bitcast i16* %5795 to <8 x i16>*
  store <8 x i16> %5794, <8 x i16>* %5796, align 16
  %5797 = mul <8 x i16> %5793, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %5798 = add <8 x i16> %5797, %5789
  %5799 = getelementptr inbounds i16, i16* %5448, i64 %5474
  %5800 = bitcast i16* %5799 to <8 x i16>*
  store <8 x i16> %5798, <8 x i16>* %5800, align 16
  %5801 = bitcast <4 x i32> %5688 to <16 x i8>
  %5802 = shufflevector <16 x i8> %5728, <16 x i8> %5801, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5803 = shufflevector <16 x i8> %5728, <16 x i8> %5801, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5804 = bitcast <16 x i8> %5803 to <4 x i32>
  %5805 = bitcast <16 x i8> %5802 to <4 x i32>
  %5806 = add <4 x i32> %5686, %5805
  %5807 = add <4 x i32> %5806, %5804
  %5808 = shl <4 x i32> %5807, <i32 2, i32 2, i32 2, i32 2>
  %5809 = mul <4 x i32> %5807, <i32 3, i32 3, i32 3, i32 3>
  %5810 = add <4 x i32> %5809, %5805
  %5811 = bitcast <4 x i32> %5696 to <16 x i8>
  %5812 = shufflevector <16 x i8> %5801, <16 x i8> %5811, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5813 = shufflevector <16 x i8> %5801, <16 x i8> %5811, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %5814 = bitcast <16 x i8> %5813 to <4 x i32>
  %5815 = bitcast <16 x i8> %5812 to <4 x i32>
  %5816 = add <4 x i32> %5688, %5815
  %5817 = add <4 x i32> %5816, %5814
  %5818 = shl <4 x i32> %5817, <i32 2, i32 2, i32 2, i32 2>
  %5819 = mul <4 x i32> %5817, <i32 3, i32 3, i32 3, i32 3>
  %5820 = add <4 x i32> %5819, %5815
  %5821 = getelementptr inbounds i32, i32* %5439, i64 %5474
  %5822 = bitcast i32* %5821 to <4 x i32>*
  store <4 x i32> %5808, <4 x i32>* %5822, align 16
  %5823 = getelementptr inbounds i32, i32* %5821, i64 4
  %5824 = bitcast i32* %5823 to <4 x i32>*
  store <4 x i32> %5818, <4 x i32>* %5824, align 16
  %5825 = getelementptr inbounds i32, i32* %5449, i64 %5474
  %5826 = bitcast i32* %5825 to <4 x i32>*
  store <4 x i32> %5810, <4 x i32>* %5826, align 16
  %5827 = getelementptr inbounds i32, i32* %5825, i64 4
  %5828 = bitcast i32* %5827 to <4 x i32>*
  store <4 x i32> %5820, <4 x i32>* %5828, align 16
  %5829 = getelementptr inbounds i16, i16* %5746, i64 8
  %5830 = bitcast i16* %5829 to <8 x i16>*
  %5831 = load <8 x i16>, <8 x i16>* %5830, align 16
  %5832 = getelementptr inbounds i16, i16* %5452, i64 %5455
  %5833 = bitcast i16* %5832 to <8 x i16>*
  %5834 = load <8 x i16>, <8 x i16>* %5833, align 16
  %5835 = getelementptr inbounds i16, i16* %5442, i64 %5455
  %5836 = bitcast i16* %5835 to <8 x i16>*
  %5837 = load <8 x i16>, <8 x i16>* %5836, align 16
  %5838 = getelementptr inbounds i32, i32* %5453, i64 %5455
  %5839 = bitcast i32* %5838 to <4 x i32>*
  %5840 = load <4 x i32>, <4 x i32>* %5839, align 16
  %5841 = getelementptr inbounds i32, i32* %5838, i64 4
  %5842 = bitcast i32* %5841 to <4 x i32>*
  %5843 = load <4 x i32>, <4 x i32>* %5842, align 16
  %5844 = getelementptr inbounds i32, i32* %5443, i64 %5455
  %5845 = bitcast i32* %5844 to <4 x i32>*
  %5846 = load <4 x i32>, <4 x i32>* %5845, align 16
  %5847 = getelementptr inbounds i32, i32* %5844, i64 4
  %5848 = bitcast i32* %5847 to <4 x i32>*
  %5849 = load <4 x i32>, <4 x i32>* %5848, align 16
  %5850 = add <8 x i16> %5834, %5798
  %5851 = add <8 x i16> %5850, %5837
  %5852 = shufflevector <8 x i16> %5851, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5853 = shufflevector <8 x i16> %5831, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5854 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5852, <8 x i16> %5853) #5
  %5855 = shufflevector <8 x i16> %5851, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5856 = shufflevector <8 x i16> %5831, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5857 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5855, <8 x i16> %5856) #5
  %5858 = add <4 x i32> %5810, <i32 256, i32 256, i32 256, i32 256>
  %5859 = add <4 x i32> %5858, %5840
  %5860 = add <4 x i32> %5859, %5846
  %5861 = sub <4 x i32> %5860, %5854
  %5862 = ashr <4 x i32> %5861, <i32 9, i32 9, i32 9, i32 9>
  %5863 = add <4 x i32> %5820, <i32 256, i32 256, i32 256, i32 256>
  %5864 = add <4 x i32> %5863, %5843
  %5865 = add <4 x i32> %5864, %5849
  %5866 = sub <4 x i32> %5865, %5857
  %5867 = ashr <4 x i32> %5866, <i32 9, i32 9, i32 9, i32 9>
  %5868 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5862, <4 x i32> %5867) #5
  %5869 = shufflevector <8 x i16> %5785, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5870 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5869, <8 x i16> %4629) #5
  %5871 = shufflevector <8 x i16> %5785, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5872 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5871, <8 x i16> %4629) #5
  %5873 = add <4 x i32> %5870, <i32 1024, i32 1024, i32 1024, i32 1024>
  %5874 = ashr <4 x i32> %5873, <i32 11, i32 11, i32 11, i32 11>
  %5875 = add <4 x i32> %5872, <i32 1024, i32 1024, i32 1024, i32 1024>
  %5876 = ashr <4 x i32> %5875, <i32 11, i32 11, i32 11, i32 11>
  %5877 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5874, <4 x i32> %5876) #5
  %5878 = add <8 x i16> %5877, %5748
  %5879 = shufflevector <8 x i16> %5868, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5880 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5879, <8 x i16> %4629) #5
  %5881 = shufflevector <8 x i16> %5868, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5882 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5881, <8 x i16> %4629) #5
  %5883 = add <4 x i32> %5880, <i32 1024, i32 1024, i32 1024, i32 1024>
  %5884 = ashr <4 x i32> %5883, <i32 11, i32 11, i32 11, i32 11>
  %5885 = add <4 x i32> %5882, <i32 1024, i32 1024, i32 1024, i32 1024>
  %5886 = ashr <4 x i32> %5885, <i32 11, i32 11, i32 11, i32 11>
  %5887 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5884, <4 x i32> %5886) #5
  %5888 = add <8 x i16> %5887, %5831
  %5889 = getelementptr inbounds i16, i16* %5293, i64 %5455
  %5890 = icmp sgt <8 x i16> %5878, zeroinitializer
  %5891 = select <8 x i1> %5890, <8 x i16> %5878, <8 x i16> zeroinitializer
  %5892 = icmp slt <8 x i16> %5891, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %5893 = select <8 x i1> %5892, <8 x i16> %5891, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %5894 = bitcast i16* %5889 to <8 x i16>*
  store <8 x i16> %5893, <8 x i16>* %5894, align 16
  %5895 = getelementptr inbounds i16, i16* %5889, i64 8
  %5896 = icmp sgt <8 x i16> %5888, zeroinitializer
  %5897 = select <8 x i1> %5896, <8 x i16> %5888, <8 x i16> zeroinitializer
  %5898 = icmp slt <8 x i16> %5897, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %5899 = select <8 x i1> %5898, <8 x i16> %5897, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %5900 = bitcast i16* %5895 to <8 x i16>*
  store <8 x i16> %5899, <8 x i16>* %5900, align 16
  %5901 = icmp slt i64 %5468, %3506
  br i1 %5901, label %5902, label %5907

5902:                                             ; preds = %5454
  %5903 = shufflevector <8 x i16> %5690, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5904 = shufflevector <8 x i16> %5610, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5905 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5903, <8 x i16> %5904) #5
  %5906 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5570, <8 x i16> %5570) #5
  br label %5454

5907:                                             ; preds = %5454
  %5908 = getelementptr inbounds i16, i16* %5295, i64 %2
  %5909 = getelementptr inbounds i16, i16* %5293, i64 %2
  %5910 = getelementptr inbounds i16, i16* %5294, i64 %6
  %5911 = add nsw i32 %5296, -1
  %5912 = icmp eq i32 %5911, 0
  br i1 %5912, label %12087, label %5276

5913:                                             ; preds = %3497
  %5914 = getelementptr inbounds i8, i8* %1, i64 -6
  %5915 = getelementptr inbounds i8, i8* %3, i64 -6
  %5916 = bitcast i8* %5915 to i16*
  %5917 = getelementptr inbounds i8, i8* %5, i64 -6
  %5918 = sext i32 %7 to i64
  %5919 = add nsw i64 %5918, 15
  %5920 = and i64 %5919, -16
  %5921 = add nsw i64 %5918, 23
  %5922 = add nsw i64 %5920, 16
  %5923 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 1, i32 1, i64 0
  %5924 = load i32, i32* %5923, align 4
  %5925 = getelementptr inbounds %"struct.libgav1::RestorationUnitInfo", %"struct.libgav1::RestorationUnitInfo"* %0, i64 0, i32 1, i32 1, i64 1
  %5926 = load i32, i32* %5925, align 4
  %5927 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 0
  %5928 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 0
  %5929 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 4, i64 0
  %5930 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 7, i64 0
  %5931 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %5922
  %5932 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 %5922
  %5933 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 4, i64 %5920
  %5934 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 7, i64 %5920
  %5935 = getelementptr inbounds i16, i16* %5931, i64 %5922
  %5936 = getelementptr inbounds i32, i32* %5932, i64 %5922
  %5937 = getelementptr inbounds i16, i16* %5933, i64 %5920
  %5938 = getelementptr inbounds i32, i32* %5934, i64 %5920
  %5939 = getelementptr inbounds i16, i16* %5935, i64 %5922
  %5940 = getelementptr inbounds i32, i32* %5936, i64 %5922
  %5941 = getelementptr inbounds i16, i16* %5937, i64 %5920
  %5942 = getelementptr inbounds i32, i32* %5938, i64 %5920
  %5943 = and i64 %5921, -16
  %5944 = getelementptr inbounds [16 x [2 x i16]], [16 x [2 x i16]]* @_ZN7libgav118kSgrScaleParameterE, i64 0, i64 %14, i64 0
  %5945 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 1, i64 0
  %5946 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 1, i64 %5922
  %5947 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 3, i64 %5922
  %5948 = getelementptr inbounds i16, i16* %5946, i64 %5922
  %5949 = getelementptr inbounds i32, i32* %5947, i64 %5922
  %5950 = getelementptr inbounds i16, i16* %5948, i64 %5922
  %5951 = getelementptr inbounds i32, i32* %5949, i64 %5922
  %5952 = getelementptr inbounds i16, i16* %5950, i64 %5922
  %5953 = getelementptr inbounds i32, i32* %5951, i64 %5922
  %5954 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 5, i64 0
  %5955 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 8, i64 0
  %5956 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 5, i64 %5920
  %5957 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 8, i64 %5920
  %5958 = getelementptr inbounds i16, i16* %5956, i64 %5920
  %5959 = getelementptr inbounds i32, i32* %5957, i64 %5920
  %5960 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 6, i64 0
  %5961 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 9, i64 0
  %5962 = sub nsw i64 %4, %5943
  %5963 = sub nsw i64 %5922, %5943
  br label %5964

5964:                                             ; preds = %6103, %5913
  %5965 = phi i16* [ %5916, %5913 ], [ %6104, %6103 ]
  %5966 = phi i16* [ %5927, %5913 ], [ %6105, %6103 ]
  %5967 = phi i16* [ %5946, %5913 ], [ %6106, %6103 ]
  %5968 = phi i32* [ %5928, %5913 ], [ %6107, %6103 ]
  %5969 = phi i32* [ %5947, %5913 ], [ %6108, %6103 ]
  %5970 = phi i32 [ 2, %5913 ], [ %6109, %6103 ]
  %5971 = bitcast i16* %5965 to <2 x i64>*
  %5972 = load <2 x i64>, <2 x i64>* %5971, align 1
  %5973 = bitcast <2 x i64> %5972 to <8 x i16>
  %5974 = shufflevector <8 x i16> %5973, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5975 = shufflevector <8 x i16> %5973, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5976 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5974, <8 x i16> %5974) #5
  %5977 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5975, <8 x i16> %5975) #5
  br label %5978

5978:                                             ; preds = %5978, %5964
  %5979 = phi <4 x i32> [ %5976, %5964 ], [ %6003, %5978 ]
  %5980 = phi <4 x i32> [ %5977, %5964 ], [ %6004, %5978 ]
  %5981 = phi <2 x i64> [ %5972, %5964 ], [ %5994, %5978 ]
  %5982 = phi i16* [ %5965, %5964 ], [ %5992, %5978 ]
  %5983 = phi i16* [ %5966, %5964 ], [ %6098, %5978 ]
  %5984 = phi i16* [ %5967, %5964 ], [ %6099, %5978 ]
  %5985 = phi i32* [ %5968, %5964 ], [ %6100, %5978 ]
  %5986 = phi i32* [ %5969, %5964 ], [ %6101, %5978 ]
  %5987 = phi i64 [ %5943, %5964 ], [ %5991, %5978 ]
  %5988 = getelementptr inbounds i16, i16* %5982, i64 8
  %5989 = bitcast i16* %5988 to <2 x i64>*
  %5990 = load <2 x i64>, <2 x i64>* %5989, align 1
  %5991 = add nsw i64 %5987, -16
  %5992 = getelementptr inbounds i16, i16* %5982, i64 16
  %5993 = bitcast i16* %5992 to <2 x i64>*
  %5994 = load <2 x i64>, <2 x i64>* %5993, align 1
  %5995 = bitcast <2 x i64> %5990 to <8 x i16>
  %5996 = shufflevector <8 x i16> %5995, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5997 = shufflevector <8 x i16> %5995, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5998 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5996, <8 x i16> %5996) #5
  %5999 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %5997, <8 x i16> %5997) #5
  %6000 = bitcast <2 x i64> %5994 to <8 x i16>
  %6001 = shufflevector <8 x i16> %6000, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6002 = shufflevector <8 x i16> %6000, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6003 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6001, <8 x i16> %6001) #5
  %6004 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6002, <8 x i16> %6002) #5
  %6005 = bitcast <2 x i64> %5981 to <8 x i16>
  %6006 = bitcast <2 x i64> %5990 to <16 x i8>
  %6007 = bitcast <2 x i64> %5981 to <16 x i8>
  %6008 = shufflevector <16 x i8> %6007, <16 x i8> %6006, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %6009 = bitcast <16 x i8> %6008 to <8 x i16>
  %6010 = shufflevector <16 x i8> %6007, <16 x i8> %6006, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6011 = bitcast <16 x i8> %6010 to <8 x i16>
  %6012 = shufflevector <16 x i8> %6007, <16 x i8> %6006, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %6013 = bitcast <16 x i8> %6012 to <8 x i16>
  %6014 = shufflevector <16 x i8> %6007, <16 x i8> %6006, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6015 = bitcast <16 x i8> %6014 to <8 x i16>
  %6016 = add <8 x i16> %6015, %6005
  %6017 = add <8 x i16> %6011, %6009
  %6018 = add <8 x i16> %6017, %6013
  %6019 = add <8 x i16> %6016, %6018
  %6020 = bitcast <2 x i64> %5994 to <16 x i8>
  %6021 = shufflevector <16 x i8> %6006, <16 x i8> %6020, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %6022 = bitcast <16 x i8> %6021 to <8 x i16>
  %6023 = shufflevector <16 x i8> %6006, <16 x i8> %6020, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6024 = bitcast <16 x i8> %6023 to <8 x i16>
  %6025 = shufflevector <16 x i8> %6006, <16 x i8> %6020, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %6026 = bitcast <16 x i8> %6025 to <8 x i16>
  %6027 = shufflevector <16 x i8> %6006, <16 x i8> %6020, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6028 = bitcast <16 x i8> %6027 to <8 x i16>
  %6029 = add <8 x i16> %6028, %5995
  %6030 = add <8 x i16> %6024, %6022
  %6031 = add <8 x i16> %6030, %6026
  %6032 = add <8 x i16> %6029, %6031
  %6033 = bitcast i16* %5983 to <8 x i16>*
  store <8 x i16> %6018, <8 x i16>* %6033, align 16
  %6034 = getelementptr inbounds i16, i16* %5983, i64 8
  %6035 = bitcast i16* %6034 to <8 x i16>*
  store <8 x i16> %6031, <8 x i16>* %6035, align 16
  %6036 = bitcast i16* %5984 to <8 x i16>*
  store <8 x i16> %6019, <8 x i16>* %6036, align 16
  %6037 = getelementptr inbounds i16, i16* %5984, i64 8
  %6038 = bitcast i16* %6037 to <8 x i16>*
  store <8 x i16> %6032, <8 x i16>* %6038, align 16
  %6039 = bitcast <4 x i32> %5980 to <16 x i8>
  %6040 = bitcast <4 x i32> %5979 to <16 x i8>
  %6041 = shufflevector <16 x i8> %6040, <16 x i8> %6039, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6042 = bitcast <16 x i8> %6041 to <4 x i32>
  %6043 = shufflevector <16 x i8> %6040, <16 x i8> %6039, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6044 = bitcast <16 x i8> %6043 to <4 x i32>
  %6045 = shufflevector <16 x i8> %6040, <16 x i8> %6039, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6046 = bitcast <16 x i8> %6045 to <4 x i32>
  %6047 = add <4 x i32> %5980, %5979
  %6048 = add <4 x i32> %6044, %6042
  %6049 = add <4 x i32> %6048, %6046
  %6050 = add <4 x i32> %6047, %6049
  %6051 = bitcast <4 x i32> %5998 to <16 x i8>
  %6052 = shufflevector <16 x i8> %6039, <16 x i8> %6051, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6053 = bitcast <16 x i8> %6052 to <4 x i32>
  %6054 = shufflevector <16 x i8> %6039, <16 x i8> %6051, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6055 = bitcast <16 x i8> %6054 to <4 x i32>
  %6056 = shufflevector <16 x i8> %6039, <16 x i8> %6051, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6057 = bitcast <16 x i8> %6056 to <4 x i32>
  %6058 = add <4 x i32> %5998, %5980
  %6059 = add <4 x i32> %6055, %6053
  %6060 = add <4 x i32> %6059, %6057
  %6061 = add <4 x i32> %6058, %6060
  %6062 = bitcast i32* %5985 to <4 x i32>*
  store <4 x i32> %6049, <4 x i32>* %6062, align 16
  %6063 = getelementptr inbounds i32, i32* %5985, i64 4
  %6064 = bitcast i32* %6063 to <4 x i32>*
  store <4 x i32> %6060, <4 x i32>* %6064, align 16
  %6065 = bitcast i32* %5986 to <4 x i32>*
  store <4 x i32> %6050, <4 x i32>* %6065, align 16
  %6066 = getelementptr inbounds i32, i32* %5986, i64 4
  %6067 = bitcast i32* %6066 to <4 x i32>*
  store <4 x i32> %6061, <4 x i32>* %6067, align 16
  %6068 = bitcast <4 x i32> %5999 to <16 x i8>
  %6069 = shufflevector <16 x i8> %6051, <16 x i8> %6068, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6070 = bitcast <16 x i8> %6069 to <4 x i32>
  %6071 = shufflevector <16 x i8> %6051, <16 x i8> %6068, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6072 = bitcast <16 x i8> %6071 to <4 x i32>
  %6073 = shufflevector <16 x i8> %6051, <16 x i8> %6068, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6074 = bitcast <16 x i8> %6073 to <4 x i32>
  %6075 = add <4 x i32> %5999, %5998
  %6076 = add <4 x i32> %6072, %6070
  %6077 = add <4 x i32> %6076, %6074
  %6078 = add <4 x i32> %6075, %6077
  %6079 = bitcast <4 x i32> %6003 to <16 x i8>
  %6080 = shufflevector <16 x i8> %6068, <16 x i8> %6079, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6081 = bitcast <16 x i8> %6080 to <4 x i32>
  %6082 = shufflevector <16 x i8> %6068, <16 x i8> %6079, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6083 = bitcast <16 x i8> %6082 to <4 x i32>
  %6084 = shufflevector <16 x i8> %6068, <16 x i8> %6079, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6085 = bitcast <16 x i8> %6084 to <4 x i32>
  %6086 = add <4 x i32> %6003, %5999
  %6087 = add <4 x i32> %6083, %6081
  %6088 = add <4 x i32> %6087, %6085
  %6089 = add <4 x i32> %6086, %6088
  %6090 = getelementptr inbounds i32, i32* %5985, i64 8
  %6091 = bitcast i32* %6090 to <4 x i32>*
  store <4 x i32> %6077, <4 x i32>* %6091, align 16
  %6092 = getelementptr inbounds i32, i32* %5985, i64 12
  %6093 = bitcast i32* %6092 to <4 x i32>*
  store <4 x i32> %6088, <4 x i32>* %6093, align 16
  %6094 = getelementptr inbounds i32, i32* %5986, i64 8
  %6095 = bitcast i32* %6094 to <4 x i32>*
  store <4 x i32> %6078, <4 x i32>* %6095, align 16
  %6096 = getelementptr inbounds i32, i32* %5986, i64 12
  %6097 = bitcast i32* %6096 to <4 x i32>*
  store <4 x i32> %6089, <4 x i32>* %6097, align 16
  %6098 = getelementptr inbounds i16, i16* %5983, i64 16
  %6099 = getelementptr inbounds i16, i16* %5984, i64 16
  %6100 = getelementptr inbounds i32, i32* %5985, i64 16
  %6101 = getelementptr inbounds i32, i32* %5986, i64 16
  %6102 = icmp eq i64 %5991, 0
  br i1 %6102, label %6103, label %5978

6103:                                             ; preds = %5978
  %6104 = getelementptr inbounds i16, i16* %5992, i64 %5962
  %6105 = getelementptr inbounds i16, i16* %6098, i64 %5963
  %6106 = getelementptr inbounds i16, i16* %6099, i64 %5963
  %6107 = getelementptr inbounds i32, i32* %6100, i64 %5963
  %6108 = getelementptr inbounds i32, i32* %6101, i64 %5963
  %6109 = add nsw i32 %5970, -1
  %6110 = icmp eq i32 %6109, 0
  br i1 %6110, label %6111, label %5964

6111:                                             ; preds = %6103
  %6112 = bitcast i8* %5914 to i16*
  %6113 = bitcast i8* %5917 to i16*
  %6114 = sub i32 128, %5924
  %6115 = ptrtoint %"union.libgav1::RestorationBuffer"* %9 to i64
  %6116 = ptrtoint i32* %5928 to i64
  %6117 = ptrtoint i16* %5929 to i64
  %6118 = ptrtoint i32* %5930 to i64
  %6119 = ptrtoint i16* %5931 to i64
  %6120 = ptrtoint i32* %5932 to i64
  %6121 = ptrtoint i16* %5933 to i64
  %6122 = ptrtoint i32* %5934 to i64
  %6123 = ptrtoint i16* %5935 to i64
  %6124 = ptrtoint i32* %5936 to i64
  %6125 = ptrtoint i16* %5937 to i64
  %6126 = ptrtoint i32* %5938 to i64
  %6127 = ptrtoint i16* %5939 to i64
  %6128 = ptrtoint i32* %5940 to i64
  %6129 = ptrtoint i16* %5941 to i64
  %6130 = ptrtoint i32* %5942 to i64
  %6131 = sub i32 %6114, %5926
  %6132 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 3, i64 0
  %6133 = ptrtoint i16* %5946 to i64
  %6134 = ptrtoint i32* %5947 to i64
  %6135 = ptrtoint i16* %5948 to i64
  %6136 = ptrtoint i32* %5949 to i64
  %6137 = ptrtoint i16* %5950 to i64
  %6138 = ptrtoint i32* %5951 to i64
  %6139 = ptrtoint i16* %5952 to i64
  %6140 = ptrtoint i32* %5953 to i64
  %6141 = ptrtoint i16* %5954 to i64
  %6142 = ptrtoint i32* %5955 to i64
  %6143 = ptrtoint i16* %5958 to i64
  %6144 = ptrtoint i32* %5959 to i64
  %6145 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 6, i64 %5920
  %6146 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 9, i64 %5920
  %6147 = ptrtoint i16* %5960 to i64
  %6148 = ptrtoint i32* %5961 to i64
  %6149 = icmp sgt i32 %8, 1
  %6150 = getelementptr inbounds i16, i16* %6112, i64 %2
  %6151 = select i1 %6149, i16* %6150, i16* %6113
  %6152 = bitcast i8* %5914 to <8 x i16>*
  %6153 = load <8 x i16>, <8 x i16>* %6152, align 1
  %6154 = getelementptr inbounds i8, i8* %1, i64 10
  %6155 = bitcast i8* %6154 to <2 x i64>*
  %6156 = load <2 x i64>, <2 x i64>* %6155, align 1
  %6157 = bitcast i16* %6151 to <8 x i16>*
  %6158 = load <8 x i16>, <8 x i16>* %6157, align 1
  %6159 = getelementptr inbounds i16, i16* %6151, i64 8
  %6160 = bitcast i16* %6159 to <2 x i64>*
  %6161 = load <2 x i64>, <2 x i64>* %6160, align 1
  %6162 = shufflevector <8 x i16> %6153, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6163 = shufflevector <8 x i16> %6153, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6164 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6162, <8 x i16> %6162) #5
  %6165 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6163, <8 x i16> %6163) #5
  %6166 = shufflevector <8 x i16> %6158, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6167 = shufflevector <8 x i16> %6158, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6168 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6166, <8 x i16> %6166) #5
  %6169 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6167, <8 x i16> %6167) #5
  %6170 = bitcast <2 x i64> %6156 to <8 x i16>
  %6171 = shufflevector <8 x i16> %6170, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6172 = shufflevector <8 x i16> %6170, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6173 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6171, <8 x i16> %6171) #5
  %6174 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6172, <8 x i16> %6172) #5
  %6175 = bitcast <2 x i64> %6161 to <8 x i16>
  %6176 = shufflevector <8 x i16> %6175, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6177 = shufflevector <8 x i16> %6175, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6178 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6176, <8 x i16> %6176) #5
  %6179 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6177, <8 x i16> %6177) #5
  %6180 = bitcast <2 x i64> %6156 to <16 x i8>
  %6181 = bitcast <8 x i16> %6153 to <16 x i8>
  %6182 = shufflevector <16 x i8> %6181, <16 x i8> %6180, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %6183 = bitcast <16 x i8> %6182 to <8 x i16>
  %6184 = shufflevector <16 x i8> %6181, <16 x i8> %6180, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6185 = bitcast <16 x i8> %6184 to <8 x i16>
  %6186 = shufflevector <16 x i8> %6181, <16 x i8> %6180, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %6187 = bitcast <16 x i8> %6186 to <8 x i16>
  %6188 = shufflevector <16 x i8> %6181, <16 x i8> %6180, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6189 = bitcast <16 x i8> %6188 to <8 x i16>
  %6190 = add <8 x i16> %6153, %6189
  %6191 = add <8 x i16> %6185, %6183
  %6192 = add <8 x i16> %6191, %6187
  %6193 = add <8 x i16> %6190, %6192
  %6194 = bitcast <2 x i64> %6161 to <16 x i8>
  %6195 = bitcast <8 x i16> %6158 to <16 x i8>
  %6196 = shufflevector <16 x i8> %6195, <16 x i8> %6194, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %6197 = bitcast <16 x i8> %6196 to <8 x i16>
  %6198 = shufflevector <16 x i8> %6195, <16 x i8> %6194, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6199 = bitcast <16 x i8> %6198 to <8 x i16>
  %6200 = shufflevector <16 x i8> %6195, <16 x i8> %6194, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %6201 = bitcast <16 x i8> %6200 to <8 x i16>
  %6202 = shufflevector <16 x i8> %6195, <16 x i8> %6194, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6203 = bitcast <16 x i8> %6202 to <8 x i16>
  %6204 = add <8 x i16> %6158, %6203
  %6205 = add <8 x i16> %6199, %6197
  %6206 = add <8 x i16> %6205, %6201
  %6207 = add <8 x i16> %6204, %6206
  %6208 = bitcast i16* %5935 to <8 x i16>*
  store <8 x i16> %6192, <8 x i16>* %6208, align 16
  %6209 = bitcast i16* %5939 to <8 x i16>*
  store <8 x i16> %6206, <8 x i16>* %6209, align 16
  %6210 = bitcast i16* %5950 to <8 x i16>*
  store <8 x i16> %6193, <8 x i16>* %6210, align 16
  %6211 = bitcast i16* %5952 to <8 x i16>*
  store <8 x i16> %6207, <8 x i16>* %6211, align 16
  %6212 = bitcast <4 x i32> %6165 to <16 x i8>
  %6213 = bitcast <4 x i32> %6164 to <16 x i8>
  %6214 = shufflevector <16 x i8> %6213, <16 x i8> %6212, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6215 = bitcast <16 x i8> %6214 to <4 x i32>
  %6216 = shufflevector <16 x i8> %6213, <16 x i8> %6212, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6217 = bitcast <16 x i8> %6216 to <4 x i32>
  %6218 = shufflevector <16 x i8> %6213, <16 x i8> %6212, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6219 = bitcast <16 x i8> %6218 to <4 x i32>
  %6220 = add <4 x i32> %6165, %6164
  %6221 = add <4 x i32> %6217, %6215
  %6222 = add <4 x i32> %6221, %6219
  %6223 = add <4 x i32> %6220, %6222
  %6224 = bitcast <4 x i32> %6173 to <16 x i8>
  %6225 = shufflevector <16 x i8> %6212, <16 x i8> %6224, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6226 = bitcast <16 x i8> %6225 to <4 x i32>
  %6227 = shufflevector <16 x i8> %6212, <16 x i8> %6224, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6228 = bitcast <16 x i8> %6227 to <4 x i32>
  %6229 = shufflevector <16 x i8> %6212, <16 x i8> %6224, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6230 = bitcast <16 x i8> %6229 to <4 x i32>
  %6231 = add <4 x i32> %6173, %6165
  %6232 = add <4 x i32> %6228, %6226
  %6233 = add <4 x i32> %6232, %6230
  %6234 = add <4 x i32> %6231, %6233
  %6235 = bitcast i32* %5936 to <4 x i32>*
  store <4 x i32> %6222, <4 x i32>* %6235, align 16
  %6236 = getelementptr inbounds i32, i32* %5936, i64 4
  %6237 = bitcast i32* %6236 to <4 x i32>*
  store <4 x i32> %6233, <4 x i32>* %6237, align 16
  %6238 = bitcast i32* %5951 to <4 x i32>*
  store <4 x i32> %6223, <4 x i32>* %6238, align 16
  %6239 = getelementptr inbounds i32, i32* %5951, i64 4
  %6240 = bitcast i32* %6239 to <4 x i32>*
  store <4 x i32> %6234, <4 x i32>* %6240, align 16
  %6241 = bitcast <4 x i32> %6169 to <16 x i8>
  %6242 = bitcast <4 x i32> %6168 to <16 x i8>
  %6243 = shufflevector <16 x i8> %6242, <16 x i8> %6241, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6244 = bitcast <16 x i8> %6243 to <4 x i32>
  %6245 = shufflevector <16 x i8> %6242, <16 x i8> %6241, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6246 = bitcast <16 x i8> %6245 to <4 x i32>
  %6247 = shufflevector <16 x i8> %6242, <16 x i8> %6241, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6248 = bitcast <16 x i8> %6247 to <4 x i32>
  %6249 = add <4 x i32> %6169, %6168
  %6250 = add <4 x i32> %6246, %6244
  %6251 = add <4 x i32> %6250, %6248
  %6252 = add <4 x i32> %6249, %6251
  %6253 = bitcast <4 x i32> %6178 to <16 x i8>
  %6254 = shufflevector <16 x i8> %6241, <16 x i8> %6253, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6255 = bitcast <16 x i8> %6254 to <4 x i32>
  %6256 = shufflevector <16 x i8> %6241, <16 x i8> %6253, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6257 = bitcast <16 x i8> %6256 to <4 x i32>
  %6258 = shufflevector <16 x i8> %6241, <16 x i8> %6253, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6259 = bitcast <16 x i8> %6258 to <4 x i32>
  %6260 = add <4 x i32> %6178, %6169
  %6261 = add <4 x i32> %6257, %6255
  %6262 = add <4 x i32> %6261, %6259
  %6263 = add <4 x i32> %6260, %6262
  %6264 = bitcast i32* %5940 to <4 x i32>*
  store <4 x i32> %6251, <4 x i32>* %6264, align 16
  %6265 = getelementptr inbounds i32, i32* %5940, i64 4
  %6266 = bitcast i32* %6265 to <4 x i32>*
  store <4 x i32> %6262, <4 x i32>* %6266, align 16
  %6267 = bitcast i32* %5953 to <4 x i32>*
  store <4 x i32> %6252, <4 x i32>* %6267, align 16
  %6268 = getelementptr inbounds i32, i32* %5953, i64 4
  %6269 = bitcast i32* %6268 to <4 x i32>*
  store <4 x i32> %6263, <4 x i32>* %6269, align 16
  %6270 = bitcast %"union.libgav1::RestorationBuffer"* %9 to <8 x i16>*
  %6271 = load <8 x i16>, <8 x i16>* %6270, align 16
  %6272 = bitcast i16* %5931 to <8 x i16>*
  %6273 = load <8 x i16>, <8 x i16>* %6272, align 16
  %6274 = bitcast i32* %5928 to <4 x i32>*
  %6275 = load <4 x i32>, <4 x i32>* %6274, align 16
  %6276 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 4
  %6277 = bitcast i32* %6276 to <4 x i32>*
  %6278 = load <4 x i32>, <4 x i32>* %6277, align 16
  %6279 = bitcast i32* %5932 to <4 x i32>*
  %6280 = load <4 x i32>, <4 x i32>* %6279, align 16
  %6281 = getelementptr inbounds i32, i32* %5932, i64 4
  %6282 = bitcast i32* %6281 to <4 x i32>*
  %6283 = load <4 x i32>, <4 x i32>* %6282, align 16
  %6284 = bitcast i16* %5946 to <8 x i16>*
  %6285 = load <8 x i16>, <8 x i16>* %6284, align 16
  %6286 = bitcast i16* %5948 to <8 x i16>*
  %6287 = load <8 x i16>, <8 x i16>* %6286, align 16
  %6288 = bitcast i32* %5947 to <4 x i32>*
  %6289 = load <4 x i32>, <4 x i32>* %6288, align 16
  %6290 = getelementptr inbounds i32, i32* %5947, i64 4
  %6291 = bitcast i32* %6290 to <4 x i32>*
  %6292 = load <4 x i32>, <4 x i32>* %6291, align 16
  %6293 = bitcast i32* %5949 to <4 x i32>*
  %6294 = load <4 x i32>, <4 x i32>* %6293, align 16
  %6295 = getelementptr inbounds i32, i32* %5949, i64 4
  %6296 = bitcast i32* %6295 to <4 x i32>*
  %6297 = load <4 x i32>, <4 x i32>* %6296, align 16
  %6298 = getelementptr inbounds [16 x [2 x i16]], [16 x [2 x i16]]* @_ZN7libgav118kSgrScaleParameterE, i64 0, i64 %14, i64 1
  %6299 = load i16, i16* %6298, align 2
  %6300 = zext i16 %6299 to i32
  %6301 = add <8 x i16> %6273, %6192
  %6302 = add <8 x i16> %6301, %6271
  %6303 = add <8 x i16> %6302, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6304 = lshr <8 x i16> %6303, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6305 = shufflevector <8 x i16> %6304, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6306 = shufflevector <8 x i16> %6304, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6307 = add <4 x i32> %6222, <i32 8, i32 8, i32 8, i32 8>
  %6308 = add <4 x i32> %6307, %6280
  %6309 = add <4 x i32> %6308, %6275
  %6310 = lshr <4 x i32> %6309, <i32 4, i32 4, i32 4, i32 4>
  %6311 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6305, <8 x i16> %6305) #5
  %6312 = mul nuw <4 x i32> %6310, <i32 9, i32 9, i32 9, i32 9>
  %6313 = sub <4 x i32> %6312, %6311
  %6314 = icmp sgt <4 x i32> %6313, zeroinitializer
  %6315 = select <4 x i1> %6314, <4 x i32> %6313, <4 x i32> zeroinitializer
  %6316 = insertelement <4 x i32> undef, i32 %6300, i32 0
  %6317 = shufflevector <4 x i32> %6316, <4 x i32> undef, <4 x i32> zeroinitializer
  %6318 = mul <4 x i32> %6315, %6317
  %6319 = add <4 x i32> %6318, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6320 = lshr <4 x i32> %6319, <i32 20, i32 20, i32 20, i32 20>
  %6321 = add <4 x i32> %6233, <i32 8, i32 8, i32 8, i32 8>
  %6322 = add <4 x i32> %6321, %6283
  %6323 = add <4 x i32> %6322, %6278
  %6324 = lshr <4 x i32> %6323, <i32 4, i32 4, i32 4, i32 4>
  %6325 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6306, <8 x i16> %6306) #5
  %6326 = mul nuw <4 x i32> %6324, <i32 9, i32 9, i32 9, i32 9>
  %6327 = sub <4 x i32> %6326, %6325
  %6328 = icmp sgt <4 x i32> %6327, zeroinitializer
  %6329 = select <4 x i1> %6328, <4 x i32> %6327, <4 x i32> zeroinitializer
  %6330 = mul <4 x i32> %6329, %6317
  %6331 = add <4 x i32> %6330, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6332 = lshr <4 x i32> %6331, <i32 20, i32 20, i32 20, i32 20>
  %6333 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6320, <4 x i32> %6332) #5
  %6334 = add <8 x i16> %6301, %6206
  %6335 = add <8 x i16> %6334, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6336 = lshr <8 x i16> %6335, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6337 = shufflevector <8 x i16> %6336, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6338 = shufflevector <8 x i16> %6336, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6339 = add <4 x i32> %6308, %6251
  %6340 = lshr <4 x i32> %6339, <i32 4, i32 4, i32 4, i32 4>
  %6341 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6337, <8 x i16> %6337) #5
  %6342 = mul nuw <4 x i32> %6340, <i32 9, i32 9, i32 9, i32 9>
  %6343 = sub <4 x i32> %6342, %6341
  %6344 = icmp sgt <4 x i32> %6343, zeroinitializer
  %6345 = select <4 x i1> %6344, <4 x i32> %6343, <4 x i32> zeroinitializer
  %6346 = mul <4 x i32> %6345, %6317
  %6347 = add <4 x i32> %6346, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6348 = lshr <4 x i32> %6347, <i32 20, i32 20, i32 20, i32 20>
  %6349 = add <4 x i32> %6322, %6262
  %6350 = lshr <4 x i32> %6349, <i32 4, i32 4, i32 4, i32 4>
  %6351 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6338, <8 x i16> %6338) #5
  %6352 = mul nuw <4 x i32> %6350, <i32 9, i32 9, i32 9, i32 9>
  %6353 = sub <4 x i32> %6352, %6351
  %6354 = icmp sgt <4 x i32> %6353, zeroinitializer
  %6355 = select <4 x i1> %6354, <4 x i32> %6353, <4 x i32> zeroinitializer
  %6356 = mul <4 x i32> %6355, %6317
  %6357 = add <4 x i32> %6356, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6358 = lshr <4 x i32> %6357, <i32 20, i32 20, i32 20, i32 20>
  %6359 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6348, <4 x i32> %6358) #5
  %6360 = load <16 x i8>, <16 x i8>* bitcast ([256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE to <16 x i8>*), align 16
  %6361 = load <16 x i8>, <16 x i8>* bitcast (i8* getelementptr inbounds ([256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 16) to <16 x i8>*), align 16
  %6362 = load <16 x i8>, <16 x i8>* bitcast (i8* getelementptr inbounds ([256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 32) to <16 x i8>*), align 16
  %6363 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6333, <8 x i16> %6359) #5
  %6364 = icmp ult <16 x i8> %6363, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %6365 = select <16 x i1> %6364, <16 x i8> %6363, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %6366 = icmp sgt <16 x i8> %6365, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %6367 = select <16 x i1> %6366, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %6365
  %6368 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %6367) #5
  %6369 = add nsw <16 x i8> %6365, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %6370 = icmp sgt <16 x i8> %6369, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %6371 = select <16 x i1> %6370, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %6369
  %6372 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %6371) #5
  %6373 = or <16 x i8> %6372, %6368
  %6374 = add nsw <16 x i8> %6365, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %6375 = icmp sgt <16 x i8> %6374, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %6376 = select <16 x i1> %6375, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %6374
  %6377 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %6376) #5
  %6378 = or <16 x i8> %6373, %6377
  %6379 = xor <16 x i8> %6363, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %6380 = icmp ugt <16 x i8> %6378, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %6381 = select <16 x i1> %6380, <16 x i8> %6378, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %6382 = icmp sgt <16 x i8> %6379, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %6383 = icmp sgt <16 x i8> %6379, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %6384 = sext <16 x i1> %6383 to <16 x i8>
  %6385 = icmp sgt <16 x i8> %6379, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %6386 = icmp sgt <16 x i8> %6379, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %6387 = icmp eq <16 x i8> %6379, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %6388 = zext <16 x i1> %6382 to <16 x i8>
  %6389 = sub nsw <16 x i8> %6384, %6388
  %6390 = zext <16 x i1> %6385 to <16 x i8>
  %6391 = sub nsw <16 x i8> %6389, %6390
  %6392 = zext <16 x i1> %6386 to <16 x i8>
  %6393 = sub nsw <16 x i8> %6391, %6392
  %6394 = zext <16 x i1> %6387 to <16 x i8>
  %6395 = sub nsw <16 x i8> %6393, %6394
  %6396 = add <16 x i8> %6395, %6381
  %6397 = shufflevector <16 x i8> %6396, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6398 = bitcast <16 x i8> %6397 to <8 x i16>
  %6399 = shufflevector <8 x i16> %6398, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6400 = shufflevector <8 x i16> %6302, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6401 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6399, <8 x i16> %6400) #5
  %6402 = shufflevector <8 x i16> %6398, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6403 = shufflevector <8 x i16> %6302, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6404 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6402, <8 x i16> %6403) #5
  %6405 = mul <4 x i32> %6401, <i32 455, i32 455, i32 455, i32 455>
  %6406 = add <4 x i32> %6405, <i32 2048, i32 2048, i32 2048, i32 2048>
  %6407 = lshr <4 x i32> %6406, <i32 12, i32 12, i32 12, i32 12>
  %6408 = shufflevector <16 x i8> %6396, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %6409 = bitcast <16 x i8> %6408 to <8 x i16>
  %6410 = shufflevector <8 x i16> %6409, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6411 = shufflevector <8 x i16> %6334, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6412 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6410, <8 x i16> %6411) #5
  %6413 = shufflevector <8 x i16> %6409, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6414 = shufflevector <8 x i16> %6334, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6415 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6413, <8 x i16> %6414) #5
  %6416 = mul <4 x i32> %6412, <i32 455, i32 455, i32 455, i32 455>
  %6417 = add <4 x i32> %6416, <i32 2048, i32 2048, i32 2048, i32 2048>
  %6418 = lshr <4 x i32> %6417, <i32 12, i32 12, i32 12, i32 12>
  %6419 = shufflevector <16 x i8> %6396, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6420 = load i16, i16* %5944, align 4
  %6421 = zext i16 %6420 to i32
  %6422 = shl <8 x i16> %6285, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %6423 = add <8 x i16> %6207, %6193
  %6424 = add <8 x i16> %6423, %6287
  %6425 = add <8 x i16> %6424, %6422
  %6426 = add <8 x i16> %6425, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6427 = lshr <8 x i16> %6426, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6428 = shufflevector <8 x i16> %6427, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6429 = shufflevector <8 x i16> %6427, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6430 = shl <4 x i32> %6289, <i32 1, i32 1, i32 1, i32 1>
  %6431 = add <4 x i32> %6223, <i32 8, i32 8, i32 8, i32 8>
  %6432 = add <4 x i32> %6431, %6252
  %6433 = add <4 x i32> %6432, %6430
  %6434 = add <4 x i32> %6433, %6294
  %6435 = lshr <4 x i32> %6434, <i32 4, i32 4, i32 4, i32 4>
  %6436 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6428, <8 x i16> %6428) #5
  %6437 = mul <4 x i32> %6435, <i32 25, i32 25, i32 25, i32 25>
  %6438 = sub <4 x i32> %6437, %6436
  %6439 = icmp sgt <4 x i32> %6438, zeroinitializer
  %6440 = select <4 x i1> %6439, <4 x i32> %6438, <4 x i32> zeroinitializer
  %6441 = insertelement <4 x i32> undef, i32 %6421, i32 0
  %6442 = shufflevector <4 x i32> %6441, <4 x i32> undef, <4 x i32> zeroinitializer
  %6443 = mul <4 x i32> %6440, %6442
  %6444 = add <4 x i32> %6443, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6445 = lshr <4 x i32> %6444, <i32 20, i32 20, i32 20, i32 20>
  %6446 = shl <4 x i32> %6292, <i32 1, i32 1, i32 1, i32 1>
  %6447 = add <4 x i32> %6234, <i32 8, i32 8, i32 8, i32 8>
  %6448 = add <4 x i32> %6447, %6263
  %6449 = add <4 x i32> %6448, %6446
  %6450 = add <4 x i32> %6449, %6297
  %6451 = lshr <4 x i32> %6450, <i32 4, i32 4, i32 4, i32 4>
  %6452 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6429, <8 x i16> %6429) #5
  %6453 = mul <4 x i32> %6451, <i32 25, i32 25, i32 25, i32 25>
  %6454 = sub <4 x i32> %6453, %6452
  %6455 = icmp sgt <4 x i32> %6454, zeroinitializer
  %6456 = select <4 x i1> %6455, <4 x i32> %6454, <4 x i32> zeroinitializer
  %6457 = mul <4 x i32> %6456, %6442
  %6458 = add <4 x i32> %6457, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6459 = lshr <4 x i32> %6458, <i32 20, i32 20, i32 20, i32 20>
  %6460 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6445, <4 x i32> %6459) #5
  %6461 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6460, <8 x i16> undef) #5
  %6462 = bitcast <16 x i8> %6461 to <2 x i64>
  %6463 = extractelement <2 x i64> %6462, i32 0
  %6464 = lshr i64 %6463, 8
  %6465 = lshr i64 %6463, 16
  %6466 = lshr i64 %6463, 24
  %6467 = lshr i64 %6463, 32
  %6468 = lshr i64 %6463, 40
  %6469 = lshr i64 %6463, 48
  %6470 = lshr i64 %6463, 56
  %6471 = and i64 %6463, 255
  %6472 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6471
  %6473 = load i8, i8* %6472, align 1
  %6474 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %6473, i64 0
  %6475 = and i64 %6464, 255
  %6476 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6475
  %6477 = load i8, i8* %6476, align 1
  %6478 = insertelement <16 x i8> %6474, i8 %6477, i64 1
  %6479 = and i64 %6465, 255
  %6480 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6479
  %6481 = load i8, i8* %6480, align 1
  %6482 = insertelement <16 x i8> %6478, i8 %6481, i64 2
  %6483 = and i64 %6466, 255
  %6484 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6483
  %6485 = load i8, i8* %6484, align 1
  %6486 = insertelement <16 x i8> %6482, i8 %6485, i64 3
  %6487 = and i64 %6467, 255
  %6488 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6487
  %6489 = load i8, i8* %6488, align 1
  %6490 = insertelement <16 x i8> %6486, i8 %6489, i64 4
  %6491 = and i64 %6468, 255
  %6492 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6491
  %6493 = load i8, i8* %6492, align 1
  %6494 = insertelement <16 x i8> %6490, i8 %6493, i64 5
  %6495 = and i64 %6469, 255
  %6496 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6495
  %6497 = load i8, i8* %6496, align 1
  %6498 = insertelement <16 x i8> %6494, i8 %6497, i64 6
  %6499 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6470
  %6500 = load i8, i8* %6499, align 1
  %6501 = insertelement <16 x i8> %6498, i8 %6500, i64 7
  %6502 = shufflevector <16 x i8> %6501, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6503 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6502, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %6504 = shufflevector <8 x i16> %6503, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6505 = shufflevector <8 x i16> %6425, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6506 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6504, <8 x i16> %6505) #5
  %6507 = shufflevector <8 x i16> %6503, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6508 = shufflevector <8 x i16> %6425, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6509 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6507, <8 x i16> %6508) #5
  %6510 = add <4 x i32> %6506, <i32 512, i32 512, i32 512, i32 512>
  %6511 = lshr <4 x i32> %6510, <i32 10, i32 10, i32 10, i32 10>
  %6512 = getelementptr inbounds i16, i16* %5935, i64 8
  %6513 = getelementptr inbounds i16, i16* %5950, i64 8
  %6514 = getelementptr inbounds i16, i16* %5939, i64 8
  %6515 = getelementptr inbounds i16, i16* %5952, i64 8
  %6516 = getelementptr inbounds i32, i32* %5936, i64 8
  %6517 = getelementptr inbounds i32, i32* %5951, i64 8
  %6518 = getelementptr inbounds i32, i32* %5940, i64 8
  %6519 = getelementptr inbounds i32, i32* %5953, i64 8
  br label %6520

6520:                                             ; preds = %6520, %6111
  %6521 = phi i64 [ %6552, %6520 ], [ 0, %6111 ]
  %6522 = phi <2 x i64> [ %6564, %6520 ], [ %6161, %6111 ]
  %6523 = phi <2 x i64> [ %6557, %6520 ], [ %6156, %6111 ]
  %6524 = phi <16 x i8> [ %7162, %6520 ], [ %6419, %6111 ]
  %6525 = phi <16 x i8> [ %7100, %6520 ], [ %6396, %6111 ]
  %6526 = phi <16 x i8> [ %7258, %6520 ], [ <i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, %6111 ]
  %6527 = phi <16 x i8> [ %7258, %6520 ], [ %6501, %6111 ]
  %6528 = phi <4 x i32> [ %6902, %6520 ], [ %6179, %6111 ]
  %6529 = phi <4 x i32> [ %6901, %6520 ], [ %6178, %6111 ]
  %6530 = phi <4 x i32> [ %6897, %6520 ], [ %6174, %6111 ]
  %6531 = phi <4 x i32> [ %6896, %6520 ], [ %6173, %6111 ]
  %6532 = phi <4 x i32> [ %7157, %6520 ], [ %6415, %6111 ]
  %6533 = phi <4 x i32> [ %7160, %6520 ], [ %6418, %6111 ]
  %6534 = phi <4 x i32> [ %7095, %6520 ], [ %6404, %6111 ]
  %6535 = phi <4 x i32> [ %7098, %6520 ], [ %6407, %6111 ]
  %6536 = phi <4 x i32> [ %7266, %6520 ], [ %6509, %6111 ]
  %6537 = phi <4 x i32> [ %7268, %6520 ], [ %6511, %6111 ]
  %6538 = phi i16* [ %7499, %6520 ], [ %5960, %6111 ]
  %6539 = phi i32* [ %7500, %6520 ], [ %5961, %6111 ]
  %6540 = mul <4 x i32> %6532, <i32 455, i32 455, i32 455, i32 455>
  %6541 = add <4 x i32> %6540, <i32 2048, i32 2048, i32 2048, i32 2048>
  %6542 = lshr <4 x i32> %6541, <i32 12, i32 12, i32 12, i32 12>
  %6543 = add <4 x i32> %6536, <i32 512, i32 512, i32 512, i32 512>
  %6544 = lshr <4 x i32> %6543, <i32 10, i32 10, i32 10, i32 10>
  %6545 = mul <4 x i32> %6534, <i32 455, i32 455, i32 455, i32 455>
  %6546 = add <4 x i32> %6545, <i32 2048, i32 2048, i32 2048, i32 2048>
  %6547 = lshr <4 x i32> %6546, <i32 12, i32 12, i32 12, i32 12>
  %6548 = bitcast <16 x i8> %6525 to <2 x i64>
  %6549 = bitcast <16 x i8> %6524 to <2 x i64>
  %6550 = getelementptr inbounds i16, i16* %6112, i64 %6521
  %6551 = getelementptr inbounds i16, i16* %6550, i64 16
  %6552 = add nuw nsw i64 %6521, 16
  %6553 = bitcast i16* %6551 to <2 x i64>*
  %6554 = load <2 x i64>, <2 x i64>* %6553, align 1
  %6555 = getelementptr inbounds i16, i16* %6550, i64 24
  %6556 = bitcast i16* %6555 to <2 x i64>*
  %6557 = load <2 x i64>, <2 x i64>* %6556, align 1
  %6558 = getelementptr inbounds i16, i16* %6151, i64 %6521
  %6559 = getelementptr inbounds i16, i16* %6558, i64 16
  %6560 = bitcast i16* %6559 to <2 x i64>*
  %6561 = load <2 x i64>, <2 x i64>* %6560, align 1
  %6562 = getelementptr inbounds i16, i16* %6558, i64 24
  %6563 = bitcast i16* %6562 to <2 x i64>*
  %6564 = load <2 x i64>, <2 x i64>* %6563, align 1
  %6565 = or i64 %6521, 8
  %6566 = bitcast <2 x i64> %6523 to <8 x i16>
  %6567 = bitcast <2 x i64> %6554 to <16 x i8>
  %6568 = bitcast <2 x i64> %6523 to <16 x i8>
  %6569 = shufflevector <16 x i8> %6568, <16 x i8> %6567, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %6570 = bitcast <16 x i8> %6569 to <8 x i16>
  %6571 = shufflevector <16 x i8> %6568, <16 x i8> %6567, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6572 = bitcast <16 x i8> %6571 to <8 x i16>
  %6573 = shufflevector <16 x i8> %6568, <16 x i8> %6567, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %6574 = bitcast <16 x i8> %6573 to <8 x i16>
  %6575 = shufflevector <16 x i8> %6568, <16 x i8> %6567, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6576 = bitcast <16 x i8> %6575 to <8 x i16>
  %6577 = add <8 x i16> %6576, %6566
  %6578 = add <8 x i16> %6572, %6570
  %6579 = add <8 x i16> %6578, %6574
  %6580 = add <8 x i16> %6577, %6579
  %6581 = bitcast <2 x i64> %6554 to <8 x i16>
  %6582 = bitcast <2 x i64> %6557 to <16 x i8>
  %6583 = shufflevector <16 x i8> %6567, <16 x i8> %6582, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %6584 = bitcast <16 x i8> %6583 to <8 x i16>
  %6585 = shufflevector <16 x i8> %6567, <16 x i8> %6582, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6586 = bitcast <16 x i8> %6585 to <8 x i16>
  %6587 = shufflevector <16 x i8> %6567, <16 x i8> %6582, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %6588 = bitcast <16 x i8> %6587 to <8 x i16>
  %6589 = shufflevector <16 x i8> %6567, <16 x i8> %6582, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6590 = bitcast <16 x i8> %6589 to <8 x i16>
  %6591 = add <8 x i16> %6590, %6581
  %6592 = add <8 x i16> %6586, %6584
  %6593 = add <8 x i16> %6592, %6588
  %6594 = add <8 x i16> %6591, %6593
  %6595 = getelementptr inbounds i16, i16* %5935, i64 %6565
  %6596 = bitcast i16* %6595 to <8 x i16>*
  store <8 x i16> %6579, <8 x i16>* %6596, align 16
  %6597 = getelementptr inbounds i16, i16* %6512, i64 %6565
  %6598 = bitcast i16* %6597 to <8 x i16>*
  store <8 x i16> %6593, <8 x i16>* %6598, align 16
  %6599 = getelementptr inbounds i16, i16* %5950, i64 %6565
  %6600 = bitcast i16* %6599 to <8 x i16>*
  store <8 x i16> %6580, <8 x i16>* %6600, align 16
  %6601 = getelementptr inbounds i16, i16* %6513, i64 %6565
  %6602 = bitcast i16* %6601 to <8 x i16>*
  store <8 x i16> %6594, <8 x i16>* %6602, align 16
  %6603 = bitcast <2 x i64> %6522 to <8 x i16>
  %6604 = bitcast <2 x i64> %6561 to <16 x i8>
  %6605 = bitcast <2 x i64> %6522 to <16 x i8>
  %6606 = shufflevector <16 x i8> %6605, <16 x i8> %6604, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %6607 = bitcast <16 x i8> %6606 to <8 x i16>
  %6608 = shufflevector <16 x i8> %6605, <16 x i8> %6604, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6609 = bitcast <16 x i8> %6608 to <8 x i16>
  %6610 = shufflevector <16 x i8> %6605, <16 x i8> %6604, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %6611 = bitcast <16 x i8> %6610 to <8 x i16>
  %6612 = shufflevector <16 x i8> %6605, <16 x i8> %6604, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6613 = bitcast <16 x i8> %6612 to <8 x i16>
  %6614 = add <8 x i16> %6613, %6603
  %6615 = add <8 x i16> %6609, %6607
  %6616 = add <8 x i16> %6615, %6611
  %6617 = add <8 x i16> %6614, %6616
  %6618 = bitcast <2 x i64> %6561 to <8 x i16>
  %6619 = bitcast <2 x i64> %6564 to <16 x i8>
  %6620 = shufflevector <16 x i8> %6604, <16 x i8> %6619, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %6621 = bitcast <16 x i8> %6620 to <8 x i16>
  %6622 = shufflevector <16 x i8> %6604, <16 x i8> %6619, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6623 = bitcast <16 x i8> %6622 to <8 x i16>
  %6624 = shufflevector <16 x i8> %6604, <16 x i8> %6619, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %6625 = bitcast <16 x i8> %6624 to <8 x i16>
  %6626 = shufflevector <16 x i8> %6604, <16 x i8> %6619, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6627 = bitcast <16 x i8> %6626 to <8 x i16>
  %6628 = add <8 x i16> %6627, %6618
  %6629 = add <8 x i16> %6623, %6621
  %6630 = add <8 x i16> %6629, %6625
  %6631 = add <8 x i16> %6628, %6630
  %6632 = getelementptr inbounds i16, i16* %5939, i64 %6565
  %6633 = bitcast i16* %6632 to <8 x i16>*
  store <8 x i16> %6616, <8 x i16>* %6633, align 16
  %6634 = getelementptr inbounds i16, i16* %6514, i64 %6565
  %6635 = bitcast i16* %6634 to <8 x i16>*
  store <8 x i16> %6630, <8 x i16>* %6635, align 16
  %6636 = getelementptr inbounds i16, i16* %5952, i64 %6565
  %6637 = bitcast i16* %6636 to <8 x i16>*
  store <8 x i16> %6617, <8 x i16>* %6637, align 16
  %6638 = getelementptr inbounds i16, i16* %6515, i64 %6565
  %6639 = bitcast i16* %6638 to <8 x i16>*
  store <8 x i16> %6631, <8 x i16>* %6639, align 16
  %6640 = shufflevector <8 x i16> %6581, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6641 = shufflevector <8 x i16> %6581, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6642 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6640, <8 x i16> %6640) #5
  %6643 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6641, <8 x i16> %6641) #5
  %6644 = shufflevector <8 x i16> %6618, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6645 = shufflevector <8 x i16> %6618, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6646 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6644, <8 x i16> %6644) #5
  %6647 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6645, <8 x i16> %6645) #5
  %6648 = bitcast <4 x i32> %6530 to <16 x i8>
  %6649 = bitcast <4 x i32> %6531 to <16 x i8>
  %6650 = shufflevector <16 x i8> %6649, <16 x i8> %6648, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6651 = bitcast <16 x i8> %6650 to <4 x i32>
  %6652 = shufflevector <16 x i8> %6649, <16 x i8> %6648, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6653 = bitcast <16 x i8> %6652 to <4 x i32>
  %6654 = shufflevector <16 x i8> %6649, <16 x i8> %6648, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6655 = bitcast <16 x i8> %6654 to <4 x i32>
  %6656 = add <4 x i32> %6531, %6530
  %6657 = add <4 x i32> %6653, %6651
  %6658 = add <4 x i32> %6657, %6655
  %6659 = add <4 x i32> %6656, %6658
  %6660 = bitcast <4 x i32> %6642 to <16 x i8>
  %6661 = shufflevector <16 x i8> %6648, <16 x i8> %6660, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6662 = bitcast <16 x i8> %6661 to <4 x i32>
  %6663 = shufflevector <16 x i8> %6648, <16 x i8> %6660, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6664 = bitcast <16 x i8> %6663 to <4 x i32>
  %6665 = shufflevector <16 x i8> %6648, <16 x i8> %6660, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6666 = bitcast <16 x i8> %6665 to <4 x i32>
  %6667 = add <4 x i32> %6642, %6530
  %6668 = add <4 x i32> %6664, %6662
  %6669 = add <4 x i32> %6668, %6666
  %6670 = add <4 x i32> %6667, %6669
  %6671 = getelementptr inbounds i32, i32* %5936, i64 %6565
  %6672 = bitcast i32* %6671 to <4 x i32>*
  store <4 x i32> %6658, <4 x i32>* %6672, align 16
  %6673 = getelementptr inbounds i32, i32* %6671, i64 4
  %6674 = bitcast i32* %6673 to <4 x i32>*
  store <4 x i32> %6669, <4 x i32>* %6674, align 16
  %6675 = getelementptr inbounds i32, i32* %5951, i64 %6565
  %6676 = bitcast i32* %6675 to <4 x i32>*
  store <4 x i32> %6659, <4 x i32>* %6676, align 16
  %6677 = getelementptr inbounds i32, i32* %6675, i64 4
  %6678 = bitcast i32* %6677 to <4 x i32>*
  store <4 x i32> %6670, <4 x i32>* %6678, align 16
  %6679 = bitcast <4 x i32> %6528 to <16 x i8>
  %6680 = bitcast <4 x i32> %6529 to <16 x i8>
  %6681 = shufflevector <16 x i8> %6680, <16 x i8> %6679, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6682 = bitcast <16 x i8> %6681 to <4 x i32>
  %6683 = shufflevector <16 x i8> %6680, <16 x i8> %6679, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6684 = bitcast <16 x i8> %6683 to <4 x i32>
  %6685 = shufflevector <16 x i8> %6680, <16 x i8> %6679, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6686 = bitcast <16 x i8> %6685 to <4 x i32>
  %6687 = add <4 x i32> %6529, %6528
  %6688 = add <4 x i32> %6684, %6682
  %6689 = add <4 x i32> %6688, %6686
  %6690 = add <4 x i32> %6687, %6689
  %6691 = bitcast <4 x i32> %6646 to <16 x i8>
  %6692 = shufflevector <16 x i8> %6679, <16 x i8> %6691, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6693 = bitcast <16 x i8> %6692 to <4 x i32>
  %6694 = shufflevector <16 x i8> %6679, <16 x i8> %6691, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6695 = bitcast <16 x i8> %6694 to <4 x i32>
  %6696 = shufflevector <16 x i8> %6679, <16 x i8> %6691, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6697 = bitcast <16 x i8> %6696 to <4 x i32>
  %6698 = add <4 x i32> %6646, %6528
  %6699 = add <4 x i32> %6695, %6693
  %6700 = add <4 x i32> %6699, %6697
  %6701 = add <4 x i32> %6698, %6700
  %6702 = getelementptr inbounds i32, i32* %5940, i64 %6565
  %6703 = bitcast i32* %6702 to <4 x i32>*
  store <4 x i32> %6689, <4 x i32>* %6703, align 16
  %6704 = getelementptr inbounds i32, i32* %6702, i64 4
  %6705 = bitcast i32* %6704 to <4 x i32>*
  store <4 x i32> %6700, <4 x i32>* %6705, align 16
  %6706 = getelementptr inbounds i32, i32* %5953, i64 %6565
  %6707 = bitcast i32* %6706 to <4 x i32>*
  store <4 x i32> %6690, <4 x i32>* %6707, align 16
  %6708 = getelementptr inbounds i32, i32* %6706, i64 4
  %6709 = bitcast i32* %6708 to <4 x i32>*
  store <4 x i32> %6701, <4 x i32>* %6709, align 16
  %6710 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %6565
  %6711 = bitcast i16* %6710 to <8 x i16>*
  %6712 = load <8 x i16>, <8 x i16>* %6711, align 16
  %6713 = getelementptr inbounds i16, i16* %5931, i64 %6565
  %6714 = bitcast i16* %6713 to <8 x i16>*
  %6715 = load <8 x i16>, <8 x i16>* %6714, align 16
  %6716 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 %6565
  %6717 = bitcast i32* %6716 to <4 x i32>*
  %6718 = load <4 x i32>, <4 x i32>* %6717, align 16
  %6719 = getelementptr inbounds i32, i32* %6716, i64 4
  %6720 = bitcast i32* %6719 to <4 x i32>*
  %6721 = load <4 x i32>, <4 x i32>* %6720, align 16
  %6722 = getelementptr inbounds i32, i32* %5932, i64 %6565
  %6723 = bitcast i32* %6722 to <4 x i32>*
  %6724 = load <4 x i32>, <4 x i32>* %6723, align 16
  %6725 = getelementptr inbounds i32, i32* %6722, i64 4
  %6726 = bitcast i32* %6725 to <4 x i32>*
  %6727 = load <4 x i32>, <4 x i32>* %6726, align 16
  %6728 = add <8 x i16> %6715, %6579
  %6729 = add <8 x i16> %6728, %6712
  %6730 = add <8 x i16> %6729, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6731 = lshr <8 x i16> %6730, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6732 = shufflevector <8 x i16> %6731, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6733 = shufflevector <8 x i16> %6731, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6734 = add <4 x i32> %6658, <i32 8, i32 8, i32 8, i32 8>
  %6735 = add <4 x i32> %6734, %6724
  %6736 = add <4 x i32> %6735, %6718
  %6737 = lshr <4 x i32> %6736, <i32 4, i32 4, i32 4, i32 4>
  %6738 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6732, <8 x i16> %6732) #5
  %6739 = mul nuw <4 x i32> %6737, <i32 9, i32 9, i32 9, i32 9>
  %6740 = sub <4 x i32> %6739, %6738
  %6741 = icmp sgt <4 x i32> %6740, zeroinitializer
  %6742 = select <4 x i1> %6741, <4 x i32> %6740, <4 x i32> zeroinitializer
  %6743 = mul <4 x i32> %6742, %6317
  %6744 = add <4 x i32> %6743, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6745 = lshr <4 x i32> %6744, <i32 20, i32 20, i32 20, i32 20>
  %6746 = add <4 x i32> %6669, <i32 8, i32 8, i32 8, i32 8>
  %6747 = add <4 x i32> %6746, %6727
  %6748 = add <4 x i32> %6747, %6721
  %6749 = lshr <4 x i32> %6748, <i32 4, i32 4, i32 4, i32 4>
  %6750 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6733, <8 x i16> %6733) #5
  %6751 = mul nuw <4 x i32> %6749, <i32 9, i32 9, i32 9, i32 9>
  %6752 = sub <4 x i32> %6751, %6750
  %6753 = icmp sgt <4 x i32> %6752, zeroinitializer
  %6754 = select <4 x i1> %6753, <4 x i32> %6752, <4 x i32> zeroinitializer
  %6755 = mul <4 x i32> %6754, %6317
  %6756 = add <4 x i32> %6755, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6757 = lshr <4 x i32> %6756, <i32 20, i32 20, i32 20, i32 20>
  %6758 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6745, <4 x i32> %6757) #5
  %6759 = add <8 x i16> %6728, %6616
  %6760 = add <8 x i16> %6759, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6761 = lshr <8 x i16> %6760, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6762 = shufflevector <8 x i16> %6761, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6763 = shufflevector <8 x i16> %6761, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6764 = add <4 x i32> %6735, %6689
  %6765 = lshr <4 x i32> %6764, <i32 4, i32 4, i32 4, i32 4>
  %6766 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6762, <8 x i16> %6762) #5
  %6767 = mul nuw <4 x i32> %6765, <i32 9, i32 9, i32 9, i32 9>
  %6768 = sub <4 x i32> %6767, %6766
  %6769 = icmp sgt <4 x i32> %6768, zeroinitializer
  %6770 = select <4 x i1> %6769, <4 x i32> %6768, <4 x i32> zeroinitializer
  %6771 = mul <4 x i32> %6770, %6317
  %6772 = add <4 x i32> %6771, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6773 = lshr <4 x i32> %6772, <i32 20, i32 20, i32 20, i32 20>
  %6774 = add <4 x i32> %6747, %6700
  %6775 = lshr <4 x i32> %6774, <i32 4, i32 4, i32 4, i32 4>
  %6776 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6763, <8 x i16> %6763) #5
  %6777 = mul nuw <4 x i32> %6775, <i32 9, i32 9, i32 9, i32 9>
  %6778 = sub <4 x i32> %6777, %6776
  %6779 = icmp sgt <4 x i32> %6778, zeroinitializer
  %6780 = select <4 x i1> %6779, <4 x i32> %6778, <4 x i32> zeroinitializer
  %6781 = mul <4 x i32> %6780, %6317
  %6782 = add <4 x i32> %6781, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6783 = lshr <4 x i32> %6782, <i32 20, i32 20, i32 20, i32 20>
  %6784 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6773, <4 x i32> %6783) #5
  %6785 = getelementptr inbounds i16, i16* %5946, i64 %6565
  %6786 = bitcast i16* %6785 to <8 x i16>*
  %6787 = load <8 x i16>, <8 x i16>* %6786, align 16
  %6788 = getelementptr inbounds i16, i16* %5948, i64 %6565
  %6789 = bitcast i16* %6788 to <8 x i16>*
  %6790 = load <8 x i16>, <8 x i16>* %6789, align 16
  %6791 = getelementptr inbounds i32, i32* %5947, i64 %6565
  %6792 = bitcast i32* %6791 to <4 x i32>*
  %6793 = load <4 x i32>, <4 x i32>* %6792, align 16
  %6794 = getelementptr inbounds i32, i32* %6791, i64 4
  %6795 = bitcast i32* %6794 to <4 x i32>*
  %6796 = load <4 x i32>, <4 x i32>* %6795, align 16
  %6797 = getelementptr inbounds i32, i32* %5949, i64 %6565
  %6798 = bitcast i32* %6797 to <4 x i32>*
  %6799 = load <4 x i32>, <4 x i32>* %6798, align 16
  %6800 = getelementptr inbounds i32, i32* %6797, i64 4
  %6801 = bitcast i32* %6800 to <4 x i32>*
  %6802 = load <4 x i32>, <4 x i32>* %6801, align 16
  %6803 = shl <8 x i16> %6787, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %6804 = add <8 x i16> %6617, %6580
  %6805 = add <8 x i16> %6804, %6790
  %6806 = add <8 x i16> %6805, %6803
  %6807 = add <8 x i16> %6806, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6808 = lshr <8 x i16> %6807, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6809 = shufflevector <8 x i16> %6808, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6810 = shufflevector <8 x i16> %6808, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6811 = shl <4 x i32> %6793, <i32 1, i32 1, i32 1, i32 1>
  %6812 = add <4 x i32> %6690, <i32 8, i32 8, i32 8, i32 8>
  %6813 = add <4 x i32> %6812, %6659
  %6814 = add <4 x i32> %6813, %6811
  %6815 = add <4 x i32> %6814, %6799
  %6816 = lshr <4 x i32> %6815, <i32 4, i32 4, i32 4, i32 4>
  %6817 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6809, <8 x i16> %6809) #5
  %6818 = mul <4 x i32> %6816, <i32 25, i32 25, i32 25, i32 25>
  %6819 = sub <4 x i32> %6818, %6817
  %6820 = icmp sgt <4 x i32> %6819, zeroinitializer
  %6821 = select <4 x i1> %6820, <4 x i32> %6819, <4 x i32> zeroinitializer
  %6822 = mul <4 x i32> %6821, %6442
  %6823 = add <4 x i32> %6822, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6824 = lshr <4 x i32> %6823, <i32 20, i32 20, i32 20, i32 20>
  %6825 = shl <4 x i32> %6796, <i32 1, i32 1, i32 1, i32 1>
  %6826 = add <4 x i32> %6670, <i32 8, i32 8, i32 8, i32 8>
  %6827 = add <4 x i32> %6826, %6701
  %6828 = add <4 x i32> %6827, %6825
  %6829 = add <4 x i32> %6828, %6802
  %6830 = lshr <4 x i32> %6829, <i32 4, i32 4, i32 4, i32 4>
  %6831 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6810, <8 x i16> %6810) #5
  %6832 = mul <4 x i32> %6830, <i32 25, i32 25, i32 25, i32 25>
  %6833 = sub <4 x i32> %6832, %6831
  %6834 = icmp sgt <4 x i32> %6833, zeroinitializer
  %6835 = select <4 x i1> %6834, <4 x i32> %6833, <4 x i32> zeroinitializer
  %6836 = mul <4 x i32> %6835, %6442
  %6837 = add <4 x i32> %6836, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6838 = lshr <4 x i32> %6837, <i32 20, i32 20, i32 20, i32 20>
  %6839 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6824, <4 x i32> %6838) #5
  %6840 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6839, <8 x i16> undef) #5
  %6841 = bitcast <16 x i8> %6840 to <2 x i64>
  %6842 = extractelement <2 x i64> %6841, i32 0
  %6843 = lshr i64 %6842, 8
  %6844 = lshr i64 %6842, 16
  %6845 = lshr i64 %6842, 24
  %6846 = lshr i64 %6842, 32
  %6847 = lshr i64 %6842, 40
  %6848 = lshr i64 %6842, 48
  %6849 = lshr i64 %6842, 56
  %6850 = and i64 %6842, 255
  %6851 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6850
  %6852 = load i8, i8* %6851, align 1
  %6853 = insertelement <16 x i8> %6527, i8 %6852, i64 8
  %6854 = and i64 %6843, 255
  %6855 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6854
  %6856 = load i8, i8* %6855, align 1
  %6857 = insertelement <16 x i8> %6853, i8 %6856, i64 9
  %6858 = and i64 %6844, 255
  %6859 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6858
  %6860 = load i8, i8* %6859, align 1
  %6861 = insertelement <16 x i8> %6857, i8 %6860, i64 10
  %6862 = and i64 %6845, 255
  %6863 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6862
  %6864 = load i8, i8* %6863, align 1
  %6865 = insertelement <16 x i8> %6861, i8 %6864, i64 11
  %6866 = and i64 %6846, 255
  %6867 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6866
  %6868 = load i8, i8* %6867, align 1
  %6869 = insertelement <16 x i8> %6865, i8 %6868, i64 12
  %6870 = and i64 %6847, 255
  %6871 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6870
  %6872 = load i8, i8* %6871, align 1
  %6873 = insertelement <16 x i8> %6869, i8 %6872, i64 13
  %6874 = and i64 %6848, 255
  %6875 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6874
  %6876 = load i8, i8* %6875, align 1
  %6877 = insertelement <16 x i8> %6873, i8 %6876, i64 14
  %6878 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %6849
  %6879 = load i8, i8* %6878, align 1
  %6880 = insertelement <16 x i8> %6877, i8 %6879, i64 15
  %6881 = shufflevector <16 x i8> %6880, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %6882 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6881, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %6883 = shufflevector <8 x i16> %6882, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6884 = shufflevector <8 x i16> %6806, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6885 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6883, <8 x i16> %6884) #5
  %6886 = shufflevector <8 x i16> %6882, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6887 = shufflevector <8 x i16> %6806, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6888 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6886, <8 x i16> %6887) #5
  %6889 = add <4 x i32> %6885, <i32 512, i32 512, i32 512, i32 512>
  %6890 = lshr <4 x i32> %6889, <i32 10, i32 10, i32 10, i32 10>
  %6891 = add <4 x i32> %6888, <i32 512, i32 512, i32 512, i32 512>
  %6892 = lshr <4 x i32> %6891, <i32 10, i32 10, i32 10, i32 10>
  %6893 = bitcast <2 x i64> %6557 to <8 x i16>
  %6894 = shufflevector <8 x i16> %6893, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6895 = shufflevector <8 x i16> %6893, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6896 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6894, <8 x i16> %6894) #5
  %6897 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6895, <8 x i16> %6895) #5
  %6898 = bitcast <2 x i64> %6564 to <8 x i16>
  %6899 = shufflevector <8 x i16> %6898, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6900 = shufflevector <8 x i16> %6898, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6901 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6899, <8 x i16> %6899) #5
  %6902 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6900, <8 x i16> %6900) #5
  %6903 = bitcast <4 x i32> %6643 to <16 x i8>
  %6904 = shufflevector <16 x i8> %6660, <16 x i8> %6903, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6905 = bitcast <16 x i8> %6904 to <4 x i32>
  %6906 = shufflevector <16 x i8> %6660, <16 x i8> %6903, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6907 = bitcast <16 x i8> %6906 to <4 x i32>
  %6908 = shufflevector <16 x i8> %6660, <16 x i8> %6903, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6909 = bitcast <16 x i8> %6908 to <4 x i32>
  %6910 = add <4 x i32> %6643, %6642
  %6911 = add <4 x i32> %6907, %6905
  %6912 = add <4 x i32> %6911, %6909
  %6913 = add <4 x i32> %6910, %6912
  %6914 = bitcast <4 x i32> %6896 to <16 x i8>
  %6915 = shufflevector <16 x i8> %6903, <16 x i8> %6914, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6916 = bitcast <16 x i8> %6915 to <4 x i32>
  %6917 = shufflevector <16 x i8> %6903, <16 x i8> %6914, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6918 = bitcast <16 x i8> %6917 to <4 x i32>
  %6919 = shufflevector <16 x i8> %6903, <16 x i8> %6914, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6920 = bitcast <16 x i8> %6919 to <4 x i32>
  %6921 = add <4 x i32> %6896, %6643
  %6922 = add <4 x i32> %6918, %6916
  %6923 = add <4 x i32> %6922, %6920
  %6924 = add <4 x i32> %6921, %6923
  %6925 = getelementptr inbounds i32, i32* %6516, i64 %6565
  %6926 = bitcast i32* %6925 to <4 x i32>*
  store <4 x i32> %6912, <4 x i32>* %6926, align 16
  %6927 = getelementptr inbounds i32, i32* %6925, i64 4
  %6928 = bitcast i32* %6927 to <4 x i32>*
  store <4 x i32> %6923, <4 x i32>* %6928, align 16
  %6929 = getelementptr inbounds i32, i32* %6517, i64 %6565
  %6930 = bitcast i32* %6929 to <4 x i32>*
  store <4 x i32> %6913, <4 x i32>* %6930, align 16
  %6931 = getelementptr inbounds i32, i32* %6929, i64 4
  %6932 = bitcast i32* %6931 to <4 x i32>*
  store <4 x i32> %6924, <4 x i32>* %6932, align 16
  %6933 = bitcast <4 x i32> %6647 to <16 x i8>
  %6934 = shufflevector <16 x i8> %6691, <16 x i8> %6933, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6935 = bitcast <16 x i8> %6934 to <4 x i32>
  %6936 = shufflevector <16 x i8> %6691, <16 x i8> %6933, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6937 = bitcast <16 x i8> %6936 to <4 x i32>
  %6938 = shufflevector <16 x i8> %6691, <16 x i8> %6933, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6939 = bitcast <16 x i8> %6938 to <4 x i32>
  %6940 = add <4 x i32> %6647, %6646
  %6941 = add <4 x i32> %6937, %6935
  %6942 = add <4 x i32> %6941, %6939
  %6943 = add <4 x i32> %6940, %6942
  %6944 = bitcast <4 x i32> %6901 to <16 x i8>
  %6945 = shufflevector <16 x i8> %6933, <16 x i8> %6944, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %6946 = bitcast <16 x i8> %6945 to <4 x i32>
  %6947 = shufflevector <16 x i8> %6933, <16 x i8> %6944, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %6948 = bitcast <16 x i8> %6947 to <4 x i32>
  %6949 = shufflevector <16 x i8> %6933, <16 x i8> %6944, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %6950 = bitcast <16 x i8> %6949 to <4 x i32>
  %6951 = add <4 x i32> %6901, %6647
  %6952 = add <4 x i32> %6948, %6946
  %6953 = add <4 x i32> %6952, %6950
  %6954 = add <4 x i32> %6951, %6953
  %6955 = getelementptr inbounds i32, i32* %6518, i64 %6565
  %6956 = bitcast i32* %6955 to <4 x i32>*
  store <4 x i32> %6942, <4 x i32>* %6956, align 16
  %6957 = getelementptr inbounds i32, i32* %6955, i64 4
  %6958 = bitcast i32* %6957 to <4 x i32>*
  store <4 x i32> %6953, <4 x i32>* %6958, align 16
  %6959 = getelementptr inbounds i32, i32* %6519, i64 %6565
  %6960 = bitcast i32* %6959 to <4 x i32>*
  store <4 x i32> %6943, <4 x i32>* %6960, align 16
  %6961 = getelementptr inbounds i32, i32* %6959, i64 4
  %6962 = bitcast i32* %6961 to <4 x i32>*
  store <4 x i32> %6954, <4 x i32>* %6962, align 16
  %6963 = add nuw nsw i64 %6565, 8
  %6964 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 0, i64 %6963
  %6965 = bitcast i16* %6964 to <8 x i16>*
  %6966 = load <8 x i16>, <8 x i16>* %6965, align 16
  %6967 = getelementptr inbounds i16, i16* %5931, i64 %6963
  %6968 = bitcast i16* %6967 to <8 x i16>*
  %6969 = load <8 x i16>, <8 x i16>* %6968, align 16
  %6970 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 2, i64 %6963
  %6971 = bitcast i32* %6970 to <4 x i32>*
  %6972 = load <4 x i32>, <4 x i32>* %6971, align 16
  %6973 = getelementptr inbounds i32, i32* %6970, i64 4
  %6974 = bitcast i32* %6973 to <4 x i32>*
  %6975 = load <4 x i32>, <4 x i32>* %6974, align 16
  %6976 = getelementptr inbounds i32, i32* %5932, i64 %6963
  %6977 = bitcast i32* %6976 to <4 x i32>*
  %6978 = load <4 x i32>, <4 x i32>* %6977, align 16
  %6979 = getelementptr inbounds i32, i32* %6976, i64 4
  %6980 = bitcast i32* %6979 to <4 x i32>*
  %6981 = load <4 x i32>, <4 x i32>* %6980, align 16
  %6982 = add <8 x i16> %6969, %6593
  %6983 = add <8 x i16> %6982, %6966
  %6984 = add <8 x i16> %6983, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6985 = lshr <8 x i16> %6984, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %6986 = shufflevector <8 x i16> %6985, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6987 = shufflevector <8 x i16> %6985, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6988 = add <4 x i32> %6912, <i32 8, i32 8, i32 8, i32 8>
  %6989 = add <4 x i32> %6988, %6978
  %6990 = add <4 x i32> %6989, %6972
  %6991 = lshr <4 x i32> %6990, <i32 4, i32 4, i32 4, i32 4>
  %6992 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6986, <8 x i16> %6986) #5
  %6993 = mul nuw <4 x i32> %6991, <i32 9, i32 9, i32 9, i32 9>
  %6994 = sub <4 x i32> %6993, %6992
  %6995 = icmp sgt <4 x i32> %6994, zeroinitializer
  %6996 = select <4 x i1> %6995, <4 x i32> %6994, <4 x i32> zeroinitializer
  %6997 = mul <4 x i32> %6996, %6317
  %6998 = add <4 x i32> %6997, <i32 524288, i32 524288, i32 524288, i32 524288>
  %6999 = lshr <4 x i32> %6998, <i32 20, i32 20, i32 20, i32 20>
  %7000 = add <4 x i32> %6923, <i32 8, i32 8, i32 8, i32 8>
  %7001 = add <4 x i32> %7000, %6981
  %7002 = add <4 x i32> %7001, %6975
  %7003 = lshr <4 x i32> %7002, <i32 4, i32 4, i32 4, i32 4>
  %7004 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6987, <8 x i16> %6987) #5
  %7005 = mul nuw <4 x i32> %7003, <i32 9, i32 9, i32 9, i32 9>
  %7006 = sub <4 x i32> %7005, %7004
  %7007 = icmp sgt <4 x i32> %7006, zeroinitializer
  %7008 = select <4 x i1> %7007, <4 x i32> %7006, <4 x i32> zeroinitializer
  %7009 = mul <4 x i32> %7008, %6317
  %7010 = add <4 x i32> %7009, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7011 = lshr <4 x i32> %7010, <i32 20, i32 20, i32 20, i32 20>
  %7012 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6999, <4 x i32> %7011) #5
  %7013 = add <8 x i16> %6982, %6630
  %7014 = add <8 x i16> %7013, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7015 = lshr <8 x i16> %7014, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7016 = shufflevector <8 x i16> %7015, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7017 = shufflevector <8 x i16> %7015, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7018 = add <4 x i32> %6989, %6942
  %7019 = lshr <4 x i32> %7018, <i32 4, i32 4, i32 4, i32 4>
  %7020 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7016, <8 x i16> %7016) #5
  %7021 = mul nuw <4 x i32> %7019, <i32 9, i32 9, i32 9, i32 9>
  %7022 = sub <4 x i32> %7021, %7020
  %7023 = icmp sgt <4 x i32> %7022, zeroinitializer
  %7024 = select <4 x i1> %7023, <4 x i32> %7022, <4 x i32> zeroinitializer
  %7025 = mul <4 x i32> %7024, %6317
  %7026 = add <4 x i32> %7025, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7027 = lshr <4 x i32> %7026, <i32 20, i32 20, i32 20, i32 20>
  %7028 = add <4 x i32> %7001, %6953
  %7029 = lshr <4 x i32> %7028, <i32 4, i32 4, i32 4, i32 4>
  %7030 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7017, <8 x i16> %7017) #5
  %7031 = mul nuw <4 x i32> %7029, <i32 9, i32 9, i32 9, i32 9>
  %7032 = sub <4 x i32> %7031, %7030
  %7033 = icmp sgt <4 x i32> %7032, zeroinitializer
  %7034 = select <4 x i1> %7033, <4 x i32> %7032, <4 x i32> zeroinitializer
  %7035 = mul <4 x i32> %7034, %6317
  %7036 = add <4 x i32> %7035, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7037 = lshr <4 x i32> %7036, <i32 20, i32 20, i32 20, i32 20>
  %7038 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %7027, <4 x i32> %7037) #5
  %7039 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6758, <8 x i16> %7012) #5
  %7040 = icmp ult <16 x i8> %7039, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7041 = select <16 x i1> %7040, <16 x i8> %7039, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7042 = icmp sgt <16 x i8> %7041, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7043 = select <16 x i1> %7042, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7041
  %7044 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %7043) #5
  %7045 = add nsw <16 x i8> %7041, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %7046 = icmp sgt <16 x i8> %7045, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7047 = select <16 x i1> %7046, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7045
  %7048 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %7047) #5
  %7049 = or <16 x i8> %7048, %7044
  %7050 = add nsw <16 x i8> %7041, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %7051 = icmp sgt <16 x i8> %7050, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7052 = select <16 x i1> %7051, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7050
  %7053 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %7052) #5
  %7054 = or <16 x i8> %7049, %7053
  %7055 = xor <16 x i8> %7039, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %7056 = icmp ugt <16 x i8> %7054, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %7057 = select <16 x i1> %7056, <16 x i8> %7054, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %7058 = icmp sgt <16 x i8> %7055, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %7059 = icmp sgt <16 x i8> %7055, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %7060 = sext <16 x i1> %7059 to <16 x i8>
  %7061 = icmp sgt <16 x i8> %7055, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %7062 = icmp sgt <16 x i8> %7055, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %7063 = icmp eq <16 x i8> %7055, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7064 = zext <16 x i1> %7058 to <16 x i8>
  %7065 = sub nsw <16 x i8> %7060, %7064
  %7066 = zext <16 x i1> %7061 to <16 x i8>
  %7067 = sub nsw <16 x i8> %7065, %7066
  %7068 = zext <16 x i1> %7062 to <16 x i8>
  %7069 = sub nsw <16 x i8> %7067, %7068
  %7070 = zext <16 x i1> %7063 to <16 x i8>
  %7071 = sub nsw <16 x i8> %7069, %7070
  %7072 = add <16 x i8> %7071, %7057
  %7073 = bitcast <16 x i8> %7072 to <2 x i64>
  %7074 = shufflevector <16 x i8> %7072, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7075 = bitcast <16 x i8> %7074 to <8 x i16>
  %7076 = shufflevector <8 x i16> %7075, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7077 = shufflevector <8 x i16> %6729, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7078 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7076, <8 x i16> %7077) #5
  %7079 = shufflevector <8 x i16> %7075, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7080 = shufflevector <8 x i16> %6729, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7081 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7079, <8 x i16> %7080) #5
  %7082 = mul <4 x i32> %7078, <i32 455, i32 455, i32 455, i32 455>
  %7083 = mul <4 x i32> %7081, <i32 455, i32 455, i32 455, i32 455>
  %7084 = add <4 x i32> %7082, <i32 2048, i32 2048, i32 2048, i32 2048>
  %7085 = lshr <4 x i32> %7084, <i32 12, i32 12, i32 12, i32 12>
  %7086 = add <4 x i32> %7083, <i32 2048, i32 2048, i32 2048, i32 2048>
  %7087 = lshr <4 x i32> %7086, <i32 12, i32 12, i32 12, i32 12>
  %7088 = shufflevector <16 x i8> %7072, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7089 = bitcast <16 x i8> %7088 to <8 x i16>
  %7090 = shufflevector <8 x i16> %7089, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7091 = shufflevector <8 x i16> %6983, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7092 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7090, <8 x i16> %7091) #5
  %7093 = shufflevector <8 x i16> %7089, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7094 = shufflevector <8 x i16> %6983, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7095 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7093, <8 x i16> %7094) #5
  %7096 = mul <4 x i32> %7092, <i32 455, i32 455, i32 455, i32 455>
  %7097 = add <4 x i32> %7096, <i32 2048, i32 2048, i32 2048, i32 2048>
  %7098 = lshr <4 x i32> %7097, <i32 12, i32 12, i32 12, i32 12>
  %7099 = shufflevector <2 x i64> %6548, <2 x i64> %7073, <2 x i32> <i32 0, i32 2>
  %7100 = shufflevector <16 x i8> %7072, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6784, <8 x i16> %7038) #5
  %7102 = icmp ult <16 x i8> %7101, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7103 = select <16 x i1> %7102, <16 x i8> %7101, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7104 = icmp sgt <16 x i8> %7103, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7105 = select <16 x i1> %7104, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7103
  %7106 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %7105) #5
  %7107 = add nsw <16 x i8> %7103, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %7108 = icmp sgt <16 x i8> %7107, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7109 = select <16 x i1> %7108, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7107
  %7110 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %7109) #5
  %7111 = or <16 x i8> %7110, %7106
  %7112 = add nsw <16 x i8> %7103, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %7113 = icmp sgt <16 x i8> %7112, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7114 = select <16 x i1> %7113, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7112
  %7115 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %7114) #5
  %7116 = or <16 x i8> %7111, %7115
  %7117 = xor <16 x i8> %7101, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %7118 = icmp ugt <16 x i8> %7116, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %7119 = select <16 x i1> %7118, <16 x i8> %7116, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %7120 = icmp sgt <16 x i8> %7117, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %7121 = icmp sgt <16 x i8> %7117, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %7122 = sext <16 x i1> %7121 to <16 x i8>
  %7123 = icmp sgt <16 x i8> %7117, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %7124 = icmp sgt <16 x i8> %7117, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %7125 = icmp eq <16 x i8> %7117, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7126 = zext <16 x i1> %7120 to <16 x i8>
  %7127 = sub nsw <16 x i8> %7122, %7126
  %7128 = zext <16 x i1> %7123 to <16 x i8>
  %7129 = sub nsw <16 x i8> %7127, %7128
  %7130 = zext <16 x i1> %7124 to <16 x i8>
  %7131 = sub nsw <16 x i8> %7129, %7130
  %7132 = zext <16 x i1> %7125 to <16 x i8>
  %7133 = sub nsw <16 x i8> %7131, %7132
  %7134 = add <16 x i8> %7133, %7119
  %7135 = bitcast <16 x i8> %7134 to <2 x i64>
  %7136 = shufflevector <16 x i8> %7134, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7137 = bitcast <16 x i8> %7136 to <8 x i16>
  %7138 = shufflevector <8 x i16> %7137, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7139 = shufflevector <8 x i16> %6759, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7140 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7138, <8 x i16> %7139) #5
  %7141 = shufflevector <8 x i16> %7137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7142 = shufflevector <8 x i16> %6759, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7143 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7141, <8 x i16> %7142) #5
  %7144 = mul <4 x i32> %7140, <i32 455, i32 455, i32 455, i32 455>
  %7145 = mul <4 x i32> %7143, <i32 455, i32 455, i32 455, i32 455>
  %7146 = add <4 x i32> %7144, <i32 2048, i32 2048, i32 2048, i32 2048>
  %7147 = lshr <4 x i32> %7146, <i32 12, i32 12, i32 12, i32 12>
  %7148 = add <4 x i32> %7145, <i32 2048, i32 2048, i32 2048, i32 2048>
  %7149 = lshr <4 x i32> %7148, <i32 12, i32 12, i32 12, i32 12>
  %7150 = shufflevector <16 x i8> %7134, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7151 = bitcast <16 x i8> %7150 to <8 x i16>
  %7152 = shufflevector <8 x i16> %7151, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7153 = shufflevector <8 x i16> %7013, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7154 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7152, <8 x i16> %7153) #5
  %7155 = shufflevector <8 x i16> %7151, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7156 = shufflevector <8 x i16> %7013, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7155, <8 x i16> %7156) #5
  %7158 = mul <4 x i32> %7154, <i32 455, i32 455, i32 455, i32 455>
  %7159 = add <4 x i32> %7158, <i32 2048, i32 2048, i32 2048, i32 2048>
  %7160 = lshr <4 x i32> %7159, <i32 12, i32 12, i32 12, i32 12>
  %7161 = shufflevector <2 x i64> %6549, <2 x i64> %7135, <2 x i32> <i32 0, i32 2>
  %7162 = shufflevector <16 x i8> %7134, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7163 = getelementptr inbounds i16, i16* %5946, i64 %6963
  %7164 = bitcast i16* %7163 to <8 x i16>*
  %7165 = load <8 x i16>, <8 x i16>* %7164, align 16
  %7166 = getelementptr inbounds i16, i16* %5948, i64 %6963
  %7167 = bitcast i16* %7166 to <8 x i16>*
  %7168 = load <8 x i16>, <8 x i16>* %7167, align 16
  %7169 = getelementptr inbounds i32, i32* %5947, i64 %6963
  %7170 = bitcast i32* %7169 to <4 x i32>*
  %7171 = load <4 x i32>, <4 x i32>* %7170, align 16
  %7172 = getelementptr inbounds i32, i32* %7169, i64 4
  %7173 = bitcast i32* %7172 to <4 x i32>*
  %7174 = load <4 x i32>, <4 x i32>* %7173, align 16
  %7175 = getelementptr inbounds i32, i32* %5949, i64 %6963
  %7176 = bitcast i32* %7175 to <4 x i32>*
  %7177 = load <4 x i32>, <4 x i32>* %7176, align 16
  %7178 = getelementptr inbounds i32, i32* %7175, i64 4
  %7179 = bitcast i32* %7178 to <4 x i32>*
  %7180 = load <4 x i32>, <4 x i32>* %7179, align 16
  %7181 = shl <8 x i16> %7165, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %7182 = add <8 x i16> %6631, %6594
  %7183 = add <8 x i16> %7182, %7168
  %7184 = add <8 x i16> %7183, %7181
  %7185 = add <8 x i16> %7184, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7186 = lshr <8 x i16> %7185, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7187 = shufflevector <8 x i16> %7186, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7188 = shufflevector <8 x i16> %7186, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7189 = shl <4 x i32> %7171, <i32 1, i32 1, i32 1, i32 1>
  %7190 = add <4 x i32> %6913, <i32 8, i32 8, i32 8, i32 8>
  %7191 = add <4 x i32> %7190, %6943
  %7192 = add <4 x i32> %7191, %7189
  %7193 = add <4 x i32> %7192, %7177
  %7194 = lshr <4 x i32> %7193, <i32 4, i32 4, i32 4, i32 4>
  %7195 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7187, <8 x i16> %7187) #5
  %7196 = mul <4 x i32> %7194, <i32 25, i32 25, i32 25, i32 25>
  %7197 = sub <4 x i32> %7196, %7195
  %7198 = icmp sgt <4 x i32> %7197, zeroinitializer
  %7199 = select <4 x i1> %7198, <4 x i32> %7197, <4 x i32> zeroinitializer
  %7200 = mul <4 x i32> %7199, %6442
  %7201 = add <4 x i32> %7200, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7202 = lshr <4 x i32> %7201, <i32 20, i32 20, i32 20, i32 20>
  %7203 = shl <4 x i32> %7174, <i32 1, i32 1, i32 1, i32 1>
  %7204 = add <4 x i32> %6924, <i32 8, i32 8, i32 8, i32 8>
  %7205 = add <4 x i32> %7204, %6954
  %7206 = add <4 x i32> %7205, %7203
  %7207 = add <4 x i32> %7206, %7180
  %7208 = lshr <4 x i32> %7207, <i32 4, i32 4, i32 4, i32 4>
  %7209 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7188, <8 x i16> %7188) #5
  %7210 = mul <4 x i32> %7208, <i32 25, i32 25, i32 25, i32 25>
  %7211 = sub <4 x i32> %7210, %7209
  %7212 = icmp sgt <4 x i32> %7211, zeroinitializer
  %7213 = select <4 x i1> %7212, <4 x i32> %7211, <4 x i32> zeroinitializer
  %7214 = mul <4 x i32> %7213, %6442
  %7215 = add <4 x i32> %7214, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7216 = lshr <4 x i32> %7215, <i32 20, i32 20, i32 20, i32 20>
  %7217 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %7202, <4 x i32> %7216) #5
  %7218 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7217, <8 x i16> undef) #5
  %7219 = bitcast <16 x i8> %7218 to <2 x i64>
  %7220 = extractelement <2 x i64> %7219, i32 0
  %7221 = lshr i64 %7220, 8
  %7222 = lshr i64 %7220, 16
  %7223 = lshr i64 %7220, 24
  %7224 = lshr i64 %7220, 32
  %7225 = lshr i64 %7220, 40
  %7226 = lshr i64 %7220, 48
  %7227 = lshr i64 %7220, 56
  %7228 = and i64 %7220, 255
  %7229 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7228
  %7230 = load i8, i8* %7229, align 1
  %7231 = insertelement <16 x i8> %6526, i8 %7230, i64 0
  %7232 = and i64 %7221, 255
  %7233 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7232
  %7234 = load i8, i8* %7233, align 1
  %7235 = insertelement <16 x i8> %7231, i8 %7234, i64 1
  %7236 = and i64 %7222, 255
  %7237 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7236
  %7238 = load i8, i8* %7237, align 1
  %7239 = insertelement <16 x i8> %7235, i8 %7238, i64 2
  %7240 = and i64 %7223, 255
  %7241 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7240
  %7242 = load i8, i8* %7241, align 1
  %7243 = insertelement <16 x i8> %7239, i8 %7242, i64 3
  %7244 = and i64 %7224, 255
  %7245 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7244
  %7246 = load i8, i8* %7245, align 1
  %7247 = insertelement <16 x i8> %7243, i8 %7246, i64 4
  %7248 = and i64 %7225, 255
  %7249 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7248
  %7250 = load i8, i8* %7249, align 1
  %7251 = insertelement <16 x i8> %7247, i8 %7250, i64 5
  %7252 = and i64 %7226, 255
  %7253 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7252
  %7254 = load i8, i8* %7253, align 1
  %7255 = insertelement <16 x i8> %7251, i8 %7254, i64 6
  %7256 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7227
  %7257 = load i8, i8* %7256, align 1
  %7258 = insertelement <16 x i8> %7255, i8 %7257, i64 7
  %7259 = shufflevector <16 x i8> %7258, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7260 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7259, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %7261 = shufflevector <8 x i16> %7260, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7262 = shufflevector <8 x i16> %7184, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7263 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7261, <8 x i16> %7262) #5
  %7264 = shufflevector <8 x i16> %7260, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7265 = shufflevector <8 x i16> %7184, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7266 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7264, <8 x i16> %7265) #5
  %7267 = add <4 x i32> %7263, <i32 512, i32 512, i32 512, i32 512>
  %7268 = lshr <4 x i32> %7267, <i32 10, i32 10, i32 10, i32 10>
  %7269 = bitcast <2 x i64> %7099 to <16 x i8>
  %7270 = shufflevector <16 x i8> %7269, <16 x i8> %7100, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %7271 = shufflevector <16 x i8> %7269, <16 x i8> %7100, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %7272 = shufflevector <16 x i8> %7269, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7273 = shufflevector <16 x i8> %7270, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7274 = bitcast <16 x i8> %7272 to <8 x i16>
  %7275 = bitcast <16 x i8> %7273 to <8 x i16>
  %7276 = add <8 x i16> %7275, %7274
  %7277 = shufflevector <16 x i8> %7271, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7278 = bitcast <16 x i8> %7277 to <8 x i16>
  %7279 = add <8 x i16> %7276, %7278
  %7280 = mul <8 x i16> %7279, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %7281 = add <8 x i16> %7280, %7275
  %7282 = shufflevector <16 x i8> %7269, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7283 = shufflevector <16 x i8> %7270, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7284 = bitcast <16 x i8> %7282 to <8 x i16>
  %7285 = bitcast <16 x i8> %7283 to <8 x i16>
  %7286 = add <8 x i16> %7285, %7284
  %7287 = shufflevector <16 x i8> %7271, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7288 = bitcast <16 x i8> %7287 to <8 x i16>
  %7289 = add <8 x i16> %7286, %7288
  %7290 = mul <8 x i16> %7289, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %7291 = add <8 x i16> %7290, %7285
  %7292 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 4, i64 %6521
  %7293 = bitcast i16* %7292 to <8 x i16>*
  store <8 x i16> %7281, <8 x i16>* %7293, align 16
  %7294 = getelementptr inbounds i16, i16* %7292, i64 8
  %7295 = bitcast i16* %7294 to <8 x i16>*
  store <8 x i16> %7291, <8 x i16>* %7295, align 16
  %7296 = bitcast <4 x i32> %6547 to <16 x i8>
  %7297 = bitcast <4 x i32> %6535 to <16 x i8>
  %7298 = shufflevector <16 x i8> %7297, <16 x i8> %7296, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7299 = bitcast <16 x i8> %7298 to <4 x i32>
  %7300 = shufflevector <16 x i8> %7297, <16 x i8> %7296, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7301 = bitcast <16 x i8> %7300 to <4 x i32>
  %7302 = add <4 x i32> %6535, %7299
  %7303 = add <4 x i32> %7302, %7301
  %7304 = mul <4 x i32> %7303, <i32 3, i32 3, i32 3, i32 3>
  %7305 = add <4 x i32> %7304, %7299
  %7306 = bitcast <4 x i32> %7085 to <16 x i8>
  %7307 = shufflevector <16 x i8> %7296, <16 x i8> %7306, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7308 = bitcast <16 x i8> %7307 to <4 x i32>
  %7309 = shufflevector <16 x i8> %7296, <16 x i8> %7306, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7310 = bitcast <16 x i8> %7309 to <4 x i32>
  %7311 = add <4 x i32> %6547, %7308
  %7312 = add <4 x i32> %7311, %7310
  %7313 = mul <4 x i32> %7312, <i32 3, i32 3, i32 3, i32 3>
  %7314 = add <4 x i32> %7313, %7308
  %7315 = bitcast <4 x i32> %7087 to <16 x i8>
  %7316 = shufflevector <16 x i8> %7306, <16 x i8> %7315, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7317 = bitcast <16 x i8> %7316 to <4 x i32>
  %7318 = shufflevector <16 x i8> %7306, <16 x i8> %7315, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7319 = bitcast <16 x i8> %7318 to <4 x i32>
  %7320 = add <4 x i32> %7085, %7317
  %7321 = add <4 x i32> %7320, %7319
  %7322 = mul <4 x i32> %7321, <i32 3, i32 3, i32 3, i32 3>
  %7323 = add <4 x i32> %7322, %7317
  %7324 = bitcast <4 x i32> %7098 to <16 x i8>
  %7325 = shufflevector <16 x i8> %7315, <16 x i8> %7324, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7326 = bitcast <16 x i8> %7325 to <4 x i32>
  %7327 = shufflevector <16 x i8> %7315, <16 x i8> %7324, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7328 = bitcast <16 x i8> %7327 to <4 x i32>
  %7329 = add <4 x i32> %7087, %7326
  %7330 = add <4 x i32> %7329, %7328
  %7331 = mul <4 x i32> %7330, <i32 3, i32 3, i32 3, i32 3>
  %7332 = add <4 x i32> %7331, %7326
  %7333 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 7, i64 %6521
  %7334 = bitcast i32* %7333 to <4 x i32>*
  store <4 x i32> %7305, <4 x i32>* %7334, align 16
  %7335 = getelementptr inbounds i32, i32* %7333, i64 4
  %7336 = bitcast i32* %7335 to <4 x i32>*
  store <4 x i32> %7314, <4 x i32>* %7336, align 16
  %7337 = getelementptr inbounds i32, i32* %7333, i64 8
  %7338 = bitcast i32* %7337 to <4 x i32>*
  store <4 x i32> %7323, <4 x i32>* %7338, align 16
  %7339 = getelementptr inbounds i32, i32* %7333, i64 12
  %7340 = bitcast i32* %7339 to <4 x i32>*
  store <4 x i32> %7332, <4 x i32>* %7340, align 16
  %7341 = bitcast <4 x i32> %6544 to <16 x i8>
  %7342 = bitcast <4 x i32> %6537 to <16 x i8>
  %7343 = shufflevector <16 x i8> %7342, <16 x i8> %7341, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7344 = bitcast <16 x i8> %7343 to <4 x i32>
  %7345 = shufflevector <16 x i8> %7342, <16 x i8> %7341, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7346 = bitcast <16 x i8> %7345 to <4 x i32>
  %7347 = add <4 x i32> %6537, %7344
  %7348 = add <4 x i32> %7347, %7346
  %7349 = mul <4 x i32> %7348, <i32 5, i32 5, i32 5, i32 5>
  %7350 = add <4 x i32> %7349, %7344
  %7351 = bitcast <4 x i32> %6890 to <16 x i8>
  %7352 = shufflevector <16 x i8> %7341, <16 x i8> %7351, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7353 = bitcast <16 x i8> %7352 to <4 x i32>
  %7354 = shufflevector <16 x i8> %7341, <16 x i8> %7351, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7355 = bitcast <16 x i8> %7354 to <4 x i32>
  %7356 = add <4 x i32> %6544, %7353
  %7357 = add <4 x i32> %7356, %7355
  %7358 = mul <4 x i32> %7357, <i32 5, i32 5, i32 5, i32 5>
  %7359 = add <4 x i32> %7358, %7353
  %7360 = bitcast <4 x i32> %6892 to <16 x i8>
  %7361 = shufflevector <16 x i8> %7351, <16 x i8> %7360, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7362 = bitcast <16 x i8> %7361 to <4 x i32>
  %7363 = shufflevector <16 x i8> %7351, <16 x i8> %7360, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7364 = bitcast <16 x i8> %7363 to <4 x i32>
  %7365 = add <4 x i32> %6890, %7362
  %7366 = add <4 x i32> %7365, %7364
  %7367 = mul <4 x i32> %7366, <i32 5, i32 5, i32 5, i32 5>
  %7368 = add <4 x i32> %7367, %7362
  %7369 = bitcast <4 x i32> %7268 to <16 x i8>
  %7370 = shufflevector <16 x i8> %7360, <16 x i8> %7369, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7371 = bitcast <16 x i8> %7370 to <4 x i32>
  %7372 = shufflevector <16 x i8> %7360, <16 x i8> %7369, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7373 = bitcast <16 x i8> %7372 to <4 x i32>
  %7374 = add <4 x i32> %6892, %7371
  %7375 = add <4 x i32> %7374, %7373
  %7376 = mul <4 x i32> %7375, <i32 5, i32 5, i32 5, i32 5>
  %7377 = add <4 x i32> %7376, %7371
  %7378 = bitcast i32* %6539 to <4 x i32>*
  store <4 x i32> %7350, <4 x i32>* %7378, align 16
  %7379 = getelementptr inbounds i32, i32* %6539, i64 4
  %7380 = bitcast i32* %7379 to <4 x i32>*
  store <4 x i32> %7359, <4 x i32>* %7380, align 16
  %7381 = getelementptr inbounds i32, i32* %6539, i64 8
  %7382 = bitcast i32* %7381 to <4 x i32>*
  store <4 x i32> %7368, <4 x i32>* %7382, align 16
  %7383 = getelementptr inbounds i32, i32* %6539, i64 12
  %7384 = bitcast i32* %7383 to <4 x i32>*
  store <4 x i32> %7377, <4 x i32>* %7384, align 16
  %7385 = bitcast <2 x i64> %7161 to <16 x i8>
  %7386 = shufflevector <16 x i8> %7385, <16 x i8> %7162, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %7387 = shufflevector <16 x i8> %7385, <16 x i8> %7162, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %7388 = shufflevector <16 x i8> %7385, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7389 = shufflevector <16 x i8> %7386, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7390 = bitcast <16 x i8> %7388 to <8 x i16>
  %7391 = bitcast <16 x i8> %7389 to <8 x i16>
  %7392 = add <8 x i16> %7391, %7390
  %7393 = shufflevector <16 x i8> %7387, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7394 = bitcast <16 x i8> %7393 to <8 x i16>
  %7395 = add <8 x i16> %7392, %7394
  %7396 = shl <8 x i16> %7395, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7397 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 5, i64 %6521
  %7398 = bitcast i16* %7397 to <8 x i16>*
  store <8 x i16> %7396, <8 x i16>* %7398, align 16
  %7399 = mul <8 x i16> %7395, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %7400 = add <8 x i16> %7399, %7391
  %7401 = getelementptr inbounds i16, i16* %5933, i64 %6521
  %7402 = bitcast i16* %7401 to <8 x i16>*
  store <8 x i16> %7400, <8 x i16>* %7402, align 16
  %7403 = bitcast <4 x i32> %6542 to <16 x i8>
  %7404 = bitcast <4 x i32> %6533 to <16 x i8>
  %7405 = shufflevector <16 x i8> %7404, <16 x i8> %7403, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7406 = shufflevector <16 x i8> %7404, <16 x i8> %7403, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7407 = bitcast <16 x i8> %7406 to <4 x i32>
  %7408 = bitcast <16 x i8> %7405 to <4 x i32>
  %7409 = add <4 x i32> %6533, %7408
  %7410 = add <4 x i32> %7409, %7407
  %7411 = shl <4 x i32> %7410, <i32 2, i32 2, i32 2, i32 2>
  %7412 = mul <4 x i32> %7410, <i32 3, i32 3, i32 3, i32 3>
  %7413 = add <4 x i32> %7412, %7408
  %7414 = bitcast <4 x i32> %7147 to <16 x i8>
  %7415 = shufflevector <16 x i8> %7403, <16 x i8> %7414, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7416 = shufflevector <16 x i8> %7403, <16 x i8> %7414, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7417 = bitcast <16 x i8> %7416 to <4 x i32>
  %7418 = bitcast <16 x i8> %7415 to <4 x i32>
  %7419 = add <4 x i32> %6542, %7418
  %7420 = add <4 x i32> %7419, %7417
  %7421 = shl <4 x i32> %7420, <i32 2, i32 2, i32 2, i32 2>
  %7422 = mul <4 x i32> %7420, <i32 3, i32 3, i32 3, i32 3>
  %7423 = add <4 x i32> %7422, %7418
  %7424 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 8, i64 %6521
  %7425 = bitcast i32* %7424 to <4 x i32>*
  store <4 x i32> %7411, <4 x i32>* %7425, align 16
  %7426 = getelementptr inbounds i32, i32* %7424, i64 4
  %7427 = bitcast i32* %7426 to <4 x i32>*
  store <4 x i32> %7421, <4 x i32>* %7427, align 16
  %7428 = getelementptr inbounds i32, i32* %5934, i64 %6521
  %7429 = bitcast i32* %7428 to <4 x i32>*
  store <4 x i32> %7413, <4 x i32>* %7429, align 16
  %7430 = getelementptr inbounds i32, i32* %7428, i64 4
  %7431 = bitcast i32* %7430 to <4 x i32>*
  store <4 x i32> %7423, <4 x i32>* %7431, align 16
  %7432 = shufflevector <16 x i8> %7385, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7433 = shufflevector <16 x i8> %7386, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7434 = bitcast <16 x i8> %7432 to <8 x i16>
  %7435 = bitcast <16 x i8> %7433 to <8 x i16>
  %7436 = add <8 x i16> %7435, %7434
  %7437 = shufflevector <16 x i8> %7387, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7438 = bitcast <16 x i8> %7437 to <8 x i16>
  %7439 = add <8 x i16> %7436, %7438
  %7440 = shl <8 x i16> %7439, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7441 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 5, i64 %6565
  %7442 = bitcast i16* %7441 to <8 x i16>*
  store <8 x i16> %7440, <8 x i16>* %7442, align 16
  %7443 = mul <8 x i16> %7439, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %7444 = add <8 x i16> %7443, %7435
  %7445 = getelementptr inbounds i16, i16* %5933, i64 %6565
  %7446 = bitcast i16* %7445 to <8 x i16>*
  store <8 x i16> %7444, <8 x i16>* %7446, align 16
  %7447 = bitcast <4 x i32> %7149 to <16 x i8>
  %7448 = shufflevector <16 x i8> %7414, <16 x i8> %7447, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7449 = shufflevector <16 x i8> %7414, <16 x i8> %7447, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7450 = bitcast <16 x i8> %7449 to <4 x i32>
  %7451 = bitcast <16 x i8> %7448 to <4 x i32>
  %7452 = add <4 x i32> %7147, %7451
  %7453 = add <4 x i32> %7452, %7450
  %7454 = shl <4 x i32> %7453, <i32 2, i32 2, i32 2, i32 2>
  %7455 = mul <4 x i32> %7453, <i32 3, i32 3, i32 3, i32 3>
  %7456 = add <4 x i32> %7455, %7451
  %7457 = bitcast <4 x i32> %7160 to <16 x i8>
  %7458 = shufflevector <16 x i8> %7447, <16 x i8> %7457, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7459 = shufflevector <16 x i8> %7447, <16 x i8> %7457, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7460 = bitcast <16 x i8> %7459 to <4 x i32>
  %7461 = bitcast <16 x i8> %7458 to <4 x i32>
  %7462 = add <4 x i32> %7149, %7461
  %7463 = add <4 x i32> %7462, %7460
  %7464 = shl <4 x i32> %7463, <i32 2, i32 2, i32 2, i32 2>
  %7465 = mul <4 x i32> %7463, <i32 3, i32 3, i32 3, i32 3>
  %7466 = add <4 x i32> %7465, %7461
  %7467 = getelementptr inbounds %"union.libgav1::RestorationBuffer", %"union.libgav1::RestorationBuffer"* %9, i64 0, i32 0, i32 8, i64 %6565
  %7468 = bitcast i32* %7467 to <4 x i32>*
  store <4 x i32> %7454, <4 x i32>* %7468, align 16
  %7469 = getelementptr inbounds i32, i32* %7467, i64 4
  %7470 = bitcast i32* %7469 to <4 x i32>*
  store <4 x i32> %7464, <4 x i32>* %7470, align 16
  %7471 = getelementptr inbounds i32, i32* %5934, i64 %6565
  %7472 = bitcast i32* %7471 to <4 x i32>*
  store <4 x i32> %7456, <4 x i32>* %7472, align 16
  %7473 = getelementptr inbounds i32, i32* %7471, i64 4
  %7474 = bitcast i32* %7473 to <4 x i32>*
  store <4 x i32> %7466, <4 x i32>* %7474, align 16
  %7475 = shufflevector <16 x i8> %6880, <16 x i8> %7258, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %7476 = shufflevector <16 x i8> %6880, <16 x i8> %7258, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %7477 = shufflevector <16 x i8> %6880, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7478 = shufflevector <16 x i8> %7475, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7479 = bitcast <16 x i8> %7477 to <8 x i16>
  %7480 = bitcast <16 x i8> %7478 to <8 x i16>
  %7481 = add <8 x i16> %7480, %7479
  %7482 = shufflevector <16 x i8> %7476, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7483 = bitcast <16 x i8> %7482 to <8 x i16>
  %7484 = add <8 x i16> %7481, %7483
  %7485 = mul <8 x i16> %7484, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %7486 = add <8 x i16> %7485, %7480
  %7487 = shufflevector <16 x i8> %7475, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7488 = bitcast <16 x i8> %6881 to <8 x i16>
  %7489 = bitcast <16 x i8> %7487 to <8 x i16>
  %7490 = add <8 x i16> %7489, %7488
  %7491 = shufflevector <16 x i8> %7476, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7492 = bitcast <16 x i8> %7491 to <8 x i16>
  %7493 = add <8 x i16> %7490, %7492
  %7494 = mul <8 x i16> %7493, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %7495 = add <8 x i16> %7494, %7489
  %7496 = bitcast i16* %6538 to <8 x i16>*
  store <8 x i16> %7486, <8 x i16>* %7496, align 16
  %7497 = getelementptr inbounds i16, i16* %6538, i64 8
  %7498 = bitcast i16* %7497 to <8 x i16>*
  store <8 x i16> %7495, <8 x i16>* %7498, align 16
  %7499 = getelementptr inbounds i16, i16* %6538, i64 16
  %7500 = getelementptr inbounds i32, i32* %6539, i64 16
  %7501 = icmp slt i64 %6552, %5918
  br i1 %7501, label %6520, label %7502

7502:                                             ; preds = %6520
  %7503 = ptrtoint i16* %6145 to i64
  %7504 = ptrtoint i32* %6146 to i64
  %7505 = ashr i32 %8, 1
  %7506 = shl nsw i64 %2, 1
  %7507 = mul nsw i64 %2, 3
  %7508 = and i32 %5924, 65535
  %7509 = shl i32 %6131, 16
  %7510 = or i32 %7509, %7508
  %7511 = insertelement <4 x i32> undef, i32 %7510, i32 0
  %7512 = shufflevector <4 x i32> %7511, <4 x i32> undef, <4 x i32> zeroinitializer
  %7513 = bitcast <4 x i32> %7512 to <8 x i16>
  %7514 = ptrtoint i16* %5945 to i64
  %7515 = ptrtoint i32* %6132 to i64
  %7516 = add nsw i32 %7505, -1
  %7517 = icmp sgt i32 %7516, 0
  br i1 %7517, label %7563, label %7523

7518:                                             ; preds = %9303
  %7519 = inttoptr i64 %7596 to i16*
  %7520 = inttoptr i64 %7586 to i32*
  %7521 = inttoptr i64 %7594 to i16*
  %7522 = inttoptr i64 %7584 to i32*
  br label %7523

7523:                                             ; preds = %7518, %7502
  %7524 = phi i64 [ %6127, %7502 ], [ %7598, %7518 ]
  %7525 = phi i64 [ %6123, %7502 ], [ %7597, %7518 ]
  %7526 = phi i64 [ %6119, %7502 ], [ %7600, %7518 ]
  %7527 = phi i64 [ %6115, %7502 ], [ %7599, %7518 ]
  %7528 = phi i16* [ %5941, %7502 ], [ %7521, %7518 ]
  %7529 = phi i64 [ %6125, %7502 ], [ %7593, %7518 ]
  %7530 = phi i16* [ %5933, %7502 ], [ %7519, %7518 ]
  %7531 = phi i64 [ %6117, %7502 ], [ %7595, %7518 ]
  %7532 = phi i64 [ %6143, %7502 ], [ %7591, %7518 ]
  %7533 = phi i64 [ %6141, %7502 ], [ %7592, %7518 ]
  %7534 = phi i64 [ %6128, %7502 ], [ %7588, %7518 ]
  %7535 = phi i64 [ %6124, %7502 ], [ %7587, %7518 ]
  %7536 = phi i64 [ %6120, %7502 ], [ %7590, %7518 ]
  %7537 = phi i64 [ %6116, %7502 ], [ %7589, %7518 ]
  %7538 = phi i32* [ %5942, %7502 ], [ %7522, %7518 ]
  %7539 = phi i64 [ %6126, %7502 ], [ %7583, %7518 ]
  %7540 = phi i32* [ %5934, %7502 ], [ %7520, %7518 ]
  %7541 = phi i64 [ %6118, %7502 ], [ %7585, %7518 ]
  %7542 = phi i64 [ %6144, %7502 ], [ %7581, %7518 ]
  %7543 = phi i64 [ %6142, %7502 ], [ %7582, %7518 ]
  %7544 = phi i64 [ %6139, %7502 ], [ %7577, %7518 ]
  %7545 = phi i64 [ %6137, %7502 ], [ %7571, %7518 ]
  %7546 = phi i64 [ %6135, %7502 ], [ %7580, %7518 ]
  %7547 = phi i64 [ %6133, %7502 ], [ %7579, %7518 ]
  %7548 = phi i64 [ %6140, %7502 ], [ %7573, %7518 ]
  %7549 = phi i64 [ %6138, %7502 ], [ %7572, %7518 ]
  %7550 = phi i64 [ %6136, %7502 ], [ %7576, %7518 ]
  %7551 = phi i64 [ %6134, %7502 ], [ %7575, %7518 ]
  %7552 = phi i64 [ %7515, %7502 ], [ %7574, %7518 ]
  %7553 = phi i64 [ %7514, %7502 ], [ %7578, %7518 ]
  %7554 = phi i64 [ %7503, %7502 ], [ %7569, %7518 ]
  %7555 = phi i64 [ %6147, %7502 ], [ %7570, %7518 ]
  %7556 = phi i64 [ %7504, %7502 ], [ %7567, %7518 ]
  %7557 = phi i64 [ %6148, %7502 ], [ %7568, %7518 ]
  %7558 = phi i16* [ %17, %7502 ], [ %9304, %7518 ]
  %7559 = phi i16* [ %6112, %7502 ], [ %7603, %7518 ]
  %7560 = and i32 %8, 1
  %7561 = icmp eq i32 %7560, 0
  %7562 = or i1 %6149, %7561
  br i1 %7562, label %9307, label %11008

7563:                                             ; preds = %7502, %9303
  %7564 = phi i32 [ %9305, %9303 ], [ %7516, %7502 ]
  %7565 = phi i16* [ %7603, %9303 ], [ %6112, %7502 ]
  %7566 = phi i16* [ %9304, %9303 ], [ %17, %7502 ]
  %7567 = phi i64 [ %7568, %9303 ], [ %6148, %7502 ]
  %7568 = phi i64 [ %7567, %9303 ], [ %7504, %7502 ]
  %7569 = phi i64 [ %7570, %9303 ], [ %6147, %7502 ]
  %7570 = phi i64 [ %7569, %9303 ], [ %7503, %7502 ]
  %7571 = phi i64 [ %7578, %9303 ], [ %7514, %7502 ]
  %7572 = phi i64 [ %7574, %9303 ], [ %7515, %7502 ]
  %7573 = phi i64 [ %7575, %9303 ], [ %6134, %7502 ]
  %7574 = phi i64 [ %7576, %9303 ], [ %6136, %7502 ]
  %7575 = phi i64 [ %7572, %9303 ], [ %6138, %7502 ]
  %7576 = phi i64 [ %7573, %9303 ], [ %6140, %7502 ]
  %7577 = phi i64 [ %7579, %9303 ], [ %6133, %7502 ]
  %7578 = phi i64 [ %7580, %9303 ], [ %6135, %7502 ]
  %7579 = phi i64 [ %7571, %9303 ], [ %6137, %7502 ]
  %7580 = phi i64 [ %7577, %9303 ], [ %6139, %7502 ]
  %7581 = phi i64 [ %7582, %9303 ], [ %6142, %7502 ]
  %7582 = phi i64 [ %7581, %9303 ], [ %6144, %7502 ]
  %7583 = phi i64 [ %7585, %9303 ], [ %6118, %7502 ]
  %7584 = phi i64 [ %7586, %9303 ], [ %6122, %7502 ]
  %7585 = phi i64 [ %7583, %9303 ], [ %6126, %7502 ]
  %7586 = phi i64 [ %7584, %9303 ], [ %6130, %7502 ]
  %7587 = phi i64 [ %7589, %9303 ], [ %6116, %7502 ]
  %7588 = phi i64 [ %7590, %9303 ], [ %6120, %7502 ]
  %7589 = phi i64 [ %7587, %9303 ], [ %6124, %7502 ]
  %7590 = phi i64 [ %7588, %9303 ], [ %6128, %7502 ]
  %7591 = phi i64 [ %7592, %9303 ], [ %6141, %7502 ]
  %7592 = phi i64 [ %7591, %9303 ], [ %6143, %7502 ]
  %7593 = phi i64 [ %7595, %9303 ], [ %6117, %7502 ]
  %7594 = phi i64 [ %7596, %9303 ], [ %6121, %7502 ]
  %7595 = phi i64 [ %7593, %9303 ], [ %6125, %7502 ]
  %7596 = phi i64 [ %7594, %9303 ], [ %6129, %7502 ]
  %7597 = phi i64 [ %7599, %9303 ], [ %6115, %7502 ]
  %7598 = phi i64 [ %7600, %9303 ], [ %6119, %7502 ]
  %7599 = phi i64 [ %7597, %9303 ], [ %6123, %7502 ]
  %7600 = phi i64 [ %7598, %9303 ], [ %6127, %7502 ]
  %7601 = inttoptr i64 %7597 to <8 x i16>*
  %7602 = getelementptr inbounds i16, i16* %7565, i64 3
  %7603 = getelementptr inbounds i16, i16* %7565, i64 %7506
  %7604 = getelementptr inbounds i16, i16* %7565, i64 %7507
  %7605 = bitcast i16* %7603 to <8 x i16>*
  %7606 = load <8 x i16>, <8 x i16>* %7605, align 1
  %7607 = getelementptr inbounds i16, i16* %7603, i64 8
  %7608 = bitcast i16* %7607 to <2 x i64>*
  %7609 = load <2 x i64>, <2 x i64>* %7608, align 1
  %7610 = bitcast i16* %7604 to <8 x i16>*
  %7611 = load <8 x i16>, <8 x i16>* %7610, align 1
  %7612 = getelementptr inbounds i16, i16* %7604, i64 8
  %7613 = bitcast i16* %7612 to <2 x i64>*
  %7614 = load <2 x i64>, <2 x i64>* %7613, align 1
  %7615 = shufflevector <8 x i16> %7606, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7616 = shufflevector <8 x i16> %7606, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7617 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7615, <8 x i16> %7615) #5
  %7618 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7616, <8 x i16> %7616) #5
  %7619 = shufflevector <8 x i16> %7611, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7620 = shufflevector <8 x i16> %7611, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7621 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7619, <8 x i16> %7619) #5
  %7622 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7620, <8 x i16> %7620) #5
  %7623 = bitcast <2 x i64> %7609 to <8 x i16>
  %7624 = shufflevector <8 x i16> %7623, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7625 = shufflevector <8 x i16> %7623, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7626 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7624, <8 x i16> %7624) #5
  %7627 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7625, <8 x i16> %7625) #5
  %7628 = bitcast <2 x i64> %7614 to <8 x i16>
  %7629 = shufflevector <8 x i16> %7628, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7630 = shufflevector <8 x i16> %7628, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7631 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7629, <8 x i16> %7629) #5
  %7632 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7630, <8 x i16> %7630) #5
  %7633 = bitcast <2 x i64> %7609 to <16 x i8>
  %7634 = bitcast <8 x i16> %7606 to <16 x i8>
  %7635 = shufflevector <16 x i8> %7634, <16 x i8> %7633, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %7636 = bitcast <16 x i8> %7635 to <8 x i16>
  %7637 = shufflevector <16 x i8> %7634, <16 x i8> %7633, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7638 = bitcast <16 x i8> %7637 to <8 x i16>
  %7639 = shufflevector <16 x i8> %7634, <16 x i8> %7633, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %7640 = bitcast <16 x i8> %7639 to <8 x i16>
  %7641 = shufflevector <16 x i8> %7634, <16 x i8> %7633, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7642 = bitcast <16 x i8> %7641 to <8 x i16>
  %7643 = add <8 x i16> %7606, %7642
  %7644 = add <8 x i16> %7638, %7636
  %7645 = add <8 x i16> %7644, %7640
  %7646 = add <8 x i16> %7643, %7645
  %7647 = bitcast <2 x i64> %7614 to <16 x i8>
  %7648 = bitcast <8 x i16> %7611 to <16 x i8>
  %7649 = shufflevector <16 x i8> %7648, <16 x i8> %7647, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %7650 = bitcast <16 x i8> %7649 to <8 x i16>
  %7651 = shufflevector <16 x i8> %7648, <16 x i8> %7647, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7652 = bitcast <16 x i8> %7651 to <8 x i16>
  %7653 = shufflevector <16 x i8> %7648, <16 x i8> %7647, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %7654 = bitcast <16 x i8> %7653 to <8 x i16>
  %7655 = shufflevector <16 x i8> %7648, <16 x i8> %7647, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7656 = bitcast <16 x i8> %7655 to <8 x i16>
  %7657 = add <8 x i16> %7611, %7656
  %7658 = add <8 x i16> %7652, %7650
  %7659 = add <8 x i16> %7658, %7654
  %7660 = add <8 x i16> %7657, %7659
  store <8 x i16> %7645, <8 x i16>* %7601, align 16
  %7661 = inttoptr i64 %7598 to <8 x i16>*
  store <8 x i16> %7659, <8 x i16>* %7661, align 16
  %7662 = inttoptr i64 %7571 to <8 x i16>*
  store <8 x i16> %7646, <8 x i16>* %7662, align 16
  %7663 = inttoptr i64 %7577 to <8 x i16>*
  store <8 x i16> %7660, <8 x i16>* %7663, align 16
  %7664 = bitcast <4 x i32> %7618 to <16 x i8>
  %7665 = bitcast <4 x i32> %7617 to <16 x i8>
  %7666 = shufflevector <16 x i8> %7665, <16 x i8> %7664, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7667 = bitcast <16 x i8> %7666 to <4 x i32>
  %7668 = shufflevector <16 x i8> %7665, <16 x i8> %7664, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7669 = bitcast <16 x i8> %7668 to <4 x i32>
  %7670 = shufflevector <16 x i8> %7665, <16 x i8> %7664, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %7671 = bitcast <16 x i8> %7670 to <4 x i32>
  %7672 = add <4 x i32> %7618, %7617
  %7673 = add <4 x i32> %7669, %7667
  %7674 = add <4 x i32> %7673, %7671
  %7675 = add <4 x i32> %7672, %7674
  %7676 = bitcast <4 x i32> %7626 to <16 x i8>
  %7677 = shufflevector <16 x i8> %7664, <16 x i8> %7676, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7678 = bitcast <16 x i8> %7677 to <4 x i32>
  %7679 = shufflevector <16 x i8> %7664, <16 x i8> %7676, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7680 = bitcast <16 x i8> %7679 to <4 x i32>
  %7681 = shufflevector <16 x i8> %7664, <16 x i8> %7676, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %7682 = bitcast <16 x i8> %7681 to <4 x i32>
  %7683 = add <4 x i32> %7626, %7618
  %7684 = add <4 x i32> %7680, %7678
  %7685 = add <4 x i32> %7684, %7682
  %7686 = add <4 x i32> %7683, %7685
  %7687 = inttoptr i64 %7587 to i32*
  %7688 = inttoptr i64 %7587 to <4 x i32>*
  store <4 x i32> %7674, <4 x i32>* %7688, align 16
  %7689 = getelementptr inbounds i32, i32* %7687, i64 4
  %7690 = bitcast i32* %7689 to <4 x i32>*
  store <4 x i32> %7685, <4 x i32>* %7690, align 16
  %7691 = inttoptr i64 %7572 to i32*
  %7692 = inttoptr i64 %7572 to <4 x i32>*
  store <4 x i32> %7675, <4 x i32>* %7692, align 16
  %7693 = getelementptr inbounds i32, i32* %7691, i64 4
  %7694 = bitcast i32* %7693 to <4 x i32>*
  store <4 x i32> %7686, <4 x i32>* %7694, align 16
  %7695 = bitcast <4 x i32> %7622 to <16 x i8>
  %7696 = bitcast <4 x i32> %7621 to <16 x i8>
  %7697 = shufflevector <16 x i8> %7696, <16 x i8> %7695, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7698 = bitcast <16 x i8> %7697 to <4 x i32>
  %7699 = shufflevector <16 x i8> %7696, <16 x i8> %7695, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7700 = bitcast <16 x i8> %7699 to <4 x i32>
  %7701 = shufflevector <16 x i8> %7696, <16 x i8> %7695, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %7702 = bitcast <16 x i8> %7701 to <4 x i32>
  %7703 = add <4 x i32> %7622, %7621
  %7704 = add <4 x i32> %7700, %7698
  %7705 = add <4 x i32> %7704, %7702
  %7706 = add <4 x i32> %7703, %7705
  %7707 = bitcast <4 x i32> %7631 to <16 x i8>
  %7708 = shufflevector <16 x i8> %7695, <16 x i8> %7707, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %7709 = bitcast <16 x i8> %7708 to <4 x i32>
  %7710 = shufflevector <16 x i8> %7695, <16 x i8> %7707, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7711 = bitcast <16 x i8> %7710 to <4 x i32>
  %7712 = shufflevector <16 x i8> %7695, <16 x i8> %7707, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %7713 = bitcast <16 x i8> %7712 to <4 x i32>
  %7714 = add <4 x i32> %7631, %7622
  %7715 = add <4 x i32> %7711, %7709
  %7716 = add <4 x i32> %7715, %7713
  %7717 = add <4 x i32> %7714, %7716
  %7718 = inttoptr i64 %7588 to i32*
  %7719 = inttoptr i64 %7588 to <4 x i32>*
  store <4 x i32> %7705, <4 x i32>* %7719, align 16
  %7720 = getelementptr inbounds i32, i32* %7718, i64 4
  %7721 = bitcast i32* %7720 to <4 x i32>*
  store <4 x i32> %7716, <4 x i32>* %7721, align 16
  %7722 = inttoptr i64 %7573 to i32*
  %7723 = inttoptr i64 %7573 to <4 x i32>*
  store <4 x i32> %7706, <4 x i32>* %7723, align 16
  %7724 = getelementptr inbounds i32, i32* %7722, i64 4
  %7725 = bitcast i32* %7724 to <4 x i32>*
  store <4 x i32> %7717, <4 x i32>* %7725, align 16
  %7726 = inttoptr i64 %7599 to <8 x i16>*
  %7727 = load <8 x i16>, <8 x i16>* %7726, align 16
  %7728 = inttoptr i64 %7600 to <8 x i16>*
  %7729 = load <8 x i16>, <8 x i16>* %7728, align 16
  %7730 = inttoptr i64 %7589 to i32*
  %7731 = inttoptr i64 %7589 to <4 x i32>*
  %7732 = load <4 x i32>, <4 x i32>* %7731, align 16
  %7733 = getelementptr inbounds i32, i32* %7730, i64 4
  %7734 = bitcast i32* %7733 to <4 x i32>*
  %7735 = load <4 x i32>, <4 x i32>* %7734, align 16
  %7736 = inttoptr i64 %7590 to i32*
  %7737 = inttoptr i64 %7590 to <4 x i32>*
  %7738 = load <4 x i32>, <4 x i32>* %7737, align 16
  %7739 = getelementptr inbounds i32, i32* %7736, i64 4
  %7740 = bitcast i32* %7739 to <4 x i32>*
  %7741 = load <4 x i32>, <4 x i32>* %7740, align 16
  %7742 = inttoptr i64 %7578 to <8 x i16>*
  %7743 = load <8 x i16>, <8 x i16>* %7742, align 16
  %7744 = inttoptr i64 %7579 to <8 x i16>*
  %7745 = load <8 x i16>, <8 x i16>* %7744, align 16
  %7746 = inttoptr i64 %7580 to <8 x i16>*
  %7747 = load <8 x i16>, <8 x i16>* %7746, align 16
  %7748 = inttoptr i64 %7574 to i32*
  %7749 = inttoptr i64 %7574 to <4 x i32>*
  %7750 = load <4 x i32>, <4 x i32>* %7749, align 16
  %7751 = getelementptr inbounds i32, i32* %7748, i64 4
  %7752 = bitcast i32* %7751 to <4 x i32>*
  %7753 = load <4 x i32>, <4 x i32>* %7752, align 16
  %7754 = inttoptr i64 %7575 to i32*
  %7755 = inttoptr i64 %7575 to <4 x i32>*
  %7756 = load <4 x i32>, <4 x i32>* %7755, align 16
  %7757 = getelementptr inbounds i32, i32* %7754, i64 4
  %7758 = bitcast i32* %7757 to <4 x i32>*
  %7759 = load <4 x i32>, <4 x i32>* %7758, align 16
  %7760 = inttoptr i64 %7576 to i32*
  %7761 = inttoptr i64 %7576 to <4 x i32>*
  %7762 = load <4 x i32>, <4 x i32>* %7761, align 16
  %7763 = getelementptr inbounds i32, i32* %7760, i64 4
  %7764 = bitcast i32* %7763 to <4 x i32>*
  %7765 = load <4 x i32>, <4 x i32>* %7764, align 16
  %7766 = add <8 x i16> %7729, %7645
  %7767 = add <8 x i16> %7766, %7727
  %7768 = add <8 x i16> %7767, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7769 = lshr <8 x i16> %7768, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7770 = shufflevector <8 x i16> %7769, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7771 = shufflevector <8 x i16> %7769, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7772 = add <4 x i32> %7674, <i32 8, i32 8, i32 8, i32 8>
  %7773 = add <4 x i32> %7772, %7738
  %7774 = add <4 x i32> %7773, %7732
  %7775 = lshr <4 x i32> %7774, <i32 4, i32 4, i32 4, i32 4>
  %7776 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7770, <8 x i16> %7770) #5
  %7777 = mul nuw <4 x i32> %7775, <i32 9, i32 9, i32 9, i32 9>
  %7778 = sub <4 x i32> %7777, %7776
  %7779 = icmp sgt <4 x i32> %7778, zeroinitializer
  %7780 = select <4 x i1> %7779, <4 x i32> %7778, <4 x i32> zeroinitializer
  %7781 = mul <4 x i32> %7780, %6317
  %7782 = add <4 x i32> %7781, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7783 = lshr <4 x i32> %7782, <i32 20, i32 20, i32 20, i32 20>
  %7784 = add <4 x i32> %7685, <i32 8, i32 8, i32 8, i32 8>
  %7785 = add <4 x i32> %7784, %7741
  %7786 = add <4 x i32> %7785, %7735
  %7787 = lshr <4 x i32> %7786, <i32 4, i32 4, i32 4, i32 4>
  %7788 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7771, <8 x i16> %7771) #5
  %7789 = mul nuw <4 x i32> %7787, <i32 9, i32 9, i32 9, i32 9>
  %7790 = sub <4 x i32> %7789, %7788
  %7791 = icmp sgt <4 x i32> %7790, zeroinitializer
  %7792 = select <4 x i1> %7791, <4 x i32> %7790, <4 x i32> zeroinitializer
  %7793 = mul <4 x i32> %7792, %6317
  %7794 = add <4 x i32> %7793, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7795 = lshr <4 x i32> %7794, <i32 20, i32 20, i32 20, i32 20>
  %7796 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %7783, <4 x i32> %7795) #5
  %7797 = add <8 x i16> %7766, %7659
  %7798 = add <8 x i16> %7797, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7799 = lshr <8 x i16> %7798, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7800 = shufflevector <8 x i16> %7799, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7801 = shufflevector <8 x i16> %7799, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7802 = add <4 x i32> %7773, %7705
  %7803 = lshr <4 x i32> %7802, <i32 4, i32 4, i32 4, i32 4>
  %7804 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7800, <8 x i16> %7800) #5
  %7805 = mul nuw <4 x i32> %7803, <i32 9, i32 9, i32 9, i32 9>
  %7806 = sub <4 x i32> %7805, %7804
  %7807 = icmp sgt <4 x i32> %7806, zeroinitializer
  %7808 = select <4 x i1> %7807, <4 x i32> %7806, <4 x i32> zeroinitializer
  %7809 = mul <4 x i32> %7808, %6317
  %7810 = add <4 x i32> %7809, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7811 = lshr <4 x i32> %7810, <i32 20, i32 20, i32 20, i32 20>
  %7812 = add <4 x i32> %7785, %7716
  %7813 = lshr <4 x i32> %7812, <i32 4, i32 4, i32 4, i32 4>
  %7814 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7801, <8 x i16> %7801) #5
  %7815 = mul nuw <4 x i32> %7813, <i32 9, i32 9, i32 9, i32 9>
  %7816 = sub <4 x i32> %7815, %7814
  %7817 = icmp sgt <4 x i32> %7816, zeroinitializer
  %7818 = select <4 x i1> %7817, <4 x i32> %7816, <4 x i32> zeroinitializer
  %7819 = mul <4 x i32> %7818, %6317
  %7820 = add <4 x i32> %7819, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7821 = lshr <4 x i32> %7820, <i32 20, i32 20, i32 20, i32 20>
  %7822 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %7811, <4 x i32> %7821) #5
  %7823 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7796, <8 x i16> %7822) #5
  %7824 = icmp ult <16 x i8> %7823, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7825 = select <16 x i1> %7824, <16 x i8> %7823, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7826 = icmp sgt <16 x i8> %7825, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7827 = select <16 x i1> %7826, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7825
  %7828 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %7827) #5
  %7829 = add nsw <16 x i8> %7825, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %7830 = icmp sgt <16 x i8> %7829, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7831 = select <16 x i1> %7830, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7829
  %7832 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %7831) #5
  %7833 = or <16 x i8> %7832, %7828
  %7834 = add nsw <16 x i8> %7825, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %7835 = icmp sgt <16 x i8> %7834, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %7836 = select <16 x i1> %7835, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %7834
  %7837 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %7836) #5
  %7838 = or <16 x i8> %7833, %7837
  %7839 = xor <16 x i8> %7823, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %7840 = icmp ugt <16 x i8> %7838, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %7841 = select <16 x i1> %7840, <16 x i8> %7838, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %7842 = icmp sgt <16 x i8> %7839, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %7843 = icmp sgt <16 x i8> %7839, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %7844 = sext <16 x i1> %7843 to <16 x i8>
  %7845 = icmp sgt <16 x i8> %7839, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %7846 = icmp sgt <16 x i8> %7839, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %7847 = icmp eq <16 x i8> %7839, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %7848 = zext <16 x i1> %7842 to <16 x i8>
  %7849 = sub nsw <16 x i8> %7844, %7848
  %7850 = zext <16 x i1> %7845 to <16 x i8>
  %7851 = sub nsw <16 x i8> %7849, %7850
  %7852 = zext <16 x i1> %7846 to <16 x i8>
  %7853 = sub nsw <16 x i8> %7851, %7852
  %7854 = zext <16 x i1> %7847 to <16 x i8>
  %7855 = sub nsw <16 x i8> %7853, %7854
  %7856 = add <16 x i8> %7855, %7841
  %7857 = shufflevector <16 x i8> %7856, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7858 = bitcast <16 x i8> %7857 to <8 x i16>
  %7859 = shufflevector <8 x i16> %7858, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7860 = shufflevector <8 x i16> %7767, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7861 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7859, <8 x i16> %7860) #5
  %7862 = shufflevector <8 x i16> %7858, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7863 = shufflevector <8 x i16> %7767, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7864 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7862, <8 x i16> %7863) #5
  %7865 = mul <4 x i32> %7861, <i32 455, i32 455, i32 455, i32 455>
  %7866 = add <4 x i32> %7865, <i32 2048, i32 2048, i32 2048, i32 2048>
  %7867 = lshr <4 x i32> %7866, <i32 12, i32 12, i32 12, i32 12>
  %7868 = shufflevector <16 x i8> %7856, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %7869 = bitcast <16 x i8> %7868 to <8 x i16>
  %7870 = shufflevector <8 x i16> %7869, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7871 = shufflevector <8 x i16> %7797, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7872 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7870, <8 x i16> %7871) #5
  %7873 = shufflevector <8 x i16> %7869, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7874 = shufflevector <8 x i16> %7797, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7875 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7873, <8 x i16> %7874) #5
  %7876 = mul <4 x i32> %7872, <i32 455, i32 455, i32 455, i32 455>
  %7877 = add <4 x i32> %7876, <i32 2048, i32 2048, i32 2048, i32 2048>
  %7878 = lshr <4 x i32> %7877, <i32 12, i32 12, i32 12, i32 12>
  %7879 = shufflevector <16 x i8> %7856, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %7880 = add <8 x i16> %7660, %7646
  %7881 = add <8 x i16> %7880, %7743
  %7882 = add <8 x i16> %7881, %7745
  %7883 = add <8 x i16> %7882, %7747
  %7884 = add <8 x i16> %7883, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7885 = lshr <8 x i16> %7884, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %7886 = shufflevector <8 x i16> %7885, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7887 = shufflevector <8 x i16> %7885, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7888 = add <4 x i32> %7675, <i32 8, i32 8, i32 8, i32 8>
  %7889 = add <4 x i32> %7888, %7706
  %7890 = add <4 x i32> %7889, %7750
  %7891 = add <4 x i32> %7890, %7756
  %7892 = add <4 x i32> %7891, %7762
  %7893 = lshr <4 x i32> %7892, <i32 4, i32 4, i32 4, i32 4>
  %7894 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7886, <8 x i16> %7886) #5
  %7895 = mul <4 x i32> %7893, <i32 25, i32 25, i32 25, i32 25>
  %7896 = sub <4 x i32> %7895, %7894
  %7897 = icmp sgt <4 x i32> %7896, zeroinitializer
  %7898 = select <4 x i1> %7897, <4 x i32> %7896, <4 x i32> zeroinitializer
  %7899 = mul <4 x i32> %7898, %6442
  %7900 = add <4 x i32> %7899, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7901 = lshr <4 x i32> %7900, <i32 20, i32 20, i32 20, i32 20>
  %7902 = add <4 x i32> %7686, <i32 8, i32 8, i32 8, i32 8>
  %7903 = add <4 x i32> %7902, %7717
  %7904 = add <4 x i32> %7903, %7753
  %7905 = add <4 x i32> %7904, %7759
  %7906 = add <4 x i32> %7905, %7765
  %7907 = lshr <4 x i32> %7906, <i32 4, i32 4, i32 4, i32 4>
  %7908 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7887, <8 x i16> %7887) #5
  %7909 = mul <4 x i32> %7907, <i32 25, i32 25, i32 25, i32 25>
  %7910 = sub <4 x i32> %7909, %7908
  %7911 = icmp sgt <4 x i32> %7910, zeroinitializer
  %7912 = select <4 x i1> %7911, <4 x i32> %7910, <4 x i32> zeroinitializer
  %7913 = mul <4 x i32> %7912, %6442
  %7914 = add <4 x i32> %7913, <i32 524288, i32 524288, i32 524288, i32 524288>
  %7915 = lshr <4 x i32> %7914, <i32 20, i32 20, i32 20, i32 20>
  %7916 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %7901, <4 x i32> %7915) #5
  %7917 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7916, <8 x i16> undef) #5
  %7918 = bitcast <16 x i8> %7917 to <2 x i64>
  %7919 = extractelement <2 x i64> %7918, i32 0
  %7920 = lshr i64 %7919, 8
  %7921 = lshr i64 %7919, 16
  %7922 = lshr i64 %7919, 24
  %7923 = lshr i64 %7919, 32
  %7924 = lshr i64 %7919, 40
  %7925 = lshr i64 %7919, 48
  %7926 = lshr i64 %7919, 56
  %7927 = and i64 %7919, 255
  %7928 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7927
  %7929 = load i8, i8* %7928, align 1
  %7930 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %7929, i64 0
  %7931 = and i64 %7920, 255
  %7932 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7931
  %7933 = load i8, i8* %7932, align 1
  %7934 = insertelement <16 x i8> %7930, i8 %7933, i64 1
  %7935 = and i64 %7921, 255
  %7936 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7935
  %7937 = load i8, i8* %7936, align 1
  %7938 = insertelement <16 x i8> %7934, i8 %7937, i64 2
  %7939 = and i64 %7922, 255
  %7940 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7939
  %7941 = load i8, i8* %7940, align 1
  %7942 = insertelement <16 x i8> %7938, i8 %7941, i64 3
  %7943 = and i64 %7923, 255
  %7944 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7943
  %7945 = load i8, i8* %7944, align 1
  %7946 = insertelement <16 x i8> %7942, i8 %7945, i64 4
  %7947 = and i64 %7924, 255
  %7948 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7947
  %7949 = load i8, i8* %7948, align 1
  %7950 = insertelement <16 x i8> %7946, i8 %7949, i64 5
  %7951 = and i64 %7925, 255
  %7952 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7951
  %7953 = load i8, i8* %7952, align 1
  %7954 = insertelement <16 x i8> %7950, i8 %7953, i64 6
  %7955 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %7926
  %7956 = load i8, i8* %7955, align 1
  %7957 = insertelement <16 x i8> %7954, i8 %7956, i64 7
  %7958 = shufflevector <16 x i8> %7957, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7959 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7958, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %7960 = shufflevector <8 x i16> %7959, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7961 = shufflevector <8 x i16> %7883, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7962 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7960, <8 x i16> %7961) #5
  %7963 = shufflevector <8 x i16> %7959, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7964 = shufflevector <8 x i16> %7883, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7965 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7963, <8 x i16> %7964) #5
  %7966 = add <4 x i32> %7962, <i32 512, i32 512, i32 512, i32 512>
  %7967 = lshr <4 x i32> %7966, <i32 10, i32 10, i32 10, i32 10>
  %7968 = getelementptr inbounds i16, i16* %7602, i64 %2
  %7969 = getelementptr inbounds i16, i16* %7566, i64 %2
  %7970 = inttoptr i64 %7570 to i16*
  %7971 = inttoptr i64 %7568 to i32*
  %7972 = inttoptr i64 %7569 to i16*
  %7973 = inttoptr i64 %7567 to i32*
  %7974 = getelementptr inbounds i16, i16* %7970, i64 8
  %7975 = getelementptr inbounds i32, i32* %7971, i64 8
  %7976 = getelementptr inbounds i16, i16* %7972, i64 8
  %7977 = getelementptr inbounds i32, i32* %7973, i64 8
  %7978 = inttoptr i64 %7597 to i16*
  %7979 = getelementptr inbounds i16, i16* %7978, i64 8
  %7980 = inttoptr i64 %7571 to i16*
  %7981 = getelementptr inbounds i16, i16* %7980, i64 8
  %7982 = inttoptr i64 %7598 to i16*
  %7983 = getelementptr inbounds i16, i16* %7982, i64 8
  %7984 = inttoptr i64 %7577 to i16*
  %7985 = getelementptr inbounds i16, i16* %7984, i64 8
  %7986 = inttoptr i64 %7599 to i16*
  %7987 = inttoptr i64 %7600 to i16*
  %7988 = inttoptr i64 %7578 to i16*
  %7989 = inttoptr i64 %7579 to i16*
  %7990 = inttoptr i64 %7580 to i16*
  %7991 = getelementptr inbounds i32, i32* %7687, i64 8
  %7992 = getelementptr inbounds i32, i32* %7691, i64 8
  %7993 = getelementptr inbounds i32, i32* %7718, i64 8
  %7994 = getelementptr inbounds i32, i32* %7722, i64 8
  %7995 = inttoptr i64 %7595 to i16*
  %7996 = inttoptr i64 %7585 to i32*
  %7997 = inttoptr i64 %7596 to i16*
  %7998 = inttoptr i64 %7592 to i16*
  %7999 = inttoptr i64 %7586 to i32*
  %8000 = inttoptr i64 %7582 to i32*
  %8001 = inttoptr i64 %7593 to i16*
  %8002 = inttoptr i64 %7591 to i16*
  %8003 = inttoptr i64 %7583 to i32*
  %8004 = inttoptr i64 %7581 to i32*
  %8005 = inttoptr i64 %7594 to i16*
  %8006 = inttoptr i64 %7584 to i32*
  %8007 = getelementptr inbounds i16, i16* %8001, i64 8
  %8008 = getelementptr inbounds i16, i16* %8002, i64 8
  %8009 = getelementptr inbounds i32, i32* %8003, i64 8
  %8010 = getelementptr inbounds i32, i32* %8004, i64 8
  %8011 = getelementptr inbounds i16, i16* %8005, i64 8
  %8012 = getelementptr inbounds i32, i32* %8006, i64 8
  br label %8013

8013:                                             ; preds = %8013, %7563
  %8014 = phi i64 [ %8043, %8013 ], [ 0, %7563 ]
  %8015 = phi <2 x i64> [ %8055, %8013 ], [ %7614, %7563 ]
  %8016 = phi <2 x i64> [ %8048, %8013 ], [ %7609, %7563 ]
  %8017 = phi <16 x i8> [ %8662, %8013 ], [ %7879, %7563 ]
  %8018 = phi <16 x i8> [ %8600, %8013 ], [ %7856, %7563 ]
  %8019 = phi <16 x i8> [ %8767, %8013 ], [ <i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, %7563 ]
  %8020 = phi <16 x i8> [ %8767, %8013 ], [ %7957, %7563 ]
  %8021 = phi <4 x i32> [ %8402, %8013 ], [ %7632, %7563 ]
  %8022 = phi <4 x i32> [ %8401, %8013 ], [ %7631, %7563 ]
  %8023 = phi <4 x i32> [ %8397, %8013 ], [ %7627, %7563 ]
  %8024 = phi <4 x i32> [ %8396, %8013 ], [ %7626, %7563 ]
  %8025 = phi <4 x i32> [ %8657, %8013 ], [ %7875, %7563 ]
  %8026 = phi <4 x i32> [ %8660, %8013 ], [ %7878, %7563 ]
  %8027 = phi <4 x i32> [ %8595, %8013 ], [ %7864, %7563 ]
  %8028 = phi <4 x i32> [ %8598, %8013 ], [ %7867, %7563 ]
  %8029 = phi <4 x i32> [ %8775, %8013 ], [ %7965, %7563 ]
  %8030 = phi <4 x i32> [ %8777, %8013 ], [ %7967, %7563 ]
  %8031 = add <4 x i32> %8029, <i32 512, i32 512, i32 512, i32 512>
  %8032 = lshr <4 x i32> %8031, <i32 10, i32 10, i32 10, i32 10>
  %8033 = mul <4 x i32> %8025, <i32 455, i32 455, i32 455, i32 455>
  %8034 = add <4 x i32> %8033, <i32 2048, i32 2048, i32 2048, i32 2048>
  %8035 = lshr <4 x i32> %8034, <i32 12, i32 12, i32 12, i32 12>
  %8036 = mul <4 x i32> %8027, <i32 455, i32 455, i32 455, i32 455>
  %8037 = add <4 x i32> %8036, <i32 2048, i32 2048, i32 2048, i32 2048>
  %8038 = lshr <4 x i32> %8037, <i32 12, i32 12, i32 12, i32 12>
  %8039 = bitcast <16 x i8> %8018 to <2 x i64>
  %8040 = bitcast <16 x i8> %8017 to <2 x i64>
  %8041 = getelementptr inbounds i16, i16* %7603, i64 %8014
  %8042 = getelementptr inbounds i16, i16* %8041, i64 16
  %8043 = add nuw nsw i64 %8014, 16
  %8044 = bitcast i16* %8042 to <2 x i64>*
  %8045 = load <2 x i64>, <2 x i64>* %8044, align 1
  %8046 = getelementptr inbounds i16, i16* %8041, i64 24
  %8047 = bitcast i16* %8046 to <2 x i64>*
  %8048 = load <2 x i64>, <2 x i64>* %8047, align 1
  %8049 = getelementptr inbounds i16, i16* %7604, i64 %8014
  %8050 = getelementptr inbounds i16, i16* %8049, i64 16
  %8051 = bitcast i16* %8050 to <2 x i64>*
  %8052 = load <2 x i64>, <2 x i64>* %8051, align 1
  %8053 = getelementptr inbounds i16, i16* %8049, i64 24
  %8054 = bitcast i16* %8053 to <2 x i64>*
  %8055 = load <2 x i64>, <2 x i64>* %8054, align 1
  %8056 = or i64 %8014, 8
  %8057 = bitcast <2 x i64> %8016 to <8 x i16>
  %8058 = bitcast <2 x i64> %8045 to <16 x i8>
  %8059 = bitcast <2 x i64> %8016 to <16 x i8>
  %8060 = shufflevector <16 x i8> %8059, <16 x i8> %8058, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %8061 = bitcast <16 x i8> %8060 to <8 x i16>
  %8062 = shufflevector <16 x i8> %8059, <16 x i8> %8058, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8063 = bitcast <16 x i8> %8062 to <8 x i16>
  %8064 = shufflevector <16 x i8> %8059, <16 x i8> %8058, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %8065 = bitcast <16 x i8> %8064 to <8 x i16>
  %8066 = shufflevector <16 x i8> %8059, <16 x i8> %8058, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8067 = bitcast <16 x i8> %8066 to <8 x i16>
  %8068 = add <8 x i16> %8067, %8057
  %8069 = add <8 x i16> %8063, %8061
  %8070 = add <8 x i16> %8069, %8065
  %8071 = add <8 x i16> %8068, %8070
  %8072 = bitcast <2 x i64> %8045 to <8 x i16>
  %8073 = bitcast <2 x i64> %8048 to <16 x i8>
  %8074 = shufflevector <16 x i8> %8058, <16 x i8> %8073, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %8075 = bitcast <16 x i8> %8074 to <8 x i16>
  %8076 = shufflevector <16 x i8> %8058, <16 x i8> %8073, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8077 = bitcast <16 x i8> %8076 to <8 x i16>
  %8078 = shufflevector <16 x i8> %8058, <16 x i8> %8073, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %8079 = bitcast <16 x i8> %8078 to <8 x i16>
  %8080 = shufflevector <16 x i8> %8058, <16 x i8> %8073, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8081 = bitcast <16 x i8> %8080 to <8 x i16>
  %8082 = add <8 x i16> %8081, %8072
  %8083 = add <8 x i16> %8077, %8075
  %8084 = add <8 x i16> %8083, %8079
  %8085 = add <8 x i16> %8082, %8084
  %8086 = getelementptr inbounds i16, i16* %7978, i64 %8056
  %8087 = bitcast i16* %8086 to <8 x i16>*
  store <8 x i16> %8070, <8 x i16>* %8087, align 16
  %8088 = getelementptr inbounds i16, i16* %7979, i64 %8056
  %8089 = bitcast i16* %8088 to <8 x i16>*
  store <8 x i16> %8084, <8 x i16>* %8089, align 16
  %8090 = getelementptr inbounds i16, i16* %7980, i64 %8056
  %8091 = bitcast i16* %8090 to <8 x i16>*
  store <8 x i16> %8071, <8 x i16>* %8091, align 16
  %8092 = getelementptr inbounds i16, i16* %7981, i64 %8056
  %8093 = bitcast i16* %8092 to <8 x i16>*
  store <8 x i16> %8085, <8 x i16>* %8093, align 16
  %8094 = bitcast <2 x i64> %8015 to <8 x i16>
  %8095 = bitcast <2 x i64> %8052 to <16 x i8>
  %8096 = bitcast <2 x i64> %8015 to <16 x i8>
  %8097 = shufflevector <16 x i8> %8096, <16 x i8> %8095, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %8098 = bitcast <16 x i8> %8097 to <8 x i16>
  %8099 = shufflevector <16 x i8> %8096, <16 x i8> %8095, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8100 = bitcast <16 x i8> %8099 to <8 x i16>
  %8101 = shufflevector <16 x i8> %8096, <16 x i8> %8095, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %8102 = bitcast <16 x i8> %8101 to <8 x i16>
  %8103 = shufflevector <16 x i8> %8096, <16 x i8> %8095, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8104 = bitcast <16 x i8> %8103 to <8 x i16>
  %8105 = add <8 x i16> %8104, %8094
  %8106 = add <8 x i16> %8100, %8098
  %8107 = add <8 x i16> %8106, %8102
  %8108 = add <8 x i16> %8105, %8107
  %8109 = bitcast <2 x i64> %8052 to <8 x i16>
  %8110 = bitcast <2 x i64> %8055 to <16 x i8>
  %8111 = shufflevector <16 x i8> %8095, <16 x i8> %8110, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %8112 = bitcast <16 x i8> %8111 to <8 x i16>
  %8113 = shufflevector <16 x i8> %8095, <16 x i8> %8110, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8114 = bitcast <16 x i8> %8113 to <8 x i16>
  %8115 = shufflevector <16 x i8> %8095, <16 x i8> %8110, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %8116 = bitcast <16 x i8> %8115 to <8 x i16>
  %8117 = shufflevector <16 x i8> %8095, <16 x i8> %8110, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8118 = bitcast <16 x i8> %8117 to <8 x i16>
  %8119 = add <8 x i16> %8118, %8109
  %8120 = add <8 x i16> %8114, %8112
  %8121 = add <8 x i16> %8120, %8116
  %8122 = add <8 x i16> %8119, %8121
  %8123 = getelementptr inbounds i16, i16* %7982, i64 %8056
  %8124 = bitcast i16* %8123 to <8 x i16>*
  store <8 x i16> %8107, <8 x i16>* %8124, align 16
  %8125 = getelementptr inbounds i16, i16* %7983, i64 %8056
  %8126 = bitcast i16* %8125 to <8 x i16>*
  store <8 x i16> %8121, <8 x i16>* %8126, align 16
  %8127 = getelementptr inbounds i16, i16* %7984, i64 %8056
  %8128 = bitcast i16* %8127 to <8 x i16>*
  store <8 x i16> %8108, <8 x i16>* %8128, align 16
  %8129 = getelementptr inbounds i16, i16* %7985, i64 %8056
  %8130 = bitcast i16* %8129 to <8 x i16>*
  store <8 x i16> %8122, <8 x i16>* %8130, align 16
  %8131 = shufflevector <8 x i16> %8072, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8132 = shufflevector <8 x i16> %8072, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8133 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8131, <8 x i16> %8131) #5
  %8134 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8132, <8 x i16> %8132) #5
  %8135 = shufflevector <8 x i16> %8109, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8136 = shufflevector <8 x i16> %8109, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8137 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8135, <8 x i16> %8135) #5
  %8138 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8136, <8 x i16> %8136) #5
  %8139 = bitcast <4 x i32> %8023 to <16 x i8>
  %8140 = bitcast <4 x i32> %8024 to <16 x i8>
  %8141 = shufflevector <16 x i8> %8140, <16 x i8> %8139, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8142 = bitcast <16 x i8> %8141 to <4 x i32>
  %8143 = shufflevector <16 x i8> %8140, <16 x i8> %8139, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8144 = bitcast <16 x i8> %8143 to <4 x i32>
  %8145 = shufflevector <16 x i8> %8140, <16 x i8> %8139, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8146 = bitcast <16 x i8> %8145 to <4 x i32>
  %8147 = add <4 x i32> %8024, %8023
  %8148 = add <4 x i32> %8144, %8142
  %8149 = add <4 x i32> %8148, %8146
  %8150 = add <4 x i32> %8147, %8149
  %8151 = bitcast <4 x i32> %8133 to <16 x i8>
  %8152 = shufflevector <16 x i8> %8139, <16 x i8> %8151, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8153 = bitcast <16 x i8> %8152 to <4 x i32>
  %8154 = shufflevector <16 x i8> %8139, <16 x i8> %8151, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8155 = bitcast <16 x i8> %8154 to <4 x i32>
  %8156 = shufflevector <16 x i8> %8139, <16 x i8> %8151, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8157 = bitcast <16 x i8> %8156 to <4 x i32>
  %8158 = add <4 x i32> %8133, %8023
  %8159 = add <4 x i32> %8155, %8153
  %8160 = add <4 x i32> %8159, %8157
  %8161 = add <4 x i32> %8158, %8160
  %8162 = getelementptr inbounds i32, i32* %7687, i64 %8056
  %8163 = bitcast i32* %8162 to <4 x i32>*
  store <4 x i32> %8149, <4 x i32>* %8163, align 16
  %8164 = getelementptr inbounds i32, i32* %8162, i64 4
  %8165 = bitcast i32* %8164 to <4 x i32>*
  store <4 x i32> %8160, <4 x i32>* %8165, align 16
  %8166 = getelementptr inbounds i32, i32* %7691, i64 %8056
  %8167 = bitcast i32* %8166 to <4 x i32>*
  store <4 x i32> %8150, <4 x i32>* %8167, align 16
  %8168 = getelementptr inbounds i32, i32* %8166, i64 4
  %8169 = bitcast i32* %8168 to <4 x i32>*
  store <4 x i32> %8161, <4 x i32>* %8169, align 16
  %8170 = bitcast <4 x i32> %8021 to <16 x i8>
  %8171 = bitcast <4 x i32> %8022 to <16 x i8>
  %8172 = shufflevector <16 x i8> %8171, <16 x i8> %8170, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8173 = bitcast <16 x i8> %8172 to <4 x i32>
  %8174 = shufflevector <16 x i8> %8171, <16 x i8> %8170, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8175 = bitcast <16 x i8> %8174 to <4 x i32>
  %8176 = shufflevector <16 x i8> %8171, <16 x i8> %8170, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8177 = bitcast <16 x i8> %8176 to <4 x i32>
  %8178 = add <4 x i32> %8022, %8021
  %8179 = add <4 x i32> %8175, %8173
  %8180 = add <4 x i32> %8179, %8177
  %8181 = add <4 x i32> %8178, %8180
  %8182 = bitcast <4 x i32> %8137 to <16 x i8>
  %8183 = shufflevector <16 x i8> %8170, <16 x i8> %8182, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8184 = bitcast <16 x i8> %8183 to <4 x i32>
  %8185 = shufflevector <16 x i8> %8170, <16 x i8> %8182, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8186 = bitcast <16 x i8> %8185 to <4 x i32>
  %8187 = shufflevector <16 x i8> %8170, <16 x i8> %8182, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8188 = bitcast <16 x i8> %8187 to <4 x i32>
  %8189 = add <4 x i32> %8137, %8021
  %8190 = add <4 x i32> %8186, %8184
  %8191 = add <4 x i32> %8190, %8188
  %8192 = add <4 x i32> %8189, %8191
  %8193 = getelementptr inbounds i32, i32* %7718, i64 %8056
  %8194 = bitcast i32* %8193 to <4 x i32>*
  store <4 x i32> %8180, <4 x i32>* %8194, align 16
  %8195 = getelementptr inbounds i32, i32* %8193, i64 4
  %8196 = bitcast i32* %8195 to <4 x i32>*
  store <4 x i32> %8191, <4 x i32>* %8196, align 16
  %8197 = getelementptr inbounds i32, i32* %7722, i64 %8056
  %8198 = bitcast i32* %8197 to <4 x i32>*
  store <4 x i32> %8181, <4 x i32>* %8198, align 16
  %8199 = getelementptr inbounds i32, i32* %8197, i64 4
  %8200 = bitcast i32* %8199 to <4 x i32>*
  store <4 x i32> %8192, <4 x i32>* %8200, align 16
  %8201 = getelementptr inbounds i16, i16* %7986, i64 %8056
  %8202 = bitcast i16* %8201 to <8 x i16>*
  %8203 = load <8 x i16>, <8 x i16>* %8202, align 16
  %8204 = getelementptr inbounds i16, i16* %7987, i64 %8056
  %8205 = bitcast i16* %8204 to <8 x i16>*
  %8206 = load <8 x i16>, <8 x i16>* %8205, align 16
  %8207 = getelementptr inbounds i32, i32* %7730, i64 %8056
  %8208 = bitcast i32* %8207 to <4 x i32>*
  %8209 = load <4 x i32>, <4 x i32>* %8208, align 16
  %8210 = getelementptr inbounds i32, i32* %8207, i64 4
  %8211 = bitcast i32* %8210 to <4 x i32>*
  %8212 = load <4 x i32>, <4 x i32>* %8211, align 16
  %8213 = getelementptr inbounds i32, i32* %7736, i64 %8056
  %8214 = bitcast i32* %8213 to <4 x i32>*
  %8215 = load <4 x i32>, <4 x i32>* %8214, align 16
  %8216 = getelementptr inbounds i32, i32* %8213, i64 4
  %8217 = bitcast i32* %8216 to <4 x i32>*
  %8218 = load <4 x i32>, <4 x i32>* %8217, align 16
  %8219 = add <8 x i16> %8206, %8070
  %8220 = add <8 x i16> %8219, %8203
  %8221 = add <8 x i16> %8220, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8222 = lshr <8 x i16> %8221, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8223 = shufflevector <8 x i16> %8222, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8224 = shufflevector <8 x i16> %8222, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8225 = add <4 x i32> %8149, <i32 8, i32 8, i32 8, i32 8>
  %8226 = add <4 x i32> %8225, %8215
  %8227 = add <4 x i32> %8226, %8209
  %8228 = lshr <4 x i32> %8227, <i32 4, i32 4, i32 4, i32 4>
  %8229 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8223, <8 x i16> %8223) #5
  %8230 = mul nuw <4 x i32> %8228, <i32 9, i32 9, i32 9, i32 9>
  %8231 = sub <4 x i32> %8230, %8229
  %8232 = icmp sgt <4 x i32> %8231, zeroinitializer
  %8233 = select <4 x i1> %8232, <4 x i32> %8231, <4 x i32> zeroinitializer
  %8234 = mul <4 x i32> %8233, %6317
  %8235 = add <4 x i32> %8234, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8236 = lshr <4 x i32> %8235, <i32 20, i32 20, i32 20, i32 20>
  %8237 = add <4 x i32> %8160, <i32 8, i32 8, i32 8, i32 8>
  %8238 = add <4 x i32> %8237, %8218
  %8239 = add <4 x i32> %8238, %8212
  %8240 = lshr <4 x i32> %8239, <i32 4, i32 4, i32 4, i32 4>
  %8241 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8224, <8 x i16> %8224) #5
  %8242 = mul nuw <4 x i32> %8240, <i32 9, i32 9, i32 9, i32 9>
  %8243 = sub <4 x i32> %8242, %8241
  %8244 = icmp sgt <4 x i32> %8243, zeroinitializer
  %8245 = select <4 x i1> %8244, <4 x i32> %8243, <4 x i32> zeroinitializer
  %8246 = mul <4 x i32> %8245, %6317
  %8247 = add <4 x i32> %8246, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8248 = lshr <4 x i32> %8247, <i32 20, i32 20, i32 20, i32 20>
  %8249 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %8236, <4 x i32> %8248) #5
  %8250 = add <8 x i16> %8219, %8107
  %8251 = add <8 x i16> %8250, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8252 = lshr <8 x i16> %8251, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8253 = shufflevector <8 x i16> %8252, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8254 = shufflevector <8 x i16> %8252, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8255 = add <4 x i32> %8226, %8180
  %8256 = lshr <4 x i32> %8255, <i32 4, i32 4, i32 4, i32 4>
  %8257 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8253, <8 x i16> %8253) #5
  %8258 = mul nuw <4 x i32> %8256, <i32 9, i32 9, i32 9, i32 9>
  %8259 = sub <4 x i32> %8258, %8257
  %8260 = icmp sgt <4 x i32> %8259, zeroinitializer
  %8261 = select <4 x i1> %8260, <4 x i32> %8259, <4 x i32> zeroinitializer
  %8262 = mul <4 x i32> %8261, %6317
  %8263 = add <4 x i32> %8262, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8264 = lshr <4 x i32> %8263, <i32 20, i32 20, i32 20, i32 20>
  %8265 = add <4 x i32> %8238, %8191
  %8266 = lshr <4 x i32> %8265, <i32 4, i32 4, i32 4, i32 4>
  %8267 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8254, <8 x i16> %8254) #5
  %8268 = mul nuw <4 x i32> %8266, <i32 9, i32 9, i32 9, i32 9>
  %8269 = sub <4 x i32> %8268, %8267
  %8270 = icmp sgt <4 x i32> %8269, zeroinitializer
  %8271 = select <4 x i1> %8270, <4 x i32> %8269, <4 x i32> zeroinitializer
  %8272 = mul <4 x i32> %8271, %6317
  %8273 = add <4 x i32> %8272, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8274 = lshr <4 x i32> %8273, <i32 20, i32 20, i32 20, i32 20>
  %8275 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %8264, <4 x i32> %8274) #5
  %8276 = getelementptr inbounds i16, i16* %7988, i64 %8056
  %8277 = bitcast i16* %8276 to <8 x i16>*
  %8278 = load <8 x i16>, <8 x i16>* %8277, align 16
  %8279 = getelementptr inbounds i16, i16* %7989, i64 %8056
  %8280 = bitcast i16* %8279 to <8 x i16>*
  %8281 = load <8 x i16>, <8 x i16>* %8280, align 16
  %8282 = getelementptr inbounds i16, i16* %7990, i64 %8056
  %8283 = bitcast i16* %8282 to <8 x i16>*
  %8284 = load <8 x i16>, <8 x i16>* %8283, align 16
  %8285 = getelementptr inbounds i32, i32* %7748, i64 %8056
  %8286 = bitcast i32* %8285 to <4 x i32>*
  %8287 = load <4 x i32>, <4 x i32>* %8286, align 16
  %8288 = getelementptr inbounds i32, i32* %8285, i64 4
  %8289 = bitcast i32* %8288 to <4 x i32>*
  %8290 = load <4 x i32>, <4 x i32>* %8289, align 16
  %8291 = getelementptr inbounds i32, i32* %7754, i64 %8056
  %8292 = bitcast i32* %8291 to <4 x i32>*
  %8293 = load <4 x i32>, <4 x i32>* %8292, align 16
  %8294 = getelementptr inbounds i32, i32* %8291, i64 4
  %8295 = bitcast i32* %8294 to <4 x i32>*
  %8296 = load <4 x i32>, <4 x i32>* %8295, align 16
  %8297 = getelementptr inbounds i32, i32* %7760, i64 %8056
  %8298 = bitcast i32* %8297 to <4 x i32>*
  %8299 = load <4 x i32>, <4 x i32>* %8298, align 16
  %8300 = getelementptr inbounds i32, i32* %8297, i64 4
  %8301 = bitcast i32* %8300 to <4 x i32>*
  %8302 = load <4 x i32>, <4 x i32>* %8301, align 16
  %8303 = add <8 x i16> %8108, %8071
  %8304 = add <8 x i16> %8303, %8278
  %8305 = add <8 x i16> %8304, %8281
  %8306 = add <8 x i16> %8305, %8284
  %8307 = add <8 x i16> %8306, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8308 = lshr <8 x i16> %8307, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8309 = shufflevector <8 x i16> %8308, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8310 = shufflevector <8 x i16> %8308, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8311 = add <4 x i32> %8181, <i32 8, i32 8, i32 8, i32 8>
  %8312 = add <4 x i32> %8311, %8150
  %8313 = add <4 x i32> %8312, %8287
  %8314 = add <4 x i32> %8313, %8293
  %8315 = add <4 x i32> %8314, %8299
  %8316 = lshr <4 x i32> %8315, <i32 4, i32 4, i32 4, i32 4>
  %8317 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8309, <8 x i16> %8309) #5
  %8318 = mul <4 x i32> %8316, <i32 25, i32 25, i32 25, i32 25>
  %8319 = sub <4 x i32> %8318, %8317
  %8320 = icmp sgt <4 x i32> %8319, zeroinitializer
  %8321 = select <4 x i1> %8320, <4 x i32> %8319, <4 x i32> zeroinitializer
  %8322 = mul <4 x i32> %8321, %6442
  %8323 = add <4 x i32> %8322, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8324 = lshr <4 x i32> %8323, <i32 20, i32 20, i32 20, i32 20>
  %8325 = add <4 x i32> %8161, <i32 8, i32 8, i32 8, i32 8>
  %8326 = add <4 x i32> %8325, %8192
  %8327 = add <4 x i32> %8326, %8290
  %8328 = add <4 x i32> %8327, %8296
  %8329 = add <4 x i32> %8328, %8302
  %8330 = lshr <4 x i32> %8329, <i32 4, i32 4, i32 4, i32 4>
  %8331 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8310, <8 x i16> %8310) #5
  %8332 = mul <4 x i32> %8330, <i32 25, i32 25, i32 25, i32 25>
  %8333 = sub <4 x i32> %8332, %8331
  %8334 = icmp sgt <4 x i32> %8333, zeroinitializer
  %8335 = select <4 x i1> %8334, <4 x i32> %8333, <4 x i32> zeroinitializer
  %8336 = mul <4 x i32> %8335, %6442
  %8337 = add <4 x i32> %8336, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8338 = lshr <4 x i32> %8337, <i32 20, i32 20, i32 20, i32 20>
  %8339 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %8324, <4 x i32> %8338) #5
  %8340 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %8339, <8 x i16> undef) #5
  %8341 = bitcast <16 x i8> %8340 to <2 x i64>
  %8342 = extractelement <2 x i64> %8341, i32 0
  %8343 = lshr i64 %8342, 8
  %8344 = lshr i64 %8342, 16
  %8345 = lshr i64 %8342, 24
  %8346 = lshr i64 %8342, 32
  %8347 = lshr i64 %8342, 40
  %8348 = lshr i64 %8342, 48
  %8349 = lshr i64 %8342, 56
  %8350 = and i64 %8342, 255
  %8351 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8350
  %8352 = load i8, i8* %8351, align 1
  %8353 = insertelement <16 x i8> %8020, i8 %8352, i64 8
  %8354 = and i64 %8343, 255
  %8355 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8354
  %8356 = load i8, i8* %8355, align 1
  %8357 = insertelement <16 x i8> %8353, i8 %8356, i64 9
  %8358 = and i64 %8344, 255
  %8359 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8358
  %8360 = load i8, i8* %8359, align 1
  %8361 = insertelement <16 x i8> %8357, i8 %8360, i64 10
  %8362 = and i64 %8345, 255
  %8363 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8362
  %8364 = load i8, i8* %8363, align 1
  %8365 = insertelement <16 x i8> %8361, i8 %8364, i64 11
  %8366 = and i64 %8346, 255
  %8367 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8366
  %8368 = load i8, i8* %8367, align 1
  %8369 = insertelement <16 x i8> %8365, i8 %8368, i64 12
  %8370 = and i64 %8347, 255
  %8371 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8370
  %8372 = load i8, i8* %8371, align 1
  %8373 = insertelement <16 x i8> %8369, i8 %8372, i64 13
  %8374 = and i64 %8348, 255
  %8375 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8374
  %8376 = load i8, i8* %8375, align 1
  %8377 = insertelement <16 x i8> %8373, i8 %8376, i64 14
  %8378 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8349
  %8379 = load i8, i8* %8378, align 1
  %8380 = insertelement <16 x i8> %8377, i8 %8379, i64 15
  %8381 = shufflevector <16 x i8> %8380, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %8382 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8381, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %8383 = shufflevector <8 x i16> %8382, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8384 = shufflevector <8 x i16> %8306, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8385 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8383, <8 x i16> %8384) #5
  %8386 = shufflevector <8 x i16> %8382, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8387 = shufflevector <8 x i16> %8306, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8388 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8386, <8 x i16> %8387) #5
  %8389 = add <4 x i32> %8385, <i32 512, i32 512, i32 512, i32 512>
  %8390 = lshr <4 x i32> %8389, <i32 10, i32 10, i32 10, i32 10>
  %8391 = add <4 x i32> %8388, <i32 512, i32 512, i32 512, i32 512>
  %8392 = lshr <4 x i32> %8391, <i32 10, i32 10, i32 10, i32 10>
  %8393 = bitcast <2 x i64> %8048 to <8 x i16>
  %8394 = shufflevector <8 x i16> %8393, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8395 = shufflevector <8 x i16> %8393, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8396 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8394, <8 x i16> %8394) #5
  %8397 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8395, <8 x i16> %8395) #5
  %8398 = bitcast <2 x i64> %8055 to <8 x i16>
  %8399 = shufflevector <8 x i16> %8398, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8400 = shufflevector <8 x i16> %8398, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8401 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8399, <8 x i16> %8399) #5
  %8402 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8400, <8 x i16> %8400) #5
  %8403 = bitcast <4 x i32> %8134 to <16 x i8>
  %8404 = shufflevector <16 x i8> %8151, <16 x i8> %8403, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8405 = bitcast <16 x i8> %8404 to <4 x i32>
  %8406 = shufflevector <16 x i8> %8151, <16 x i8> %8403, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8407 = bitcast <16 x i8> %8406 to <4 x i32>
  %8408 = shufflevector <16 x i8> %8151, <16 x i8> %8403, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8409 = bitcast <16 x i8> %8408 to <4 x i32>
  %8410 = add <4 x i32> %8134, %8133
  %8411 = add <4 x i32> %8407, %8405
  %8412 = add <4 x i32> %8411, %8409
  %8413 = add <4 x i32> %8410, %8412
  %8414 = bitcast <4 x i32> %8396 to <16 x i8>
  %8415 = shufflevector <16 x i8> %8403, <16 x i8> %8414, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8416 = bitcast <16 x i8> %8415 to <4 x i32>
  %8417 = shufflevector <16 x i8> %8403, <16 x i8> %8414, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8418 = bitcast <16 x i8> %8417 to <4 x i32>
  %8419 = shufflevector <16 x i8> %8403, <16 x i8> %8414, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8420 = bitcast <16 x i8> %8419 to <4 x i32>
  %8421 = add <4 x i32> %8396, %8134
  %8422 = add <4 x i32> %8418, %8416
  %8423 = add <4 x i32> %8422, %8420
  %8424 = add <4 x i32> %8421, %8423
  %8425 = getelementptr inbounds i32, i32* %7991, i64 %8056
  %8426 = bitcast i32* %8425 to <4 x i32>*
  store <4 x i32> %8412, <4 x i32>* %8426, align 16
  %8427 = getelementptr inbounds i32, i32* %8425, i64 4
  %8428 = bitcast i32* %8427 to <4 x i32>*
  store <4 x i32> %8423, <4 x i32>* %8428, align 16
  %8429 = getelementptr inbounds i32, i32* %7992, i64 %8056
  %8430 = bitcast i32* %8429 to <4 x i32>*
  store <4 x i32> %8413, <4 x i32>* %8430, align 16
  %8431 = getelementptr inbounds i32, i32* %8429, i64 4
  %8432 = bitcast i32* %8431 to <4 x i32>*
  store <4 x i32> %8424, <4 x i32>* %8432, align 16
  %8433 = bitcast <4 x i32> %8138 to <16 x i8>
  %8434 = shufflevector <16 x i8> %8182, <16 x i8> %8433, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8435 = bitcast <16 x i8> %8434 to <4 x i32>
  %8436 = shufflevector <16 x i8> %8182, <16 x i8> %8433, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8437 = bitcast <16 x i8> %8436 to <4 x i32>
  %8438 = shufflevector <16 x i8> %8182, <16 x i8> %8433, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8439 = bitcast <16 x i8> %8438 to <4 x i32>
  %8440 = add <4 x i32> %8138, %8137
  %8441 = add <4 x i32> %8437, %8435
  %8442 = add <4 x i32> %8441, %8439
  %8443 = add <4 x i32> %8440, %8442
  %8444 = bitcast <4 x i32> %8401 to <16 x i8>
  %8445 = shufflevector <16 x i8> %8433, <16 x i8> %8444, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8446 = bitcast <16 x i8> %8445 to <4 x i32>
  %8447 = shufflevector <16 x i8> %8433, <16 x i8> %8444, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8448 = bitcast <16 x i8> %8447 to <4 x i32>
  %8449 = shufflevector <16 x i8> %8433, <16 x i8> %8444, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %8450 = bitcast <16 x i8> %8449 to <4 x i32>
  %8451 = add <4 x i32> %8401, %8138
  %8452 = add <4 x i32> %8448, %8446
  %8453 = add <4 x i32> %8452, %8450
  %8454 = add <4 x i32> %8451, %8453
  %8455 = getelementptr inbounds i32, i32* %7993, i64 %8056
  %8456 = bitcast i32* %8455 to <4 x i32>*
  store <4 x i32> %8442, <4 x i32>* %8456, align 16
  %8457 = getelementptr inbounds i32, i32* %8455, i64 4
  %8458 = bitcast i32* %8457 to <4 x i32>*
  store <4 x i32> %8453, <4 x i32>* %8458, align 16
  %8459 = getelementptr inbounds i32, i32* %7994, i64 %8056
  %8460 = bitcast i32* %8459 to <4 x i32>*
  store <4 x i32> %8443, <4 x i32>* %8460, align 16
  %8461 = getelementptr inbounds i32, i32* %8459, i64 4
  %8462 = bitcast i32* %8461 to <4 x i32>*
  store <4 x i32> %8454, <4 x i32>* %8462, align 16
  %8463 = add nuw nsw i64 %8056, 8
  %8464 = getelementptr inbounds i16, i16* %7986, i64 %8463
  %8465 = bitcast i16* %8464 to <8 x i16>*
  %8466 = load <8 x i16>, <8 x i16>* %8465, align 16
  %8467 = getelementptr inbounds i16, i16* %7987, i64 %8463
  %8468 = bitcast i16* %8467 to <8 x i16>*
  %8469 = load <8 x i16>, <8 x i16>* %8468, align 16
  %8470 = getelementptr inbounds i32, i32* %7730, i64 %8463
  %8471 = bitcast i32* %8470 to <4 x i32>*
  %8472 = load <4 x i32>, <4 x i32>* %8471, align 16
  %8473 = getelementptr inbounds i32, i32* %8470, i64 4
  %8474 = bitcast i32* %8473 to <4 x i32>*
  %8475 = load <4 x i32>, <4 x i32>* %8474, align 16
  %8476 = getelementptr inbounds i32, i32* %7736, i64 %8463
  %8477 = bitcast i32* %8476 to <4 x i32>*
  %8478 = load <4 x i32>, <4 x i32>* %8477, align 16
  %8479 = getelementptr inbounds i32, i32* %8476, i64 4
  %8480 = bitcast i32* %8479 to <4 x i32>*
  %8481 = load <4 x i32>, <4 x i32>* %8480, align 16
  %8482 = add <8 x i16> %8469, %8084
  %8483 = add <8 x i16> %8482, %8466
  %8484 = add <8 x i16> %8483, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8485 = lshr <8 x i16> %8484, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8486 = shufflevector <8 x i16> %8485, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8487 = shufflevector <8 x i16> %8485, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8488 = add <4 x i32> %8412, <i32 8, i32 8, i32 8, i32 8>
  %8489 = add <4 x i32> %8488, %8478
  %8490 = add <4 x i32> %8489, %8472
  %8491 = lshr <4 x i32> %8490, <i32 4, i32 4, i32 4, i32 4>
  %8492 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8486, <8 x i16> %8486) #5
  %8493 = mul nuw <4 x i32> %8491, <i32 9, i32 9, i32 9, i32 9>
  %8494 = sub <4 x i32> %8493, %8492
  %8495 = icmp sgt <4 x i32> %8494, zeroinitializer
  %8496 = select <4 x i1> %8495, <4 x i32> %8494, <4 x i32> zeroinitializer
  %8497 = mul <4 x i32> %8496, %6317
  %8498 = add <4 x i32> %8497, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8499 = lshr <4 x i32> %8498, <i32 20, i32 20, i32 20, i32 20>
  %8500 = add <4 x i32> %8423, <i32 8, i32 8, i32 8, i32 8>
  %8501 = add <4 x i32> %8500, %8481
  %8502 = add <4 x i32> %8501, %8475
  %8503 = lshr <4 x i32> %8502, <i32 4, i32 4, i32 4, i32 4>
  %8504 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8487, <8 x i16> %8487) #5
  %8505 = mul nuw <4 x i32> %8503, <i32 9, i32 9, i32 9, i32 9>
  %8506 = sub <4 x i32> %8505, %8504
  %8507 = icmp sgt <4 x i32> %8506, zeroinitializer
  %8508 = select <4 x i1> %8507, <4 x i32> %8506, <4 x i32> zeroinitializer
  %8509 = mul <4 x i32> %8508, %6317
  %8510 = add <4 x i32> %8509, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8511 = lshr <4 x i32> %8510, <i32 20, i32 20, i32 20, i32 20>
  %8512 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %8499, <4 x i32> %8511) #5
  %8513 = add <8 x i16> %8482, %8121
  %8514 = add <8 x i16> %8513, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8515 = lshr <8 x i16> %8514, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8516 = shufflevector <8 x i16> %8515, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8517 = shufflevector <8 x i16> %8515, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8518 = add <4 x i32> %8489, %8442
  %8519 = lshr <4 x i32> %8518, <i32 4, i32 4, i32 4, i32 4>
  %8520 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8516, <8 x i16> %8516) #5
  %8521 = mul nuw <4 x i32> %8519, <i32 9, i32 9, i32 9, i32 9>
  %8522 = sub <4 x i32> %8521, %8520
  %8523 = icmp sgt <4 x i32> %8522, zeroinitializer
  %8524 = select <4 x i1> %8523, <4 x i32> %8522, <4 x i32> zeroinitializer
  %8525 = mul <4 x i32> %8524, %6317
  %8526 = add <4 x i32> %8525, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8527 = lshr <4 x i32> %8526, <i32 20, i32 20, i32 20, i32 20>
  %8528 = add <4 x i32> %8501, %8453
  %8529 = lshr <4 x i32> %8528, <i32 4, i32 4, i32 4, i32 4>
  %8530 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8517, <8 x i16> %8517) #5
  %8531 = mul nuw <4 x i32> %8529, <i32 9, i32 9, i32 9, i32 9>
  %8532 = sub <4 x i32> %8531, %8530
  %8533 = icmp sgt <4 x i32> %8532, zeroinitializer
  %8534 = select <4 x i1> %8533, <4 x i32> %8532, <4 x i32> zeroinitializer
  %8535 = mul <4 x i32> %8534, %6317
  %8536 = add <4 x i32> %8535, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8537 = lshr <4 x i32> %8536, <i32 20, i32 20, i32 20, i32 20>
  %8538 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %8527, <4 x i32> %8537) #5
  %8539 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %8249, <8 x i16> %8512) #5
  %8540 = icmp ult <16 x i8> %8539, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %8541 = select <16 x i1> %8540, <16 x i8> %8539, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %8542 = icmp sgt <16 x i8> %8541, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %8543 = select <16 x i1> %8542, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %8541
  %8544 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %8543) #5
  %8545 = add nsw <16 x i8> %8541, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %8546 = icmp sgt <16 x i8> %8545, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %8547 = select <16 x i1> %8546, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %8545
  %8548 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %8547) #5
  %8549 = or <16 x i8> %8548, %8544
  %8550 = add nsw <16 x i8> %8541, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %8551 = icmp sgt <16 x i8> %8550, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %8552 = select <16 x i1> %8551, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %8550
  %8553 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %8552) #5
  %8554 = or <16 x i8> %8549, %8553
  %8555 = xor <16 x i8> %8539, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %8556 = icmp ugt <16 x i8> %8554, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %8557 = select <16 x i1> %8556, <16 x i8> %8554, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %8558 = icmp sgt <16 x i8> %8555, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %8559 = icmp sgt <16 x i8> %8555, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %8560 = sext <16 x i1> %8559 to <16 x i8>
  %8561 = icmp sgt <16 x i8> %8555, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %8562 = icmp sgt <16 x i8> %8555, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %8563 = icmp eq <16 x i8> %8555, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %8564 = zext <16 x i1> %8558 to <16 x i8>
  %8565 = sub nsw <16 x i8> %8560, %8564
  %8566 = zext <16 x i1> %8561 to <16 x i8>
  %8567 = sub nsw <16 x i8> %8565, %8566
  %8568 = zext <16 x i1> %8562 to <16 x i8>
  %8569 = sub nsw <16 x i8> %8567, %8568
  %8570 = zext <16 x i1> %8563 to <16 x i8>
  %8571 = sub nsw <16 x i8> %8569, %8570
  %8572 = add <16 x i8> %8571, %8557
  %8573 = bitcast <16 x i8> %8572 to <2 x i64>
  %8574 = shufflevector <16 x i8> %8572, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8575 = bitcast <16 x i8> %8574 to <8 x i16>
  %8576 = shufflevector <8 x i16> %8575, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8577 = shufflevector <8 x i16> %8220, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8578 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8576, <8 x i16> %8577) #5
  %8579 = shufflevector <8 x i16> %8575, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8580 = shufflevector <8 x i16> %8220, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8581 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8579, <8 x i16> %8580) #5
  %8582 = mul <4 x i32> %8578, <i32 455, i32 455, i32 455, i32 455>
  %8583 = mul <4 x i32> %8581, <i32 455, i32 455, i32 455, i32 455>
  %8584 = add <4 x i32> %8582, <i32 2048, i32 2048, i32 2048, i32 2048>
  %8585 = lshr <4 x i32> %8584, <i32 12, i32 12, i32 12, i32 12>
  %8586 = add <4 x i32> %8583, <i32 2048, i32 2048, i32 2048, i32 2048>
  %8587 = lshr <4 x i32> %8586, <i32 12, i32 12, i32 12, i32 12>
  %8588 = shufflevector <16 x i8> %8572, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %8589 = bitcast <16 x i8> %8588 to <8 x i16>
  %8590 = shufflevector <8 x i16> %8589, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8591 = shufflevector <8 x i16> %8483, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8592 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8590, <8 x i16> %8591) #5
  %8593 = shufflevector <8 x i16> %8589, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8594 = shufflevector <8 x i16> %8483, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8595 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8593, <8 x i16> %8594) #5
  %8596 = mul <4 x i32> %8592, <i32 455, i32 455, i32 455, i32 455>
  %8597 = add <4 x i32> %8596, <i32 2048, i32 2048, i32 2048, i32 2048>
  %8598 = lshr <4 x i32> %8597, <i32 12, i32 12, i32 12, i32 12>
  %8599 = shufflevector <2 x i64> %8039, <2 x i64> %8573, <2 x i32> <i32 0, i32 2>
  %8600 = shufflevector <16 x i8> %8572, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8601 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %8275, <8 x i16> %8538) #5
  %8602 = icmp ult <16 x i8> %8601, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %8603 = select <16 x i1> %8602, <16 x i8> %8601, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %8604 = icmp sgt <16 x i8> %8603, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %8605 = select <16 x i1> %8604, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %8603
  %8606 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %8605) #5
  %8607 = add nsw <16 x i8> %8603, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %8608 = icmp sgt <16 x i8> %8607, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %8609 = select <16 x i1> %8608, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %8607
  %8610 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %8609) #5
  %8611 = or <16 x i8> %8610, %8606
  %8612 = add nsw <16 x i8> %8603, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %8613 = icmp sgt <16 x i8> %8612, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %8614 = select <16 x i1> %8613, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %8612
  %8615 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %8614) #5
  %8616 = or <16 x i8> %8611, %8615
  %8617 = xor <16 x i8> %8601, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %8618 = icmp ugt <16 x i8> %8616, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %8619 = select <16 x i1> %8618, <16 x i8> %8616, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %8620 = icmp sgt <16 x i8> %8617, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %8621 = icmp sgt <16 x i8> %8617, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %8622 = sext <16 x i1> %8621 to <16 x i8>
  %8623 = icmp sgt <16 x i8> %8617, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %8624 = icmp sgt <16 x i8> %8617, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %8625 = icmp eq <16 x i8> %8617, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %8626 = zext <16 x i1> %8620 to <16 x i8>
  %8627 = sub nsw <16 x i8> %8622, %8626
  %8628 = zext <16 x i1> %8623 to <16 x i8>
  %8629 = sub nsw <16 x i8> %8627, %8628
  %8630 = zext <16 x i1> %8624 to <16 x i8>
  %8631 = sub nsw <16 x i8> %8629, %8630
  %8632 = zext <16 x i1> %8625 to <16 x i8>
  %8633 = sub nsw <16 x i8> %8631, %8632
  %8634 = add <16 x i8> %8633, %8619
  %8635 = bitcast <16 x i8> %8634 to <2 x i64>
  %8636 = shufflevector <16 x i8> %8634, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8637 = bitcast <16 x i8> %8636 to <8 x i16>
  %8638 = shufflevector <8 x i16> %8637, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8639 = shufflevector <8 x i16> %8250, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8640 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8638, <8 x i16> %8639) #5
  %8641 = shufflevector <8 x i16> %8637, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8642 = shufflevector <8 x i16> %8250, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8643 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8641, <8 x i16> %8642) #5
  %8644 = mul <4 x i32> %8640, <i32 455, i32 455, i32 455, i32 455>
  %8645 = mul <4 x i32> %8643, <i32 455, i32 455, i32 455, i32 455>
  %8646 = add <4 x i32> %8644, <i32 2048, i32 2048, i32 2048, i32 2048>
  %8647 = lshr <4 x i32> %8646, <i32 12, i32 12, i32 12, i32 12>
  %8648 = add <4 x i32> %8645, <i32 2048, i32 2048, i32 2048, i32 2048>
  %8649 = lshr <4 x i32> %8648, <i32 12, i32 12, i32 12, i32 12>
  %8650 = shufflevector <16 x i8> %8634, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %8651 = bitcast <16 x i8> %8650 to <8 x i16>
  %8652 = shufflevector <8 x i16> %8651, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8653 = shufflevector <8 x i16> %8513, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8654 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8652, <8 x i16> %8653) #5
  %8655 = shufflevector <8 x i16> %8651, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8656 = shufflevector <8 x i16> %8513, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8657 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8655, <8 x i16> %8656) #5
  %8658 = mul <4 x i32> %8654, <i32 455, i32 455, i32 455, i32 455>
  %8659 = add <4 x i32> %8658, <i32 2048, i32 2048, i32 2048, i32 2048>
  %8660 = lshr <4 x i32> %8659, <i32 12, i32 12, i32 12, i32 12>
  %8661 = shufflevector <2 x i64> %8040, <2 x i64> %8635, <2 x i32> <i32 0, i32 2>
  %8662 = shufflevector <16 x i8> %8634, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8663 = getelementptr inbounds i16, i16* %7988, i64 %8463
  %8664 = bitcast i16* %8663 to <8 x i16>*
  %8665 = load <8 x i16>, <8 x i16>* %8664, align 16
  %8666 = getelementptr inbounds i16, i16* %7989, i64 %8463
  %8667 = bitcast i16* %8666 to <8 x i16>*
  %8668 = load <8 x i16>, <8 x i16>* %8667, align 16
  %8669 = getelementptr inbounds i16, i16* %7990, i64 %8463
  %8670 = bitcast i16* %8669 to <8 x i16>*
  %8671 = load <8 x i16>, <8 x i16>* %8670, align 16
  %8672 = getelementptr inbounds i32, i32* %7748, i64 %8463
  %8673 = bitcast i32* %8672 to <4 x i32>*
  %8674 = load <4 x i32>, <4 x i32>* %8673, align 16
  %8675 = getelementptr inbounds i32, i32* %8672, i64 4
  %8676 = bitcast i32* %8675 to <4 x i32>*
  %8677 = load <4 x i32>, <4 x i32>* %8676, align 16
  %8678 = getelementptr inbounds i32, i32* %7754, i64 %8463
  %8679 = bitcast i32* %8678 to <4 x i32>*
  %8680 = load <4 x i32>, <4 x i32>* %8679, align 16
  %8681 = getelementptr inbounds i32, i32* %8678, i64 4
  %8682 = bitcast i32* %8681 to <4 x i32>*
  %8683 = load <4 x i32>, <4 x i32>* %8682, align 16
  %8684 = getelementptr inbounds i32, i32* %7760, i64 %8463
  %8685 = bitcast i32* %8684 to <4 x i32>*
  %8686 = load <4 x i32>, <4 x i32>* %8685, align 16
  %8687 = getelementptr inbounds i32, i32* %8684, i64 4
  %8688 = bitcast i32* %8687 to <4 x i32>*
  %8689 = load <4 x i32>, <4 x i32>* %8688, align 16
  %8690 = add <8 x i16> %8122, %8085
  %8691 = add <8 x i16> %8690, %8665
  %8692 = add <8 x i16> %8691, %8668
  %8693 = add <8 x i16> %8692, %8671
  %8694 = add <8 x i16> %8693, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8695 = lshr <8 x i16> %8694, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8696 = shufflevector <8 x i16> %8695, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8697 = shufflevector <8 x i16> %8695, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8698 = add <4 x i32> %8413, <i32 8, i32 8, i32 8, i32 8>
  %8699 = add <4 x i32> %8698, %8443
  %8700 = add <4 x i32> %8699, %8674
  %8701 = add <4 x i32> %8700, %8680
  %8702 = add <4 x i32> %8701, %8686
  %8703 = lshr <4 x i32> %8702, <i32 4, i32 4, i32 4, i32 4>
  %8704 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8696, <8 x i16> %8696) #5
  %8705 = mul <4 x i32> %8703, <i32 25, i32 25, i32 25, i32 25>
  %8706 = sub <4 x i32> %8705, %8704
  %8707 = icmp sgt <4 x i32> %8706, zeroinitializer
  %8708 = select <4 x i1> %8707, <4 x i32> %8706, <4 x i32> zeroinitializer
  %8709 = mul <4 x i32> %8708, %6442
  %8710 = add <4 x i32> %8709, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8711 = lshr <4 x i32> %8710, <i32 20, i32 20, i32 20, i32 20>
  %8712 = add <4 x i32> %8424, <i32 8, i32 8, i32 8, i32 8>
  %8713 = add <4 x i32> %8712, %8454
  %8714 = add <4 x i32> %8713, %8677
  %8715 = add <4 x i32> %8714, %8683
  %8716 = add <4 x i32> %8715, %8689
  %8717 = lshr <4 x i32> %8716, <i32 4, i32 4, i32 4, i32 4>
  %8718 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8697, <8 x i16> %8697) #5
  %8719 = mul <4 x i32> %8717, <i32 25, i32 25, i32 25, i32 25>
  %8720 = sub <4 x i32> %8719, %8718
  %8721 = icmp sgt <4 x i32> %8720, zeroinitializer
  %8722 = select <4 x i1> %8721, <4 x i32> %8720, <4 x i32> zeroinitializer
  %8723 = mul <4 x i32> %8722, %6442
  %8724 = add <4 x i32> %8723, <i32 524288, i32 524288, i32 524288, i32 524288>
  %8725 = lshr <4 x i32> %8724, <i32 20, i32 20, i32 20, i32 20>
  %8726 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %8711, <4 x i32> %8725) #5
  %8727 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %8726, <8 x i16> undef) #5
  %8728 = bitcast <16 x i8> %8727 to <2 x i64>
  %8729 = extractelement <2 x i64> %8728, i32 0
  %8730 = lshr i64 %8729, 8
  %8731 = lshr i64 %8729, 16
  %8732 = lshr i64 %8729, 24
  %8733 = lshr i64 %8729, 32
  %8734 = lshr i64 %8729, 40
  %8735 = lshr i64 %8729, 48
  %8736 = lshr i64 %8729, 56
  %8737 = and i64 %8729, 255
  %8738 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8737
  %8739 = load i8, i8* %8738, align 1
  %8740 = insertelement <16 x i8> %8019, i8 %8739, i64 0
  %8741 = and i64 %8730, 255
  %8742 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8741
  %8743 = load i8, i8* %8742, align 1
  %8744 = insertelement <16 x i8> %8740, i8 %8743, i64 1
  %8745 = and i64 %8731, 255
  %8746 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8745
  %8747 = load i8, i8* %8746, align 1
  %8748 = insertelement <16 x i8> %8744, i8 %8747, i64 2
  %8749 = and i64 %8732, 255
  %8750 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8749
  %8751 = load i8, i8* %8750, align 1
  %8752 = insertelement <16 x i8> %8748, i8 %8751, i64 3
  %8753 = and i64 %8733, 255
  %8754 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8753
  %8755 = load i8, i8* %8754, align 1
  %8756 = insertelement <16 x i8> %8752, i8 %8755, i64 4
  %8757 = and i64 %8734, 255
  %8758 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8757
  %8759 = load i8, i8* %8758, align 1
  %8760 = insertelement <16 x i8> %8756, i8 %8759, i64 5
  %8761 = and i64 %8735, 255
  %8762 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8761
  %8763 = load i8, i8* %8762, align 1
  %8764 = insertelement <16 x i8> %8760, i8 %8763, i64 6
  %8765 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %8736
  %8766 = load i8, i8* %8765, align 1
  %8767 = insertelement <16 x i8> %8764, i8 %8766, i64 7
  %8768 = shufflevector <16 x i8> %8767, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8769 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8768, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %8770 = shufflevector <8 x i16> %8769, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8771 = shufflevector <8 x i16> %8693, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8772 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8770, <8 x i16> %8771) #5
  %8773 = shufflevector <8 x i16> %8769, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8774 = shufflevector <8 x i16> %8693, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8775 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8773, <8 x i16> %8774) #5
  %8776 = add <4 x i32> %8772, <i32 512, i32 512, i32 512, i32 512>
  %8777 = lshr <4 x i32> %8776, <i32 10, i32 10, i32 10, i32 10>
  %8778 = bitcast <2 x i64> %8599 to <16 x i8>
  %8779 = shufflevector <16 x i8> %8778, <16 x i8> %8600, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %8780 = shufflevector <16 x i8> %8778, <16 x i8> %8600, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %8781 = bitcast <2 x i64> %8661 to <16 x i8>
  %8782 = shufflevector <16 x i8> %8781, <16 x i8> %8662, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %8783 = shufflevector <16 x i8> %8781, <16 x i8> %8662, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %8784 = shufflevector <16 x i8> %8380, <16 x i8> %8767, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %8785 = shufflevector <16 x i8> %8380, <16 x i8> %8767, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %8786 = shufflevector <16 x i8> %8778, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8787 = shufflevector <16 x i8> %8779, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8788 = bitcast <16 x i8> %8786 to <8 x i16>
  %8789 = bitcast <16 x i8> %8787 to <8 x i16>
  %8790 = add <8 x i16> %8789, %8788
  %8791 = shufflevector <16 x i8> %8780, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8792 = bitcast <16 x i8> %8791 to <8 x i16>
  %8793 = add <8 x i16> %8790, %8792
  %8794 = shl <8 x i16> %8793, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8795 = getelementptr inbounds i16, i16* %5956, i64 %8014
  %8796 = bitcast i16* %8795 to <8 x i16>*
  store <8 x i16> %8794, <8 x i16>* %8796, align 16
  %8797 = mul <8 x i16> %8793, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %8798 = add <8 x i16> %8797, %8789
  %8799 = getelementptr inbounds i16, i16* %7995, i64 %8014
  %8800 = bitcast i16* %8799 to <8 x i16>*
  store <8 x i16> %8798, <8 x i16>* %8800, align 16
  %8801 = bitcast <4 x i32> %8038 to <16 x i8>
  %8802 = bitcast <4 x i32> %8028 to <16 x i8>
  %8803 = shufflevector <16 x i8> %8802, <16 x i8> %8801, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8804 = shufflevector <16 x i8> %8802, <16 x i8> %8801, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8805 = bitcast <16 x i8> %8804 to <4 x i32>
  %8806 = bitcast <16 x i8> %8803 to <4 x i32>
  %8807 = add <4 x i32> %8028, %8806
  %8808 = add <4 x i32> %8807, %8805
  %8809 = shl <4 x i32> %8808, <i32 2, i32 2, i32 2, i32 2>
  %8810 = mul <4 x i32> %8808, <i32 3, i32 3, i32 3, i32 3>
  %8811 = add <4 x i32> %8810, %8806
  %8812 = bitcast <4 x i32> %8585 to <16 x i8>
  %8813 = shufflevector <16 x i8> %8801, <16 x i8> %8812, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8814 = shufflevector <16 x i8> %8801, <16 x i8> %8812, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8815 = bitcast <16 x i8> %8814 to <4 x i32>
  %8816 = bitcast <16 x i8> %8813 to <4 x i32>
  %8817 = add <4 x i32> %8038, %8816
  %8818 = add <4 x i32> %8817, %8815
  %8819 = shl <4 x i32> %8818, <i32 2, i32 2, i32 2, i32 2>
  %8820 = mul <4 x i32> %8818, <i32 3, i32 3, i32 3, i32 3>
  %8821 = add <4 x i32> %8820, %8816
  %8822 = getelementptr inbounds i32, i32* %5957, i64 %8014
  %8823 = bitcast i32* %8822 to <4 x i32>*
  store <4 x i32> %8809, <4 x i32>* %8823, align 16
  %8824 = getelementptr inbounds i32, i32* %8822, i64 4
  %8825 = bitcast i32* %8824 to <4 x i32>*
  store <4 x i32> %8819, <4 x i32>* %8825, align 16
  %8826 = getelementptr inbounds i32, i32* %7996, i64 %8014
  %8827 = bitcast i32* %8826 to <4 x i32>*
  store <4 x i32> %8811, <4 x i32>* %8827, align 16
  %8828 = getelementptr inbounds i32, i32* %8826, i64 4
  %8829 = bitcast i32* %8828 to <4 x i32>*
  store <4 x i32> %8821, <4 x i32>* %8829, align 16
  %8830 = shufflevector <16 x i8> %8781, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8831 = shufflevector <16 x i8> %8782, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8832 = bitcast <16 x i8> %8830 to <8 x i16>
  %8833 = bitcast <16 x i8> %8831 to <8 x i16>
  %8834 = add <8 x i16> %8833, %8832
  %8835 = shufflevector <16 x i8> %8783, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8836 = bitcast <16 x i8> %8835 to <8 x i16>
  %8837 = add <8 x i16> %8834, %8836
  %8838 = shl <8 x i16> %8837, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %8839 = getelementptr inbounds i16, i16* %7998, i64 %8014
  %8840 = bitcast i16* %8839 to <8 x i16>*
  store <8 x i16> %8838, <8 x i16>* %8840, align 16
  %8841 = mul <8 x i16> %8837, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %8842 = add <8 x i16> %8841, %8833
  %8843 = getelementptr inbounds i16, i16* %7997, i64 %8014
  %8844 = bitcast i16* %8843 to <8 x i16>*
  store <8 x i16> %8842, <8 x i16>* %8844, align 16
  %8845 = bitcast <4 x i32> %8035 to <16 x i8>
  %8846 = bitcast <4 x i32> %8026 to <16 x i8>
  %8847 = shufflevector <16 x i8> %8846, <16 x i8> %8845, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8848 = shufflevector <16 x i8> %8846, <16 x i8> %8845, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8849 = bitcast <16 x i8> %8848 to <4 x i32>
  %8850 = bitcast <16 x i8> %8847 to <4 x i32>
  %8851 = add <4 x i32> %8026, %8850
  %8852 = add <4 x i32> %8851, %8849
  %8853 = shl <4 x i32> %8852, <i32 2, i32 2, i32 2, i32 2>
  %8854 = mul <4 x i32> %8852, <i32 3, i32 3, i32 3, i32 3>
  %8855 = add <4 x i32> %8854, %8850
  %8856 = bitcast <4 x i32> %8647 to <16 x i8>
  %8857 = shufflevector <16 x i8> %8845, <16 x i8> %8856, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8858 = shufflevector <16 x i8> %8845, <16 x i8> %8856, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8859 = bitcast <16 x i8> %8858 to <4 x i32>
  %8860 = bitcast <16 x i8> %8857 to <4 x i32>
  %8861 = add <4 x i32> %8035, %8860
  %8862 = add <4 x i32> %8861, %8859
  %8863 = shl <4 x i32> %8862, <i32 2, i32 2, i32 2, i32 2>
  %8864 = mul <4 x i32> %8862, <i32 3, i32 3, i32 3, i32 3>
  %8865 = add <4 x i32> %8864, %8860
  %8866 = getelementptr inbounds i32, i32* %8000, i64 %8014
  %8867 = bitcast i32* %8866 to <4 x i32>*
  store <4 x i32> %8853, <4 x i32>* %8867, align 16
  %8868 = getelementptr inbounds i32, i32* %8866, i64 4
  %8869 = bitcast i32* %8868 to <4 x i32>*
  store <4 x i32> %8863, <4 x i32>* %8869, align 16
  %8870 = getelementptr inbounds i32, i32* %7999, i64 %8014
  %8871 = bitcast i32* %8870 to <4 x i32>*
  store <4 x i32> %8855, <4 x i32>* %8871, align 16
  %8872 = getelementptr inbounds i32, i32* %8870, i64 4
  %8873 = bitcast i32* %8872 to <4 x i32>*
  store <4 x i32> %8865, <4 x i32>* %8873, align 16
  %8874 = shufflevector <16 x i8> %8380, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8875 = shufflevector <16 x i8> %8784, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8876 = bitcast <16 x i8> %8874 to <8 x i16>
  %8877 = bitcast <16 x i8> %8875 to <8 x i16>
  %8878 = add <8 x i16> %8877, %8876
  %8879 = shufflevector <16 x i8> %8785, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8880 = bitcast <16 x i8> %8879 to <8 x i16>
  %8881 = add <8 x i16> %8878, %8880
  %8882 = mul <8 x i16> %8881, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %8883 = add <8 x i16> %8882, %8877
  %8884 = getelementptr inbounds i16, i16* %7970, i64 %8014
  %8885 = bitcast i16* %8884 to <8 x i16>*
  store <8 x i16> %8883, <8 x i16>* %8885, align 16
  %8886 = bitcast <4 x i32> %8032 to <16 x i8>
  %8887 = bitcast <4 x i32> %8030 to <16 x i8>
  %8888 = shufflevector <16 x i8> %8887, <16 x i8> %8886, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8889 = bitcast <16 x i8> %8888 to <4 x i32>
  %8890 = shufflevector <16 x i8> %8887, <16 x i8> %8886, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8891 = bitcast <16 x i8> %8890 to <4 x i32>
  %8892 = add <4 x i32> %8030, %8889
  %8893 = add <4 x i32> %8892, %8891
  %8894 = mul <4 x i32> %8893, <i32 5, i32 5, i32 5, i32 5>
  %8895 = add <4 x i32> %8894, %8889
  %8896 = bitcast <4 x i32> %8390 to <16 x i8>
  %8897 = shufflevector <16 x i8> %8886, <16 x i8> %8896, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %8898 = bitcast <16 x i8> %8897 to <4 x i32>
  %8899 = shufflevector <16 x i8> %8886, <16 x i8> %8896, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %8900 = bitcast <16 x i8> %8899 to <4 x i32>
  %8901 = add <4 x i32> %8032, %8898
  %8902 = add <4 x i32> %8901, %8900
  %8903 = mul <4 x i32> %8902, <i32 5, i32 5, i32 5, i32 5>
  %8904 = add <4 x i32> %8903, %8898
  %8905 = getelementptr inbounds i32, i32* %7971, i64 %8014
  %8906 = bitcast i32* %8905 to <4 x i32>*
  store <4 x i32> %8895, <4 x i32>* %8906, align 16
  %8907 = getelementptr inbounds i32, i32* %8905, i64 4
  %8908 = bitcast i32* %8907 to <4 x i32>*
  store <4 x i32> %8904, <4 x i32>* %8908, align 16
  %8909 = getelementptr inbounds i16, i16* %7602, i64 %8014
  %8910 = bitcast i16* %8909 to <8 x i16>*
  %8911 = load <8 x i16>, <8 x i16>* %8910, align 16
  %8912 = getelementptr inbounds i16, i16* %7968, i64 %8014
  %8913 = bitcast i16* %8912 to <8 x i16>*
  %8914 = load <8 x i16>, <8 x i16>* %8913, align 16
  %8915 = getelementptr inbounds i16, i16* %7972, i64 %8014
  %8916 = bitcast i16* %8915 to <8 x i16>*
  %8917 = load <8 x i16>, <8 x i16>* %8916, align 16
  %8918 = getelementptr inbounds i32, i32* %7973, i64 %8014
  %8919 = bitcast i32* %8918 to <4 x i32>*
  %8920 = load <4 x i32>, <4 x i32>* %8919, align 16
  %8921 = getelementptr inbounds i32, i32* %8918, i64 4
  %8922 = bitcast i32* %8921 to <4 x i32>*
  %8923 = load <4 x i32>, <4 x i32>* %8922, align 16
  %8924 = add <8 x i16> %8917, %8883
  %8925 = shufflevector <8 x i16> %8924, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8926 = shufflevector <8 x i16> %8911, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8927 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8925, <8 x i16> %8926) #5
  %8928 = shufflevector <8 x i16> %8924, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8929 = shufflevector <8 x i16> %8911, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8930 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8928, <8 x i16> %8929) #5
  %8931 = add <4 x i32> %8895, <i32 256, i32 256, i32 256, i32 256>
  %8932 = add <4 x i32> %8931, %8920
  %8933 = sub <4 x i32> %8932, %8927
  %8934 = ashr <4 x i32> %8933, <i32 9, i32 9, i32 9, i32 9>
  %8935 = add <4 x i32> %8904, <i32 256, i32 256, i32 256, i32 256>
  %8936 = add <4 x i32> %8935, %8923
  %8937 = sub <4 x i32> %8936, %8930
  %8938 = ashr <4 x i32> %8937, <i32 9, i32 9, i32 9, i32 9>
  %8939 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %8934, <4 x i32> %8938) #5
  %8940 = shufflevector <8 x i16> %8883, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8941 = shufflevector <8 x i16> %8914, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8942 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8940, <8 x i16> %8941) #5
  %8943 = shufflevector <8 x i16> %8883, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8944 = shufflevector <8 x i16> %8914, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8945 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8943, <8 x i16> %8944) #5
  %8946 = add <4 x i32> %8895, <i32 128, i32 128, i32 128, i32 128>
  %8947 = sub <4 x i32> %8946, %8942
  %8948 = ashr <4 x i32> %8947, <i32 8, i32 8, i32 8, i32 8>
  %8949 = add <4 x i32> %8904, <i32 128, i32 128, i32 128, i32 128>
  %8950 = sub <4 x i32> %8949, %8945
  %8951 = ashr <4 x i32> %8950, <i32 8, i32 8, i32 8, i32 8>
  %8952 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %8948, <4 x i32> %8951) #5
  %8953 = getelementptr inbounds i16, i16* %8001, i64 %8014
  %8954 = bitcast i16* %8953 to <8 x i16>*
  %8955 = load <8 x i16>, <8 x i16>* %8954, align 16
  %8956 = getelementptr inbounds i16, i16* %8002, i64 %8014
  %8957 = bitcast i16* %8956 to <8 x i16>*
  %8958 = load <8 x i16>, <8 x i16>* %8957, align 16
  %8959 = getelementptr inbounds i32, i32* %8003, i64 %8014
  %8960 = bitcast i32* %8959 to <4 x i32>*
  %8961 = load <4 x i32>, <4 x i32>* %8960, align 16
  %8962 = getelementptr inbounds i32, i32* %8959, i64 4
  %8963 = bitcast i32* %8962 to <4 x i32>*
  %8964 = load <4 x i32>, <4 x i32>* %8963, align 16
  %8965 = getelementptr inbounds i32, i32* %8004, i64 %8014
  %8966 = bitcast i32* %8965 to <4 x i32>*
  %8967 = load <4 x i32>, <4 x i32>* %8966, align 16
  %8968 = getelementptr inbounds i32, i32* %8965, i64 4
  %8969 = bitcast i32* %8968 to <4 x i32>*
  %8970 = load <4 x i32>, <4 x i32>* %8969, align 16
  %8971 = add <8 x i16> %8955, %8798
  %8972 = add <8 x i16> %8971, %8958
  %8973 = shufflevector <8 x i16> %8972, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8974 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8973, <8 x i16> %8926) #5
  %8975 = shufflevector <8 x i16> %8972, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8976 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8975, <8 x i16> %8929) #5
  %8977 = add <4 x i32> %8811, <i32 256, i32 256, i32 256, i32 256>
  %8978 = add <4 x i32> %8977, %8961
  %8979 = add <4 x i32> %8978, %8967
  %8980 = sub <4 x i32> %8979, %8974
  %8981 = ashr <4 x i32> %8980, <i32 9, i32 9, i32 9, i32 9>
  %8982 = add <4 x i32> %8821, <i32 256, i32 256, i32 256, i32 256>
  %8983 = add <4 x i32> %8982, %8964
  %8984 = add <4 x i32> %8983, %8970
  %8985 = sub <4 x i32> %8984, %8976
  %8986 = ashr <4 x i32> %8985, <i32 9, i32 9, i32 9, i32 9>
  %8987 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %8981, <4 x i32> %8986) #5
  %8988 = shufflevector <8 x i16> %8939, <8 x i16> %8987, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8989 = shufflevector <8 x i16> %8939, <8 x i16> %8987, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8990 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %8988) #5
  %8991 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %8989) #5
  %8992 = add <4 x i32> %8990, <i32 1024, i32 1024, i32 1024, i32 1024>
  %8993 = ashr <4 x i32> %8992, <i32 11, i32 11, i32 11, i32 11>
  %8994 = add <4 x i32> %8991, <i32 1024, i32 1024, i32 1024, i32 1024>
  %8995 = ashr <4 x i32> %8994, <i32 11, i32 11, i32 11, i32 11>
  %8996 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %8993, <4 x i32> %8995) #5
  %8997 = add <8 x i16> %8996, %8911
  %8998 = getelementptr inbounds i16, i16* %8005, i64 %8014
  %8999 = bitcast i16* %8998 to <8 x i16>*
  %9000 = load <8 x i16>, <8 x i16>* %8999, align 16
  %9001 = getelementptr inbounds i32, i32* %8006, i64 %8014
  %9002 = bitcast i32* %9001 to <4 x i32>*
  %9003 = load <4 x i32>, <4 x i32>* %9002, align 16
  %9004 = getelementptr inbounds i32, i32* %9001, i64 4
  %9005 = bitcast i32* %9004 to <4 x i32>*
  %9006 = load <4 x i32>, <4 x i32>* %9005, align 16
  %9007 = add <8 x i16> %8842, %8794
  %9008 = add <8 x i16> %9007, %9000
  %9009 = shufflevector <8 x i16> %9008, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9010 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9009, <8 x i16> %8941) #5
  %9011 = shufflevector <8 x i16> %9008, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9012 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9011, <8 x i16> %8944) #5
  %9013 = add <4 x i32> %8855, <i32 256, i32 256, i32 256, i32 256>
  %9014 = add <4 x i32> %9013, %8809
  %9015 = add <4 x i32> %9014, %9003
  %9016 = sub <4 x i32> %9015, %9010
  %9017 = ashr <4 x i32> %9016, <i32 9, i32 9, i32 9, i32 9>
  %9018 = add <4 x i32> %8819, <i32 256, i32 256, i32 256, i32 256>
  %9019 = add <4 x i32> %9018, %8865
  %9020 = add <4 x i32> %9019, %9006
  %9021 = sub <4 x i32> %9020, %9012
  %9022 = ashr <4 x i32> %9021, <i32 9, i32 9, i32 9, i32 9>
  %9023 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9017, <4 x i32> %9022) #5
  %9024 = shufflevector <8 x i16> %8952, <8 x i16> %9023, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9025 = shufflevector <8 x i16> %8952, <8 x i16> %9023, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9026 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %9024) #5
  %9027 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %9025) #5
  %9028 = add <4 x i32> %9026, <i32 1024, i32 1024, i32 1024, i32 1024>
  %9029 = ashr <4 x i32> %9028, <i32 11, i32 11, i32 11, i32 11>
  %9030 = add <4 x i32> %9027, <i32 1024, i32 1024, i32 1024, i32 1024>
  %9031 = ashr <4 x i32> %9030, <i32 11, i32 11, i32 11, i32 11>
  %9032 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9029, <4 x i32> %9031) #5
  %9033 = add <8 x i16> %9032, %8914
  %9034 = shufflevector <16 x i8> %8778, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9035 = shufflevector <16 x i8> %8779, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9036 = bitcast <16 x i8> %9034 to <8 x i16>
  %9037 = bitcast <16 x i8> %9035 to <8 x i16>
  %9038 = add <8 x i16> %9037, %9036
  %9039 = shufflevector <16 x i8> %8780, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9040 = bitcast <16 x i8> %9039 to <8 x i16>
  %9041 = add <8 x i16> %9038, %9040
  %9042 = shl <8 x i16> %9041, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9043 = getelementptr inbounds i16, i16* %5956, i64 %8056
  %9044 = bitcast i16* %9043 to <8 x i16>*
  store <8 x i16> %9042, <8 x i16>* %9044, align 16
  %9045 = mul <8 x i16> %9041, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %9046 = add <8 x i16> %9045, %9037
  %9047 = getelementptr inbounds i16, i16* %7995, i64 %8056
  %9048 = bitcast i16* %9047 to <8 x i16>*
  store <8 x i16> %9046, <8 x i16>* %9048, align 16
  %9049 = bitcast <4 x i32> %8587 to <16 x i8>
  %9050 = shufflevector <16 x i8> %8812, <16 x i8> %9049, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9051 = shufflevector <16 x i8> %8812, <16 x i8> %9049, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9052 = bitcast <16 x i8> %9051 to <4 x i32>
  %9053 = bitcast <16 x i8> %9050 to <4 x i32>
  %9054 = add <4 x i32> %8585, %9053
  %9055 = add <4 x i32> %9054, %9052
  %9056 = shl <4 x i32> %9055, <i32 2, i32 2, i32 2, i32 2>
  %9057 = mul <4 x i32> %9055, <i32 3, i32 3, i32 3, i32 3>
  %9058 = add <4 x i32> %9057, %9053
  %9059 = bitcast <4 x i32> %8598 to <16 x i8>
  %9060 = shufflevector <16 x i8> %9049, <16 x i8> %9059, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9061 = shufflevector <16 x i8> %9049, <16 x i8> %9059, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9062 = bitcast <16 x i8> %9061 to <4 x i32>
  %9063 = bitcast <16 x i8> %9060 to <4 x i32>
  %9064 = add <4 x i32> %8587, %9063
  %9065 = add <4 x i32> %9064, %9062
  %9066 = shl <4 x i32> %9065, <i32 2, i32 2, i32 2, i32 2>
  %9067 = mul <4 x i32> %9065, <i32 3, i32 3, i32 3, i32 3>
  %9068 = add <4 x i32> %9067, %9063
  %9069 = getelementptr inbounds i32, i32* %5957, i64 %8056
  %9070 = bitcast i32* %9069 to <4 x i32>*
  store <4 x i32> %9056, <4 x i32>* %9070, align 16
  %9071 = getelementptr inbounds i32, i32* %9069, i64 4
  %9072 = bitcast i32* %9071 to <4 x i32>*
  store <4 x i32> %9066, <4 x i32>* %9072, align 16
  %9073 = getelementptr inbounds i32, i32* %7996, i64 %8056
  %9074 = bitcast i32* %9073 to <4 x i32>*
  store <4 x i32> %9058, <4 x i32>* %9074, align 16
  %9075 = getelementptr inbounds i32, i32* %9073, i64 4
  %9076 = bitcast i32* %9075 to <4 x i32>*
  store <4 x i32> %9068, <4 x i32>* %9076, align 16
  %9077 = shufflevector <16 x i8> %8781, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9078 = shufflevector <16 x i8> %8782, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9079 = bitcast <16 x i8> %9077 to <8 x i16>
  %9080 = bitcast <16 x i8> %9078 to <8 x i16>
  %9081 = add <8 x i16> %9080, %9079
  %9082 = shufflevector <16 x i8> %8783, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9083 = bitcast <16 x i8> %9082 to <8 x i16>
  %9084 = add <8 x i16> %9081, %9083
  %9085 = shl <8 x i16> %9084, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9086 = getelementptr inbounds i16, i16* %7998, i64 %8056
  %9087 = bitcast i16* %9086 to <8 x i16>*
  store <8 x i16> %9085, <8 x i16>* %9087, align 16
  %9088 = mul <8 x i16> %9084, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %9089 = add <8 x i16> %9088, %9080
  %9090 = getelementptr inbounds i16, i16* %7997, i64 %8056
  %9091 = bitcast i16* %9090 to <8 x i16>*
  store <8 x i16> %9089, <8 x i16>* %9091, align 16
  %9092 = bitcast <4 x i32> %8649 to <16 x i8>
  %9093 = shufflevector <16 x i8> %8856, <16 x i8> %9092, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9094 = shufflevector <16 x i8> %8856, <16 x i8> %9092, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9095 = bitcast <16 x i8> %9094 to <4 x i32>
  %9096 = bitcast <16 x i8> %9093 to <4 x i32>
  %9097 = add <4 x i32> %8647, %9096
  %9098 = add <4 x i32> %9097, %9095
  %9099 = shl <4 x i32> %9098, <i32 2, i32 2, i32 2, i32 2>
  %9100 = mul <4 x i32> %9098, <i32 3, i32 3, i32 3, i32 3>
  %9101 = add <4 x i32> %9100, %9096
  %9102 = bitcast <4 x i32> %8660 to <16 x i8>
  %9103 = shufflevector <16 x i8> %9092, <16 x i8> %9102, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9104 = shufflevector <16 x i8> %9092, <16 x i8> %9102, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9105 = bitcast <16 x i8> %9104 to <4 x i32>
  %9106 = bitcast <16 x i8> %9103 to <4 x i32>
  %9107 = add <4 x i32> %8649, %9106
  %9108 = add <4 x i32> %9107, %9105
  %9109 = shl <4 x i32> %9108, <i32 2, i32 2, i32 2, i32 2>
  %9110 = mul <4 x i32> %9108, <i32 3, i32 3, i32 3, i32 3>
  %9111 = add <4 x i32> %9110, %9106
  %9112 = getelementptr inbounds i32, i32* %8000, i64 %8056
  %9113 = bitcast i32* %9112 to <4 x i32>*
  store <4 x i32> %9099, <4 x i32>* %9113, align 16
  %9114 = getelementptr inbounds i32, i32* %9112, i64 4
  %9115 = bitcast i32* %9114 to <4 x i32>*
  store <4 x i32> %9109, <4 x i32>* %9115, align 16
  %9116 = getelementptr inbounds i32, i32* %7999, i64 %8056
  %9117 = bitcast i32* %9116 to <4 x i32>*
  store <4 x i32> %9101, <4 x i32>* %9117, align 16
  %9118 = getelementptr inbounds i32, i32* %9116, i64 4
  %9119 = bitcast i32* %9118 to <4 x i32>*
  store <4 x i32> %9111, <4 x i32>* %9119, align 16
  %9120 = shufflevector <16 x i8> %8784, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9121 = bitcast <16 x i8> %8381 to <8 x i16>
  %9122 = bitcast <16 x i8> %9120 to <8 x i16>
  %9123 = add <8 x i16> %9122, %9121
  %9124 = shufflevector <16 x i8> %8785, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9125 = bitcast <16 x i8> %9124 to <8 x i16>
  %9126 = add <8 x i16> %9123, %9125
  %9127 = mul <8 x i16> %9126, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %9128 = add <8 x i16> %9127, %9122
  %9129 = getelementptr inbounds i16, i16* %7974, i64 %8014
  %9130 = bitcast i16* %9129 to <8 x i16>*
  store <8 x i16> %9128, <8 x i16>* %9130, align 16
  %9131 = bitcast <4 x i32> %8392 to <16 x i8>
  %9132 = shufflevector <16 x i8> %8896, <16 x i8> %9131, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9133 = bitcast <16 x i8> %9132 to <4 x i32>
  %9134 = shufflevector <16 x i8> %8896, <16 x i8> %9131, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9135 = bitcast <16 x i8> %9134 to <4 x i32>
  %9136 = add <4 x i32> %8390, %9133
  %9137 = add <4 x i32> %9136, %9135
  %9138 = mul <4 x i32> %9137, <i32 5, i32 5, i32 5, i32 5>
  %9139 = add <4 x i32> %9138, %9133
  %9140 = bitcast <4 x i32> %8777 to <16 x i8>
  %9141 = shufflevector <16 x i8> %9131, <16 x i8> %9140, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9142 = bitcast <16 x i8> %9141 to <4 x i32>
  %9143 = shufflevector <16 x i8> %9131, <16 x i8> %9140, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9144 = bitcast <16 x i8> %9143 to <4 x i32>
  %9145 = add <4 x i32> %8392, %9142
  %9146 = add <4 x i32> %9145, %9144
  %9147 = mul <4 x i32> %9146, <i32 5, i32 5, i32 5, i32 5>
  %9148 = add <4 x i32> %9147, %9142
  %9149 = getelementptr inbounds i32, i32* %7975, i64 %8014
  %9150 = bitcast i32* %9149 to <4 x i32>*
  store <4 x i32> %9139, <4 x i32>* %9150, align 16
  %9151 = getelementptr inbounds i32, i32* %9149, i64 4
  %9152 = bitcast i32* %9151 to <4 x i32>*
  store <4 x i32> %9148, <4 x i32>* %9152, align 16
  %9153 = getelementptr inbounds i16, i16* %8909, i64 8
  %9154 = bitcast i16* %9153 to <8 x i16>*
  %9155 = load <8 x i16>, <8 x i16>* %9154, align 16
  %9156 = getelementptr inbounds i16, i16* %8912, i64 8
  %9157 = bitcast i16* %9156 to <8 x i16>*
  %9158 = load <8 x i16>, <8 x i16>* %9157, align 16
  %9159 = getelementptr inbounds i16, i16* %7976, i64 %8014
  %9160 = bitcast i16* %9159 to <8 x i16>*
  %9161 = load <8 x i16>, <8 x i16>* %9160, align 16
  %9162 = getelementptr inbounds i32, i32* %7977, i64 %8014
  %9163 = bitcast i32* %9162 to <4 x i32>*
  %9164 = load <4 x i32>, <4 x i32>* %9163, align 16
  %9165 = getelementptr inbounds i32, i32* %9162, i64 4
  %9166 = bitcast i32* %9165 to <4 x i32>*
  %9167 = load <4 x i32>, <4 x i32>* %9166, align 16
  %9168 = add <8 x i16> %9161, %9128
  %9169 = shufflevector <8 x i16> %9168, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9170 = shufflevector <8 x i16> %9155, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9171 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9169, <8 x i16> %9170) #5
  %9172 = shufflevector <8 x i16> %9168, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9173 = shufflevector <8 x i16> %9155, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9174 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9172, <8 x i16> %9173) #5
  %9175 = add <4 x i32> %9139, <i32 256, i32 256, i32 256, i32 256>
  %9176 = add <4 x i32> %9175, %9164
  %9177 = sub <4 x i32> %9176, %9171
  %9178 = ashr <4 x i32> %9177, <i32 9, i32 9, i32 9, i32 9>
  %9179 = add <4 x i32> %9148, <i32 256, i32 256, i32 256, i32 256>
  %9180 = add <4 x i32> %9179, %9167
  %9181 = sub <4 x i32> %9180, %9174
  %9182 = ashr <4 x i32> %9181, <i32 9, i32 9, i32 9, i32 9>
  %9183 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9178, <4 x i32> %9182) #5
  %9184 = shufflevector <8 x i16> %9128, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9185 = shufflevector <8 x i16> %9158, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9186 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9184, <8 x i16> %9185) #5
  %9187 = shufflevector <8 x i16> %9128, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9188 = shufflevector <8 x i16> %9158, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9189 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9187, <8 x i16> %9188) #5
  %9190 = add <4 x i32> %9139, <i32 128, i32 128, i32 128, i32 128>
  %9191 = sub <4 x i32> %9190, %9186
  %9192 = ashr <4 x i32> %9191, <i32 8, i32 8, i32 8, i32 8>
  %9193 = add <4 x i32> %9148, <i32 128, i32 128, i32 128, i32 128>
  %9194 = sub <4 x i32> %9193, %9189
  %9195 = ashr <4 x i32> %9194, <i32 8, i32 8, i32 8, i32 8>
  %9196 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9192, <4 x i32> %9195) #5
  %9197 = getelementptr inbounds i16, i16* %8007, i64 %8014
  %9198 = bitcast i16* %9197 to <8 x i16>*
  %9199 = load <8 x i16>, <8 x i16>* %9198, align 16
  %9200 = getelementptr inbounds i16, i16* %8008, i64 %8014
  %9201 = bitcast i16* %9200 to <8 x i16>*
  %9202 = load <8 x i16>, <8 x i16>* %9201, align 16
  %9203 = getelementptr inbounds i32, i32* %8009, i64 %8014
  %9204 = bitcast i32* %9203 to <4 x i32>*
  %9205 = load <4 x i32>, <4 x i32>* %9204, align 16
  %9206 = getelementptr inbounds i32, i32* %9203, i64 4
  %9207 = bitcast i32* %9206 to <4 x i32>*
  %9208 = load <4 x i32>, <4 x i32>* %9207, align 16
  %9209 = getelementptr inbounds i32, i32* %8010, i64 %8014
  %9210 = bitcast i32* %9209 to <4 x i32>*
  %9211 = load <4 x i32>, <4 x i32>* %9210, align 16
  %9212 = getelementptr inbounds i32, i32* %9209, i64 4
  %9213 = bitcast i32* %9212 to <4 x i32>*
  %9214 = load <4 x i32>, <4 x i32>* %9213, align 16
  %9215 = add <8 x i16> %9199, %9046
  %9216 = add <8 x i16> %9215, %9202
  %9217 = shufflevector <8 x i16> %9216, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9218 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9217, <8 x i16> %9170) #5
  %9219 = shufflevector <8 x i16> %9216, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9220 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9219, <8 x i16> %9173) #5
  %9221 = add <4 x i32> %9058, <i32 256, i32 256, i32 256, i32 256>
  %9222 = add <4 x i32> %9221, %9205
  %9223 = add <4 x i32> %9222, %9211
  %9224 = sub <4 x i32> %9223, %9218
  %9225 = ashr <4 x i32> %9224, <i32 9, i32 9, i32 9, i32 9>
  %9226 = add <4 x i32> %9068, <i32 256, i32 256, i32 256, i32 256>
  %9227 = add <4 x i32> %9226, %9208
  %9228 = add <4 x i32> %9227, %9214
  %9229 = sub <4 x i32> %9228, %9220
  %9230 = ashr <4 x i32> %9229, <i32 9, i32 9, i32 9, i32 9>
  %9231 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9225, <4 x i32> %9230) #5
  %9232 = shufflevector <8 x i16> %9183, <8 x i16> %9231, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9233 = shufflevector <8 x i16> %9183, <8 x i16> %9231, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9234 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %9232) #5
  %9235 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %9233) #5
  %9236 = add <4 x i32> %9234, <i32 1024, i32 1024, i32 1024, i32 1024>
  %9237 = ashr <4 x i32> %9236, <i32 11, i32 11, i32 11, i32 11>
  %9238 = add <4 x i32> %9235, <i32 1024, i32 1024, i32 1024, i32 1024>
  %9239 = ashr <4 x i32> %9238, <i32 11, i32 11, i32 11, i32 11>
  %9240 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9237, <4 x i32> %9239) #5
  %9241 = add <8 x i16> %9240, %9155
  %9242 = getelementptr inbounds i16, i16* %7566, i64 %8014
  %9243 = icmp sgt <8 x i16> %8997, zeroinitializer
  %9244 = select <8 x i1> %9243, <8 x i16> %8997, <8 x i16> zeroinitializer
  %9245 = icmp slt <8 x i16> %9244, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %9246 = select <8 x i1> %9245, <8 x i16> %9244, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %9247 = bitcast i16* %9242 to <8 x i16>*
  store <8 x i16> %9246, <8 x i16>* %9247, align 16
  %9248 = getelementptr inbounds i16, i16* %9242, i64 8
  %9249 = icmp sgt <8 x i16> %9241, zeroinitializer
  %9250 = select <8 x i1> %9249, <8 x i16> %9241, <8 x i16> zeroinitializer
  %9251 = icmp slt <8 x i16> %9250, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %9252 = select <8 x i1> %9251, <8 x i16> %9250, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %9253 = bitcast i16* %9248 to <8 x i16>*
  store <8 x i16> %9252, <8 x i16>* %9253, align 16
  %9254 = getelementptr inbounds i16, i16* %8011, i64 %8014
  %9255 = bitcast i16* %9254 to <8 x i16>*
  %9256 = load <8 x i16>, <8 x i16>* %9255, align 16
  %9257 = getelementptr inbounds i32, i32* %8012, i64 %8014
  %9258 = bitcast i32* %9257 to <4 x i32>*
  %9259 = load <4 x i32>, <4 x i32>* %9258, align 16
  %9260 = getelementptr inbounds i32, i32* %9257, i64 4
  %9261 = bitcast i32* %9260 to <4 x i32>*
  %9262 = load <4 x i32>, <4 x i32>* %9261, align 16
  %9263 = add <8 x i16> %9089, %9042
  %9264 = add <8 x i16> %9263, %9256
  %9265 = shufflevector <8 x i16> %9264, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9266 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9265, <8 x i16> %9185) #5
  %9267 = shufflevector <8 x i16> %9264, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9268 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9267, <8 x i16> %9188) #5
  %9269 = add <4 x i32> %9056, <i32 256, i32 256, i32 256, i32 256>
  %9270 = add <4 x i32> %9269, %9101
  %9271 = add <4 x i32> %9270, %9259
  %9272 = sub <4 x i32> %9271, %9266
  %9273 = ashr <4 x i32> %9272, <i32 9, i32 9, i32 9, i32 9>
  %9274 = add <4 x i32> %9066, <i32 256, i32 256, i32 256, i32 256>
  %9275 = add <4 x i32> %9274, %9111
  %9276 = add <4 x i32> %9275, %9262
  %9277 = sub <4 x i32> %9276, %9268
  %9278 = ashr <4 x i32> %9277, <i32 9, i32 9, i32 9, i32 9>
  %9279 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9273, <4 x i32> %9278) #5
  %9280 = shufflevector <8 x i16> %9196, <8 x i16> %9279, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9281 = shufflevector <8 x i16> %9196, <8 x i16> %9279, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9282 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %9280) #5
  %9283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %9281) #5
  %9284 = add <4 x i32> %9282, <i32 1024, i32 1024, i32 1024, i32 1024>
  %9285 = ashr <4 x i32> %9284, <i32 11, i32 11, i32 11, i32 11>
  %9286 = add <4 x i32> %9283, <i32 1024, i32 1024, i32 1024, i32 1024>
  %9287 = ashr <4 x i32> %9286, <i32 11, i32 11, i32 11, i32 11>
  %9288 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9285, <4 x i32> %9287) #5
  %9289 = add <8 x i16> %9288, %9158
  %9290 = getelementptr inbounds i16, i16* %7969, i64 %8014
  %9291 = icmp sgt <8 x i16> %9033, zeroinitializer
  %9292 = select <8 x i1> %9291, <8 x i16> %9033, <8 x i16> zeroinitializer
  %9293 = icmp slt <8 x i16> %9292, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %9294 = select <8 x i1> %9293, <8 x i16> %9292, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %9295 = bitcast i16* %9290 to <8 x i16>*
  store <8 x i16> %9294, <8 x i16>* %9295, align 16
  %9296 = getelementptr inbounds i16, i16* %9290, i64 8
  %9297 = icmp sgt <8 x i16> %9289, zeroinitializer
  %9298 = select <8 x i1> %9297, <8 x i16> %9289, <8 x i16> zeroinitializer
  %9299 = icmp slt <8 x i16> %9298, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %9300 = select <8 x i1> %9299, <8 x i16> %9298, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %9301 = bitcast i16* %9296 to <8 x i16>*
  store <8 x i16> %9300, <8 x i16>* %9301, align 16
  %9302 = icmp slt i64 %8043, %5918
  br i1 %9302, label %8013, label %9303

9303:                                             ; preds = %8013
  %9304 = getelementptr inbounds i16, i16* %7566, i64 %7506
  %9305 = add nsw i32 %7564, -1
  %9306 = icmp sgt i32 %9305, 0
  br i1 %9306, label %7563, label %7518

9307:                                             ; preds = %7523
  %9308 = inttoptr i64 %7527 to <8 x i16>*
  %9309 = getelementptr inbounds i16, i16* %6113, i64 %6
  %9310 = getelementptr inbounds i16, i16* %7559, i64 %7506
  %9311 = select i1 %7561, i16* %9309, i16* %6113
  %9312 = select i1 %7561, i16* %6113, i16* %9310
  %9313 = getelementptr inbounds i16, i16* %7559, i64 3
  %9314 = bitcast i16* %9312 to <8 x i16>*
  %9315 = load <8 x i16>, <8 x i16>* %9314, align 1
  %9316 = getelementptr inbounds i16, i16* %9312, i64 8
  %9317 = bitcast i16* %9316 to <2 x i64>*
  %9318 = load <2 x i64>, <2 x i64>* %9317, align 1
  %9319 = bitcast i16* %9311 to <8 x i16>*
  %9320 = load <8 x i16>, <8 x i16>* %9319, align 1
  %9321 = getelementptr inbounds i16, i16* %9311, i64 8
  %9322 = bitcast i16* %9321 to <2 x i64>*
  %9323 = load <2 x i64>, <2 x i64>* %9322, align 1
  %9324 = shufflevector <8 x i16> %9315, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9325 = shufflevector <8 x i16> %9315, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9326 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9324, <8 x i16> %9324) #5
  %9327 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9325, <8 x i16> %9325) #5
  %9328 = shufflevector <8 x i16> %9320, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9329 = shufflevector <8 x i16> %9320, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9330 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9328, <8 x i16> %9328) #5
  %9331 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9329, <8 x i16> %9329) #5
  %9332 = bitcast <2 x i64> %9318 to <8 x i16>
  %9333 = shufflevector <8 x i16> %9332, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9334 = shufflevector <8 x i16> %9332, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9335 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9333, <8 x i16> %9333) #5
  %9336 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9334, <8 x i16> %9334) #5
  %9337 = bitcast <2 x i64> %9323 to <8 x i16>
  %9338 = shufflevector <8 x i16> %9337, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9339 = shufflevector <8 x i16> %9337, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9340 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9338, <8 x i16> %9338) #5
  %9341 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9339, <8 x i16> %9339) #5
  %9342 = bitcast <2 x i64> %9318 to <16 x i8>
  %9343 = bitcast <8 x i16> %9315 to <16 x i8>
  %9344 = shufflevector <16 x i8> %9343, <16 x i8> %9342, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %9345 = bitcast <16 x i8> %9344 to <8 x i16>
  %9346 = shufflevector <16 x i8> %9343, <16 x i8> %9342, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9347 = bitcast <16 x i8> %9346 to <8 x i16>
  %9348 = shufflevector <16 x i8> %9343, <16 x i8> %9342, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %9349 = bitcast <16 x i8> %9348 to <8 x i16>
  %9350 = shufflevector <16 x i8> %9343, <16 x i8> %9342, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9351 = bitcast <16 x i8> %9350 to <8 x i16>
  %9352 = add <8 x i16> %9315, %9351
  %9353 = add <8 x i16> %9347, %9345
  %9354 = add <8 x i16> %9353, %9349
  %9355 = add <8 x i16> %9352, %9354
  %9356 = bitcast <2 x i64> %9323 to <16 x i8>
  %9357 = bitcast <8 x i16> %9320 to <16 x i8>
  %9358 = shufflevector <16 x i8> %9357, <16 x i8> %9356, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %9359 = bitcast <16 x i8> %9358 to <8 x i16>
  %9360 = shufflevector <16 x i8> %9357, <16 x i8> %9356, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9361 = bitcast <16 x i8> %9360 to <8 x i16>
  %9362 = shufflevector <16 x i8> %9357, <16 x i8> %9356, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %9363 = bitcast <16 x i8> %9362 to <8 x i16>
  %9364 = shufflevector <16 x i8> %9357, <16 x i8> %9356, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9365 = bitcast <16 x i8> %9364 to <8 x i16>
  %9366 = add <8 x i16> %9320, %9365
  %9367 = add <8 x i16> %9361, %9359
  %9368 = add <8 x i16> %9367, %9363
  %9369 = add <8 x i16> %9366, %9368
  store <8 x i16> %9354, <8 x i16>* %9308, align 16
  %9370 = inttoptr i64 %7526 to <8 x i16>*
  store <8 x i16> %9368, <8 x i16>* %9370, align 16
  %9371 = inttoptr i64 %7553 to <8 x i16>*
  store <8 x i16> %9355, <8 x i16>* %9371, align 16
  %9372 = inttoptr i64 %7547 to <8 x i16>*
  store <8 x i16> %9369, <8 x i16>* %9372, align 16
  %9373 = bitcast <4 x i32> %9327 to <16 x i8>
  %9374 = bitcast <4 x i32> %9326 to <16 x i8>
  %9375 = shufflevector <16 x i8> %9374, <16 x i8> %9373, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9376 = bitcast <16 x i8> %9375 to <4 x i32>
  %9377 = shufflevector <16 x i8> %9374, <16 x i8> %9373, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9378 = bitcast <16 x i8> %9377 to <4 x i32>
  %9379 = shufflevector <16 x i8> %9374, <16 x i8> %9373, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %9380 = bitcast <16 x i8> %9379 to <4 x i32>
  %9381 = add <4 x i32> %9327, %9326
  %9382 = add <4 x i32> %9378, %9376
  %9383 = add <4 x i32> %9382, %9380
  %9384 = add <4 x i32> %9381, %9383
  %9385 = bitcast <4 x i32> %9335 to <16 x i8>
  %9386 = shufflevector <16 x i8> %9373, <16 x i8> %9385, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9387 = bitcast <16 x i8> %9386 to <4 x i32>
  %9388 = shufflevector <16 x i8> %9373, <16 x i8> %9385, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9389 = bitcast <16 x i8> %9388 to <4 x i32>
  %9390 = shufflevector <16 x i8> %9373, <16 x i8> %9385, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %9391 = bitcast <16 x i8> %9390 to <4 x i32>
  %9392 = add <4 x i32> %9335, %9327
  %9393 = add <4 x i32> %9389, %9387
  %9394 = add <4 x i32> %9393, %9391
  %9395 = add <4 x i32> %9392, %9394
  %9396 = inttoptr i64 %7537 to i32*
  %9397 = inttoptr i64 %7537 to <4 x i32>*
  store <4 x i32> %9383, <4 x i32>* %9397, align 16
  %9398 = getelementptr inbounds i32, i32* %9396, i64 4
  %9399 = bitcast i32* %9398 to <4 x i32>*
  store <4 x i32> %9394, <4 x i32>* %9399, align 16
  %9400 = inttoptr i64 %7552 to i32*
  %9401 = inttoptr i64 %7552 to <4 x i32>*
  store <4 x i32> %9384, <4 x i32>* %9401, align 16
  %9402 = getelementptr inbounds i32, i32* %9400, i64 4
  %9403 = bitcast i32* %9402 to <4 x i32>*
  store <4 x i32> %9395, <4 x i32>* %9403, align 16
  %9404 = bitcast <4 x i32> %9331 to <16 x i8>
  %9405 = bitcast <4 x i32> %9330 to <16 x i8>
  %9406 = shufflevector <16 x i8> %9405, <16 x i8> %9404, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9407 = bitcast <16 x i8> %9406 to <4 x i32>
  %9408 = shufflevector <16 x i8> %9405, <16 x i8> %9404, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9409 = bitcast <16 x i8> %9408 to <4 x i32>
  %9410 = shufflevector <16 x i8> %9405, <16 x i8> %9404, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %9411 = bitcast <16 x i8> %9410 to <4 x i32>
  %9412 = add <4 x i32> %9331, %9330
  %9413 = add <4 x i32> %9409, %9407
  %9414 = add <4 x i32> %9413, %9411
  %9415 = add <4 x i32> %9412, %9414
  %9416 = bitcast <4 x i32> %9340 to <16 x i8>
  %9417 = shufflevector <16 x i8> %9404, <16 x i8> %9416, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9418 = bitcast <16 x i8> %9417 to <4 x i32>
  %9419 = shufflevector <16 x i8> %9404, <16 x i8> %9416, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9420 = bitcast <16 x i8> %9419 to <4 x i32>
  %9421 = shufflevector <16 x i8> %9404, <16 x i8> %9416, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %9422 = bitcast <16 x i8> %9421 to <4 x i32>
  %9423 = add <4 x i32> %9340, %9331
  %9424 = add <4 x i32> %9420, %9418
  %9425 = add <4 x i32> %9424, %9422
  %9426 = add <4 x i32> %9423, %9425
  %9427 = inttoptr i64 %7536 to i32*
  %9428 = inttoptr i64 %7536 to <4 x i32>*
  store <4 x i32> %9414, <4 x i32>* %9428, align 16
  %9429 = getelementptr inbounds i32, i32* %9427, i64 4
  %9430 = bitcast i32* %9429 to <4 x i32>*
  store <4 x i32> %9425, <4 x i32>* %9430, align 16
  %9431 = inttoptr i64 %7551 to i32*
  %9432 = inttoptr i64 %7551 to <4 x i32>*
  store <4 x i32> %9415, <4 x i32>* %9432, align 16
  %9433 = getelementptr inbounds i32, i32* %9431, i64 4
  %9434 = bitcast i32* %9433 to <4 x i32>*
  store <4 x i32> %9426, <4 x i32>* %9434, align 16
  %9435 = inttoptr i64 %7525 to <8 x i16>*
  %9436 = load <8 x i16>, <8 x i16>* %9435, align 16
  %9437 = inttoptr i64 %7524 to <8 x i16>*
  %9438 = load <8 x i16>, <8 x i16>* %9437, align 16
  %9439 = inttoptr i64 %7535 to i32*
  %9440 = inttoptr i64 %7535 to <4 x i32>*
  %9441 = load <4 x i32>, <4 x i32>* %9440, align 16
  %9442 = getelementptr inbounds i32, i32* %9439, i64 4
  %9443 = bitcast i32* %9442 to <4 x i32>*
  %9444 = load <4 x i32>, <4 x i32>* %9443, align 16
  %9445 = inttoptr i64 %7534 to i32*
  %9446 = inttoptr i64 %7534 to <4 x i32>*
  %9447 = load <4 x i32>, <4 x i32>* %9446, align 16
  %9448 = getelementptr inbounds i32, i32* %9445, i64 4
  %9449 = bitcast i32* %9448 to <4 x i32>*
  %9450 = load <4 x i32>, <4 x i32>* %9449, align 16
  %9451 = inttoptr i64 %7546 to <8 x i16>*
  %9452 = load <8 x i16>, <8 x i16>* %9451, align 16
  %9453 = inttoptr i64 %7545 to <8 x i16>*
  %9454 = load <8 x i16>, <8 x i16>* %9453, align 16
  %9455 = inttoptr i64 %7544 to <8 x i16>*
  %9456 = load <8 x i16>, <8 x i16>* %9455, align 16
  %9457 = inttoptr i64 %7550 to i32*
  %9458 = inttoptr i64 %7550 to <4 x i32>*
  %9459 = load <4 x i32>, <4 x i32>* %9458, align 16
  %9460 = getelementptr inbounds i32, i32* %9457, i64 4
  %9461 = bitcast i32* %9460 to <4 x i32>*
  %9462 = load <4 x i32>, <4 x i32>* %9461, align 16
  %9463 = inttoptr i64 %7549 to i32*
  %9464 = inttoptr i64 %7549 to <4 x i32>*
  %9465 = load <4 x i32>, <4 x i32>* %9464, align 16
  %9466 = getelementptr inbounds i32, i32* %9463, i64 4
  %9467 = bitcast i32* %9466 to <4 x i32>*
  %9468 = load <4 x i32>, <4 x i32>* %9467, align 16
  %9469 = inttoptr i64 %7548 to i32*
  %9470 = inttoptr i64 %7548 to <4 x i32>*
  %9471 = load <4 x i32>, <4 x i32>* %9470, align 16
  %9472 = getelementptr inbounds i32, i32* %9469, i64 4
  %9473 = bitcast i32* %9472 to <4 x i32>*
  %9474 = load <4 x i32>, <4 x i32>* %9473, align 16
  %9475 = add <8 x i16> %9438, %9354
  %9476 = add <8 x i16> %9475, %9436
  %9477 = add <8 x i16> %9476, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9478 = lshr <8 x i16> %9477, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9479 = shufflevector <8 x i16> %9478, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9480 = shufflevector <8 x i16> %9478, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9481 = add <4 x i32> %9383, <i32 8, i32 8, i32 8, i32 8>
  %9482 = add <4 x i32> %9481, %9447
  %9483 = add <4 x i32> %9482, %9441
  %9484 = lshr <4 x i32> %9483, <i32 4, i32 4, i32 4, i32 4>
  %9485 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9479, <8 x i16> %9479) #5
  %9486 = mul nuw <4 x i32> %9484, <i32 9, i32 9, i32 9, i32 9>
  %9487 = sub <4 x i32> %9486, %9485
  %9488 = icmp sgt <4 x i32> %9487, zeroinitializer
  %9489 = select <4 x i1> %9488, <4 x i32> %9487, <4 x i32> zeroinitializer
  %9490 = mul <4 x i32> %9489, %6317
  %9491 = add <4 x i32> %9490, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9492 = lshr <4 x i32> %9491, <i32 20, i32 20, i32 20, i32 20>
  %9493 = add <4 x i32> %9394, <i32 8, i32 8, i32 8, i32 8>
  %9494 = add <4 x i32> %9493, %9450
  %9495 = add <4 x i32> %9494, %9444
  %9496 = lshr <4 x i32> %9495, <i32 4, i32 4, i32 4, i32 4>
  %9497 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9480, <8 x i16> %9480) #5
  %9498 = mul nuw <4 x i32> %9496, <i32 9, i32 9, i32 9, i32 9>
  %9499 = sub <4 x i32> %9498, %9497
  %9500 = icmp sgt <4 x i32> %9499, zeroinitializer
  %9501 = select <4 x i1> %9500, <4 x i32> %9499, <4 x i32> zeroinitializer
  %9502 = mul <4 x i32> %9501, %6317
  %9503 = add <4 x i32> %9502, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9504 = lshr <4 x i32> %9503, <i32 20, i32 20, i32 20, i32 20>
  %9505 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %9492, <4 x i32> %9504) #5
  %9506 = add <8 x i16> %9475, %9368
  %9507 = add <8 x i16> %9506, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9508 = lshr <8 x i16> %9507, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9509 = shufflevector <8 x i16> %9508, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9510 = shufflevector <8 x i16> %9508, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9511 = add <4 x i32> %9482, %9414
  %9512 = lshr <4 x i32> %9511, <i32 4, i32 4, i32 4, i32 4>
  %9513 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9509, <8 x i16> %9509) #5
  %9514 = mul nuw <4 x i32> %9512, <i32 9, i32 9, i32 9, i32 9>
  %9515 = sub <4 x i32> %9514, %9513
  %9516 = icmp sgt <4 x i32> %9515, zeroinitializer
  %9517 = select <4 x i1> %9516, <4 x i32> %9515, <4 x i32> zeroinitializer
  %9518 = mul <4 x i32> %9517, %6317
  %9519 = add <4 x i32> %9518, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9520 = lshr <4 x i32> %9519, <i32 20, i32 20, i32 20, i32 20>
  %9521 = add <4 x i32> %9494, %9425
  %9522 = lshr <4 x i32> %9521, <i32 4, i32 4, i32 4, i32 4>
  %9523 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9510, <8 x i16> %9510) #5
  %9524 = mul nuw <4 x i32> %9522, <i32 9, i32 9, i32 9, i32 9>
  %9525 = sub <4 x i32> %9524, %9523
  %9526 = icmp sgt <4 x i32> %9525, zeroinitializer
  %9527 = select <4 x i1> %9526, <4 x i32> %9525, <4 x i32> zeroinitializer
  %9528 = mul <4 x i32> %9527, %6317
  %9529 = add <4 x i32> %9528, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9530 = lshr <4 x i32> %9529, <i32 20, i32 20, i32 20, i32 20>
  %9531 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %9520, <4 x i32> %9530) #5
  %9532 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %9505, <8 x i16> %9531) #5
  %9533 = icmp ult <16 x i8> %9532, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %9534 = select <16 x i1> %9533, <16 x i8> %9532, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %9535 = icmp sgt <16 x i8> %9534, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %9536 = select <16 x i1> %9535, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %9534
  %9537 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %9536) #5
  %9538 = add nsw <16 x i8> %9534, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %9539 = icmp sgt <16 x i8> %9538, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %9540 = select <16 x i1> %9539, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %9538
  %9541 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %9540) #5
  %9542 = or <16 x i8> %9541, %9537
  %9543 = add nsw <16 x i8> %9534, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %9544 = icmp sgt <16 x i8> %9543, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %9545 = select <16 x i1> %9544, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %9543
  %9546 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %9545) #5
  %9547 = or <16 x i8> %9542, %9546
  %9548 = xor <16 x i8> %9532, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %9549 = icmp ugt <16 x i8> %9547, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %9550 = select <16 x i1> %9549, <16 x i8> %9547, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %9551 = icmp sgt <16 x i8> %9548, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %9552 = icmp sgt <16 x i8> %9548, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %9553 = sext <16 x i1> %9552 to <16 x i8>
  %9554 = icmp sgt <16 x i8> %9548, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %9555 = icmp sgt <16 x i8> %9548, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %9556 = icmp eq <16 x i8> %9548, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %9557 = zext <16 x i1> %9551 to <16 x i8>
  %9558 = sub nsw <16 x i8> %9553, %9557
  %9559 = zext <16 x i1> %9554 to <16 x i8>
  %9560 = sub nsw <16 x i8> %9558, %9559
  %9561 = zext <16 x i1> %9555 to <16 x i8>
  %9562 = sub nsw <16 x i8> %9560, %9561
  %9563 = zext <16 x i1> %9556 to <16 x i8>
  %9564 = sub nsw <16 x i8> %9562, %9563
  %9565 = add <16 x i8> %9564, %9550
  %9566 = shufflevector <16 x i8> %9565, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %9567 = bitcast <16 x i8> %9566 to <8 x i16>
  %9568 = shufflevector <8 x i16> %9567, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9569 = shufflevector <8 x i16> %9476, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9570 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9568, <8 x i16> %9569) #5
  %9571 = shufflevector <8 x i16> %9567, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9572 = shufflevector <8 x i16> %9476, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9573 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9571, <8 x i16> %9572) #5
  %9574 = mul <4 x i32> %9570, <i32 455, i32 455, i32 455, i32 455>
  %9575 = add <4 x i32> %9574, <i32 2048, i32 2048, i32 2048, i32 2048>
  %9576 = lshr <4 x i32> %9575, <i32 12, i32 12, i32 12, i32 12>
  %9577 = shufflevector <16 x i8> %9565, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9578 = bitcast <16 x i8> %9577 to <8 x i16>
  %9579 = shufflevector <8 x i16> %9578, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9580 = shufflevector <8 x i16> %9506, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9581 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9579, <8 x i16> %9580) #5
  %9582 = shufflevector <8 x i16> %9578, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9583 = shufflevector <8 x i16> %9506, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9584 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9582, <8 x i16> %9583) #5
  %9585 = mul <4 x i32> %9581, <i32 455, i32 455, i32 455, i32 455>
  %9586 = add <4 x i32> %9585, <i32 2048, i32 2048, i32 2048, i32 2048>
  %9587 = lshr <4 x i32> %9586, <i32 12, i32 12, i32 12, i32 12>
  %9588 = shufflevector <16 x i8> %9565, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9589 = add <8 x i16> %9369, %9355
  %9590 = add <8 x i16> %9589, %9452
  %9591 = add <8 x i16> %9590, %9454
  %9592 = add <8 x i16> %9591, %9456
  %9593 = add <8 x i16> %9592, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9594 = lshr <8 x i16> %9593, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9595 = shufflevector <8 x i16> %9594, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9596 = shufflevector <8 x i16> %9594, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9597 = add <4 x i32> %9384, <i32 8, i32 8, i32 8, i32 8>
  %9598 = add <4 x i32> %9597, %9415
  %9599 = add <4 x i32> %9598, %9459
  %9600 = add <4 x i32> %9599, %9465
  %9601 = add <4 x i32> %9600, %9471
  %9602 = lshr <4 x i32> %9601, <i32 4, i32 4, i32 4, i32 4>
  %9603 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9595, <8 x i16> %9595) #5
  %9604 = mul <4 x i32> %9602, <i32 25, i32 25, i32 25, i32 25>
  %9605 = sub <4 x i32> %9604, %9603
  %9606 = icmp sgt <4 x i32> %9605, zeroinitializer
  %9607 = select <4 x i1> %9606, <4 x i32> %9605, <4 x i32> zeroinitializer
  %9608 = mul <4 x i32> %9607, %6442
  %9609 = add <4 x i32> %9608, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9610 = lshr <4 x i32> %9609, <i32 20, i32 20, i32 20, i32 20>
  %9611 = add <4 x i32> %9395, <i32 8, i32 8, i32 8, i32 8>
  %9612 = add <4 x i32> %9611, %9426
  %9613 = add <4 x i32> %9612, %9462
  %9614 = add <4 x i32> %9613, %9468
  %9615 = add <4 x i32> %9614, %9474
  %9616 = lshr <4 x i32> %9615, <i32 4, i32 4, i32 4, i32 4>
  %9617 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9596, <8 x i16> %9596) #5
  %9618 = mul <4 x i32> %9616, <i32 25, i32 25, i32 25, i32 25>
  %9619 = sub <4 x i32> %9618, %9617
  %9620 = icmp sgt <4 x i32> %9619, zeroinitializer
  %9621 = select <4 x i1> %9620, <4 x i32> %9619, <4 x i32> zeroinitializer
  %9622 = mul <4 x i32> %9621, %6442
  %9623 = add <4 x i32> %9622, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9624 = lshr <4 x i32> %9623, <i32 20, i32 20, i32 20, i32 20>
  %9625 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %9610, <4 x i32> %9624) #5
  %9626 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %9625, <8 x i16> undef) #5
  %9627 = bitcast <16 x i8> %9626 to <2 x i64>
  %9628 = extractelement <2 x i64> %9627, i32 0
  %9629 = lshr i64 %9628, 8
  %9630 = lshr i64 %9628, 16
  %9631 = lshr i64 %9628, 24
  %9632 = lshr i64 %9628, 32
  %9633 = lshr i64 %9628, 40
  %9634 = lshr i64 %9628, 48
  %9635 = lshr i64 %9628, 56
  %9636 = and i64 %9628, 255
  %9637 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %9636
  %9638 = load i8, i8* %9637, align 1
  %9639 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %9638, i64 0
  %9640 = and i64 %9629, 255
  %9641 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %9640
  %9642 = load i8, i8* %9641, align 1
  %9643 = insertelement <16 x i8> %9639, i8 %9642, i64 1
  %9644 = and i64 %9630, 255
  %9645 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %9644
  %9646 = load i8, i8* %9645, align 1
  %9647 = insertelement <16 x i8> %9643, i8 %9646, i64 2
  %9648 = and i64 %9631, 255
  %9649 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %9648
  %9650 = load i8, i8* %9649, align 1
  %9651 = insertelement <16 x i8> %9647, i8 %9650, i64 3
  %9652 = and i64 %9632, 255
  %9653 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %9652
  %9654 = load i8, i8* %9653, align 1
  %9655 = insertelement <16 x i8> %9651, i8 %9654, i64 4
  %9656 = and i64 %9633, 255
  %9657 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %9656
  %9658 = load i8, i8* %9657, align 1
  %9659 = insertelement <16 x i8> %9655, i8 %9658, i64 5
  %9660 = and i64 %9634, 255
  %9661 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %9660
  %9662 = load i8, i8* %9661, align 1
  %9663 = insertelement <16 x i8> %9659, i8 %9662, i64 6
  %9664 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %9635
  %9665 = load i8, i8* %9664, align 1
  %9666 = insertelement <16 x i8> %9663, i8 %9665, i64 7
  %9667 = shufflevector <16 x i8> %9666, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %9668 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %9667, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %9669 = shufflevector <8 x i16> %9668, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9670 = shufflevector <8 x i16> %9592, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9671 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9669, <8 x i16> %9670) #5
  %9672 = shufflevector <8 x i16> %9668, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9673 = shufflevector <8 x i16> %9592, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9674 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9672, <8 x i16> %9673) #5
  %9675 = add <4 x i32> %9671, <i32 512, i32 512, i32 512, i32 512>
  %9676 = lshr <4 x i32> %9675, <i32 10, i32 10, i32 10, i32 10>
  %9677 = getelementptr inbounds i16, i16* %9313, i64 %2
  %9678 = getelementptr inbounds i16, i16* %7558, i64 %2
  %9679 = inttoptr i64 %7554 to i16*
  %9680 = inttoptr i64 %7556 to i32*
  %9681 = inttoptr i64 %7555 to i16*
  %9682 = inttoptr i64 %7557 to i32*
  %9683 = getelementptr inbounds i16, i16* %9679, i64 8
  %9684 = getelementptr inbounds i32, i32* %9680, i64 8
  %9685 = getelementptr inbounds i16, i16* %9681, i64 8
  %9686 = getelementptr inbounds i32, i32* %9682, i64 8
  %9687 = inttoptr i64 %7527 to i16*
  %9688 = getelementptr inbounds i16, i16* %9687, i64 8
  %9689 = inttoptr i64 %7553 to i16*
  %9690 = getelementptr inbounds i16, i16* %9689, i64 8
  %9691 = inttoptr i64 %7526 to i16*
  %9692 = getelementptr inbounds i16, i16* %9691, i64 8
  %9693 = inttoptr i64 %7547 to i16*
  %9694 = getelementptr inbounds i16, i16* %9693, i64 8
  %9695 = inttoptr i64 %7525 to i16*
  %9696 = inttoptr i64 %7524 to i16*
  %9697 = inttoptr i64 %7546 to i16*
  %9698 = inttoptr i64 %7545 to i16*
  %9699 = inttoptr i64 %7544 to i16*
  %9700 = getelementptr inbounds i32, i32* %9396, i64 8
  %9701 = getelementptr inbounds i32, i32* %9400, i64 8
  %9702 = getelementptr inbounds i32, i32* %9427, i64 8
  %9703 = getelementptr inbounds i32, i32* %9431, i64 8
  %9704 = inttoptr i64 %7529 to i16*
  %9705 = inttoptr i64 %7539 to i32*
  %9706 = inttoptr i64 %7532 to i16*
  %9707 = inttoptr i64 %7542 to i32*
  %9708 = inttoptr i64 %7531 to i16*
  %9709 = inttoptr i64 %7533 to i16*
  %9710 = inttoptr i64 %7541 to i32*
  %9711 = inttoptr i64 %7543 to i32*
  %9712 = getelementptr inbounds i16, i16* %9708, i64 8
  %9713 = getelementptr inbounds i16, i16* %9709, i64 8
  %9714 = getelementptr inbounds i32, i32* %9710, i64 8
  %9715 = getelementptr inbounds i32, i32* %9711, i64 8
  %9716 = getelementptr inbounds i16, i16* %7530, i64 8
  %9717 = getelementptr inbounds i32, i32* %7540, i64 8
  br label %9718

9718:                                             ; preds = %9718, %9307
  %9719 = phi i64 [ %9748, %9718 ], [ 0, %9307 ]
  %9720 = phi <2 x i64> [ %9760, %9718 ], [ %9323, %9307 ]
  %9721 = phi <2 x i64> [ %9753, %9718 ], [ %9318, %9307 ]
  %9722 = phi <16 x i8> [ %10367, %9718 ], [ %9588, %9307 ]
  %9723 = phi <16 x i8> [ %10305, %9718 ], [ %9565, %9307 ]
  %9724 = phi <16 x i8> [ %10472, %9718 ], [ <i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, %9307 ]
  %9725 = phi <16 x i8> [ %10472, %9718 ], [ %9666, %9307 ]
  %9726 = phi <4 x i32> [ %10107, %9718 ], [ %9341, %9307 ]
  %9727 = phi <4 x i32> [ %10106, %9718 ], [ %9340, %9307 ]
  %9728 = phi <4 x i32> [ %10102, %9718 ], [ %9336, %9307 ]
  %9729 = phi <4 x i32> [ %10101, %9718 ], [ %9335, %9307 ]
  %9730 = phi <4 x i32> [ %10362, %9718 ], [ %9584, %9307 ]
  %9731 = phi <4 x i32> [ %10365, %9718 ], [ %9587, %9307 ]
  %9732 = phi <4 x i32> [ %10300, %9718 ], [ %9573, %9307 ]
  %9733 = phi <4 x i32> [ %10303, %9718 ], [ %9576, %9307 ]
  %9734 = phi <4 x i32> [ %10480, %9718 ], [ %9674, %9307 ]
  %9735 = phi <4 x i32> [ %10482, %9718 ], [ %9676, %9307 ]
  %9736 = add <4 x i32> %9734, <i32 512, i32 512, i32 512, i32 512>
  %9737 = lshr <4 x i32> %9736, <i32 10, i32 10, i32 10, i32 10>
  %9738 = mul <4 x i32> %9730, <i32 455, i32 455, i32 455, i32 455>
  %9739 = add <4 x i32> %9738, <i32 2048, i32 2048, i32 2048, i32 2048>
  %9740 = lshr <4 x i32> %9739, <i32 12, i32 12, i32 12, i32 12>
  %9741 = mul <4 x i32> %9732, <i32 455, i32 455, i32 455, i32 455>
  %9742 = add <4 x i32> %9741, <i32 2048, i32 2048, i32 2048, i32 2048>
  %9743 = lshr <4 x i32> %9742, <i32 12, i32 12, i32 12, i32 12>
  %9744 = bitcast <16 x i8> %9723 to <2 x i64>
  %9745 = bitcast <16 x i8> %9722 to <2 x i64>
  %9746 = getelementptr inbounds i16, i16* %9312, i64 %9719
  %9747 = getelementptr inbounds i16, i16* %9746, i64 16
  %9748 = add nuw nsw i64 %9719, 16
  %9749 = bitcast i16* %9747 to <2 x i64>*
  %9750 = load <2 x i64>, <2 x i64>* %9749, align 1
  %9751 = getelementptr inbounds i16, i16* %9746, i64 24
  %9752 = bitcast i16* %9751 to <2 x i64>*
  %9753 = load <2 x i64>, <2 x i64>* %9752, align 1
  %9754 = getelementptr inbounds i16, i16* %9311, i64 %9719
  %9755 = getelementptr inbounds i16, i16* %9754, i64 16
  %9756 = bitcast i16* %9755 to <2 x i64>*
  %9757 = load <2 x i64>, <2 x i64>* %9756, align 1
  %9758 = getelementptr inbounds i16, i16* %9754, i64 24
  %9759 = bitcast i16* %9758 to <2 x i64>*
  %9760 = load <2 x i64>, <2 x i64>* %9759, align 1
  %9761 = or i64 %9719, 8
  %9762 = bitcast <2 x i64> %9721 to <8 x i16>
  %9763 = bitcast <2 x i64> %9750 to <16 x i8>
  %9764 = bitcast <2 x i64> %9721 to <16 x i8>
  %9765 = shufflevector <16 x i8> %9764, <16 x i8> %9763, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %9766 = bitcast <16 x i8> %9765 to <8 x i16>
  %9767 = shufflevector <16 x i8> %9764, <16 x i8> %9763, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9768 = bitcast <16 x i8> %9767 to <8 x i16>
  %9769 = shufflevector <16 x i8> %9764, <16 x i8> %9763, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %9770 = bitcast <16 x i8> %9769 to <8 x i16>
  %9771 = shufflevector <16 x i8> %9764, <16 x i8> %9763, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9772 = bitcast <16 x i8> %9771 to <8 x i16>
  %9773 = add <8 x i16> %9772, %9762
  %9774 = add <8 x i16> %9768, %9766
  %9775 = add <8 x i16> %9774, %9770
  %9776 = add <8 x i16> %9773, %9775
  %9777 = bitcast <2 x i64> %9750 to <8 x i16>
  %9778 = bitcast <2 x i64> %9753 to <16 x i8>
  %9779 = shufflevector <16 x i8> %9763, <16 x i8> %9778, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %9780 = bitcast <16 x i8> %9779 to <8 x i16>
  %9781 = shufflevector <16 x i8> %9763, <16 x i8> %9778, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9782 = bitcast <16 x i8> %9781 to <8 x i16>
  %9783 = shufflevector <16 x i8> %9763, <16 x i8> %9778, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %9784 = bitcast <16 x i8> %9783 to <8 x i16>
  %9785 = shufflevector <16 x i8> %9763, <16 x i8> %9778, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9786 = bitcast <16 x i8> %9785 to <8 x i16>
  %9787 = add <8 x i16> %9786, %9777
  %9788 = add <8 x i16> %9782, %9780
  %9789 = add <8 x i16> %9788, %9784
  %9790 = add <8 x i16> %9787, %9789
  %9791 = getelementptr inbounds i16, i16* %9687, i64 %9761
  %9792 = bitcast i16* %9791 to <8 x i16>*
  store <8 x i16> %9775, <8 x i16>* %9792, align 16
  %9793 = getelementptr inbounds i16, i16* %9688, i64 %9761
  %9794 = bitcast i16* %9793 to <8 x i16>*
  store <8 x i16> %9789, <8 x i16>* %9794, align 16
  %9795 = getelementptr inbounds i16, i16* %9689, i64 %9761
  %9796 = bitcast i16* %9795 to <8 x i16>*
  store <8 x i16> %9776, <8 x i16>* %9796, align 16
  %9797 = getelementptr inbounds i16, i16* %9690, i64 %9761
  %9798 = bitcast i16* %9797 to <8 x i16>*
  store <8 x i16> %9790, <8 x i16>* %9798, align 16
  %9799 = bitcast <2 x i64> %9720 to <8 x i16>
  %9800 = bitcast <2 x i64> %9757 to <16 x i8>
  %9801 = bitcast <2 x i64> %9720 to <16 x i8>
  %9802 = shufflevector <16 x i8> %9801, <16 x i8> %9800, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %9803 = bitcast <16 x i8> %9802 to <8 x i16>
  %9804 = shufflevector <16 x i8> %9801, <16 x i8> %9800, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9805 = bitcast <16 x i8> %9804 to <8 x i16>
  %9806 = shufflevector <16 x i8> %9801, <16 x i8> %9800, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %9807 = bitcast <16 x i8> %9806 to <8 x i16>
  %9808 = shufflevector <16 x i8> %9801, <16 x i8> %9800, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9809 = bitcast <16 x i8> %9808 to <8 x i16>
  %9810 = add <8 x i16> %9809, %9799
  %9811 = add <8 x i16> %9805, %9803
  %9812 = add <8 x i16> %9811, %9807
  %9813 = add <8 x i16> %9810, %9812
  %9814 = bitcast <2 x i64> %9757 to <8 x i16>
  %9815 = bitcast <2 x i64> %9760 to <16 x i8>
  %9816 = shufflevector <16 x i8> %9800, <16 x i8> %9815, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %9817 = bitcast <16 x i8> %9816 to <8 x i16>
  %9818 = shufflevector <16 x i8> %9800, <16 x i8> %9815, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9819 = bitcast <16 x i8> %9818 to <8 x i16>
  %9820 = shufflevector <16 x i8> %9800, <16 x i8> %9815, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %9821 = bitcast <16 x i8> %9820 to <8 x i16>
  %9822 = shufflevector <16 x i8> %9800, <16 x i8> %9815, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9823 = bitcast <16 x i8> %9822 to <8 x i16>
  %9824 = add <8 x i16> %9823, %9814
  %9825 = add <8 x i16> %9819, %9817
  %9826 = add <8 x i16> %9825, %9821
  %9827 = add <8 x i16> %9824, %9826
  %9828 = getelementptr inbounds i16, i16* %9691, i64 %9761
  %9829 = bitcast i16* %9828 to <8 x i16>*
  store <8 x i16> %9812, <8 x i16>* %9829, align 16
  %9830 = getelementptr inbounds i16, i16* %9692, i64 %9761
  %9831 = bitcast i16* %9830 to <8 x i16>*
  store <8 x i16> %9826, <8 x i16>* %9831, align 16
  %9832 = getelementptr inbounds i16, i16* %9693, i64 %9761
  %9833 = bitcast i16* %9832 to <8 x i16>*
  store <8 x i16> %9813, <8 x i16>* %9833, align 16
  %9834 = getelementptr inbounds i16, i16* %9694, i64 %9761
  %9835 = bitcast i16* %9834 to <8 x i16>*
  store <8 x i16> %9827, <8 x i16>* %9835, align 16
  %9836 = shufflevector <8 x i16> %9777, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9837 = shufflevector <8 x i16> %9777, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9838 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9836, <8 x i16> %9836) #5
  %9839 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9837, <8 x i16> %9837) #5
  %9840 = shufflevector <8 x i16> %9814, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9841 = shufflevector <8 x i16> %9814, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9842 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9840, <8 x i16> %9840) #5
  %9843 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9841, <8 x i16> %9841) #5
  %9844 = bitcast <4 x i32> %9728 to <16 x i8>
  %9845 = bitcast <4 x i32> %9729 to <16 x i8>
  %9846 = shufflevector <16 x i8> %9845, <16 x i8> %9844, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9847 = bitcast <16 x i8> %9846 to <4 x i32>
  %9848 = shufflevector <16 x i8> %9845, <16 x i8> %9844, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9849 = bitcast <16 x i8> %9848 to <4 x i32>
  %9850 = shufflevector <16 x i8> %9845, <16 x i8> %9844, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %9851 = bitcast <16 x i8> %9850 to <4 x i32>
  %9852 = add <4 x i32> %9729, %9728
  %9853 = add <4 x i32> %9849, %9847
  %9854 = add <4 x i32> %9853, %9851
  %9855 = add <4 x i32> %9852, %9854
  %9856 = bitcast <4 x i32> %9838 to <16 x i8>
  %9857 = shufflevector <16 x i8> %9844, <16 x i8> %9856, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9858 = bitcast <16 x i8> %9857 to <4 x i32>
  %9859 = shufflevector <16 x i8> %9844, <16 x i8> %9856, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9860 = bitcast <16 x i8> %9859 to <4 x i32>
  %9861 = shufflevector <16 x i8> %9844, <16 x i8> %9856, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %9862 = bitcast <16 x i8> %9861 to <4 x i32>
  %9863 = add <4 x i32> %9838, %9728
  %9864 = add <4 x i32> %9860, %9858
  %9865 = add <4 x i32> %9864, %9862
  %9866 = add <4 x i32> %9863, %9865
  %9867 = getelementptr inbounds i32, i32* %9396, i64 %9761
  %9868 = bitcast i32* %9867 to <4 x i32>*
  store <4 x i32> %9854, <4 x i32>* %9868, align 16
  %9869 = getelementptr inbounds i32, i32* %9867, i64 4
  %9870 = bitcast i32* %9869 to <4 x i32>*
  store <4 x i32> %9865, <4 x i32>* %9870, align 16
  %9871 = getelementptr inbounds i32, i32* %9400, i64 %9761
  %9872 = bitcast i32* %9871 to <4 x i32>*
  store <4 x i32> %9855, <4 x i32>* %9872, align 16
  %9873 = getelementptr inbounds i32, i32* %9871, i64 4
  %9874 = bitcast i32* %9873 to <4 x i32>*
  store <4 x i32> %9866, <4 x i32>* %9874, align 16
  %9875 = bitcast <4 x i32> %9726 to <16 x i8>
  %9876 = bitcast <4 x i32> %9727 to <16 x i8>
  %9877 = shufflevector <16 x i8> %9876, <16 x i8> %9875, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9878 = bitcast <16 x i8> %9877 to <4 x i32>
  %9879 = shufflevector <16 x i8> %9876, <16 x i8> %9875, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9880 = bitcast <16 x i8> %9879 to <4 x i32>
  %9881 = shufflevector <16 x i8> %9876, <16 x i8> %9875, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %9882 = bitcast <16 x i8> %9881 to <4 x i32>
  %9883 = add <4 x i32> %9727, %9726
  %9884 = add <4 x i32> %9880, %9878
  %9885 = add <4 x i32> %9884, %9882
  %9886 = add <4 x i32> %9883, %9885
  %9887 = bitcast <4 x i32> %9842 to <16 x i8>
  %9888 = shufflevector <16 x i8> %9875, <16 x i8> %9887, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %9889 = bitcast <16 x i8> %9888 to <4 x i32>
  %9890 = shufflevector <16 x i8> %9875, <16 x i8> %9887, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %9891 = bitcast <16 x i8> %9890 to <4 x i32>
  %9892 = shufflevector <16 x i8> %9875, <16 x i8> %9887, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %9893 = bitcast <16 x i8> %9892 to <4 x i32>
  %9894 = add <4 x i32> %9842, %9726
  %9895 = add <4 x i32> %9891, %9889
  %9896 = add <4 x i32> %9895, %9893
  %9897 = add <4 x i32> %9894, %9896
  %9898 = getelementptr inbounds i32, i32* %9427, i64 %9761
  %9899 = bitcast i32* %9898 to <4 x i32>*
  store <4 x i32> %9885, <4 x i32>* %9899, align 16
  %9900 = getelementptr inbounds i32, i32* %9898, i64 4
  %9901 = bitcast i32* %9900 to <4 x i32>*
  store <4 x i32> %9896, <4 x i32>* %9901, align 16
  %9902 = getelementptr inbounds i32, i32* %9431, i64 %9761
  %9903 = bitcast i32* %9902 to <4 x i32>*
  store <4 x i32> %9886, <4 x i32>* %9903, align 16
  %9904 = getelementptr inbounds i32, i32* %9902, i64 4
  %9905 = bitcast i32* %9904 to <4 x i32>*
  store <4 x i32> %9897, <4 x i32>* %9905, align 16
  %9906 = getelementptr inbounds i16, i16* %9695, i64 %9761
  %9907 = bitcast i16* %9906 to <8 x i16>*
  %9908 = load <8 x i16>, <8 x i16>* %9907, align 16
  %9909 = getelementptr inbounds i16, i16* %9696, i64 %9761
  %9910 = bitcast i16* %9909 to <8 x i16>*
  %9911 = load <8 x i16>, <8 x i16>* %9910, align 16
  %9912 = getelementptr inbounds i32, i32* %9439, i64 %9761
  %9913 = bitcast i32* %9912 to <4 x i32>*
  %9914 = load <4 x i32>, <4 x i32>* %9913, align 16
  %9915 = getelementptr inbounds i32, i32* %9912, i64 4
  %9916 = bitcast i32* %9915 to <4 x i32>*
  %9917 = load <4 x i32>, <4 x i32>* %9916, align 16
  %9918 = getelementptr inbounds i32, i32* %9445, i64 %9761
  %9919 = bitcast i32* %9918 to <4 x i32>*
  %9920 = load <4 x i32>, <4 x i32>* %9919, align 16
  %9921 = getelementptr inbounds i32, i32* %9918, i64 4
  %9922 = bitcast i32* %9921 to <4 x i32>*
  %9923 = load <4 x i32>, <4 x i32>* %9922, align 16
  %9924 = add <8 x i16> %9911, %9775
  %9925 = add <8 x i16> %9924, %9908
  %9926 = add <8 x i16> %9925, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9927 = lshr <8 x i16> %9926, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9928 = shufflevector <8 x i16> %9927, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9929 = shufflevector <8 x i16> %9927, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9930 = add <4 x i32> %9854, <i32 8, i32 8, i32 8, i32 8>
  %9931 = add <4 x i32> %9930, %9920
  %9932 = add <4 x i32> %9931, %9914
  %9933 = lshr <4 x i32> %9932, <i32 4, i32 4, i32 4, i32 4>
  %9934 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9928, <8 x i16> %9928) #5
  %9935 = mul nuw <4 x i32> %9933, <i32 9, i32 9, i32 9, i32 9>
  %9936 = sub <4 x i32> %9935, %9934
  %9937 = icmp sgt <4 x i32> %9936, zeroinitializer
  %9938 = select <4 x i1> %9937, <4 x i32> %9936, <4 x i32> zeroinitializer
  %9939 = mul <4 x i32> %9938, %6317
  %9940 = add <4 x i32> %9939, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9941 = lshr <4 x i32> %9940, <i32 20, i32 20, i32 20, i32 20>
  %9942 = add <4 x i32> %9865, <i32 8, i32 8, i32 8, i32 8>
  %9943 = add <4 x i32> %9942, %9923
  %9944 = add <4 x i32> %9943, %9917
  %9945 = lshr <4 x i32> %9944, <i32 4, i32 4, i32 4, i32 4>
  %9946 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9929, <8 x i16> %9929) #5
  %9947 = mul nuw <4 x i32> %9945, <i32 9, i32 9, i32 9, i32 9>
  %9948 = sub <4 x i32> %9947, %9946
  %9949 = icmp sgt <4 x i32> %9948, zeroinitializer
  %9950 = select <4 x i1> %9949, <4 x i32> %9948, <4 x i32> zeroinitializer
  %9951 = mul <4 x i32> %9950, %6317
  %9952 = add <4 x i32> %9951, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9953 = lshr <4 x i32> %9952, <i32 20, i32 20, i32 20, i32 20>
  %9954 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %9941, <4 x i32> %9953) #5
  %9955 = add <8 x i16> %9924, %9812
  %9956 = add <8 x i16> %9955, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9957 = lshr <8 x i16> %9956, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %9958 = shufflevector <8 x i16> %9957, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9959 = shufflevector <8 x i16> %9957, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9960 = add <4 x i32> %9931, %9885
  %9961 = lshr <4 x i32> %9960, <i32 4, i32 4, i32 4, i32 4>
  %9962 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9958, <8 x i16> %9958) #5
  %9963 = mul nuw <4 x i32> %9961, <i32 9, i32 9, i32 9, i32 9>
  %9964 = sub <4 x i32> %9963, %9962
  %9965 = icmp sgt <4 x i32> %9964, zeroinitializer
  %9966 = select <4 x i1> %9965, <4 x i32> %9964, <4 x i32> zeroinitializer
  %9967 = mul <4 x i32> %9966, %6317
  %9968 = add <4 x i32> %9967, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9969 = lshr <4 x i32> %9968, <i32 20, i32 20, i32 20, i32 20>
  %9970 = add <4 x i32> %9943, %9896
  %9971 = lshr <4 x i32> %9970, <i32 4, i32 4, i32 4, i32 4>
  %9972 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9959, <8 x i16> %9959) #5
  %9973 = mul nuw <4 x i32> %9971, <i32 9, i32 9, i32 9, i32 9>
  %9974 = sub <4 x i32> %9973, %9972
  %9975 = icmp sgt <4 x i32> %9974, zeroinitializer
  %9976 = select <4 x i1> %9975, <4 x i32> %9974, <4 x i32> zeroinitializer
  %9977 = mul <4 x i32> %9976, %6317
  %9978 = add <4 x i32> %9977, <i32 524288, i32 524288, i32 524288, i32 524288>
  %9979 = lshr <4 x i32> %9978, <i32 20, i32 20, i32 20, i32 20>
  %9980 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %9969, <4 x i32> %9979) #5
  %9981 = getelementptr inbounds i16, i16* %9697, i64 %9761
  %9982 = bitcast i16* %9981 to <8 x i16>*
  %9983 = load <8 x i16>, <8 x i16>* %9982, align 16
  %9984 = getelementptr inbounds i16, i16* %9698, i64 %9761
  %9985 = bitcast i16* %9984 to <8 x i16>*
  %9986 = load <8 x i16>, <8 x i16>* %9985, align 16
  %9987 = getelementptr inbounds i16, i16* %9699, i64 %9761
  %9988 = bitcast i16* %9987 to <8 x i16>*
  %9989 = load <8 x i16>, <8 x i16>* %9988, align 16
  %9990 = getelementptr inbounds i32, i32* %9457, i64 %9761
  %9991 = bitcast i32* %9990 to <4 x i32>*
  %9992 = load <4 x i32>, <4 x i32>* %9991, align 16
  %9993 = getelementptr inbounds i32, i32* %9990, i64 4
  %9994 = bitcast i32* %9993 to <4 x i32>*
  %9995 = load <4 x i32>, <4 x i32>* %9994, align 16
  %9996 = getelementptr inbounds i32, i32* %9463, i64 %9761
  %9997 = bitcast i32* %9996 to <4 x i32>*
  %9998 = load <4 x i32>, <4 x i32>* %9997, align 16
  %9999 = getelementptr inbounds i32, i32* %9996, i64 4
  %10000 = bitcast i32* %9999 to <4 x i32>*
  %10001 = load <4 x i32>, <4 x i32>* %10000, align 16
  %10002 = getelementptr inbounds i32, i32* %9469, i64 %9761
  %10003 = bitcast i32* %10002 to <4 x i32>*
  %10004 = load <4 x i32>, <4 x i32>* %10003, align 16
  %10005 = getelementptr inbounds i32, i32* %10002, i64 4
  %10006 = bitcast i32* %10005 to <4 x i32>*
  %10007 = load <4 x i32>, <4 x i32>* %10006, align 16
  %10008 = add <8 x i16> %9813, %9776
  %10009 = add <8 x i16> %10008, %9983
  %10010 = add <8 x i16> %10009, %9986
  %10011 = add <8 x i16> %10010, %9989
  %10012 = add <8 x i16> %10011, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10013 = lshr <8 x i16> %10012, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10014 = shufflevector <8 x i16> %10013, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10015 = shufflevector <8 x i16> %10013, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10016 = add <4 x i32> %9886, <i32 8, i32 8, i32 8, i32 8>
  %10017 = add <4 x i32> %10016, %9855
  %10018 = add <4 x i32> %10017, %9992
  %10019 = add <4 x i32> %10018, %9998
  %10020 = add <4 x i32> %10019, %10004
  %10021 = lshr <4 x i32> %10020, <i32 4, i32 4, i32 4, i32 4>
  %10022 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10014, <8 x i16> %10014) #5
  %10023 = mul <4 x i32> %10021, <i32 25, i32 25, i32 25, i32 25>
  %10024 = sub <4 x i32> %10023, %10022
  %10025 = icmp sgt <4 x i32> %10024, zeroinitializer
  %10026 = select <4 x i1> %10025, <4 x i32> %10024, <4 x i32> zeroinitializer
  %10027 = mul <4 x i32> %10026, %6442
  %10028 = add <4 x i32> %10027, <i32 524288, i32 524288, i32 524288, i32 524288>
  %10029 = lshr <4 x i32> %10028, <i32 20, i32 20, i32 20, i32 20>
  %10030 = add <4 x i32> %9866, <i32 8, i32 8, i32 8, i32 8>
  %10031 = add <4 x i32> %10030, %9897
  %10032 = add <4 x i32> %10031, %9995
  %10033 = add <4 x i32> %10032, %10001
  %10034 = add <4 x i32> %10033, %10007
  %10035 = lshr <4 x i32> %10034, <i32 4, i32 4, i32 4, i32 4>
  %10036 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10015, <8 x i16> %10015) #5
  %10037 = mul <4 x i32> %10035, <i32 25, i32 25, i32 25, i32 25>
  %10038 = sub <4 x i32> %10037, %10036
  %10039 = icmp sgt <4 x i32> %10038, zeroinitializer
  %10040 = select <4 x i1> %10039, <4 x i32> %10038, <4 x i32> zeroinitializer
  %10041 = mul <4 x i32> %10040, %6442
  %10042 = add <4 x i32> %10041, <i32 524288, i32 524288, i32 524288, i32 524288>
  %10043 = lshr <4 x i32> %10042, <i32 20, i32 20, i32 20, i32 20>
  %10044 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %10029, <4 x i32> %10043) #5
  %10045 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %10044, <8 x i16> undef) #5
  %10046 = bitcast <16 x i8> %10045 to <2 x i64>
  %10047 = extractelement <2 x i64> %10046, i32 0
  %10048 = lshr i64 %10047, 8
  %10049 = lshr i64 %10047, 16
  %10050 = lshr i64 %10047, 24
  %10051 = lshr i64 %10047, 32
  %10052 = lshr i64 %10047, 40
  %10053 = lshr i64 %10047, 48
  %10054 = lshr i64 %10047, 56
  %10055 = and i64 %10047, 255
  %10056 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10055
  %10057 = load i8, i8* %10056, align 1
  %10058 = insertelement <16 x i8> %9725, i8 %10057, i64 8
  %10059 = and i64 %10048, 255
  %10060 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10059
  %10061 = load i8, i8* %10060, align 1
  %10062 = insertelement <16 x i8> %10058, i8 %10061, i64 9
  %10063 = and i64 %10049, 255
  %10064 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10063
  %10065 = load i8, i8* %10064, align 1
  %10066 = insertelement <16 x i8> %10062, i8 %10065, i64 10
  %10067 = and i64 %10050, 255
  %10068 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10067
  %10069 = load i8, i8* %10068, align 1
  %10070 = insertelement <16 x i8> %10066, i8 %10069, i64 11
  %10071 = and i64 %10051, 255
  %10072 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10071
  %10073 = load i8, i8* %10072, align 1
  %10074 = insertelement <16 x i8> %10070, i8 %10073, i64 12
  %10075 = and i64 %10052, 255
  %10076 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10075
  %10077 = load i8, i8* %10076, align 1
  %10078 = insertelement <16 x i8> %10074, i8 %10077, i64 13
  %10079 = and i64 %10053, 255
  %10080 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10079
  %10081 = load i8, i8* %10080, align 1
  %10082 = insertelement <16 x i8> %10078, i8 %10081, i64 14
  %10083 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10054
  %10084 = load i8, i8* %10083, align 1
  %10085 = insertelement <16 x i8> %10082, i8 %10084, i64 15
  %10086 = shufflevector <16 x i8> %10085, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10087 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10086, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %10088 = shufflevector <8 x i16> %10087, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10089 = shufflevector <8 x i16> %10011, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10090 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10088, <8 x i16> %10089) #5
  %10091 = shufflevector <8 x i16> %10087, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10092 = shufflevector <8 x i16> %10011, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10093 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10091, <8 x i16> %10092) #5
  %10094 = add <4 x i32> %10090, <i32 512, i32 512, i32 512, i32 512>
  %10095 = lshr <4 x i32> %10094, <i32 10, i32 10, i32 10, i32 10>
  %10096 = add <4 x i32> %10093, <i32 512, i32 512, i32 512, i32 512>
  %10097 = lshr <4 x i32> %10096, <i32 10, i32 10, i32 10, i32 10>
  %10098 = bitcast <2 x i64> %9753 to <8 x i16>
  %10099 = shufflevector <8 x i16> %10098, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10100 = shufflevector <8 x i16> %10098, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10101 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10099, <8 x i16> %10099) #5
  %10102 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10100, <8 x i16> %10100) #5
  %10103 = bitcast <2 x i64> %9760 to <8 x i16>
  %10104 = shufflevector <8 x i16> %10103, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10105 = shufflevector <8 x i16> %10103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10106 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10104, <8 x i16> %10104) #5
  %10107 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10105, <8 x i16> %10105) #5
  %10108 = bitcast <4 x i32> %9839 to <16 x i8>
  %10109 = shufflevector <16 x i8> %9856, <16 x i8> %10108, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10110 = bitcast <16 x i8> %10109 to <4 x i32>
  %10111 = shufflevector <16 x i8> %9856, <16 x i8> %10108, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10112 = bitcast <16 x i8> %10111 to <4 x i32>
  %10113 = shufflevector <16 x i8> %9856, <16 x i8> %10108, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %10114 = bitcast <16 x i8> %10113 to <4 x i32>
  %10115 = add <4 x i32> %9839, %9838
  %10116 = add <4 x i32> %10112, %10110
  %10117 = add <4 x i32> %10116, %10114
  %10118 = add <4 x i32> %10115, %10117
  %10119 = bitcast <4 x i32> %10101 to <16 x i8>
  %10120 = shufflevector <16 x i8> %10108, <16 x i8> %10119, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10121 = bitcast <16 x i8> %10120 to <4 x i32>
  %10122 = shufflevector <16 x i8> %10108, <16 x i8> %10119, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10123 = bitcast <16 x i8> %10122 to <4 x i32>
  %10124 = shufflevector <16 x i8> %10108, <16 x i8> %10119, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %10125 = bitcast <16 x i8> %10124 to <4 x i32>
  %10126 = add <4 x i32> %10101, %9839
  %10127 = add <4 x i32> %10123, %10121
  %10128 = add <4 x i32> %10127, %10125
  %10129 = add <4 x i32> %10126, %10128
  %10130 = getelementptr inbounds i32, i32* %9700, i64 %9761
  %10131 = bitcast i32* %10130 to <4 x i32>*
  store <4 x i32> %10117, <4 x i32>* %10131, align 16
  %10132 = getelementptr inbounds i32, i32* %10130, i64 4
  %10133 = bitcast i32* %10132 to <4 x i32>*
  store <4 x i32> %10128, <4 x i32>* %10133, align 16
  %10134 = getelementptr inbounds i32, i32* %9701, i64 %9761
  %10135 = bitcast i32* %10134 to <4 x i32>*
  store <4 x i32> %10118, <4 x i32>* %10135, align 16
  %10136 = getelementptr inbounds i32, i32* %10134, i64 4
  %10137 = bitcast i32* %10136 to <4 x i32>*
  store <4 x i32> %10129, <4 x i32>* %10137, align 16
  %10138 = bitcast <4 x i32> %9843 to <16 x i8>
  %10139 = shufflevector <16 x i8> %9887, <16 x i8> %10138, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10140 = bitcast <16 x i8> %10139 to <4 x i32>
  %10141 = shufflevector <16 x i8> %9887, <16 x i8> %10138, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10142 = bitcast <16 x i8> %10141 to <4 x i32>
  %10143 = shufflevector <16 x i8> %9887, <16 x i8> %10138, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %10144 = bitcast <16 x i8> %10143 to <4 x i32>
  %10145 = add <4 x i32> %9843, %9842
  %10146 = add <4 x i32> %10142, %10140
  %10147 = add <4 x i32> %10146, %10144
  %10148 = add <4 x i32> %10145, %10147
  %10149 = bitcast <4 x i32> %10106 to <16 x i8>
  %10150 = shufflevector <16 x i8> %10138, <16 x i8> %10149, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10151 = bitcast <16 x i8> %10150 to <4 x i32>
  %10152 = shufflevector <16 x i8> %10138, <16 x i8> %10149, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10153 = bitcast <16 x i8> %10152 to <4 x i32>
  %10154 = shufflevector <16 x i8> %10138, <16 x i8> %10149, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %10155 = bitcast <16 x i8> %10154 to <4 x i32>
  %10156 = add <4 x i32> %10106, %9843
  %10157 = add <4 x i32> %10153, %10151
  %10158 = add <4 x i32> %10157, %10155
  %10159 = add <4 x i32> %10156, %10158
  %10160 = getelementptr inbounds i32, i32* %9702, i64 %9761
  %10161 = bitcast i32* %10160 to <4 x i32>*
  store <4 x i32> %10147, <4 x i32>* %10161, align 16
  %10162 = getelementptr inbounds i32, i32* %10160, i64 4
  %10163 = bitcast i32* %10162 to <4 x i32>*
  store <4 x i32> %10158, <4 x i32>* %10163, align 16
  %10164 = getelementptr inbounds i32, i32* %9703, i64 %9761
  %10165 = bitcast i32* %10164 to <4 x i32>*
  store <4 x i32> %10148, <4 x i32>* %10165, align 16
  %10166 = getelementptr inbounds i32, i32* %10164, i64 4
  %10167 = bitcast i32* %10166 to <4 x i32>*
  store <4 x i32> %10159, <4 x i32>* %10167, align 16
  %10168 = add nuw nsw i64 %9761, 8
  %10169 = getelementptr inbounds i16, i16* %9695, i64 %10168
  %10170 = bitcast i16* %10169 to <8 x i16>*
  %10171 = load <8 x i16>, <8 x i16>* %10170, align 16
  %10172 = getelementptr inbounds i16, i16* %9696, i64 %10168
  %10173 = bitcast i16* %10172 to <8 x i16>*
  %10174 = load <8 x i16>, <8 x i16>* %10173, align 16
  %10175 = getelementptr inbounds i32, i32* %9439, i64 %10168
  %10176 = bitcast i32* %10175 to <4 x i32>*
  %10177 = load <4 x i32>, <4 x i32>* %10176, align 16
  %10178 = getelementptr inbounds i32, i32* %10175, i64 4
  %10179 = bitcast i32* %10178 to <4 x i32>*
  %10180 = load <4 x i32>, <4 x i32>* %10179, align 16
  %10181 = getelementptr inbounds i32, i32* %9445, i64 %10168
  %10182 = bitcast i32* %10181 to <4 x i32>*
  %10183 = load <4 x i32>, <4 x i32>* %10182, align 16
  %10184 = getelementptr inbounds i32, i32* %10181, i64 4
  %10185 = bitcast i32* %10184 to <4 x i32>*
  %10186 = load <4 x i32>, <4 x i32>* %10185, align 16
  %10187 = add <8 x i16> %10174, %9789
  %10188 = add <8 x i16> %10187, %10171
  %10189 = add <8 x i16> %10188, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10190 = lshr <8 x i16> %10189, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10191 = shufflevector <8 x i16> %10190, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10192 = shufflevector <8 x i16> %10190, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10193 = add <4 x i32> %10117, <i32 8, i32 8, i32 8, i32 8>
  %10194 = add <4 x i32> %10193, %10183
  %10195 = add <4 x i32> %10194, %10177
  %10196 = lshr <4 x i32> %10195, <i32 4, i32 4, i32 4, i32 4>
  %10197 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10191, <8 x i16> %10191) #5
  %10198 = mul nuw <4 x i32> %10196, <i32 9, i32 9, i32 9, i32 9>
  %10199 = sub <4 x i32> %10198, %10197
  %10200 = icmp sgt <4 x i32> %10199, zeroinitializer
  %10201 = select <4 x i1> %10200, <4 x i32> %10199, <4 x i32> zeroinitializer
  %10202 = mul <4 x i32> %10201, %6317
  %10203 = add <4 x i32> %10202, <i32 524288, i32 524288, i32 524288, i32 524288>
  %10204 = lshr <4 x i32> %10203, <i32 20, i32 20, i32 20, i32 20>
  %10205 = add <4 x i32> %10128, <i32 8, i32 8, i32 8, i32 8>
  %10206 = add <4 x i32> %10205, %10186
  %10207 = add <4 x i32> %10206, %10180
  %10208 = lshr <4 x i32> %10207, <i32 4, i32 4, i32 4, i32 4>
  %10209 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10192, <8 x i16> %10192) #5
  %10210 = mul nuw <4 x i32> %10208, <i32 9, i32 9, i32 9, i32 9>
  %10211 = sub <4 x i32> %10210, %10209
  %10212 = icmp sgt <4 x i32> %10211, zeroinitializer
  %10213 = select <4 x i1> %10212, <4 x i32> %10211, <4 x i32> zeroinitializer
  %10214 = mul <4 x i32> %10213, %6317
  %10215 = add <4 x i32> %10214, <i32 524288, i32 524288, i32 524288, i32 524288>
  %10216 = lshr <4 x i32> %10215, <i32 20, i32 20, i32 20, i32 20>
  %10217 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %10204, <4 x i32> %10216) #5
  %10218 = add <8 x i16> %10187, %9826
  %10219 = add <8 x i16> %10218, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10220 = lshr <8 x i16> %10219, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10221 = shufflevector <8 x i16> %10220, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10222 = shufflevector <8 x i16> %10220, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10223 = add <4 x i32> %10194, %10147
  %10224 = lshr <4 x i32> %10223, <i32 4, i32 4, i32 4, i32 4>
  %10225 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10221, <8 x i16> %10221) #5
  %10226 = mul nuw <4 x i32> %10224, <i32 9, i32 9, i32 9, i32 9>
  %10227 = sub <4 x i32> %10226, %10225
  %10228 = icmp sgt <4 x i32> %10227, zeroinitializer
  %10229 = select <4 x i1> %10228, <4 x i32> %10227, <4 x i32> zeroinitializer
  %10230 = mul <4 x i32> %10229, %6317
  %10231 = add <4 x i32> %10230, <i32 524288, i32 524288, i32 524288, i32 524288>
  %10232 = lshr <4 x i32> %10231, <i32 20, i32 20, i32 20, i32 20>
  %10233 = add <4 x i32> %10206, %10158
  %10234 = lshr <4 x i32> %10233, <i32 4, i32 4, i32 4, i32 4>
  %10235 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10222, <8 x i16> %10222) #5
  %10236 = mul nuw <4 x i32> %10234, <i32 9, i32 9, i32 9, i32 9>
  %10237 = sub <4 x i32> %10236, %10235
  %10238 = icmp sgt <4 x i32> %10237, zeroinitializer
  %10239 = select <4 x i1> %10238, <4 x i32> %10237, <4 x i32> zeroinitializer
  %10240 = mul <4 x i32> %10239, %6317
  %10241 = add <4 x i32> %10240, <i32 524288, i32 524288, i32 524288, i32 524288>
  %10242 = lshr <4 x i32> %10241, <i32 20, i32 20, i32 20, i32 20>
  %10243 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %10232, <4 x i32> %10242) #5
  %10244 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %9954, <8 x i16> %10217) #5
  %10245 = icmp ult <16 x i8> %10244, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %10246 = select <16 x i1> %10245, <16 x i8> %10244, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %10247 = icmp sgt <16 x i8> %10246, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %10248 = select <16 x i1> %10247, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %10246
  %10249 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %10248) #5
  %10250 = add nsw <16 x i8> %10246, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %10251 = icmp sgt <16 x i8> %10250, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %10252 = select <16 x i1> %10251, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %10250
  %10253 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %10252) #5
  %10254 = or <16 x i8> %10253, %10249
  %10255 = add nsw <16 x i8> %10246, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %10256 = icmp sgt <16 x i8> %10255, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %10257 = select <16 x i1> %10256, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %10255
  %10258 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %10257) #5
  %10259 = or <16 x i8> %10254, %10258
  %10260 = xor <16 x i8> %10244, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %10261 = icmp ugt <16 x i8> %10259, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %10262 = select <16 x i1> %10261, <16 x i8> %10259, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %10263 = icmp sgt <16 x i8> %10260, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %10264 = icmp sgt <16 x i8> %10260, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %10265 = sext <16 x i1> %10264 to <16 x i8>
  %10266 = icmp sgt <16 x i8> %10260, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %10267 = icmp sgt <16 x i8> %10260, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %10268 = icmp eq <16 x i8> %10260, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %10269 = zext <16 x i1> %10263 to <16 x i8>
  %10270 = sub nsw <16 x i8> %10265, %10269
  %10271 = zext <16 x i1> %10266 to <16 x i8>
  %10272 = sub nsw <16 x i8> %10270, %10271
  %10273 = zext <16 x i1> %10267 to <16 x i8>
  %10274 = sub nsw <16 x i8> %10272, %10273
  %10275 = zext <16 x i1> %10268 to <16 x i8>
  %10276 = sub nsw <16 x i8> %10274, %10275
  %10277 = add <16 x i8> %10276, %10262
  %10278 = bitcast <16 x i8> %10277 to <2 x i64>
  %10279 = shufflevector <16 x i8> %10277, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10280 = bitcast <16 x i8> %10279 to <8 x i16>
  %10281 = shufflevector <8 x i16> %10280, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10282 = shufflevector <8 x i16> %9925, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10281, <8 x i16> %10282) #5
  %10284 = shufflevector <8 x i16> %10280, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10285 = shufflevector <8 x i16> %9925, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10286 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10284, <8 x i16> %10285) #5
  %10287 = mul <4 x i32> %10283, <i32 455, i32 455, i32 455, i32 455>
  %10288 = mul <4 x i32> %10286, <i32 455, i32 455, i32 455, i32 455>
  %10289 = add <4 x i32> %10287, <i32 2048, i32 2048, i32 2048, i32 2048>
  %10290 = lshr <4 x i32> %10289, <i32 12, i32 12, i32 12, i32 12>
  %10291 = add <4 x i32> %10288, <i32 2048, i32 2048, i32 2048, i32 2048>
  %10292 = lshr <4 x i32> %10291, <i32 12, i32 12, i32 12, i32 12>
  %10293 = shufflevector <16 x i8> %10277, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10294 = bitcast <16 x i8> %10293 to <8 x i16>
  %10295 = shufflevector <8 x i16> %10294, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10296 = shufflevector <8 x i16> %10188, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10297 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10295, <8 x i16> %10296) #5
  %10298 = shufflevector <8 x i16> %10294, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10299 = shufflevector <8 x i16> %10188, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10300 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10298, <8 x i16> %10299) #5
  %10301 = mul <4 x i32> %10297, <i32 455, i32 455, i32 455, i32 455>
  %10302 = add <4 x i32> %10301, <i32 2048, i32 2048, i32 2048, i32 2048>
  %10303 = lshr <4 x i32> %10302, <i32 12, i32 12, i32 12, i32 12>
  %10304 = shufflevector <2 x i64> %9744, <2 x i64> %10278, <2 x i32> <i32 0, i32 2>
  %10305 = shufflevector <16 x i8> %10277, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10306 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %9980, <8 x i16> %10243) #5
  %10307 = icmp ult <16 x i8> %10306, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %10308 = select <16 x i1> %10307, <16 x i8> %10306, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %10309 = icmp sgt <16 x i8> %10308, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %10310 = select <16 x i1> %10309, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %10308
  %10311 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %10310) #5
  %10312 = add nsw <16 x i8> %10308, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %10313 = icmp sgt <16 x i8> %10312, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %10314 = select <16 x i1> %10313, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %10312
  %10315 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %10314) #5
  %10316 = or <16 x i8> %10315, %10311
  %10317 = add nsw <16 x i8> %10308, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %10318 = icmp sgt <16 x i8> %10317, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %10319 = select <16 x i1> %10318, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %10317
  %10320 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %10319) #5
  %10321 = or <16 x i8> %10316, %10320
  %10322 = xor <16 x i8> %10306, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %10323 = icmp ugt <16 x i8> %10321, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %10324 = select <16 x i1> %10323, <16 x i8> %10321, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %10325 = icmp sgt <16 x i8> %10322, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %10326 = icmp sgt <16 x i8> %10322, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %10327 = sext <16 x i1> %10326 to <16 x i8>
  %10328 = icmp sgt <16 x i8> %10322, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %10329 = icmp sgt <16 x i8> %10322, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %10330 = icmp eq <16 x i8> %10322, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %10331 = zext <16 x i1> %10325 to <16 x i8>
  %10332 = sub nsw <16 x i8> %10327, %10331
  %10333 = zext <16 x i1> %10328 to <16 x i8>
  %10334 = sub nsw <16 x i8> %10332, %10333
  %10335 = zext <16 x i1> %10329 to <16 x i8>
  %10336 = sub nsw <16 x i8> %10334, %10335
  %10337 = zext <16 x i1> %10330 to <16 x i8>
  %10338 = sub nsw <16 x i8> %10336, %10337
  %10339 = add <16 x i8> %10338, %10324
  %10340 = bitcast <16 x i8> %10339 to <2 x i64>
  %10341 = shufflevector <16 x i8> %10339, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10342 = bitcast <16 x i8> %10341 to <8 x i16>
  %10343 = shufflevector <8 x i16> %10342, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10344 = shufflevector <8 x i16> %9955, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10345 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10343, <8 x i16> %10344) #5
  %10346 = shufflevector <8 x i16> %10342, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10347 = shufflevector <8 x i16> %9955, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10348 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10346, <8 x i16> %10347) #5
  %10349 = mul <4 x i32> %10345, <i32 455, i32 455, i32 455, i32 455>
  %10350 = mul <4 x i32> %10348, <i32 455, i32 455, i32 455, i32 455>
  %10351 = add <4 x i32> %10349, <i32 2048, i32 2048, i32 2048, i32 2048>
  %10352 = lshr <4 x i32> %10351, <i32 12, i32 12, i32 12, i32 12>
  %10353 = add <4 x i32> %10350, <i32 2048, i32 2048, i32 2048, i32 2048>
  %10354 = lshr <4 x i32> %10353, <i32 12, i32 12, i32 12, i32 12>
  %10355 = shufflevector <16 x i8> %10339, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10356 = bitcast <16 x i8> %10355 to <8 x i16>
  %10357 = shufflevector <8 x i16> %10356, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10358 = shufflevector <8 x i16> %10218, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10359 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10357, <8 x i16> %10358) #5
  %10360 = shufflevector <8 x i16> %10356, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10361 = shufflevector <8 x i16> %10218, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10362 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10360, <8 x i16> %10361) #5
  %10363 = mul <4 x i32> %10359, <i32 455, i32 455, i32 455, i32 455>
  %10364 = add <4 x i32> %10363, <i32 2048, i32 2048, i32 2048, i32 2048>
  %10365 = lshr <4 x i32> %10364, <i32 12, i32 12, i32 12, i32 12>
  %10366 = shufflevector <2 x i64> %9745, <2 x i64> %10340, <2 x i32> <i32 0, i32 2>
  %10367 = shufflevector <16 x i8> %10339, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10368 = getelementptr inbounds i16, i16* %9697, i64 %10168
  %10369 = bitcast i16* %10368 to <8 x i16>*
  %10370 = load <8 x i16>, <8 x i16>* %10369, align 16
  %10371 = getelementptr inbounds i16, i16* %9698, i64 %10168
  %10372 = bitcast i16* %10371 to <8 x i16>*
  %10373 = load <8 x i16>, <8 x i16>* %10372, align 16
  %10374 = getelementptr inbounds i16, i16* %9699, i64 %10168
  %10375 = bitcast i16* %10374 to <8 x i16>*
  %10376 = load <8 x i16>, <8 x i16>* %10375, align 16
  %10377 = getelementptr inbounds i32, i32* %9457, i64 %10168
  %10378 = bitcast i32* %10377 to <4 x i32>*
  %10379 = load <4 x i32>, <4 x i32>* %10378, align 16
  %10380 = getelementptr inbounds i32, i32* %10377, i64 4
  %10381 = bitcast i32* %10380 to <4 x i32>*
  %10382 = load <4 x i32>, <4 x i32>* %10381, align 16
  %10383 = getelementptr inbounds i32, i32* %9463, i64 %10168
  %10384 = bitcast i32* %10383 to <4 x i32>*
  %10385 = load <4 x i32>, <4 x i32>* %10384, align 16
  %10386 = getelementptr inbounds i32, i32* %10383, i64 4
  %10387 = bitcast i32* %10386 to <4 x i32>*
  %10388 = load <4 x i32>, <4 x i32>* %10387, align 16
  %10389 = getelementptr inbounds i32, i32* %9469, i64 %10168
  %10390 = bitcast i32* %10389 to <4 x i32>*
  %10391 = load <4 x i32>, <4 x i32>* %10390, align 16
  %10392 = getelementptr inbounds i32, i32* %10389, i64 4
  %10393 = bitcast i32* %10392 to <4 x i32>*
  %10394 = load <4 x i32>, <4 x i32>* %10393, align 16
  %10395 = add <8 x i16> %9827, %9790
  %10396 = add <8 x i16> %10395, %10370
  %10397 = add <8 x i16> %10396, %10373
  %10398 = add <8 x i16> %10397, %10376
  %10399 = add <8 x i16> %10398, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10400 = lshr <8 x i16> %10399, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10401 = shufflevector <8 x i16> %10400, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10402 = shufflevector <8 x i16> %10400, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10403 = add <4 x i32> %10118, <i32 8, i32 8, i32 8, i32 8>
  %10404 = add <4 x i32> %10403, %10148
  %10405 = add <4 x i32> %10404, %10379
  %10406 = add <4 x i32> %10405, %10385
  %10407 = add <4 x i32> %10406, %10391
  %10408 = lshr <4 x i32> %10407, <i32 4, i32 4, i32 4, i32 4>
  %10409 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10401, <8 x i16> %10401) #5
  %10410 = mul <4 x i32> %10408, <i32 25, i32 25, i32 25, i32 25>
  %10411 = sub <4 x i32> %10410, %10409
  %10412 = icmp sgt <4 x i32> %10411, zeroinitializer
  %10413 = select <4 x i1> %10412, <4 x i32> %10411, <4 x i32> zeroinitializer
  %10414 = mul <4 x i32> %10413, %6442
  %10415 = add <4 x i32> %10414, <i32 524288, i32 524288, i32 524288, i32 524288>
  %10416 = lshr <4 x i32> %10415, <i32 20, i32 20, i32 20, i32 20>
  %10417 = add <4 x i32> %10129, <i32 8, i32 8, i32 8, i32 8>
  %10418 = add <4 x i32> %10417, %10159
  %10419 = add <4 x i32> %10418, %10382
  %10420 = add <4 x i32> %10419, %10388
  %10421 = add <4 x i32> %10420, %10394
  %10422 = lshr <4 x i32> %10421, <i32 4, i32 4, i32 4, i32 4>
  %10423 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10402, <8 x i16> %10402) #5
  %10424 = mul <4 x i32> %10422, <i32 25, i32 25, i32 25, i32 25>
  %10425 = sub <4 x i32> %10424, %10423
  %10426 = icmp sgt <4 x i32> %10425, zeroinitializer
  %10427 = select <4 x i1> %10426, <4 x i32> %10425, <4 x i32> zeroinitializer
  %10428 = mul <4 x i32> %10427, %6442
  %10429 = add <4 x i32> %10428, <i32 524288, i32 524288, i32 524288, i32 524288>
  %10430 = lshr <4 x i32> %10429, <i32 20, i32 20, i32 20, i32 20>
  %10431 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %10416, <4 x i32> %10430) #5
  %10432 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %10431, <8 x i16> undef) #5
  %10433 = bitcast <16 x i8> %10432 to <2 x i64>
  %10434 = extractelement <2 x i64> %10433, i32 0
  %10435 = lshr i64 %10434, 8
  %10436 = lshr i64 %10434, 16
  %10437 = lshr i64 %10434, 24
  %10438 = lshr i64 %10434, 32
  %10439 = lshr i64 %10434, 40
  %10440 = lshr i64 %10434, 48
  %10441 = lshr i64 %10434, 56
  %10442 = and i64 %10434, 255
  %10443 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10442
  %10444 = load i8, i8* %10443, align 1
  %10445 = insertelement <16 x i8> %9724, i8 %10444, i64 0
  %10446 = and i64 %10435, 255
  %10447 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10446
  %10448 = load i8, i8* %10447, align 1
  %10449 = insertelement <16 x i8> %10445, i8 %10448, i64 1
  %10450 = and i64 %10436, 255
  %10451 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10450
  %10452 = load i8, i8* %10451, align 1
  %10453 = insertelement <16 x i8> %10449, i8 %10452, i64 2
  %10454 = and i64 %10437, 255
  %10455 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10454
  %10456 = load i8, i8* %10455, align 1
  %10457 = insertelement <16 x i8> %10453, i8 %10456, i64 3
  %10458 = and i64 %10438, 255
  %10459 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10458
  %10460 = load i8, i8* %10459, align 1
  %10461 = insertelement <16 x i8> %10457, i8 %10460, i64 4
  %10462 = and i64 %10439, 255
  %10463 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10462
  %10464 = load i8, i8* %10463, align 1
  %10465 = insertelement <16 x i8> %10461, i8 %10464, i64 5
  %10466 = and i64 %10440, 255
  %10467 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10466
  %10468 = load i8, i8* %10467, align 1
  %10469 = insertelement <16 x i8> %10465, i8 %10468, i64 6
  %10470 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %10441
  %10471 = load i8, i8* %10470, align 1
  %10472 = insertelement <16 x i8> %10469, i8 %10471, i64 7
  %10473 = shufflevector <16 x i8> %10472, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10474 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10473, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %10475 = shufflevector <8 x i16> %10474, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10476 = shufflevector <8 x i16> %10398, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10477 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10475, <8 x i16> %10476) #5
  %10478 = shufflevector <8 x i16> %10474, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10479 = shufflevector <8 x i16> %10398, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10480 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10478, <8 x i16> %10479) #5
  %10481 = add <4 x i32> %10477, <i32 512, i32 512, i32 512, i32 512>
  %10482 = lshr <4 x i32> %10481, <i32 10, i32 10, i32 10, i32 10>
  %10483 = bitcast <2 x i64> %10304 to <16 x i8>
  %10484 = shufflevector <16 x i8> %10483, <16 x i8> %10305, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %10485 = shufflevector <16 x i8> %10483, <16 x i8> %10305, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %10486 = bitcast <2 x i64> %10366 to <16 x i8>
  %10487 = shufflevector <16 x i8> %10486, <16 x i8> %10367, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %10488 = shufflevector <16 x i8> %10486, <16 x i8> %10367, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %10489 = shufflevector <16 x i8> %10085, <16 x i8> %10472, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %10490 = shufflevector <16 x i8> %10085, <16 x i8> %10472, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %10491 = shufflevector <16 x i8> %10483, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10492 = shufflevector <16 x i8> %10484, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10493 = bitcast <16 x i8> %10491 to <8 x i16>
  %10494 = bitcast <16 x i8> %10492 to <8 x i16>
  %10495 = add <8 x i16> %10494, %10493
  %10496 = shufflevector <16 x i8> %10485, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10497 = bitcast <16 x i8> %10496 to <8 x i16>
  %10498 = add <8 x i16> %10495, %10497
  %10499 = shl <8 x i16> %10498, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10500 = getelementptr inbounds i16, i16* %5956, i64 %9719
  %10501 = bitcast i16* %10500 to <8 x i16>*
  store <8 x i16> %10499, <8 x i16>* %10501, align 16
  %10502 = mul <8 x i16> %10498, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %10503 = add <8 x i16> %10502, %10494
  %10504 = getelementptr inbounds i16, i16* %9704, i64 %9719
  %10505 = bitcast i16* %10504 to <8 x i16>*
  store <8 x i16> %10503, <8 x i16>* %10505, align 16
  %10506 = bitcast <4 x i32> %9743 to <16 x i8>
  %10507 = bitcast <4 x i32> %9733 to <16 x i8>
  %10508 = shufflevector <16 x i8> %10507, <16 x i8> %10506, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10509 = shufflevector <16 x i8> %10507, <16 x i8> %10506, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10510 = bitcast <16 x i8> %10509 to <4 x i32>
  %10511 = bitcast <16 x i8> %10508 to <4 x i32>
  %10512 = add <4 x i32> %9733, %10511
  %10513 = add <4 x i32> %10512, %10510
  %10514 = shl <4 x i32> %10513, <i32 2, i32 2, i32 2, i32 2>
  %10515 = mul <4 x i32> %10513, <i32 3, i32 3, i32 3, i32 3>
  %10516 = add <4 x i32> %10515, %10511
  %10517 = bitcast <4 x i32> %10290 to <16 x i8>
  %10518 = shufflevector <16 x i8> %10506, <16 x i8> %10517, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10519 = shufflevector <16 x i8> %10506, <16 x i8> %10517, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10520 = bitcast <16 x i8> %10519 to <4 x i32>
  %10521 = bitcast <16 x i8> %10518 to <4 x i32>
  %10522 = add <4 x i32> %9743, %10521
  %10523 = add <4 x i32> %10522, %10520
  %10524 = shl <4 x i32> %10523, <i32 2, i32 2, i32 2, i32 2>
  %10525 = mul <4 x i32> %10523, <i32 3, i32 3, i32 3, i32 3>
  %10526 = add <4 x i32> %10525, %10521
  %10527 = getelementptr inbounds i32, i32* %5957, i64 %9719
  %10528 = bitcast i32* %10527 to <4 x i32>*
  store <4 x i32> %10514, <4 x i32>* %10528, align 16
  %10529 = getelementptr inbounds i32, i32* %10527, i64 4
  %10530 = bitcast i32* %10529 to <4 x i32>*
  store <4 x i32> %10524, <4 x i32>* %10530, align 16
  %10531 = getelementptr inbounds i32, i32* %9705, i64 %9719
  %10532 = bitcast i32* %10531 to <4 x i32>*
  store <4 x i32> %10516, <4 x i32>* %10532, align 16
  %10533 = getelementptr inbounds i32, i32* %10531, i64 4
  %10534 = bitcast i32* %10533 to <4 x i32>*
  store <4 x i32> %10526, <4 x i32>* %10534, align 16
  %10535 = shufflevector <16 x i8> %10486, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10536 = shufflevector <16 x i8> %10487, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10537 = bitcast <16 x i8> %10535 to <8 x i16>
  %10538 = bitcast <16 x i8> %10536 to <8 x i16>
  %10539 = add <8 x i16> %10538, %10537
  %10540 = shufflevector <16 x i8> %10488, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10541 = bitcast <16 x i8> %10540 to <8 x i16>
  %10542 = add <8 x i16> %10539, %10541
  %10543 = shl <8 x i16> %10542, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10544 = getelementptr inbounds i16, i16* %9706, i64 %9719
  %10545 = bitcast i16* %10544 to <8 x i16>*
  store <8 x i16> %10543, <8 x i16>* %10545, align 16
  %10546 = mul <8 x i16> %10542, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %10547 = add <8 x i16> %10546, %10538
  %10548 = getelementptr inbounds i16, i16* %7528, i64 %9719
  %10549 = bitcast i16* %10548 to <8 x i16>*
  store <8 x i16> %10547, <8 x i16>* %10549, align 16
  %10550 = bitcast <4 x i32> %9740 to <16 x i8>
  %10551 = bitcast <4 x i32> %9731 to <16 x i8>
  %10552 = shufflevector <16 x i8> %10551, <16 x i8> %10550, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10553 = shufflevector <16 x i8> %10551, <16 x i8> %10550, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10554 = bitcast <16 x i8> %10553 to <4 x i32>
  %10555 = bitcast <16 x i8> %10552 to <4 x i32>
  %10556 = add <4 x i32> %9731, %10555
  %10557 = add <4 x i32> %10556, %10554
  %10558 = shl <4 x i32> %10557, <i32 2, i32 2, i32 2, i32 2>
  %10559 = mul <4 x i32> %10557, <i32 3, i32 3, i32 3, i32 3>
  %10560 = add <4 x i32> %10559, %10555
  %10561 = bitcast <4 x i32> %10352 to <16 x i8>
  %10562 = shufflevector <16 x i8> %10550, <16 x i8> %10561, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10563 = shufflevector <16 x i8> %10550, <16 x i8> %10561, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10564 = bitcast <16 x i8> %10563 to <4 x i32>
  %10565 = bitcast <16 x i8> %10562 to <4 x i32>
  %10566 = add <4 x i32> %9740, %10565
  %10567 = add <4 x i32> %10566, %10564
  %10568 = shl <4 x i32> %10567, <i32 2, i32 2, i32 2, i32 2>
  %10569 = mul <4 x i32> %10567, <i32 3, i32 3, i32 3, i32 3>
  %10570 = add <4 x i32> %10569, %10565
  %10571 = getelementptr inbounds i32, i32* %9707, i64 %9719
  %10572 = bitcast i32* %10571 to <4 x i32>*
  store <4 x i32> %10558, <4 x i32>* %10572, align 16
  %10573 = getelementptr inbounds i32, i32* %10571, i64 4
  %10574 = bitcast i32* %10573 to <4 x i32>*
  store <4 x i32> %10568, <4 x i32>* %10574, align 16
  %10575 = getelementptr inbounds i32, i32* %7538, i64 %9719
  %10576 = bitcast i32* %10575 to <4 x i32>*
  store <4 x i32> %10560, <4 x i32>* %10576, align 16
  %10577 = getelementptr inbounds i32, i32* %10575, i64 4
  %10578 = bitcast i32* %10577 to <4 x i32>*
  store <4 x i32> %10570, <4 x i32>* %10578, align 16
  %10579 = shufflevector <16 x i8> %10085, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10580 = shufflevector <16 x i8> %10489, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10581 = bitcast <16 x i8> %10579 to <8 x i16>
  %10582 = bitcast <16 x i8> %10580 to <8 x i16>
  %10583 = add <8 x i16> %10582, %10581
  %10584 = shufflevector <16 x i8> %10490, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10585 = bitcast <16 x i8> %10584 to <8 x i16>
  %10586 = add <8 x i16> %10583, %10585
  %10587 = mul <8 x i16> %10586, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %10588 = add <8 x i16> %10587, %10582
  %10589 = getelementptr inbounds i16, i16* %9679, i64 %9719
  %10590 = bitcast i16* %10589 to <8 x i16>*
  store <8 x i16> %10588, <8 x i16>* %10590, align 16
  %10591 = bitcast <4 x i32> %9737 to <16 x i8>
  %10592 = bitcast <4 x i32> %9735 to <16 x i8>
  %10593 = shufflevector <16 x i8> %10592, <16 x i8> %10591, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10594 = bitcast <16 x i8> %10593 to <4 x i32>
  %10595 = shufflevector <16 x i8> %10592, <16 x i8> %10591, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10596 = bitcast <16 x i8> %10595 to <4 x i32>
  %10597 = add <4 x i32> %9735, %10594
  %10598 = add <4 x i32> %10597, %10596
  %10599 = mul <4 x i32> %10598, <i32 5, i32 5, i32 5, i32 5>
  %10600 = add <4 x i32> %10599, %10594
  %10601 = bitcast <4 x i32> %10095 to <16 x i8>
  %10602 = shufflevector <16 x i8> %10591, <16 x i8> %10601, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10603 = bitcast <16 x i8> %10602 to <4 x i32>
  %10604 = shufflevector <16 x i8> %10591, <16 x i8> %10601, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10605 = bitcast <16 x i8> %10604 to <4 x i32>
  %10606 = add <4 x i32> %9737, %10603
  %10607 = add <4 x i32> %10606, %10605
  %10608 = mul <4 x i32> %10607, <i32 5, i32 5, i32 5, i32 5>
  %10609 = add <4 x i32> %10608, %10603
  %10610 = getelementptr inbounds i32, i32* %9680, i64 %9719
  %10611 = bitcast i32* %10610 to <4 x i32>*
  store <4 x i32> %10600, <4 x i32>* %10611, align 16
  %10612 = getelementptr inbounds i32, i32* %10610, i64 4
  %10613 = bitcast i32* %10612 to <4 x i32>*
  store <4 x i32> %10609, <4 x i32>* %10613, align 16
  %10614 = getelementptr inbounds i16, i16* %9313, i64 %9719
  %10615 = bitcast i16* %10614 to <8 x i16>*
  %10616 = load <8 x i16>, <8 x i16>* %10615, align 16
  %10617 = getelementptr inbounds i16, i16* %9677, i64 %9719
  %10618 = bitcast i16* %10617 to <8 x i16>*
  %10619 = load <8 x i16>, <8 x i16>* %10618, align 16
  %10620 = getelementptr inbounds i16, i16* %9681, i64 %9719
  %10621 = bitcast i16* %10620 to <8 x i16>*
  %10622 = load <8 x i16>, <8 x i16>* %10621, align 16
  %10623 = getelementptr inbounds i32, i32* %9682, i64 %9719
  %10624 = bitcast i32* %10623 to <4 x i32>*
  %10625 = load <4 x i32>, <4 x i32>* %10624, align 16
  %10626 = getelementptr inbounds i32, i32* %10623, i64 4
  %10627 = bitcast i32* %10626 to <4 x i32>*
  %10628 = load <4 x i32>, <4 x i32>* %10627, align 16
  %10629 = add <8 x i16> %10622, %10588
  %10630 = shufflevector <8 x i16> %10629, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10631 = shufflevector <8 x i16> %10616, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10632 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10630, <8 x i16> %10631) #5
  %10633 = shufflevector <8 x i16> %10629, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10634 = shufflevector <8 x i16> %10616, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10635 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10633, <8 x i16> %10634) #5
  %10636 = add <4 x i32> %10600, <i32 256, i32 256, i32 256, i32 256>
  %10637 = add <4 x i32> %10636, %10625
  %10638 = sub <4 x i32> %10637, %10632
  %10639 = ashr <4 x i32> %10638, <i32 9, i32 9, i32 9, i32 9>
  %10640 = add <4 x i32> %10609, <i32 256, i32 256, i32 256, i32 256>
  %10641 = add <4 x i32> %10640, %10628
  %10642 = sub <4 x i32> %10641, %10635
  %10643 = ashr <4 x i32> %10642, <i32 9, i32 9, i32 9, i32 9>
  %10644 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10639, <4 x i32> %10643) #5
  %10645 = shufflevector <8 x i16> %10588, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10646 = shufflevector <8 x i16> %10619, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10647 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10645, <8 x i16> %10646) #5
  %10648 = shufflevector <8 x i16> %10588, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10649 = shufflevector <8 x i16> %10619, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10650 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10648, <8 x i16> %10649) #5
  %10651 = add <4 x i32> %10600, <i32 128, i32 128, i32 128, i32 128>
  %10652 = sub <4 x i32> %10651, %10647
  %10653 = ashr <4 x i32> %10652, <i32 8, i32 8, i32 8, i32 8>
  %10654 = add <4 x i32> %10609, <i32 128, i32 128, i32 128, i32 128>
  %10655 = sub <4 x i32> %10654, %10650
  %10656 = ashr <4 x i32> %10655, <i32 8, i32 8, i32 8, i32 8>
  %10657 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10653, <4 x i32> %10656) #5
  %10658 = getelementptr inbounds i16, i16* %9708, i64 %9719
  %10659 = bitcast i16* %10658 to <8 x i16>*
  %10660 = load <8 x i16>, <8 x i16>* %10659, align 16
  %10661 = getelementptr inbounds i16, i16* %9709, i64 %9719
  %10662 = bitcast i16* %10661 to <8 x i16>*
  %10663 = load <8 x i16>, <8 x i16>* %10662, align 16
  %10664 = getelementptr inbounds i32, i32* %9710, i64 %9719
  %10665 = bitcast i32* %10664 to <4 x i32>*
  %10666 = load <4 x i32>, <4 x i32>* %10665, align 16
  %10667 = getelementptr inbounds i32, i32* %10664, i64 4
  %10668 = bitcast i32* %10667 to <4 x i32>*
  %10669 = load <4 x i32>, <4 x i32>* %10668, align 16
  %10670 = getelementptr inbounds i32, i32* %9711, i64 %9719
  %10671 = bitcast i32* %10670 to <4 x i32>*
  %10672 = load <4 x i32>, <4 x i32>* %10671, align 16
  %10673 = getelementptr inbounds i32, i32* %10670, i64 4
  %10674 = bitcast i32* %10673 to <4 x i32>*
  %10675 = load <4 x i32>, <4 x i32>* %10674, align 16
  %10676 = add <8 x i16> %10660, %10503
  %10677 = add <8 x i16> %10676, %10663
  %10678 = shufflevector <8 x i16> %10677, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10679 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10678, <8 x i16> %10631) #5
  %10680 = shufflevector <8 x i16> %10677, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10681 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10680, <8 x i16> %10634) #5
  %10682 = add <4 x i32> %10516, <i32 256, i32 256, i32 256, i32 256>
  %10683 = add <4 x i32> %10682, %10666
  %10684 = add <4 x i32> %10683, %10672
  %10685 = sub <4 x i32> %10684, %10679
  %10686 = ashr <4 x i32> %10685, <i32 9, i32 9, i32 9, i32 9>
  %10687 = add <4 x i32> %10526, <i32 256, i32 256, i32 256, i32 256>
  %10688 = add <4 x i32> %10687, %10669
  %10689 = add <4 x i32> %10688, %10675
  %10690 = sub <4 x i32> %10689, %10681
  %10691 = ashr <4 x i32> %10690, <i32 9, i32 9, i32 9, i32 9>
  %10692 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10686, <4 x i32> %10691) #5
  %10693 = shufflevector <8 x i16> %10644, <8 x i16> %10692, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10694 = shufflevector <8 x i16> %10644, <8 x i16> %10692, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10695 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %10693) #5
  %10696 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %10694) #5
  %10697 = add <4 x i32> %10695, <i32 1024, i32 1024, i32 1024, i32 1024>
  %10698 = ashr <4 x i32> %10697, <i32 11, i32 11, i32 11, i32 11>
  %10699 = add <4 x i32> %10696, <i32 1024, i32 1024, i32 1024, i32 1024>
  %10700 = ashr <4 x i32> %10699, <i32 11, i32 11, i32 11, i32 11>
  %10701 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10698, <4 x i32> %10700) #5
  %10702 = add <8 x i16> %10701, %10616
  %10703 = getelementptr inbounds i16, i16* %7530, i64 %9719
  %10704 = bitcast i16* %10703 to <8 x i16>*
  %10705 = load <8 x i16>, <8 x i16>* %10704, align 16
  %10706 = getelementptr inbounds i32, i32* %7540, i64 %9719
  %10707 = bitcast i32* %10706 to <4 x i32>*
  %10708 = load <4 x i32>, <4 x i32>* %10707, align 16
  %10709 = getelementptr inbounds i32, i32* %10706, i64 4
  %10710 = bitcast i32* %10709 to <4 x i32>*
  %10711 = load <4 x i32>, <4 x i32>* %10710, align 16
  %10712 = add <8 x i16> %10547, %10499
  %10713 = add <8 x i16> %10712, %10705
  %10714 = shufflevector <8 x i16> %10713, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10715 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10714, <8 x i16> %10646) #5
  %10716 = shufflevector <8 x i16> %10713, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10717 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10716, <8 x i16> %10649) #5
  %10718 = add <4 x i32> %10560, <i32 256, i32 256, i32 256, i32 256>
  %10719 = add <4 x i32> %10718, %10514
  %10720 = add <4 x i32> %10719, %10708
  %10721 = sub <4 x i32> %10720, %10715
  %10722 = ashr <4 x i32> %10721, <i32 9, i32 9, i32 9, i32 9>
  %10723 = add <4 x i32> %10524, <i32 256, i32 256, i32 256, i32 256>
  %10724 = add <4 x i32> %10723, %10570
  %10725 = add <4 x i32> %10724, %10711
  %10726 = sub <4 x i32> %10725, %10717
  %10727 = ashr <4 x i32> %10726, <i32 9, i32 9, i32 9, i32 9>
  %10728 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10722, <4 x i32> %10727) #5
  %10729 = shufflevector <8 x i16> %10657, <8 x i16> %10728, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10730 = shufflevector <8 x i16> %10657, <8 x i16> %10728, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10731 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %10729) #5
  %10732 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %10730) #5
  %10733 = add <4 x i32> %10731, <i32 1024, i32 1024, i32 1024, i32 1024>
  %10734 = ashr <4 x i32> %10733, <i32 11, i32 11, i32 11, i32 11>
  %10735 = add <4 x i32> %10732, <i32 1024, i32 1024, i32 1024, i32 1024>
  %10736 = ashr <4 x i32> %10735, <i32 11, i32 11, i32 11, i32 11>
  %10737 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10734, <4 x i32> %10736) #5
  %10738 = add <8 x i16> %10737, %10619
  %10739 = shufflevector <16 x i8> %10483, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10740 = shufflevector <16 x i8> %10484, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10741 = bitcast <16 x i8> %10739 to <8 x i16>
  %10742 = bitcast <16 x i8> %10740 to <8 x i16>
  %10743 = add <8 x i16> %10742, %10741
  %10744 = shufflevector <16 x i8> %10485, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10745 = bitcast <16 x i8> %10744 to <8 x i16>
  %10746 = add <8 x i16> %10743, %10745
  %10747 = shl <8 x i16> %10746, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10748 = getelementptr inbounds i16, i16* %5956, i64 %9761
  %10749 = bitcast i16* %10748 to <8 x i16>*
  store <8 x i16> %10747, <8 x i16>* %10749, align 16
  %10750 = mul <8 x i16> %10746, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %10751 = add <8 x i16> %10750, %10742
  %10752 = getelementptr inbounds i16, i16* %9704, i64 %9761
  %10753 = bitcast i16* %10752 to <8 x i16>*
  store <8 x i16> %10751, <8 x i16>* %10753, align 16
  %10754 = bitcast <4 x i32> %10292 to <16 x i8>
  %10755 = shufflevector <16 x i8> %10517, <16 x i8> %10754, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10756 = shufflevector <16 x i8> %10517, <16 x i8> %10754, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10757 = bitcast <16 x i8> %10756 to <4 x i32>
  %10758 = bitcast <16 x i8> %10755 to <4 x i32>
  %10759 = add <4 x i32> %10290, %10758
  %10760 = add <4 x i32> %10759, %10757
  %10761 = shl <4 x i32> %10760, <i32 2, i32 2, i32 2, i32 2>
  %10762 = mul <4 x i32> %10760, <i32 3, i32 3, i32 3, i32 3>
  %10763 = add <4 x i32> %10762, %10758
  %10764 = bitcast <4 x i32> %10303 to <16 x i8>
  %10765 = shufflevector <16 x i8> %10754, <16 x i8> %10764, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10766 = shufflevector <16 x i8> %10754, <16 x i8> %10764, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10767 = bitcast <16 x i8> %10766 to <4 x i32>
  %10768 = bitcast <16 x i8> %10765 to <4 x i32>
  %10769 = add <4 x i32> %10292, %10768
  %10770 = add <4 x i32> %10769, %10767
  %10771 = shl <4 x i32> %10770, <i32 2, i32 2, i32 2, i32 2>
  %10772 = mul <4 x i32> %10770, <i32 3, i32 3, i32 3, i32 3>
  %10773 = add <4 x i32> %10772, %10768
  %10774 = getelementptr inbounds i32, i32* %5957, i64 %9761
  %10775 = bitcast i32* %10774 to <4 x i32>*
  store <4 x i32> %10761, <4 x i32>* %10775, align 16
  %10776 = getelementptr inbounds i32, i32* %10774, i64 4
  %10777 = bitcast i32* %10776 to <4 x i32>*
  store <4 x i32> %10771, <4 x i32>* %10777, align 16
  %10778 = getelementptr inbounds i32, i32* %9705, i64 %9761
  %10779 = bitcast i32* %10778 to <4 x i32>*
  store <4 x i32> %10763, <4 x i32>* %10779, align 16
  %10780 = getelementptr inbounds i32, i32* %10778, i64 4
  %10781 = bitcast i32* %10780 to <4 x i32>*
  store <4 x i32> %10773, <4 x i32>* %10781, align 16
  %10782 = shufflevector <16 x i8> %10486, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10783 = shufflevector <16 x i8> %10487, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10784 = bitcast <16 x i8> %10782 to <8 x i16>
  %10785 = bitcast <16 x i8> %10783 to <8 x i16>
  %10786 = add <8 x i16> %10785, %10784
  %10787 = shufflevector <16 x i8> %10488, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10788 = bitcast <16 x i8> %10787 to <8 x i16>
  %10789 = add <8 x i16> %10786, %10788
  %10790 = shl <8 x i16> %10789, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %10791 = getelementptr inbounds i16, i16* %9706, i64 %9761
  %10792 = bitcast i16* %10791 to <8 x i16>*
  store <8 x i16> %10790, <8 x i16>* %10792, align 16
  %10793 = mul <8 x i16> %10789, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %10794 = add <8 x i16> %10793, %10785
  %10795 = getelementptr inbounds i16, i16* %7528, i64 %9761
  %10796 = bitcast i16* %10795 to <8 x i16>*
  store <8 x i16> %10794, <8 x i16>* %10796, align 16
  %10797 = bitcast <4 x i32> %10354 to <16 x i8>
  %10798 = shufflevector <16 x i8> %10561, <16 x i8> %10797, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10799 = shufflevector <16 x i8> %10561, <16 x i8> %10797, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10800 = bitcast <16 x i8> %10799 to <4 x i32>
  %10801 = bitcast <16 x i8> %10798 to <4 x i32>
  %10802 = add <4 x i32> %10352, %10801
  %10803 = add <4 x i32> %10802, %10800
  %10804 = shl <4 x i32> %10803, <i32 2, i32 2, i32 2, i32 2>
  %10805 = mul <4 x i32> %10803, <i32 3, i32 3, i32 3, i32 3>
  %10806 = add <4 x i32> %10805, %10801
  %10807 = bitcast <4 x i32> %10365 to <16 x i8>
  %10808 = shufflevector <16 x i8> %10797, <16 x i8> %10807, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10809 = shufflevector <16 x i8> %10797, <16 x i8> %10807, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10810 = bitcast <16 x i8> %10809 to <4 x i32>
  %10811 = bitcast <16 x i8> %10808 to <4 x i32>
  %10812 = add <4 x i32> %10354, %10811
  %10813 = add <4 x i32> %10812, %10810
  %10814 = shl <4 x i32> %10813, <i32 2, i32 2, i32 2, i32 2>
  %10815 = mul <4 x i32> %10813, <i32 3, i32 3, i32 3, i32 3>
  %10816 = add <4 x i32> %10815, %10811
  %10817 = getelementptr inbounds i32, i32* %9707, i64 %9761
  %10818 = bitcast i32* %10817 to <4 x i32>*
  store <4 x i32> %10804, <4 x i32>* %10818, align 16
  %10819 = getelementptr inbounds i32, i32* %10817, i64 4
  %10820 = bitcast i32* %10819 to <4 x i32>*
  store <4 x i32> %10814, <4 x i32>* %10820, align 16
  %10821 = getelementptr inbounds i32, i32* %7538, i64 %9761
  %10822 = bitcast i32* %10821 to <4 x i32>*
  store <4 x i32> %10806, <4 x i32>* %10822, align 16
  %10823 = getelementptr inbounds i32, i32* %10821, i64 4
  %10824 = bitcast i32* %10823 to <4 x i32>*
  store <4 x i32> %10816, <4 x i32>* %10824, align 16
  %10825 = shufflevector <16 x i8> %10489, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10826 = bitcast <16 x i8> %10086 to <8 x i16>
  %10827 = bitcast <16 x i8> %10825 to <8 x i16>
  %10828 = add <8 x i16> %10827, %10826
  %10829 = shufflevector <16 x i8> %10490, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %10830 = bitcast <16 x i8> %10829 to <8 x i16>
  %10831 = add <8 x i16> %10828, %10830
  %10832 = mul <8 x i16> %10831, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %10833 = add <8 x i16> %10832, %10827
  %10834 = getelementptr inbounds i16, i16* %9683, i64 %9719
  %10835 = bitcast i16* %10834 to <8 x i16>*
  store <8 x i16> %10833, <8 x i16>* %10835, align 16
  %10836 = bitcast <4 x i32> %10097 to <16 x i8>
  %10837 = shufflevector <16 x i8> %10601, <16 x i8> %10836, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10838 = bitcast <16 x i8> %10837 to <4 x i32>
  %10839 = shufflevector <16 x i8> %10601, <16 x i8> %10836, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10840 = bitcast <16 x i8> %10839 to <4 x i32>
  %10841 = add <4 x i32> %10095, %10838
  %10842 = add <4 x i32> %10841, %10840
  %10843 = mul <4 x i32> %10842, <i32 5, i32 5, i32 5, i32 5>
  %10844 = add <4 x i32> %10843, %10838
  %10845 = bitcast <4 x i32> %10482 to <16 x i8>
  %10846 = shufflevector <16 x i8> %10836, <16 x i8> %10845, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %10847 = bitcast <16 x i8> %10846 to <4 x i32>
  %10848 = shufflevector <16 x i8> %10836, <16 x i8> %10845, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10849 = bitcast <16 x i8> %10848 to <4 x i32>
  %10850 = add <4 x i32> %10097, %10847
  %10851 = add <4 x i32> %10850, %10849
  %10852 = mul <4 x i32> %10851, <i32 5, i32 5, i32 5, i32 5>
  %10853 = add <4 x i32> %10852, %10847
  %10854 = getelementptr inbounds i32, i32* %9684, i64 %9719
  %10855 = bitcast i32* %10854 to <4 x i32>*
  store <4 x i32> %10844, <4 x i32>* %10855, align 16
  %10856 = getelementptr inbounds i32, i32* %10854, i64 4
  %10857 = bitcast i32* %10856 to <4 x i32>*
  store <4 x i32> %10853, <4 x i32>* %10857, align 16
  %10858 = getelementptr inbounds i16, i16* %10614, i64 8
  %10859 = bitcast i16* %10858 to <8 x i16>*
  %10860 = load <8 x i16>, <8 x i16>* %10859, align 16
  %10861 = getelementptr inbounds i16, i16* %10617, i64 8
  %10862 = bitcast i16* %10861 to <8 x i16>*
  %10863 = load <8 x i16>, <8 x i16>* %10862, align 16
  %10864 = getelementptr inbounds i16, i16* %9685, i64 %9719
  %10865 = bitcast i16* %10864 to <8 x i16>*
  %10866 = load <8 x i16>, <8 x i16>* %10865, align 16
  %10867 = getelementptr inbounds i32, i32* %9686, i64 %9719
  %10868 = bitcast i32* %10867 to <4 x i32>*
  %10869 = load <4 x i32>, <4 x i32>* %10868, align 16
  %10870 = getelementptr inbounds i32, i32* %10867, i64 4
  %10871 = bitcast i32* %10870 to <4 x i32>*
  %10872 = load <4 x i32>, <4 x i32>* %10871, align 16
  %10873 = add <8 x i16> %10866, %10833
  %10874 = shufflevector <8 x i16> %10873, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10875 = shufflevector <8 x i16> %10860, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10876 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10874, <8 x i16> %10875) #5
  %10877 = shufflevector <8 x i16> %10873, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10878 = shufflevector <8 x i16> %10860, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10879 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10877, <8 x i16> %10878) #5
  %10880 = add <4 x i32> %10844, <i32 256, i32 256, i32 256, i32 256>
  %10881 = add <4 x i32> %10880, %10869
  %10882 = sub <4 x i32> %10881, %10876
  %10883 = ashr <4 x i32> %10882, <i32 9, i32 9, i32 9, i32 9>
  %10884 = add <4 x i32> %10853, <i32 256, i32 256, i32 256, i32 256>
  %10885 = add <4 x i32> %10884, %10872
  %10886 = sub <4 x i32> %10885, %10879
  %10887 = ashr <4 x i32> %10886, <i32 9, i32 9, i32 9, i32 9>
  %10888 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10883, <4 x i32> %10887) #5
  %10889 = shufflevector <8 x i16> %10833, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10890 = shufflevector <8 x i16> %10863, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10891 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10889, <8 x i16> %10890) #5
  %10892 = shufflevector <8 x i16> %10833, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10893 = shufflevector <8 x i16> %10863, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10894 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10892, <8 x i16> %10893) #5
  %10895 = add <4 x i32> %10844, <i32 128, i32 128, i32 128, i32 128>
  %10896 = sub <4 x i32> %10895, %10891
  %10897 = ashr <4 x i32> %10896, <i32 8, i32 8, i32 8, i32 8>
  %10898 = add <4 x i32> %10853, <i32 128, i32 128, i32 128, i32 128>
  %10899 = sub <4 x i32> %10898, %10894
  %10900 = ashr <4 x i32> %10899, <i32 8, i32 8, i32 8, i32 8>
  %10901 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10897, <4 x i32> %10900) #5
  %10902 = getelementptr inbounds i16, i16* %9712, i64 %9719
  %10903 = bitcast i16* %10902 to <8 x i16>*
  %10904 = load <8 x i16>, <8 x i16>* %10903, align 16
  %10905 = getelementptr inbounds i16, i16* %9713, i64 %9719
  %10906 = bitcast i16* %10905 to <8 x i16>*
  %10907 = load <8 x i16>, <8 x i16>* %10906, align 16
  %10908 = getelementptr inbounds i32, i32* %9714, i64 %9719
  %10909 = bitcast i32* %10908 to <4 x i32>*
  %10910 = load <4 x i32>, <4 x i32>* %10909, align 16
  %10911 = getelementptr inbounds i32, i32* %10908, i64 4
  %10912 = bitcast i32* %10911 to <4 x i32>*
  %10913 = load <4 x i32>, <4 x i32>* %10912, align 16
  %10914 = getelementptr inbounds i32, i32* %9715, i64 %9719
  %10915 = bitcast i32* %10914 to <4 x i32>*
  %10916 = load <4 x i32>, <4 x i32>* %10915, align 16
  %10917 = getelementptr inbounds i32, i32* %10914, i64 4
  %10918 = bitcast i32* %10917 to <4 x i32>*
  %10919 = load <4 x i32>, <4 x i32>* %10918, align 16
  %10920 = add <8 x i16> %10904, %10751
  %10921 = add <8 x i16> %10920, %10907
  %10922 = shufflevector <8 x i16> %10921, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10923 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10922, <8 x i16> %10875) #5
  %10924 = shufflevector <8 x i16> %10921, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10925 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10924, <8 x i16> %10878) #5
  %10926 = add <4 x i32> %10763, <i32 256, i32 256, i32 256, i32 256>
  %10927 = add <4 x i32> %10926, %10910
  %10928 = add <4 x i32> %10927, %10916
  %10929 = sub <4 x i32> %10928, %10923
  %10930 = ashr <4 x i32> %10929, <i32 9, i32 9, i32 9, i32 9>
  %10931 = add <4 x i32> %10773, <i32 256, i32 256, i32 256, i32 256>
  %10932 = add <4 x i32> %10931, %10913
  %10933 = add <4 x i32> %10932, %10919
  %10934 = sub <4 x i32> %10933, %10925
  %10935 = ashr <4 x i32> %10934, <i32 9, i32 9, i32 9, i32 9>
  %10936 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10930, <4 x i32> %10935) #5
  %10937 = shufflevector <8 x i16> %10888, <8 x i16> %10936, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10938 = shufflevector <8 x i16> %10888, <8 x i16> %10936, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10939 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %10937) #5
  %10940 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %10938) #5
  %10941 = add <4 x i32> %10939, <i32 1024, i32 1024, i32 1024, i32 1024>
  %10942 = ashr <4 x i32> %10941, <i32 11, i32 11, i32 11, i32 11>
  %10943 = add <4 x i32> %10940, <i32 1024, i32 1024, i32 1024, i32 1024>
  %10944 = ashr <4 x i32> %10943, <i32 11, i32 11, i32 11, i32 11>
  %10945 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10942, <4 x i32> %10944) #5
  %10946 = add <8 x i16> %10945, %10860
  %10947 = getelementptr inbounds i16, i16* %7558, i64 %9719
  %10948 = icmp sgt <8 x i16> %10702, zeroinitializer
  %10949 = select <8 x i1> %10948, <8 x i16> %10702, <8 x i16> zeroinitializer
  %10950 = icmp slt <8 x i16> %10949, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %10951 = select <8 x i1> %10950, <8 x i16> %10949, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %10952 = bitcast i16* %10947 to <8 x i16>*
  store <8 x i16> %10951, <8 x i16>* %10952, align 16
  %10953 = getelementptr inbounds i16, i16* %10947, i64 8
  %10954 = icmp sgt <8 x i16> %10946, zeroinitializer
  %10955 = select <8 x i1> %10954, <8 x i16> %10946, <8 x i16> zeroinitializer
  %10956 = icmp slt <8 x i16> %10955, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %10957 = select <8 x i1> %10956, <8 x i16> %10955, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %10958 = bitcast i16* %10953 to <8 x i16>*
  store <8 x i16> %10957, <8 x i16>* %10958, align 16
  %10959 = getelementptr inbounds i16, i16* %9716, i64 %9719
  %10960 = bitcast i16* %10959 to <8 x i16>*
  %10961 = load <8 x i16>, <8 x i16>* %10960, align 16
  %10962 = getelementptr inbounds i32, i32* %9717, i64 %9719
  %10963 = bitcast i32* %10962 to <4 x i32>*
  %10964 = load <4 x i32>, <4 x i32>* %10963, align 16
  %10965 = getelementptr inbounds i32, i32* %10962, i64 4
  %10966 = bitcast i32* %10965 to <4 x i32>*
  %10967 = load <4 x i32>, <4 x i32>* %10966, align 16
  %10968 = add <8 x i16> %10794, %10747
  %10969 = add <8 x i16> %10968, %10961
  %10970 = shufflevector <8 x i16> %10969, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10971 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10970, <8 x i16> %10890) #5
  %10972 = shufflevector <8 x i16> %10969, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10973 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10972, <8 x i16> %10893) #5
  %10974 = add <4 x i32> %10761, <i32 256, i32 256, i32 256, i32 256>
  %10975 = add <4 x i32> %10974, %10806
  %10976 = add <4 x i32> %10975, %10964
  %10977 = sub <4 x i32> %10976, %10971
  %10978 = ashr <4 x i32> %10977, <i32 9, i32 9, i32 9, i32 9>
  %10979 = add <4 x i32> %10771, <i32 256, i32 256, i32 256, i32 256>
  %10980 = add <4 x i32> %10979, %10816
  %10981 = add <4 x i32> %10980, %10967
  %10982 = sub <4 x i32> %10981, %10973
  %10983 = ashr <4 x i32> %10982, <i32 9, i32 9, i32 9, i32 9>
  %10984 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10978, <4 x i32> %10983) #5
  %10985 = shufflevector <8 x i16> %10901, <8 x i16> %10984, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10986 = shufflevector <8 x i16> %10901, <8 x i16> %10984, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10987 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %10985) #5
  %10988 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %10986) #5
  %10989 = add <4 x i32> %10987, <i32 1024, i32 1024, i32 1024, i32 1024>
  %10990 = ashr <4 x i32> %10989, <i32 11, i32 11, i32 11, i32 11>
  %10991 = add <4 x i32> %10988, <i32 1024, i32 1024, i32 1024, i32 1024>
  %10992 = ashr <4 x i32> %10991, <i32 11, i32 11, i32 11, i32 11>
  %10993 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10990, <4 x i32> %10992) #5
  %10994 = add <8 x i16> %10993, %10863
  %10995 = getelementptr inbounds i16, i16* %9678, i64 %9719
  %10996 = icmp sgt <8 x i16> %10738, zeroinitializer
  %10997 = select <8 x i1> %10996, <8 x i16> %10738, <8 x i16> zeroinitializer
  %10998 = icmp slt <8 x i16> %10997, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %10999 = select <8 x i1> %10998, <8 x i16> %10997, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %11000 = bitcast i16* %10995 to <8 x i16>*
  store <8 x i16> %10999, <8 x i16>* %11000, align 16
  %11001 = getelementptr inbounds i16, i16* %10995, i64 8
  %11002 = icmp sgt <8 x i16> %10994, zeroinitializer
  %11003 = select <8 x i1> %11002, <8 x i16> %10994, <8 x i16> zeroinitializer
  %11004 = icmp slt <8 x i16> %11003, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %11005 = select <8 x i1> %11004, <8 x i16> %11003, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %11006 = bitcast i16* %11001 to <8 x i16>*
  store <8 x i16> %11005, <8 x i16>* %11006, align 16
  %11007 = icmp slt i64 %9748, %5918
  br i1 %11007, label %9718, label %11008

11008:                                            ; preds = %9718, %7523
  br i1 %7561, label %12087, label %11009

11009:                                            ; preds = %11008
  br i1 %6149, label %11010, label %11013

11010:                                            ; preds = %11009
  %11011 = getelementptr inbounds i16, i16* %7559, i64 %7506
  %11012 = getelementptr inbounds i16, i16* %7558, i64 %7506
  br label %11013

11013:                                            ; preds = %11009, %11010
  %11014 = phi i64 [ %7526, %11010 ], [ %7524, %11009 ]
  %11015 = phi i64 [ %7527, %11010 ], [ %7525, %11009 ]
  %11016 = phi i64 [ %7536, %11010 ], [ %7534, %11009 ]
  %11017 = phi i64 [ %7537, %11010 ], [ %7535, %11009 ]
  %11018 = phi i64 [ %7547, %11010 ], [ %7544, %11009 ]
  %11019 = phi i64 [ %7553, %11010 ], [ %7545, %11009 ]
  %11020 = phi i64 [ %7544, %11010 ], [ %7546, %11009 ]
  %11021 = phi i64 [ %7551, %11010 ], [ %7548, %11009 ]
  %11022 = phi i64 [ %7552, %11010 ], [ %7549, %11009 ]
  %11023 = phi i64 [ %7548, %11010 ], [ %7550, %11009 ]
  %11024 = phi i64 [ %7542, %11010 ], [ %7543, %11009 ]
  %11025 = phi i64 [ %7539, %11010 ], [ %7541, %11009 ]
  %11026 = phi i64 [ %7532, %11010 ], [ %7533, %11009 ]
  %11027 = phi i64 [ %7529, %11010 ], [ %7531, %11009 ]
  %11028 = phi i64 [ %7554, %11010 ], [ %7555, %11009 ]
  %11029 = phi i64 [ %7556, %11010 ], [ %7557, %11009 ]
  %11030 = phi i16* [ %11012, %11010 ], [ %7558, %11009 ]
  %11031 = phi i16* [ %11011, %11010 ], [ %7559, %11009 ]
  %11032 = inttoptr i64 %11027 to i16*
  %11033 = inttoptr i64 %11026 to i16*
  %11034 = inttoptr i64 %11025 to i32*
  %11035 = inttoptr i64 %11024 to i32*
  %11036 = inttoptr i64 %11020 to <8 x i16>*
  %11037 = inttoptr i64 %11019 to <8 x i16>*
  %11038 = inttoptr i64 %11018 to <8 x i16>*
  %11039 = inttoptr i64 %11023 to i32*
  %11040 = inttoptr i64 %11022 to i32*
  %11041 = inttoptr i64 %11021 to i32*
  %11042 = getelementptr inbounds i16, i16* %11031, i64 3
  %11043 = getelementptr inbounds i16, i16* %6113, i64 %6
  %11044 = inttoptr i64 %11028 to i16*
  %11045 = inttoptr i64 %11029 to i32*
  %11046 = bitcast i16* %11043 to <8 x i16>*
  %11047 = load <8 x i16>, <8 x i16>* %11046, align 1
  %11048 = getelementptr inbounds i16, i16* %11043, i64 8
  %11049 = bitcast i16* %11048 to <2 x i64>*
  %11050 = load <2 x i64>, <2 x i64>* %11049, align 1
  %11051 = shufflevector <8 x i16> %11047, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11052 = shufflevector <8 x i16> %11047, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11053 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11051, <8 x i16> %11051) #5
  %11054 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11052, <8 x i16> %11052) #5
  %11055 = bitcast <2 x i64> %11050 to <8 x i16>
  %11056 = shufflevector <8 x i16> %11055, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11057 = shufflevector <8 x i16> %11055, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11058 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11056, <8 x i16> %11056) #5
  %11059 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11057, <8 x i16> %11057) #5
  %11060 = bitcast <2 x i64> %11050 to <16 x i8>
  %11061 = bitcast <8 x i16> %11047 to <16 x i8>
  %11062 = shufflevector <16 x i8> %11061, <16 x i8> %11060, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %11063 = bitcast <16 x i8> %11062 to <8 x i16>
  %11064 = shufflevector <16 x i8> %11061, <16 x i8> %11060, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11065 = bitcast <16 x i8> %11064 to <8 x i16>
  %11066 = shufflevector <16 x i8> %11061, <16 x i8> %11060, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %11067 = bitcast <16 x i8> %11066 to <8 x i16>
  %11068 = shufflevector <16 x i8> %11061, <16 x i8> %11060, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11069 = bitcast <16 x i8> %11068 to <8 x i16>
  %11070 = add <8 x i16> %11047, %11069
  %11071 = add <8 x i16> %11065, %11063
  %11072 = add <8 x i16> %11071, %11067
  %11073 = add <8 x i16> %11070, %11072
  %11074 = bitcast <4 x i32> %11054 to <16 x i8>
  %11075 = bitcast <4 x i32> %11053 to <16 x i8>
  %11076 = shufflevector <16 x i8> %11075, <16 x i8> %11074, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11077 = bitcast <16 x i8> %11076 to <4 x i32>
  %11078 = shufflevector <16 x i8> %11075, <16 x i8> %11074, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11079 = bitcast <16 x i8> %11078 to <4 x i32>
  %11080 = shufflevector <16 x i8> %11075, <16 x i8> %11074, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %11081 = bitcast <16 x i8> %11080 to <4 x i32>
  %11082 = add <4 x i32> %11054, %11053
  %11083 = add <4 x i32> %11079, %11077
  %11084 = add <4 x i32> %11083, %11081
  %11085 = add <4 x i32> %11082, %11084
  %11086 = bitcast <4 x i32> %11058 to <16 x i8>
  %11087 = shufflevector <16 x i8> %11074, <16 x i8> %11086, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11088 = bitcast <16 x i8> %11087 to <4 x i32>
  %11089 = shufflevector <16 x i8> %11074, <16 x i8> %11086, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11090 = bitcast <16 x i8> %11089 to <4 x i32>
  %11091 = shufflevector <16 x i8> %11074, <16 x i8> %11086, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %11092 = bitcast <16 x i8> %11091 to <4 x i32>
  %11093 = add <4 x i32> %11058, %11054
  %11094 = add <4 x i32> %11090, %11088
  %11095 = add <4 x i32> %11094, %11092
  %11096 = add <4 x i32> %11093, %11095
  %11097 = load <8 x i16>, <8 x i16>* %11036, align 16
  %11098 = load <8 x i16>, <8 x i16>* %11037, align 16
  %11099 = load <8 x i16>, <8 x i16>* %11038, align 16
  %11100 = inttoptr i64 %11023 to <4 x i32>*
  %11101 = load <4 x i32>, <4 x i32>* %11100, align 16
  %11102 = getelementptr inbounds i32, i32* %11039, i64 4
  %11103 = bitcast i32* %11102 to <4 x i32>*
  %11104 = load <4 x i32>, <4 x i32>* %11103, align 16
  %11105 = inttoptr i64 %11022 to <4 x i32>*
  %11106 = load <4 x i32>, <4 x i32>* %11105, align 16
  %11107 = getelementptr inbounds i32, i32* %11040, i64 4
  %11108 = bitcast i32* %11107 to <4 x i32>*
  %11109 = load <4 x i32>, <4 x i32>* %11108, align 16
  %11110 = inttoptr i64 %11021 to <4 x i32>*
  %11111 = load <4 x i32>, <4 x i32>* %11110, align 16
  %11112 = getelementptr inbounds i32, i32* %11041, i64 4
  %11113 = bitcast i32* %11112 to <4 x i32>*
  %11114 = load <4 x i32>, <4 x i32>* %11113, align 16
  %11115 = shl <8 x i16> %11073, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %11116 = add <8 x i16> %11098, %11097
  %11117 = add <8 x i16> %11116, %11115
  %11118 = add <8 x i16> %11117, %11099
  %11119 = add <8 x i16> %11118, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11120 = lshr <8 x i16> %11119, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11121 = shufflevector <8 x i16> %11120, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11122 = shufflevector <8 x i16> %11120, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11123 = shl <4 x i32> %11085, <i32 1, i32 1, i32 1, i32 1>
  %11124 = add <4 x i32> %11101, <i32 8, i32 8, i32 8, i32 8>
  %11125 = add <4 x i32> %11124, %11123
  %11126 = add <4 x i32> %11125, %11106
  %11127 = add <4 x i32> %11126, %11111
  %11128 = lshr <4 x i32> %11127, <i32 4, i32 4, i32 4, i32 4>
  %11129 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11121, <8 x i16> %11121) #5
  %11130 = mul <4 x i32> %11128, <i32 25, i32 25, i32 25, i32 25>
  %11131 = sub <4 x i32> %11130, %11129
  %11132 = icmp sgt <4 x i32> %11131, zeroinitializer
  %11133 = select <4 x i1> %11132, <4 x i32> %11131, <4 x i32> zeroinitializer
  %11134 = mul <4 x i32> %11133, %6442
  %11135 = add <4 x i32> %11134, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11136 = lshr <4 x i32> %11135, <i32 20, i32 20, i32 20, i32 20>
  %11137 = shl <4 x i32> %11096, <i32 1, i32 1, i32 1, i32 1>
  %11138 = add <4 x i32> %11104, <i32 8, i32 8, i32 8, i32 8>
  %11139 = add <4 x i32> %11138, %11137
  %11140 = add <4 x i32> %11139, %11109
  %11141 = add <4 x i32> %11140, %11114
  %11142 = lshr <4 x i32> %11141, <i32 4, i32 4, i32 4, i32 4>
  %11143 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11122, <8 x i16> %11122) #5
  %11144 = mul <4 x i32> %11142, <i32 25, i32 25, i32 25, i32 25>
  %11145 = sub <4 x i32> %11144, %11143
  %11146 = icmp sgt <4 x i32> %11145, zeroinitializer
  %11147 = select <4 x i1> %11146, <4 x i32> %11145, <4 x i32> zeroinitializer
  %11148 = mul <4 x i32> %11147, %6442
  %11149 = add <4 x i32> %11148, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11150 = lshr <4 x i32> %11149, <i32 20, i32 20, i32 20, i32 20>
  %11151 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %11136, <4 x i32> %11150) #5
  %11152 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %11151, <8 x i16> undef) #5
  %11153 = bitcast <16 x i8> %11152 to <2 x i64>
  %11154 = extractelement <2 x i64> %11153, i32 0
  %11155 = lshr i64 %11154, 8
  %11156 = lshr i64 %11154, 16
  %11157 = lshr i64 %11154, 24
  %11158 = lshr i64 %11154, 32
  %11159 = lshr i64 %11154, 40
  %11160 = lshr i64 %11154, 48
  %11161 = lshr i64 %11154, 56
  %11162 = and i64 %11154, 255
  %11163 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11162
  %11164 = load i8, i8* %11163, align 1
  %11165 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %11164, i64 0
  %11166 = and i64 %11155, 255
  %11167 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11166
  %11168 = load i8, i8* %11167, align 1
  %11169 = insertelement <16 x i8> %11165, i8 %11168, i64 1
  %11170 = and i64 %11156, 255
  %11171 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11170
  %11172 = load i8, i8* %11171, align 1
  %11173 = insertelement <16 x i8> %11169, i8 %11172, i64 2
  %11174 = and i64 %11157, 255
  %11175 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11174
  %11176 = load i8, i8* %11175, align 1
  %11177 = insertelement <16 x i8> %11173, i8 %11176, i64 3
  %11178 = and i64 %11158, 255
  %11179 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11178
  %11180 = load i8, i8* %11179, align 1
  %11181 = insertelement <16 x i8> %11177, i8 %11180, i64 4
  %11182 = and i64 %11159, 255
  %11183 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11182
  %11184 = load i8, i8* %11183, align 1
  %11185 = insertelement <16 x i8> %11181, i8 %11184, i64 5
  %11186 = and i64 %11160, 255
  %11187 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11186
  %11188 = load i8, i8* %11187, align 1
  %11189 = insertelement <16 x i8> %11185, i8 %11188, i64 6
  %11190 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11161
  %11191 = load i8, i8* %11190, align 1
  %11192 = insertelement <16 x i8> %11189, i8 %11191, i64 7
  %11193 = shufflevector <16 x i8> %11192, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11194 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %11193, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %11195 = shufflevector <8 x i16> %11194, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11196 = shufflevector <8 x i16> %11118, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11197 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11195, <8 x i16> %11196) #5
  %11198 = shufflevector <8 x i16> %11194, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11199 = shufflevector <8 x i16> %11118, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11200 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11198, <8 x i16> %11199) #5
  %11201 = add <4 x i32> %11197, <i32 512, i32 512, i32 512, i32 512>
  %11202 = lshr <4 x i32> %11201, <i32 10, i32 10, i32 10, i32 10>
  %11203 = inttoptr i64 %11015 to <8 x i16>*
  %11204 = load <8 x i16>, <8 x i16>* %11203, align 16
  %11205 = inttoptr i64 %11014 to <8 x i16>*
  %11206 = load <8 x i16>, <8 x i16>* %11205, align 16
  %11207 = inttoptr i64 %11017 to i32*
  %11208 = inttoptr i64 %11017 to <4 x i32>*
  %11209 = load <4 x i32>, <4 x i32>* %11208, align 16
  %11210 = getelementptr inbounds i32, i32* %11207, i64 4
  %11211 = bitcast i32* %11210 to <4 x i32>*
  %11212 = load <4 x i32>, <4 x i32>* %11211, align 16
  %11213 = inttoptr i64 %11016 to i32*
  %11214 = inttoptr i64 %11016 to <4 x i32>*
  %11215 = load <4 x i32>, <4 x i32>* %11214, align 16
  %11216 = getelementptr inbounds i32, i32* %11213, i64 4
  %11217 = bitcast i32* %11216 to <4 x i32>*
  %11218 = load <4 x i32>, <4 x i32>* %11217, align 16
  %11219 = add <8 x i16> %11204, %11072
  %11220 = add <8 x i16> %11219, %11206
  %11221 = add <8 x i16> %11220, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11222 = lshr <8 x i16> %11221, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11223 = shufflevector <8 x i16> %11222, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11224 = shufflevector <8 x i16> %11222, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11225 = add <4 x i32> %11084, <i32 8, i32 8, i32 8, i32 8>
  %11226 = add <4 x i32> %11225, %11209
  %11227 = add <4 x i32> %11226, %11215
  %11228 = lshr <4 x i32> %11227, <i32 4, i32 4, i32 4, i32 4>
  %11229 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11223, <8 x i16> %11223) #5
  %11230 = mul nuw <4 x i32> %11228, <i32 9, i32 9, i32 9, i32 9>
  %11231 = sub <4 x i32> %11230, %11229
  %11232 = icmp sgt <4 x i32> %11231, zeroinitializer
  %11233 = select <4 x i1> %11232, <4 x i32> %11231, <4 x i32> zeroinitializer
  %11234 = mul <4 x i32> %11233, %6317
  %11235 = add <4 x i32> %11234, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11236 = lshr <4 x i32> %11235, <i32 20, i32 20, i32 20, i32 20>
  %11237 = add <4 x i32> %11095, <i32 8, i32 8, i32 8, i32 8>
  %11238 = add <4 x i32> %11237, %11212
  %11239 = add <4 x i32> %11238, %11218
  %11240 = lshr <4 x i32> %11239, <i32 4, i32 4, i32 4, i32 4>
  %11241 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11224, <8 x i16> %11224) #5
  %11242 = mul nuw <4 x i32> %11240, <i32 9, i32 9, i32 9, i32 9>
  %11243 = sub <4 x i32> %11242, %11241
  %11244 = icmp sgt <4 x i32> %11243, zeroinitializer
  %11245 = select <4 x i1> %11244, <4 x i32> %11243, <4 x i32> zeroinitializer
  %11246 = mul <4 x i32> %11245, %6317
  %11247 = add <4 x i32> %11246, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11248 = lshr <4 x i32> %11247, <i32 20, i32 20, i32 20, i32 20>
  %11249 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %11236, <4 x i32> %11248) #5
  %11250 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %11249, <8 x i16> undef) #5
  %11251 = bitcast <16 x i8> %11250 to <2 x i64>
  %11252 = extractelement <2 x i64> %11251, i32 0
  %11253 = lshr i64 %11252, 8
  %11254 = lshr i64 %11252, 16
  %11255 = lshr i64 %11252, 24
  %11256 = lshr i64 %11252, 32
  %11257 = lshr i64 %11252, 40
  %11258 = lshr i64 %11252, 48
  %11259 = lshr i64 %11252, 56
  %11260 = and i64 %11252, 255
  %11261 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11260
  %11262 = load i8, i8* %11261, align 1
  %11263 = insertelement <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, i8 %11262, i64 0
  %11264 = and i64 %11253, 255
  %11265 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11264
  %11266 = load i8, i8* %11265, align 1
  %11267 = insertelement <16 x i8> %11263, i8 %11266, i64 1
  %11268 = and i64 %11254, 255
  %11269 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11268
  %11270 = load i8, i8* %11269, align 1
  %11271 = insertelement <16 x i8> %11267, i8 %11270, i64 2
  %11272 = and i64 %11255, 255
  %11273 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11272
  %11274 = load i8, i8* %11273, align 1
  %11275 = insertelement <16 x i8> %11271, i8 %11274, i64 3
  %11276 = and i64 %11256, 255
  %11277 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11276
  %11278 = load i8, i8* %11277, align 1
  %11279 = insertelement <16 x i8> %11275, i8 %11278, i64 4
  %11280 = and i64 %11257, 255
  %11281 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11280
  %11282 = load i8, i8* %11281, align 1
  %11283 = insertelement <16 x i8> %11279, i8 %11282, i64 5
  %11284 = and i64 %11258, 255
  %11285 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11284
  %11286 = load i8, i8* %11285, align 1
  %11287 = insertelement <16 x i8> %11283, i8 %11286, i64 6
  %11288 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11259
  %11289 = load i8, i8* %11288, align 1
  %11290 = insertelement <16 x i8> %11287, i8 %11289, i64 7
  %11291 = shufflevector <16 x i8> %11290, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11292 = bitcast <16 x i8> %11291 to <8 x i16>
  %11293 = shufflevector <8 x i16> %11292, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11294 = shufflevector <8 x i16> %11220, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11295 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11293, <8 x i16> %11294) #5
  %11296 = shufflevector <8 x i16> %11292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11297 = shufflevector <8 x i16> %11220, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11298 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11296, <8 x i16> %11297) #5
  %11299 = mul <4 x i32> %11295, <i32 455, i32 455, i32 455, i32 455>
  %11300 = add <4 x i32> %11299, <i32 2048, i32 2048, i32 2048, i32 2048>
  %11301 = lshr <4 x i32> %11300, <i32 12, i32 12, i32 12, i32 12>
  %11302 = inttoptr i64 %11020 to i16*
  %11303 = inttoptr i64 %11019 to i16*
  %11304 = inttoptr i64 %11018 to i16*
  %11305 = inttoptr i64 %11015 to i16*
  %11306 = inttoptr i64 %11014 to i16*
  br label %11307

11307:                                            ; preds = %11307, %11013
  %11308 = phi i64 [ %11327, %11307 ], [ 0, %11013 ]
  %11309 = phi <2 x i64> [ %11332, %11307 ], [ %11050, %11013 ]
  %11310 = phi <16 x i8> [ %11809, %11307 ], [ %11290, %11013 ]
  %11311 = phi <16 x i8> [ %11688, %11307 ], [ <i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86, i8 -86>, %11013 ]
  %11312 = phi <16 x i8> [ %11688, %11307 ], [ %11192, %11013 ]
  %11313 = phi <4 x i32> [ %11560, %11307 ], [ %11059, %11013 ]
  %11314 = phi <4 x i32> [ %11559, %11307 ], [ %11058, %11013 ]
  %11315 = phi <4 x i32> [ %11804, %11307 ], [ %11298, %11013 ]
  %11316 = phi <4 x i32> [ %11807, %11307 ], [ %11301, %11013 ]
  %11317 = phi <4 x i32> [ %11696, %11307 ], [ %11200, %11013 ]
  %11318 = phi <4 x i32> [ %11698, %11307 ], [ %11202, %11013 ]
  %11319 = mul <4 x i32> %11315, <i32 455, i32 455, i32 455, i32 455>
  %11320 = add <4 x i32> %11319, <i32 2048, i32 2048, i32 2048, i32 2048>
  %11321 = lshr <4 x i32> %11320, <i32 12, i32 12, i32 12, i32 12>
  %11322 = add <4 x i32> %11317, <i32 512, i32 512, i32 512, i32 512>
  %11323 = lshr <4 x i32> %11322, <i32 10, i32 10, i32 10, i32 10>
  %11324 = bitcast <16 x i8> %11310 to <2 x i64>
  %11325 = getelementptr inbounds i16, i16* %11043, i64 %11308
  %11326 = getelementptr inbounds i16, i16* %11325, i64 16
  %11327 = add nuw nsw i64 %11308, 16
  %11328 = bitcast i16* %11326 to <2 x i64>*
  %11329 = load <2 x i64>, <2 x i64>* %11328, align 1
  %11330 = getelementptr inbounds i16, i16* %11325, i64 24
  %11331 = bitcast i16* %11330 to <2 x i64>*
  %11332 = load <2 x i64>, <2 x i64>* %11331, align 1
  %11333 = or i64 %11308, 8
  %11334 = bitcast <2 x i64> %11329 to <8 x i16>
  %11335 = shufflevector <8 x i16> %11334, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11336 = shufflevector <8 x i16> %11334, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11337 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11335, <8 x i16> %11335) #5
  %11338 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11336, <8 x i16> %11336) #5
  %11339 = bitcast <2 x i64> %11309 to <8 x i16>
  %11340 = bitcast <2 x i64> %11329 to <16 x i8>
  %11341 = bitcast <2 x i64> %11309 to <16 x i8>
  %11342 = shufflevector <16 x i8> %11341, <16 x i8> %11340, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %11343 = bitcast <16 x i8> %11342 to <8 x i16>
  %11344 = shufflevector <16 x i8> %11341, <16 x i8> %11340, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11345 = bitcast <16 x i8> %11344 to <8 x i16>
  %11346 = shufflevector <16 x i8> %11341, <16 x i8> %11340, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %11347 = bitcast <16 x i8> %11346 to <8 x i16>
  %11348 = shufflevector <16 x i8> %11341, <16 x i8> %11340, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11349 = bitcast <16 x i8> %11348 to <8 x i16>
  %11350 = add <8 x i16> %11349, %11339
  %11351 = add <8 x i16> %11345, %11343
  %11352 = add <8 x i16> %11351, %11347
  %11353 = add <8 x i16> %11350, %11352
  %11354 = bitcast <2 x i64> %11332 to <16 x i8>
  %11355 = shufflevector <16 x i8> %11340, <16 x i8> %11354, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %11356 = bitcast <16 x i8> %11355 to <8 x i16>
  %11357 = shufflevector <16 x i8> %11340, <16 x i8> %11354, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11358 = bitcast <16 x i8> %11357 to <8 x i16>
  %11359 = shufflevector <16 x i8> %11340, <16 x i8> %11354, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %11360 = bitcast <16 x i8> %11359 to <8 x i16>
  %11361 = shufflevector <16 x i8> %11340, <16 x i8> %11354, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11362 = bitcast <16 x i8> %11361 to <8 x i16>
  %11363 = add <8 x i16> %11362, %11334
  %11364 = add <8 x i16> %11358, %11356
  %11365 = add <8 x i16> %11364, %11360
  %11366 = add <8 x i16> %11363, %11365
  %11367 = bitcast <4 x i32> %11313 to <16 x i8>
  %11368 = bitcast <4 x i32> %11314 to <16 x i8>
  %11369 = shufflevector <16 x i8> %11368, <16 x i8> %11367, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11370 = bitcast <16 x i8> %11369 to <4 x i32>
  %11371 = shufflevector <16 x i8> %11368, <16 x i8> %11367, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11372 = bitcast <16 x i8> %11371 to <4 x i32>
  %11373 = shufflevector <16 x i8> %11368, <16 x i8> %11367, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %11374 = bitcast <16 x i8> %11373 to <4 x i32>
  %11375 = add <4 x i32> %11314, %11313
  %11376 = add <4 x i32> %11372, %11370
  %11377 = add <4 x i32> %11376, %11374
  %11378 = add <4 x i32> %11375, %11377
  %11379 = bitcast <4 x i32> %11337 to <16 x i8>
  %11380 = shufflevector <16 x i8> %11367, <16 x i8> %11379, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11381 = bitcast <16 x i8> %11380 to <4 x i32>
  %11382 = shufflevector <16 x i8> %11367, <16 x i8> %11379, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11383 = bitcast <16 x i8> %11382 to <4 x i32>
  %11384 = shufflevector <16 x i8> %11367, <16 x i8> %11379, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %11385 = bitcast <16 x i8> %11384 to <4 x i32>
  %11386 = add <4 x i32> %11337, %11313
  %11387 = add <4 x i32> %11383, %11381
  %11388 = add <4 x i32> %11387, %11385
  %11389 = add <4 x i32> %11386, %11388
  %11390 = getelementptr inbounds i16, i16* %11302, i64 %11333
  %11391 = bitcast i16* %11390 to <8 x i16>*
  %11392 = load <8 x i16>, <8 x i16>* %11391, align 16
  %11393 = getelementptr inbounds i16, i16* %11303, i64 %11333
  %11394 = bitcast i16* %11393 to <8 x i16>*
  %11395 = load <8 x i16>, <8 x i16>* %11394, align 16
  %11396 = getelementptr inbounds i16, i16* %11304, i64 %11333
  %11397 = bitcast i16* %11396 to <8 x i16>*
  %11398 = load <8 x i16>, <8 x i16>* %11397, align 16
  %11399 = getelementptr inbounds i32, i32* %11039, i64 %11333
  %11400 = bitcast i32* %11399 to <4 x i32>*
  %11401 = load <4 x i32>, <4 x i32>* %11400, align 16
  %11402 = getelementptr inbounds i32, i32* %11399, i64 4
  %11403 = bitcast i32* %11402 to <4 x i32>*
  %11404 = load <4 x i32>, <4 x i32>* %11403, align 16
  %11405 = getelementptr inbounds i32, i32* %11040, i64 %11333
  %11406 = bitcast i32* %11405 to <4 x i32>*
  %11407 = load <4 x i32>, <4 x i32>* %11406, align 16
  %11408 = getelementptr inbounds i32, i32* %11405, i64 4
  %11409 = bitcast i32* %11408 to <4 x i32>*
  %11410 = load <4 x i32>, <4 x i32>* %11409, align 16
  %11411 = getelementptr inbounds i32, i32* %11041, i64 %11333
  %11412 = bitcast i32* %11411 to <4 x i32>*
  %11413 = load <4 x i32>, <4 x i32>* %11412, align 16
  %11414 = getelementptr inbounds i32, i32* %11411, i64 4
  %11415 = bitcast i32* %11414 to <4 x i32>*
  %11416 = load <4 x i32>, <4 x i32>* %11415, align 16
  %11417 = shl <8 x i16> %11353, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %11418 = add <8 x i16> %11395, %11392
  %11419 = add <8 x i16> %11418, %11398
  %11420 = add <8 x i16> %11419, %11417
  %11421 = add <8 x i16> %11420, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11422 = lshr <8 x i16> %11421, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11423 = shufflevector <8 x i16> %11422, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11424 = shufflevector <8 x i16> %11422, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11425 = shl <4 x i32> %11378, <i32 1, i32 1, i32 1, i32 1>
  %11426 = add <4 x i32> %11425, <i32 8, i32 8, i32 8, i32 8>
  %11427 = add <4 x i32> %11426, %11401
  %11428 = add <4 x i32> %11427, %11407
  %11429 = add <4 x i32> %11428, %11413
  %11430 = lshr <4 x i32> %11429, <i32 4, i32 4, i32 4, i32 4>
  %11431 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11423, <8 x i16> %11423) #5
  %11432 = mul <4 x i32> %11430, <i32 25, i32 25, i32 25, i32 25>
  %11433 = sub <4 x i32> %11432, %11431
  %11434 = icmp sgt <4 x i32> %11433, zeroinitializer
  %11435 = select <4 x i1> %11434, <4 x i32> %11433, <4 x i32> zeroinitializer
  %11436 = mul <4 x i32> %11435, %6442
  %11437 = add <4 x i32> %11436, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11438 = lshr <4 x i32> %11437, <i32 20, i32 20, i32 20, i32 20>
  %11439 = shl <4 x i32> %11389, <i32 1, i32 1, i32 1, i32 1>
  %11440 = add <4 x i32> %11404, <i32 8, i32 8, i32 8, i32 8>
  %11441 = add <4 x i32> %11440, %11439
  %11442 = add <4 x i32> %11441, %11410
  %11443 = add <4 x i32> %11442, %11416
  %11444 = lshr <4 x i32> %11443, <i32 4, i32 4, i32 4, i32 4>
  %11445 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11424, <8 x i16> %11424) #5
  %11446 = mul <4 x i32> %11444, <i32 25, i32 25, i32 25, i32 25>
  %11447 = sub <4 x i32> %11446, %11445
  %11448 = icmp sgt <4 x i32> %11447, zeroinitializer
  %11449 = select <4 x i1> %11448, <4 x i32> %11447, <4 x i32> zeroinitializer
  %11450 = mul <4 x i32> %11449, %6442
  %11451 = add <4 x i32> %11450, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11452 = lshr <4 x i32> %11451, <i32 20, i32 20, i32 20, i32 20>
  %11453 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %11438, <4 x i32> %11452) #5
  %11454 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %11453, <8 x i16> undef) #5
  %11455 = bitcast <16 x i8> %11454 to <2 x i64>
  %11456 = extractelement <2 x i64> %11455, i32 0
  %11457 = lshr i64 %11456, 8
  %11458 = lshr i64 %11456, 16
  %11459 = lshr i64 %11456, 24
  %11460 = lshr i64 %11456, 32
  %11461 = lshr i64 %11456, 40
  %11462 = lshr i64 %11456, 48
  %11463 = lshr i64 %11456, 56
  %11464 = and i64 %11456, 255
  %11465 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11464
  %11466 = load i8, i8* %11465, align 1
  %11467 = insertelement <16 x i8> %11312, i8 %11466, i64 8
  %11468 = and i64 %11457, 255
  %11469 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11468
  %11470 = load i8, i8* %11469, align 1
  %11471 = insertelement <16 x i8> %11467, i8 %11470, i64 9
  %11472 = and i64 %11458, 255
  %11473 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11472
  %11474 = load i8, i8* %11473, align 1
  %11475 = insertelement <16 x i8> %11471, i8 %11474, i64 10
  %11476 = and i64 %11459, 255
  %11477 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11476
  %11478 = load i8, i8* %11477, align 1
  %11479 = insertelement <16 x i8> %11475, i8 %11478, i64 11
  %11480 = and i64 %11460, 255
  %11481 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11480
  %11482 = load i8, i8* %11481, align 1
  %11483 = insertelement <16 x i8> %11479, i8 %11482, i64 12
  %11484 = and i64 %11461, 255
  %11485 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11484
  %11486 = load i8, i8* %11485, align 1
  %11487 = insertelement <16 x i8> %11483, i8 %11486, i64 13
  %11488 = and i64 %11462, 255
  %11489 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11488
  %11490 = load i8, i8* %11489, align 1
  %11491 = insertelement <16 x i8> %11487, i8 %11490, i64 14
  %11492 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11463
  %11493 = load i8, i8* %11492, align 1
  %11494 = insertelement <16 x i8> %11491, i8 %11493, i64 15
  %11495 = shufflevector <16 x i8> %11494, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %11496 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %11495, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %11497 = shufflevector <8 x i16> %11496, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11498 = shufflevector <8 x i16> %11420, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11499 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11497, <8 x i16> %11498) #5
  %11500 = shufflevector <8 x i16> %11496, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11501 = shufflevector <8 x i16> %11420, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11502 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11500, <8 x i16> %11501) #5
  %11503 = add <4 x i32> %11499, <i32 512, i32 512, i32 512, i32 512>
  %11504 = lshr <4 x i32> %11503, <i32 10, i32 10, i32 10, i32 10>
  %11505 = add <4 x i32> %11502, <i32 512, i32 512, i32 512, i32 512>
  %11506 = lshr <4 x i32> %11505, <i32 10, i32 10, i32 10, i32 10>
  %11507 = getelementptr inbounds i16, i16* %11305, i64 %11333
  %11508 = bitcast i16* %11507 to <8 x i16>*
  %11509 = load <8 x i16>, <8 x i16>* %11508, align 16
  %11510 = getelementptr inbounds i16, i16* %11306, i64 %11333
  %11511 = bitcast i16* %11510 to <8 x i16>*
  %11512 = load <8 x i16>, <8 x i16>* %11511, align 16
  %11513 = getelementptr inbounds i32, i32* %11207, i64 %11333
  %11514 = bitcast i32* %11513 to <4 x i32>*
  %11515 = load <4 x i32>, <4 x i32>* %11514, align 16
  %11516 = getelementptr inbounds i32, i32* %11513, i64 4
  %11517 = bitcast i32* %11516 to <4 x i32>*
  %11518 = load <4 x i32>, <4 x i32>* %11517, align 16
  %11519 = getelementptr inbounds i32, i32* %11213, i64 %11333
  %11520 = bitcast i32* %11519 to <4 x i32>*
  %11521 = load <4 x i32>, <4 x i32>* %11520, align 16
  %11522 = getelementptr inbounds i32, i32* %11519, i64 4
  %11523 = bitcast i32* %11522 to <4 x i32>*
  %11524 = load <4 x i32>, <4 x i32>* %11523, align 16
  %11525 = add <8 x i16> %11509, %11352
  %11526 = add <8 x i16> %11525, %11512
  %11527 = add <8 x i16> %11526, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11528 = lshr <8 x i16> %11527, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11529 = shufflevector <8 x i16> %11528, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11530 = shufflevector <8 x i16> %11528, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11531 = add <4 x i32> %11377, <i32 8, i32 8, i32 8, i32 8>
  %11532 = add <4 x i32> %11531, %11515
  %11533 = add <4 x i32> %11532, %11521
  %11534 = lshr <4 x i32> %11533, <i32 4, i32 4, i32 4, i32 4>
  %11535 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11529, <8 x i16> %11529) #5
  %11536 = mul nuw <4 x i32> %11534, <i32 9, i32 9, i32 9, i32 9>
  %11537 = sub <4 x i32> %11536, %11535
  %11538 = icmp sgt <4 x i32> %11537, zeroinitializer
  %11539 = select <4 x i1> %11538, <4 x i32> %11537, <4 x i32> zeroinitializer
  %11540 = mul <4 x i32> %11539, %6317
  %11541 = add <4 x i32> %11540, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11542 = lshr <4 x i32> %11541, <i32 20, i32 20, i32 20, i32 20>
  %11543 = add <4 x i32> %11388, <i32 8, i32 8, i32 8, i32 8>
  %11544 = add <4 x i32> %11543, %11518
  %11545 = add <4 x i32> %11544, %11524
  %11546 = lshr <4 x i32> %11545, <i32 4, i32 4, i32 4, i32 4>
  %11547 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11530, <8 x i16> %11530) #5
  %11548 = mul nuw <4 x i32> %11546, <i32 9, i32 9, i32 9, i32 9>
  %11549 = sub <4 x i32> %11548, %11547
  %11550 = icmp sgt <4 x i32> %11549, zeroinitializer
  %11551 = select <4 x i1> %11550, <4 x i32> %11549, <4 x i32> zeroinitializer
  %11552 = mul <4 x i32> %11551, %6317
  %11553 = add <4 x i32> %11552, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11554 = lshr <4 x i32> %11553, <i32 20, i32 20, i32 20, i32 20>
  %11555 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %11542, <4 x i32> %11554) #5
  %11556 = bitcast <2 x i64> %11332 to <8 x i16>
  %11557 = shufflevector <8 x i16> %11556, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11558 = shufflevector <8 x i16> %11556, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11559 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11557, <8 x i16> %11557) #5
  %11560 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11558, <8 x i16> %11558) #5
  %11561 = bitcast <4 x i32> %11338 to <16 x i8>
  %11562 = shufflevector <16 x i8> %11379, <16 x i8> %11561, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11563 = bitcast <16 x i8> %11562 to <4 x i32>
  %11564 = shufflevector <16 x i8> %11379, <16 x i8> %11561, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11565 = bitcast <16 x i8> %11564 to <4 x i32>
  %11566 = shufflevector <16 x i8> %11379, <16 x i8> %11561, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %11567 = bitcast <16 x i8> %11566 to <4 x i32>
  %11568 = add <4 x i32> %11338, %11337
  %11569 = add <4 x i32> %11565, %11563
  %11570 = add <4 x i32> %11569, %11567
  %11571 = add <4 x i32> %11568, %11570
  %11572 = bitcast <4 x i32> %11559 to <16 x i8>
  %11573 = shufflevector <16 x i8> %11561, <16 x i8> %11572, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11574 = bitcast <16 x i8> %11573 to <4 x i32>
  %11575 = shufflevector <16 x i8> %11561, <16 x i8> %11572, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11576 = bitcast <16 x i8> %11575 to <4 x i32>
  %11577 = shufflevector <16 x i8> %11561, <16 x i8> %11572, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %11578 = bitcast <16 x i8> %11577 to <4 x i32>
  %11579 = add <4 x i32> %11559, %11338
  %11580 = add <4 x i32> %11576, %11574
  %11581 = add <4 x i32> %11580, %11578
  %11582 = add <4 x i32> %11579, %11581
  %11583 = add nuw nsw i64 %11333, 8
  %11584 = getelementptr inbounds i16, i16* %11302, i64 %11583
  %11585 = bitcast i16* %11584 to <8 x i16>*
  %11586 = load <8 x i16>, <8 x i16>* %11585, align 16
  %11587 = getelementptr inbounds i16, i16* %11303, i64 %11583
  %11588 = bitcast i16* %11587 to <8 x i16>*
  %11589 = load <8 x i16>, <8 x i16>* %11588, align 16
  %11590 = getelementptr inbounds i16, i16* %11304, i64 %11583
  %11591 = bitcast i16* %11590 to <8 x i16>*
  %11592 = load <8 x i16>, <8 x i16>* %11591, align 16
  %11593 = getelementptr inbounds i32, i32* %11039, i64 %11583
  %11594 = bitcast i32* %11593 to <4 x i32>*
  %11595 = load <4 x i32>, <4 x i32>* %11594, align 16
  %11596 = getelementptr inbounds i32, i32* %11593, i64 4
  %11597 = bitcast i32* %11596 to <4 x i32>*
  %11598 = load <4 x i32>, <4 x i32>* %11597, align 16
  %11599 = getelementptr inbounds i32, i32* %11040, i64 %11583
  %11600 = bitcast i32* %11599 to <4 x i32>*
  %11601 = load <4 x i32>, <4 x i32>* %11600, align 16
  %11602 = getelementptr inbounds i32, i32* %11599, i64 4
  %11603 = bitcast i32* %11602 to <4 x i32>*
  %11604 = load <4 x i32>, <4 x i32>* %11603, align 16
  %11605 = getelementptr inbounds i32, i32* %11041, i64 %11583
  %11606 = bitcast i32* %11605 to <4 x i32>*
  %11607 = load <4 x i32>, <4 x i32>* %11606, align 16
  %11608 = getelementptr inbounds i32, i32* %11605, i64 4
  %11609 = bitcast i32* %11608 to <4 x i32>*
  %11610 = load <4 x i32>, <4 x i32>* %11609, align 16
  %11611 = shl <8 x i16> %11366, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %11612 = add <8 x i16> %11586, %11611
  %11613 = add <8 x i16> %11612, %11589
  %11614 = add <8 x i16> %11613, %11592
  %11615 = add <8 x i16> %11614, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11616 = lshr <8 x i16> %11615, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11617 = shufflevector <8 x i16> %11616, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11618 = shufflevector <8 x i16> %11616, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11619 = shl <4 x i32> %11571, <i32 1, i32 1, i32 1, i32 1>
  %11620 = add <4 x i32> %11619, <i32 8, i32 8, i32 8, i32 8>
  %11621 = add <4 x i32> %11620, %11595
  %11622 = add <4 x i32> %11621, %11601
  %11623 = add <4 x i32> %11622, %11607
  %11624 = lshr <4 x i32> %11623, <i32 4, i32 4, i32 4, i32 4>
  %11625 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11617, <8 x i16> %11617) #5
  %11626 = mul <4 x i32> %11624, <i32 25, i32 25, i32 25, i32 25>
  %11627 = sub <4 x i32> %11626, %11625
  %11628 = icmp sgt <4 x i32> %11627, zeroinitializer
  %11629 = select <4 x i1> %11628, <4 x i32> %11627, <4 x i32> zeroinitializer
  %11630 = mul <4 x i32> %11629, %6442
  %11631 = add <4 x i32> %11630, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11632 = lshr <4 x i32> %11631, <i32 20, i32 20, i32 20, i32 20>
  %11633 = shl <4 x i32> %11582, <i32 1, i32 1, i32 1, i32 1>
  %11634 = add <4 x i32> %11598, <i32 8, i32 8, i32 8, i32 8>
  %11635 = add <4 x i32> %11634, %11633
  %11636 = add <4 x i32> %11635, %11604
  %11637 = add <4 x i32> %11636, %11610
  %11638 = lshr <4 x i32> %11637, <i32 4, i32 4, i32 4, i32 4>
  %11639 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11618, <8 x i16> %11618) #5
  %11640 = mul <4 x i32> %11638, <i32 25, i32 25, i32 25, i32 25>
  %11641 = sub <4 x i32> %11640, %11639
  %11642 = icmp sgt <4 x i32> %11641, zeroinitializer
  %11643 = select <4 x i1> %11642, <4 x i32> %11641, <4 x i32> zeroinitializer
  %11644 = mul <4 x i32> %11643, %6442
  %11645 = add <4 x i32> %11644, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11646 = lshr <4 x i32> %11645, <i32 20, i32 20, i32 20, i32 20>
  %11647 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %11632, <4 x i32> %11646) #5
  %11648 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %11647, <8 x i16> undef) #5
  %11649 = bitcast <16 x i8> %11648 to <2 x i64>
  %11650 = extractelement <2 x i64> %11649, i32 0
  %11651 = lshr i64 %11650, 8
  %11652 = lshr i64 %11650, 16
  %11653 = lshr i64 %11650, 24
  %11654 = lshr i64 %11650, 32
  %11655 = lshr i64 %11650, 40
  %11656 = lshr i64 %11650, 48
  %11657 = lshr i64 %11650, 56
  %11658 = and i64 %11650, 255
  %11659 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11658
  %11660 = load i8, i8* %11659, align 1
  %11661 = insertelement <16 x i8> %11311, i8 %11660, i64 0
  %11662 = and i64 %11651, 255
  %11663 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11662
  %11664 = load i8, i8* %11663, align 1
  %11665 = insertelement <16 x i8> %11661, i8 %11664, i64 1
  %11666 = and i64 %11652, 255
  %11667 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11666
  %11668 = load i8, i8* %11667, align 1
  %11669 = insertelement <16 x i8> %11665, i8 %11668, i64 2
  %11670 = and i64 %11653, 255
  %11671 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11670
  %11672 = load i8, i8* %11671, align 1
  %11673 = insertelement <16 x i8> %11669, i8 %11672, i64 3
  %11674 = and i64 %11654, 255
  %11675 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11674
  %11676 = load i8, i8* %11675, align 1
  %11677 = insertelement <16 x i8> %11673, i8 %11676, i64 4
  %11678 = and i64 %11655, 255
  %11679 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11678
  %11680 = load i8, i8* %11679, align 1
  %11681 = insertelement <16 x i8> %11677, i8 %11680, i64 5
  %11682 = and i64 %11656, 255
  %11683 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11682
  %11684 = load i8, i8* %11683, align 1
  %11685 = insertelement <16 x i8> %11681, i8 %11684, i64 6
  %11686 = getelementptr inbounds [256 x i8], [256 x i8]* @_ZN7libgav13dsp12kSgrMaLookupE, i64 0, i64 %11657
  %11687 = load i8, i8* %11686, align 1
  %11688 = insertelement <16 x i8> %11685, i8 %11687, i64 7
  %11689 = shufflevector <16 x i8> %11688, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11690 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %11689, <16 x i8> <i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0, i8 41, i8 0>) #5
  %11691 = shufflevector <8 x i16> %11690, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11692 = shufflevector <8 x i16> %11614, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11693 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11691, <8 x i16> %11692) #5
  %11694 = shufflevector <8 x i16> %11690, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11695 = shufflevector <8 x i16> %11614, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11696 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11694, <8 x i16> %11695) #5
  %11697 = add <4 x i32> %11693, <i32 512, i32 512, i32 512, i32 512>
  %11698 = lshr <4 x i32> %11697, <i32 10, i32 10, i32 10, i32 10>
  %11699 = getelementptr inbounds i16, i16* %11305, i64 %11583
  %11700 = bitcast i16* %11699 to <8 x i16>*
  %11701 = load <8 x i16>, <8 x i16>* %11700, align 16
  %11702 = getelementptr inbounds i16, i16* %11306, i64 %11583
  %11703 = bitcast i16* %11702 to <8 x i16>*
  %11704 = load <8 x i16>, <8 x i16>* %11703, align 16
  %11705 = getelementptr inbounds i32, i32* %11207, i64 %11583
  %11706 = bitcast i32* %11705 to <4 x i32>*
  %11707 = load <4 x i32>, <4 x i32>* %11706, align 16
  %11708 = getelementptr inbounds i32, i32* %11705, i64 4
  %11709 = bitcast i32* %11708 to <4 x i32>*
  %11710 = load <4 x i32>, <4 x i32>* %11709, align 16
  %11711 = getelementptr inbounds i32, i32* %11213, i64 %11583
  %11712 = bitcast i32* %11711 to <4 x i32>*
  %11713 = load <4 x i32>, <4 x i32>* %11712, align 16
  %11714 = getelementptr inbounds i32, i32* %11711, i64 4
  %11715 = bitcast i32* %11714 to <4 x i32>*
  %11716 = load <4 x i32>, <4 x i32>* %11715, align 16
  %11717 = add <8 x i16> %11701, %11365
  %11718 = add <8 x i16> %11717, %11704
  %11719 = add <8 x i16> %11718, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11720 = lshr <8 x i16> %11719, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11721 = shufflevector <8 x i16> %11720, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11722 = shufflevector <8 x i16> %11720, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11723 = add <4 x i32> %11570, <i32 8, i32 8, i32 8, i32 8>
  %11724 = add <4 x i32> %11723, %11707
  %11725 = add <4 x i32> %11724, %11713
  %11726 = lshr <4 x i32> %11725, <i32 4, i32 4, i32 4, i32 4>
  %11727 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11721, <8 x i16> %11721) #5
  %11728 = mul nuw <4 x i32> %11726, <i32 9, i32 9, i32 9, i32 9>
  %11729 = sub <4 x i32> %11728, %11727
  %11730 = icmp sgt <4 x i32> %11729, zeroinitializer
  %11731 = select <4 x i1> %11730, <4 x i32> %11729, <4 x i32> zeroinitializer
  %11732 = mul <4 x i32> %11731, %6317
  %11733 = add <4 x i32> %11732, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11734 = lshr <4 x i32> %11733, <i32 20, i32 20, i32 20, i32 20>
  %11735 = add <4 x i32> %11581, <i32 8, i32 8, i32 8, i32 8>
  %11736 = add <4 x i32> %11735, %11710
  %11737 = add <4 x i32> %11736, %11716
  %11738 = lshr <4 x i32> %11737, <i32 4, i32 4, i32 4, i32 4>
  %11739 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11722, <8 x i16> %11722) #5
  %11740 = mul nuw <4 x i32> %11738, <i32 9, i32 9, i32 9, i32 9>
  %11741 = sub <4 x i32> %11740, %11739
  %11742 = icmp sgt <4 x i32> %11741, zeroinitializer
  %11743 = select <4 x i1> %11742, <4 x i32> %11741, <4 x i32> zeroinitializer
  %11744 = mul <4 x i32> %11743, %6317
  %11745 = add <4 x i32> %11744, <i32 524288, i32 524288, i32 524288, i32 524288>
  %11746 = lshr <4 x i32> %11745, <i32 20, i32 20, i32 20, i32 20>
  %11747 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %11734, <4 x i32> %11746) #5
  %11748 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %11555, <8 x i16> %11747) #5
  %11749 = icmp ult <16 x i8> %11748, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %11750 = select <16 x i1> %11749, <16 x i8> %11748, <16 x i8> <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %11751 = icmp sgt <16 x i8> %11750, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %11752 = select <16 x i1> %11751, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %11750
  %11753 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6360, <16 x i8> %11752) #5
  %11754 = add nsw <16 x i8> %11750, <i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16, i8 -16>
  %11755 = icmp sgt <16 x i8> %11754, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %11756 = select <16 x i1> %11755, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %11754
  %11757 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6361, <16 x i8> %11756) #5
  %11758 = or <16 x i8> %11757, %11753
  %11759 = add nsw <16 x i8> %11750, <i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32, i8 -32>
  %11760 = icmp sgt <16 x i8> %11759, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %11761 = select <16 x i1> %11760, <16 x i8> <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>, <16 x i8> %11759
  %11762 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6362, <16 x i8> %11761) #5
  %11763 = or <16 x i8> %11758, %11762
  %11764 = xor <16 x i8> %11748, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %11765 = icmp ugt <16 x i8> %11763, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %11766 = select <16 x i1> %11765, <16 x i8> %11763, <16 x i8> <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %11767 = icmp sgt <16 x i8> %11764, <i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73, i8 -73>
  %11768 = icmp sgt <16 x i8> %11764, <i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56, i8 -56>
  %11769 = sext <16 x i1> %11768 to <16 x i8>
  %11770 = icmp sgt <16 x i8> %11764, <i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27, i8 -27>
  %11771 = icmp sgt <16 x i8> %11764, <i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41, i8 41>
  %11772 = icmp eq <16 x i8> %11764, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %11773 = zext <16 x i1> %11767 to <16 x i8>
  %11774 = sub nsw <16 x i8> %11769, %11773
  %11775 = zext <16 x i1> %11770 to <16 x i8>
  %11776 = sub nsw <16 x i8> %11774, %11775
  %11777 = zext <16 x i1> %11771 to <16 x i8>
  %11778 = sub nsw <16 x i8> %11776, %11777
  %11779 = zext <16 x i1> %11772 to <16 x i8>
  %11780 = sub nsw <16 x i8> %11778, %11779
  %11781 = add <16 x i8> %11780, %11766
  %11782 = bitcast <16 x i8> %11781 to <2 x i64>
  %11783 = shufflevector <16 x i8> %11781, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11784 = bitcast <16 x i8> %11783 to <8 x i16>
  %11785 = shufflevector <8 x i16> %11784, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11786 = shufflevector <8 x i16> %11526, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11787 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11785, <8 x i16> %11786) #5
  %11788 = shufflevector <8 x i16> %11784, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11789 = shufflevector <8 x i16> %11526, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11790 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11788, <8 x i16> %11789) #5
  %11791 = mul <4 x i32> %11787, <i32 455, i32 455, i32 455, i32 455>
  %11792 = mul <4 x i32> %11790, <i32 455, i32 455, i32 455, i32 455>
  %11793 = add <4 x i32> %11791, <i32 2048, i32 2048, i32 2048, i32 2048>
  %11794 = lshr <4 x i32> %11793, <i32 12, i32 12, i32 12, i32 12>
  %11795 = add <4 x i32> %11792, <i32 2048, i32 2048, i32 2048, i32 2048>
  %11796 = lshr <4 x i32> %11795, <i32 12, i32 12, i32 12, i32 12>
  %11797 = shufflevector <16 x i8> %11781, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %11798 = bitcast <16 x i8> %11797 to <8 x i16>
  %11799 = shufflevector <8 x i16> %11798, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11800 = shufflevector <8 x i16> %11718, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11801 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11799, <8 x i16> %11800) #5
  %11802 = shufflevector <8 x i16> %11798, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11803 = shufflevector <8 x i16> %11718, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11804 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11802, <8 x i16> %11803) #5
  %11805 = mul <4 x i32> %11801, <i32 455, i32 455, i32 455, i32 455>
  %11806 = add <4 x i32> %11805, <i32 2048, i32 2048, i32 2048, i32 2048>
  %11807 = lshr <4 x i32> %11806, <i32 12, i32 12, i32 12, i32 12>
  %11808 = shufflevector <2 x i64> %11324, <2 x i64> %11782, <2 x i32> <i32 0, i32 2>
  %11809 = shufflevector <16 x i8> %11781, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11810 = bitcast <2 x i64> %11808 to <16 x i8>
  %11811 = shufflevector <16 x i8> %11810, <16 x i8> %11809, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %11812 = shufflevector <16 x i8> %11810, <16 x i8> %11809, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %11813 = shufflevector <16 x i8> %11494, <16 x i8> %11688, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16>
  %11814 = shufflevector <16 x i8> %11494, <16 x i8> %11688, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %11815 = shufflevector <16 x i8> %11494, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11816 = shufflevector <16 x i8> %11813, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11817 = bitcast <16 x i8> %11815 to <8 x i16>
  %11818 = bitcast <16 x i8> %11816 to <8 x i16>
  %11819 = add <8 x i16> %11818, %11817
  %11820 = shufflevector <16 x i8> %11814, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11821 = bitcast <16 x i8> %11820 to <8 x i16>
  %11822 = add <8 x i16> %11819, %11821
  %11823 = mul <8 x i16> %11822, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %11824 = add <8 x i16> %11823, %11818
  %11825 = bitcast <4 x i32> %11323 to <16 x i8>
  %11826 = bitcast <4 x i32> %11318 to <16 x i8>
  %11827 = shufflevector <16 x i8> %11826, <16 x i8> %11825, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11828 = bitcast <16 x i8> %11827 to <4 x i32>
  %11829 = shufflevector <16 x i8> %11826, <16 x i8> %11825, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11830 = bitcast <16 x i8> %11829 to <4 x i32>
  %11831 = add <4 x i32> %11318, %11828
  %11832 = add <4 x i32> %11831, %11830
  %11833 = mul <4 x i32> %11832, <i32 5, i32 5, i32 5, i32 5>
  %11834 = bitcast <4 x i32> %11504 to <16 x i8>
  %11835 = shufflevector <16 x i8> %11825, <16 x i8> %11834, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11836 = bitcast <16 x i8> %11835 to <4 x i32>
  %11837 = shufflevector <16 x i8> %11825, <16 x i8> %11834, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11838 = bitcast <16 x i8> %11837 to <4 x i32>
  %11839 = add <4 x i32> %11323, %11836
  %11840 = add <4 x i32> %11839, %11838
  %11841 = mul <4 x i32> %11840, <i32 5, i32 5, i32 5, i32 5>
  %11842 = shufflevector <16 x i8> %11810, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11843 = shufflevector <16 x i8> %11811, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11844 = bitcast <16 x i8> %11842 to <8 x i16>
  %11845 = bitcast <16 x i8> %11843 to <8 x i16>
  %11846 = add <8 x i16> %11845, %11844
  %11847 = shufflevector <16 x i8> %11812, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %11848 = bitcast <16 x i8> %11847 to <8 x i16>
  %11849 = add <8 x i16> %11846, %11848
  %11850 = mul <8 x i16> %11849, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %11851 = bitcast <4 x i32> %11321 to <16 x i8>
  %11852 = bitcast <4 x i32> %11316 to <16 x i8>
  %11853 = shufflevector <16 x i8> %11852, <16 x i8> %11851, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11854 = bitcast <16 x i8> %11853 to <4 x i32>
  %11855 = shufflevector <16 x i8> %11852, <16 x i8> %11851, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11856 = bitcast <16 x i8> %11855 to <4 x i32>
  %11857 = add <4 x i32> %11316, %11854
  %11858 = add <4 x i32> %11857, %11856
  %11859 = mul <4 x i32> %11858, <i32 3, i32 3, i32 3, i32 3>
  %11860 = bitcast <4 x i32> %11794 to <16 x i8>
  %11861 = shufflevector <16 x i8> %11851, <16 x i8> %11860, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11862 = bitcast <16 x i8> %11861 to <4 x i32>
  %11863 = shufflevector <16 x i8> %11851, <16 x i8> %11860, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11864 = bitcast <16 x i8> %11863 to <4 x i32>
  %11865 = add <4 x i32> %11321, %11862
  %11866 = add <4 x i32> %11865, %11864
  %11867 = mul <4 x i32> %11866, <i32 3, i32 3, i32 3, i32 3>
  %11868 = getelementptr inbounds i16, i16* %11042, i64 %11308
  %11869 = bitcast i16* %11868 to <8 x i16>*
  %11870 = load <8 x i16>, <8 x i16>* %11869, align 16
  %11871 = getelementptr inbounds i16, i16* %11044, i64 %11308
  %11872 = bitcast i16* %11871 to <8 x i16>*
  %11873 = load <8 x i16>, <8 x i16>* %11872, align 16
  %11874 = getelementptr inbounds i32, i32* %11045, i64 %11308
  %11875 = bitcast i32* %11874 to <4 x i32>*
  %11876 = load <4 x i32>, <4 x i32>* %11875, align 16
  %11877 = getelementptr inbounds i32, i32* %11874, i64 4
  %11878 = bitcast i32* %11877 to <4 x i32>*
  %11879 = load <4 x i32>, <4 x i32>* %11878, align 16
  %11880 = add <8 x i16> %11824, %11873
  %11881 = shufflevector <8 x i16> %11880, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11882 = shufflevector <8 x i16> %11870, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11883 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11881, <8 x i16> %11882) #5
  %11884 = shufflevector <8 x i16> %11880, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11885 = shufflevector <8 x i16> %11870, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11886 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11884, <8 x i16> %11885) #5
  %11887 = add <4 x i32> %11828, <i32 256, i32 256, i32 256, i32 256>
  %11888 = add <4 x i32> %11887, %11833
  %11889 = add <4 x i32> %11888, %11876
  %11890 = sub <4 x i32> %11889, %11883
  %11891 = ashr <4 x i32> %11890, <i32 9, i32 9, i32 9, i32 9>
  %11892 = add <4 x i32> %11836, <i32 256, i32 256, i32 256, i32 256>
  %11893 = add <4 x i32> %11892, %11841
  %11894 = add <4 x i32> %11893, %11879
  %11895 = sub <4 x i32> %11894, %11886
  %11896 = ashr <4 x i32> %11895, <i32 9, i32 9, i32 9, i32 9>
  %11897 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %11891, <4 x i32> %11896) #5
  %11898 = getelementptr inbounds i16, i16* %11032, i64 %11308
  %11899 = bitcast i16* %11898 to <8 x i16>*
  %11900 = load <8 x i16>, <8 x i16>* %11899, align 16
  %11901 = getelementptr inbounds i16, i16* %11033, i64 %11308
  %11902 = bitcast i16* %11901 to <8 x i16>*
  %11903 = load <8 x i16>, <8 x i16>* %11902, align 16
  %11904 = getelementptr inbounds i32, i32* %11034, i64 %11308
  %11905 = bitcast i32* %11904 to <4 x i32>*
  %11906 = load <4 x i32>, <4 x i32>* %11905, align 16
  %11907 = getelementptr inbounds i32, i32* %11904, i64 4
  %11908 = bitcast i32* %11907 to <4 x i32>*
  %11909 = load <4 x i32>, <4 x i32>* %11908, align 16
  %11910 = getelementptr inbounds i32, i32* %11035, i64 %11308
  %11911 = bitcast i32* %11910 to <4 x i32>*
  %11912 = load <4 x i32>, <4 x i32>* %11911, align 16
  %11913 = getelementptr inbounds i32, i32* %11910, i64 4
  %11914 = bitcast i32* %11913 to <4 x i32>*
  %11915 = load <4 x i32>, <4 x i32>* %11914, align 16
  %11916 = add <8 x i16> %11900, %11845
  %11917 = add <8 x i16> %11916, %11903
  %11918 = add <8 x i16> %11917, %11850
  %11919 = shufflevector <8 x i16> %11918, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11920 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11919, <8 x i16> %11882) #5
  %11921 = shufflevector <8 x i16> %11918, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11922 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11921, <8 x i16> %11885) #5
  %11923 = add <4 x i32> %11854, <i32 256, i32 256, i32 256, i32 256>
  %11924 = add <4 x i32> %11923, %11859
  %11925 = add <4 x i32> %11924, %11906
  %11926 = add <4 x i32> %11925, %11912
  %11927 = sub <4 x i32> %11926, %11920
  %11928 = ashr <4 x i32> %11927, <i32 9, i32 9, i32 9, i32 9>
  %11929 = add <4 x i32> %11862, <i32 256, i32 256, i32 256, i32 256>
  %11930 = add <4 x i32> %11929, %11867
  %11931 = add <4 x i32> %11930, %11909
  %11932 = add <4 x i32> %11931, %11915
  %11933 = sub <4 x i32> %11932, %11922
  %11934 = ashr <4 x i32> %11933, <i32 9, i32 9, i32 9, i32 9>
  %11935 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %11928, <4 x i32> %11934) #5
  %11936 = shufflevector <8 x i16> %11897, <8 x i16> %11935, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11937 = shufflevector <8 x i16> %11897, <8 x i16> %11935, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11938 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %11936) #5
  %11939 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %11937) #5
  %11940 = add <4 x i32> %11938, <i32 1024, i32 1024, i32 1024, i32 1024>
  %11941 = ashr <4 x i32> %11940, <i32 11, i32 11, i32 11, i32 11>
  %11942 = add <4 x i32> %11939, <i32 1024, i32 1024, i32 1024, i32 1024>
  %11943 = ashr <4 x i32> %11942, <i32 11, i32 11, i32 11, i32 11>
  %11944 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %11941, <4 x i32> %11943) #5
  %11945 = add <8 x i16> %11944, %11870
  %11946 = shufflevector <16 x i8> %11813, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %11947 = bitcast <16 x i8> %11495 to <8 x i16>
  %11948 = bitcast <16 x i8> %11946 to <8 x i16>
  %11949 = add <8 x i16> %11948, %11947
  %11950 = shufflevector <16 x i8> %11814, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %11951 = bitcast <16 x i8> %11950 to <8 x i16>
  %11952 = add <8 x i16> %11949, %11951
  %11953 = mul <8 x i16> %11952, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %11954 = add <8 x i16> %11953, %11948
  %11955 = bitcast <4 x i32> %11506 to <16 x i8>
  %11956 = shufflevector <16 x i8> %11834, <16 x i8> %11955, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11957 = bitcast <16 x i8> %11956 to <4 x i32>
  %11958 = shufflevector <16 x i8> %11834, <16 x i8> %11955, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11959 = bitcast <16 x i8> %11958 to <4 x i32>
  %11960 = add <4 x i32> %11504, %11957
  %11961 = add <4 x i32> %11960, %11959
  %11962 = mul <4 x i32> %11961, <i32 5, i32 5, i32 5, i32 5>
  %11963 = bitcast <4 x i32> %11698 to <16 x i8>
  %11964 = shufflevector <16 x i8> %11955, <16 x i8> %11963, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11965 = bitcast <16 x i8> %11964 to <4 x i32>
  %11966 = shufflevector <16 x i8> %11955, <16 x i8> %11963, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11967 = bitcast <16 x i8> %11966 to <4 x i32>
  %11968 = add <4 x i32> %11506, %11965
  %11969 = add <4 x i32> %11968, %11967
  %11970 = mul <4 x i32> %11969, <i32 5, i32 5, i32 5, i32 5>
  %11971 = shufflevector <16 x i8> %11810, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %11972 = shufflevector <16 x i8> %11811, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %11973 = bitcast <16 x i8> %11971 to <8 x i16>
  %11974 = bitcast <16 x i8> %11972 to <8 x i16>
  %11975 = add <8 x i16> %11974, %11973
  %11976 = shufflevector <16 x i8> %11812, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %11977 = bitcast <16 x i8> %11976 to <8 x i16>
  %11978 = add <8 x i16> %11975, %11977
  %11979 = mul <8 x i16> %11978, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %11980 = bitcast <4 x i32> %11796 to <16 x i8>
  %11981 = shufflevector <16 x i8> %11860, <16 x i8> %11980, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11982 = bitcast <16 x i8> %11981 to <4 x i32>
  %11983 = shufflevector <16 x i8> %11860, <16 x i8> %11980, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11984 = bitcast <16 x i8> %11983 to <4 x i32>
  %11985 = add <4 x i32> %11794, %11982
  %11986 = add <4 x i32> %11985, %11984
  %11987 = mul <4 x i32> %11986, <i32 3, i32 3, i32 3, i32 3>
  %11988 = bitcast <4 x i32> %11807 to <16 x i8>
  %11989 = shufflevector <16 x i8> %11980, <16 x i8> %11988, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %11990 = bitcast <16 x i8> %11989 to <4 x i32>
  %11991 = shufflevector <16 x i8> %11980, <16 x i8> %11988, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %11992 = bitcast <16 x i8> %11991 to <4 x i32>
  %11993 = add <4 x i32> %11796, %11990
  %11994 = add <4 x i32> %11993, %11992
  %11995 = mul <4 x i32> %11994, <i32 3, i32 3, i32 3, i32 3>
  %11996 = getelementptr inbounds i16, i16* %11868, i64 8
  %11997 = bitcast i16* %11996 to <8 x i16>*
  %11998 = load <8 x i16>, <8 x i16>* %11997, align 16
  %11999 = getelementptr inbounds i16, i16* %11871, i64 8
  %12000 = bitcast i16* %11999 to <8 x i16>*
  %12001 = load <8 x i16>, <8 x i16>* %12000, align 16
  %12002 = getelementptr inbounds i32, i32* %11874, i64 8
  %12003 = bitcast i32* %12002 to <4 x i32>*
  %12004 = load <4 x i32>, <4 x i32>* %12003, align 16
  %12005 = getelementptr inbounds i32, i32* %12002, i64 4
  %12006 = bitcast i32* %12005 to <4 x i32>*
  %12007 = load <4 x i32>, <4 x i32>* %12006, align 16
  %12008 = add <8 x i16> %11954, %12001
  %12009 = shufflevector <8 x i16> %12008, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %12010 = shufflevector <8 x i16> %11998, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %12011 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %12009, <8 x i16> %12010) #5
  %12012 = shufflevector <8 x i16> %12008, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %12013 = shufflevector <8 x i16> %11998, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %12014 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %12012, <8 x i16> %12013) #5
  %12015 = add <4 x i32> %11957, <i32 256, i32 256, i32 256, i32 256>
  %12016 = add <4 x i32> %12015, %11962
  %12017 = add <4 x i32> %12016, %12004
  %12018 = sub <4 x i32> %12017, %12011
  %12019 = ashr <4 x i32> %12018, <i32 9, i32 9, i32 9, i32 9>
  %12020 = add <4 x i32> %11965, <i32 256, i32 256, i32 256, i32 256>
  %12021 = add <4 x i32> %12020, %11970
  %12022 = add <4 x i32> %12021, %12007
  %12023 = sub <4 x i32> %12022, %12014
  %12024 = ashr <4 x i32> %12023, <i32 9, i32 9, i32 9, i32 9>
  %12025 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %12019, <4 x i32> %12024) #5
  %12026 = getelementptr inbounds i16, i16* %11898, i64 8
  %12027 = bitcast i16* %12026 to <8 x i16>*
  %12028 = load <8 x i16>, <8 x i16>* %12027, align 16
  %12029 = getelementptr inbounds i16, i16* %11901, i64 8
  %12030 = bitcast i16* %12029 to <8 x i16>*
  %12031 = load <8 x i16>, <8 x i16>* %12030, align 16
  %12032 = getelementptr inbounds i32, i32* %11904, i64 8
  %12033 = bitcast i32* %12032 to <4 x i32>*
  %12034 = load <4 x i32>, <4 x i32>* %12033, align 16
  %12035 = getelementptr inbounds i32, i32* %12032, i64 4
  %12036 = bitcast i32* %12035 to <4 x i32>*
  %12037 = load <4 x i32>, <4 x i32>* %12036, align 16
  %12038 = getelementptr inbounds i32, i32* %11910, i64 8
  %12039 = bitcast i32* %12038 to <4 x i32>*
  %12040 = load <4 x i32>, <4 x i32>* %12039, align 16
  %12041 = getelementptr inbounds i32, i32* %12038, i64 4
  %12042 = bitcast i32* %12041 to <4 x i32>*
  %12043 = load <4 x i32>, <4 x i32>* %12042, align 16
  %12044 = add <8 x i16> %11979, %11974
  %12045 = add <8 x i16> %12044, %12028
  %12046 = add <8 x i16> %12045, %12031
  %12047 = shufflevector <8 x i16> %12046, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %12048 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %12047, <8 x i16> %12010) #5
  %12049 = shufflevector <8 x i16> %12046, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %12050 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %12049, <8 x i16> %12013) #5
  %12051 = add <4 x i32> %11982, <i32 256, i32 256, i32 256, i32 256>
  %12052 = add <4 x i32> %12051, %11987
  %12053 = add <4 x i32> %12052, %12034
  %12054 = add <4 x i32> %12053, %12040
  %12055 = sub <4 x i32> %12054, %12048
  %12056 = ashr <4 x i32> %12055, <i32 9, i32 9, i32 9, i32 9>
  %12057 = add <4 x i32> %11990, <i32 256, i32 256, i32 256, i32 256>
  %12058 = add <4 x i32> %12057, %11995
  %12059 = add <4 x i32> %12058, %12037
  %12060 = add <4 x i32> %12059, %12043
  %12061 = sub <4 x i32> %12060, %12050
  %12062 = ashr <4 x i32> %12061, <i32 9, i32 9, i32 9, i32 9>
  %12063 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %12056, <4 x i32> %12062) #5
  %12064 = shufflevector <8 x i16> %12025, <8 x i16> %12063, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %12065 = shufflevector <8 x i16> %12025, <8 x i16> %12063, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %12066 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %12064) #5
  %12067 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7513, <8 x i16> %12065) #5
  %12068 = add <4 x i32> %12066, <i32 1024, i32 1024, i32 1024, i32 1024>
  %12069 = ashr <4 x i32> %12068, <i32 11, i32 11, i32 11, i32 11>
  %12070 = add <4 x i32> %12067, <i32 1024, i32 1024, i32 1024, i32 1024>
  %12071 = ashr <4 x i32> %12070, <i32 11, i32 11, i32 11, i32 11>
  %12072 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %12069, <4 x i32> %12071) #5
  %12073 = add <8 x i16> %12072, %11998
  %12074 = getelementptr inbounds i16, i16* %11030, i64 %11308
  %12075 = icmp sgt <8 x i16> %11945, zeroinitializer
  %12076 = select <8 x i1> %12075, <8 x i16> %11945, <8 x i16> zeroinitializer
  %12077 = icmp slt <8 x i16> %12076, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %12078 = select <8 x i1> %12077, <8 x i16> %12076, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %12079 = bitcast i16* %12074 to <8 x i16>*
  store <8 x i16> %12078, <8 x i16>* %12079, align 16
  %12080 = getelementptr inbounds i16, i16* %12074, i64 8
  %12081 = icmp sgt <8 x i16> %12073, zeroinitializer
  %12082 = select <8 x i1> %12081, <8 x i16> %12073, <8 x i16> zeroinitializer
  %12083 = icmp slt <8 x i16> %12082, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %12084 = select <8 x i1> %12083, <8 x i16> %12082, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %12085 = bitcast i16* %12080 to <8 x i16>*
  store <8 x i16> %12084, <8 x i16>* %12085, align 16
  %12086 = icmp slt i64 %11327, %5918
  br i1 %12086, label %11307, label %12087

12087:                                            ; preds = %11307, %5907, %3012, %11008, %2826
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #3

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32>, <4 x i32>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #4

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { argmemonly nounwind }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
