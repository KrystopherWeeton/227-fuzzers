; ModuleID = '../../third_party/libaom/source/libaom/aom_dsp/aom_dsp_rtcd.c'
source_filename = "../../third_party/libaom/source/libaom/aom_dsp/aom_dsp_rtcd.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.dist_wtd_comp_params = type { i32, i32, i32 }
%struct.macroblockd = type { i32, i32, i32, i8, [3 x %struct.macroblockd_plane], %struct.TileInfo, %struct.MB_MODE_INFO**, i8, i8, i8, i8, %struct.MB_MODE_INFO*, %struct.MB_MODE_INFO*, %struct.MB_MODE_INFO*, %struct.MB_MODE_INFO*, i8*, i32, i32, i32, i32, i32, [2 x %struct.scale_factors*], %struct.yv12_buffer_config*, [3 x i8*], [3 x [32 x i8]], i8*, [32 x i8], i8*, i8*, [32 x i8], [3 x %struct.WienerInfo], [3 x %struct.SgrprojInfo], i8, i8, [29 x [8 x %struct.candidate_mv]], [29 x [8 x i16]], i8, i8, [8 x i8], %struct.frame_contexts*, i32, [8 x i32], [8 x i32], i32, i32, %struct.aom_internal_error_info*, %struct.WarpedMotionParams*, i8, [4 x i8], [4 x i8], i8*, %struct.cfl_ctx, [2 x i16], i16*, [2 x i8*], [8 x i8] }
%struct.macroblockd_plane = type { i8, i32, i32, %struct.buf_2d, [2 x %struct.buf_2d], i8*, i8*, [8 x [2 x i16]], i8*, i8, i8, [8 x [19 x i8*]], [8 x [19 x i8*]] }
%struct.buf_2d = type { i8*, i8*, i32, i32, i32 }
%struct.TileInfo = type { i32, i32, i32, i32, i32, i32 }
%struct.MB_MODE_INFO = type <{ i8, i8, i8, i8, i32, [2 x %union.int_mv], [2 x i8], [2 x i8], %union.int_interpfilters, i8, i8, i8, i8, %struct.WarpedMotionParams, i8, i8, [6 x i8], %struct.INTERINTER_COMPOUND_DATA, [2 x i8], %struct.FILTER_INTRA_MODE_INFO, i8, i8, %struct.PALETTE_MODE_INFO, i8, i8, [16 x i8], i8, [4 x i8], i16, [7 x i8] }>
%union.int_mv = type { i32 }
%union.int_interpfilters = type { i32 }
%struct.WarpedMotionParams = type { [8 x i32], i16, i16, i16, i16, i8, i8 }
%struct.INTERINTER_COMPOUND_DATA = type { i8*, i8, i8, i8, i8 }
%struct.FILTER_INTRA_MODE_INFO = type { i8, i8 }
%struct.PALETTE_MODE_INFO = type { [24 x i16], [2 x i8] }
%struct.scale_factors = type { i32, i32, i32, i32, i32 (i32, %struct.scale_factors*)*, i32 (i32, %struct.scale_factors*)* }
%struct.yv12_buffer_config = type { %union.anon, %union.anon.0, %union.anon.2, %union.anon.4, %union.anon.6, %union.anon.8, i32, [3 x i8*], i8*, i32, i8*, i64, i32, i64, i32, i32, i32, i32, i32, i32, i8, i32, i32, i32, i32, i32, i32, %struct.aom_metadata_array* }
%union.anon = type { %struct.anon }
%struct.anon = type { i32, i32 }
%union.anon.0 = type { %struct.anon.1 }
%struct.anon.1 = type { i32, i32 }
%union.anon.2 = type { %struct.anon.3 }
%struct.anon.3 = type { i32, i32 }
%union.anon.4 = type { %struct.anon.5 }
%struct.anon.5 = type { i32, i32 }
%union.anon.6 = type { %struct.anon.7 }
%struct.anon.7 = type { i32, i32 }
%union.anon.8 = type { %struct.anon.9 }
%struct.anon.9 = type { i8*, i8*, i8* }
%struct.aom_metadata_array = type { i64, %struct.aom_metadata** }
%struct.aom_metadata = type { i32, i8*, i64, i32 }
%struct.WienerInfo = type { [8 x i16], [8 x i16] }
%struct.SgrprojInfo = type { i32, [2 x i32] }
%struct.candidate_mv = type { %union.int_mv, %union.int_mv }
%struct.frame_contexts = type { [5 x [13 x [3 x i16]]], [5 x [2 x [9 x [3 x i16]]]], [2 x [3 x [3 x i16]]], [2 x [2 x [6 x i16]]], [2 x [2 x [7 x i16]]], [2 x [2 x [8 x i16]]], [2 x [2 x [9 x i16]]], [2 x [2 x [10 x i16]]], [2 x [2 x [11 x i16]]], [2 x [2 x [12 x i16]]], [5 x [2 x [4 x [4 x i16]]]], [5 x [2 x [42 x [5 x i16]]]], [5 x [2 x [21 x [5 x i16]]]], [6 x [3 x i16]], [2 x [3 x i16]], [6 x [3 x i16]], [3 x [3 x i16]], [8 x [9 x i16]], [22 x [3 x i16]], [22 x [17 x i16]], [4 x [3 x i16]], [22 x [3 x i16]], [4 x [5 x i16]], [22 x [4 x i16]], [22 x [3 x i16]], [7 x [8 x i16]], [7 x [8 x i16]], [7 x [5 x [9 x i16]]], [7 x [5 x [9 x i16]]], [7 x [3 x [3 x i16]]], [2 x [3 x i16]], [5 x [3 x i16]], [3 x [6 x [3 x i16]]], [5 x [3 x i16]], [3 x [3 x [3 x i16]]], [3 x [3 x [3 x i16]]], [3 x [2 x [3 x i16]]], [21 x [3 x i16]], [6 x [3 x i16]], [6 x [3 x i16]], [3 x [3 x i16]], [3 x [3 x i16]], [4 x [3 x i16]], %struct.nmv_context, %struct.nmv_context, [3 x i16], %struct.segmentation_probs, [22 x [3 x i16]], [6 x i16], [4 x i16], [3 x i16], [3 x i16], [4 x [14 x i16]], [2 x [13 x [15 x i16]]], [20 x [11 x i16]], [16 x [4 x i16]], [5 x [5 x [14 x i16]]], [8 x [8 x i16]], [4 x [3 x [4 x i16]]], [5 x i16], [4 x [5 x i16]], [5 x i16], [3 x [4 x [13 x [17 x i16]]]], [4 x [4 x [17 x i16]]], [9 x i16], [6 x [17 x i16]], i32 }
%struct.nmv_context = type { [5 x i16], [2 x %struct.nmv_component] }
%struct.nmv_component = type { [12 x i16], [2 x [5 x i16]], [5 x i16], [3 x i16], [3 x i16], [3 x i16], [3 x i16], [10 x [3 x i16]] }
%struct.segmentation_probs = type { [9 x i16], [3 x [3 x i16]], [3 x [9 x i16]] }
%struct.aom_internal_error_info = type opaque
%struct.cfl_ctx = type { [1024 x i16], [1024 x i16], [2 x i32], i32, [2 x [32 x i16]], i32, i32, i32, i32, i32, i32 }
%struct.AV1Common = type opaque
%struct.mv = type { i16, i16 }
%struct.ConvolveParams = type { i32, i16*, i32, i32, i32, i32, i32, i32, i32, i32 }

@aom_blend_a64_hmask = common hidden local_unnamed_addr global void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)* null, align 8
@aom_blend_a64_mask = common hidden local_unnamed_addr global void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32)* null, align 8
@aom_blend_a64_vmask = common hidden local_unnamed_addr global void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)* null, align 8
@aom_comp_mask_pred = common hidden local_unnamed_addr global void (i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32)* null, align 8
@aom_convolve8_horiz = common hidden local_unnamed_addr global void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* null, align 8
@aom_convolve8_vert = common hidden local_unnamed_addr global void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* null, align 8
@aom_convolve_copy = common hidden local_unnamed_addr global void (i8*, i64, i8*, i64, i32, i32)* null, align 8
@aom_dc_128_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_128_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_128_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_128_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_128_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_left_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_left_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_left_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_left_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_left_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_top_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_top_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_top_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_top_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dc_top_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_dist_wtd_comp_avg_pred = common hidden local_unnamed_addr global void (i8*, i8*, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_comp_avg_upsampled_pred = common hidden local_unnamed_addr global void (%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i8*, i32, i32, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*, i32)* null, align 8
@aom_dist_wtd_sad128x128_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad128x64_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad16x16_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad16x32_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad16x8_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad32x16_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad32x32_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad32x64_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad4x4_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad4x8_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad64x128_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad64x32_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad64x64_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad8x16_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad8x4_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sad8x8_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance128x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance128x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance16x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance16x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance16x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance32x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance32x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance32x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance4x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance4x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance64x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance64x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance64x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance8x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance8x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_dist_wtd_sub_pixel_avg_variance8x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* null, align 8
@aom_fdct8x8 = common hidden local_unnamed_addr global void (i16*, i32*, i32)* null, align 8
@aom_fft16x16_float = common hidden local_unnamed_addr global void (float*, float*, float*)* null, align 8
@aom_fft32x32_float = common hidden local_unnamed_addr global void (float*, float*, float*)* null, align 8
@aom_fft8x8_float = common hidden local_unnamed_addr global void (float*, float*, float*)* null, align 8
@aom_get_blk_sse_sum = common hidden local_unnamed_addr global void (i16*, i32, i32, i32, i32*, i64*)* null, align 8
@aom_h_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_hadamard_16x16 = common hidden local_unnamed_addr global void (i16*, i64, i32*)* null, align 8
@aom_hadamard_32x32 = common hidden local_unnamed_addr global void (i16*, i64, i32*)* null, align 8
@aom_hadamard_lp_16x16 = common hidden local_unnamed_addr global void (i16*, i64, i16*)* null, align 8
@aom_ifft16x16_float = common hidden local_unnamed_addr global void (float*, float*, float*)* null, align 8
@aom_ifft32x32_float = common hidden local_unnamed_addr global void (float*, float*, float*)* null, align 8
@aom_ifft8x8_float = common hidden local_unnamed_addr global void (float*, float*, float*)* null, align 8
@aom_lowbd_blend_a64_d16_mask = common hidden local_unnamed_addr global void (i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*)* null, align 8
@aom_masked_sad128x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad128x128x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad128x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad128x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad16x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad16x16x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad16x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad16x32x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad16x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad16x8x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad32x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad32x16x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad32x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad32x32x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad32x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad32x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad4x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad4x4x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad4x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad4x8x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad64x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad64x128x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad64x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad64x32x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad64x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad64x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad8x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad8x16x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad8x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad8x4x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sad8x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* null, align 8
@aom_masked_sad8x8x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance128x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance128x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance16x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance16x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance16x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance32x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance32x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance32x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance4x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance4x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance64x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance64x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance64x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance8x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance8x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_masked_sub_pixel_variance8x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* null, align 8
@aom_mse16x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_mse_wxh_16bit = common hidden local_unnamed_addr global i64 (i8*, i32, i16*, i32, i32, i32)* null, align 8
@aom_paeth_predictor_16x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_16x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_16x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_4x4 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_4x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_8x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_8x4 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_paeth_predictor_8x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_quantize_b = common hidden local_unnamed_addr global void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* null, align 8
@aom_quantize_b_32x32 = common hidden local_unnamed_addr global void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* null, align 8
@aom_quantize_b_64x64 = common hidden local_unnamed_addr global void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* null, align 8
@aom_quantize_b_adaptive = common hidden local_unnamed_addr global void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* null, align 8
@aom_sad128x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad128x128_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*)* null, align 8
@aom_sad128x128x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad128x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad128x64_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*)* null, align 8
@aom_sad128x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad32x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad32x16_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*)* null, align 8
@aom_sad32x16x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad32x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad32x32_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*)* null, align 8
@aom_sad32x32x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad32x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad32x64_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*)* null, align 8
@aom_sad32x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad64x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad64x128_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*)* null, align 8
@aom_sad64x128x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad64x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad64x32_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*)* null, align 8
@aom_sad64x32x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad64x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad64x64_avg = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i8*)* null, align 8
@aom_sad64x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad_skip_128x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad_skip_128x128x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad_skip_128x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad_skip_128x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad_skip_32x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad_skip_32x16x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad_skip_32x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad_skip_32x32x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad_skip_32x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad_skip_32x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad_skip_64x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad_skip_64x128x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad_skip_64x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad_skip_64x32x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_sad_skip_64x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32)* null, align 8
@aom_sad_skip_64x64x4d = common hidden local_unnamed_addr global void (i8*, i32, i8**, i32, i32*)* null, align 8
@aom_satd = common hidden local_unnamed_addr global i32 (i32*, i32)* null, align 8
@aom_satd_lp = common hidden local_unnamed_addr global i32 (i16*, i32)* null, align 8
@aom_scaled_2d = common hidden local_unnamed_addr global void (i8*, i64, i8*, i64, [8 x i16]*, i32, i32, i32, i32, i32, i32)* null, align 8
@aom_smooth_h_predictor_16x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_16x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_16x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_4x4 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_4x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_8x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_8x4 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_h_predictor_8x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_16x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_16x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_16x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_4x4 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_4x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_8x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_8x4 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_predictor_8x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_16x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_16x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_16x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_4x4 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_4x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_8x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_8x4 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_smooth_v_predictor_8x8 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_sse = common hidden local_unnamed_addr global i64 (i8*, i32, i8*, i32, i32, i32)* null, align 8
@aom_sub_pixel_avg_variance128x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance128x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance16x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance16x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance16x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance32x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance32x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance32x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance4x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance4x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance64x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance64x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance64x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance8x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance8x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_avg_variance8x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* null, align 8
@aom_sub_pixel_variance128x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance128x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance16x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance16x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance16x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance32x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance32x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance32x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance4x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance4x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance64x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance64x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance64x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance8x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance8x4 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_sub_pixel_variance8x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i32, i32, i8*, i32, i32*)* null, align 8
@aom_subtract_block = common hidden local_unnamed_addr global void (i32, i32, i16*, i64, i8*, i64, i8*, i64)* null, align 8
@aom_sum_squares_2d_i16 = common hidden local_unnamed_addr global i64 (i16*, i32, i32, i32)* null, align 8
@aom_sum_sse_2d_i16 = common hidden local_unnamed_addr global i64 (i16*, i32, i32, i32, i32*)* null, align 8
@aom_v_predictor_32x16 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_v_predictor_32x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_v_predictor_32x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_v_predictor_64x32 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_v_predictor_64x64 = common hidden local_unnamed_addr global void (i8*, i64, i8*, i8*)* null, align 8
@aom_var_2d_u16 = common hidden local_unnamed_addr global i64 (i8*, i32, i32, i32)* null, align 8
@aom_var_2d_u8 = common hidden local_unnamed_addr global i64 (i8*, i32, i32, i32)* null, align 8
@aom_variance128x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance128x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance16x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance16x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance16x8 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance32x16 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance32x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance32x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance64x128 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance64x32 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_variance64x64 = common hidden local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)* null, align 8
@aom_once.lock = internal global i32 0, align 4
@.str = private unnamed_addr constant [14 x i8] c"AOM_SIMD_CAPS\00", align 1
@.str.1 = private unnamed_addr constant [19 x i8] c"AOM_SIMD_CAPS_MASK\00", align 1

; Function Attrs: nounwind ssp uwtable
define hidden void @aom_dsp_rtcd() local_unnamed_addr #0 {
  %1 = tail call i32 @pthread_once(i32* nonnull @aom_once.lock, void ()* nonnull @setup_rtcd_internal) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @setup_rtcd_internal() #0 {
  %1 = tail call i8* @getenv(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str, i64 0, i64 0)) #4
  %2 = icmp eq i8* %1, null
  br i1 %2, label %9, label %3

3:                                                ; preds = %0
  %4 = load i8, i8* %1, align 1
  %5 = icmp eq i8 %4, 0
  br i1 %5, label %9, label %6

6:                                                ; preds = %3
  %7 = tail call i64 @strtol(i8* nocapture nonnull %1, i8** null, i32 0) #4
  %8 = trunc i64 %7 to i32
  br label %63

9:                                                ; preds = %3, %0
  %10 = tail call i8* @getenv(i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.1, i64 0, i64 0)) #4
  %11 = icmp eq i8* %10, null
  br i1 %11, label %18, label %12

12:                                               ; preds = %9
  %13 = load i8, i8* %10, align 1
  %14 = icmp eq i8 %13, 0
  br i1 %14, label %18, label %15

15:                                               ; preds = %12
  %16 = tail call i64 @strtoul(i8* nocapture nonnull %10, i8** null, i32 0) #4
  %17 = trunc i64 %16 to i32
  br label %18

18:                                               ; preds = %15, %12, %9
  %19 = phi i32 [ %17, %15 ], [ -1, %12 ], [ -1, %9 ]
  %20 = tail call { i32, i32, i32, i32 } asm sideeffect "cpuid           \0A\09", "={ax},={bx},={cx},={dx},{ax},{cx},~{dirflag},~{fpsr},~{flags}"(i32 0, i32 0) #4, !srcloc !2
  %21 = extractvalue { i32, i32, i32, i32 } %20, 0
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %63, label %23

23:                                               ; preds = %18
  %24 = tail call { i32, i32, i32, i32 } asm sideeffect "cpuid           \0A\09", "={ax},={bx},={cx},={dx},{ax},{cx},~{dirflag},~{fpsr},~{flags}"(i32 1, i32 0) #4, !srcloc !3
  %25 = extractvalue { i32, i32, i32, i32 } %24, 2
  %26 = extractvalue { i32, i32, i32, i32 } %24, 3
  %27 = lshr i32 %26, 23
  %28 = and i32 %27, 1
  %29 = lshr i32 %26, 24
  %30 = and i32 %29, 2
  %31 = or i32 %30, %28
  %32 = and i32 %29, 4
  %33 = or i32 %31, %32
  %34 = shl i32 %25, 3
  %35 = and i32 %34, 8
  %36 = or i32 %33, %35
  %37 = lshr i32 %25, 5
  %38 = and i32 %37, 16
  %39 = or i32 %36, %38
  %40 = lshr i32 %25, 14
  %41 = and i32 %40, 32
  %42 = or i32 %39, %41
  %43 = and i32 %25, 402653184
  %44 = icmp eq i32 %43, 402653184
  br i1 %44, label %45, label %60

45:                                               ; preds = %23
  %46 = tail call { i32, i32 } asm sideeffect ".byte 0x0f, 0x01, 0xd0\0A", "={ax},={dx},{cx},~{dirflag},~{fpsr},~{flags}"(i32 0) #4, !srcloc !4
  %47 = extractvalue { i32, i32 } %46, 0
  %48 = and i32 %47, 6
  %49 = icmp eq i32 %48, 6
  br i1 %49, label %50, label %60

50:                                               ; preds = %45
  %51 = or i32 %42, 64
  %52 = icmp ugt i32 %21, 6
  br i1 %52, label %53, label %60

53:                                               ; preds = %50
  %54 = tail call { i32, i32, i32, i32 } asm sideeffect "cpuid           \0A\09", "={ax},={bx},={cx},={dx},{ax},{cx},~{dirflag},~{fpsr},~{flags}"(i32 7, i32 0) #4, !srcloc !5
  %55 = extractvalue { i32, i32, i32, i32 } %54, 1
  %56 = and i32 %55, 32
  %57 = icmp eq i32 %56, 0
  %58 = or i32 %42, 192
  %59 = select i1 %57, i32 %51, i32 %58
  br label %60

60:                                               ; preds = %53, %50, %45, %23
  %61 = phi i32 [ %51, %50 ], [ %42, %45 ], [ %42, %23 ], [ %59, %53 ]
  %62 = and i32 %61, %19
  br label %63

63:                                               ; preds = %6, %18, %60
  %64 = phi i32 [ %8, %6 ], [ %62, %60 ], [ 0, %18 ]
  %65 = and i32 %64, 32
  %66 = icmp ne i32 %65, 0
  %67 = select i1 %66, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)* @aom_blend_a64_hmask_sse4_1, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)* @aom_blend_a64_hmask_c
  store void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)* %67, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)** @aom_blend_a64_hmask, align 8
  %68 = select i1 %66, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32)* @aom_blend_a64_mask_sse4_1, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32)* @aom_blend_a64_mask_c
  %69 = trunc i32 %64 to i8
  %70 = icmp slt i8 %69, 0
  %71 = select i1 %70, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32)* @aom_blend_a64_mask_avx2, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32)* %68
  store void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32)* %71, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32)** @aom_blend_a64_mask, align 8
  %72 = select i1 %66, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)* @aom_blend_a64_vmask_sse4_1, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)* @aom_blend_a64_vmask_c
  store void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)* %72, void (i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32)** @aom_blend_a64_vmask, align 8
  %73 = and i32 %64, 16
  %74 = icmp ne i32 %73, 0
  %75 = select i1 %74, void (i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32)* @aom_comp_mask_pred_ssse3, void (i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32)* @aom_comp_mask_pred_c
  %76 = select i1 %70, void (i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32)* @aom_comp_mask_pred_avx2, void (i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32)* %75
  store void (i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32)* %76, void (i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32)** @aom_comp_mask_pred, align 8
  %77 = select i1 %74, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* @aom_convolve8_horiz_ssse3, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* @aom_convolve8_horiz_sse2
  %78 = select i1 %70, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* @aom_convolve8_horiz_avx2, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* %77
  store void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* %78, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)** @aom_convolve8_horiz, align 8
  %79 = select i1 %74, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* @aom_convolve8_vert_ssse3, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* @aom_convolve8_vert_sse2
  %80 = select i1 %70, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* @aom_convolve8_vert_avx2, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* %79
  store void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)* %80, void (i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32)** @aom_convolve8_vert, align 8
  %81 = select i1 %70, void (i8*, i64, i8*, i64, i32, i32)* @aom_convolve_copy_avx2, void (i8*, i64, i8*, i64, i32, i32)* @aom_convolve_copy_sse2
  store void (i8*, i64, i8*, i64, i32, i32)* %81, void (i8*, i64, i8*, i64, i32, i32)** @aom_convolve_copy, align 8
  %82 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_32x16_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_32x16_sse2
  store void (i8*, i64, i8*, i8*)* %82, void (i8*, i64, i8*, i8*)** @aom_dc_128_predictor_32x16, align 8
  %83 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_32x32_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_32x32_sse2
  store void (i8*, i64, i8*, i8*)* %83, void (i8*, i64, i8*, i8*)** @aom_dc_128_predictor_32x32, align 8
  %84 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_32x64_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_32x64_sse2
  store void (i8*, i64, i8*, i8*)* %84, void (i8*, i64, i8*, i8*)** @aom_dc_128_predictor_32x64, align 8
  %85 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_64x32_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_64x32_sse2
  store void (i8*, i64, i8*, i8*)* %85, void (i8*, i64, i8*, i8*)** @aom_dc_128_predictor_64x32, align 8
  %86 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_64x64_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_128_predictor_64x64_sse2
  store void (i8*, i64, i8*, i8*)* %86, void (i8*, i64, i8*, i8*)** @aom_dc_128_predictor_64x64, align 8
  %87 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_32x16_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_32x16_sse2
  store void (i8*, i64, i8*, i8*)* %87, void (i8*, i64, i8*, i8*)** @aom_dc_left_predictor_32x16, align 8
  %88 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_32x32_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_32x32_sse2
  store void (i8*, i64, i8*, i8*)* %88, void (i8*, i64, i8*, i8*)** @aom_dc_left_predictor_32x32, align 8
  %89 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_32x64_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_32x64_sse2
  store void (i8*, i64, i8*, i8*)* %89, void (i8*, i64, i8*, i8*)** @aom_dc_left_predictor_32x64, align 8
  %90 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_64x32_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_64x32_sse2
  store void (i8*, i64, i8*, i8*)* %90, void (i8*, i64, i8*, i8*)** @aom_dc_left_predictor_64x32, align 8
  %91 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_64x64_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_left_predictor_64x64_sse2
  store void (i8*, i64, i8*, i8*)* %91, void (i8*, i64, i8*, i8*)** @aom_dc_left_predictor_64x64, align 8
  %92 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_32x16_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_32x16_sse2
  store void (i8*, i64, i8*, i8*)* %92, void (i8*, i64, i8*, i8*)** @aom_dc_predictor_32x16, align 8
  %93 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_32x32_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_32x32_sse2
  store void (i8*, i64, i8*, i8*)* %93, void (i8*, i64, i8*, i8*)** @aom_dc_predictor_32x32, align 8
  %94 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_32x64_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_32x64_sse2
  store void (i8*, i64, i8*, i8*)* %94, void (i8*, i64, i8*, i8*)** @aom_dc_predictor_32x64, align 8
  %95 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_64x32_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_64x32_sse2
  store void (i8*, i64, i8*, i8*)* %95, void (i8*, i64, i8*, i8*)** @aom_dc_predictor_64x32, align 8
  %96 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_64x64_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_predictor_64x64_sse2
  store void (i8*, i64, i8*, i8*)* %96, void (i8*, i64, i8*, i8*)** @aom_dc_predictor_64x64, align 8
  %97 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_32x16_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_32x16_sse2
  store void (i8*, i64, i8*, i8*)* %97, void (i8*, i64, i8*, i8*)** @aom_dc_top_predictor_32x16, align 8
  %98 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_32x32_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_32x32_sse2
  store void (i8*, i64, i8*, i8*)* %98, void (i8*, i64, i8*, i8*)** @aom_dc_top_predictor_32x32, align 8
  %99 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_32x64_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_32x64_sse2
  store void (i8*, i64, i8*, i8*)* %99, void (i8*, i64, i8*, i8*)** @aom_dc_top_predictor_32x64, align 8
  %100 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_64x32_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_64x32_sse2
  store void (i8*, i64, i8*, i8*)* %100, void (i8*, i64, i8*, i8*)** @aom_dc_top_predictor_64x32, align 8
  %101 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_64x64_avx2, void (i8*, i64, i8*, i8*)* @aom_dc_top_predictor_64x64_sse2
  store void (i8*, i64, i8*, i8*)* %101, void (i8*, i64, i8*, i8*)** @aom_dc_top_predictor_64x64, align 8
  %102 = select i1 %74, void (i8*, i8*, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_comp_avg_pred_ssse3, void (i8*, i8*, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_comp_avg_pred_c
  store void (i8*, i8*, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*)* %102, void (i8*, i8*, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_comp_avg_pred, align 8
  %103 = select i1 %74, void (%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i8*, i32, i32, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*, i32)* @aom_dist_wtd_comp_avg_upsampled_pred_ssse3, void (%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i8*, i32, i32, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*, i32)* @aom_dist_wtd_comp_avg_upsampled_pred_c
  store void (%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i8*, i32, i32, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*, i32)* %103, void (%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i8*, i32, i32, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*, i32)** @aom_dist_wtd_comp_avg_upsampled_pred, align 8
  %104 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad128x128_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad128x128_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %104, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad128x128_avg, align 8
  %105 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad128x64_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad128x64_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %105, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad128x64_avg, align 8
  %106 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad16x16_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad16x16_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %106, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad16x16_avg, align 8
  %107 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad16x32_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad16x32_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %107, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad16x32_avg, align 8
  %108 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad16x8_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad16x8_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %108, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad16x8_avg, align 8
  %109 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad32x16_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad32x16_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %109, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad32x16_avg, align 8
  %110 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad32x32_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad32x32_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %110, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad32x32_avg, align 8
  %111 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad32x64_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad32x64_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %111, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad32x64_avg, align 8
  %112 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad4x4_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad4x4_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %112, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad4x4_avg, align 8
  %113 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad4x8_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad4x8_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %113, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad4x8_avg, align 8
  %114 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad64x128_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad64x128_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %114, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad64x128_avg, align 8
  %115 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad64x32_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad64x32_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %115, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad64x32_avg, align 8
  %116 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad64x64_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad64x64_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %116, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad64x64_avg, align 8
  %117 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad8x16_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad8x16_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %117, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad8x16_avg, align 8
  %118 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad8x4_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad8x4_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %118, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad8x4_avg, align 8
  %119 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad8x8_avg_ssse3, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sad8x8_avg_c
  store i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)* %119, i32 (i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sad8x8_avg, align 8
  %120 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance128x128_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance128x128_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %120, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance128x128, align 8
  %121 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance128x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance128x64_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %121, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance128x64, align 8
  %122 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance16x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance16x16_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %122, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance16x16, align 8
  %123 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance16x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance16x32_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %123, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance16x32, align 8
  %124 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance16x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance16x8_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %124, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance16x8, align 8
  %125 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance32x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance32x16_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %125, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance32x16, align 8
  %126 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance32x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance32x32_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %126, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance32x32, align 8
  %127 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance32x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance32x64_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %127, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance32x64, align 8
  %128 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance4x4_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance4x4_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %128, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance4x4, align 8
  %129 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance4x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance4x8_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %129, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance4x8, align 8
  %130 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance64x128_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance64x128_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %130, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance64x128, align 8
  %131 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance64x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance64x32_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %131, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance64x32, align 8
  %132 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance64x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance64x64_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %132, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance64x64, align 8
  %133 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance8x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance8x16_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %133, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance8x16, align 8
  %134 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance8x4_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance8x4_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %134, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance8x4, align 8
  %135 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance8x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* @aom_dist_wtd_sub_pixel_avg_variance8x8_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)* %135, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*)** @aom_dist_wtd_sub_pixel_avg_variance8x8, align 8
  %136 = select i1 %74, void (i16*, i32*, i32)* @aom_fdct8x8_ssse3, void (i16*, i32*, i32)* @aom_fdct8x8_sse2
  store void (i16*, i32*, i32)* %136, void (i16*, i32*, i32)** @aom_fdct8x8, align 8
  %137 = select i1 %70, void (float*, float*, float*)* @aom_fft16x16_float_avx2, void (float*, float*, float*)* @aom_fft16x16_float_sse2
  store void (float*, float*, float*)* %137, void (float*, float*, float*)** @aom_fft16x16_float, align 8
  %138 = select i1 %70, void (float*, float*, float*)* @aom_fft32x32_float_avx2, void (float*, float*, float*)* @aom_fft32x32_float_sse2
  store void (float*, float*, float*)* %138, void (float*, float*, float*)** @aom_fft32x32_float, align 8
  %139 = select i1 %70, void (float*, float*, float*)* @aom_fft8x8_float_avx2, void (float*, float*, float*)* @aom_fft8x8_float_sse2
  store void (float*, float*, float*)* %139, void (float*, float*, float*)** @aom_fft8x8_float, align 8
  %140 = select i1 %70, void (i16*, i32, i32, i32, i32*, i64*)* @aom_get_blk_sse_sum_avx2, void (i16*, i32, i32, i32, i32*, i64*)* @aom_get_blk_sse_sum_sse2
  store void (i16*, i32, i32, i32, i32*, i64*)* %140, void (i16*, i32, i32, i32, i32*, i64*)** @aom_get_blk_sse_sum, align 8
  %141 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_h_predictor_32x32_avx2, void (i8*, i64, i8*, i8*)* @aom_h_predictor_32x32_sse2
  store void (i8*, i64, i8*, i8*)* %141, void (i8*, i64, i8*, i8*)** @aom_h_predictor_32x32, align 8
  %142 = select i1 %70, void (i16*, i64, i32*)* @aom_hadamard_16x16_avx2, void (i16*, i64, i32*)* @aom_hadamard_16x16_sse2
  store void (i16*, i64, i32*)* %142, void (i16*, i64, i32*)** @aom_hadamard_16x16, align 8
  %143 = select i1 %70, void (i16*, i64, i32*)* @aom_hadamard_32x32_avx2, void (i16*, i64, i32*)* @aom_hadamard_32x32_sse2
  store void (i16*, i64, i32*)* %143, void (i16*, i64, i32*)** @aom_hadamard_32x32, align 8
  %144 = select i1 %70, void (i16*, i64, i16*)* @aom_hadamard_lp_16x16_avx2, void (i16*, i64, i16*)* @aom_hadamard_lp_16x16_c
  store void (i16*, i64, i16*)* %144, void (i16*, i64, i16*)** @aom_hadamard_lp_16x16, align 8
  %145 = select i1 %70, void (float*, float*, float*)* @aom_ifft16x16_float_avx2, void (float*, float*, float*)* @aom_ifft16x16_float_sse2
  store void (float*, float*, float*)* %145, void (float*, float*, float*)** @aom_ifft16x16_float, align 8
  %146 = select i1 %70, void (float*, float*, float*)* @aom_ifft32x32_float_avx2, void (float*, float*, float*)* @aom_ifft32x32_float_sse2
  store void (float*, float*, float*)* %146, void (float*, float*, float*)** @aom_ifft32x32_float, align 8
  %147 = select i1 %70, void (float*, float*, float*)* @aom_ifft8x8_float_avx2, void (float*, float*, float*)* @aom_ifft8x8_float_sse2
  store void (float*, float*, float*)* %147, void (float*, float*, float*)** @aom_ifft8x8_float, align 8
  %148 = select i1 %66, void (i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*)* @aom_lowbd_blend_a64_d16_mask_sse4_1, void (i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*)* @aom_lowbd_blend_a64_d16_mask_c
  %149 = select i1 %70, void (i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*)* @aom_lowbd_blend_a64_d16_mask_avx2, void (i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*)* %148
  store void (i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*)* %149, void (i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*)** @aom_lowbd_blend_a64_d16_mask, align 8
  %150 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad128x128_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad128x128_c
  %151 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad128x128_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %150
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %151, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad128x128, align 8
  %152 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad128x128x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad128x128x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %152, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad128x128x4d, align 8
  %153 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad128x64_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad128x64_c
  %154 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad128x64_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %153
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %154, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad128x64, align 8
  %155 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad128x64x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad128x64x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %155, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad128x64x4d, align 8
  %156 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x16_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x16_c
  %157 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x16_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %156
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %157, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad16x16, align 8
  %158 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad16x16x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad16x16x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %158, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad16x16x4d, align 8
  %159 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x32_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x32_c
  %160 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x32_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %159
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %160, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad16x32, align 8
  %161 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad16x32x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad16x32x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %161, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad16x32x4d, align 8
  %162 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x8_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x8_c
  %163 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad16x8_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %162
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %163, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad16x8, align 8
  %164 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad16x8x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad16x8x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %164, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad16x8x4d, align 8
  %165 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x16_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x16_c
  %166 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x16_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %165
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %166, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad32x16, align 8
  %167 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad32x16x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad32x16x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %167, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad32x16x4d, align 8
  %168 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x32_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x32_c
  %169 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x32_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %168
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %169, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad32x32, align 8
  %170 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad32x32x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad32x32x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %170, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad32x32x4d, align 8
  %171 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x64_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x64_c
  %172 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad32x64_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %171
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %172, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad32x64, align 8
  %173 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad32x64x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad32x64x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %173, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad32x64x4d, align 8
  %174 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad4x4_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad4x4_c
  %175 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad4x4_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %174
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %175, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad4x4, align 8
  %176 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad4x4x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad4x4x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %176, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad4x4x4d, align 8
  %177 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad4x8_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad4x8_c
  %178 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad4x8_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %177
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %178, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad4x8, align 8
  %179 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad4x8x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad4x8x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %179, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad4x8x4d, align 8
  %180 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x128_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x128_c
  %181 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x128_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %180
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %181, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad64x128, align 8
  %182 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad64x128x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad64x128x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %182, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad64x128x4d, align 8
  %183 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x32_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x32_c
  %184 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x32_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %183
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %184, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad64x32, align 8
  %185 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad64x32x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad64x32x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %185, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad64x32x4d, align 8
  %186 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x64_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x64_c
  %187 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad64x64_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %186
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %187, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad64x64, align 8
  %188 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad64x64x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad64x64x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %188, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad64x64x4d, align 8
  %189 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x16_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x16_c
  %190 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x16_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %189
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %190, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad8x16, align 8
  %191 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad8x16x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad8x16x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %191, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad8x16x4d, align 8
  %192 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x4_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x4_c
  %193 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x4_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %192
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %193, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad8x4, align 8
  %194 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad8x4x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad8x4x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %194, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad8x4x4d, align 8
  %195 = select i1 %74, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x8_ssse3, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x8_c
  %196 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* @aom_masked_sad8x8_avx2, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %195
  store i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)* %196, i32 (i8*, i32, i8*, i32, i8*, i8*, i32, i32)** @aom_masked_sad8x8, align 8
  %197 = select i1 %74, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad8x8x4d_ssse3, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sad8x8x4d_c
  store void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)* %197, void (i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sad8x8x4d, align 8
  %198 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance128x128_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance128x128_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %198, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance128x128, align 8
  %199 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance128x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance128x64_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %199, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance128x64, align 8
  %200 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance16x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance16x16_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %200, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance16x16, align 8
  %201 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance16x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance16x32_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %201, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance16x32, align 8
  %202 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance16x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance16x8_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %202, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance16x8, align 8
  %203 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance32x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance32x16_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %203, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance32x16, align 8
  %204 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance32x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance32x32_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %204, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance32x32, align 8
  %205 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance32x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance32x64_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %205, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance32x64, align 8
  %206 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance4x4_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance4x4_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %206, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance4x4, align 8
  %207 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance4x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance4x8_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %207, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance4x8, align 8
  %208 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance64x128_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance64x128_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %208, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance64x128, align 8
  %209 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance64x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance64x32_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %209, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance64x32, align 8
  %210 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance64x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance64x64_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %210, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance64x64, align 8
  %211 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance8x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance8x16_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %211, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance8x16, align 8
  %212 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance8x4_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance8x4_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %212, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance8x4, align 8
  %213 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance8x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* @aom_masked_sub_pixel_variance8x8_c
  store i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)* %213, i32 (i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*)** @aom_masked_sub_pixel_variance8x8, align 8
  %214 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_mse16x16_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_mse16x16_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %214, i32 (i8*, i32, i8*, i32, i32*)** @aom_mse16x16, align 8
  %215 = select i1 %70, i64 (i8*, i32, i16*, i32, i32, i32)* @aom_mse_wxh_16bit_avx2, i64 (i8*, i32, i16*, i32, i32, i32)* @aom_mse_wxh_16bit_sse2
  store i64 (i8*, i32, i16*, i32, i32, i32)* %215, i64 (i8*, i32, i16*, i32, i32, i32)** @aom_mse_wxh_16bit, align 8
  %216 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x16_c
  %217 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x16_avx2, void (i8*, i64, i8*, i8*)* %216
  store void (i8*, i64, i8*, i8*)* %217, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_16x16, align 8
  %218 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x32_c
  %219 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x32_avx2, void (i8*, i64, i8*, i8*)* %218
  store void (i8*, i64, i8*, i8*)* %219, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_16x32, align 8
  %220 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x8_c
  %221 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_16x8_avx2, void (i8*, i64, i8*, i8*)* %220
  store void (i8*, i64, i8*, i8*)* %221, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_16x8, align 8
  %222 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x16_c
  %223 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x16_avx2, void (i8*, i64, i8*, i8*)* %222
  store void (i8*, i64, i8*, i8*)* %223, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_32x16, align 8
  %224 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x32_c
  %225 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x32_avx2, void (i8*, i64, i8*, i8*)* %224
  store void (i8*, i64, i8*, i8*)* %225, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_32x32, align 8
  %226 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x64_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x64_c
  %227 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_32x64_avx2, void (i8*, i64, i8*, i8*)* %226
  store void (i8*, i64, i8*, i8*)* %227, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_32x64, align 8
  %228 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_4x4_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_4x4_c
  store void (i8*, i64, i8*, i8*)* %228, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_4x4, align 8
  %229 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_4x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_4x8_c
  store void (i8*, i64, i8*, i8*)* %229, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_4x8, align 8
  %230 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_64x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_64x32_c
  %231 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_64x32_avx2, void (i8*, i64, i8*, i8*)* %230
  store void (i8*, i64, i8*, i8*)* %231, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_64x32, align 8
  %232 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_64x64_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_64x64_c
  %233 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_64x64_avx2, void (i8*, i64, i8*, i8*)* %232
  store void (i8*, i64, i8*, i8*)* %233, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_64x64, align 8
  %234 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_8x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_8x16_c
  store void (i8*, i64, i8*, i8*)* %234, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_8x16, align 8
  %235 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_8x4_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_8x4_c
  store void (i8*, i64, i8*, i8*)* %235, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_8x4, align 8
  %236 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_8x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_paeth_predictor_8x8_c
  store void (i8*, i64, i8*, i8*)* %236, void (i8*, i64, i8*, i8*)** @aom_paeth_predictor_8x8, align 8
  %237 = select i1 %74, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_ssse3, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_sse2
  %238 = and i32 %64, 64
  %239 = icmp ne i32 %238, 0
  %240 = select i1 %239, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_avx, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* %237
  store void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* %240, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)** @aom_quantize_b, align 8
  %241 = select i1 %74, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_32x32_ssse3, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_32x32_c
  %242 = select i1 %239, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_32x32_avx, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* %241
  store void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* %242, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)** @aom_quantize_b_32x32, align 8
  %243 = select i1 %74, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_64x64_ssse3, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_64x64_c
  store void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* %243, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)** @aom_quantize_b_64x64, align 8
  %244 = select i1 %70, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_adaptive_avx2, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* @aom_quantize_b_adaptive_sse2
  store void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)* %244, void (i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*)** @aom_quantize_b_adaptive, align 8
  %245 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad128x128_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad128x128_sse2
  store i32 (i8*, i32, i8*, i32)* %245, i32 (i8*, i32, i8*, i32)** @aom_sad128x128, align 8
  %246 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad128x128_avg_avx2, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad128x128_avg_sse2
  store i32 (i8*, i32, i8*, i32, i8*)* %246, i32 (i8*, i32, i8*, i32, i8*)** @aom_sad128x128_avg, align 8
  %247 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad128x128x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad128x128x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %247, void (i8*, i32, i8**, i32, i32*)** @aom_sad128x128x4d, align 8
  %248 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad128x64_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad128x64_sse2
  store i32 (i8*, i32, i8*, i32)* %248, i32 (i8*, i32, i8*, i32)** @aom_sad128x64, align 8
  %249 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad128x64_avg_avx2, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad128x64_avg_sse2
  store i32 (i8*, i32, i8*, i32, i8*)* %249, i32 (i8*, i32, i8*, i32, i8*)** @aom_sad128x64_avg, align 8
  %250 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad128x64x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad128x64x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %250, void (i8*, i32, i8**, i32, i32*)** @aom_sad128x64x4d, align 8
  %251 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad32x16_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad32x16_sse2
  store i32 (i8*, i32, i8*, i32)* %251, i32 (i8*, i32, i8*, i32)** @aom_sad32x16, align 8
  %252 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad32x16_avg_avx2, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad32x16_avg_sse2
  store i32 (i8*, i32, i8*, i32, i8*)* %252, i32 (i8*, i32, i8*, i32, i8*)** @aom_sad32x16_avg, align 8
  %253 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad32x16x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad32x16x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %253, void (i8*, i32, i8**, i32, i32*)** @aom_sad32x16x4d, align 8
  %254 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad32x32_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad32x32_sse2
  store i32 (i8*, i32, i8*, i32)* %254, i32 (i8*, i32, i8*, i32)** @aom_sad32x32, align 8
  %255 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad32x32_avg_avx2, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad32x32_avg_sse2
  store i32 (i8*, i32, i8*, i32, i8*)* %255, i32 (i8*, i32, i8*, i32, i8*)** @aom_sad32x32_avg, align 8
  %256 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad32x32x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad32x32x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %256, void (i8*, i32, i8**, i32, i32*)** @aom_sad32x32x4d, align 8
  %257 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad32x64_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad32x64_sse2
  store i32 (i8*, i32, i8*, i32)* %257, i32 (i8*, i32, i8*, i32)** @aom_sad32x64, align 8
  %258 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad32x64_avg_avx2, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad32x64_avg_sse2
  store i32 (i8*, i32, i8*, i32, i8*)* %258, i32 (i8*, i32, i8*, i32, i8*)** @aom_sad32x64_avg, align 8
  %259 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad32x64x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad32x64x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %259, void (i8*, i32, i8**, i32, i32*)** @aom_sad32x64x4d, align 8
  %260 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad64x128_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad64x128_sse2
  store i32 (i8*, i32, i8*, i32)* %260, i32 (i8*, i32, i8*, i32)** @aom_sad64x128, align 8
  %261 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad64x128_avg_avx2, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad64x128_avg_sse2
  store i32 (i8*, i32, i8*, i32, i8*)* %261, i32 (i8*, i32, i8*, i32, i8*)** @aom_sad64x128_avg, align 8
  %262 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad64x128x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad64x128x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %262, void (i8*, i32, i8**, i32, i32*)** @aom_sad64x128x4d, align 8
  %263 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad64x32_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad64x32_sse2
  store i32 (i8*, i32, i8*, i32)* %263, i32 (i8*, i32, i8*, i32)** @aom_sad64x32, align 8
  %264 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad64x32_avg_avx2, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad64x32_avg_sse2
  store i32 (i8*, i32, i8*, i32, i8*)* %264, i32 (i8*, i32, i8*, i32, i8*)** @aom_sad64x32_avg, align 8
  %265 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad64x32x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad64x32x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %265, void (i8*, i32, i8**, i32, i32*)** @aom_sad64x32x4d, align 8
  %266 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad64x64_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad64x64_sse2
  store i32 (i8*, i32, i8*, i32)* %266, i32 (i8*, i32, i8*, i32)** @aom_sad64x64, align 8
  %267 = select i1 %70, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad64x64_avg_avx2, i32 (i8*, i32, i8*, i32, i8*)* @aom_sad64x64_avg_sse2
  store i32 (i8*, i32, i8*, i32, i8*)* %267, i32 (i8*, i32, i8*, i32, i8*)** @aom_sad64x64_avg, align 8
  %268 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad64x64x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad64x64x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %268, void (i8*, i32, i8**, i32, i32*)** @aom_sad64x64x4d, align 8
  %269 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_128x128_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_128x128_sse2
  store i32 (i8*, i32, i8*, i32)* %269, i32 (i8*, i32, i8*, i32)** @aom_sad_skip_128x128, align 8
  %270 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_128x128x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_128x128x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %270, void (i8*, i32, i8**, i32, i32*)** @aom_sad_skip_128x128x4d, align 8
  %271 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_128x64_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_128x64_sse2
  store i32 (i8*, i32, i8*, i32)* %271, i32 (i8*, i32, i8*, i32)** @aom_sad_skip_128x64, align 8
  %272 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_128x64x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_128x64x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %272, void (i8*, i32, i8**, i32, i32*)** @aom_sad_skip_128x64x4d, align 8
  %273 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_32x16_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_32x16_sse2
  store i32 (i8*, i32, i8*, i32)* %273, i32 (i8*, i32, i8*, i32)** @aom_sad_skip_32x16, align 8
  %274 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_32x16x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_32x16x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %274, void (i8*, i32, i8**, i32, i32*)** @aom_sad_skip_32x16x4d, align 8
  %275 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_32x32_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_32x32_sse2
  store i32 (i8*, i32, i8*, i32)* %275, i32 (i8*, i32, i8*, i32)** @aom_sad_skip_32x32, align 8
  %276 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_32x32x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_32x32x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %276, void (i8*, i32, i8**, i32, i32*)** @aom_sad_skip_32x32x4d, align 8
  %277 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_32x64_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_32x64_sse2
  store i32 (i8*, i32, i8*, i32)* %277, i32 (i8*, i32, i8*, i32)** @aom_sad_skip_32x64, align 8
  %278 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_32x64x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_32x64x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %278, void (i8*, i32, i8**, i32, i32*)** @aom_sad_skip_32x64x4d, align 8
  %279 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_64x128_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_64x128_sse2
  store i32 (i8*, i32, i8*, i32)* %279, i32 (i8*, i32, i8*, i32)** @aom_sad_skip_64x128, align 8
  %280 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_64x128x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_64x128x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %280, void (i8*, i32, i8**, i32, i32*)** @aom_sad_skip_64x128x4d, align 8
  %281 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_64x32_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_64x32_sse2
  store i32 (i8*, i32, i8*, i32)* %281, i32 (i8*, i32, i8*, i32)** @aom_sad_skip_64x32, align 8
  %282 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_64x32x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_64x32x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %282, void (i8*, i32, i8**, i32, i32*)** @aom_sad_skip_64x32x4d, align 8
  %283 = select i1 %70, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_64x64_avx2, i32 (i8*, i32, i8*, i32)* @aom_sad_skip_64x64_sse2
  store i32 (i8*, i32, i8*, i32)* %283, i32 (i8*, i32, i8*, i32)** @aom_sad_skip_64x64, align 8
  %284 = select i1 %70, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_64x64x4d_avx2, void (i8*, i32, i8**, i32, i32*)* @aom_sad_skip_64x64x4d_sse2
  store void (i8*, i32, i8**, i32, i32*)* %284, void (i8*, i32, i8**, i32, i32*)** @aom_sad_skip_64x64x4d, align 8
  %285 = select i1 %70, i32 (i32*, i32)* @aom_satd_avx2, i32 (i32*, i32)* @aom_satd_c
  store i32 (i32*, i32)* %285, i32 (i32*, i32)** @aom_satd, align 8
  %286 = select i1 %70, i32 (i16*, i32)* @aom_satd_lp_avx2, i32 (i16*, i32)* @aom_satd_lp_c
  store i32 (i16*, i32)* %286, i32 (i16*, i32)** @aom_satd_lp, align 8
  %287 = select i1 %74, void (i8*, i64, i8*, i64, [8 x i16]*, i32, i32, i32, i32, i32, i32)* @aom_scaled_2d_ssse3, void (i8*, i64, i8*, i64, [8 x i16]*, i32, i32, i32, i32, i32, i32)* @aom_scaled_2d_c
  store void (i8*, i64, i8*, i64, [8 x i16]*, i32, i32, i32, i32, i32, i32)* %287, void (i8*, i64, i8*, i64, [8 x i16]*, i32, i32, i32, i32, i32, i32)** @aom_scaled_2d, align 8
  %288 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_16x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_16x16_c
  store void (i8*, i64, i8*, i8*)* %288, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_16x16, align 8
  %289 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_16x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_16x32_c
  store void (i8*, i64, i8*, i8*)* %289, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_16x32, align 8
  %290 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_16x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_16x8_c
  store void (i8*, i64, i8*, i8*)* %290, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_16x8, align 8
  %291 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_32x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_32x16_c
  store void (i8*, i64, i8*, i8*)* %291, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_32x16, align 8
  %292 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_32x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_32x32_c
  store void (i8*, i64, i8*, i8*)* %292, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_32x32, align 8
  %293 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_32x64_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_32x64_c
  store void (i8*, i64, i8*, i8*)* %293, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_32x64, align 8
  %294 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_4x4_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_4x4_c
  store void (i8*, i64, i8*, i8*)* %294, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_4x4, align 8
  %295 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_4x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_4x8_c
  store void (i8*, i64, i8*, i8*)* %295, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_4x8, align 8
  %296 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_64x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_64x32_c
  store void (i8*, i64, i8*, i8*)* %296, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_64x32, align 8
  %297 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_64x64_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_64x64_c
  store void (i8*, i64, i8*, i8*)* %297, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_64x64, align 8
  %298 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_8x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_8x16_c
  store void (i8*, i64, i8*, i8*)* %298, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_8x16, align 8
  %299 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_8x4_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_8x4_c
  store void (i8*, i64, i8*, i8*)* %299, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_8x4, align 8
  %300 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_8x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_h_predictor_8x8_c
  store void (i8*, i64, i8*, i8*)* %300, void (i8*, i64, i8*, i8*)** @aom_smooth_h_predictor_8x8, align 8
  %301 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_16x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_16x16_c
  store void (i8*, i64, i8*, i8*)* %301, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_16x16, align 8
  %302 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_16x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_16x32_c
  store void (i8*, i64, i8*, i8*)* %302, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_16x32, align 8
  %303 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_16x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_16x8_c
  store void (i8*, i64, i8*, i8*)* %303, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_16x8, align 8
  %304 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_32x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_32x16_c
  store void (i8*, i64, i8*, i8*)* %304, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_32x16, align 8
  %305 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_32x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_32x32_c
  store void (i8*, i64, i8*, i8*)* %305, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_32x32, align 8
  %306 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_32x64_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_32x64_c
  store void (i8*, i64, i8*, i8*)* %306, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_32x64, align 8
  %307 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_4x4_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_4x4_c
  store void (i8*, i64, i8*, i8*)* %307, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_4x4, align 8
  %308 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_4x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_4x8_c
  store void (i8*, i64, i8*, i8*)* %308, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_4x8, align 8
  %309 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_64x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_64x32_c
  store void (i8*, i64, i8*, i8*)* %309, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_64x32, align 8
  %310 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_64x64_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_64x64_c
  store void (i8*, i64, i8*, i8*)* %310, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_64x64, align 8
  %311 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_8x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_8x16_c
  store void (i8*, i64, i8*, i8*)* %311, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_8x16, align 8
  %312 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_8x4_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_8x4_c
  store void (i8*, i64, i8*, i8*)* %312, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_8x4, align 8
  %313 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_8x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_predictor_8x8_c
  store void (i8*, i64, i8*, i8*)* %313, void (i8*, i64, i8*, i8*)** @aom_smooth_predictor_8x8, align 8
  %314 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_16x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_16x16_c
  store void (i8*, i64, i8*, i8*)* %314, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_16x16, align 8
  %315 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_16x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_16x32_c
  store void (i8*, i64, i8*, i8*)* %315, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_16x32, align 8
  %316 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_16x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_16x8_c
  store void (i8*, i64, i8*, i8*)* %316, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_16x8, align 8
  %317 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_32x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_32x16_c
  store void (i8*, i64, i8*, i8*)* %317, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_32x16, align 8
  %318 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_32x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_32x32_c
  store void (i8*, i64, i8*, i8*)* %318, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_32x32, align 8
  %319 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_32x64_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_32x64_c
  store void (i8*, i64, i8*, i8*)* %319, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_32x64, align 8
  %320 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_4x4_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_4x4_c
  store void (i8*, i64, i8*, i8*)* %320, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_4x4, align 8
  %321 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_4x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_4x8_c
  store void (i8*, i64, i8*, i8*)* %321, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_4x8, align 8
  %322 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_64x32_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_64x32_c
  store void (i8*, i64, i8*, i8*)* %322, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_64x32, align 8
  %323 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_64x64_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_64x64_c
  store void (i8*, i64, i8*, i8*)* %323, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_64x64, align 8
  %324 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_8x16_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_8x16_c
  store void (i8*, i64, i8*, i8*)* %324, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_8x16, align 8
  %325 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_8x4_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_8x4_c
  store void (i8*, i64, i8*, i8*)* %325, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_8x4, align 8
  %326 = select i1 %74, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_8x8_ssse3, void (i8*, i64, i8*, i8*)* @aom_smooth_v_predictor_8x8_c
  store void (i8*, i64, i8*, i8*)* %326, void (i8*, i64, i8*, i8*)** @aom_smooth_v_predictor_8x8, align 8
  %327 = select i1 %66, i64 (i8*, i32, i8*, i32, i32, i32)* @aom_sse_sse4_1, i64 (i8*, i32, i8*, i32, i32, i32)* @aom_sse_c
  %328 = select i1 %70, i64 (i8*, i32, i8*, i32, i32, i32)* @aom_sse_avx2, i64 (i8*, i32, i8*, i32, i32, i32)* %327
  store i64 (i8*, i32, i8*, i32, i32, i32)* %328, i64 (i8*, i32, i8*, i32, i32, i32)** @aom_sse, align 8
  %329 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance128x128_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance128x128_sse2
  %330 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance128x128_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %329
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %330, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance128x128, align 8
  %331 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance128x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance128x64_sse2
  %332 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance128x64_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %331
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %332, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance128x64, align 8
  %333 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance16x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance16x16_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %333, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance16x16, align 8
  %334 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance16x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance16x32_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %334, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance16x32, align 8
  %335 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance16x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance16x8_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %335, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance16x8, align 8
  %336 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x16_sse2
  %337 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x16_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %336
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %337, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance32x16, align 8
  %338 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x32_sse2
  %339 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x32_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %338
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %339, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance32x32, align 8
  %340 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x64_sse2
  %341 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance32x64_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %340
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %341, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance32x64, align 8
  %342 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance4x4_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance4x4_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %342, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance4x4, align 8
  %343 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance4x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance4x8_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %343, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance4x8, align 8
  %344 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x128_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x128_sse2
  %345 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x128_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %344
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %345, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance64x128, align 8
  %346 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x32_sse2
  %347 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x32_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %346
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %347, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance64x32, align 8
  %348 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x64_sse2
  %349 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance64x64_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %348
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %349, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance64x64, align 8
  %350 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance8x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance8x16_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %350, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance8x16, align 8
  %351 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance8x4_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance8x4_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %351, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance8x4, align 8
  %352 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance8x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* @aom_sub_pixel_avg_variance8x8_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)* %352, i32 (i8*, i32, i32, i32, i8*, i32, i32*, i8*)** @aom_sub_pixel_avg_variance8x8, align 8
  %353 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance128x128_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance128x128_sse2
  %354 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance128x128_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %353
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %354, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance128x128, align 8
  %355 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance128x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance128x64_sse2
  %356 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance128x64_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %355
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %356, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance128x64, align 8
  %357 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x16_sse2
  %358 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x16_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %357
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %358, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance16x16, align 8
  %359 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x32_sse2
  %360 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x32_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %359
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %360, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance16x32, align 8
  %361 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x8_sse2
  %362 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance16x8_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %361
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %362, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance16x8, align 8
  %363 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x16_sse2
  %364 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x16_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %363
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %364, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance32x16, align 8
  %365 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x32_sse2
  %366 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x32_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %365
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %366, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance32x32, align 8
  %367 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x64_sse2
  %368 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance32x64_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %367
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %368, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance32x64, align 8
  %369 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance4x4_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance4x4_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %369, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance4x4, align 8
  %370 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance4x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance4x8_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %370, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance4x8, align 8
  %371 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x128_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x128_sse2
  %372 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x128_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %371
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %372, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance64x128, align 8
  %373 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x32_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x32_sse2
  %374 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x32_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %373
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %374, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance64x32, align 8
  %375 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x64_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x64_sse2
  %376 = select i1 %70, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance64x64_avx2, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %375
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %376, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance64x64, align 8
  %377 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance8x16_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance8x16_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %377, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance8x16, align 8
  %378 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance8x4_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance8x4_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %378, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance8x4, align 8
  %379 = select i1 %74, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance8x8_ssse3, i32 (i8*, i32, i32, i32, i8*, i32, i32*)* @aom_sub_pixel_variance8x8_sse2
  store i32 (i8*, i32, i32, i32, i8*, i32, i32*)* %379, i32 (i8*, i32, i32, i32, i8*, i32, i32*)** @aom_sub_pixel_variance8x8, align 8
  %380 = select i1 %70, void (i32, i32, i16*, i64, i8*, i64, i8*, i64)* @aom_subtract_block_avx2, void (i32, i32, i16*, i64, i8*, i64, i8*, i64)* @aom_subtract_block_sse2
  store void (i32, i32, i16*, i64, i8*, i64, i8*, i64)* %380, void (i32, i32, i16*, i64, i8*, i64, i8*, i64)** @aom_subtract_block, align 8
  %381 = select i1 %70, i64 (i16*, i32, i32, i32)* @aom_sum_squares_2d_i16_avx2, i64 (i16*, i32, i32, i32)* @aom_sum_squares_2d_i16_sse2
  store i64 (i16*, i32, i32, i32)* %381, i64 (i16*, i32, i32, i32)** @aom_sum_squares_2d_i16, align 8
  %382 = select i1 %70, i64 (i16*, i32, i32, i32, i32*)* @aom_sum_sse_2d_i16_avx2, i64 (i16*, i32, i32, i32, i32*)* @aom_sum_sse_2d_i16_sse2
  store i64 (i16*, i32, i32, i32, i32*)* %382, i64 (i16*, i32, i32, i32, i32*)** @aom_sum_sse_2d_i16, align 8
  %383 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_v_predictor_32x16_avx2, void (i8*, i64, i8*, i8*)* @aom_v_predictor_32x16_sse2
  store void (i8*, i64, i8*, i8*)* %383, void (i8*, i64, i8*, i8*)** @aom_v_predictor_32x16, align 8
  %384 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_v_predictor_32x32_avx2, void (i8*, i64, i8*, i8*)* @aom_v_predictor_32x32_sse2
  store void (i8*, i64, i8*, i8*)* %384, void (i8*, i64, i8*, i8*)** @aom_v_predictor_32x32, align 8
  %385 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_v_predictor_32x64_avx2, void (i8*, i64, i8*, i8*)* @aom_v_predictor_32x64_sse2
  store void (i8*, i64, i8*, i8*)* %385, void (i8*, i64, i8*, i8*)** @aom_v_predictor_32x64, align 8
  %386 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_v_predictor_64x32_avx2, void (i8*, i64, i8*, i8*)* @aom_v_predictor_64x32_sse2
  store void (i8*, i64, i8*, i8*)* %386, void (i8*, i64, i8*, i8*)** @aom_v_predictor_64x32, align 8
  %387 = select i1 %70, void (i8*, i64, i8*, i8*)* @aom_v_predictor_64x64_avx2, void (i8*, i64, i8*, i8*)* @aom_v_predictor_64x64_sse2
  store void (i8*, i64, i8*, i8*)* %387, void (i8*, i64, i8*, i8*)** @aom_v_predictor_64x64, align 8
  %388 = select i1 %70, i64 (i8*, i32, i32, i32)* @aom_var_2d_u16_avx2, i64 (i8*, i32, i32, i32)* @aom_var_2d_u16_sse2
  store i64 (i8*, i32, i32, i32)* %388, i64 (i8*, i32, i32, i32)** @aom_var_2d_u16, align 8
  %389 = select i1 %70, i64 (i8*, i32, i32, i32)* @aom_var_2d_u8_avx2, i64 (i8*, i32, i32, i32)* @aom_var_2d_u8_sse2
  store i64 (i8*, i32, i32, i32)* %389, i64 (i8*, i32, i32, i32)** @aom_var_2d_u8, align 8
  %390 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance128x128_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance128x128_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %390, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance128x128, align 8
  %391 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance128x64_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance128x64_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %391, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance128x64, align 8
  %392 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance16x16_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance16x16_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %392, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance16x16, align 8
  %393 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance16x32_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance16x32_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %393, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance16x32, align 8
  %394 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance16x8_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance16x8_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %394, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance16x8, align 8
  %395 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance32x16_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance32x16_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %395, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance32x16, align 8
  %396 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance32x32_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance32x32_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %396, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance32x32, align 8
  %397 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance32x64_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance32x64_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %397, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance32x64, align 8
  %398 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance64x128_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance64x128_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %398, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance64x128, align 8
  %399 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance64x32_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance64x32_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %399, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance64x32, align 8
  %400 = select i1 %70, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance64x64_avx2, i32 (i8*, i32, i8*, i32, i32*)* @aom_variance64x64_sse2
  store i32 (i8*, i32, i8*, i32, i32*)* %400, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance64x64, align 8
  ret void
}

declare i32 @pthread_once(i32*, void ()*) local_unnamed_addr #1

declare void @aom_blend_a64_hmask_c(i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32) #1

declare void @aom_blend_a64_hmask_sse4_1(i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32) #1

declare void @aom_blend_a64_mask_c(i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32) #1

declare void @aom_blend_a64_mask_sse4_1(i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32) #1

declare void @aom_blend_a64_mask_avx2(i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32, i32, i32, i32) #1

declare void @aom_blend_a64_vmask_c(i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32) #1

declare void @aom_blend_a64_vmask_sse4_1(i8*, i32, i8*, i32, i8*, i32, i8*, i32, i32) #1

declare void @aom_comp_mask_pred_c(i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32) #1

declare void @aom_comp_mask_pred_ssse3(i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32) #1

declare void @aom_comp_mask_pred_avx2(i8*, i8*, i32, i32, i8*, i32, i8*, i32, i32) #1

declare void @aom_convolve8_horiz_sse2(i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32) #1

declare void @aom_convolve8_horiz_ssse3(i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32) #1

declare void @aom_convolve8_horiz_avx2(i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32) #1

declare void @aom_convolve8_vert_sse2(i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32) #1

declare void @aom_convolve8_vert_ssse3(i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32) #1

declare void @aom_convolve8_vert_avx2(i8*, i64, i8*, i64, i16*, i32, i16*, i32, i32, i32) #1

declare void @aom_convolve_copy_sse2(i8*, i64, i8*, i64, i32, i32) #1

declare void @aom_convolve_copy_avx2(i8*, i64, i8*, i64, i32, i32) #1

declare void @aom_dc_128_predictor_32x16_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_32x16_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_32x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_32x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_32x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_32x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_64x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_64x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_64x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_128_predictor_64x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_32x16_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_32x16_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_32x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_32x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_32x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_32x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_64x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_64x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_64x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_left_predictor_64x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_32x16_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_32x16_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_32x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_32x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_32x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_32x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_64x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_64x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_64x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_predictor_64x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_32x16_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_32x16_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_32x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_32x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_32x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_32x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_64x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_64x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_64x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_dc_top_predictor_64x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_dist_wtd_comp_avg_pred_c(i8*, i8*, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*) #1

declare void @aom_dist_wtd_comp_avg_pred_ssse3(i8*, i8*, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*) #1

declare void @aom_dist_wtd_comp_avg_upsampled_pred_c(%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i8*, i32, i32, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*, i32) #1

declare void @aom_dist_wtd_comp_avg_upsampled_pred_ssse3(%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i8*, i32, i32, i32, i32, i8*, i32, %struct.dist_wtd_comp_params*, i32) #1

declare i32 @aom_dist_wtd_sad128x128_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad128x128_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad128x64_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad128x64_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad16x16_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad16x16_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad16x32_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad16x32_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad16x8_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad16x8_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad32x16_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad32x16_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad32x32_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad32x32_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad32x64_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad32x64_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad4x4_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad4x4_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad4x8_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad4x8_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad64x128_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad64x128_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad64x32_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad64x32_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad64x64_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad64x64_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad8x16_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad8x16_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad8x4_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad8x4_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad8x8_avg_c(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sad8x8_avg_ssse3(i8*, i32, i8*, i32, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance128x128_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance128x128_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance128x64_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance128x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance16x16_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance16x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance16x32_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance16x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance16x8_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance16x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance32x16_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance32x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance32x32_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance32x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance32x64_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance32x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance4x4_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance4x4_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance4x8_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance4x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance64x128_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance64x128_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance64x32_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance64x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance64x64_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance64x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance8x16_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance8x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance8x4_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance8x4_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance8x8_c(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare i32 @aom_dist_wtd_sub_pixel_avg_variance8x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*, %struct.dist_wtd_comp_params*) #1

declare void @aom_fdct8x8_sse2(i16*, i32*, i32) #1

declare void @aom_fdct8x8_ssse3(i16*, i32*, i32) #1

declare void @aom_fft16x16_float_sse2(float*, float*, float*) #1

declare void @aom_fft16x16_float_avx2(float*, float*, float*) #1

declare void @aom_fft32x32_float_sse2(float*, float*, float*) #1

declare void @aom_fft32x32_float_avx2(float*, float*, float*) #1

declare void @aom_fft8x8_float_sse2(float*, float*, float*) #1

declare void @aom_fft8x8_float_avx2(float*, float*, float*) #1

declare void @aom_get_blk_sse_sum_sse2(i16*, i32, i32, i32, i32*, i64*) #1

declare void @aom_get_blk_sse_sum_avx2(i16*, i32, i32, i32, i32*, i64*) #1

declare void @aom_h_predictor_32x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_h_predictor_32x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_hadamard_16x16_sse2(i16*, i64, i32*) #1

declare void @aom_hadamard_16x16_avx2(i16*, i64, i32*) #1

declare void @aom_hadamard_32x32_sse2(i16*, i64, i32*) #1

declare void @aom_hadamard_32x32_avx2(i16*, i64, i32*) #1

declare void @aom_hadamard_lp_16x16_c(i16*, i64, i16*) #1

declare void @aom_hadamard_lp_16x16_avx2(i16*, i64, i16*) #1

declare void @aom_ifft16x16_float_sse2(float*, float*, float*) #1

declare void @aom_ifft16x16_float_avx2(float*, float*, float*) #1

declare void @aom_ifft32x32_float_sse2(float*, float*, float*) #1

declare void @aom_ifft32x32_float_avx2(float*, float*, float*) #1

declare void @aom_ifft8x8_float_sse2(float*, float*, float*) #1

declare void @aom_ifft8x8_float_avx2(float*, float*, float*) #1

declare void @aom_lowbd_blend_a64_d16_mask_c(i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*) #1

declare void @aom_lowbd_blend_a64_d16_mask_sse4_1(i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*) #1

declare void @aom_lowbd_blend_a64_d16_mask_avx2(i8*, i32, i16*, i32, i16*, i32, i8*, i32, i32, i32, i32, i32, %struct.ConvolveParams*) #1

declare i32 @aom_masked_sad128x128_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad128x128_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad128x128_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad128x128x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad128x128x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad128x64_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad128x64_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad128x64_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad128x64x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad128x64x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad16x16_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad16x16_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad16x16_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad16x16x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad16x16x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad16x32_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad16x32_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad16x32_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad16x32x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad16x32x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad16x8_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad16x8_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad16x8_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad16x8x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad16x8x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad32x16_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad32x16_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad32x16_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad32x16x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad32x16x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad32x32_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad32x32_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad32x32_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad32x32x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad32x32x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad32x64_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad32x64_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad32x64_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad32x64x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad32x64x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad4x4_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad4x4_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad4x4_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad4x4x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad4x4x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad4x8_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad4x8_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad4x8_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad4x8x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad4x8x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad64x128_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad64x128_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad64x128_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad64x128x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad64x128x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad64x32_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad64x32_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad64x32_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad64x32x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad64x32x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad64x64_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad64x64_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad64x64_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad64x64x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad64x64x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad8x16_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad8x16_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad8x16_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad8x16x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad8x16x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad8x4_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad8x4_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad8x4_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad8x4x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad8x4x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sad8x8_c(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad8x8_ssse3(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare i32 @aom_masked_sad8x8_avx2(i8*, i32, i8*, i32, i8*, i8*, i32, i32) #1

declare void @aom_masked_sad8x8x4d_c(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare void @aom_masked_sad8x8x4d_ssse3(i8*, i32, i8**, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance128x128_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance128x128_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance128x64_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance128x64_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance16x16_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance16x16_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance16x32_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance16x32_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance16x8_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance16x8_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance32x16_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance32x16_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance32x32_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance32x32_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance32x64_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance32x64_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance4x4_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance4x4_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance4x8_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance4x8_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance64x128_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance64x128_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance64x32_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance64x32_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance64x64_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance64x64_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance8x16_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance8x16_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance8x4_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance8x4_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance8x8_c(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_masked_sub_pixel_variance8x8_ssse3(i8*, i32, i32, i32, i8*, i32, i8*, i8*, i32, i32, i32*) #1

declare i32 @aom_mse16x16_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_mse16x16_avx2(i8*, i32, i8*, i32, i32*) #1

declare i64 @aom_mse_wxh_16bit_sse2(i8*, i32, i16*, i32, i32, i32) #1

declare i64 @aom_mse_wxh_16bit_avx2(i8*, i32, i16*, i32, i32, i32) #1

declare void @aom_paeth_predictor_16x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_16x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_16x16_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_16x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_16x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_16x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_16x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_16x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_16x8_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x16_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x64_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x64_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_32x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_4x4_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_4x4_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_4x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_4x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_64x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_64x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_64x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_64x64_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_64x64_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_64x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_8x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_8x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_8x4_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_8x4_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_8x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_paeth_predictor_8x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_quantize_b_sse2(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_ssse3(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_avx(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_32x32_c(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_32x32_ssse3(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_32x32_avx(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_64x64_c(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_64x64_ssse3(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_adaptive_sse2(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare void @aom_quantize_b_adaptive_avx2(i32*, i64, i16*, i16*, i16*, i16*, i32*, i32*, i16*, i16*, i16*, i16*) #1

declare i32 @aom_sad128x128_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad128x128_avx2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad128x128_avg_sse2(i8*, i32, i8*, i32, i8*) #1

declare i32 @aom_sad128x128_avg_avx2(i8*, i32, i8*, i32, i8*) #1

declare void @aom_sad128x128x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad128x128x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad128x64_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad128x64_avx2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad128x64_avg_sse2(i8*, i32, i8*, i32, i8*) #1

declare i32 @aom_sad128x64_avg_avx2(i8*, i32, i8*, i32, i8*) #1

declare void @aom_sad128x64x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad128x64x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad32x16_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad32x16_avx2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad32x16_avg_sse2(i8*, i32, i8*, i32, i8*) #1

declare i32 @aom_sad32x16_avg_avx2(i8*, i32, i8*, i32, i8*) #1

declare void @aom_sad32x16x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad32x16x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad32x32_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad32x32_avx2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad32x32_avg_sse2(i8*, i32, i8*, i32, i8*) #1

declare i32 @aom_sad32x32_avg_avx2(i8*, i32, i8*, i32, i8*) #1

declare void @aom_sad32x32x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad32x32x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad32x64_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad32x64_avx2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad32x64_avg_sse2(i8*, i32, i8*, i32, i8*) #1

declare i32 @aom_sad32x64_avg_avx2(i8*, i32, i8*, i32, i8*) #1

declare void @aom_sad32x64x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad32x64x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad64x128_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad64x128_avx2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad64x128_avg_sse2(i8*, i32, i8*, i32, i8*) #1

declare i32 @aom_sad64x128_avg_avx2(i8*, i32, i8*, i32, i8*) #1

declare void @aom_sad64x128x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad64x128x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad64x32_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad64x32_avx2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad64x32_avg_sse2(i8*, i32, i8*, i32, i8*) #1

declare i32 @aom_sad64x32_avg_avx2(i8*, i32, i8*, i32, i8*) #1

declare void @aom_sad64x32x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad64x32x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad64x64_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad64x64_avx2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad64x64_avg_sse2(i8*, i32, i8*, i32, i8*) #1

declare i32 @aom_sad64x64_avg_avx2(i8*, i32, i8*, i32, i8*) #1

declare void @aom_sad64x64x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad64x64x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad_skip_128x128_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad_skip_128x128_avx2(i8*, i32, i8*, i32) #1

declare void @aom_sad_skip_128x128x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad_skip_128x128x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad_skip_128x64_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad_skip_128x64_avx2(i8*, i32, i8*, i32) #1

declare void @aom_sad_skip_128x64x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad_skip_128x64x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad_skip_32x16_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad_skip_32x16_avx2(i8*, i32, i8*, i32) #1

declare void @aom_sad_skip_32x16x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad_skip_32x16x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad_skip_32x32_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad_skip_32x32_avx2(i8*, i32, i8*, i32) #1

declare void @aom_sad_skip_32x32x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad_skip_32x32x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad_skip_32x64_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad_skip_32x64_avx2(i8*, i32, i8*, i32) #1

declare void @aom_sad_skip_32x64x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad_skip_32x64x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad_skip_64x128_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad_skip_64x128_avx2(i8*, i32, i8*, i32) #1

declare void @aom_sad_skip_64x128x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad_skip_64x128x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad_skip_64x32_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad_skip_64x32_avx2(i8*, i32, i8*, i32) #1

declare void @aom_sad_skip_64x32x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad_skip_64x32x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_sad_skip_64x64_sse2(i8*, i32, i8*, i32) #1

declare i32 @aom_sad_skip_64x64_avx2(i8*, i32, i8*, i32) #1

declare void @aom_sad_skip_64x64x4d_sse2(i8*, i32, i8**, i32, i32*) #1

declare void @aom_sad_skip_64x64x4d_avx2(i8*, i32, i8**, i32, i32*) #1

declare i32 @aom_satd_c(i32*, i32) #1

declare i32 @aom_satd_avx2(i32*, i32) #1

declare i32 @aom_satd_lp_c(i16*, i32) #1

declare i32 @aom_satd_lp_avx2(i16*, i32) #1

declare void @aom_scaled_2d_c(i8*, i64, i8*, i64, [8 x i16]*, i32, i32, i32, i32, i32, i32) #1

declare void @aom_scaled_2d_ssse3(i8*, i64, i8*, i64, [8 x i16]*, i32, i32, i32, i32, i32, i32) #1

declare void @aom_smooth_h_predictor_16x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_16x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_16x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_16x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_16x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_16x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_32x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_32x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_32x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_32x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_32x64_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_32x64_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_4x4_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_4x4_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_4x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_4x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_64x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_64x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_64x64_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_64x64_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_8x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_8x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_8x4_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_8x4_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_8x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_h_predictor_8x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_16x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_16x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_16x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_16x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_16x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_16x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_32x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_32x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_32x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_32x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_32x64_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_32x64_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_4x4_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_4x4_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_4x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_4x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_64x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_64x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_64x64_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_64x64_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_8x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_8x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_8x4_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_8x4_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_8x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_predictor_8x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_16x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_16x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_16x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_16x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_16x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_16x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_32x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_32x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_32x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_32x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_32x64_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_32x64_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_4x4_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_4x4_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_4x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_4x8_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_64x32_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_64x32_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_64x64_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_64x64_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_8x16_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_8x16_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_8x4_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_8x4_ssse3(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_8x8_c(i8*, i64, i8*, i8*) #1

declare void @aom_smooth_v_predictor_8x8_ssse3(i8*, i64, i8*, i8*) #1

declare i64 @aom_sse_c(i8*, i32, i8*, i32, i32, i32) #1

declare i64 @aom_sse_sse4_1(i8*, i32, i8*, i32, i32, i32) #1

declare i64 @aom_sse_avx2(i8*, i32, i8*, i32, i32, i32) #1

declare i32 @aom_sub_pixel_avg_variance128x128_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance128x128_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance128x128_avx2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance128x64_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance128x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance128x64_avx2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance16x16_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance16x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance16x32_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance16x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance16x8_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance16x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x16_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x16_avx2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x32_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x32_avx2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x64_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance32x64_avx2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance4x4_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance4x4_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance4x8_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance4x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x128_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x128_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x128_avx2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x32_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x32_avx2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x64_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance64x64_avx2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance8x16_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance8x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance8x4_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance8x4_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance8x8_sse2(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_avg_variance8x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8*) #1

declare i32 @aom_sub_pixel_variance128x128_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance128x128_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance128x128_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance128x64_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance128x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance128x64_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x16_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x16_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x32_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x32_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x8_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance16x8_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x16_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x16_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x32_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x32_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x64_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance32x64_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance4x4_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance4x4_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance4x8_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance4x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x128_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x128_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x128_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x32_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x32_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x64_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance64x64_avx2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance8x16_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance8x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance8x4_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance8x4_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance8x8_sse2(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare i32 @aom_sub_pixel_variance8x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*) #1

declare void @aom_subtract_block_sse2(i32, i32, i16*, i64, i8*, i64, i8*, i64) #1

declare void @aom_subtract_block_avx2(i32, i32, i16*, i64, i8*, i64, i8*, i64) #1

declare i64 @aom_sum_squares_2d_i16_sse2(i16*, i32, i32, i32) #1

declare i64 @aom_sum_squares_2d_i16_avx2(i16*, i32, i32, i32) #1

declare i64 @aom_sum_sse_2d_i16_sse2(i16*, i32, i32, i32, i32*) #1

declare i64 @aom_sum_sse_2d_i16_avx2(i16*, i32, i32, i32, i32*) #1

declare void @aom_v_predictor_32x16_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_32x16_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_32x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_32x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_32x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_32x64_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_64x32_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_64x32_avx2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_64x64_sse2(i8*, i64, i8*, i8*) #1

declare void @aom_v_predictor_64x64_avx2(i8*, i64, i8*, i8*) #1

declare i64 @aom_var_2d_u16_sse2(i8*, i32, i32, i32) #1

declare i64 @aom_var_2d_u16_avx2(i8*, i32, i32, i32) #1

declare i64 @aom_var_2d_u8_sse2(i8*, i32, i32, i32) #1

declare i64 @aom_var_2d_u8_avx2(i8*, i32, i32, i32) #1

declare i32 @aom_variance128x128_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance128x128_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance128x64_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance128x64_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance16x16_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance16x16_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance16x32_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance16x32_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance16x8_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance16x8_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance32x16_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance32x16_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance32x32_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance32x32_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance32x64_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance32x64_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance64x128_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance64x128_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance64x32_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance64x32_avx2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance64x64_sse2(i8*, i32, i8*, i32, i32*) #1

declare i32 @aom_variance64x64_avx2(i8*, i32, i8*, i32, i32*) #1

; Function Attrs: nofree nounwind readonly
declare i8* @getenv(i8* nocapture) local_unnamed_addr #2

; Function Attrs: nofree nounwind
declare i64 @strtol(i8* readonly, i8** nocapture, i32) local_unnamed_addr #3

; Function Attrs: nofree nounwind
declare i64 @strtoul(i8* readonly, i8** nocapture, i32) local_unnamed_addr #3

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nofree nounwind readonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 -2146265471, i32 -2146265452}
!3 = !{i32 -2146265250, i32 -2146265231}
!4 = !{i32 1211129}
!5 = !{i32 -2146264864, i32 -2146264845}
