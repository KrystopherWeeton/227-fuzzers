; ModuleID = '../../third_party/libaom/source/libaom/aom_dsp/x86/jnt_variance_ssse3.c'
source_filename = "../../third_party/libaom/source/libaom/aom_dsp/x86/jnt_variance_ssse3.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.dist_wtd_comp_params = type { i32, i32, i32 }
%struct.macroblockd = type { i32, i32, i32, i8, [3 x %struct.macroblockd_plane], %struct.TileInfo, %struct.MB_MODE_INFO**, i8, i8, i8, i8, %struct.MB_MODE_INFO*, %struct.MB_MODE_INFO*, %struct.MB_MODE_INFO*, %struct.MB_MODE_INFO*, i8*, i32, i32, i32, i32, i32, [2 x %struct.scale_factors*], %struct.yv12_buffer_config*, [3 x i8*], [3 x [32 x i8]], i8*, [32 x i8], i8*, i8*, [32 x i8], [3 x %struct.WienerInfo], [3 x %struct.SgrprojInfo], i8, i8, [29 x [8 x %struct.candidate_mv]], [29 x [8 x i16]], i8, i8, [8 x i8], %struct.frame_contexts*, i32, [8 x i32], [8 x i32], i32, i32, %struct.aom_internal_error_info*, %struct.WarpedMotionParams*, i8, [4 x i8], [4 x i8], i8*, %struct.cfl_ctx, [2 x i16], i16*, [2 x i8*], [8 x i8] }
%struct.macroblockd_plane = type { i8, i32, i32, %struct.buf_2d, [2 x %struct.buf_2d], i8*, i8*, [8 x [2 x i16]], i8*, i8, i8, [8 x [19 x i8*]], [8 x [19 x i8*]] }
%struct.buf_2d = type { i8*, i8*, i32, i32, i32 }
%struct.TileInfo = type { i32, i32, i32, i32, i32, i32 }
%struct.MB_MODE_INFO = type <{ i8, i8, i8, i8, i32, [2 x %union.int_mv], [2 x i8], [2 x i8], %union.int_interpfilters, i8, i8, i8, i8, %struct.WarpedMotionParams, i8, i8, [6 x i8], %struct.INTERINTER_COMPOUND_DATA, [2 x i8], %struct.FILTER_INTRA_MODE_INFO, i8, i8, %struct.PALETTE_MODE_INFO, i8, i8, [16 x i8], i8, [4 x i8], i16, [7 x i8] }>
%union.int_mv = type { i32 }
%union.int_interpfilters = type { i32 }
%struct.WarpedMotionParams = type { [8 x i32], i16, i16, i16, i16, i8, i8 }
%struct.INTERINTER_COMPOUND_DATA = type { i8*, i8, i8, i8, i8 }
%struct.FILTER_INTRA_MODE_INFO = type { i8, i8 }
%struct.PALETTE_MODE_INFO = type { [24 x i16], [2 x i8] }
%struct.scale_factors = type { i32, i32, i32, i32, i32 (i32, %struct.scale_factors*)*, i32 (i32, %struct.scale_factors*)* }
%struct.yv12_buffer_config = type { %union.anon, %union.anon.0, %union.anon.2, %union.anon.4, %union.anon.6, %union.anon.8, i32, [3 x i8*], i8*, i32, i8*, i64, i32, i64, i32, i32, i32, i32, i32, i32, i8, i32, i32, i32, i32, i32, i32, %struct.aom_metadata_array* }
%union.anon = type { %struct.anon }
%struct.anon = type { i32, i32 }
%union.anon.0 = type { %struct.anon.1 }
%struct.anon.1 = type { i32, i32 }
%union.anon.2 = type { %struct.anon.3 }
%struct.anon.3 = type { i32, i32 }
%union.anon.4 = type { %struct.anon.5 }
%struct.anon.5 = type { i32, i32 }
%union.anon.6 = type { %struct.anon.7 }
%struct.anon.7 = type { i32, i32 }
%union.anon.8 = type { %struct.anon.9 }
%struct.anon.9 = type { i8*, i8*, i8* }
%struct.aom_metadata_array = type { i64, %struct.aom_metadata** }
%struct.aom_metadata = type { i32, i8*, i64, i32 }
%struct.WienerInfo = type { [8 x i16], [8 x i16] }
%struct.SgrprojInfo = type { i32, [2 x i32] }
%struct.candidate_mv = type { %union.int_mv, %union.int_mv }
%struct.frame_contexts = type { [5 x [13 x [3 x i16]]], [5 x [2 x [9 x [3 x i16]]]], [2 x [3 x [3 x i16]]], [2 x [2 x [6 x i16]]], [2 x [2 x [7 x i16]]], [2 x [2 x [8 x i16]]], [2 x [2 x [9 x i16]]], [2 x [2 x [10 x i16]]], [2 x [2 x [11 x i16]]], [2 x [2 x [12 x i16]]], [5 x [2 x [4 x [4 x i16]]]], [5 x [2 x [42 x [5 x i16]]]], [5 x [2 x [21 x [5 x i16]]]], [6 x [3 x i16]], [2 x [3 x i16]], [6 x [3 x i16]], [3 x [3 x i16]], [8 x [9 x i16]], [22 x [3 x i16]], [22 x [17 x i16]], [4 x [3 x i16]], [22 x [3 x i16]], [4 x [5 x i16]], [22 x [4 x i16]], [22 x [3 x i16]], [7 x [8 x i16]], [7 x [8 x i16]], [7 x [5 x [9 x i16]]], [7 x [5 x [9 x i16]]], [7 x [3 x [3 x i16]]], [2 x [3 x i16]], [5 x [3 x i16]], [3 x [6 x [3 x i16]]], [5 x [3 x i16]], [3 x [3 x [3 x i16]]], [3 x [3 x [3 x i16]]], [3 x [2 x [3 x i16]]], [21 x [3 x i16]], [6 x [3 x i16]], [6 x [3 x i16]], [3 x [3 x i16]], [3 x [3 x i16]], [4 x [3 x i16]], %struct.nmv_context, %struct.nmv_context, [3 x i16], %struct.segmentation_probs, [22 x [3 x i16]], [6 x i16], [4 x i16], [3 x i16], [3 x i16], [4 x [14 x i16]], [2 x [13 x [15 x i16]]], [20 x [11 x i16]], [16 x [4 x i16]], [5 x [5 x [14 x i16]]], [8 x [8 x i16]], [4 x [3 x [4 x i16]]], [5 x i16], [4 x [5 x i16]], [5 x i16], [3 x [4 x [13 x [17 x i16]]]], [4 x [4 x [17 x i16]]], [9 x i16], [6 x [17 x i16]], i32 }
%struct.nmv_context = type { [5 x i16], [2 x %struct.nmv_component] }
%struct.nmv_component = type { [12 x i16], [2 x [5 x i16]], [5 x i16], [3 x i16], [3 x i16], [3 x i16], [3 x i16], [10 x [3 x i16]] }
%struct.segmentation_probs = type { [9 x i16], [3 x [3 x i16]], [3 x [9 x i16]] }
%struct.aom_internal_error_info = type opaque
%struct.cfl_ctx = type { [1024 x i16], [1024 x i16], [2 x i32], i32, [2 x [32 x i16]], i32, i32, i32, i32, i32, i32 }
%struct.AV1Common = type opaque
%struct.mv = type { i16, i16 }

@bilinear_filters_2t = internal constant [8 x [2 x i8]] [[2 x i8] c"\80\00", [2 x i8] c"p\10", [2 x i8] c"` ", [2 x i8] c"P0", [2 x i8] c"@@", [2 x i8] c"0P", [2 x i8] c" `", [2 x i8] c"\10p"], align 16
@aom_variance128x128 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance128x64 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance64x128 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance64x64 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance64x32 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance32x64 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance32x32 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance32x16 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance16x32 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance16x16 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8
@aom_variance16x8 = external local_unnamed_addr global i32 (i8*, i32, i8*, i32, i32*)*, align 8

; Function Attrs: nounwind ssp uwtable
define hidden void @aom_dist_wtd_comp_avg_pred_ssse3(i8* nocapture, i8* nocapture readonly, i32, i32, i8* nocapture readonly, i32, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %8 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %6, i64 0, i32 1
  %9 = bitcast i32* %8 to <2 x i32>*
  %10 = load <2 x i32>, <2 x i32>* %9, align 4
  %11 = trunc <2 x i32> %10 to <2 x i8>
  %12 = shufflevector <2 x i8> %11, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %13 = icmp sgt i32 %2, 15
  br i1 %13, label %14, label %104

14:                                               ; preds = %7
  %15 = icmp sgt i32 %3, 0
  br i1 %15, label %16, label %219

16:                                               ; preds = %14
  %17 = sub nsw i32 %5, %2
  %18 = sext i32 %17 to i64
  %19 = add i32 %2, -1
  %20 = lshr i32 %19, 4
  %21 = add nuw nsw i32 %20, 1
  %22 = and i32 %21, 1
  %23 = icmp eq i32 %20, 0
  %24 = sub nuw nsw i32 %21, %22
  %25 = icmp eq i32 %22, 0
  br label %26

26:                                               ; preds = %97, %16
  %27 = phi i8* [ %0, %16 ], [ %98, %97 ]
  %28 = phi i8* [ %1, %16 ], [ %99, %97 ]
  %29 = phi i8* [ %4, %16 ], [ %101, %97 ]
  %30 = phi i32 [ 0, %16 ], [ %102, %97 ]
  br i1 %23, label %72, label %31

31:                                               ; preds = %26, %31
  %32 = phi i8* [ %67, %31 ], [ %27, %26 ]
  %33 = phi i8* [ %68, %31 ], [ %28, %26 ]
  %34 = phi i8* [ %69, %31 ], [ %29, %26 ]
  %35 = phi i32 [ %70, %31 ], [ %24, %26 ]
  %36 = bitcast i8* %34 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %33 to <16 x i8>*
  %39 = load <16 x i8>, <16 x i8>* %38, align 1
  %40 = shufflevector <16 x i8> %37, <16 x i8> %39, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %41 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %40, <16 x i8> %12) #4
  %42 = add <8 x i16> %41, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %43 = ashr <8 x i16> %42, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %44 = shufflevector <16 x i8> %37, <16 x i8> %39, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %45 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %44, <16 x i8> %12) #4
  %46 = add <8 x i16> %45, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %47 = ashr <8 x i16> %46, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %48 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %43, <8 x i16> %47) #4
  %49 = bitcast i8* %32 to <16 x i8>*
  store <16 x i8> %48, <16 x i8>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %32, i64 16
  %51 = getelementptr inbounds i8, i8* %33, i64 16
  %52 = getelementptr inbounds i8, i8* %34, i64 16
  %53 = bitcast i8* %52 to <16 x i8>*
  %54 = load <16 x i8>, <16 x i8>* %53, align 1
  %55 = bitcast i8* %51 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = shufflevector <16 x i8> %54, <16 x i8> %56, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %57, <16 x i8> %12) #4
  %59 = add <8 x i16> %58, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %60 = ashr <8 x i16> %59, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %61 = shufflevector <16 x i8> %54, <16 x i8> %56, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %62 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %61, <16 x i8> %12) #4
  %63 = add <8 x i16> %62, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %64 = ashr <8 x i16> %63, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %65 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %60, <8 x i16> %64) #4
  %66 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %65, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %32, i64 32
  %68 = getelementptr inbounds i8, i8* %33, i64 32
  %69 = getelementptr inbounds i8, i8* %34, i64 32
  %70 = add i32 %35, -2
  %71 = icmp eq i32 %70, 0
  br i1 %71, label %72, label %31

72:                                               ; preds = %31, %26
  %73 = phi i8* [ undef, %26 ], [ %67, %31 ]
  %74 = phi i8* [ undef, %26 ], [ %68, %31 ]
  %75 = phi i8* [ undef, %26 ], [ %69, %31 ]
  %76 = phi i8* [ %27, %26 ], [ %67, %31 ]
  %77 = phi i8* [ %28, %26 ], [ %68, %31 ]
  %78 = phi i8* [ %29, %26 ], [ %69, %31 ]
  br i1 %25, label %97, label %79

79:                                               ; preds = %72
  %80 = bitcast i8* %78 to <16 x i8>*
  %81 = load <16 x i8>, <16 x i8>* %80, align 1
  %82 = bitcast i8* %77 to <16 x i8>*
  %83 = load <16 x i8>, <16 x i8>* %82, align 1
  %84 = shufflevector <16 x i8> %81, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %85 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> %12) #4
  %86 = add <8 x i16> %85, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %87 = ashr <8 x i16> %86, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %88 = shufflevector <16 x i8> %81, <16 x i8> %83, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %89 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %88, <16 x i8> %12) #4
  %90 = add <8 x i16> %89, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %91 = ashr <8 x i16> %90, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %92 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %87, <8 x i16> %91) #4
  %93 = bitcast i8* %76 to <16 x i8>*
  store <16 x i8> %92, <16 x i8>* %93, align 1
  %94 = getelementptr inbounds i8, i8* %78, i64 16
  %95 = getelementptr inbounds i8, i8* %77, i64 16
  %96 = getelementptr inbounds i8, i8* %76, i64 16
  br label %97

97:                                               ; preds = %72, %79
  %98 = phi i8* [ %73, %72 ], [ %96, %79 ]
  %99 = phi i8* [ %74, %72 ], [ %95, %79 ]
  %100 = phi i8* [ %75, %72 ], [ %94, %79 ]
  %101 = getelementptr inbounds i8, i8* %100, i64 %18
  %102 = add nuw nsw i32 %30, 1
  %103 = icmp eq i32 %102, %3
  br i1 %103, label %219, label %26

104:                                              ; preds = %7
  %105 = icmp sgt i32 %2, 7
  %106 = icmp sgt i32 %3, 0
  br i1 %105, label %116, label %107

107:                                              ; preds = %104
  br i1 %106, label %108, label %219

108:                                              ; preds = %107
  %109 = sext i32 %5 to i64
  %110 = shl nsw i32 %5, 1
  %111 = sext i32 %110 to i64
  %112 = mul nsw i32 %5, 3
  %113 = sext i32 %112 to i64
  %114 = shl nsw i32 %5, 2
  %115 = sext i32 %114 to i64
  br label %151

116:                                              ; preds = %104
  br i1 %106, label %117, label %219

117:                                              ; preds = %116
  %118 = sext i32 %5 to i64
  %119 = shl nsw i32 %5, 1
  %120 = sext i32 %119 to i64
  br label %121

121:                                              ; preds = %117, %121
  %122 = phi i8* [ %0, %117 ], [ %146, %121 ]
  %123 = phi i8* [ %1, %117 ], [ %147, %121 ]
  %124 = phi i8* [ %4, %117 ], [ %148, %121 ]
  %125 = phi i32 [ 0, %117 ], [ %149, %121 ]
  %126 = bitcast i8* %124 to i64*
  %127 = load i64, i64* %126, align 1
  %128 = insertelement <2 x i64> undef, i64 %127, i32 0
  %129 = getelementptr inbounds i8, i8* %124, i64 %118
  %130 = bitcast i8* %129 to i64*
  %131 = load i64, i64* %130, align 1
  %132 = insertelement <2 x i64> %128, i64 %131, i32 1
  %133 = bitcast i8* %123 to <16 x i8>*
  %134 = load <16 x i8>, <16 x i8>* %133, align 1
  %135 = bitcast <2 x i64> %132 to <16 x i8>
  %136 = shufflevector <16 x i8> %135, <16 x i8> %134, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %137 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %136, <16 x i8> %12) #4
  %138 = add <8 x i16> %137, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %139 = ashr <8 x i16> %138, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %140 = shufflevector <16 x i8> %135, <16 x i8> %134, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %141 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %140, <16 x i8> %12) #4
  %142 = add <8 x i16> %141, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %143 = ashr <8 x i16> %142, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %144 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %139, <8 x i16> %143) #4
  %145 = bitcast i8* %122 to <16 x i8>*
  store <16 x i8> %144, <16 x i8>* %145, align 1
  %146 = getelementptr inbounds i8, i8* %122, i64 16
  %147 = getelementptr inbounds i8, i8* %123, i64 16
  %148 = getelementptr inbounds i8, i8* %124, i64 %120
  %149 = add nuw nsw i32 %125, 2
  %150 = icmp slt i32 %149, %3
  br i1 %150, label %121, label %219

151:                                              ; preds = %108, %151
  %152 = phi i8* [ %0, %108 ], [ %214, %151 ]
  %153 = phi i8* [ %1, %108 ], [ %215, %151 ]
  %154 = phi i8* [ %4, %108 ], [ %216, %151 ]
  %155 = phi i32 [ 0, %108 ], [ %217, %151 ]
  %156 = getelementptr inbounds i8, i8* %154, i64 %109
  %157 = getelementptr inbounds i8, i8* %154, i64 %111
  %158 = getelementptr inbounds i8, i8* %154, i64 %113
  %159 = bitcast i8* %154 to <4 x i8>*
  %160 = load <4 x i8>, <4 x i8>* %159, align 1
  %161 = load i8, i8* %156, align 1
  %162 = getelementptr inbounds i8, i8* %156, i64 1
  %163 = load i8, i8* %162, align 1
  %164 = getelementptr inbounds i8, i8* %156, i64 2
  %165 = load i8, i8* %164, align 1
  %166 = getelementptr inbounds i8, i8* %156, i64 3
  %167 = load i8, i8* %166, align 1
  %168 = load i8, i8* %157, align 1
  %169 = getelementptr inbounds i8, i8* %157, i64 1
  %170 = load i8, i8* %169, align 1
  %171 = getelementptr inbounds i8, i8* %157, i64 2
  %172 = load i8, i8* %171, align 1
  %173 = getelementptr inbounds i8, i8* %157, i64 3
  %174 = load i8, i8* %173, align 1
  %175 = load i8, i8* %158, align 1
  %176 = getelementptr inbounds i8, i8* %158, i64 1
  %177 = load i8, i8* %176, align 1
  %178 = getelementptr inbounds i8, i8* %158, i64 2
  %179 = load i8, i8* %178, align 1
  %180 = getelementptr inbounds i8, i8* %158, i64 3
  %181 = load i8, i8* %180, align 1
  %182 = extractelement <4 x i8> %160, i32 0
  %183 = insertelement <16 x i8> undef, i8 %182, i32 0
  %184 = extractelement <4 x i8> %160, i32 1
  %185 = insertelement <16 x i8> %183, i8 %184, i32 1
  %186 = extractelement <4 x i8> %160, i32 2
  %187 = insertelement <16 x i8> %185, i8 %186, i32 2
  %188 = extractelement <4 x i8> %160, i32 3
  %189 = insertelement <16 x i8> %187, i8 %188, i32 3
  %190 = insertelement <16 x i8> %189, i8 %161, i32 4
  %191 = insertelement <16 x i8> %190, i8 %163, i32 5
  %192 = insertelement <16 x i8> %191, i8 %165, i32 6
  %193 = insertelement <16 x i8> %192, i8 %167, i32 7
  %194 = insertelement <16 x i8> %193, i8 %168, i32 8
  %195 = insertelement <16 x i8> %194, i8 %170, i32 9
  %196 = insertelement <16 x i8> %195, i8 %172, i32 10
  %197 = insertelement <16 x i8> %196, i8 %174, i32 11
  %198 = insertelement <16 x i8> %197, i8 %175, i32 12
  %199 = insertelement <16 x i8> %198, i8 %177, i32 13
  %200 = insertelement <16 x i8> %199, i8 %179, i32 14
  %201 = insertelement <16 x i8> %200, i8 %181, i32 15
  %202 = bitcast i8* %153 to <16 x i8>*
  %203 = load <16 x i8>, <16 x i8>* %202, align 1
  %204 = shufflevector <16 x i8> %201, <16 x i8> %203, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %205 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %204, <16 x i8> %12) #4
  %206 = add <8 x i16> %205, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %207 = ashr <8 x i16> %206, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %208 = shufflevector <16 x i8> %201, <16 x i8> %203, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %209 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %208, <16 x i8> %12) #4
  %210 = add <8 x i16> %209, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %211 = ashr <8 x i16> %210, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %212 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %207, <8 x i16> %211) #4
  %213 = bitcast i8* %152 to <16 x i8>*
  store <16 x i8> %212, <16 x i8>* %213, align 1
  %214 = getelementptr inbounds i8, i8* %152, i64 16
  %215 = getelementptr inbounds i8, i8* %153, i64 16
  %216 = getelementptr inbounds i8, i8* %154, i64 %115
  %217 = add nuw nsw i32 %155, 4
  %218 = icmp slt i32 %217, %3
  br i1 %218, label %151, label %219

219:                                              ; preds = %151, %121, %97, %107, %116, %14
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @aom_dist_wtd_comp_avg_upsampled_pred_ssse3(%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i8* nocapture readonly, i32, i32, i32, i32, i8*, i32, %struct.dist_wtd_comp_params* nocapture readonly, i32) local_unnamed_addr #0 {
  tail call void @aom_upsampled_pred_sse2(%struct.macroblockd* %0, %struct.AV1Common* %1, i32 %2, i32 %3, %struct.mv* %4, i8* %5, i32 %7, i32 %8, i32 %9, i32 %10, i8* %11, i32 %12, i32 %14) #4
  %16 = mul nsw i32 %8, %7
  %17 = ashr i32 %16, 4
  %18 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %13, i64 0, i32 1
  %19 = bitcast i32* %18 to <2 x i32>*
  %20 = load <2 x i32>, <2 x i32>* %19, align 4
  %21 = trunc <2 x i32> %20 to <2 x i8>
  %22 = shufflevector <2 x i8> %21, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %23 = icmp sgt i32 %16, 15
  br i1 %23, label %24, label %45

24:                                               ; preds = %15, %24
  %25 = phi i8* [ %41, %24 ], [ %5, %15 ]
  %26 = phi i8* [ %42, %24 ], [ %6, %15 ]
  %27 = phi i32 [ %43, %24 ], [ 0, %15 ]
  %28 = bitcast i8* %25 to <16 x i8>*
  %29 = load <16 x i8>, <16 x i8>* %28, align 1
  %30 = bitcast i8* %26 to <16 x i8>*
  %31 = load <16 x i8>, <16 x i8>* %30, align 1
  %32 = shufflevector <16 x i8> %29, <16 x i8> %31, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %33 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %32, <16 x i8> %22) #4
  %34 = add <8 x i16> %33, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %35 = ashr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = shufflevector <16 x i8> %29, <16 x i8> %31, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %37 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %36, <16 x i8> %22) #4
  %38 = add <8 x i16> %37, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %39 = ashr <8 x i16> %38, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %40 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %35, <8 x i16> %39) #4
  store <16 x i8> %40, <16 x i8>* %28, align 1
  %41 = getelementptr inbounds i8, i8* %25, i64 16
  %42 = getelementptr inbounds i8, i8* %26, i64 16
  %43 = add nuw nsw i32 %27, 1
  %44 = icmp slt i32 %43, %17
  br i1 %44, label %24, label %45

45:                                               ; preds = %24, %15
  ret void
}

declare void @aom_upsampled_pred_sse2(%struct.macroblockd*, %struct.AV1Common*, i32, i32, %struct.mv*, i8*, i32, i32, i32, i32, i8*, i32, i32) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance128x128_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [16512 x i16], align 16
  %11 = alloca [16384 x i8], align 16
  %12 = alloca [16384 x i8], align 16
  %13 = bitcast [16512 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 33024, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 33024, i1 false)
  %14 = getelementptr inbounds [16384 x i8], [16384 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 16384, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 16384, i1 false)
  %15 = getelementptr inbounds [16384 x i8], [16384 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 16384, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 16384, i1 false)
  %16 = getelementptr inbounds [16512 x i16], [16512 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 129, i32 128, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 128, i32 128, i32 128, i32 128, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %164, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %165, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %166, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %167, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = bitcast i8* %64 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 1
  %67 = bitcast i8* %63 to <16 x i8>*
  %68 = load <16 x i8>, <16 x i8>* %67, align 1
  %69 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %70 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %25) #4
  %71 = add <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = ashr <8 x i16> %71, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %73 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %74 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %25) #4
  %75 = add <8 x i16> %74, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %76 = ashr <8 x i16> %75, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %77 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> %76) #4
  %78 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %27, i64 48
  %80 = getelementptr inbounds i8, i8* %28, i64 48
  %81 = getelementptr inbounds i8, i8* %29, i64 48
  %82 = bitcast i8* %81 to <16 x i8>*
  %83 = load <16 x i8>, <16 x i8>* %82, align 1
  %84 = bitcast i8* %80 to <16 x i8>*
  %85 = load <16 x i8>, <16 x i8>* %84, align 1
  %86 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %87 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %86, <16 x i8> %25) #4
  %88 = add <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = ashr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %91 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %90, <16 x i8> %25) #4
  %92 = add <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = ashr <8 x i16> %92, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %94 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> %93) #4
  %95 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %94, <16 x i8>* %95, align 1
  %96 = getelementptr inbounds i8, i8* %27, i64 64
  %97 = getelementptr inbounds i8, i8* %28, i64 64
  %98 = getelementptr inbounds i8, i8* %29, i64 64
  %99 = bitcast i8* %98 to <16 x i8>*
  %100 = load <16 x i8>, <16 x i8>* %99, align 1
  %101 = bitcast i8* %97 to <16 x i8>*
  %102 = load <16 x i8>, <16 x i8>* %101, align 1
  %103 = shufflevector <16 x i8> %100, <16 x i8> %102, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %104 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %103, <16 x i8> %25) #4
  %105 = add <8 x i16> %104, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %106 = ashr <8 x i16> %105, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %107 = shufflevector <16 x i8> %100, <16 x i8> %102, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %108 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %107, <16 x i8> %25) #4
  %109 = add <8 x i16> %108, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %110 = ashr <8 x i16> %109, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %111 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %106, <8 x i16> %110) #4
  %112 = bitcast i8* %96 to <16 x i8>*
  store <16 x i8> %111, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %27, i64 80
  %114 = getelementptr inbounds i8, i8* %28, i64 80
  %115 = getelementptr inbounds i8, i8* %29, i64 80
  %116 = bitcast i8* %115 to <16 x i8>*
  %117 = load <16 x i8>, <16 x i8>* %116, align 1
  %118 = bitcast i8* %114 to <16 x i8>*
  %119 = load <16 x i8>, <16 x i8>* %118, align 1
  %120 = shufflevector <16 x i8> %117, <16 x i8> %119, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %121 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %120, <16 x i8> %25) #4
  %122 = add <8 x i16> %121, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %123 = ashr <8 x i16> %122, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %124 = shufflevector <16 x i8> %117, <16 x i8> %119, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %125 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %124, <16 x i8> %25) #4
  %126 = add <8 x i16> %125, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %127 = ashr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %123, <8 x i16> %127) #4
  %129 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %128, <16 x i8>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %27, i64 96
  %131 = getelementptr inbounds i8, i8* %28, i64 96
  %132 = getelementptr inbounds i8, i8* %29, i64 96
  %133 = bitcast i8* %132 to <16 x i8>*
  %134 = load <16 x i8>, <16 x i8>* %133, align 1
  %135 = bitcast i8* %131 to <16 x i8>*
  %136 = load <16 x i8>, <16 x i8>* %135, align 1
  %137 = shufflevector <16 x i8> %134, <16 x i8> %136, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %138 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %137, <16 x i8> %25) #4
  %139 = add <8 x i16> %138, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %140 = ashr <8 x i16> %139, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %141 = shufflevector <16 x i8> %134, <16 x i8> %136, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %142 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %141, <16 x i8> %25) #4
  %143 = add <8 x i16> %142, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %144 = ashr <8 x i16> %143, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %145 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %140, <8 x i16> %144) #4
  %146 = bitcast i8* %130 to <16 x i8>*
  store <16 x i8> %145, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %27, i64 112
  %148 = getelementptr inbounds i8, i8* %28, i64 112
  %149 = getelementptr inbounds i8, i8* %29, i64 112
  %150 = bitcast i8* %149 to <16 x i8>*
  %151 = load <16 x i8>, <16 x i8>* %150, align 1
  %152 = bitcast i8* %148 to <16 x i8>*
  %153 = load <16 x i8>, <16 x i8>* %152, align 1
  %154 = shufflevector <16 x i8> %151, <16 x i8> %153, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %155 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %154, <16 x i8> %25) #4
  %156 = add <8 x i16> %155, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %157 = ashr <8 x i16> %156, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %158 = shufflevector <16 x i8> %151, <16 x i8> %153, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %159 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %158, <16 x i8> %25) #4
  %160 = add <8 x i16> %159, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %161 = ashr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %157, <8 x i16> %161) #4
  %163 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %162, <16 x i8>* %163, align 1
  %164 = getelementptr inbounds i8, i8* %27, i64 128
  %165 = getelementptr inbounds i8, i8* %28, i64 128
  %166 = getelementptr inbounds i8, i8* %29, i64 128
  %167 = add nuw nsw i32 %30, 1
  %168 = icmp eq i32 %167, 128
  br i1 %168, label %169, label %26

169:                                              ; preds = %26
  %170 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance128x128, align 8
  %171 = call i32 %170(i8* nonnull %15, i32 128, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 16384, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 16384, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 33024, i8* nonnull %13) #4
  ret i32 %171
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

declare void @aom_var_filter_block2d_bil_first_pass_ssse3(i8*, i16*, i32, i32, i32, i32, i8*) local_unnamed_addr #2

declare void @aom_var_filter_block2d_bil_second_pass_ssse3(i16*, i8*, i32, i32, i32, i32, i8*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance128x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [8320 x i16], align 16
  %11 = alloca [8192 x i8], align 16
  %12 = alloca [8192 x i8], align 16
  %13 = bitcast [8320 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16640, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 16640, i1 false)
  %14 = getelementptr inbounds [8192 x i8], [8192 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 8192, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 8192, i1 false)
  %15 = getelementptr inbounds [8192 x i8], [8192 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 8192, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 8192, i1 false)
  %16 = getelementptr inbounds [8320 x i16], [8320 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 65, i32 128, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 128, i32 128, i32 64, i32 128, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %164, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %165, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %166, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %167, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = bitcast i8* %64 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 1
  %67 = bitcast i8* %63 to <16 x i8>*
  %68 = load <16 x i8>, <16 x i8>* %67, align 1
  %69 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %70 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %25) #4
  %71 = add <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = ashr <8 x i16> %71, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %73 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %74 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %25) #4
  %75 = add <8 x i16> %74, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %76 = ashr <8 x i16> %75, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %77 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> %76) #4
  %78 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %27, i64 48
  %80 = getelementptr inbounds i8, i8* %28, i64 48
  %81 = getelementptr inbounds i8, i8* %29, i64 48
  %82 = bitcast i8* %81 to <16 x i8>*
  %83 = load <16 x i8>, <16 x i8>* %82, align 1
  %84 = bitcast i8* %80 to <16 x i8>*
  %85 = load <16 x i8>, <16 x i8>* %84, align 1
  %86 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %87 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %86, <16 x i8> %25) #4
  %88 = add <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = ashr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %91 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %90, <16 x i8> %25) #4
  %92 = add <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = ashr <8 x i16> %92, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %94 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> %93) #4
  %95 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %94, <16 x i8>* %95, align 1
  %96 = getelementptr inbounds i8, i8* %27, i64 64
  %97 = getelementptr inbounds i8, i8* %28, i64 64
  %98 = getelementptr inbounds i8, i8* %29, i64 64
  %99 = bitcast i8* %98 to <16 x i8>*
  %100 = load <16 x i8>, <16 x i8>* %99, align 1
  %101 = bitcast i8* %97 to <16 x i8>*
  %102 = load <16 x i8>, <16 x i8>* %101, align 1
  %103 = shufflevector <16 x i8> %100, <16 x i8> %102, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %104 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %103, <16 x i8> %25) #4
  %105 = add <8 x i16> %104, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %106 = ashr <8 x i16> %105, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %107 = shufflevector <16 x i8> %100, <16 x i8> %102, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %108 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %107, <16 x i8> %25) #4
  %109 = add <8 x i16> %108, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %110 = ashr <8 x i16> %109, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %111 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %106, <8 x i16> %110) #4
  %112 = bitcast i8* %96 to <16 x i8>*
  store <16 x i8> %111, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %27, i64 80
  %114 = getelementptr inbounds i8, i8* %28, i64 80
  %115 = getelementptr inbounds i8, i8* %29, i64 80
  %116 = bitcast i8* %115 to <16 x i8>*
  %117 = load <16 x i8>, <16 x i8>* %116, align 1
  %118 = bitcast i8* %114 to <16 x i8>*
  %119 = load <16 x i8>, <16 x i8>* %118, align 1
  %120 = shufflevector <16 x i8> %117, <16 x i8> %119, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %121 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %120, <16 x i8> %25) #4
  %122 = add <8 x i16> %121, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %123 = ashr <8 x i16> %122, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %124 = shufflevector <16 x i8> %117, <16 x i8> %119, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %125 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %124, <16 x i8> %25) #4
  %126 = add <8 x i16> %125, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %127 = ashr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %123, <8 x i16> %127) #4
  %129 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %128, <16 x i8>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %27, i64 96
  %131 = getelementptr inbounds i8, i8* %28, i64 96
  %132 = getelementptr inbounds i8, i8* %29, i64 96
  %133 = bitcast i8* %132 to <16 x i8>*
  %134 = load <16 x i8>, <16 x i8>* %133, align 1
  %135 = bitcast i8* %131 to <16 x i8>*
  %136 = load <16 x i8>, <16 x i8>* %135, align 1
  %137 = shufflevector <16 x i8> %134, <16 x i8> %136, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %138 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %137, <16 x i8> %25) #4
  %139 = add <8 x i16> %138, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %140 = ashr <8 x i16> %139, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %141 = shufflevector <16 x i8> %134, <16 x i8> %136, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %142 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %141, <16 x i8> %25) #4
  %143 = add <8 x i16> %142, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %144 = ashr <8 x i16> %143, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %145 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %140, <8 x i16> %144) #4
  %146 = bitcast i8* %130 to <16 x i8>*
  store <16 x i8> %145, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %27, i64 112
  %148 = getelementptr inbounds i8, i8* %28, i64 112
  %149 = getelementptr inbounds i8, i8* %29, i64 112
  %150 = bitcast i8* %149 to <16 x i8>*
  %151 = load <16 x i8>, <16 x i8>* %150, align 1
  %152 = bitcast i8* %148 to <16 x i8>*
  %153 = load <16 x i8>, <16 x i8>* %152, align 1
  %154 = shufflevector <16 x i8> %151, <16 x i8> %153, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %155 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %154, <16 x i8> %25) #4
  %156 = add <8 x i16> %155, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %157 = ashr <8 x i16> %156, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %158 = shufflevector <16 x i8> %151, <16 x i8> %153, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %159 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %158, <16 x i8> %25) #4
  %160 = add <8 x i16> %159, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %161 = ashr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %157, <8 x i16> %161) #4
  %163 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %162, <16 x i8>* %163, align 1
  %164 = getelementptr inbounds i8, i8* %27, i64 128
  %165 = getelementptr inbounds i8, i8* %28, i64 128
  %166 = getelementptr inbounds i8, i8* %29, i64 128
  %167 = add nuw nsw i32 %30, 1
  %168 = icmp eq i32 %167, 64
  br i1 %168, label %169, label %26

169:                                              ; preds = %26
  %170 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance128x64, align 8
  %171 = call i32 %170(i8* nonnull %15, i32 128, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 8192, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 8192, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 16640, i8* nonnull %13) #4
  ret i32 %171
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance64x128_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [8256 x i16], align 16
  %11 = alloca [8192 x i8], align 16
  %12 = alloca [8192 x i8], align 16
  %13 = bitcast [8256 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16512, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 16512, i1 false)
  %14 = getelementptr inbounds [8192 x i8], [8192 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 8192, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 8192, i1 false)
  %15 = getelementptr inbounds [8192 x i8], [8192 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 8192, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 8192, i1 false)
  %16 = getelementptr inbounds [8256 x i16], [8256 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 129, i32 64, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 64, i32 64, i32 128, i32 64, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %96, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %97, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %98, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %99, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = bitcast i8* %64 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 1
  %67 = bitcast i8* %63 to <16 x i8>*
  %68 = load <16 x i8>, <16 x i8>* %67, align 1
  %69 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %70 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %25) #4
  %71 = add <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = ashr <8 x i16> %71, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %73 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %74 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %25) #4
  %75 = add <8 x i16> %74, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %76 = ashr <8 x i16> %75, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %77 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> %76) #4
  %78 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %27, i64 48
  %80 = getelementptr inbounds i8, i8* %28, i64 48
  %81 = getelementptr inbounds i8, i8* %29, i64 48
  %82 = bitcast i8* %81 to <16 x i8>*
  %83 = load <16 x i8>, <16 x i8>* %82, align 1
  %84 = bitcast i8* %80 to <16 x i8>*
  %85 = load <16 x i8>, <16 x i8>* %84, align 1
  %86 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %87 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %86, <16 x i8> %25) #4
  %88 = add <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = ashr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %91 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %90, <16 x i8> %25) #4
  %92 = add <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = ashr <8 x i16> %92, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %94 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> %93) #4
  %95 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %94, <16 x i8>* %95, align 1
  %96 = getelementptr inbounds i8, i8* %27, i64 64
  %97 = getelementptr inbounds i8, i8* %28, i64 64
  %98 = getelementptr inbounds i8, i8* %29, i64 64
  %99 = add nuw nsw i32 %30, 1
  %100 = icmp eq i32 %99, 128
  br i1 %100, label %101, label %26

101:                                              ; preds = %26
  %102 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance64x128, align 8
  %103 = call i32 %102(i8* nonnull %15, i32 64, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 8192, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 8192, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 16512, i8* nonnull %13) #4
  ret i32 %103
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance64x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [4160 x i16], align 16
  %11 = alloca [4096 x i8], align 16
  %12 = alloca [4096 x i8], align 16
  %13 = bitcast [4160 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8320, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 8320, i1 false)
  %14 = getelementptr inbounds [4096 x i8], [4096 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 4096, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 4096, i1 false)
  %15 = getelementptr inbounds [4096 x i8], [4096 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 4096, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 4096, i1 false)
  %16 = getelementptr inbounds [4160 x i16], [4160 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 65, i32 64, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 64, i32 64, i32 64, i32 64, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %96, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %97, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %98, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %99, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = bitcast i8* %64 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 1
  %67 = bitcast i8* %63 to <16 x i8>*
  %68 = load <16 x i8>, <16 x i8>* %67, align 1
  %69 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %70 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %25) #4
  %71 = add <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = ashr <8 x i16> %71, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %73 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %74 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %25) #4
  %75 = add <8 x i16> %74, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %76 = ashr <8 x i16> %75, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %77 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> %76) #4
  %78 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %27, i64 48
  %80 = getelementptr inbounds i8, i8* %28, i64 48
  %81 = getelementptr inbounds i8, i8* %29, i64 48
  %82 = bitcast i8* %81 to <16 x i8>*
  %83 = load <16 x i8>, <16 x i8>* %82, align 1
  %84 = bitcast i8* %80 to <16 x i8>*
  %85 = load <16 x i8>, <16 x i8>* %84, align 1
  %86 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %87 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %86, <16 x i8> %25) #4
  %88 = add <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = ashr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %91 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %90, <16 x i8> %25) #4
  %92 = add <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = ashr <8 x i16> %92, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %94 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> %93) #4
  %95 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %94, <16 x i8>* %95, align 1
  %96 = getelementptr inbounds i8, i8* %27, i64 64
  %97 = getelementptr inbounds i8, i8* %28, i64 64
  %98 = getelementptr inbounds i8, i8* %29, i64 64
  %99 = add nuw nsw i32 %30, 1
  %100 = icmp eq i32 %99, 64
  br i1 %100, label %101, label %26

101:                                              ; preds = %26
  %102 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance64x64, align 8
  %103 = call i32 %102(i8* nonnull %15, i32 64, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 4096, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 4096, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 8320, i8* nonnull %13) #4
  ret i32 %103
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance64x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [2112 x i16], align 16
  %11 = alloca [2048 x i8], align 16
  %12 = alloca [2048 x i8], align 16
  %13 = bitcast [2112 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4224, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 4224, i1 false)
  %14 = getelementptr inbounds [2048 x i8], [2048 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 2048, i1 false)
  %15 = getelementptr inbounds [2048 x i8], [2048 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 2048, i1 false)
  %16 = getelementptr inbounds [2112 x i16], [2112 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 33, i32 64, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 64, i32 64, i32 32, i32 64, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %96, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %97, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %98, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %99, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = bitcast i8* %64 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 1
  %67 = bitcast i8* %63 to <16 x i8>*
  %68 = load <16 x i8>, <16 x i8>* %67, align 1
  %69 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %70 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %25) #4
  %71 = add <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = ashr <8 x i16> %71, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %73 = shufflevector <16 x i8> %66, <16 x i8> %68, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %74 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %25) #4
  %75 = add <8 x i16> %74, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %76 = ashr <8 x i16> %75, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %77 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> %76) #4
  %78 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %27, i64 48
  %80 = getelementptr inbounds i8, i8* %28, i64 48
  %81 = getelementptr inbounds i8, i8* %29, i64 48
  %82 = bitcast i8* %81 to <16 x i8>*
  %83 = load <16 x i8>, <16 x i8>* %82, align 1
  %84 = bitcast i8* %80 to <16 x i8>*
  %85 = load <16 x i8>, <16 x i8>* %84, align 1
  %86 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %87 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %86, <16 x i8> %25) #4
  %88 = add <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = ashr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = shufflevector <16 x i8> %83, <16 x i8> %85, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %91 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %90, <16 x i8> %25) #4
  %92 = add <8 x i16> %91, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %93 = ashr <8 x i16> %92, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %94 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> %93) #4
  %95 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %94, <16 x i8>* %95, align 1
  %96 = getelementptr inbounds i8, i8* %27, i64 64
  %97 = getelementptr inbounds i8, i8* %28, i64 64
  %98 = getelementptr inbounds i8, i8* %29, i64 64
  %99 = add nuw nsw i32 %30, 1
  %100 = icmp eq i32 %99, 32
  br i1 %100, label %101, label %26

101:                                              ; preds = %26
  %102 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance64x32, align 8
  %103 = call i32 %102(i8* nonnull %15, i32 64, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 4224, i8* nonnull %13) #4
  ret i32 %103
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance32x64_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [2080 x i16], align 16
  %11 = alloca [2048 x i8], align 16
  %12 = alloca [2048 x i8], align 16
  %13 = bitcast [2080 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4160, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 4160, i1 false)
  %14 = getelementptr inbounds [2048 x i8], [2048 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 2048, i1 false)
  %15 = getelementptr inbounds [2048 x i8], [2048 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 2048, i1 false)
  %16 = getelementptr inbounds [2080 x i16], [2080 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 65, i32 32, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 32, i32 32, i32 64, i32 32, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %62, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %63, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %64, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %65, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = add nuw nsw i32 %30, 1
  %66 = icmp eq i32 %65, 64
  br i1 %66, label %67, label %26

67:                                               ; preds = %26
  %68 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance32x64, align 8
  %69 = call i32 %68(i8* nonnull %15, i32 32, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 4160, i8* nonnull %13) #4
  ret i32 %69
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance32x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [1056 x i16], align 16
  %11 = alloca [1024 x i8], align 16
  %12 = alloca [1024 x i8], align 16
  %13 = bitcast [1056 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2112, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 2112, i1 false)
  %14 = getelementptr inbounds [1024 x i8], [1024 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 1024, i1 false)
  %15 = getelementptr inbounds [1024 x i8], [1024 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 1024, i1 false)
  %16 = getelementptr inbounds [1056 x i16], [1056 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 33, i32 32, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 32, i32 32, i32 32, i32 32, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %62, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %63, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %64, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %65, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = add nuw nsw i32 %30, 1
  %66 = icmp eq i32 %65, 32
  br i1 %66, label %67, label %26

67:                                               ; preds = %26
  %68 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance32x32, align 8
  %69 = call i32 %68(i8* nonnull %15, i32 32, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 2112, i8* nonnull %13) #4
  ret i32 %69
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance32x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [544 x i16], align 16
  %11 = alloca [512 x i8], align 16
  %12 = alloca [512 x i8], align 16
  %13 = bitcast [544 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1088, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 1088, i1 false)
  %14 = getelementptr inbounds [512 x i8], [512 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 512, i1 false)
  %15 = getelementptr inbounds [512 x i8], [512 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 512, i1 false)
  %16 = getelementptr inbounds [544 x i16], [544 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 17, i32 32, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 32, i32 32, i32 16, i32 32, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %62, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %63, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %64, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %65, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = add nuw nsw i32 %30, 1
  %66 = icmp eq i32 %65, 16
  br i1 %66, label %67, label %26

67:                                               ; preds = %26
  %68 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance32x16, align 8
  %69 = call i32 %68(i8* nonnull %15, i32 32, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 1088, i8* nonnull %13) #4
  ret i32 %69
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance16x32_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [528 x i16], align 16
  %11 = alloca [512 x i8], align 16
  %12 = alloca [512 x i8], align 16
  %13 = bitcast [528 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1056, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 1056, i1 false)
  %14 = getelementptr inbounds [512 x i8], [512 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 512, i1 false)
  %15 = getelementptr inbounds [512 x i8], [512 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 512, i1 false)
  %16 = getelementptr inbounds [528 x i16], [528 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 33, i32 16, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 16, i32 16, i32 32, i32 16, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %62, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %63, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %64, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %65, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = add nuw nsw i32 %30, 2
  %66 = icmp eq i32 %65, 32
  br i1 %66, label %67, label %26

67:                                               ; preds = %26
  %68 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance16x32, align 8
  %69 = call i32 %68(i8* nonnull %15, i32 16, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 1056, i8* nonnull %13) #4
  ret i32 %69
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance16x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [272 x i16], align 16
  %11 = alloca [256 x i8], align 16
  %12 = alloca [256 x i8], align 16
  %13 = bitcast [272 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 544, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 544, i1 false)
  %14 = getelementptr inbounds [256 x i8], [256 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 256, i1 false)
  %15 = getelementptr inbounds [256 x i8], [256 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %15) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 256, i1 false)
  %16 = getelementptr inbounds [272 x i16], [272 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 17, i32 16, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 16, i32 16, i32 16, i32 16, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  br label %26

26:                                               ; preds = %26, %9
  %27 = phi i8* [ %15, %9 ], [ %62, %26 ]
  %28 = phi i8* [ %7, %9 ], [ %63, %26 ]
  %29 = phi i8* [ %14, %9 ], [ %64, %26 ]
  %30 = phi i32 [ 0, %9 ], [ %65, %26 ]
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = bitcast i8* %28 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %25) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = shufflevector <16 x i8> %32, <16 x i8> %34, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %40 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %39, <16 x i8> %25) #4
  %41 = add <8 x i16> %40, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %42 = ashr <8 x i16> %41, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %43 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %42) #4
  %44 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %43, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %27, i64 16
  %46 = getelementptr inbounds i8, i8* %28, i64 16
  %47 = getelementptr inbounds i8, i8* %29, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  %49 = load <16 x i8>, <16 x i8>* %48, align 1
  %50 = bitcast i8* %46 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %25) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = shufflevector <16 x i8> %49, <16 x i8> %51, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %57 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> %25) #4
  %58 = add <8 x i16> %57, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %59 = ashr <8 x i16> %58, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %60 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %59) #4
  %61 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %60, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %27, i64 32
  %63 = getelementptr inbounds i8, i8* %28, i64 32
  %64 = getelementptr inbounds i8, i8* %29, i64 32
  %65 = add nuw nsw i32 %30, 2
  %66 = icmp eq i32 %65, 16
  br i1 %66, label %67, label %26

67:                                               ; preds = %26
  %68 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance16x16, align 8
  %69 = call i32 %68(i8* nonnull %15, i32 16, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 544, i8* nonnull %13) #4
  ret i32 %69
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance16x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [144 x i16], align 16
  %11 = alloca [128 x i8], align 16
  %12 = alloca [128 x i8], align 16
  %13 = bitcast [144 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 288, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 288, i1 false)
  %14 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 128, i1 false)
  %15 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15) #4
  %16 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 64
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 -86, i64 64, i1 false)
  %17 = getelementptr inbounds [144 x i16], [144 x i16]* %10, i64 0, i64 0
  %18 = sext i32 %2 to i64
  %19 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %18, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %17, i32 %1, i32 1, i32 9, i32 16, i8* %19) #4
  %20 = sext i32 %3 to i64
  %21 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %20, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %17, i8* nonnull %14, i32 16, i32 16, i32 8, i32 16, i8* %21) #4
  %22 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %23 = bitcast i32* %22 to <2 x i32>*
  %24 = load <2 x i32>, <2 x i32>* %23, align 4
  %25 = trunc <2 x i32> %24 to <2 x i8>
  %26 = shufflevector <2 x i8> %25, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %27 = bitcast [128 x i8]* %11 to <16 x i8>*
  %28 = load <16 x i8>, <16 x i8>* %27, align 16
  %29 = bitcast i8* %7 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = shufflevector <16 x i8> %28, <16 x i8> %30, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %32 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %31, <16 x i8> %26) #4
  %33 = add <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = ashr <8 x i16> %33, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %35 = shufflevector <16 x i8> %28, <16 x i8> %30, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %26) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> %38) #4
  %40 = bitcast [128 x i8]* %12 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 16
  %42 = getelementptr inbounds i8, i8* %7, i64 16
  %43 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 16
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 16
  %46 = bitcast i8* %42 to <16 x i8>*
  %47 = load <16 x i8>, <16 x i8>* %46, align 1
  %48 = shufflevector <16 x i8> %45, <16 x i8> %47, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %49 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> %26) #4
  %50 = add <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = ashr <8 x i16> %50, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %52 = shufflevector <16 x i8> %45, <16 x i8> %47, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %26) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %51, <8 x i16> %55) #4
  %57 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 16
  %58 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 32
  %59 = getelementptr inbounds i8, i8* %7, i64 32
  %60 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 32
  %61 = bitcast i8* %60 to <16 x i8>*
  %62 = load <16 x i8>, <16 x i8>* %61, align 16
  %63 = bitcast i8* %59 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %62, <16 x i8> %64, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %26) #4
  %67 = add <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = ashr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = shufflevector <16 x i8> %62, <16 x i8> %64, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %26) #4
  %71 = add <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = ashr <8 x i16> %71, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %73 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #4
  %74 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 48
  %76 = getelementptr inbounds i8, i8* %7, i64 48
  %77 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 48
  %78 = bitcast i8* %77 to <16 x i8>*
  %79 = load <16 x i8>, <16 x i8>* %78, align 16
  %80 = bitcast i8* %76 to <16 x i8>*
  %81 = load <16 x i8>, <16 x i8>* %80, align 1
  %82 = shufflevector <16 x i8> %79, <16 x i8> %81, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %83 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %82, <16 x i8> %26) #4
  %84 = add <8 x i16> %83, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %85 = ashr <8 x i16> %84, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %86 = shufflevector <16 x i8> %79, <16 x i8> %81, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %87 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %86, <16 x i8> %26) #4
  %88 = add <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = ashr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> %89) #4
  %91 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %90, <16 x i8>* %91, align 16
  %92 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 64
  %93 = getelementptr inbounds i8, i8* %7, i64 64
  %94 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 64
  %95 = bitcast i8* %94 to <16 x i8>*
  %96 = load <16 x i8>, <16 x i8>* %95, align 16
  %97 = bitcast i8* %93 to <16 x i8>*
  %98 = load <16 x i8>, <16 x i8>* %97, align 1
  %99 = shufflevector <16 x i8> %96, <16 x i8> %98, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %100 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %99, <16 x i8> %26) #4
  %101 = add <8 x i16> %100, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %102 = ashr <8 x i16> %101, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %103 = shufflevector <16 x i8> %96, <16 x i8> %98, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %104 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %103, <16 x i8> %26) #4
  %105 = add <8 x i16> %104, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %106 = ashr <8 x i16> %105, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %107 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %102, <8 x i16> %106) #4
  %108 = bitcast i8* %92 to <16 x i8>*
  store <16 x i8> %107, <16 x i8>* %108, align 16
  %109 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 80
  %110 = getelementptr inbounds i8, i8* %7, i64 80
  %111 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 80
  %112 = bitcast i8* %111 to <16 x i8>*
  %113 = load <16 x i8>, <16 x i8>* %112, align 16
  %114 = bitcast i8* %110 to <16 x i8>*
  %115 = load <16 x i8>, <16 x i8>* %114, align 1
  %116 = shufflevector <16 x i8> %113, <16 x i8> %115, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %117 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %116, <16 x i8> %26) #4
  %118 = add <8 x i16> %117, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %119 = ashr <8 x i16> %118, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %120 = shufflevector <16 x i8> %113, <16 x i8> %115, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %121 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %120, <16 x i8> %26) #4
  %122 = add <8 x i16> %121, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %123 = ashr <8 x i16> %122, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %124 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> %123) #4
  %125 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %124, <16 x i8>* %125, align 16
  %126 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 96
  %127 = getelementptr inbounds i8, i8* %7, i64 96
  %128 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 96
  %129 = bitcast i8* %128 to <16 x i8>*
  %130 = load <16 x i8>, <16 x i8>* %129, align 16
  %131 = bitcast i8* %127 to <16 x i8>*
  %132 = load <16 x i8>, <16 x i8>* %131, align 1
  %133 = shufflevector <16 x i8> %130, <16 x i8> %132, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %134 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %133, <16 x i8> %26) #4
  %135 = add <8 x i16> %134, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %136 = ashr <8 x i16> %135, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %137 = shufflevector <16 x i8> %130, <16 x i8> %132, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %138 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %137, <16 x i8> %26) #4
  %139 = add <8 x i16> %138, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %140 = ashr <8 x i16> %139, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %141 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %136, <8 x i16> %140) #4
  %142 = bitcast i8* %126 to <16 x i8>*
  store <16 x i8> %141, <16 x i8>* %142, align 16
  %143 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 112
  %144 = getelementptr inbounds i8, i8* %7, i64 112
  %145 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 112
  %146 = bitcast i8* %145 to <16 x i8>*
  %147 = load <16 x i8>, <16 x i8>* %146, align 16
  %148 = bitcast i8* %144 to <16 x i8>*
  %149 = load <16 x i8>, <16 x i8>* %148, align 1
  %150 = shufflevector <16 x i8> %147, <16 x i8> %149, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %151 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %150, <16 x i8> %26) #4
  %152 = add <8 x i16> %151, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %153 = ashr <8 x i16> %152, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %154 = shufflevector <16 x i8> %147, <16 x i8> %149, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %155 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %154, <16 x i8> %26) #4
  %156 = add <8 x i16> %155, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %157 = ashr <8 x i16> %156, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %158 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %153, <8 x i16> %157) #4
  %159 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %158, <16 x i8>* %159, align 16
  %160 = load i32 (i8*, i32, i8*, i32, i32*)*, i32 (i8*, i32, i8*, i32, i32*)** @aom_variance16x8, align 8
  %161 = call i32 %160(i8* nonnull %15, i32 16, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 288, i8* nonnull %13) #4
  ret i32 %161
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance8x16_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [136 x i16], align 16
  %11 = alloca [128 x i8], align 16
  %12 = alloca [128 x i8], align 16
  %13 = bitcast [136 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 272, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 272, i1 false)
  %14 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 128, i1 false)
  %15 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15) #4
  %16 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 48
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds [136 x i16], [136 x i16]* %10, i64 0, i64 0
  %18 = sext i32 %2 to i64
  %19 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %18, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %17, i32 %1, i32 1, i32 17, i32 8, i8* %19) #4
  %20 = sext i32 %3 to i64
  %21 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %20, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %17, i8* nonnull %14, i32 8, i32 8, i32 16, i32 8, i8* %21) #4
  %22 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %23 = bitcast i32* %22 to <2 x i32>*
  %24 = load <2 x i32>, <2 x i32>* %23, align 4
  %25 = trunc <2 x i32> %24 to <2 x i8>
  %26 = shufflevector <2 x i8> %25, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %27 = bitcast [128 x i8]* %11 to <16 x i8>*
  %28 = load <16 x i8>, <16 x i8>* %27, align 16
  %29 = bitcast i8* %7 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = shufflevector <16 x i8> %28, <16 x i8> %30, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %32 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %31, <16 x i8> %26) #4
  %33 = add <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = ashr <8 x i16> %33, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %35 = shufflevector <16 x i8> %28, <16 x i8> %30, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %26) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> %38) #4
  %40 = bitcast [128 x i8]* %12 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 16
  %42 = getelementptr inbounds i8, i8* %7, i64 16
  %43 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 16
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 16
  %46 = bitcast i8* %42 to <16 x i8>*
  %47 = load <16 x i8>, <16 x i8>* %46, align 1
  %48 = shufflevector <16 x i8> %45, <16 x i8> %47, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %49 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> %26) #4
  %50 = add <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = ashr <8 x i16> %50, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %52 = shufflevector <16 x i8> %45, <16 x i8> %47, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %26) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %51, <8 x i16> %55) #4
  %57 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 16
  %58 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 32
  %59 = getelementptr inbounds i8, i8* %7, i64 32
  %60 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 32
  %61 = bitcast i8* %60 to <16 x i8>*
  %62 = load <16 x i8>, <16 x i8>* %61, align 16
  %63 = bitcast i8* %59 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %62, <16 x i8> %64, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %26) #4
  %67 = add <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = ashr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = shufflevector <16 x i8> %62, <16 x i8> %64, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %26) #4
  %71 = add <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = ashr <8 x i16> %71, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %73 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #4
  %74 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 48
  %76 = getelementptr inbounds i8, i8* %7, i64 48
  %77 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 48
  %78 = bitcast i8* %77 to <16 x i8>*
  %79 = load <16 x i8>, <16 x i8>* %78, align 16
  %80 = bitcast i8* %76 to <16 x i8>*
  %81 = load <16 x i8>, <16 x i8>* %80, align 1
  %82 = shufflevector <16 x i8> %79, <16 x i8> %81, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %83 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %82, <16 x i8> %26) #4
  %84 = add <8 x i16> %83, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %85 = ashr <8 x i16> %84, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %86 = shufflevector <16 x i8> %79, <16 x i8> %81, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %87 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %86, <16 x i8> %26) #4
  %88 = add <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = ashr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> %89) #4
  %91 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %90, <16 x i8>* %91, align 16
  %92 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 64
  %93 = getelementptr inbounds i8, i8* %7, i64 64
  %94 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 64
  %95 = bitcast i8* %94 to <16 x i8>*
  %96 = load <16 x i8>, <16 x i8>* %95, align 16
  %97 = bitcast i8* %93 to <16 x i8>*
  %98 = load <16 x i8>, <16 x i8>* %97, align 1
  %99 = shufflevector <16 x i8> %96, <16 x i8> %98, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %100 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %99, <16 x i8> %26) #4
  %101 = add <8 x i16> %100, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %102 = ashr <8 x i16> %101, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %103 = shufflevector <16 x i8> %96, <16 x i8> %98, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %104 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %103, <16 x i8> %26) #4
  %105 = add <8 x i16> %104, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %106 = ashr <8 x i16> %105, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %107 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %102, <8 x i16> %106) #4
  %108 = bitcast i8* %92 to <16 x i8>*
  store <16 x i8> %107, <16 x i8>* %108, align 16
  %109 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 80
  %110 = getelementptr inbounds i8, i8* %7, i64 80
  %111 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 80
  %112 = bitcast i8* %111 to <16 x i8>*
  %113 = load <16 x i8>, <16 x i8>* %112, align 16
  %114 = bitcast i8* %110 to <16 x i8>*
  %115 = load <16 x i8>, <16 x i8>* %114, align 1
  %116 = shufflevector <16 x i8> %113, <16 x i8> %115, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %117 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %116, <16 x i8> %26) #4
  %118 = add <8 x i16> %117, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %119 = ashr <8 x i16> %118, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %120 = shufflevector <16 x i8> %113, <16 x i8> %115, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %121 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %120, <16 x i8> %26) #4
  %122 = add <8 x i16> %121, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %123 = ashr <8 x i16> %122, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %124 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> %123) #4
  %125 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %124, <16 x i8>* %125, align 16
  %126 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 96
  %127 = getelementptr inbounds i8, i8* %7, i64 96
  %128 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 96
  %129 = bitcast i8* %128 to <16 x i8>*
  %130 = load <16 x i8>, <16 x i8>* %129, align 16
  %131 = bitcast i8* %127 to <16 x i8>*
  %132 = load <16 x i8>, <16 x i8>* %131, align 1
  %133 = shufflevector <16 x i8> %130, <16 x i8> %132, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %134 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %133, <16 x i8> %26) #4
  %135 = add <8 x i16> %134, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %136 = ashr <8 x i16> %135, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %137 = shufflevector <16 x i8> %130, <16 x i8> %132, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %138 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %137, <16 x i8> %26) #4
  %139 = add <8 x i16> %138, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %140 = ashr <8 x i16> %139, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %141 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %136, <8 x i16> %140) #4
  %142 = bitcast i8* %126 to <16 x i8>*
  store <16 x i8> %141, <16 x i8>* %142, align 16
  %143 = getelementptr inbounds [128 x i8], [128 x i8]* %12, i64 0, i64 112
  %144 = getelementptr inbounds i8, i8* %7, i64 112
  %145 = getelementptr inbounds [128 x i8], [128 x i8]* %11, i64 0, i64 112
  %146 = bitcast i8* %145 to <16 x i8>*
  %147 = load <16 x i8>, <16 x i8>* %146, align 16
  %148 = bitcast i8* %144 to <16 x i8>*
  %149 = load <16 x i8>, <16 x i8>* %148, align 1
  %150 = shufflevector <16 x i8> %147, <16 x i8> %149, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %151 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %150, <16 x i8> %26) #4
  %152 = add <8 x i16> %151, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %153 = ashr <8 x i16> %152, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %154 = shufflevector <16 x i8> %147, <16 x i8> %149, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %155 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %154, <16 x i8> %26) #4
  %156 = add <8 x i16> %155, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %157 = ashr <8 x i16> %156, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %158 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %153, <8 x i16> %157) #4
  %159 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %158, <16 x i8>* %159, align 16
  %160 = call i32 @aom_variance8x16_sse2(i8* nonnull %15, i32 8, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 272, i8* nonnull %13) #4
  ret i32 %160
}

declare i32 @aom_variance8x16_sse2(i8*, i32, i8*, i32, i32*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance8x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [72 x i16], align 16
  %11 = alloca [64 x i8], align 16
  %12 = alloca [64 x i8], align 16
  %13 = bitcast [72 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 144, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 144, i1 false)
  %14 = getelementptr inbounds [64 x i8], [64 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %14) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 64, i1 false)
  %15 = getelementptr inbounds [64 x i8], [64 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %15) #4
  %16 = getelementptr inbounds [64 x i8], [64 x i8]* %12, i64 0, i64 48
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 -86, i64 16, i1 false)
  %17 = getelementptr inbounds [72 x i16], [72 x i16]* %10, i64 0, i64 0
  %18 = sext i32 %2 to i64
  %19 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %18, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %17, i32 %1, i32 1, i32 9, i32 8, i8* %19) #4
  %20 = sext i32 %3 to i64
  %21 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %20, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %17, i8* nonnull %14, i32 8, i32 8, i32 8, i32 8, i8* %21) #4
  %22 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %23 = bitcast i32* %22 to <2 x i32>*
  %24 = load <2 x i32>, <2 x i32>* %23, align 4
  %25 = trunc <2 x i32> %24 to <2 x i8>
  %26 = shufflevector <2 x i8> %25, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %27 = bitcast [64 x i8]* %11 to <16 x i8>*
  %28 = load <16 x i8>, <16 x i8>* %27, align 16
  %29 = bitcast i8* %7 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = shufflevector <16 x i8> %28, <16 x i8> %30, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %32 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %31, <16 x i8> %26) #4
  %33 = add <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = ashr <8 x i16> %33, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %35 = shufflevector <16 x i8> %28, <16 x i8> %30, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %26) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> %38) #4
  %40 = bitcast [64 x i8]* %12 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds [64 x i8], [64 x i8]* %12, i64 0, i64 16
  %42 = getelementptr inbounds i8, i8* %7, i64 16
  %43 = getelementptr inbounds [64 x i8], [64 x i8]* %11, i64 0, i64 16
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 16
  %46 = bitcast i8* %42 to <16 x i8>*
  %47 = load <16 x i8>, <16 x i8>* %46, align 1
  %48 = shufflevector <16 x i8> %45, <16 x i8> %47, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %49 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> %26) #4
  %50 = add <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = ashr <8 x i16> %50, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %52 = shufflevector <16 x i8> %45, <16 x i8> %47, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %26) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %51, <8 x i16> %55) #4
  %57 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 16
  %58 = getelementptr inbounds [64 x i8], [64 x i8]* %12, i64 0, i64 32
  %59 = getelementptr inbounds i8, i8* %7, i64 32
  %60 = getelementptr inbounds [64 x i8], [64 x i8]* %11, i64 0, i64 32
  %61 = bitcast i8* %60 to <16 x i8>*
  %62 = load <16 x i8>, <16 x i8>* %61, align 16
  %63 = bitcast i8* %59 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %62, <16 x i8> %64, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %26) #4
  %67 = add <8 x i16> %66, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %68 = ashr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = shufflevector <16 x i8> %62, <16 x i8> %64, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %26) #4
  %71 = add <8 x i16> %70, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %72 = ashr <8 x i16> %71, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %73 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #4
  %74 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds [64 x i8], [64 x i8]* %12, i64 0, i64 48
  %76 = getelementptr inbounds i8, i8* %7, i64 48
  %77 = getelementptr inbounds [64 x i8], [64 x i8]* %11, i64 0, i64 48
  %78 = bitcast i8* %77 to <16 x i8>*
  %79 = load <16 x i8>, <16 x i8>* %78, align 16
  %80 = bitcast i8* %76 to <16 x i8>*
  %81 = load <16 x i8>, <16 x i8>* %80, align 1
  %82 = shufflevector <16 x i8> %79, <16 x i8> %81, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %83 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %82, <16 x i8> %26) #4
  %84 = add <8 x i16> %83, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %85 = ashr <8 x i16> %84, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %86 = shufflevector <16 x i8> %79, <16 x i8> %81, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %87 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %86, <16 x i8> %26) #4
  %88 = add <8 x i16> %87, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %89 = ashr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> %89) #4
  %91 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %90, <16 x i8>* %91, align 16
  %92 = call i32 @aom_variance8x8_sse2(i8* nonnull %15, i32 8, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 144, i8* nonnull %13) #4
  ret i32 %92
}

declare i32 @aom_variance8x8_sse2(i8*, i32, i8*, i32, i32*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance8x4_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [40 x i16], align 16
  %11 = alloca [32 x i8], align 16
  %12 = alloca [32 x i8], align 16
  %13 = bitcast [40 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 80, i1 false)
  %14 = getelementptr inbounds [32 x i8], [32 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %14) #4
  %15 = getelementptr inbounds [32 x i8], [32 x i8]* %12, i64 0, i64 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 32, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %15) #4
  %16 = getelementptr inbounds [40 x i16], [40 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 5, i32 8, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 8, i32 8, i32 4, i32 8, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %26 = bitcast [32 x i8]* %11 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 16
  %28 = bitcast i8* %7 to <16 x i8>*
  %29 = load <16 x i8>, <16 x i8>* %28, align 1
  %30 = shufflevector <16 x i8> %27, <16 x i8> %29, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %31 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %30, <16 x i8> %25) #4
  %32 = add <8 x i16> %31, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %33 = ashr <8 x i16> %32, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %34 = shufflevector <16 x i8> %27, <16 x i8> %29, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %35 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %34, <16 x i8> %25) #4
  %36 = add <8 x i16> %35, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %37 = ashr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %33, <8 x i16> %37) #4
  %39 = bitcast [32 x i8]* %12 to <16 x i8>*
  store <16 x i8> %38, <16 x i8>* %39, align 16
  %40 = getelementptr inbounds [32 x i8], [32 x i8]* %12, i64 0, i64 16
  %41 = getelementptr inbounds i8, i8* %7, i64 16
  %42 = getelementptr inbounds [32 x i8], [32 x i8]* %11, i64 0, i64 16
  %43 = bitcast i8* %42 to <16 x i8>*
  %44 = load <16 x i8>, <16 x i8>* %43, align 16
  %45 = bitcast i8* %41 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %44, <16 x i8> %46, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %25) #4
  %49 = add <8 x i16> %48, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %50 = ashr <8 x i16> %49, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %51 = shufflevector <16 x i8> %44, <16 x i8> %46, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %52 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %51, <16 x i8> %25) #4
  %53 = add <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = ashr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %50, <8 x i16> %54) #4
  %56 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %55, <16 x i8>* %56, align 16
  %57 = call i32 @aom_variance8x4_sse2(i8* nonnull %15, i32 8, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %13) #4
  ret i32 %57
}

declare i32 @aom_variance8x4_sse2(i8*, i32, i8*, i32, i32*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance4x8_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [36 x i16], align 16
  %11 = alloca [32 x i8], align 16
  %12 = alloca [32 x i8], align 16
  %13 = bitcast [36 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 72, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 72, i1 false)
  %14 = getelementptr inbounds [32 x i8], [32 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %14) #4
  %15 = getelementptr inbounds [32 x i8], [32 x i8]* %12, i64 0, i64 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 32, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %15) #4
  %16 = getelementptr inbounds [36 x i16], [36 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  %19 = getelementptr inbounds [32 x i8], [32 x i8]* %12, i64 0, i64 16
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %19, i8 -86, i64 16, i1 false)
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 9, i32 4, i8* %18) #4
  %20 = sext i32 %3 to i64
  %21 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %20, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 4, i32 4, i32 8, i32 4, i8* %21) #4
  %22 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %23 = bitcast i32* %22 to <2 x i32>*
  %24 = load <2 x i32>, <2 x i32>* %23, align 4
  %25 = trunc <2 x i32> %24 to <2 x i8>
  %26 = shufflevector <2 x i8> %25, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %27 = bitcast [32 x i8]* %11 to <16 x i8>*
  %28 = load <16 x i8>, <16 x i8>* %27, align 16
  %29 = bitcast i8* %7 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = shufflevector <16 x i8> %28, <16 x i8> %30, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %32 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %31, <16 x i8> %26) #4
  %33 = add <8 x i16> %32, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %34 = ashr <8 x i16> %33, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %35 = shufflevector <16 x i8> %28, <16 x i8> %30, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %36 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> %26) #4
  %37 = add <8 x i16> %36, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %38 = ashr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> %38) #4
  %40 = bitcast [32 x i8]* %12 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds [32 x i8], [32 x i8]* %12, i64 0, i64 16
  %42 = getelementptr inbounds i8, i8* %7, i64 16
  %43 = getelementptr inbounds [32 x i8], [32 x i8]* %11, i64 0, i64 16
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 16
  %46 = bitcast i8* %42 to <16 x i8>*
  %47 = load <16 x i8>, <16 x i8>* %46, align 1
  %48 = shufflevector <16 x i8> %45, <16 x i8> %47, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %49 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> %26) #4
  %50 = add <8 x i16> %49, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %51 = ashr <8 x i16> %50, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %52 = shufflevector <16 x i8> %45, <16 x i8> %47, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %53 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> %26) #4
  %54 = add <8 x i16> %53, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %55 = ashr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %51, <8 x i16> %55) #4
  %57 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 16
  %58 = call i32 @aom_variance4x8_sse2(i8* nonnull %15, i32 4, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %13) #4
  ret i32 %58
}

declare i32 @aom_variance4x8_sse2(i8*, i32, i8*, i32, i32*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i32 @aom_dist_wtd_sub_pixel_avg_variance4x4_ssse3(i8*, i32, i32, i32, i8*, i32, i32*, i8* nocapture readonly, %struct.dist_wtd_comp_params* nocapture readonly) local_unnamed_addr #0 {
  %10 = alloca [20 x i16], align 16
  %11 = alloca <16 x i8>, align 16
  %12 = alloca <16 x i8>, align 16
  %13 = bitcast [20 x i16]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 40, i1 false)
  %14 = getelementptr inbounds <16 x i8>, <16 x i8>* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %14) #4
  %15 = getelementptr inbounds <16 x i8>, <16 x i8>* %12, i64 0, i64 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %15) #4
  %16 = getelementptr inbounds [20 x i16], [20 x i16]* %10, i64 0, i64 0
  %17 = sext i32 %2 to i64
  %18 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %17, i64 0
  call void @aom_var_filter_block2d_bil_first_pass_ssse3(i8* %0, i16* nonnull %16, i32 %1, i32 1, i32 5, i32 4, i8* %18) #4
  %19 = sext i32 %3 to i64
  %20 = getelementptr inbounds [8 x [2 x i8]], [8 x [2 x i8]]* @bilinear_filters_2t, i64 0, i64 %19, i64 0
  call void @aom_var_filter_block2d_bil_second_pass_ssse3(i16* nonnull %16, i8* nonnull %14, i32 4, i32 4, i32 4, i32 4, i8* %20) #4
  %21 = getelementptr inbounds %struct.dist_wtd_comp_params, %struct.dist_wtd_comp_params* %8, i64 0, i32 1
  %22 = bitcast i32* %21 to <2 x i32>*
  %23 = load <2 x i32>, <2 x i32>* %22, align 4
  %24 = trunc <2 x i32> %23 to <2 x i8>
  %25 = shufflevector <2 x i8> %24, <2 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %26 = load <16 x i8>, <16 x i8>* %11, align 16
  %27 = bitcast i8* %7 to <16 x i8>*
  %28 = load <16 x i8>, <16 x i8>* %27, align 1
  %29 = shufflevector <16 x i8> %26, <16 x i8> %28, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %30 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %29, <16 x i8> %25) #4
  %31 = add <8 x i16> %30, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %32 = ashr <8 x i16> %31, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %33 = shufflevector <16 x i8> %26, <16 x i8> %28, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %34 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %33, <16 x i8> %25) #4
  %35 = add <8 x i16> %34, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %36 = ashr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %32, <8 x i16> %36) #4
  store <16 x i8> %37, <16 x i8>* %12, align 16
  %38 = call i32 @aom_variance4x4_sse2(i8* nonnull %15, i32 4, i8* %4, i32 %5, i32* %6) #4
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %15) #4
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %14) #4
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %13) #4
  ret i32 %38
}

declare i32 @aom_variance4x4_sse2(i8*, i32, i8*, i32, i32*) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #3

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #3

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
