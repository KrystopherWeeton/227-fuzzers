; ModuleID = '../../third_party/libgav1/src/src/dsp/x86/cdef_sse4.cc'
source_filename = "../../third_party/libgav1/src/src/dsp/x86/cdef_sse4.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.libgav1::dsp::Dsp" = type { void (i8*, i8*, i32, i32, i8*, i64)*, void (i8*, i64, i8*, i32*)*, [2 x [3 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*]], [19 x void (i8*, i64, [32 x i16]*, i32)*], [19 x [3 x void ([32 x i16]*, i32, i32, i8*, i64)*]], [2 x [2 x [2 x [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i8*, i64)*]]]], [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i64)*], void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)*, void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i8*, i8, i8, i32, i32, i8*, i64)*, %"struct.libgav1::dsp::FilmGrainFuncs", void (i8*, i64, i8*, i8*, i8, i32, i32)*, [3 x void (i8*, i8*, i64, i8*, i64, i32, i32)*], void (i8*, i32, i32)*, void (i8*, i32)*, [19 x [10 x void (i8*, i64, i8*, i8*)*]], [4 x [5 x [2 x void (i8, i8, i32, i8*, i32, i32, i8*)*]]], [4 x [2 x void (i8*, i64, i32, i32, i32)*]], [2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*], [3 x [2 x void (i8*, i8*, i64, i8*, i64, i32, i32, i8*, i64)*]], void (%"struct.libgav1::ReferenceInfo"*, i32, i32, i32, i32, i32, i32, %"struct.libgav1::TemporalMotionField"*)*, [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32*, i32, %"union.libgav1::CompoundMotionVector"*)*], [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32, i32, %"struct.libgav1::MotionVector"*)*], [2 x void (i8*, i64, i32, i32, i8*, i64)*], void (i32, i32, i32, i8*)*, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, [6 x [6 x [2 x void (i8*, i8*, i8*, i64)*]]] }
%"struct.libgav1::dsp::FilmGrainFuncs" = type { [3 x void (%"struct.libgav1::FilmGrainParams"*, i8*)*], [2 x [4 x void (%"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i8*, i8*)*]], [2 x void (i8*, i32, i32, i32, i32, i32, i8*)*], void (i8*, i32, i32, i32, i32, i8*)*, void (i32, i8*, i8*, i8*)*, void (i8*, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64)*, [2 x void (i8, %"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64, i8*, i64)*] }
%"struct.libgav1::FilmGrainParams" = type { i8, i8, i8, i8, i8, i8, i8, i8, [14 x i8], [14 x i8], [10 x i8], [10 x i8], [10 x i8], [10 x i8], i8, i8, [24 x i8], [25 x i8], [25 x i8], i8, i16, i32, i32, i8, i8, i16, i8, i8, i16 }
%"struct.libgav1::RestorationUnitInfo" = type { i8, %"struct.libgav1::SgrProjInfo", [16 x i8], %"struct.libgav1::WienerInfo" }
%"struct.libgav1::SgrProjInfo" = type { i32, [2 x i32] }
%"struct.libgav1::WienerInfo" = type { [2 x i16], [28 x i8], [2 x [4 x i16]], [16 x i8] }
%"union.libgav1::RestorationBuffer" = type { %"struct.libgav1::SgrBuffer", [5024 x i8] }
%"struct.libgav1::SgrBuffer" = type { [1152 x i16], [1440 x i16], [1152 x i32], [1440 x i32], [1024 x i16], [768 x i16], [512 x i16], [1024 x i32], [768 x i32], [512 x i32], [288 x i8], [288 x i32] }
%"struct.libgav1::ReferenceInfo" = type { %"struct.std::__1::array", %"struct.std::__1::array.0", %"struct.std::__1::array.0", %"struct.std::__1::array.1", %"struct.std::__1::array.2", %"class.libgav1::Array2D", %"class.libgav1::Array2D.4" }
%"struct.std::__1::array" = type { [8 x i8] }
%"struct.std::__1::array.0" = type { [8 x i8] }
%"struct.std::__1::array.1" = type { [8 x i8] }
%"struct.std::__1::array.2" = type { [8 x i16] }
%"class.libgav1::Array2D" = type { %"class.std::__1::unique_ptr", i64, i64, %"class.libgav1::Array2DView" }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i8* }
%"class.libgav1::Array2DView" = type { i32, i32, i8* }
%"class.libgav1::Array2D.4" = type { %"class.std::__1::unique_ptr.5", i64, i64, %"class.libgav1::Array2DView.11" }
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.libgav1::MotionVector"* }
%"struct.libgav1::MotionVector" = type { %union.anon }
%union.anon = type { i32 }
%"class.libgav1::Array2DView.11" = type { i32, i32, %"struct.libgav1::MotionVector"* }
%"struct.libgav1::TemporalMotionField" = type { %"class.libgav1::Array2D.4", %"class.libgav1::Array2D.12" }
%"class.libgav1::Array2D.12" = type { %"class.std::__1::unique_ptr.13", i64, i64, %"class.libgav1::Array2DView.19" }
%"class.std::__1::unique_ptr.13" = type { %"class.std::__1::__compressed_pair.14" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.15" }
%"struct.std::__1::__compressed_pair_elem.15" = type { i8* }
%"class.libgav1::Array2DView.19" = type { i32, i32, i8* }
%"union.libgav1::CompoundMotionVector" = type { i64 }

@_ZN7libgav116kCdefPrimaryTapsE = external local_unnamed_addr constant [2 x [2 x i8]], align 1
@_ZN7libgav121kCdefDirectionsPaddedE = external local_unnamed_addr constant [12 x [2 x [2 x i8]]], align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN7libgav13dsp15CdefInit_SSE4_1Ev() local_unnamed_addr #0 {
  %1 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 8) #6
  %2 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 1
  store void (i8*, i64, i8*, i32*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120CdefDirection_SSE4_1EPKvlPhPi, void (i8*, i64, i8*, i32*)** %2, align 8
  %3 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 2, i64 0, i64 0
  %4 = bitcast void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)** %3 to <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*>*
  store <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*> <void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi4ELb1ELb1EEEvPKtliiiiiPvl, void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi4ELb1ELb0EEEvPKtliiiiiPvl>, <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*>* %4, align 8
  %5 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 2, i64 0, i64 2
  %6 = bitcast void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)** %5 to <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*>*
  store <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*> <void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi4ELb0ELb1EEEvPKtliiiiiPvl, void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi8ELb1ELb1EEEvPKtliiiiiPvl>, <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*>* %6, align 8
  %7 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 2, i64 1, i64 1
  %8 = bitcast void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)** %7 to <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*>*
  store <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*> <void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi8ELb1ELb0EEEvPKtliiiiiPvl, void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi8ELb0ELb1EEEvPKtliiiiiPvl>, <2 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*>* %8, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

declare %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120CdefDirection_SSE4_1EPKvlPhPi(i8* nocapture readonly, i64, i8* nocapture, i32* nocapture) #3 {
  %5 = alloca [8 x i32], align 16
  %6 = bitcast [8 x i32]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %6) #6
  %7 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 0
  %8 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 1
  %9 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 2
  %10 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 3
  %11 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 4
  %12 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 5
  %13 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 6
  %14 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 7
  %15 = bitcast i8* %0 to i64*
  %16 = bitcast [8 x i32]* %5 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 -86, i64 32, i1 false)
  %17 = load i64, i64* %15, align 1
  %18 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %17, i32 0
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast i8* %19 to i64*
  %21 = load i64, i64* %20, align 1
  %22 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %21, i32 0
  %23 = getelementptr inbounds i8, i8* %19, i64 %1
  %24 = bitcast i8* %23 to i64*
  %25 = load i64, i64* %24, align 1
  %26 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %25, i32 0
  %27 = getelementptr inbounds i8, i8* %23, i64 %1
  %28 = bitcast i8* %27 to i64*
  %29 = load i64, i64* %28, align 1
  %30 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %29, i32 0
  %31 = getelementptr inbounds i8, i8* %27, i64 %1
  %32 = bitcast i8* %31 to i64*
  %33 = load i64, i64* %32, align 1
  %34 = insertelement <2 x i64> undef, i64 %33, i32 0
  %35 = getelementptr inbounds i8, i8* %31, i64 %1
  %36 = bitcast i8* %35 to i64*
  %37 = load i64, i64* %36, align 1
  %38 = insertelement <2 x i64> undef, i64 %37, i32 0
  %39 = getelementptr inbounds i8, i8* %35, i64 %1
  %40 = bitcast i8* %39 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> undef, i64 %41, i32 0
  %43 = getelementptr inbounds i8, i8* %39, i64 %1
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> undef, i64 %45, i32 0
  %47 = insertelement <2 x i64> %18, i64 %33, i32 1
  %48 = insertelement <2 x i64> %22, i64 %37, i32 1
  %49 = insertelement <2 x i64> %26, i64 %41, i32 1
  %50 = insertelement <2 x i64> %30, i64 %45, i32 1
  %51 = bitcast <2 x i64> %47 to <16 x i8>
  %52 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %51, <16 x i8> zeroinitializer) #6
  %53 = bitcast <2 x i64> %48 to <16 x i8>
  %54 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %53, <16 x i8> zeroinitializer) #6
  %55 = bitcast <2 x i64> %49 to <16 x i8>
  %56 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %55, <16 x i8> zeroinitializer) #6
  %57 = bitcast <2 x i64> %50 to <16 x i8>
  %58 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %57, <16 x i8> zeroinitializer) #6
  %59 = bitcast <2 x i64> %52 to <8 x i16>
  %60 = bitcast <2 x i64> %54 to <8 x i16>
  %61 = shufflevector <8 x i16> %59, <8 x i16> %60, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %62 = bitcast <2 x i64> %56 to <8 x i16>
  %63 = bitcast <2 x i64> %58 to <8 x i16>
  %64 = shufflevector <8 x i16> %62, <8 x i16> %63, <8 x i32> <i32 0, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %65 = shufflevector <8 x i16> %59, <8 x i16> %60, <8 x i32> <i32 4, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %66 = shufflevector <8 x i16> %62, <8 x i16> %63, <8 x i32> <i32 4, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %67 = bitcast <8 x i16> %61 to <4 x i32>
  %68 = bitcast <8 x i16> %64 to <4 x i32>
  %69 = shufflevector <4 x i32> %67, <4 x i32> %68, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %70 = bitcast <4 x i32> %69 to <2 x i64>
  %71 = bitcast <8 x i16> %65 to <4 x i32>
  %72 = bitcast <8 x i16> %66 to <4 x i32>
  %73 = shufflevector <4 x i32> %71, <4 x i32> %72, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %74 = bitcast <4 x i32> %73 to <2 x i64>
  %75 = shufflevector <2 x i64> %70, <2 x i64> %74, <2 x i32> <i32 0, i32 2>
  %76 = bitcast <2 x i64> %18 to <16 x i8>
  %77 = shufflevector <16 x i8> %76, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %78 = zext <8 x i8> %77 to <8 x i16>
  %79 = bitcast <2 x i64> %22 to <16 x i8>
  %80 = shufflevector <16 x i8> %79, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %81 = zext <8 x i8> %80 to <8 x i16>
  %82 = bitcast <2 x i64> %26 to <16 x i8>
  %83 = shufflevector <16 x i8> %82, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %84 = zext <8 x i8> %83 to <8 x i16>
  %85 = bitcast <2 x i64> %30 to <16 x i8>
  %86 = shufflevector <16 x i8> %85, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %87 = zext <8 x i8> %86 to <8 x i16>
  %88 = bitcast <2 x i64> %34 to <16 x i8>
  %89 = shufflevector <16 x i8> %88, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %90 = zext <8 x i8> %89 to <8 x i16>
  %91 = bitcast <2 x i64> %38 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %93 = zext <8 x i8> %92 to <8 x i16>
  %94 = bitcast <2 x i64> %42 to <16 x i8>
  %95 = shufflevector <16 x i8> %94, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %96 = zext <8 x i8> %95 to <8 x i16>
  %97 = bitcast <2 x i64> %46 to <16 x i8>
  %98 = shufflevector <16 x i8> %97, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %99 = zext <8 x i8> %98 to <8 x i16>
  %100 = add nuw nsw <8 x i16> %81, %78
  %101 = add nuw nsw <8 x i16> %87, %84
  %102 = add nuw nsw <8 x i16> %101, %100
  %103 = add nuw nsw <8 x i16> %102, %90
  %104 = add nuw nsw <8 x i16> %103, %93
  %105 = add nuw nsw <8 x i16> %104, %96
  %106 = add nuw nsw <8 x i16> %105, %99
  %107 = bitcast <8 x i16> %81 to <16 x i8>
  %108 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %107, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %109 = bitcast <16 x i8> %108 to <8 x i16>
  %110 = add <8 x i16> %109, %78
  %111 = shufflevector <16 x i8> %107, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 undef, i32 undef>
  %112 = bitcast <16 x i8> %111 to <8 x i16>
  %113 = bitcast <8 x i16> %84 to <16 x i8>
  %114 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %113, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %115 = bitcast <16 x i8> %114 to <8 x i16>
  %116 = add <8 x i16> %110, %115
  %117 = shufflevector <16 x i8> %113, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 undef, i32 undef>
  %118 = bitcast <16 x i8> %117 to <8 x i16>
  %119 = add <8 x i16> %118, %112
  %120 = bitcast <8 x i16> %87 to <16 x i8>
  %121 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %120, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %122 = bitcast <16 x i8> %121 to <8 x i16>
  %123 = add <8 x i16> %116, %122
  %124 = shufflevector <16 x i8> %120, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef>
  %125 = bitcast <16 x i8> %124 to <8 x i16>
  %126 = add <8 x i16> %119, %125
  %127 = bitcast <8 x i16> %90 to <16 x i8>
  %128 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %127, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %129 = bitcast <16 x i8> %128 to <8 x i16>
  %130 = add <8 x i16> %123, %129
  %131 = shufflevector <16 x i8> %127, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 undef, i32 undef>
  %132 = bitcast <16 x i8> %131 to <8 x i16>
  %133 = add <8 x i16> %126, %132
  %134 = bitcast <8 x i16> %93 to <16 x i8>
  %135 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %134, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %136 = bitcast <16 x i8> %135 to <8 x i16>
  %137 = add <8 x i16> %130, %136
  %138 = shufflevector <16 x i8> %134, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef>
  %139 = bitcast <16 x i8> %138 to <8 x i16>
  %140 = add <8 x i16> %133, %139
  %141 = bitcast <8 x i16> %96 to <16 x i8>
  %142 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %141, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %143 = bitcast <16 x i8> %142 to <8 x i16>
  %144 = add <8 x i16> %137, %143
  %145 = shufflevector <16 x i8> %141, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 undef, i32 undef>
  %146 = bitcast <16 x i8> %145 to <8 x i16>
  %147 = add <8 x i16> %140, %146
  %148 = bitcast <8 x i16> %99 to <16 x i8>
  %149 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %148, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %150 = bitcast <16 x i8> %149 to <8 x i16>
  %151 = add <8 x i16> %144, %150
  %152 = shufflevector <16 x i8> %148, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef>
  %153 = bitcast <16 x i8> %152 to <8 x i16>
  %154 = add <8 x i16> %147, %153
  %155 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %78, <8 x i16> zeroinitializer) #6
  %156 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %81, <8 x i16> zeroinitializer) #6
  %157 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %84, <8 x i16> zeroinitializer) #6
  %158 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %87, <8 x i16> zeroinitializer) #6
  %159 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %90, <8 x i16> zeroinitializer) #6
  %160 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %93, <8 x i16> zeroinitializer) #6
  %161 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %96, <8 x i16> zeroinitializer) #6
  %162 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %99, <8 x i16> zeroinitializer) #6
  %163 = bitcast <8 x i16> %156 to <16 x i8>
  %164 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %163, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %165 = bitcast <16 x i8> %164 to <8 x i16>
  %166 = add <8 x i16> %155, %165
  %167 = bitcast <8 x i16> %157 to <16 x i8>
  %168 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %167, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %169 = bitcast <16 x i8> %168 to <8 x i16>
  %170 = add <8 x i16> %166, %169
  %171 = bitcast <8 x i16> %158 to <16 x i8>
  %172 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %171, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %173 = bitcast <16 x i8> %172 to <8 x i16>
  %174 = add <8 x i16> %170, %173
  %175 = bitcast <8 x i16> %159 to <16 x i8>
  %176 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %175, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %177 = bitcast <16 x i8> %176 to <8 x i16>
  %178 = add <8 x i16> %174, %177
  %179 = bitcast <8 x i16> %160 to <16 x i8>
  %180 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %179, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %181 = bitcast <16 x i8> %180 to <8 x i16>
  %182 = add <8 x i16> %178, %181
  %183 = shufflevector <16 x i8> %179, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %184 = bitcast <16 x i8> %183 to <8 x i16>
  %185 = bitcast <8 x i16> %161 to <16 x i8>
  %186 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %185, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %187 = bitcast <16 x i8> %186 to <8 x i16>
  %188 = add <8 x i16> %182, %187
  %189 = shufflevector <16 x i8> %185, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %190 = bitcast <16 x i8> %189 to <8 x i16>
  %191 = add <8 x i16> %190, %184
  %192 = bitcast <8 x i16> %162 to <16 x i8>
  %193 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %192, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %194 = bitcast <16 x i8> %193 to <8 x i16>
  %195 = add <8 x i16> %188, %194
  %196 = shufflevector <16 x i8> %192, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %197 = bitcast <16 x i8> %196 to <8 x i16>
  %198 = add <8 x i16> %191, %197
  %199 = add nuw nsw <8 x i16> %93, %90
  %200 = add nuw nsw <8 x i16> %99, %96
  %201 = bitcast <8 x i16> %101 to <16 x i8>
  %202 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %201, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %203 = bitcast <16 x i8> %202 to <8 x i16>
  %204 = add <8 x i16> %100, %203
  %205 = shufflevector <16 x i8> %201, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %206 = bitcast <16 x i8> %205 to <8 x i16>
  %207 = bitcast <8 x i16> %199 to <16 x i8>
  %208 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %207, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %209 = bitcast <16 x i8> %208 to <8 x i16>
  %210 = add <8 x i16> %204, %209
  %211 = shufflevector <16 x i8> %207, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %212 = bitcast <16 x i8> %211 to <8 x i16>
  %213 = add <8 x i16> %212, %206
  %214 = bitcast <8 x i16> %200 to <16 x i8>
  %215 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %214, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %216 = bitcast <16 x i8> %215 to <8 x i16>
  %217 = add <8 x i16> %210, %216
  %218 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %219 = bitcast <16 x i8> %218 to <8 x i16>
  %220 = add <8 x i16> %213, %219
  %221 = bitcast <8 x i16> %78 to <16 x i8>
  %222 = shufflevector <16 x i8> %221, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %223 = bitcast <16 x i8> %222 to <8 x i16>
  %224 = shufflevector <16 x i8> %107, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %225 = bitcast <16 x i8> %224 to <8 x i16>
  %226 = shufflevector <16 x i8> %113, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %227 = bitcast <16 x i8> %226 to <8 x i16>
  %228 = shufflevector <16 x i8> %120, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %229 = bitcast <16 x i8> %228 to <8 x i16>
  %230 = shufflevector <16 x i8> %127, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %231 = bitcast <16 x i8> %230 to <8 x i16>
  %232 = shufflevector <16 x i8> %134, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %233 = bitcast <16 x i8> %232 to <8 x i16>
  %234 = shufflevector <16 x i8> %141, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %235 = bitcast <16 x i8> %234 to <8 x i16>
  %236 = shufflevector <16 x i8> %148, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %237 = bitcast <16 x i8> %236 to <8 x i16>
  %238 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %224, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %239 = bitcast <16 x i8> %238 to <8 x i16>
  %240 = add <8 x i16> %239, %223
  %241 = shufflevector <16 x i8> %224, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 undef, i32 undef>
  %242 = bitcast <16 x i8> %241 to <8 x i16>
  %243 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %226, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %244 = bitcast <16 x i8> %243 to <8 x i16>
  %245 = add <8 x i16> %240, %244
  %246 = shufflevector <16 x i8> %226, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 undef, i32 undef>
  %247 = bitcast <16 x i8> %246 to <8 x i16>
  %248 = add <8 x i16> %247, %242
  %249 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %228, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %250 = bitcast <16 x i8> %249 to <8 x i16>
  %251 = add <8 x i16> %245, %250
  %252 = shufflevector <16 x i8> %228, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 undef, i32 undef>
  %253 = bitcast <16 x i8> %252 to <8 x i16>
  %254 = add <8 x i16> %248, %253
  %255 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %230, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %256 = bitcast <16 x i8> %255 to <8 x i16>
  %257 = add <8 x i16> %251, %256
  %258 = shufflevector <16 x i8> %230, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 undef, i32 undef>
  %259 = bitcast <16 x i8> %258 to <8 x i16>
  %260 = add <8 x i16> %254, %259
  %261 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %232, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %262 = bitcast <16 x i8> %261 to <8 x i16>
  %263 = add <8 x i16> %257, %262
  %264 = shufflevector <16 x i8> %232, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef>
  %265 = bitcast <16 x i8> %264 to <8 x i16>
  %266 = add <8 x i16> %260, %265
  %267 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %234, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %268 = bitcast <16 x i8> %267 to <8 x i16>
  %269 = add <8 x i16> %263, %268
  %270 = shufflevector <16 x i8> %234, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 undef, i32 undef>
  %271 = bitcast <16 x i8> %270 to <8 x i16>
  %272 = add <8 x i16> %266, %271
  %273 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %236, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %274 = bitcast <16 x i8> %273 to <8 x i16>
  %275 = add <8 x i16> %269, %274
  %276 = shufflevector <16 x i8> %236, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef>
  %277 = bitcast <16 x i8> %276 to <8 x i16>
  %278 = add <8 x i16> %272, %277
  %279 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %223, <8 x i16> zeroinitializer) #6
  %280 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %225, <8 x i16> zeroinitializer) #6
  %281 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %227, <8 x i16> zeroinitializer) #6
  %282 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %229, <8 x i16> zeroinitializer) #6
  %283 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %231, <8 x i16> zeroinitializer) #6
  %284 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %233, <8 x i16> zeroinitializer) #6
  %285 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %235, <8 x i16> zeroinitializer) #6
  %286 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %237, <8 x i16> zeroinitializer) #6
  %287 = bitcast <8 x i16> %280 to <16 x i8>
  %288 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %287, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %289 = bitcast <16 x i8> %288 to <8 x i16>
  %290 = add <8 x i16> %279, %289
  %291 = bitcast <8 x i16> %281 to <16 x i8>
  %292 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %291, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %293 = bitcast <16 x i8> %292 to <8 x i16>
  %294 = add <8 x i16> %290, %293
  %295 = bitcast <8 x i16> %282 to <16 x i8>
  %296 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %295, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %297 = bitcast <16 x i8> %296 to <8 x i16>
  %298 = add <8 x i16> %294, %297
  %299 = bitcast <8 x i16> %283 to <16 x i8>
  %300 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %299, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %301 = bitcast <16 x i8> %300 to <8 x i16>
  %302 = add <8 x i16> %298, %301
  %303 = bitcast <8 x i16> %284 to <16 x i8>
  %304 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %303, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21>
  %305 = bitcast <16 x i8> %304 to <8 x i16>
  %306 = add <8 x i16> %302, %305
  %307 = shufflevector <16 x i8> %303, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %308 = bitcast <16 x i8> %307 to <8 x i16>
  %309 = bitcast <8 x i16> %285 to <16 x i8>
  %310 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %309, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %311 = bitcast <16 x i8> %310 to <8 x i16>
  %312 = add <8 x i16> %306, %311
  %313 = shufflevector <16 x i8> %309, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %314 = bitcast <16 x i8> %313 to <8 x i16>
  %315 = add <8 x i16> %314, %308
  %316 = bitcast <8 x i16> %286 to <16 x i8>
  %317 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %316, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %318 = bitcast <16 x i8> %317 to <8 x i16>
  %319 = add <8 x i16> %312, %318
  %320 = shufflevector <16 x i8> %316, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %321 = bitcast <16 x i8> %320 to <8 x i16>
  %322 = add <8 x i16> %315, %321
  %323 = add <8 x i16> %225, %223
  %324 = add <8 x i16> %229, %227
  %325 = add <8 x i16> %233, %231
  %326 = add <8 x i16> %237, %235
  %327 = bitcast <8 x i16> %324 to <16 x i8>
  %328 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0>, <16 x i8> %327, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29>
  %329 = bitcast <16 x i8> %328 to <8 x i16>
  %330 = add <8 x i16> %323, %329
  %331 = shufflevector <16 x i8> %327, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %332 = bitcast <16 x i8> %331 to <8 x i16>
  %333 = bitcast <8 x i16> %325 to <16 x i8>
  %334 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %333, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27>
  %335 = bitcast <16 x i8> %334 to <8 x i16>
  %336 = add <8 x i16> %330, %335
  %337 = shufflevector <16 x i8> %333, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %338 = bitcast <16 x i8> %337 to <8 x i16>
  %339 = add <8 x i16> %338, %332
  %340 = bitcast <8 x i16> %326 to <16 x i8>
  %341 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %340, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %342 = bitcast <16 x i8> %341 to <8 x i16>
  %343 = add <8 x i16> %336, %342
  %344 = shufflevector <16 x i8> %340, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %345 = bitcast <16 x i8> %344 to <8 x i16>
  %346 = add <8 x i16> %339, %345
  %347 = bitcast <2 x i64> %75 to <8 x i16>
  %348 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %347, <8 x i16> %347) #6
  %349 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %348, <4 x i32> %348) #6
  %350 = bitcast <4 x i32> %349 to <16 x i8>
  %351 = shufflevector <16 x i8> %350, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %352 = bitcast <16 x i8> %351 to <4 x i32>
  %353 = add <4 x i32> %349, %352
  %354 = extractelement <4 x i32> %353, i32 0
  %355 = mul i32 %354, 105
  store i32 %355, i32* %9, align 8
  %356 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %106, <8 x i16> %106) #6
  %357 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %356, <4 x i32> %356) #6
  %358 = bitcast <4 x i32> %357 to <16 x i8>
  %359 = shufflevector <16 x i8> %358, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %360 = bitcast <16 x i8> %359 to <4 x i32>
  %361 = add <4 x i32> %357, %360
  %362 = extractelement <4 x i32> %361, i32 0
  %363 = mul i32 %362, 105
  store i32 %363, i32* %13, align 8
  %364 = bitcast <8 x i16> %154 to <16 x i8>
  %365 = shufflevector <16 x i8> %364, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1, i32 16, i32 16>
  %366 = bitcast <16 x i8> %365 to <8 x i16>
  %367 = shufflevector <8 x i16> %151, <8 x i16> %366, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %368 = shufflevector <8 x i16> %151, <8 x i16> %366, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %369 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %367, <8 x i16> %367) #6
  %370 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %368, <8 x i16> %368) #6
  %371 = mul <4 x i32> %369, <i32 840, i32 420, i32 280, i32 210>
  %372 = mul <4 x i32> %370, <i32 168, i32 140, i32 120, i32 105>
  %373 = add <4 x i32> %372, %371
  %374 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %373, <4 x i32> %373) #6
  %375 = bitcast <4 x i32> %374 to <16 x i8>
  %376 = shufflevector <16 x i8> %375, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %377 = bitcast <16 x i8> %376 to <4 x i32>
  %378 = add <4 x i32> %374, %377
  %379 = extractelement <4 x i32> %378, i32 0
  store i32 %379, i32* %7, align 16
  %380 = bitcast <8 x i16> %278 to <16 x i8>
  %381 = shufflevector <16 x i8> %380, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1, i32 16, i32 16>
  %382 = bitcast <16 x i8> %381 to <8 x i16>
  %383 = shufflevector <8 x i16> %275, <8 x i16> %382, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %384 = shufflevector <8 x i16> %275, <8 x i16> %382, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %385 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %383, <8 x i16> %383) #6
  %386 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %384, <8 x i16> %384) #6
  %387 = mul <4 x i32> %385, <i32 840, i32 420, i32 280, i32 210>
  %388 = mul <4 x i32> %386, <i32 168, i32 140, i32 120, i32 105>
  %389 = add <4 x i32> %388, %387
  %390 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %389, <4 x i32> %389) #6
  %391 = bitcast <4 x i32> %390 to <16 x i8>
  %392 = shufflevector <16 x i8> %391, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %393 = bitcast <16 x i8> %392 to <4 x i32>
  %394 = add <4 x i32> %390, %393
  %395 = extractelement <4 x i32> %394, i32 0
  store i32 %395, i32* %11, align 16
  %396 = bitcast <8 x i16> %198 to <16 x i8>
  %397 = shufflevector <16 x i8> %396, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 2, i32 3, i32 0, i32 1, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %398 = bitcast <16 x i8> %397 to <8 x i16>
  %399 = shufflevector <8 x i16> %195, <8 x i16> %398, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %400 = shufflevector <8 x i16> %195, <8 x i16> %398, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %401 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %399, <8 x i16> %399) #6
  %402 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %400, <8 x i16> %400) #6
  %403 = mul <4 x i32> %401, <i32 420, i32 210, i32 140, i32 105>
  %404 = mul <4 x i32> %402, <i32 105, i32 105, i32 105, i32 105>
  %405 = add <4 x i32> %404, %403
  %406 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %405, <4 x i32> %405) #6
  %407 = bitcast <4 x i32> %406 to <16 x i8>
  %408 = shufflevector <16 x i8> %407, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %409 = bitcast <16 x i8> %408 to <4 x i32>
  %410 = add <4 x i32> %406, %409
  %411 = extractelement <4 x i32> %410, i32 0
  store i32 %411, i32* %8, align 4
  %412 = bitcast <8 x i16> %322 to <16 x i8>
  %413 = shufflevector <16 x i8> %412, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 2, i32 3, i32 0, i32 1, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %414 = bitcast <16 x i8> %413 to <8 x i16>
  %415 = shufflevector <8 x i16> %319, <8 x i16> %414, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %416 = shufflevector <8 x i16> %319, <8 x i16> %414, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %417 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %415, <8 x i16> %415) #6
  %418 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %416, <8 x i16> %416) #6
  %419 = mul <4 x i32> %417, <i32 420, i32 210, i32 140, i32 105>
  %420 = mul <4 x i32> %418, <i32 105, i32 105, i32 105, i32 105>
  %421 = add <4 x i32> %420, %419
  %422 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %421, <4 x i32> %421) #6
  %423 = bitcast <4 x i32> %422 to <16 x i8>
  %424 = shufflevector <16 x i8> %423, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %425 = bitcast <16 x i8> %424 to <4 x i32>
  %426 = add <4 x i32> %422, %425
  %427 = extractelement <4 x i32> %426, i32 0
  store i32 %427, i32* %10, align 4
  %428 = bitcast <8 x i16> %346 to <16 x i8>
  %429 = shufflevector <16 x i8> %428, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 2, i32 3, i32 0, i32 1, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %430 = bitcast <16 x i8> %429 to <8 x i16>
  %431 = shufflevector <8 x i16> %343, <8 x i16> %430, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %432 = shufflevector <8 x i16> %343, <8 x i16> %430, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %431, <8 x i16> %431) #6
  %434 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %432, <8 x i16> %432) #6
  %435 = mul <4 x i32> %433, <i32 420, i32 210, i32 140, i32 105>
  %436 = mul <4 x i32> %434, <i32 105, i32 105, i32 105, i32 105>
  %437 = add <4 x i32> %436, %435
  %438 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %437, <4 x i32> %437) #6
  %439 = bitcast <4 x i32> %438 to <16 x i8>
  %440 = shufflevector <16 x i8> %439, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %441 = bitcast <16 x i8> %440 to <4 x i32>
  %442 = add <4 x i32> %438, %441
  %443 = extractelement <4 x i32> %442, i32 0
  store i32 %443, i32* %12, align 4
  %444 = bitcast <8 x i16> %220 to <16 x i8>
  %445 = shufflevector <16 x i8> %444, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 2, i32 3, i32 0, i32 1, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %446 = bitcast <16 x i8> %445 to <8 x i16>
  %447 = shufflevector <8 x i16> %217, <8 x i16> %446, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %448 = shufflevector <8 x i16> %217, <8 x i16> %446, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %449 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %447, <8 x i16> %447) #6
  %450 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %448, <8 x i16> %448) #6
  %451 = mul <4 x i32> %449, <i32 420, i32 210, i32 140, i32 105>
  %452 = mul <4 x i32> %450, <i32 105, i32 105, i32 105, i32 105>
  %453 = add <4 x i32> %452, %451
  %454 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %453, <4 x i32> %453) #6
  %455 = bitcast <4 x i32> %454 to <16 x i8>
  %456 = shufflevector <16 x i8> %455, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %457 = bitcast <16 x i8> %456 to <4 x i32>
  %458 = add <4 x i32> %454, %457
  %459 = extractelement <4 x i32> %458, i32 0
  store i32 %459, i32* %14, align 4
  %460 = icmp ugt i32 %411, %379
  %461 = zext i1 %460 to i8
  %462 = select i1 %460, i32 %411, i32 %379
  store i8 %461, i8* %2, align 1
  %463 = load i32, i32* %9, align 8
  %464 = icmp ugt i32 %463, %462
  %465 = select i1 %464, i8 2, i8 %461
  %466 = select i1 %464, i32 %463, i32 %462
  %467 = icmp ugt i32 %427, %466
  %468 = select i1 %467, i32 %427, i32 %466
  %469 = icmp ugt i32 %395, %468
  %470 = select i1 %469, i32 %395, i32 %468
  %471 = or i1 %467, %469
  %472 = icmp ugt i32 %443, %470
  %473 = select i1 %472, i32 %443, i32 %470
  %474 = or i1 %471, %472
  %475 = select i1 %469, i8 4, i8 3
  %476 = select i1 %472, i8 5, i8 %475
  %477 = select i1 %474, i8 %476, i8 %465
  store i8 %477, i8* %2, align 1
  %478 = load i32, i32* %13, align 8
  %479 = icmp ugt i32 %478, %473
  %480 = select i1 %479, i32 %478, i32 %473
  %481 = icmp ugt i32 %459, %480
  %482 = select i1 %481, i32 %459, i32 %480
  %483 = or i1 %479, %481
  br i1 %483, label %484, label %486

484:                                              ; preds = %4
  %485 = select i1 %481, i8 7, i8 6
  store i8 %485, i8* %2, align 1
  br label %486

486:                                              ; preds = %4, %484
  %487 = select i1 %460, i64 5, i64 4
  %488 = select i1 %464, i64 6, i64 %487
  %489 = select i1 %467, i64 7, i64 %488
  %490 = select i1 %469, i64 0, i64 %489
  %491 = select i1 %472, i64 1, i64 %490
  %492 = select i1 %479, i64 2, i64 %491
  %493 = select i1 %481, i64 3, i64 %492
  %494 = getelementptr inbounds [8 x i32], [8 x i32]* %5, i64 0, i64 %493
  %495 = load i32, i32* %494, align 4
  %496 = sub i32 %482, %495
  %497 = lshr i32 %496, 10
  store i32 %497, i32* %3, align 4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %6) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi4ELb1ELb1EEEvPKtliiiiiPvl(i16* nocapture readonly, i64, i32, i32, i32, i32, i32, i8* nocapture, i64) #3 {
  %10 = tail call i32 @llvm.ctlz.i32(i32 %3, i1 true) #6, !range !2
  %11 = xor i32 %10, 31
  %12 = sub nsw i32 %5, %11
  %13 = icmp sgt i32 %12, 0
  %14 = select i1 %13, i32 %12, i32 0
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %14, i32 0
  %16 = tail call i32 @llvm.ctlz.i32(i32 %4, i1 true) #6, !range !2
  %17 = xor i32 %16, 31
  %18 = sub nsw i32 %5, %17
  %19 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %18, i32 0
  %20 = and i32 %3, 1
  %21 = zext i32 %20 to i64
  %22 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* @_ZN7libgav116kCdefPrimaryTapsE, i64 0, i64 %21, i64 0
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i16
  %25 = insertelement <8 x i16> undef, i16 %24, i32 0
  %26 = shufflevector <8 x i16> %25, <8 x i16> undef, <8 x i32> zeroinitializer
  %27 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* @_ZN7libgav116kCdefPrimaryTapsE, i64 0, i64 %21, i64 1
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i16
  %30 = insertelement <8 x i16> undef, i16 %29, i32 0
  %31 = shufflevector <8 x i16> %30, <8 x i16> undef, <8 x i32> zeroinitializer
  %32 = trunc i32 %3 to i16
  %33 = insertelement <8 x i16> undef, i16 %32, i32 0
  %34 = shufflevector <8 x i16> %33, <8 x i16> undef, <8 x i32> zeroinitializer
  %35 = trunc i32 %4 to i16
  %36 = insertelement <8 x i16> undef, i16 %35, i32 0
  %37 = shufflevector <8 x i16> %36, <8 x i16> undef, <8 x i32> zeroinitializer
  %38 = sext i32 %6 to i64
  %39 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 0, i64 0
  %40 = load i8, i8* %39, align 4
  %41 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 0, i64 1
  %42 = load i8, i8* %41, align 1
  %43 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 1, i64 0
  %44 = load i8, i8* %43, align 2
  %45 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 1, i64 1
  %46 = load i8, i8* %45, align 1
  %47 = sext i8 %40 to i64
  %48 = mul nsw i64 %47, %1
  %49 = sub i64 0, %48
  %50 = sext i8 %42 to i64
  %51 = sub nsw i64 0, %50
  %52 = sext i8 %44 to i64
  %53 = mul nsw i64 %52, %1
  %54 = sub i64 0, %53
  %55 = sext i8 %46 to i64
  %56 = sub nsw i64 0, %55
  %57 = bitcast <4 x i32> %15 to <8 x i16>
  %58 = add nsw i32 %6, 2
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %59, i64 0, i64 0
  %61 = load i8, i8* %60, align 4
  %62 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %59, i64 0, i64 1
  %63 = load i8, i8* %62, align 1
  %64 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %59, i64 1, i64 0
  %65 = load i8, i8* %64, align 2
  %66 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %59, i64 1, i64 1
  %67 = load i8, i8* %66, align 1
  %68 = sext i8 %61 to i64
  %69 = mul nsw i64 %68, %1
  %70 = sub i64 0, %69
  %71 = sext i8 %63 to i64
  %72 = sub nsw i64 0, %71
  %73 = sext i8 %65 to i64
  %74 = mul nsw i64 %73, %1
  %75 = sub i64 0, %74
  %76 = sext i8 %67 to i64
  %77 = sub nsw i64 0, %76
  %78 = add nsw i32 %6, -2
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %79, i64 0, i64 0
  %81 = load i8, i8* %80, align 4
  %82 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %79, i64 0, i64 1
  %83 = load i8, i8* %82, align 1
  %84 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %79, i64 1, i64 0
  %85 = load i8, i8* %84, align 2
  %86 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %79, i64 1, i64 1
  %87 = load i8, i8* %86, align 1
  %88 = sext i8 %81 to i64
  %89 = mul nsw i64 %88, %1
  %90 = sub i64 0, %89
  %91 = sext i8 %83 to i64
  %92 = sub nsw i64 0, %91
  %93 = sext i8 %85 to i64
  %94 = mul nsw i64 %93, %1
  %95 = sub i64 0, %94
  %96 = sext i8 %87 to i64
  %97 = sub nsw i64 0, %96
  %98 = bitcast <4 x i32> %19 to <8 x i16>
  %99 = shl i64 %1, 1
  br label %100

100:                                              ; preds = %100, %9
  %101 = phi i32 [ %2, %9 ], [ %479, %100 ]
  %102 = phi i8* [ %7, %9 ], [ %478, %100 ]
  %103 = phi i16* [ %0, %9 ], [ %469, %100 ]
  %104 = bitcast i16* %103 to i64*
  %105 = load i64, i64* %104, align 1
  %106 = insertelement <2 x i64> undef, i64 %105, i32 0
  %107 = getelementptr inbounds i16, i16* %103, i64 %1
  %108 = bitcast <2 x i64> %106 to <4 x float>
  %109 = bitcast i16* %107 to <2 x float>*
  %110 = load <2 x float>, <2 x float>* %109, align 1
  %111 = shufflevector <2 x float> %110, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %112 = shufflevector <4 x float> %108, <4 x float> %111, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %113 = getelementptr inbounds i16, i16* %103, i64 %49
  %114 = getelementptr inbounds i16, i16* %113, i64 %51
  %115 = bitcast i16* %114 to i64*
  %116 = load i64, i64* %115, align 1
  %117 = insertelement <2 x i64> undef, i64 %116, i32 0
  %118 = getelementptr inbounds i16, i16* %113, i64 %1
  %119 = getelementptr inbounds i16, i16* %118, i64 %51
  %120 = bitcast <2 x i64> %117 to <4 x float>
  %121 = bitcast i16* %119 to <2 x float>*
  %122 = load <2 x float>, <2 x float>* %121, align 1
  %123 = shufflevector <2 x float> %122, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %124 = shufflevector <4 x float> %120, <4 x float> %123, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %125 = getelementptr inbounds i16, i16* %103, i64 %48
  %126 = getelementptr inbounds i16, i16* %125, i64 %50
  %127 = bitcast i16* %126 to i64*
  %128 = load i64, i64* %127, align 1
  %129 = insertelement <2 x i64> undef, i64 %128, i32 0
  %130 = getelementptr inbounds i16, i16* %125, i64 %1
  %131 = getelementptr inbounds i16, i16* %130, i64 %50
  %132 = bitcast <2 x i64> %129 to <4 x float>
  %133 = bitcast i16* %131 to <2 x float>*
  %134 = load <2 x float>, <2 x float>* %133, align 1
  %135 = shufflevector <2 x float> %134, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %136 = shufflevector <4 x float> %132, <4 x float> %135, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %137 = getelementptr inbounds i16, i16* %103, i64 %54
  %138 = getelementptr inbounds i16, i16* %137, i64 %56
  %139 = bitcast i16* %138 to i64*
  %140 = load i64, i64* %139, align 1
  %141 = insertelement <2 x i64> undef, i64 %140, i32 0
  %142 = getelementptr inbounds i16, i16* %137, i64 %1
  %143 = getelementptr inbounds i16, i16* %142, i64 %56
  %144 = bitcast <2 x i64> %141 to <4 x float>
  %145 = bitcast i16* %143 to <2 x float>*
  %146 = load <2 x float>, <2 x float>* %145, align 1
  %147 = shufflevector <2 x float> %146, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %148 = shufflevector <4 x float> %144, <4 x float> %147, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %149 = getelementptr inbounds i16, i16* %103, i64 %53
  %150 = getelementptr inbounds i16, i16* %149, i64 %55
  %151 = bitcast i16* %150 to i64*
  %152 = load i64, i64* %151, align 1
  %153 = insertelement <2 x i64> undef, i64 %152, i32 0
  %154 = getelementptr inbounds i16, i16* %149, i64 %1
  %155 = getelementptr inbounds i16, i16* %154, i64 %55
  %156 = bitcast <2 x i64> %153 to <4 x float>
  %157 = bitcast i16* %155 to <2 x float>*
  %158 = load <2 x float>, <2 x float>* %157, align 1
  %159 = shufflevector <2 x float> %158, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %160 = shufflevector <4 x float> %156, <4 x float> %159, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %161 = bitcast <4 x float> %112 to <8 x i16>
  %162 = bitcast <4 x float> %124 to <8 x i16>
  %163 = icmp ugt <8 x i16> %162, %161
  %164 = select <8 x i1> %163, <8 x i16> %161, <8 x i16> %162
  %165 = bitcast <4 x float> %136 to <8 x i16>
  %166 = icmp ult <8 x i16> %164, %165
  %167 = select <8 x i1> %166, <8 x i16> %164, <8 x i16> %165
  %168 = bitcast <4 x float> %148 to <8 x i16>
  %169 = icmp ult <8 x i16> %167, %168
  %170 = select <8 x i1> %169, <8 x i16> %167, <8 x i16> %168
  %171 = bitcast <4 x float> %160 to <8 x i16>
  %172 = icmp ult <8 x i16> %170, %171
  %173 = select <8 x i1> %172, <8 x i16> %170, <8 x i16> %171
  %174 = bitcast <4 x float> %124 to <16 x i8>
  %175 = bitcast <4 x float> %136 to <16 x i8>
  %176 = icmp ugt <16 x i8> %174, %175
  %177 = select <16 x i1> %176, <16 x i8> %174, <16 x i8> %175
  %178 = bitcast <4 x float> %148 to <16 x i8>
  %179 = bitcast <4 x float> %160 to <16 x i8>
  %180 = icmp ugt <16 x i8> %178, %179
  %181 = select <16 x i1> %180, <16 x i8> %178, <16 x i8> %179
  %182 = icmp ugt <16 x i8> %177, %181
  %183 = select <16 x i1> %182, <16 x i8> %177, <16 x i8> %181
  %184 = bitcast <16 x i8> %183 to <8 x i16>
  %185 = and <8 x i16> %184, <i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385>
  %186 = icmp ult <8 x i16> %185, %161
  %187 = select <8 x i1> %186, <8 x i16> %161, <8 x i16> %185
  %188 = sub <8 x i16> %162, %161
  %189 = sub <8 x i16> zeroinitializer, %188
  %190 = icmp slt <8 x i16> %188, zeroinitializer
  %191 = select <8 x i1> %190, <8 x i16> %189, <8 x i16> %188
  %192 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %191, <8 x i16> %57) #6
  %193 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %34, <8 x i16> %192) #6
  %194 = icmp slt <8 x i16> %193, %191
  %195 = select <8 x i1> %194, <8 x i16> %193, <8 x i16> %191
  %196 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %195, <8 x i16> %188) #6
  %197 = sub <8 x i16> %165, %161
  %198 = sub <8 x i16> zeroinitializer, %197
  %199 = icmp slt <8 x i16> %197, zeroinitializer
  %200 = select <8 x i1> %199, <8 x i16> %198, <8 x i16> %197
  %201 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %200, <8 x i16> %57) #6
  %202 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %34, <8 x i16> %201) #6
  %203 = icmp slt <8 x i16> %202, %200
  %204 = select <8 x i1> %203, <8 x i16> %202, <8 x i16> %200
  %205 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %204, <8 x i16> %197) #6
  %206 = add <8 x i16> %205, %196
  %207 = mul <8 x i16> %206, %26
  %208 = sub <8 x i16> %168, %161
  %209 = sub <8 x i16> zeroinitializer, %208
  %210 = icmp slt <8 x i16> %208, zeroinitializer
  %211 = select <8 x i1> %210, <8 x i16> %209, <8 x i16> %208
  %212 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %211, <8 x i16> %57) #6
  %213 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %34, <8 x i16> %212) #6
  %214 = icmp slt <8 x i16> %213, %211
  %215 = select <8 x i1> %214, <8 x i16> %213, <8 x i16> %211
  %216 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %215, <8 x i16> %208) #6
  %217 = sub <8 x i16> %171, %161
  %218 = sub <8 x i16> zeroinitializer, %217
  %219 = icmp slt <8 x i16> %217, zeroinitializer
  %220 = select <8 x i1> %219, <8 x i16> %218, <8 x i16> %217
  %221 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %220, <8 x i16> %57) #6
  %222 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %34, <8 x i16> %221) #6
  %223 = icmp slt <8 x i16> %222, %220
  %224 = select <8 x i1> %223, <8 x i16> %222, <8 x i16> %220
  %225 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %224, <8 x i16> %217) #6
  %226 = getelementptr inbounds i16, i16* %103, i64 %70
  %227 = getelementptr inbounds i16, i16* %226, i64 %72
  %228 = bitcast i16* %227 to i64*
  %229 = load i64, i64* %228, align 1
  %230 = insertelement <2 x i64> undef, i64 %229, i32 0
  %231 = getelementptr inbounds i16, i16* %226, i64 %1
  %232 = getelementptr inbounds i16, i16* %231, i64 %72
  %233 = bitcast <2 x i64> %230 to <4 x float>
  %234 = bitcast i16* %232 to <2 x float>*
  %235 = load <2 x float>, <2 x float>* %234, align 1
  %236 = shufflevector <2 x float> %235, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %237 = shufflevector <4 x float> %233, <4 x float> %236, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %238 = getelementptr inbounds i16, i16* %103, i64 %69
  %239 = getelementptr inbounds i16, i16* %238, i64 %71
  %240 = bitcast i16* %239 to i64*
  %241 = load i64, i64* %240, align 1
  %242 = insertelement <2 x i64> undef, i64 %241, i32 0
  %243 = getelementptr inbounds i16, i16* %238, i64 %1
  %244 = getelementptr inbounds i16, i16* %243, i64 %71
  %245 = bitcast <2 x i64> %242 to <4 x float>
  %246 = bitcast i16* %244 to <2 x float>*
  %247 = load <2 x float>, <2 x float>* %246, align 1
  %248 = shufflevector <2 x float> %247, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %249 = shufflevector <4 x float> %245, <4 x float> %248, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %250 = getelementptr inbounds i16, i16* %103, i64 %75
  %251 = getelementptr inbounds i16, i16* %250, i64 %77
  %252 = bitcast i16* %251 to i64*
  %253 = load i64, i64* %252, align 1
  %254 = insertelement <2 x i64> undef, i64 %253, i32 0
  %255 = getelementptr inbounds i16, i16* %250, i64 %1
  %256 = getelementptr inbounds i16, i16* %255, i64 %77
  %257 = bitcast <2 x i64> %254 to <4 x float>
  %258 = bitcast i16* %256 to <2 x float>*
  %259 = load <2 x float>, <2 x float>* %258, align 1
  %260 = shufflevector <2 x float> %259, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %261 = shufflevector <4 x float> %257, <4 x float> %260, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %262 = getelementptr inbounds i16, i16* %103, i64 %74
  %263 = getelementptr inbounds i16, i16* %262, i64 %76
  %264 = bitcast i16* %263 to i64*
  %265 = load i64, i64* %264, align 1
  %266 = insertelement <2 x i64> undef, i64 %265, i32 0
  %267 = getelementptr inbounds i16, i16* %262, i64 %1
  %268 = getelementptr inbounds i16, i16* %267, i64 %76
  %269 = bitcast <2 x i64> %266 to <4 x float>
  %270 = bitcast i16* %268 to <2 x float>*
  %271 = load <2 x float>, <2 x float>* %270, align 1
  %272 = shufflevector <2 x float> %271, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %273 = shufflevector <4 x float> %269, <4 x float> %272, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %274 = getelementptr inbounds i16, i16* %103, i64 %90
  %275 = getelementptr inbounds i16, i16* %274, i64 %92
  %276 = bitcast i16* %275 to i64*
  %277 = load i64, i64* %276, align 1
  %278 = insertelement <2 x i64> undef, i64 %277, i32 0
  %279 = getelementptr inbounds i16, i16* %274, i64 %1
  %280 = getelementptr inbounds i16, i16* %279, i64 %92
  %281 = bitcast <2 x i64> %278 to <4 x float>
  %282 = bitcast i16* %280 to <2 x float>*
  %283 = load <2 x float>, <2 x float>* %282, align 1
  %284 = shufflevector <2 x float> %283, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %285 = shufflevector <4 x float> %281, <4 x float> %284, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %286 = getelementptr inbounds i16, i16* %103, i64 %89
  %287 = getelementptr inbounds i16, i16* %286, i64 %91
  %288 = bitcast i16* %287 to i64*
  %289 = load i64, i64* %288, align 1
  %290 = insertelement <2 x i64> undef, i64 %289, i32 0
  %291 = getelementptr inbounds i16, i16* %286, i64 %1
  %292 = getelementptr inbounds i16, i16* %291, i64 %91
  %293 = bitcast <2 x i64> %290 to <4 x float>
  %294 = bitcast i16* %292 to <2 x float>*
  %295 = load <2 x float>, <2 x float>* %294, align 1
  %296 = shufflevector <2 x float> %295, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %297 = shufflevector <4 x float> %293, <4 x float> %296, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %298 = getelementptr inbounds i16, i16* %103, i64 %95
  %299 = getelementptr inbounds i16, i16* %298, i64 %97
  %300 = bitcast i16* %299 to i64*
  %301 = load i64, i64* %300, align 1
  %302 = insertelement <2 x i64> undef, i64 %301, i32 0
  %303 = getelementptr inbounds i16, i16* %298, i64 %1
  %304 = getelementptr inbounds i16, i16* %303, i64 %97
  %305 = bitcast <2 x i64> %302 to <4 x float>
  %306 = bitcast i16* %304 to <2 x float>*
  %307 = load <2 x float>, <2 x float>* %306, align 1
  %308 = shufflevector <2 x float> %307, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %309 = shufflevector <4 x float> %305, <4 x float> %308, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %310 = getelementptr inbounds i16, i16* %103, i64 %94
  %311 = getelementptr inbounds i16, i16* %310, i64 %96
  %312 = bitcast i16* %311 to i64*
  %313 = load i64, i64* %312, align 1
  %314 = insertelement <2 x i64> undef, i64 %313, i32 0
  %315 = getelementptr inbounds i16, i16* %310, i64 %1
  %316 = getelementptr inbounds i16, i16* %315, i64 %96
  %317 = bitcast <2 x i64> %314 to <4 x float>
  %318 = bitcast i16* %316 to <2 x float>*
  %319 = load <2 x float>, <2 x float>* %318, align 1
  %320 = shufflevector <2 x float> %319, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %321 = shufflevector <4 x float> %317, <4 x float> %320, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %322 = bitcast <4 x float> %237 to <8 x i16>
  %323 = icmp ult <8 x i16> %173, %322
  %324 = select <8 x i1> %323, <8 x i16> %173, <8 x i16> %322
  %325 = bitcast <4 x float> %249 to <8 x i16>
  %326 = icmp ult <8 x i16> %324, %325
  %327 = select <8 x i1> %326, <8 x i16> %324, <8 x i16> %325
  %328 = bitcast <4 x float> %261 to <8 x i16>
  %329 = icmp ult <8 x i16> %327, %328
  %330 = select <8 x i1> %329, <8 x i16> %327, <8 x i16> %328
  %331 = bitcast <4 x float> %273 to <8 x i16>
  %332 = icmp ult <8 x i16> %330, %331
  %333 = select <8 x i1> %332, <8 x i16> %330, <8 x i16> %331
  %334 = bitcast <4 x float> %285 to <8 x i16>
  %335 = icmp ult <8 x i16> %333, %334
  %336 = select <8 x i1> %335, <8 x i16> %333, <8 x i16> %334
  %337 = bitcast <4 x float> %297 to <8 x i16>
  %338 = icmp ult <8 x i16> %336, %337
  %339 = select <8 x i1> %338, <8 x i16> %336, <8 x i16> %337
  %340 = bitcast <4 x float> %309 to <8 x i16>
  %341 = icmp ult <8 x i16> %339, %340
  %342 = select <8 x i1> %341, <8 x i16> %339, <8 x i16> %340
  %343 = bitcast <4 x float> %321 to <8 x i16>
  %344 = icmp ult <8 x i16> %342, %343
  %345 = select <8 x i1> %344, <8 x i16> %342, <8 x i16> %343
  %346 = bitcast <4 x float> %237 to <16 x i8>
  %347 = bitcast <4 x float> %249 to <16 x i8>
  %348 = icmp ugt <16 x i8> %346, %347
  %349 = select <16 x i1> %348, <16 x i8> %346, <16 x i8> %347
  %350 = bitcast <4 x float> %261 to <16 x i8>
  %351 = bitcast <4 x float> %273 to <16 x i8>
  %352 = icmp ugt <16 x i8> %350, %351
  %353 = select <16 x i1> %352, <16 x i8> %350, <16 x i8> %351
  %354 = bitcast <4 x float> %285 to <16 x i8>
  %355 = bitcast <4 x float> %297 to <16 x i8>
  %356 = icmp ugt <16 x i8> %354, %355
  %357 = select <16 x i1> %356, <16 x i8> %354, <16 x i8> %355
  %358 = bitcast <4 x float> %309 to <16 x i8>
  %359 = bitcast <4 x float> %321 to <16 x i8>
  %360 = icmp ugt <16 x i8> %358, %359
  %361 = select <16 x i1> %360, <16 x i8> %358, <16 x i8> %359
  %362 = icmp ugt <16 x i8> %349, %353
  %363 = select <16 x i1> %362, <16 x i8> %349, <16 x i8> %353
  %364 = icmp ugt <16 x i8> %357, %361
  %365 = select <16 x i1> %364, <16 x i8> %357, <16 x i8> %361
  %366 = icmp ugt <16 x i8> %363, %365
  %367 = select <16 x i1> %366, <16 x i8> %363, <16 x i8> %365
  %368 = bitcast <16 x i8> %367 to <8 x i16>
  %369 = and <8 x i16> %368, <i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385>
  %370 = icmp ugt <8 x i16> %187, %369
  %371 = select <8 x i1> %370, <8 x i16> %187, <8 x i16> %369
  %372 = sub <8 x i16> %322, %161
  %373 = sub <8 x i16> zeroinitializer, %372
  %374 = icmp slt <8 x i16> %372, zeroinitializer
  %375 = select <8 x i1> %374, <8 x i16> %373, <8 x i16> %372
  %376 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %375, <8 x i16> %98) #6
  %377 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %376) #6
  %378 = icmp slt <8 x i16> %377, %375
  %379 = select <8 x i1> %378, <8 x i16> %377, <8 x i16> %375
  %380 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %379, <8 x i16> %372) #6
  %381 = shl <8 x i16> %380, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %382 = sub <8 x i16> %325, %161
  %383 = sub <8 x i16> zeroinitializer, %382
  %384 = icmp slt <8 x i16> %382, zeroinitializer
  %385 = select <8 x i1> %384, <8 x i16> %383, <8 x i16> %382
  %386 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %385, <8 x i16> %98) #6
  %387 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %386) #6
  %388 = icmp slt <8 x i16> %387, %385
  %389 = select <8 x i1> %388, <8 x i16> %387, <8 x i16> %385
  %390 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %389, <8 x i16> %382) #6
  %391 = shl <8 x i16> %390, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %392 = sub <8 x i16> %328, %161
  %393 = sub <8 x i16> zeroinitializer, %392
  %394 = icmp slt <8 x i16> %392, zeroinitializer
  %395 = select <8 x i1> %394, <8 x i16> %393, <8 x i16> %392
  %396 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %395, <8 x i16> %98) #6
  %397 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %396) #6
  %398 = icmp slt <8 x i16> %397, %395
  %399 = select <8 x i1> %398, <8 x i16> %397, <8 x i16> %395
  %400 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %399, <8 x i16> %392) #6
  %401 = sub <8 x i16> %331, %161
  %402 = sub <8 x i16> zeroinitializer, %401
  %403 = icmp slt <8 x i16> %401, zeroinitializer
  %404 = select <8 x i1> %403, <8 x i16> %402, <8 x i16> %401
  %405 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %404, <8 x i16> %98) #6
  %406 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %405) #6
  %407 = icmp slt <8 x i16> %406, %404
  %408 = select <8 x i1> %407, <8 x i16> %406, <8 x i16> %404
  %409 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %408, <8 x i16> %401) #6
  %410 = sub <8 x i16> %334, %161
  %411 = sub <8 x i16> zeroinitializer, %410
  %412 = icmp slt <8 x i16> %410, zeroinitializer
  %413 = select <8 x i1> %412, <8 x i16> %411, <8 x i16> %410
  %414 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %413, <8 x i16> %98) #6
  %415 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %414) #6
  %416 = icmp slt <8 x i16> %415, %413
  %417 = select <8 x i1> %416, <8 x i16> %415, <8 x i16> %413
  %418 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %417, <8 x i16> %410) #6
  %419 = shl <8 x i16> %418, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %420 = sub <8 x i16> %337, %161
  %421 = sub <8 x i16> zeroinitializer, %420
  %422 = icmp slt <8 x i16> %420, zeroinitializer
  %423 = select <8 x i1> %422, <8 x i16> %421, <8 x i16> %420
  %424 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %423, <8 x i16> %98) #6
  %425 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %424) #6
  %426 = icmp slt <8 x i16> %425, %423
  %427 = select <8 x i1> %426, <8 x i16> %425, <8 x i16> %423
  %428 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %427, <8 x i16> %420) #6
  %429 = shl <8 x i16> %428, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %430 = sub <8 x i16> %340, %161
  %431 = sub <8 x i16> zeroinitializer, %430
  %432 = icmp slt <8 x i16> %430, zeroinitializer
  %433 = select <8 x i1> %432, <8 x i16> %431, <8 x i16> %430
  %434 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %433, <8 x i16> %98) #6
  %435 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %434) #6
  %436 = icmp slt <8 x i16> %435, %433
  %437 = select <8 x i1> %436, <8 x i16> %435, <8 x i16> %433
  %438 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %437, <8 x i16> %430) #6
  %439 = sub <8 x i16> %343, %161
  %440 = sub <8 x i16> zeroinitializer, %439
  %441 = icmp slt <8 x i16> %439, zeroinitializer
  %442 = select <8 x i1> %441, <8 x i16> %440, <8 x i16> %439
  %443 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %442, <8 x i16> %98) #6
  %444 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %443) #6
  %445 = icmp slt <8 x i16> %444, %442
  %446 = select <8 x i1> %445, <8 x i16> %444, <8 x i16> %442
  %447 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %446, <8 x i16> %439) #6
  %448 = add <8 x i16> %225, %216
  %449 = mul <8 x i16> %448, %31
  %450 = add <8 x i16> %449, %207
  %451 = add <8 x i16> %450, %381
  %452 = add <8 x i16> %451, %391
  %453 = add <8 x i16> %452, %400
  %454 = add <8 x i16> %453, %409
  %455 = add <8 x i16> %454, %419
  %456 = add <8 x i16> %455, %429
  %457 = add <8 x i16> %456, %438
  %458 = add <8 x i16> %457, %447
  %459 = ashr <8 x i16> %458, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %460 = add <8 x i16> %458, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %461 = add <8 x i16> %460, %459
  %462 = ashr <8 x i16> %461, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %463 = add <8 x i16> %462, %161
  %464 = icmp slt <8 x i16> %463, %371
  %465 = select <8 x i1> %464, <8 x i16> %463, <8 x i16> %371
  %466 = icmp sgt <8 x i16> %465, %345
  %467 = select <8 x i1> %466, <8 x i16> %465, <8 x i16> %345
  %468 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %467, <8 x i16> %467) #6
  %469 = getelementptr inbounds i16, i16* %103, i64 %99
  %470 = bitcast <16 x i8> %468 to <4 x i32>
  %471 = extractelement <4 x i32> %470, i32 0
  %472 = bitcast i8* %102 to i32*
  store i32 %471, i32* %472, align 1
  %473 = getelementptr inbounds i8, i8* %102, i64 %8
  %474 = shufflevector <16 x i8> %468, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %475 = bitcast <16 x i8> %474 to <4 x i32>
  %476 = extractelement <4 x i32> %475, i32 0
  %477 = bitcast i8* %473 to i32*
  store i32 %476, i32* %477, align 1
  %478 = getelementptr inbounds i8, i8* %473, i64 %8
  %479 = add nsw i32 %101, -2
  %480 = icmp eq i32 %479, 0
  br i1 %480, label %481, label %100

481:                                              ; preds = %100
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi4ELb1ELb0EEEvPKtliiiiiPvl(i16* nocapture readonly, i64, i32, i32, i32, i32, i32, i8* nocapture, i64) #3 {
  %10 = tail call i32 @llvm.ctlz.i32(i32 %3, i1 true) #6, !range !2
  %11 = xor i32 %10, 31
  %12 = sub nsw i32 %5, %11
  %13 = icmp sgt i32 %12, 0
  %14 = select i1 %13, i32 %12, i32 0
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %14, i32 0
  %16 = and i32 %3, 1
  %17 = zext i32 %16 to i64
  %18 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* @_ZN7libgav116kCdefPrimaryTapsE, i64 0, i64 %17, i64 0
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> zeroinitializer
  %23 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* @_ZN7libgav116kCdefPrimaryTapsE, i64 0, i64 %17, i64 1
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i16
  %26 = insertelement <8 x i16> undef, i16 %25, i32 0
  %27 = shufflevector <8 x i16> %26, <8 x i16> undef, <8 x i32> zeroinitializer
  %28 = trunc i32 %3 to i16
  %29 = insertelement <8 x i16> undef, i16 %28, i32 0
  %30 = shufflevector <8 x i16> %29, <8 x i16> undef, <8 x i32> zeroinitializer
  %31 = sext i32 %6 to i64
  %32 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %31, i64 0, i64 0
  %33 = load i8, i8* %32, align 4
  %34 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %31, i64 0, i64 1
  %35 = load i8, i8* %34, align 1
  %36 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %31, i64 1, i64 0
  %37 = load i8, i8* %36, align 2
  %38 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %31, i64 1, i64 1
  %39 = load i8, i8* %38, align 1
  %40 = sext i8 %33 to i64
  %41 = mul nsw i64 %40, %1
  %42 = sub i64 0, %41
  %43 = sext i8 %35 to i64
  %44 = sub nsw i64 0, %43
  %45 = sext i8 %37 to i64
  %46 = mul nsw i64 %45, %1
  %47 = sub i64 0, %46
  %48 = sext i8 %39 to i64
  %49 = sub nsw i64 0, %48
  %50 = bitcast <4 x i32> %15 to <8 x i16>
  %51 = shl i64 %1, 1
  br label %52

52:                                               ; preds = %52, %9
  %53 = phi i32 [ %2, %9 ], [ %175, %52 ]
  %54 = phi i8* [ %7, %9 ], [ %174, %52 ]
  %55 = phi i16* [ %0, %9 ], [ %165, %52 ]
  %56 = bitcast i16* %55 to i64*
  %57 = load i64, i64* %56, align 1
  %58 = insertelement <2 x i64> undef, i64 %57, i32 0
  %59 = getelementptr inbounds i16, i16* %55, i64 %1
  %60 = bitcast <2 x i64> %58 to <4 x float>
  %61 = bitcast i16* %59 to <2 x float>*
  %62 = load <2 x float>, <2 x float>* %61, align 1
  %63 = shufflevector <2 x float> %62, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %64 = shufflevector <4 x float> %60, <4 x float> %63, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %65 = getelementptr inbounds i16, i16* %55, i64 %42
  %66 = getelementptr inbounds i16, i16* %65, i64 %44
  %67 = bitcast i16* %66 to i64*
  %68 = load i64, i64* %67, align 1
  %69 = insertelement <2 x i64> undef, i64 %68, i32 0
  %70 = getelementptr inbounds i16, i16* %65, i64 %1
  %71 = getelementptr inbounds i16, i16* %70, i64 %44
  %72 = bitcast <2 x i64> %69 to <4 x float>
  %73 = bitcast i16* %71 to <2 x float>*
  %74 = load <2 x float>, <2 x float>* %73, align 1
  %75 = shufflevector <2 x float> %74, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %76 = shufflevector <4 x float> %72, <4 x float> %75, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %77 = bitcast <4 x float> %76 to <8 x i16>
  %78 = getelementptr inbounds i16, i16* %55, i64 %41
  %79 = getelementptr inbounds i16, i16* %78, i64 %43
  %80 = bitcast i16* %79 to i64*
  %81 = load i64, i64* %80, align 1
  %82 = insertelement <2 x i64> undef, i64 %81, i32 0
  %83 = getelementptr inbounds i16, i16* %78, i64 %1
  %84 = getelementptr inbounds i16, i16* %83, i64 %43
  %85 = bitcast <2 x i64> %82 to <4 x float>
  %86 = bitcast i16* %84 to <2 x float>*
  %87 = load <2 x float>, <2 x float>* %86, align 1
  %88 = shufflevector <2 x float> %87, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %89 = shufflevector <4 x float> %85, <4 x float> %88, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %90 = bitcast <4 x float> %89 to <8 x i16>
  %91 = getelementptr inbounds i16, i16* %55, i64 %47
  %92 = getelementptr inbounds i16, i16* %91, i64 %49
  %93 = bitcast i16* %92 to i64*
  %94 = load i64, i64* %93, align 1
  %95 = insertelement <2 x i64> undef, i64 %94, i32 0
  %96 = getelementptr inbounds i16, i16* %91, i64 %1
  %97 = getelementptr inbounds i16, i16* %96, i64 %49
  %98 = bitcast <2 x i64> %95 to <4 x float>
  %99 = bitcast i16* %97 to <2 x float>*
  %100 = load <2 x float>, <2 x float>* %99, align 1
  %101 = shufflevector <2 x float> %100, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %102 = shufflevector <4 x float> %98, <4 x float> %101, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %103 = bitcast <4 x float> %102 to <8 x i16>
  %104 = getelementptr inbounds i16, i16* %55, i64 %46
  %105 = getelementptr inbounds i16, i16* %104, i64 %48
  %106 = bitcast i16* %105 to i64*
  %107 = load i64, i64* %106, align 1
  %108 = insertelement <2 x i64> undef, i64 %107, i32 0
  %109 = getelementptr inbounds i16, i16* %104, i64 %1
  %110 = getelementptr inbounds i16, i16* %109, i64 %48
  %111 = bitcast <2 x i64> %108 to <4 x float>
  %112 = bitcast i16* %110 to <2 x float>*
  %113 = load <2 x float>, <2 x float>* %112, align 1
  %114 = shufflevector <2 x float> %113, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %115 = shufflevector <4 x float> %111, <4 x float> %114, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %116 = bitcast <4 x float> %115 to <8 x i16>
  %117 = bitcast <4 x float> %64 to <8 x i16>
  %118 = sub <8 x i16> %77, %117
  %119 = sub <8 x i16> zeroinitializer, %118
  %120 = icmp slt <8 x i16> %118, zeroinitializer
  %121 = select <8 x i1> %120, <8 x i16> %119, <8 x i16> %118
  %122 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %121, <8 x i16> %50) #6
  %123 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %30, <8 x i16> %122) #6
  %124 = icmp slt <8 x i16> %123, %121
  %125 = select <8 x i1> %124, <8 x i16> %123, <8 x i16> %121
  %126 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %125, <8 x i16> %118) #6
  %127 = sub <8 x i16> %90, %117
  %128 = sub <8 x i16> zeroinitializer, %127
  %129 = icmp slt <8 x i16> %127, zeroinitializer
  %130 = select <8 x i1> %129, <8 x i16> %128, <8 x i16> %127
  %131 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %130, <8 x i16> %50) #6
  %132 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %30, <8 x i16> %131) #6
  %133 = icmp slt <8 x i16> %132, %130
  %134 = select <8 x i1> %133, <8 x i16> %132, <8 x i16> %130
  %135 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %134, <8 x i16> %127) #6
  %136 = add <8 x i16> %135, %126
  %137 = mul <8 x i16> %136, %22
  %138 = sub <8 x i16> %103, %117
  %139 = sub <8 x i16> zeroinitializer, %138
  %140 = icmp slt <8 x i16> %138, zeroinitializer
  %141 = select <8 x i1> %140, <8 x i16> %139, <8 x i16> %138
  %142 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %141, <8 x i16> %50) #6
  %143 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %30, <8 x i16> %142) #6
  %144 = icmp slt <8 x i16> %143, %141
  %145 = select <8 x i1> %144, <8 x i16> %143, <8 x i16> %141
  %146 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %145, <8 x i16> %138) #6
  %147 = sub <8 x i16> %116, %117
  %148 = sub <8 x i16> zeroinitializer, %147
  %149 = icmp slt <8 x i16> %147, zeroinitializer
  %150 = select <8 x i1> %149, <8 x i16> %148, <8 x i16> %147
  %151 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %150, <8 x i16> %50) #6
  %152 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %30, <8 x i16> %151) #6
  %153 = icmp slt <8 x i16> %152, %150
  %154 = select <8 x i1> %153, <8 x i16> %152, <8 x i16> %150
  %155 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %154, <8 x i16> %147) #6
  %156 = add <8 x i16> %155, %146
  %157 = mul <8 x i16> %156, %27
  %158 = add <8 x i16> %157, %137
  %159 = ashr <8 x i16> %158, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %160 = add <8 x i16> %158, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %161 = add <8 x i16> %160, %159
  %162 = ashr <8 x i16> %161, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %163 = add <8 x i16> %162, %117
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %163) #6
  %165 = getelementptr inbounds i16, i16* %55, i64 %51
  %166 = bitcast <16 x i8> %164 to <4 x i32>
  %167 = extractelement <4 x i32> %166, i32 0
  %168 = bitcast i8* %54 to i32*
  store i32 %167, i32* %168, align 1
  %169 = getelementptr inbounds i8, i8* %54, i64 %8
  %170 = shufflevector <16 x i8> %164, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %171 = bitcast <16 x i8> %170 to <4 x i32>
  %172 = extractelement <4 x i32> %171, i32 0
  %173 = bitcast i8* %169 to i32*
  store i32 %172, i32* %173, align 1
  %174 = getelementptr inbounds i8, i8* %169, i64 %8
  %175 = add nsw i32 %53, -2
  %176 = icmp eq i32 %175, 0
  br i1 %176, label %177, label %52

177:                                              ; preds = %52
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi4ELb0ELb1EEEvPKtliiiiiPvl(i16* nocapture readonly, i64, i32, i32, i32, i32, i32, i8* nocapture, i64) #3 {
  %10 = tail call i32 @llvm.ctlz.i32(i32 %4, i1 true) #6, !range !2
  %11 = xor i32 %10, 31
  %12 = sub nsw i32 %5, %11
  %13 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %12, i32 0
  %14 = trunc i32 %4 to i16
  %15 = insertelement <8 x i16> undef, i16 %14, i32 0
  %16 = shufflevector <8 x i16> %15, <8 x i16> undef, <8 x i32> zeroinitializer
  %17 = add nsw i32 %6, 2
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %18, i64 0, i64 0
  %20 = load i8, i8* %19, align 4
  %21 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %18, i64 0, i64 1
  %22 = load i8, i8* %21, align 1
  %23 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %18, i64 1, i64 0
  %24 = load i8, i8* %23, align 2
  %25 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %18, i64 1, i64 1
  %26 = load i8, i8* %25, align 1
  %27 = sext i8 %20 to i64
  %28 = mul nsw i64 %27, %1
  %29 = sub i64 0, %28
  %30 = sext i8 %22 to i64
  %31 = sub nsw i64 0, %30
  %32 = sext i8 %24 to i64
  %33 = mul nsw i64 %32, %1
  %34 = sub i64 0, %33
  %35 = sext i8 %26 to i64
  %36 = sub nsw i64 0, %35
  %37 = add nsw i32 %6, -2
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 0, i64 0
  %40 = load i8, i8* %39, align 4
  %41 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 0, i64 1
  %42 = load i8, i8* %41, align 1
  %43 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 1, i64 0
  %44 = load i8, i8* %43, align 2
  %45 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 1, i64 1
  %46 = load i8, i8* %45, align 1
  %47 = sext i8 %40 to i64
  %48 = mul nsw i64 %47, %1
  %49 = sub i64 0, %48
  %50 = sext i8 %42 to i64
  %51 = sub nsw i64 0, %50
  %52 = sext i8 %44 to i64
  %53 = mul nsw i64 %52, %1
  %54 = sub i64 0, %53
  %55 = sext i8 %46 to i64
  %56 = sub nsw i64 0, %55
  %57 = bitcast <4 x i32> %13 to <8 x i16>
  %58 = shl i64 %1, 1
  br label %59

59:                                               ; preds = %59, %9
  %60 = phi i32 [ %2, %9 ], [ %275, %59 ]
  %61 = phi i8* [ %7, %9 ], [ %274, %59 ]
  %62 = phi i16* [ %0, %9 ], [ %265, %59 ]
  %63 = bitcast i16* %62 to i64*
  %64 = load i64, i64* %63, align 1
  %65 = insertelement <2 x i64> undef, i64 %64, i32 0
  %66 = getelementptr inbounds i16, i16* %62, i64 %1
  %67 = bitcast <2 x i64> %65 to <4 x float>
  %68 = bitcast i16* %66 to <2 x float>*
  %69 = load <2 x float>, <2 x float>* %68, align 1
  %70 = shufflevector <2 x float> %69, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %71 = shufflevector <4 x float> %67, <4 x float> %70, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %72 = getelementptr inbounds i16, i16* %62, i64 %29
  %73 = getelementptr inbounds i16, i16* %72, i64 %31
  %74 = bitcast i16* %73 to i64*
  %75 = load i64, i64* %74, align 1
  %76 = insertelement <2 x i64> undef, i64 %75, i32 0
  %77 = getelementptr inbounds i16, i16* %72, i64 %1
  %78 = getelementptr inbounds i16, i16* %77, i64 %31
  %79 = bitcast <2 x i64> %76 to <4 x float>
  %80 = bitcast i16* %78 to <2 x float>*
  %81 = load <2 x float>, <2 x float>* %80, align 1
  %82 = shufflevector <2 x float> %81, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %83 = shufflevector <4 x float> %79, <4 x float> %82, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %84 = bitcast <4 x float> %83 to <8 x i16>
  %85 = getelementptr inbounds i16, i16* %62, i64 %28
  %86 = getelementptr inbounds i16, i16* %85, i64 %30
  %87 = bitcast i16* %86 to i64*
  %88 = load i64, i64* %87, align 1
  %89 = insertelement <2 x i64> undef, i64 %88, i32 0
  %90 = getelementptr inbounds i16, i16* %85, i64 %1
  %91 = getelementptr inbounds i16, i16* %90, i64 %30
  %92 = bitcast <2 x i64> %89 to <4 x float>
  %93 = bitcast i16* %91 to <2 x float>*
  %94 = load <2 x float>, <2 x float>* %93, align 1
  %95 = shufflevector <2 x float> %94, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %96 = shufflevector <4 x float> %92, <4 x float> %95, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %97 = bitcast <4 x float> %96 to <8 x i16>
  %98 = getelementptr inbounds i16, i16* %62, i64 %34
  %99 = getelementptr inbounds i16, i16* %98, i64 %36
  %100 = bitcast i16* %99 to i64*
  %101 = load i64, i64* %100, align 1
  %102 = insertelement <2 x i64> undef, i64 %101, i32 0
  %103 = getelementptr inbounds i16, i16* %98, i64 %1
  %104 = getelementptr inbounds i16, i16* %103, i64 %36
  %105 = bitcast <2 x i64> %102 to <4 x float>
  %106 = bitcast i16* %104 to <2 x float>*
  %107 = load <2 x float>, <2 x float>* %106, align 1
  %108 = shufflevector <2 x float> %107, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %109 = shufflevector <4 x float> %105, <4 x float> %108, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %110 = bitcast <4 x float> %109 to <8 x i16>
  %111 = getelementptr inbounds i16, i16* %62, i64 %33
  %112 = getelementptr inbounds i16, i16* %111, i64 %35
  %113 = bitcast i16* %112 to i64*
  %114 = load i64, i64* %113, align 1
  %115 = insertelement <2 x i64> undef, i64 %114, i32 0
  %116 = getelementptr inbounds i16, i16* %111, i64 %1
  %117 = getelementptr inbounds i16, i16* %116, i64 %35
  %118 = bitcast <2 x i64> %115 to <4 x float>
  %119 = bitcast i16* %117 to <2 x float>*
  %120 = load <2 x float>, <2 x float>* %119, align 1
  %121 = shufflevector <2 x float> %120, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %122 = shufflevector <4 x float> %118, <4 x float> %121, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %123 = bitcast <4 x float> %122 to <8 x i16>
  %124 = getelementptr inbounds i16, i16* %62, i64 %49
  %125 = getelementptr inbounds i16, i16* %124, i64 %51
  %126 = bitcast i16* %125 to i64*
  %127 = load i64, i64* %126, align 1
  %128 = insertelement <2 x i64> undef, i64 %127, i32 0
  %129 = getelementptr inbounds i16, i16* %124, i64 %1
  %130 = getelementptr inbounds i16, i16* %129, i64 %51
  %131 = bitcast <2 x i64> %128 to <4 x float>
  %132 = bitcast i16* %130 to <2 x float>*
  %133 = load <2 x float>, <2 x float>* %132, align 1
  %134 = shufflevector <2 x float> %133, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %135 = shufflevector <4 x float> %131, <4 x float> %134, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %136 = bitcast <4 x float> %135 to <8 x i16>
  %137 = getelementptr inbounds i16, i16* %62, i64 %48
  %138 = getelementptr inbounds i16, i16* %137, i64 %50
  %139 = bitcast i16* %138 to i64*
  %140 = load i64, i64* %139, align 1
  %141 = insertelement <2 x i64> undef, i64 %140, i32 0
  %142 = getelementptr inbounds i16, i16* %137, i64 %1
  %143 = getelementptr inbounds i16, i16* %142, i64 %50
  %144 = bitcast <2 x i64> %141 to <4 x float>
  %145 = bitcast i16* %143 to <2 x float>*
  %146 = load <2 x float>, <2 x float>* %145, align 1
  %147 = shufflevector <2 x float> %146, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %148 = shufflevector <4 x float> %144, <4 x float> %147, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %149 = bitcast <4 x float> %148 to <8 x i16>
  %150 = getelementptr inbounds i16, i16* %62, i64 %54
  %151 = getelementptr inbounds i16, i16* %150, i64 %56
  %152 = bitcast i16* %151 to i64*
  %153 = load i64, i64* %152, align 1
  %154 = insertelement <2 x i64> undef, i64 %153, i32 0
  %155 = getelementptr inbounds i16, i16* %150, i64 %1
  %156 = getelementptr inbounds i16, i16* %155, i64 %56
  %157 = bitcast <2 x i64> %154 to <4 x float>
  %158 = bitcast i16* %156 to <2 x float>*
  %159 = load <2 x float>, <2 x float>* %158, align 1
  %160 = shufflevector <2 x float> %159, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %161 = shufflevector <4 x float> %157, <4 x float> %160, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %162 = bitcast <4 x float> %161 to <8 x i16>
  %163 = getelementptr inbounds i16, i16* %62, i64 %53
  %164 = getelementptr inbounds i16, i16* %163, i64 %55
  %165 = bitcast i16* %164 to i64*
  %166 = load i64, i64* %165, align 1
  %167 = insertelement <2 x i64> undef, i64 %166, i32 0
  %168 = getelementptr inbounds i16, i16* %163, i64 %1
  %169 = getelementptr inbounds i16, i16* %168, i64 %55
  %170 = bitcast <2 x i64> %167 to <4 x float>
  %171 = bitcast i16* %169 to <2 x float>*
  %172 = load <2 x float>, <2 x float>* %171, align 1
  %173 = shufflevector <2 x float> %172, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %174 = shufflevector <4 x float> %170, <4 x float> %173, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %175 = bitcast <4 x float> %174 to <8 x i16>
  %176 = bitcast <4 x float> %71 to <8 x i16>
  %177 = sub <8 x i16> %84, %176
  %178 = sub <8 x i16> zeroinitializer, %177
  %179 = icmp slt <8 x i16> %177, zeroinitializer
  %180 = select <8 x i1> %179, <8 x i16> %178, <8 x i16> %177
  %181 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %180, <8 x i16> %57) #6
  %182 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %181) #6
  %183 = icmp slt <8 x i16> %182, %180
  %184 = select <8 x i1> %183, <8 x i16> %182, <8 x i16> %180
  %185 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %184, <8 x i16> %177) #6
  %186 = sub <8 x i16> %97, %176
  %187 = sub <8 x i16> zeroinitializer, %186
  %188 = icmp slt <8 x i16> %186, zeroinitializer
  %189 = select <8 x i1> %188, <8 x i16> %187, <8 x i16> %186
  %190 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %189, <8 x i16> %57) #6
  %191 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %190) #6
  %192 = icmp slt <8 x i16> %191, %189
  %193 = select <8 x i1> %192, <8 x i16> %191, <8 x i16> %189
  %194 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %193, <8 x i16> %186) #6
  %195 = add <8 x i16> %194, %185
  %196 = shl <8 x i16> %195, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %197 = sub <8 x i16> %110, %176
  %198 = sub <8 x i16> zeroinitializer, %197
  %199 = icmp slt <8 x i16> %197, zeroinitializer
  %200 = select <8 x i1> %199, <8 x i16> %198, <8 x i16> %197
  %201 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %200, <8 x i16> %57) #6
  %202 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %201) #6
  %203 = icmp slt <8 x i16> %202, %200
  %204 = select <8 x i1> %203, <8 x i16> %202, <8 x i16> %200
  %205 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %204, <8 x i16> %197) #6
  %206 = add <8 x i16> %205, %196
  %207 = sub <8 x i16> %123, %176
  %208 = sub <8 x i16> zeroinitializer, %207
  %209 = icmp slt <8 x i16> %207, zeroinitializer
  %210 = select <8 x i1> %209, <8 x i16> %208, <8 x i16> %207
  %211 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %210, <8 x i16> %57) #6
  %212 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %211) #6
  %213 = icmp slt <8 x i16> %212, %210
  %214 = select <8 x i1> %213, <8 x i16> %212, <8 x i16> %210
  %215 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %214, <8 x i16> %207) #6
  %216 = add <8 x i16> %206, %215
  %217 = sub <8 x i16> %136, %176
  %218 = sub <8 x i16> zeroinitializer, %217
  %219 = icmp slt <8 x i16> %217, zeroinitializer
  %220 = select <8 x i1> %219, <8 x i16> %218, <8 x i16> %217
  %221 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %220, <8 x i16> %57) #6
  %222 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %221) #6
  %223 = icmp slt <8 x i16> %222, %220
  %224 = select <8 x i1> %223, <8 x i16> %222, <8 x i16> %220
  %225 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %224, <8 x i16> %217) #6
  %226 = shl <8 x i16> %225, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %227 = add <8 x i16> %216, %226
  %228 = sub <8 x i16> %149, %176
  %229 = sub <8 x i16> zeroinitializer, %228
  %230 = icmp slt <8 x i16> %228, zeroinitializer
  %231 = select <8 x i1> %230, <8 x i16> %229, <8 x i16> %228
  %232 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %231, <8 x i16> %57) #6
  %233 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %232) #6
  %234 = icmp slt <8 x i16> %233, %231
  %235 = select <8 x i1> %234, <8 x i16> %233, <8 x i16> %231
  %236 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %235, <8 x i16> %228) #6
  %237 = shl <8 x i16> %236, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %238 = add <8 x i16> %227, %237
  %239 = sub <8 x i16> %162, %176
  %240 = sub <8 x i16> zeroinitializer, %239
  %241 = icmp slt <8 x i16> %239, zeroinitializer
  %242 = select <8 x i1> %241, <8 x i16> %240, <8 x i16> %239
  %243 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %242, <8 x i16> %57) #6
  %244 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %243) #6
  %245 = icmp slt <8 x i16> %244, %242
  %246 = select <8 x i1> %245, <8 x i16> %244, <8 x i16> %242
  %247 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %246, <8 x i16> %239) #6
  %248 = add <8 x i16> %238, %247
  %249 = sub <8 x i16> %175, %176
  %250 = sub <8 x i16> zeroinitializer, %249
  %251 = icmp slt <8 x i16> %249, zeroinitializer
  %252 = select <8 x i1> %251, <8 x i16> %250, <8 x i16> %249
  %253 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %252, <8 x i16> %57) #6
  %254 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %253) #6
  %255 = icmp slt <8 x i16> %254, %252
  %256 = select <8 x i1> %255, <8 x i16> %254, <8 x i16> %252
  %257 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %256, <8 x i16> %249) #6
  %258 = add <8 x i16> %248, %257
  %259 = ashr <8 x i16> %258, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %260 = add <8 x i16> %258, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %261 = add <8 x i16> %260, %259
  %262 = ashr <8 x i16> %261, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %263 = add <8 x i16> %262, %176
  %264 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %263, <8 x i16> %263) #6
  %265 = getelementptr inbounds i16, i16* %62, i64 %58
  %266 = bitcast <16 x i8> %264 to <4 x i32>
  %267 = extractelement <4 x i32> %266, i32 0
  %268 = bitcast i8* %61 to i32*
  store i32 %267, i32* %268, align 1
  %269 = getelementptr inbounds i8, i8* %61, i64 %8
  %270 = shufflevector <16 x i8> %264, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %271 = bitcast <16 x i8> %270 to <4 x i32>
  %272 = extractelement <4 x i32> %271, i32 0
  %273 = bitcast i8* %269 to i32*
  store i32 %272, i32* %273, align 1
  %274 = getelementptr inbounds i8, i8* %269, i64 %8
  %275 = add nsw i32 %60, -2
  %276 = icmp eq i32 %275, 0
  br i1 %276, label %277, label %59

277:                                              ; preds = %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi8ELb1ELb1EEEvPKtliiiiiPvl(i16* nocapture readonly, i64, i32, i32, i32, i32, i32, i8* nocapture, i64) #3 {
  %10 = tail call i32 @llvm.ctlz.i32(i32 %3, i1 true) #6, !range !2
  %11 = xor i32 %10, 31
  %12 = sub nsw i32 %5, %11
  %13 = icmp sgt i32 %12, 0
  %14 = select i1 %13, i32 %12, i32 0
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %14, i32 0
  %16 = tail call i32 @llvm.ctlz.i32(i32 %4, i1 true) #6, !range !2
  %17 = xor i32 %16, 31
  %18 = sub nsw i32 %5, %17
  %19 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %18, i32 0
  %20 = and i32 %3, 1
  %21 = zext i32 %20 to i64
  %22 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* @_ZN7libgav116kCdefPrimaryTapsE, i64 0, i64 %21, i64 0
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i16
  %25 = insertelement <8 x i16> undef, i16 %24, i32 0
  %26 = shufflevector <8 x i16> %25, <8 x i16> undef, <8 x i32> zeroinitializer
  %27 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* @_ZN7libgav116kCdefPrimaryTapsE, i64 0, i64 %21, i64 1
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i16
  %30 = insertelement <8 x i16> undef, i16 %29, i32 0
  %31 = shufflevector <8 x i16> %30, <8 x i16> undef, <8 x i32> zeroinitializer
  %32 = trunc i32 %3 to i16
  %33 = insertelement <8 x i16> undef, i16 %32, i32 0
  %34 = shufflevector <8 x i16> %33, <8 x i16> undef, <8 x i32> zeroinitializer
  %35 = trunc i32 %4 to i16
  %36 = insertelement <8 x i16> undef, i16 %35, i32 0
  %37 = shufflevector <8 x i16> %36, <8 x i16> undef, <8 x i32> zeroinitializer
  %38 = sext i32 %6 to i64
  %39 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 0, i64 0
  %40 = load i8, i8* %39, align 4
  %41 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 0, i64 1
  %42 = load i8, i8* %41, align 1
  %43 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 1, i64 0
  %44 = load i8, i8* %43, align 2
  %45 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 1, i64 1
  %46 = load i8, i8* %45, align 1
  %47 = sext i8 %40 to i64
  %48 = mul nsw i64 %47, %1
  %49 = sub i64 0, %48
  %50 = sext i8 %42 to i64
  %51 = sub nsw i64 0, %50
  %52 = sext i8 %44 to i64
  %53 = mul nsw i64 %52, %1
  %54 = sub i64 0, %53
  %55 = sext i8 %46 to i64
  %56 = sub nsw i64 0, %55
  %57 = bitcast <4 x i32> %15 to <8 x i16>
  %58 = add nsw i32 %6, 2
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %59, i64 0, i64 0
  %61 = load i8, i8* %60, align 4
  %62 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %59, i64 0, i64 1
  %63 = load i8, i8* %62, align 1
  %64 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %59, i64 1, i64 0
  %65 = load i8, i8* %64, align 2
  %66 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %59, i64 1, i64 1
  %67 = load i8, i8* %66, align 1
  %68 = sext i8 %61 to i64
  %69 = mul nsw i64 %68, %1
  %70 = sub i64 0, %69
  %71 = sext i8 %63 to i64
  %72 = sub nsw i64 0, %71
  %73 = sext i8 %65 to i64
  %74 = mul nsw i64 %73, %1
  %75 = sub i64 0, %74
  %76 = sext i8 %67 to i64
  %77 = sub nsw i64 0, %76
  %78 = add nsw i32 %6, -2
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %79, i64 0, i64 0
  %81 = load i8, i8* %80, align 4
  %82 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %79, i64 0, i64 1
  %83 = load i8, i8* %82, align 1
  %84 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %79, i64 1, i64 0
  %85 = load i8, i8* %84, align 2
  %86 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %79, i64 1, i64 1
  %87 = load i8, i8* %86, align 1
  %88 = sext i8 %81 to i64
  %89 = mul nsw i64 %88, %1
  %90 = sub i64 0, %89
  %91 = sext i8 %83 to i64
  %92 = sub nsw i64 0, %91
  %93 = sext i8 %85 to i64
  %94 = mul nsw i64 %93, %1
  %95 = sub i64 0, %94
  %96 = sext i8 %87 to i64
  %97 = sub nsw i64 0, %96
  %98 = bitcast <4 x i32> %19 to <8 x i16>
  br label %99

99:                                               ; preds = %99, %9
  %100 = phi i32 [ %2, %9 ], [ %369, %99 ]
  %101 = phi i8* [ %7, %9 ], [ %368, %99 ]
  %102 = phi i16* [ %0, %9 ], [ %365, %99 ]
  %103 = bitcast i16* %102 to <8 x i16>*
  %104 = load <8 x i16>, <8 x i16>* %103, align 1
  %105 = getelementptr inbounds i16, i16* %102, i64 %49
  %106 = getelementptr inbounds i16, i16* %105, i64 %51
  %107 = bitcast i16* %106 to <2 x i64>*
  %108 = load <2 x i64>, <2 x i64>* %107, align 1
  %109 = getelementptr inbounds i16, i16* %102, i64 %48
  %110 = getelementptr inbounds i16, i16* %109, i64 %50
  %111 = bitcast i16* %110 to <2 x i64>*
  %112 = load <2 x i64>, <2 x i64>* %111, align 1
  %113 = getelementptr inbounds i16, i16* %102, i64 %54
  %114 = getelementptr inbounds i16, i16* %113, i64 %56
  %115 = bitcast i16* %114 to <2 x i64>*
  %116 = load <2 x i64>, <2 x i64>* %115, align 1
  %117 = getelementptr inbounds i16, i16* %102, i64 %53
  %118 = getelementptr inbounds i16, i16* %117, i64 %55
  %119 = bitcast i16* %118 to <2 x i64>*
  %120 = load <2 x i64>, <2 x i64>* %119, align 1
  %121 = bitcast <2 x i64> %108 to <8 x i16>
  %122 = icmp ult <8 x i16> %104, %121
  %123 = select <8 x i1> %122, <8 x i16> %104, <8 x i16> %121
  %124 = bitcast <2 x i64> %112 to <8 x i16>
  %125 = icmp ult <8 x i16> %123, %124
  %126 = select <8 x i1> %125, <8 x i16> %123, <8 x i16> %124
  %127 = bitcast <2 x i64> %116 to <8 x i16>
  %128 = icmp ult <8 x i16> %126, %127
  %129 = select <8 x i1> %128, <8 x i16> %126, <8 x i16> %127
  %130 = bitcast <2 x i64> %120 to <8 x i16>
  %131 = icmp ult <8 x i16> %129, %130
  %132 = select <8 x i1> %131, <8 x i16> %129, <8 x i16> %130
  %133 = bitcast <2 x i64> %108 to <16 x i8>
  %134 = bitcast <2 x i64> %112 to <16 x i8>
  %135 = icmp ugt <16 x i8> %133, %134
  %136 = select <16 x i1> %135, <16 x i8> %133, <16 x i8> %134
  %137 = bitcast <2 x i64> %116 to <16 x i8>
  %138 = bitcast <2 x i64> %120 to <16 x i8>
  %139 = icmp ugt <16 x i8> %137, %138
  %140 = select <16 x i1> %139, <16 x i8> %137, <16 x i8> %138
  %141 = icmp ugt <16 x i8> %136, %140
  %142 = select <16 x i1> %141, <16 x i8> %136, <16 x i8> %140
  %143 = bitcast <16 x i8> %142 to <8 x i16>
  %144 = and <8 x i16> %143, <i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385>
  %145 = icmp ugt <8 x i16> %104, %144
  %146 = select <8 x i1> %145, <8 x i16> %104, <8 x i16> %144
  %147 = sub <8 x i16> %121, %104
  %148 = sub <8 x i16> zeroinitializer, %147
  %149 = icmp slt <8 x i16> %147, zeroinitializer
  %150 = select <8 x i1> %149, <8 x i16> %148, <8 x i16> %147
  %151 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %150, <8 x i16> %57) #6
  %152 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %34, <8 x i16> %151) #6
  %153 = icmp slt <8 x i16> %152, %150
  %154 = select <8 x i1> %153, <8 x i16> %152, <8 x i16> %150
  %155 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %154, <8 x i16> %147) #6
  %156 = sub <8 x i16> %124, %104
  %157 = sub <8 x i16> zeroinitializer, %156
  %158 = icmp slt <8 x i16> %156, zeroinitializer
  %159 = select <8 x i1> %158, <8 x i16> %157, <8 x i16> %156
  %160 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %159, <8 x i16> %57) #6
  %161 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %34, <8 x i16> %160) #6
  %162 = icmp slt <8 x i16> %161, %159
  %163 = select <8 x i1> %162, <8 x i16> %161, <8 x i16> %159
  %164 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %163, <8 x i16> %156) #6
  %165 = add <8 x i16> %164, %155
  %166 = mul <8 x i16> %165, %26
  %167 = sub <8 x i16> %127, %104
  %168 = sub <8 x i16> zeroinitializer, %167
  %169 = icmp slt <8 x i16> %167, zeroinitializer
  %170 = select <8 x i1> %169, <8 x i16> %168, <8 x i16> %167
  %171 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %170, <8 x i16> %57) #6
  %172 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %34, <8 x i16> %171) #6
  %173 = icmp slt <8 x i16> %172, %170
  %174 = select <8 x i1> %173, <8 x i16> %172, <8 x i16> %170
  %175 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %174, <8 x i16> %167) #6
  %176 = sub <8 x i16> %130, %104
  %177 = sub <8 x i16> zeroinitializer, %176
  %178 = icmp slt <8 x i16> %176, zeroinitializer
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %176
  %180 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %179, <8 x i16> %57) #6
  %181 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %34, <8 x i16> %180) #6
  %182 = icmp slt <8 x i16> %181, %179
  %183 = select <8 x i1> %182, <8 x i16> %181, <8 x i16> %179
  %184 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %183, <8 x i16> %176) #6
  %185 = getelementptr inbounds i16, i16* %102, i64 %70
  %186 = getelementptr inbounds i16, i16* %185, i64 %72
  %187 = bitcast i16* %186 to <2 x i64>*
  %188 = load <2 x i64>, <2 x i64>* %187, align 1
  %189 = getelementptr inbounds i16, i16* %102, i64 %69
  %190 = getelementptr inbounds i16, i16* %189, i64 %71
  %191 = bitcast i16* %190 to <2 x i64>*
  %192 = load <2 x i64>, <2 x i64>* %191, align 1
  %193 = getelementptr inbounds i16, i16* %102, i64 %75
  %194 = getelementptr inbounds i16, i16* %193, i64 %77
  %195 = bitcast i16* %194 to <2 x i64>*
  %196 = load <2 x i64>, <2 x i64>* %195, align 1
  %197 = getelementptr inbounds i16, i16* %102, i64 %74
  %198 = getelementptr inbounds i16, i16* %197, i64 %76
  %199 = bitcast i16* %198 to <2 x i64>*
  %200 = load <2 x i64>, <2 x i64>* %199, align 1
  %201 = getelementptr inbounds i16, i16* %102, i64 %90
  %202 = getelementptr inbounds i16, i16* %201, i64 %92
  %203 = bitcast i16* %202 to <2 x i64>*
  %204 = load <2 x i64>, <2 x i64>* %203, align 1
  %205 = getelementptr inbounds i16, i16* %102, i64 %89
  %206 = getelementptr inbounds i16, i16* %205, i64 %91
  %207 = bitcast i16* %206 to <2 x i64>*
  %208 = load <2 x i64>, <2 x i64>* %207, align 1
  %209 = getelementptr inbounds i16, i16* %102, i64 %95
  %210 = getelementptr inbounds i16, i16* %209, i64 %97
  %211 = bitcast i16* %210 to <2 x i64>*
  %212 = load <2 x i64>, <2 x i64>* %211, align 1
  %213 = getelementptr inbounds i16, i16* %102, i64 %94
  %214 = getelementptr inbounds i16, i16* %213, i64 %96
  %215 = bitcast i16* %214 to <2 x i64>*
  %216 = load <2 x i64>, <2 x i64>* %215, align 1
  %217 = bitcast <2 x i64> %188 to <8 x i16>
  %218 = icmp ult <8 x i16> %132, %217
  %219 = select <8 x i1> %218, <8 x i16> %132, <8 x i16> %217
  %220 = bitcast <2 x i64> %192 to <8 x i16>
  %221 = icmp ult <8 x i16> %219, %220
  %222 = select <8 x i1> %221, <8 x i16> %219, <8 x i16> %220
  %223 = bitcast <2 x i64> %196 to <8 x i16>
  %224 = icmp ult <8 x i16> %222, %223
  %225 = select <8 x i1> %224, <8 x i16> %222, <8 x i16> %223
  %226 = bitcast <2 x i64> %200 to <8 x i16>
  %227 = icmp ult <8 x i16> %225, %226
  %228 = select <8 x i1> %227, <8 x i16> %225, <8 x i16> %226
  %229 = bitcast <2 x i64> %204 to <8 x i16>
  %230 = icmp ult <8 x i16> %228, %229
  %231 = select <8 x i1> %230, <8 x i16> %228, <8 x i16> %229
  %232 = bitcast <2 x i64> %208 to <8 x i16>
  %233 = icmp ult <8 x i16> %231, %232
  %234 = select <8 x i1> %233, <8 x i16> %231, <8 x i16> %232
  %235 = bitcast <2 x i64> %212 to <8 x i16>
  %236 = icmp ult <8 x i16> %234, %235
  %237 = select <8 x i1> %236, <8 x i16> %234, <8 x i16> %235
  %238 = bitcast <2 x i64> %216 to <8 x i16>
  %239 = icmp ult <8 x i16> %237, %238
  %240 = select <8 x i1> %239, <8 x i16> %237, <8 x i16> %238
  %241 = bitcast <2 x i64> %188 to <16 x i8>
  %242 = bitcast <2 x i64> %192 to <16 x i8>
  %243 = icmp ugt <16 x i8> %241, %242
  %244 = select <16 x i1> %243, <16 x i8> %241, <16 x i8> %242
  %245 = bitcast <2 x i64> %196 to <16 x i8>
  %246 = bitcast <2 x i64> %200 to <16 x i8>
  %247 = icmp ugt <16 x i8> %245, %246
  %248 = select <16 x i1> %247, <16 x i8> %245, <16 x i8> %246
  %249 = bitcast <2 x i64> %204 to <16 x i8>
  %250 = bitcast <2 x i64> %208 to <16 x i8>
  %251 = icmp ugt <16 x i8> %249, %250
  %252 = select <16 x i1> %251, <16 x i8> %249, <16 x i8> %250
  %253 = bitcast <2 x i64> %212 to <16 x i8>
  %254 = bitcast <2 x i64> %216 to <16 x i8>
  %255 = icmp ugt <16 x i8> %253, %254
  %256 = select <16 x i1> %255, <16 x i8> %253, <16 x i8> %254
  %257 = icmp ugt <16 x i8> %244, %248
  %258 = select <16 x i1> %257, <16 x i8> %244, <16 x i8> %248
  %259 = icmp ugt <16 x i8> %252, %256
  %260 = select <16 x i1> %259, <16 x i8> %252, <16 x i8> %256
  %261 = icmp ugt <16 x i8> %258, %260
  %262 = select <16 x i1> %261, <16 x i8> %258, <16 x i8> %260
  %263 = bitcast <16 x i8> %262 to <8 x i16>
  %264 = and <8 x i16> %263, <i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385, i16 -16385>
  %265 = icmp ugt <8 x i16> %146, %264
  %266 = select <8 x i1> %265, <8 x i16> %146, <8 x i16> %264
  %267 = sub <8 x i16> %217, %104
  %268 = sub <8 x i16> zeroinitializer, %267
  %269 = icmp slt <8 x i16> %267, zeroinitializer
  %270 = select <8 x i1> %269, <8 x i16> %268, <8 x i16> %267
  %271 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %270, <8 x i16> %98) #6
  %272 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %271) #6
  %273 = icmp slt <8 x i16> %272, %270
  %274 = select <8 x i1> %273, <8 x i16> %272, <8 x i16> %270
  %275 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %274, <8 x i16> %267) #6
  %276 = shl <8 x i16> %275, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %277 = sub <8 x i16> %220, %104
  %278 = sub <8 x i16> zeroinitializer, %277
  %279 = icmp slt <8 x i16> %277, zeroinitializer
  %280 = select <8 x i1> %279, <8 x i16> %278, <8 x i16> %277
  %281 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %280, <8 x i16> %98) #6
  %282 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %281) #6
  %283 = icmp slt <8 x i16> %282, %280
  %284 = select <8 x i1> %283, <8 x i16> %282, <8 x i16> %280
  %285 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %284, <8 x i16> %277) #6
  %286 = shl <8 x i16> %285, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %287 = sub <8 x i16> %223, %104
  %288 = sub <8 x i16> zeroinitializer, %287
  %289 = icmp slt <8 x i16> %287, zeroinitializer
  %290 = select <8 x i1> %289, <8 x i16> %288, <8 x i16> %287
  %291 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %290, <8 x i16> %98) #6
  %292 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %291) #6
  %293 = icmp slt <8 x i16> %292, %290
  %294 = select <8 x i1> %293, <8 x i16> %292, <8 x i16> %290
  %295 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %294, <8 x i16> %287) #6
  %296 = sub <8 x i16> %226, %104
  %297 = sub <8 x i16> zeroinitializer, %296
  %298 = icmp slt <8 x i16> %296, zeroinitializer
  %299 = select <8 x i1> %298, <8 x i16> %297, <8 x i16> %296
  %300 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %299, <8 x i16> %98) #6
  %301 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %300) #6
  %302 = icmp slt <8 x i16> %301, %299
  %303 = select <8 x i1> %302, <8 x i16> %301, <8 x i16> %299
  %304 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %303, <8 x i16> %296) #6
  %305 = sub <8 x i16> %229, %104
  %306 = sub <8 x i16> zeroinitializer, %305
  %307 = icmp slt <8 x i16> %305, zeroinitializer
  %308 = select <8 x i1> %307, <8 x i16> %306, <8 x i16> %305
  %309 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %308, <8 x i16> %98) #6
  %310 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %309) #6
  %311 = icmp slt <8 x i16> %310, %308
  %312 = select <8 x i1> %311, <8 x i16> %310, <8 x i16> %308
  %313 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %312, <8 x i16> %305) #6
  %314 = shl <8 x i16> %313, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %315 = sub <8 x i16> %232, %104
  %316 = sub <8 x i16> zeroinitializer, %315
  %317 = icmp slt <8 x i16> %315, zeroinitializer
  %318 = select <8 x i1> %317, <8 x i16> %316, <8 x i16> %315
  %319 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %318, <8 x i16> %98) #6
  %320 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %319) #6
  %321 = icmp slt <8 x i16> %320, %318
  %322 = select <8 x i1> %321, <8 x i16> %320, <8 x i16> %318
  %323 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %322, <8 x i16> %315) #6
  %324 = shl <8 x i16> %323, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %325 = sub <8 x i16> %235, %104
  %326 = sub <8 x i16> zeroinitializer, %325
  %327 = icmp slt <8 x i16> %325, zeroinitializer
  %328 = select <8 x i1> %327, <8 x i16> %326, <8 x i16> %325
  %329 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %328, <8 x i16> %98) #6
  %330 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %329) #6
  %331 = icmp slt <8 x i16> %330, %328
  %332 = select <8 x i1> %331, <8 x i16> %330, <8 x i16> %328
  %333 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %332, <8 x i16> %325) #6
  %334 = sub <8 x i16> %238, %104
  %335 = sub <8 x i16> zeroinitializer, %334
  %336 = icmp slt <8 x i16> %334, zeroinitializer
  %337 = select <8 x i1> %336, <8 x i16> %335, <8 x i16> %334
  %338 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %337, <8 x i16> %98) #6
  %339 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %37, <8 x i16> %338) #6
  %340 = icmp slt <8 x i16> %339, %337
  %341 = select <8 x i1> %340, <8 x i16> %339, <8 x i16> %337
  %342 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %341, <8 x i16> %334) #6
  %343 = add <8 x i16> %184, %175
  %344 = mul <8 x i16> %343, %31
  %345 = add <8 x i16> %344, %166
  %346 = add <8 x i16> %345, %276
  %347 = add <8 x i16> %346, %286
  %348 = add <8 x i16> %347, %295
  %349 = add <8 x i16> %348, %304
  %350 = add <8 x i16> %349, %314
  %351 = add <8 x i16> %350, %324
  %352 = add <8 x i16> %351, %333
  %353 = add <8 x i16> %352, %342
  %354 = ashr <8 x i16> %353, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %355 = add <8 x i16> %353, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %356 = add <8 x i16> %355, %354
  %357 = ashr <8 x i16> %356, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %358 = add <8 x i16> %357, %104
  %359 = icmp slt <8 x i16> %358, %266
  %360 = select <8 x i1> %359, <8 x i16> %358, <8 x i16> %266
  %361 = icmp sgt <8 x i16> %360, %240
  %362 = select <8 x i1> %361, <8 x i16> %360, <8 x i16> %240
  %363 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %362, <8 x i16> undef) #6
  %364 = bitcast <16 x i8> %363 to <2 x i64>
  %365 = getelementptr inbounds i16, i16* %102, i64 %1
  %366 = extractelement <2 x i64> %364, i32 0
  %367 = bitcast i8* %101 to i64*
  store i64 %366, i64* %367, align 1
  %368 = getelementptr inbounds i8, i8* %101, i64 %8
  %369 = add nsw i32 %100, -1
  %370 = icmp eq i32 %369, 0
  br i1 %370, label %371, label %99

371:                                              ; preds = %99
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi8ELb1ELb0EEEvPKtliiiiiPvl(i16* nocapture readonly, i64, i32, i32, i32, i32, i32, i8* nocapture, i64) #3 {
  %10 = tail call i32 @llvm.ctlz.i32(i32 %3, i1 true) #6, !range !2
  %11 = xor i32 %10, 31
  %12 = sub nsw i32 %5, %11
  %13 = icmp sgt i32 %12, 0
  %14 = select i1 %13, i32 %12, i32 0
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %14, i32 0
  %16 = and i32 %3, 1
  %17 = zext i32 %16 to i64
  %18 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* @_ZN7libgav116kCdefPrimaryTapsE, i64 0, i64 %17, i64 0
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> zeroinitializer
  %23 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* @_ZN7libgav116kCdefPrimaryTapsE, i64 0, i64 %17, i64 1
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i16
  %26 = insertelement <8 x i16> undef, i16 %25, i32 0
  %27 = shufflevector <8 x i16> %26, <8 x i16> undef, <8 x i32> zeroinitializer
  %28 = trunc i32 %3 to i16
  %29 = insertelement <8 x i16> undef, i16 %28, i32 0
  %30 = shufflevector <8 x i16> %29, <8 x i16> undef, <8 x i32> zeroinitializer
  %31 = sext i32 %6 to i64
  %32 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %31, i64 0, i64 0
  %33 = load i8, i8* %32, align 4
  %34 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %31, i64 0, i64 1
  %35 = load i8, i8* %34, align 1
  %36 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %31, i64 1, i64 0
  %37 = load i8, i8* %36, align 2
  %38 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %31, i64 1, i64 1
  %39 = load i8, i8* %38, align 1
  %40 = sext i8 %33 to i64
  %41 = mul nsw i64 %40, %1
  %42 = sub i64 0, %41
  %43 = sext i8 %35 to i64
  %44 = sub nsw i64 0, %43
  %45 = sext i8 %37 to i64
  %46 = mul nsw i64 %45, %1
  %47 = sub i64 0, %46
  %48 = sext i8 %39 to i64
  %49 = sub nsw i64 0, %48
  %50 = bitcast <4 x i32> %15 to <8 x i16>
  br label %51

51:                                               ; preds = %51, %9
  %52 = phi i32 [ %2, %9 ], [ %125, %51 ]
  %53 = phi i8* [ %7, %9 ], [ %124, %51 ]
  %54 = phi i16* [ %0, %9 ], [ %121, %51 ]
  %55 = bitcast i16* %54 to <8 x i16>*
  %56 = load <8 x i16>, <8 x i16>* %55, align 1
  %57 = getelementptr inbounds i16, i16* %54, i64 %42
  %58 = getelementptr inbounds i16, i16* %57, i64 %44
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 1
  %61 = getelementptr inbounds i16, i16* %54, i64 %41
  %62 = getelementptr inbounds i16, i16* %61, i64 %43
  %63 = bitcast i16* %62 to <8 x i16>*
  %64 = load <8 x i16>, <8 x i16>* %63, align 1
  %65 = getelementptr inbounds i16, i16* %54, i64 %47
  %66 = getelementptr inbounds i16, i16* %65, i64 %49
  %67 = bitcast i16* %66 to <8 x i16>*
  %68 = load <8 x i16>, <8 x i16>* %67, align 1
  %69 = getelementptr inbounds i16, i16* %54, i64 %46
  %70 = getelementptr inbounds i16, i16* %69, i64 %48
  %71 = bitcast i16* %70 to <8 x i16>*
  %72 = load <8 x i16>, <8 x i16>* %71, align 1
  %73 = sub <8 x i16> %60, %56
  %74 = sub <8 x i16> zeroinitializer, %73
  %75 = icmp slt <8 x i16> %73, zeroinitializer
  %76 = select <8 x i1> %75, <8 x i16> %74, <8 x i16> %73
  %77 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %76, <8 x i16> %50) #6
  %78 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %30, <8 x i16> %77) #6
  %79 = icmp slt <8 x i16> %78, %76
  %80 = select <8 x i1> %79, <8 x i16> %78, <8 x i16> %76
  %81 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %80, <8 x i16> %73) #6
  %82 = sub <8 x i16> %64, %56
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %85, <8 x i16> %50) #6
  %87 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %30, <8 x i16> %86) #6
  %88 = icmp slt <8 x i16> %87, %85
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> %85
  %90 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %89, <8 x i16> %82) #6
  %91 = add <8 x i16> %90, %81
  %92 = mul <8 x i16> %91, %22
  %93 = sub <8 x i16> %68, %56
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %96, <8 x i16> %50) #6
  %98 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %30, <8 x i16> %97) #6
  %99 = icmp slt <8 x i16> %98, %96
  %100 = select <8 x i1> %99, <8 x i16> %98, <8 x i16> %96
  %101 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %100, <8 x i16> %93) #6
  %102 = sub <8 x i16> %72, %56
  %103 = sub <8 x i16> zeroinitializer, %102
  %104 = icmp slt <8 x i16> %102, zeroinitializer
  %105 = select <8 x i1> %104, <8 x i16> %103, <8 x i16> %102
  %106 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %105, <8 x i16> %50) #6
  %107 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %30, <8 x i16> %106) #6
  %108 = icmp slt <8 x i16> %107, %105
  %109 = select <8 x i1> %108, <8 x i16> %107, <8 x i16> %105
  %110 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %109, <8 x i16> %102) #6
  %111 = add <8 x i16> %110, %101
  %112 = mul <8 x i16> %111, %27
  %113 = add <8 x i16> %112, %92
  %114 = ashr <8 x i16> %113, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %115 = add <8 x i16> %113, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %116 = add <8 x i16> %115, %114
  %117 = ashr <8 x i16> %116, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %118 = add <8 x i16> %117, %56
  %119 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> undef) #6
  %120 = bitcast <16 x i8> %119 to <2 x i64>
  %121 = getelementptr inbounds i16, i16* %54, i64 %1
  %122 = extractelement <2 x i64> %120, i32 0
  %123 = bitcast i8* %53 to i64*
  store i64 %122, i64* %123, align 1
  %124 = getelementptr inbounds i8, i8* %53, i64 %8
  %125 = add nsw i32 %52, -1
  %126 = icmp eq i32 %125, 0
  br i1 %126, label %127, label %51

127:                                              ; preds = %51
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117CdefFilter_SSE4_1ILi8ELb0ELb1EEEvPKtliiiiiPvl(i16* nocapture readonly, i64, i32, i32, i32, i32, i32, i8* nocapture, i64) #3 {
  %10 = tail call i32 @llvm.ctlz.i32(i32 %4, i1 true) #6, !range !2
  %11 = xor i32 %10, 31
  %12 = sub nsw i32 %5, %11
  %13 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %12, i32 0
  %14 = trunc i32 %4 to i16
  %15 = insertelement <8 x i16> undef, i16 %14, i32 0
  %16 = shufflevector <8 x i16> %15, <8 x i16> undef, <8 x i32> zeroinitializer
  %17 = add nsw i32 %6, 2
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %18, i64 0, i64 0
  %20 = load i8, i8* %19, align 4
  %21 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %18, i64 0, i64 1
  %22 = load i8, i8* %21, align 1
  %23 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %18, i64 1, i64 0
  %24 = load i8, i8* %23, align 2
  %25 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %18, i64 1, i64 1
  %26 = load i8, i8* %25, align 1
  %27 = sext i8 %20 to i64
  %28 = mul nsw i64 %27, %1
  %29 = sub i64 0, %28
  %30 = sext i8 %22 to i64
  %31 = sub nsw i64 0, %30
  %32 = sext i8 %24 to i64
  %33 = mul nsw i64 %32, %1
  %34 = sub i64 0, %33
  %35 = sext i8 %26 to i64
  %36 = sub nsw i64 0, %35
  %37 = add nsw i32 %6, -2
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 0, i64 0
  %40 = load i8, i8* %39, align 4
  %41 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 0, i64 1
  %42 = load i8, i8* %41, align 1
  %43 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 1, i64 0
  %44 = load i8, i8* %43, align 2
  %45 = getelementptr inbounds [2 x [2 x i8]], [2 x [2 x i8]]* bitcast (i8* getelementptr inbounds ([12 x [2 x [2 x i8]]], [12 x [2 x [2 x i8]]]* @_ZN7libgav121kCdefDirectionsPaddedE, i64 0, i64 2, i64 0, i64 0) to [2 x [2 x i8]]*), i64 %38, i64 1, i64 1
  %46 = load i8, i8* %45, align 1
  %47 = sext i8 %40 to i64
  %48 = mul nsw i64 %47, %1
  %49 = sub i64 0, %48
  %50 = sext i8 %42 to i64
  %51 = sub nsw i64 0, %50
  %52 = sext i8 %44 to i64
  %53 = mul nsw i64 %52, %1
  %54 = sub i64 0, %53
  %55 = sext i8 %46 to i64
  %56 = sub nsw i64 0, %55
  %57 = bitcast <4 x i32> %13 to <8 x i16>
  br label %58

58:                                               ; preds = %58, %9
  %59 = phi i32 [ %2, %9 ], [ %189, %58 ]
  %60 = phi i8* [ %7, %9 ], [ %188, %58 ]
  %61 = phi i16* [ %0, %9 ], [ %185, %58 ]
  %62 = bitcast i16* %61 to <8 x i16>*
  %63 = load <8 x i16>, <8 x i16>* %62, align 1
  %64 = getelementptr inbounds i16, i16* %61, i64 %29
  %65 = getelementptr inbounds i16, i16* %64, i64 %31
  %66 = bitcast i16* %65 to <8 x i16>*
  %67 = load <8 x i16>, <8 x i16>* %66, align 1
  %68 = getelementptr inbounds i16, i16* %61, i64 %28
  %69 = getelementptr inbounds i16, i16* %68, i64 %30
  %70 = bitcast i16* %69 to <8 x i16>*
  %71 = load <8 x i16>, <8 x i16>* %70, align 1
  %72 = getelementptr inbounds i16, i16* %61, i64 %34
  %73 = getelementptr inbounds i16, i16* %72, i64 %36
  %74 = bitcast i16* %73 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 1
  %76 = getelementptr inbounds i16, i16* %61, i64 %33
  %77 = getelementptr inbounds i16, i16* %76, i64 %35
  %78 = bitcast i16* %77 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 1
  %80 = getelementptr inbounds i16, i16* %61, i64 %49
  %81 = getelementptr inbounds i16, i16* %80, i64 %51
  %82 = bitcast i16* %81 to <8 x i16>*
  %83 = load <8 x i16>, <8 x i16>* %82, align 1
  %84 = getelementptr inbounds i16, i16* %61, i64 %48
  %85 = getelementptr inbounds i16, i16* %84, i64 %50
  %86 = bitcast i16* %85 to <8 x i16>*
  %87 = load <8 x i16>, <8 x i16>* %86, align 1
  %88 = getelementptr inbounds i16, i16* %61, i64 %54
  %89 = getelementptr inbounds i16, i16* %88, i64 %56
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 1
  %92 = getelementptr inbounds i16, i16* %61, i64 %53
  %93 = getelementptr inbounds i16, i16* %92, i64 %55
  %94 = bitcast i16* %93 to <8 x i16>*
  %95 = load <8 x i16>, <8 x i16>* %94, align 1
  %96 = sub <8 x i16> %67, %63
  %97 = sub <8 x i16> zeroinitializer, %96
  %98 = icmp slt <8 x i16> %96, zeroinitializer
  %99 = select <8 x i1> %98, <8 x i16> %97, <8 x i16> %96
  %100 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %99, <8 x i16> %57) #6
  %101 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %100) #6
  %102 = icmp slt <8 x i16> %101, %99
  %103 = select <8 x i1> %102, <8 x i16> %101, <8 x i16> %99
  %104 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %103, <8 x i16> %96) #6
  %105 = sub <8 x i16> %71, %63
  %106 = sub <8 x i16> zeroinitializer, %105
  %107 = icmp slt <8 x i16> %105, zeroinitializer
  %108 = select <8 x i1> %107, <8 x i16> %106, <8 x i16> %105
  %109 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %108, <8 x i16> %57) #6
  %110 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %109) #6
  %111 = icmp slt <8 x i16> %110, %108
  %112 = select <8 x i1> %111, <8 x i16> %110, <8 x i16> %108
  %113 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %112, <8 x i16> %105) #6
  %114 = add <8 x i16> %113, %104
  %115 = shl <8 x i16> %114, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %116 = sub <8 x i16> %75, %63
  %117 = sub <8 x i16> zeroinitializer, %116
  %118 = icmp slt <8 x i16> %116, zeroinitializer
  %119 = select <8 x i1> %118, <8 x i16> %117, <8 x i16> %116
  %120 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %119, <8 x i16> %57) #6
  %121 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %120) #6
  %122 = icmp slt <8 x i16> %121, %119
  %123 = select <8 x i1> %122, <8 x i16> %121, <8 x i16> %119
  %124 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %123, <8 x i16> %116) #6
  %125 = add <8 x i16> %124, %115
  %126 = sub <8 x i16> %79, %63
  %127 = sub <8 x i16> zeroinitializer, %126
  %128 = icmp slt <8 x i16> %126, zeroinitializer
  %129 = select <8 x i1> %128, <8 x i16> %127, <8 x i16> %126
  %130 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %129, <8 x i16> %57) #6
  %131 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %130) #6
  %132 = icmp slt <8 x i16> %131, %129
  %133 = select <8 x i1> %132, <8 x i16> %131, <8 x i16> %129
  %134 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %133, <8 x i16> %126) #6
  %135 = add <8 x i16> %125, %134
  %136 = sub <8 x i16> %83, %63
  %137 = sub <8 x i16> zeroinitializer, %136
  %138 = icmp slt <8 x i16> %136, zeroinitializer
  %139 = select <8 x i1> %138, <8 x i16> %137, <8 x i16> %136
  %140 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %139, <8 x i16> %57) #6
  %141 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %140) #6
  %142 = icmp slt <8 x i16> %141, %139
  %143 = select <8 x i1> %142, <8 x i16> %141, <8 x i16> %139
  %144 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %143, <8 x i16> %136) #6
  %145 = shl <8 x i16> %144, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %146 = add <8 x i16> %135, %145
  %147 = sub <8 x i16> %87, %63
  %148 = sub <8 x i16> zeroinitializer, %147
  %149 = icmp slt <8 x i16> %147, zeroinitializer
  %150 = select <8 x i1> %149, <8 x i16> %148, <8 x i16> %147
  %151 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %150, <8 x i16> %57) #6
  %152 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %151) #6
  %153 = icmp slt <8 x i16> %152, %150
  %154 = select <8 x i1> %153, <8 x i16> %152, <8 x i16> %150
  %155 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %154, <8 x i16> %147) #6
  %156 = shl <8 x i16> %155, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %157 = add <8 x i16> %146, %156
  %158 = sub <8 x i16> %91, %63
  %159 = sub <8 x i16> zeroinitializer, %158
  %160 = icmp slt <8 x i16> %158, zeroinitializer
  %161 = select <8 x i1> %160, <8 x i16> %159, <8 x i16> %158
  %162 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %161, <8 x i16> %57) #6
  %163 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %162) #6
  %164 = icmp slt <8 x i16> %163, %161
  %165 = select <8 x i1> %164, <8 x i16> %163, <8 x i16> %161
  %166 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %165, <8 x i16> %158) #6
  %167 = add <8 x i16> %157, %166
  %168 = sub <8 x i16> %95, %63
  %169 = sub <8 x i16> zeroinitializer, %168
  %170 = icmp slt <8 x i16> %168, zeroinitializer
  %171 = select <8 x i1> %170, <8 x i16> %169, <8 x i16> %168
  %172 = tail call <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16> %171, <8 x i16> %57) #6
  %173 = tail call <8 x i16> @llvm.usub.sat.v8i16(<8 x i16> %16, <8 x i16> %172) #6
  %174 = icmp slt <8 x i16> %173, %171
  %175 = select <8 x i1> %174, <8 x i16> %173, <8 x i16> %171
  %176 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %175, <8 x i16> %168) #6
  %177 = add <8 x i16> %167, %176
  %178 = ashr <8 x i16> %177, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %179 = add <8 x i16> %177, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %180 = add <8 x i16> %179, %178
  %181 = ashr <8 x i16> %180, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %182 = add <8 x i16> %181, %63
  %183 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> undef) #6
  %184 = bitcast <16 x i8> %183 to <2 x i64>
  %185 = getelementptr inbounds i16, i16* %61, i64 %1
  %186 = extractelement <2 x i64> %184, i32 0
  %187 = bitcast i8* %60 to i64*
  store i64 %186, i64* %187, align 1
  %188 = getelementptr inbounds i8, i8* %60, i64 %8
  %189 = add nsw i32 %59, -1
  %190 = icmp eq i32 %189, 0
  br i1 %190, label %191, label %58

191:                                              ; preds = %58
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind readnone
declare <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32>, <4 x i32>) #4

; Function Attrs: nounwind readnone speculatable
declare i32 @llvm.ctlz.i32(i32, i1 immarg) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.psrl.w(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.usub.sat.v8i16(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #4

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind readnone speculatable }
attributes #6 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 0, i32 33}
