; ModuleID = '../../third_party/opus/src/silk/x86/NSQ_sse4_1.c'
source_filename = "../../third_party/opus/src/silk/x86/NSQ_sse4_1.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"
module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.silk_encoder_state = type { [2 x i32], i32, i32, %struct.silk_LP_state, %struct.silk_VAD_state, %struct.silk_nsq_state, [16 x i16], i32, i32, i8, i8, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, %struct.silk_NLSF_CB_struct*, [4 x i32], i32, i32, [3 x i8], i8, [3 x i32], %struct.SideInfoIndices, [320 x i8], i32, [322 x i16], i32, i32, i32, i32, i32, i32, i32, i32, i16, %struct._silk_resampler_state_struct, i32, i32, i32, i32, i32, i32, [3 x %struct.SideInfoIndices], [3 x [320 x i8]] }
%struct.silk_LP_state = type { [2 x i32], i32, i32, i32 }
%struct.silk_VAD_state = type { [2 x i32], [2 x i32], [2 x i32], [4 x i32], [4 x i32], i16, [4 x i32], [4 x i32], [4 x i32], i32 }
%struct.silk_nsq_state = type { [640 x i16], [640 x i32], [96 x i32], [24 x i32], i32, i32, i32, i32, i32, i32, i32, i32 }
%struct.silk_NLSF_CB_struct = type { i16, i16, i16, i16, i8*, i16*, i8*, i8*, i8*, i8*, i8*, i16* }
%struct.SideInfoIndices = type { [4 x i8], [4 x i8], [17 x i8], i16, i8, i8, i8, i8, i8, i8, i8 }
%struct._silk_resampler_state_struct = type { [6 x i32], %union.anon, [48 x i16], i32, i32, i32, i32, i32, i32, i32, i32, i16* }
%union.anon = type { [36 x i32] }

@silk_Quantization_Offsets_Q10 = external local_unnamed_addr constant [2 x [2 x i16]], align 2
@.str = private unnamed_addr constant [32 x i8] c"assertion failed: start_idx > 0\00", align 1
@.str.1 = private unnamed_addr constant [49 x i8] c"../../third_party/opus/src/silk/x86/NSQ_sse4_1.c\00", align 1

; Function Attrs: nounwind ssp uwtable
define hidden void @silk_NSQ_sse4_1(%struct.silk_encoder_state* nocapture readonly, %struct.silk_nsq_state*, %struct.SideInfoIndices* nocapture readonly, i32* nocapture readonly, i8*, i16*, i16*, i16*, i32* nocapture readonly, i32* nocapture readonly, i32* nocapture readonly, i32* nocapture readonly, i32* nocapture readonly, i32, i32) local_unnamed_addr #0 {
  %16 = alloca [64 x [4 x i32]], align 16
  %17 = bitcast [64 x [4 x i32]]* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %17) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %17, i8 -86, i64 1024, i1 false)
  %18 = getelementptr inbounds %struct.SideInfoIndices, %struct.SideInfoIndices* %2, i64 0, i32 10
  %19 = load i8, i8* %18, align 2
  %20 = sext i8 %19 to i32
  %21 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 9
  store i32 %20, i32* %21, align 4
  %22 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 6
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %struct.SideInfoIndices, %struct.SideInfoIndices* %2, i64 0, i32 5
  %25 = load i8, i8* %24, align 1
  %26 = ashr i8 %25, 1
  %27 = sext i8 %26 to i64
  %28 = getelementptr inbounds %struct.SideInfoIndices, %struct.SideInfoIndices* %2, i64 0, i32 6
  %29 = load i8, i8* %28, align 2
  %30 = sext i8 %29 to i64
  %31 = getelementptr inbounds [2 x [2 x i16]], [2 x [2 x i16]]* @silk_Quantization_Offsets_Q10, i64 0, i64 %27, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = sext i16 %32 to i32
  %34 = add nsw i32 %33, 944
  %35 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 32
  %36 = getelementptr inbounds [4 x i32], [4 x i32]* %35, i64 0, i64 0
  store i32 %33, i32* %36, align 16
  %37 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 32, i64 1
  store i32 %34, i32* %37, align 4
  %38 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 32, i64 2
  store i32 -1888, i32* %38, align 8
  %39 = mul i32 %13, -944
  %40 = mul nsw i32 %33, %33
  %41 = mul nsw i32 %34, %34
  %42 = add i32 %40, %39
  %43 = sub i32 %42, %41
  %44 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 32, i64 3
  store i32 %43, i32* %44, align 4
  %45 = add nsw i32 %33, -944
  %46 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 31, i64 0
  store i32 %45, i32* %46, align 16
  %47 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 31, i64 1
  store i32 %33, i32* %47, align 4
  %48 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 31, i64 2
  store i32 -1888, i32* %48, align 8
  %49 = mul nsw i32 %33, -2
  %50 = add nsw i32 %49, 944
  %51 = mul i32 %50, %13
  %52 = mul nsw i32 %45, %45
  %53 = sub nsw i32 %52, %40
  %54 = add nsw i32 %53, %51
  %55 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 31, i64 3
  store i32 %54, i32* %55, align 4
  %56 = mul i32 %13, -1024
  %57 = sext i16 %32 to i64
  %58 = insertelement <4 x i64> undef, i64 %57, i32 0
  %59 = shufflevector <4 x i64> %58, <4 x i64> undef, <4 x i32> zeroinitializer
  %60 = insertelement <4 x i32> undef, i32 %33, i32 0
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> zeroinitializer
  %62 = insertelement <4 x i32> undef, i32 %56, i32 0
  %63 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> zeroinitializer
  %64 = add nsw <4 x i64> %59, <i64 1024, i64 2048, i64 3072, i64 4096>
  %65 = add <4 x i32> %61, <i32 944, i32 1968, i32 2992, i32 4016>
  %66 = add <4 x i32> %61, <i32 1968, i32 2992, i32 4016, i32 5040>
  %67 = trunc <4 x i64> %64 to <4 x i32>
  %68 = add <4 x i32> %67, <i32 -80, i32 -80, i32 -80, i32 -80>
  %69 = trunc <4 x i64> %64 to <4 x i32>
  %70 = add <4 x i32> %69, <i32 944, i32 944, i32 944, i32 944>
  %71 = mul nsw <4 x i32> %65, %65
  %72 = mul nsw <4 x i32> %66, %66
  %73 = add <4 x i32> %71, %63
  %74 = sub <4 x i32> %73, %72
  %75 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 33, i64 0
  %76 = bitcast i32* %75 to <16 x i32>*
  %77 = shufflevector <4 x i32> %68, <4 x i32> %70, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %78 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %74, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %79 = shufflevector <8 x i32> %77, <8 x i32> %78, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %79, <16 x i32>* %76, align 16
  %80 = add nsw <4 x i64> %59, <i64 5120, i64 6144, i64 7168, i64 8192>
  %81 = add <4 x i32> %61, <i32 5040, i32 6064, i32 7088, i32 8112>
  %82 = add <4 x i32> %61, <i32 6064, i32 7088, i32 8112, i32 9136>
  %83 = trunc <4 x i64> %80 to <4 x i32>
  %84 = add <4 x i32> %83, <i32 -80, i32 -80, i32 -80, i32 -80>
  %85 = trunc <4 x i64> %80 to <4 x i32>
  %86 = add <4 x i32> %85, <i32 944, i32 944, i32 944, i32 944>
  %87 = mul nsw <4 x i32> %81, %81
  %88 = mul nsw <4 x i32> %82, %82
  %89 = add <4 x i32> %87, %63
  %90 = sub <4 x i32> %89, %88
  %91 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 37, i64 0
  %92 = bitcast i32* %91 to <16 x i32>*
  %93 = shufflevector <4 x i32> %84, <4 x i32> %86, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %94 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %90, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %95 = shufflevector <8 x i32> %93, <8 x i32> %94, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %95, <16 x i32>* %92, align 16
  %96 = add nsw <4 x i64> %59, <i64 9216, i64 10240, i64 11264, i64 12288>
  %97 = add <4 x i32> %61, <i32 9136, i32 10160, i32 11184, i32 12208>
  %98 = add <4 x i32> %61, <i32 10160, i32 11184, i32 12208, i32 13232>
  %99 = trunc <4 x i64> %96 to <4 x i32>
  %100 = add <4 x i32> %99, <i32 -80, i32 -80, i32 -80, i32 -80>
  %101 = trunc <4 x i64> %96 to <4 x i32>
  %102 = add <4 x i32> %101, <i32 944, i32 944, i32 944, i32 944>
  %103 = mul nsw <4 x i32> %97, %97
  %104 = mul nsw <4 x i32> %98, %98
  %105 = add <4 x i32> %103, %63
  %106 = sub <4 x i32> %105, %104
  %107 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 41, i64 0
  %108 = bitcast i32* %107 to <16 x i32>*
  %109 = shufflevector <4 x i32> %100, <4 x i32> %102, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %110 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %106, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %111 = shufflevector <8 x i32> %109, <8 x i32> %110, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %111, <16 x i32>* %108, align 16
  %112 = add nsw <4 x i64> %59, <i64 13312, i64 14336, i64 15360, i64 16384>
  %113 = add <4 x i32> %61, <i32 13232, i32 14256, i32 15280, i32 16304>
  %114 = add <4 x i32> %61, <i32 14256, i32 15280, i32 16304, i32 17328>
  %115 = trunc <4 x i64> %112 to <4 x i32>
  %116 = add <4 x i32> %115, <i32 -80, i32 -80, i32 -80, i32 -80>
  %117 = trunc <4 x i64> %112 to <4 x i32>
  %118 = add <4 x i32> %117, <i32 944, i32 944, i32 944, i32 944>
  %119 = mul nsw <4 x i32> %113, %113
  %120 = mul nsw <4 x i32> %114, %114
  %121 = add <4 x i32> %119, %63
  %122 = sub <4 x i32> %121, %120
  %123 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 45, i64 0
  %124 = bitcast i32* %123 to <16 x i32>*
  %125 = shufflevector <4 x i32> %116, <4 x i32> %118, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %126 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %122, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %127 = shufflevector <8 x i32> %125, <8 x i32> %126, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %127, <16 x i32>* %124, align 16
  %128 = add nsw <4 x i64> %59, <i64 17408, i64 18432, i64 19456, i64 20480>
  %129 = add <4 x i32> %61, <i32 17328, i32 18352, i32 19376, i32 20400>
  %130 = add <4 x i32> %61, <i32 18352, i32 19376, i32 20400, i32 21424>
  %131 = trunc <4 x i64> %128 to <4 x i32>
  %132 = add <4 x i32> %131, <i32 -80, i32 -80, i32 -80, i32 -80>
  %133 = trunc <4 x i64> %128 to <4 x i32>
  %134 = add <4 x i32> %133, <i32 944, i32 944, i32 944, i32 944>
  %135 = mul nsw <4 x i32> %129, %129
  %136 = mul nsw <4 x i32> %130, %130
  %137 = add <4 x i32> %135, %63
  %138 = sub <4 x i32> %137, %136
  %139 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 49, i64 0
  %140 = bitcast i32* %139 to <16 x i32>*
  %141 = shufflevector <4 x i32> %132, <4 x i32> %134, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %142 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %138, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %143 = shufflevector <8 x i32> %141, <8 x i32> %142, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %143, <16 x i32>* %140, align 16
  %144 = add nsw <4 x i64> %59, <i64 21504, i64 22528, i64 23552, i64 24576>
  %145 = add <4 x i32> %61, <i32 21424, i32 22448, i32 23472, i32 24496>
  %146 = add <4 x i32> %61, <i32 22448, i32 23472, i32 24496, i32 25520>
  %147 = trunc <4 x i64> %144 to <4 x i32>
  %148 = add <4 x i32> %147, <i32 -80, i32 -80, i32 -80, i32 -80>
  %149 = trunc <4 x i64> %144 to <4 x i32>
  %150 = add <4 x i32> %149, <i32 944, i32 944, i32 944, i32 944>
  %151 = mul nsw <4 x i32> %145, %145
  %152 = mul nsw <4 x i32> %146, %146
  %153 = add <4 x i32> %151, %63
  %154 = sub <4 x i32> %153, %152
  %155 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 53, i64 0
  %156 = bitcast i32* %155 to <16 x i32>*
  %157 = shufflevector <4 x i32> %148, <4 x i32> %150, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %158 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %154, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %159 = shufflevector <8 x i32> %157, <8 x i32> %158, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %159, <16 x i32>* %156, align 16
  %160 = add nsw <4 x i64> %59, <i64 25600, i64 26624, i64 27648, i64 28672>
  %161 = add <4 x i32> %61, <i32 25520, i32 26544, i32 27568, i32 28592>
  %162 = add <4 x i32> %61, <i32 26544, i32 27568, i32 28592, i32 29616>
  %163 = trunc <4 x i64> %160 to <4 x i32>
  %164 = add <4 x i32> %163, <i32 -80, i32 -80, i32 -80, i32 -80>
  %165 = trunc <4 x i64> %160 to <4 x i32>
  %166 = add <4 x i32> %165, <i32 944, i32 944, i32 944, i32 944>
  %167 = mul nsw <4 x i32> %161, %161
  %168 = mul nsw <4 x i32> %162, %162
  %169 = add <4 x i32> %167, %63
  %170 = sub <4 x i32> %169, %168
  %171 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 57, i64 0
  %172 = bitcast i32* %171 to <16 x i32>*
  %173 = shufflevector <4 x i32> %164, <4 x i32> %166, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %174 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %170, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %175 = shufflevector <8 x i32> %173, <8 x i32> %174, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %175, <16 x i32>* %172, align 16
  %176 = add nsw i64 %57, 29696
  %177 = add nsw i32 %33, 29616
  %178 = add nsw i32 %33, 30640
  %179 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 61, i64 0
  %180 = trunc i64 %176 to i32
  %181 = add i32 %180, -80
  store i32 %181, i32* %179, align 16
  %182 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 61, i64 1
  %183 = trunc i64 %176 to i32
  %184 = add i32 %183, 944
  store i32 %184, i32* %182, align 4
  %185 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 61, i64 2
  store i32 -2048, i32* %185, align 8
  %186 = mul nsw i32 %177, %177
  %187 = mul nsw i32 %178, %178
  %188 = add i32 %186, %56
  %189 = sub i32 %188, %187
  %190 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 61, i64 3
  store i32 %189, i32* %190, align 4
  %191 = add nsw i64 %57, 30720
  %192 = add nsw i32 %33, 30640
  %193 = add nsw i32 %33, 31664
  %194 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 62, i64 0
  %195 = trunc i64 %191 to i32
  %196 = add i32 %195, -80
  store i32 %196, i32* %194, align 16
  %197 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 62, i64 1
  %198 = trunc i64 %191 to i32
  %199 = add i32 %198, 944
  store i32 %199, i32* %197, align 4
  %200 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 62, i64 2
  store i32 -2048, i32* %200, align 8
  %201 = mul nsw i32 %192, %192
  %202 = mul nsw i32 %193, %193
  %203 = add i32 %201, %56
  %204 = sub i32 %203, %202
  %205 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 62, i64 3
  store i32 %204, i32* %205, align 4
  %206 = add nsw i64 %57, 31744
  %207 = add nsw i32 %33, 31664
  %208 = add nsw i32 %33, 32688
  %209 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 63, i64 0
  %210 = trunc i64 %206 to i32
  %211 = add i32 %210, -80
  store i32 %211, i32* %209, align 16
  %212 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 63, i64 1
  %213 = trunc i64 %206 to i32
  %214 = add i32 %213, 944
  store i32 %214, i32* %212, align 4
  %215 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 63, i64 2
  store i32 -2048, i32* %215, align 8
  %216 = mul nsw i32 %207, %207
  %217 = mul nsw i32 %208, %208
  %218 = add i32 %216, %56
  %219 = sub i32 %218, %217
  %220 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 63, i64 3
  store i32 %219, i32* %220, align 4
  %221 = shl i32 %13, 10
  %222 = insertelement <4 x i64> undef, i64 %57, i32 0
  %223 = shufflevector <4 x i64> %222, <4 x i64> undef, <4 x i32> zeroinitializer
  %224 = insertelement <4 x i32> undef, i32 %33, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = insertelement <4 x i32> undef, i32 %221, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i64> %223, <i64 -32768, i64 -31744, i64 -30720, i64 -29696>
  %229 = add <4 x i32> %225, <i32 -32688, i32 -31664, i32 -30640, i32 -29616>
  %230 = add <4 x i32> %225, <i32 -31664, i32 -30640, i32 -29616, i32 -28592>
  %231 = trunc <4 x i64> %228 to <4 x i32>
  %232 = add <4 x i32> %231, <i32 80, i32 80, i32 80, i32 80>
  %233 = trunc <4 x i64> %228 to <4 x i32>
  %234 = add <4 x i32> %233, <i32 1104, i32 1104, i32 1104, i32 1104>
  %235 = mul nsw <4 x i32> %229, %229
  %236 = mul nsw <4 x i32> %230, %230
  %237 = add <4 x i32> %235, %227
  %238 = sub <4 x i32> %237, %236
  %239 = bitcast [64 x [4 x i32]]* %16 to <16 x i32>*
  %240 = shufflevector <4 x i32> %232, <4 x i32> %234, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %241 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %238, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %242 = shufflevector <8 x i32> %240, <8 x i32> %241, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %242, <16 x i32>* %239, align 16
  %243 = add nsw <4 x i64> %223, <i64 -28672, i64 -27648, i64 -26624, i64 -25600>
  %244 = add <4 x i32> %225, <i32 -28592, i32 -27568, i32 -26544, i32 -25520>
  %245 = add <4 x i32> %225, <i32 -27568, i32 -26544, i32 -25520, i32 -24496>
  %246 = trunc <4 x i64> %243 to <4 x i32>
  %247 = add <4 x i32> %246, <i32 80, i32 80, i32 80, i32 80>
  %248 = trunc <4 x i64> %243 to <4 x i32>
  %249 = add <4 x i32> %248, <i32 1104, i32 1104, i32 1104, i32 1104>
  %250 = mul nsw <4 x i32> %244, %244
  %251 = mul nsw <4 x i32> %245, %245
  %252 = add <4 x i32> %250, %227
  %253 = sub <4 x i32> %252, %251
  %254 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 4, i64 0
  %255 = bitcast i32* %254 to <16 x i32>*
  %256 = shufflevector <4 x i32> %247, <4 x i32> %249, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %257 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %253, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %258 = shufflevector <8 x i32> %256, <8 x i32> %257, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %258, <16 x i32>* %255, align 16
  %259 = add nsw <4 x i64> %223, <i64 -24576, i64 -23552, i64 -22528, i64 -21504>
  %260 = add <4 x i32> %225, <i32 -24496, i32 -23472, i32 -22448, i32 -21424>
  %261 = add <4 x i32> %225, <i32 -23472, i32 -22448, i32 -21424, i32 -20400>
  %262 = trunc <4 x i64> %259 to <4 x i32>
  %263 = add <4 x i32> %262, <i32 80, i32 80, i32 80, i32 80>
  %264 = trunc <4 x i64> %259 to <4 x i32>
  %265 = add <4 x i32> %264, <i32 1104, i32 1104, i32 1104, i32 1104>
  %266 = mul nsw <4 x i32> %260, %260
  %267 = mul nsw <4 x i32> %261, %261
  %268 = add <4 x i32> %266, %227
  %269 = sub <4 x i32> %268, %267
  %270 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 8, i64 0
  %271 = bitcast i32* %270 to <16 x i32>*
  %272 = shufflevector <4 x i32> %263, <4 x i32> %265, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %273 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %269, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %274 = shufflevector <8 x i32> %272, <8 x i32> %273, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %274, <16 x i32>* %271, align 16
  %275 = add nsw <4 x i64> %223, <i64 -20480, i64 -19456, i64 -18432, i64 -17408>
  %276 = add <4 x i32> %225, <i32 -20400, i32 -19376, i32 -18352, i32 -17328>
  %277 = add <4 x i32> %225, <i32 -19376, i32 -18352, i32 -17328, i32 -16304>
  %278 = trunc <4 x i64> %275 to <4 x i32>
  %279 = add <4 x i32> %278, <i32 80, i32 80, i32 80, i32 80>
  %280 = trunc <4 x i64> %275 to <4 x i32>
  %281 = add <4 x i32> %280, <i32 1104, i32 1104, i32 1104, i32 1104>
  %282 = mul nsw <4 x i32> %276, %276
  %283 = mul nsw <4 x i32> %277, %277
  %284 = add <4 x i32> %282, %227
  %285 = sub <4 x i32> %284, %283
  %286 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 12, i64 0
  %287 = bitcast i32* %286 to <16 x i32>*
  %288 = shufflevector <4 x i32> %279, <4 x i32> %281, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %289 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %285, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %290 = shufflevector <8 x i32> %288, <8 x i32> %289, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %290, <16 x i32>* %287, align 16
  %291 = add nsw <4 x i64> %223, <i64 -16384, i64 -15360, i64 -14336, i64 -13312>
  %292 = add <4 x i32> %225, <i32 -16304, i32 -15280, i32 -14256, i32 -13232>
  %293 = add <4 x i32> %225, <i32 -15280, i32 -14256, i32 -13232, i32 -12208>
  %294 = trunc <4 x i64> %291 to <4 x i32>
  %295 = add <4 x i32> %294, <i32 80, i32 80, i32 80, i32 80>
  %296 = trunc <4 x i64> %291 to <4 x i32>
  %297 = add <4 x i32> %296, <i32 1104, i32 1104, i32 1104, i32 1104>
  %298 = mul nsw <4 x i32> %292, %292
  %299 = mul nsw <4 x i32> %293, %293
  %300 = add <4 x i32> %298, %227
  %301 = sub <4 x i32> %300, %299
  %302 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 16, i64 0
  %303 = bitcast i32* %302 to <16 x i32>*
  %304 = shufflevector <4 x i32> %295, <4 x i32> %297, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %305 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %301, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %306 = shufflevector <8 x i32> %304, <8 x i32> %305, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %306, <16 x i32>* %303, align 16
  %307 = add nsw <4 x i64> %223, <i64 -12288, i64 -11264, i64 -10240, i64 -9216>
  %308 = add <4 x i32> %225, <i32 -12208, i32 -11184, i32 -10160, i32 -9136>
  %309 = add <4 x i32> %225, <i32 -11184, i32 -10160, i32 -9136, i32 -8112>
  %310 = trunc <4 x i64> %307 to <4 x i32>
  %311 = add <4 x i32> %310, <i32 80, i32 80, i32 80, i32 80>
  %312 = trunc <4 x i64> %307 to <4 x i32>
  %313 = add <4 x i32> %312, <i32 1104, i32 1104, i32 1104, i32 1104>
  %314 = mul nsw <4 x i32> %308, %308
  %315 = mul nsw <4 x i32> %309, %309
  %316 = add <4 x i32> %314, %227
  %317 = sub <4 x i32> %316, %315
  %318 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 20, i64 0
  %319 = bitcast i32* %318 to <16 x i32>*
  %320 = shufflevector <4 x i32> %311, <4 x i32> %313, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %321 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %317, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %322 = shufflevector <8 x i32> %320, <8 x i32> %321, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %322, <16 x i32>* %319, align 16
  %323 = add nsw <4 x i64> %223, <i64 -8192, i64 -7168, i64 -6144, i64 -5120>
  %324 = add <4 x i32> %225, <i32 -8112, i32 -7088, i32 -6064, i32 -5040>
  %325 = add <4 x i32> %225, <i32 -7088, i32 -6064, i32 -5040, i32 -4016>
  %326 = trunc <4 x i64> %323 to <4 x i32>
  %327 = add <4 x i32> %326, <i32 80, i32 80, i32 80, i32 80>
  %328 = trunc <4 x i64> %323 to <4 x i32>
  %329 = add <4 x i32> %328, <i32 1104, i32 1104, i32 1104, i32 1104>
  %330 = mul nsw <4 x i32> %324, %324
  %331 = mul nsw <4 x i32> %325, %325
  %332 = add <4 x i32> %330, %227
  %333 = sub <4 x i32> %332, %331
  %334 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 24, i64 0
  %335 = bitcast i32* %334 to <16 x i32>*
  %336 = shufflevector <4 x i32> %327, <4 x i32> %329, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %337 = shufflevector <4 x i32> <i32 -2048, i32 -2048, i32 -2048, i32 -2048>, <4 x i32> %333, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %338 = shufflevector <8 x i32> %336, <8 x i32> %337, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %338, <16 x i32>* %335, align 16
  %339 = add nsw i64 %57, -4096
  %340 = add nsw i32 %33, -4016
  %341 = add nsw i32 %33, -2992
  %342 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 28, i64 0
  %343 = trunc i64 %339 to i32
  %344 = add i32 %343, 80
  store i32 %344, i32* %342, align 16
  %345 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 28, i64 1
  %346 = trunc i64 %339 to i32
  %347 = add i32 %346, 1104
  store i32 %347, i32* %345, align 4
  %348 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 28, i64 2
  store i32 -2048, i32* %348, align 8
  %349 = mul nsw i32 %340, %340
  %350 = mul nsw i32 %341, %341
  %351 = add i32 %349, %221
  %352 = sub i32 %351, %350
  %353 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 28, i64 3
  store i32 %352, i32* %353, align 4
  %354 = add nsw i64 %57, -3072
  %355 = add nsw i32 %33, -2992
  %356 = add nsw i32 %33, -1968
  %357 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 29, i64 0
  %358 = trunc i64 %354 to i32
  %359 = add i32 %358, 80
  store i32 %359, i32* %357, align 16
  %360 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 29, i64 1
  %361 = trunc i64 %354 to i32
  %362 = add i32 %361, 1104
  store i32 %362, i32* %360, align 4
  %363 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 29, i64 2
  store i32 -2048, i32* %363, align 8
  %364 = mul nsw i32 %355, %355
  %365 = mul nsw i32 %356, %356
  %366 = add i32 %364, %221
  %367 = sub i32 %366, %365
  %368 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 29, i64 3
  store i32 %367, i32* %368, align 4
  %369 = add nsw i64 %57, -2048
  %370 = add nsw i32 %33, -1968
  %371 = add nsw i32 %33, -944
  %372 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 30, i64 0
  %373 = trunc i64 %369 to i32
  %374 = add i32 %373, 80
  store i32 %374, i32* %372, align 16
  %375 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 30, i64 1
  %376 = trunc i64 %369 to i32
  %377 = add i32 %376, 1104
  store i32 %377, i32* %375, align 4
  %378 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 30, i64 2
  store i32 -2048, i32* %378, align 8
  %379 = mul nsw i32 %370, %370
  %380 = mul nsw i32 %371, %371
  %381 = add i32 %379, %221
  %382 = sub i32 %381, %380
  %383 = getelementptr inbounds [64 x [4 x i32]], [64 x [4 x i32]]* %16, i64 0, i64 30, i64 3
  store i32 %382, i32* %383, align 4
  %384 = getelementptr inbounds %struct.SideInfoIndices, %struct.SideInfoIndices* %2, i64 0, i32 7
  %385 = load i8, i8* %384, align 1
  %386 = icmp ne i8 %385, 4
  %387 = zext i1 %386 to i32
  %388 = getelementptr inbounds %struct.silk_encoder_state, %struct.silk_encoder_state* %0, i64 0, i32 23
  %389 = load i32, i32* %388, align 8
  %390 = getelementptr inbounds %struct.silk_encoder_state, %struct.silk_encoder_state* %0, i64 0, i32 21
  %391 = load i32, i32* %390, align 8
  %392 = add nsw i32 %391, %389
  %393 = sext i32 %392 to i64
  %394 = shl nsw i64 %393, 2
  %395 = alloca i32, i64 %393, align 16
  %396 = bitcast i32* %395 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %396, i8 -86, i64 %394, i1 false)
  %397 = shl nsw i64 %393, 1
  %398 = alloca i16, i64 %393, align 16
  %399 = bitcast i16* %398 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %399, i8 -86, i64 %397, i1 false)
  %400 = getelementptr inbounds %struct.silk_encoder_state, %struct.silk_encoder_state* %0, i64 0, i32 22
  %401 = load i32, i32* %400, align 4
  %402 = sext i32 %401 to i64
  %403 = shl nsw i64 %402, 2
  %404 = alloca i32, i64 %402, align 16
  %405 = bitcast i32* %404 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %405, i8 -86, i64 %403, i1 false)
  %406 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 8
  store i32 %389, i32* %406, align 4
  %407 = load i32, i32* %388, align 8
  %408 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 7
  store i32 %407, i32* %408, align 4
  %409 = getelementptr inbounds %struct.silk_encoder_state, %struct.silk_encoder_state* %0, i64 0, i32 20
  %410 = load i32, i32* %409, align 4
  %411 = icmp sgt i32 %410, 0
  br i1 %411, label %412, label %1663

412:                                              ; preds = %15
  %413 = load i32, i32* %388, align 8
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 0, i64 %414
  %416 = xor i32 %387, 1
  %417 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 11
  %418 = shl nuw nsw i32 %387, 1
  %419 = xor i32 %418, 3
  %420 = getelementptr inbounds %struct.silk_encoder_state, %struct.silk_encoder_state* %0, i64 0, i32 35
  %421 = getelementptr inbounds %struct.silk_encoder_state, %struct.silk_encoder_state* %0, i64 0, i32 57
  %422 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 10
  %423 = zext i32 %14 to i64
  %424 = shl i64 %423, 48
  %425 = ashr exact i64 %424, 48
  %426 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 4
  %427 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 0
  %428 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 1
  %429 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 2
  %430 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 3
  %431 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 4
  %432 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 5
  %433 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 6
  %434 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 7
  %435 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 8
  %436 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 9
  %437 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 10
  %438 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 11
  %439 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 12
  %440 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 13
  %441 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 14
  %442 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 15
  %443 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 0
  %444 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 1
  %445 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 2
  %446 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 3
  %447 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 4
  %448 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 5
  %449 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 6
  %450 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 7
  %451 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 8
  %452 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 9
  %453 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 10
  %454 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 11
  %455 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 12
  %456 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 13
  %457 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 14
  %458 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 15
  %459 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 16
  %460 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 17
  %461 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 18
  %462 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 19
  %463 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 20
  %464 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 21
  %465 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 22
  %466 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3, i64 23
  %467 = getelementptr inbounds %struct.silk_encoder_state, %struct.silk_encoder_state* %0, i64 0, i32 34
  %468 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2
  %469 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 -1
  %470 = bitcast i32* %469 to <16 x i8>*
  %471 = bitcast i32* %430 to <16 x i8>*
  %472 = bitcast i32* %434 to <16 x i8>*
  %473 = bitcast i32* %438 to <16 x i8>*
  %474 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 3
  %475 = bitcast [24 x i32]* %474 to <16 x i8>*
  %476 = bitcast i32* %447 to <16 x i8>*
  %477 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 16
  %478 = bitcast i32* %447 to <8 x i16>*
  %479 = bitcast [24 x i32]* %474 to <8 x i16>*
  %480 = bitcast [96 x i32]* %468 to i8*
  %481 = getelementptr %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 16
  %482 = getelementptr %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 16
  br label %483

483:                                              ; preds = %412, %1653
  %484 = phi i64 [ 0, %412 ], [ %1659, %1653 ]
  %485 = phi i16* [ %415, %412 ], [ %1658, %1653 ]
  %486 = phi i32 [ %23, %412 ], [ %537, %1653 ]
  %487 = phi i32* [ %3, %412 ], [ %1656, %1653 ]
  %488 = phi i8* [ %4, %412 ], [ %1657, %1653 ]
  %489 = trunc i64 %484 to i32
  %490 = lshr i32 %489, 1
  %491 = or i32 %490, %416
  %492 = shl nsw i32 %491, 4
  %493 = zext i32 %492 to i64
  %494 = getelementptr inbounds i16, i16* %5, i64 %493
  %495 = mul i64 %484, 5
  %496 = and i64 %495, 4294967295
  %497 = getelementptr inbounds i16, i16* %6, i64 %496
  %498 = mul i64 %484, 24
  %499 = and i64 %498, 4294967288
  %500 = getelementptr inbounds i16, i16* %7, i64 %499
  %501 = getelementptr inbounds i32, i32* %8, i64 %484
  %502 = load i32, i32* %501, align 4
  %503 = ashr i32 %502, 2
  %504 = lshr i32 %502, 1
  %505 = shl i32 %504, 16
  %506 = or i32 %505, %503
  store i32 0, i32* %417, align 4
  %507 = load i8, i8* %24, align 1
  %508 = icmp eq i8 %507, 2
  br i1 %508, label %509, label %534

509:                                              ; preds = %483
  %510 = getelementptr inbounds i32, i32* %12, i64 %484
  %511 = load i32, i32* %510, align 4
  %512 = and i32 %419, %489
  %513 = icmp eq i32 %512, 0
  br i1 %513, label %514, label %534

514:                                              ; preds = %509
  %515 = load i32, i32* %388, align 8
  %516 = load i32, i32* %420, align 8
  %517 = sub i32 -2, %511
  %518 = add i32 %517, %515
  %519 = sub i32 %518, %516
  %520 = icmp sgt i32 %519, 0
  br i1 %520, label %522, label %521

521:                                              ; preds = %514
  call void @celt_fatal(i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.1, i64 0, i64 0), i32 202) #7
  unreachable

522:                                              ; preds = %514
  %523 = sext i32 %519 to i64
  %524 = getelementptr inbounds i16, i16* %398, i64 %523
  %525 = load i32, i32* %400, align 4
  %526 = mul nsw i32 %525, %489
  %527 = add nsw i32 %526, %519
  %528 = sext i32 %527 to i64
  %529 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 0, i64 %528
  %530 = sub nsw i32 %515, %519
  %531 = load i32, i32* %421, align 4
  call void @silk_LPC_analysis_filter(i16* %524, i16* %529, i16* %494, i32 %530, i32 %516, i32 %531) #6
  store i32 1, i32* %417, align 4
  %532 = load i32, i32* %388, align 8
  store i32 %532, i32* %408, align 4
  %533 = load i8, i8* %24, align 1
  br label %534

534:                                              ; preds = %509, %522, %483
  %535 = phi i32 [ 1, %522 ], [ 0, %509 ], [ 0, %483 ]
  %536 = phi i8 [ %533, %522 ], [ 2, %509 ], [ %507, %483 ]
  %537 = phi i32 [ %511, %522 ], [ %511, %509 ], [ %486, %483 ]
  %538 = getelementptr inbounds i32, i32* %12, i64 %484
  %539 = load i32, i32* %538, align 4
  %540 = getelementptr inbounds i32, i32* %11, i64 %484
  %541 = load i32, i32* %540, align 4
  %542 = icmp sgt i32 %541, 1
  %543 = select i1 %542, i32 %541, i32 1
  %544 = call i32 @llvm.ctlz.i32(i32 %543, i1 false) #6, !range !2
  %545 = add nsw i32 %544, -1
  %546 = shl i32 %543, %545
  %547 = ashr i32 %546, 16
  %548 = sdiv i32 536870911, %547
  %549 = shl i32 %548, 16
  %550 = sext i32 %546 to i64
  %551 = zext i32 %548 to i64
  %552 = shl i64 %551, 48
  %553 = ashr exact i64 %552, 29
  %554 = mul i64 %553, %550
  %555 = and i64 %554, -34359738368
  %556 = sub i64 0, %555
  %557 = ashr exact i64 %556, 32
  %558 = sext i32 %548 to i64
  %559 = mul nsw i64 %557, %558
  %560 = lshr i64 %559, 16
  %561 = trunc i64 %560 to i32
  %562 = add i32 %549, %561
  %563 = icmp ult i32 %543, 131072
  br i1 %563, label %564, label %582

564:                                              ; preds = %534
  %565 = add nsw i32 %544, -15
  %566 = ashr i32 -2147483648, %565
  %567 = lshr i32 2147483647, %565
  %568 = icmp sgt i32 %566, %567
  br i1 %568, label %569, label %574

569:                                              ; preds = %564
  %570 = icmp sgt i32 %562, %566
  br i1 %570, label %579, label %571

571:                                              ; preds = %569
  %572 = icmp slt i32 %562, %567
  %573 = select i1 %572, i32 %567, i32 %562
  br label %579

574:                                              ; preds = %564
  %575 = icmp sgt i32 %562, %567
  br i1 %575, label %579, label %576

576:                                              ; preds = %574
  %577 = icmp slt i32 %562, %566
  %578 = select i1 %577, i32 %566, i32 %562
  br label %579

579:                                              ; preds = %576, %574, %571, %569
  %580 = phi i32 [ %566, %569 ], [ %573, %571 ], [ %567, %574 ], [ %578, %576 ]
  %581 = shl i32 %580, %565
  br label %585

582:                                              ; preds = %534
  %583 = sub nsw i32 15, %544
  %584 = ashr i32 %562, %583
  br label %585

585:                                              ; preds = %582, %579
  %586 = phi i32 [ %581, %579 ], [ %584, %582 ]
  %587 = load i32, i32* %422, align 4
  %588 = icmp eq i32 %541, %587
  br i1 %588, label %647, label %589

589:                                              ; preds = %585
  %590 = icmp slt i32 %587, 0
  %591 = sub nsw i32 0, %587
  %592 = select i1 %590, i32 %591, i32 %587
  %593 = call i32 @llvm.ctlz.i32(i32 %592, i1 false) #6, !range !2
  %594 = add nsw i32 %593, -1
  %595 = shl i32 %587, %594
  %596 = icmp slt i32 %541, 0
  %597 = sub nsw i32 0, %541
  %598 = select i1 %596, i32 %597, i32 %541
  %599 = call i32 @llvm.ctlz.i32(i32 %598, i1 false) #6, !range !2
  %600 = add nsw i32 %599, -1
  %601 = shl i32 %541, %600
  %602 = ashr i32 %601, 16
  %603 = sdiv i32 536870911, %602
  %604 = sext i32 %595 to i64
  %605 = zext i32 %603 to i64
  %606 = shl i64 %605, 48
  %607 = ashr exact i64 %606, 48
  %608 = mul nsw i64 %607, %604
  %609 = sext i32 %601 to i64
  %610 = ashr i64 %608, 16
  %611 = mul nsw i64 %610, %609
  %612 = lshr i64 %611, 29
  %613 = trunc i64 %612 to i32
  %614 = and i32 %613, -8
  %615 = sub i32 %595, %614
  %616 = sext i32 %615 to i64
  %617 = mul nsw i64 %607, %616
  %618 = lshr i64 %617, 16
  %619 = add nsw i64 %618, %610
  %620 = trunc i64 %619 to i32
  %621 = sub nsw i32 29, %599
  %622 = add nsw i32 %593, %621
  %623 = add nsw i32 %622, -16
  %624 = icmp slt i32 %623, 0
  br i1 %624, label %625, label %643

625:                                              ; preds = %589
  %626 = sub nsw i32 16, %622
  %627 = ashr i32 -2147483648, %626
  %628 = lshr i32 2147483647, %626
  %629 = icmp sgt i32 %627, %628
  br i1 %629, label %630, label %635

630:                                              ; preds = %625
  %631 = icmp slt i32 %627, %620
  br i1 %631, label %640, label %632

632:                                              ; preds = %630
  %633 = icmp sgt i32 %628, %620
  %634 = select i1 %633, i32 %628, i32 %620
  br label %640

635:                                              ; preds = %625
  %636 = icmp slt i32 %628, %620
  br i1 %636, label %640, label %637

637:                                              ; preds = %635
  %638 = icmp sgt i32 %627, %620
  %639 = select i1 %638, i32 %627, i32 %620
  br label %640

640:                                              ; preds = %637, %635, %632, %630
  %641 = phi i32 [ %627, %630 ], [ %634, %632 ], [ %628, %635 ], [ %639, %637 ]
  %642 = shl i32 %641, %626
  br label %647

643:                                              ; preds = %589
  %644 = icmp slt i32 %623, 32
  %645 = ashr i32 %620, %623
  %646 = select i1 %644, i32 %645, i32 0
  br label %647

647:                                              ; preds = %643, %640, %585
  %648 = phi i32 [ 65536, %585 ], [ %642, %640 ], [ %646, %643 ]
  %649 = ashr i32 %586, 7
  %650 = add nsw i32 %649, 1
  %651 = ashr i32 %650, 1
  %652 = load i32, i32* %400, align 4
  %653 = icmp sgt i32 %652, 3
  br i1 %653, label %654, label %664

654:                                              ; preds = %647
  %655 = insertelement <4 x i32> undef, i32 %651, i32 0
  %656 = shufflevector <4 x i32> %655, <4 x i32> undef, <4 x i32> zeroinitializer
  %657 = bitcast <4 x i32> %656 to <2 x i64>
  %658 = shl <2 x i64> %657, <i64 32, i64 32>
  %659 = ashr exact <2 x i64> %658, <i64 32, i64 32>
  %660 = add nsw i32 %652, -3
  %661 = sext i32 %660 to i64
  br label %671

662:                                              ; preds = %671
  %663 = trunc i64 %692 to i32
  br label %664

664:                                              ; preds = %662, %647
  %665 = phi i32 [ 0, %647 ], [ %663, %662 ]
  %666 = icmp slt i32 %665, %652
  br i1 %666, label %667, label %705

667:                                              ; preds = %664
  %668 = sext i32 %651 to i64
  %669 = zext i32 %665 to i64
  %670 = sext i32 %652 to i64
  br label %694

671:                                              ; preds = %671, %654
  %672 = phi i64 [ 0, %654 ], [ %692, %671 ]
  %673 = getelementptr inbounds i32, i32* %487, i64 %672
  %674 = bitcast i32* %673 to <2 x i64>*
  %675 = load <2 x i64>, <2 x i64>* %674, align 1
  %676 = bitcast <2 x i64> %675 to <4 x i32>
  %677 = shufflevector <4 x i32> %676, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
  %678 = bitcast <4 x i32> %677 to <2 x i64>
  %679 = shl <2 x i64> %675, <i64 32, i64 32>
  %680 = ashr exact <2 x i64> %679, <i64 32, i64 32>
  %681 = mul nsw <2 x i64> %680, %659
  %682 = shl <2 x i64> %678, <i64 32, i64 32>
  %683 = ashr exact <2 x i64> %682, <i64 32, i64 32>
  %684 = mul nsw <2 x i64> %683, %659
  %685 = lshr <2 x i64> %681, <i64 16, i64 16>
  %686 = shl <2 x i64> %684, <i64 16, i64 16>
  %687 = bitcast <2 x i64> %685 to <8 x i16>
  %688 = bitcast <2 x i64> %686 to <8 x i16>
  %689 = shufflevector <8 x i16> %687, <8 x i16> %688, <8 x i32> <i32 0, i32 1, i32 10, i32 11, i32 4, i32 5, i32 14, i32 15>
  %690 = getelementptr inbounds i32, i32* %404, i64 %672
  %691 = bitcast i32* %690 to <8 x i16>*
  store <8 x i16> %689, <8 x i16>* %691, align 16
  %692 = add nuw nsw i64 %672, 4
  %693 = icmp slt i64 %692, %661
  br i1 %693, label %671, label %662

694:                                              ; preds = %694, %667
  %695 = phi i64 [ %669, %667 ], [ %703, %694 ]
  %696 = getelementptr inbounds i32, i32* %487, i64 %695
  %697 = load i32, i32* %696, align 4
  %698 = sext i32 %697 to i64
  %699 = mul nsw i64 %698, %668
  %700 = lshr i64 %699, 16
  %701 = trunc i64 %700 to i32
  %702 = getelementptr inbounds i32, i32* %404, i64 %695
  store i32 %701, i32* %702, align 4
  %703 = add nuw nsw i64 %695, 1
  %704 = icmp slt i64 %703, %670
  br i1 %704, label %694, label %705

705:                                              ; preds = %694, %664
  store i32 %541, i32* %422, align 4
  %706 = icmp eq i32 %535, 0
  br i1 %706, label %781, label %707

707:                                              ; preds = %705
  %708 = icmp eq i64 %484, 0
  br i1 %708, label %709, label %715

709:                                              ; preds = %707
  %710 = sext i32 %586 to i64
  %711 = mul nsw i64 %425, %710
  %712 = lshr i64 %711, 14
  %713 = trunc i64 %712 to i32
  %714 = and i32 %713, -4
  br label %715

715:                                              ; preds = %709, %707
  %716 = phi i32 [ %714, %709 ], [ %586, %707 ]
  %717 = load i32, i32* %408, align 4
  %718 = sub i32 -2, %539
  %719 = add i32 %717, %718
  %720 = icmp slt i32 %719, %717
  br i1 %720, label %721, label %781

721:                                              ; preds = %715
  %722 = sext i32 %716 to i64
  %723 = sext i32 %719 to i64
  %724 = sext i32 %717 to i64
  %725 = sub nsw i64 %724, %723
  %726 = xor i64 %723, -1
  %727 = add nsw i64 %726, %724
  %728 = and i64 %725, 3
  %729 = icmp eq i64 %728, 0
  br i1 %729, label %743, label %730

730:                                              ; preds = %721, %730
  %731 = phi i64 [ %740, %730 ], [ %723, %721 ]
  %732 = phi i64 [ %741, %730 ], [ %728, %721 ]
  %733 = getelementptr inbounds i16, i16* %398, i64 %731
  %734 = load i16, i16* %733, align 2
  %735 = sext i16 %734 to i64
  %736 = mul nsw i64 %735, %722
  %737 = lshr i64 %736, 16
  %738 = trunc i64 %737 to i32
  %739 = getelementptr inbounds i32, i32* %395, i64 %731
  store i32 %738, i32* %739, align 4
  %740 = add nsw i64 %731, 1
  %741 = add i64 %732, -1
  %742 = icmp eq i64 %741, 0
  br i1 %742, label %743, label %730, !llvm.loop !3

743:                                              ; preds = %730, %721
  %744 = phi i64 [ %723, %721 ], [ %740, %730 ]
  %745 = icmp ult i64 %727, 3
  br i1 %745, label %781, label %746

746:                                              ; preds = %743, %746
  %747 = phi i64 [ %779, %746 ], [ %744, %743 ]
  %748 = getelementptr inbounds i16, i16* %398, i64 %747
  %749 = load i16, i16* %748, align 2
  %750 = sext i16 %749 to i64
  %751 = mul nsw i64 %750, %722
  %752 = lshr i64 %751, 16
  %753 = trunc i64 %752 to i32
  %754 = getelementptr inbounds i32, i32* %395, i64 %747
  store i32 %753, i32* %754, align 4
  %755 = add nsw i64 %747, 1
  %756 = getelementptr inbounds i16, i16* %398, i64 %755
  %757 = load i16, i16* %756, align 2
  %758 = sext i16 %757 to i64
  %759 = mul nsw i64 %758, %722
  %760 = lshr i64 %759, 16
  %761 = trunc i64 %760 to i32
  %762 = getelementptr inbounds i32, i32* %395, i64 %755
  store i32 %761, i32* %762, align 4
  %763 = add nsw i64 %747, 2
  %764 = getelementptr inbounds i16, i16* %398, i64 %763
  %765 = load i16, i16* %764, align 2
  %766 = sext i16 %765 to i64
  %767 = mul nsw i64 %766, %722
  %768 = lshr i64 %767, 16
  %769 = trunc i64 %768 to i32
  %770 = getelementptr inbounds i32, i32* %395, i64 %763
  store i32 %769, i32* %770, align 4
  %771 = add nsw i64 %747, 3
  %772 = getelementptr inbounds i16, i16* %398, i64 %771
  %773 = load i16, i16* %772, align 2
  %774 = sext i16 %773 to i64
  %775 = mul nsw i64 %774, %722
  %776 = lshr i64 %775, 16
  %777 = trunc i64 %776 to i32
  %778 = getelementptr inbounds i32, i32* %395, i64 %771
  store i32 %777, i32* %778, align 4
  %779 = add nsw i64 %747, 4
  %780 = icmp eq i64 %779, %724
  br i1 %780, label %781, label %746

781:                                              ; preds = %743, %746, %715, %705
  %782 = icmp eq i32 %648, 65536
  br i1 %782, label %1114, label %783

783:                                              ; preds = %781
  %784 = load i32, i32* %406, align 4
  %785 = load i32, i32* %388, align 8
  %786 = sub i32 %784, %785
  %787 = add nsw i32 %784, -3
  %788 = icmp slt i32 %786, %787
  br i1 %788, label %789, label %798

789:                                              ; preds = %783
  %790 = insertelement <4 x i32> undef, i32 %648, i32 0
  %791 = shufflevector <4 x i32> %790, <4 x i32> undef, <4 x i32> zeroinitializer
  %792 = bitcast <4 x i32> %791 to <2 x i64>
  %793 = shl <2 x i64> %792, <i64 32, i64 32>
  %794 = ashr exact <2 x i64> %793, <i64 32, i64 32>
  %795 = sext i32 %786 to i64
  br label %805

796:                                              ; preds = %805
  %797 = trunc i64 %825 to i32
  br label %798

798:                                              ; preds = %796, %783
  %799 = phi i32 [ %784, %783 ], [ %826, %796 ]
  %800 = phi i32 [ %786, %783 ], [ %797, %796 ]
  %801 = icmp slt i32 %800, %799
  br i1 %801, label %802, label %842

802:                                              ; preds = %798
  %803 = sext i32 %648 to i64
  %804 = sext i32 %800 to i64
  br label %830

805:                                              ; preds = %805, %789
  %806 = phi i64 [ %795, %789 ], [ %825, %805 ]
  %807 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 1, i64 %806
  %808 = bitcast i32* %807 to <2 x i64>*
  %809 = load <2 x i64>, <2 x i64>* %808, align 1
  %810 = bitcast <2 x i64> %809 to <4 x i32>
  %811 = shufflevector <4 x i32> %810, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
  %812 = bitcast <4 x i32> %811 to <2 x i64>
  %813 = shl <2 x i64> %809, <i64 32, i64 32>
  %814 = ashr exact <2 x i64> %813, <i64 32, i64 32>
  %815 = mul nsw <2 x i64> %814, %794
  %816 = shl <2 x i64> %812, <i64 32, i64 32>
  %817 = ashr exact <2 x i64> %816, <i64 32, i64 32>
  %818 = mul nsw <2 x i64> %817, %794
  %819 = lshr <2 x i64> %815, <i64 16, i64 16>
  %820 = shl <2 x i64> %818, <i64 16, i64 16>
  %821 = bitcast <2 x i64> %819 to <8 x i16>
  %822 = bitcast <2 x i64> %820 to <8 x i16>
  %823 = shufflevector <8 x i16> %821, <8 x i16> %822, <8 x i32> <i32 0, i32 1, i32 10, i32 11, i32 4, i32 5, i32 14, i32 15>
  %824 = bitcast i32* %807 to <8 x i16>*
  store <8 x i16> %823, <8 x i16>* %824, align 1
  %825 = add nsw i64 %806, 4
  %826 = load i32, i32* %406, align 4
  %827 = add nsw i32 %826, -3
  %828 = sext i32 %827 to i64
  %829 = icmp slt i64 %825, %828
  br i1 %829, label %805, label %796

830:                                              ; preds = %830, %802
  %831 = phi i64 [ %804, %802 ], [ %838, %830 ]
  %832 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 1, i64 %831
  %833 = load i32, i32* %832, align 4
  %834 = sext i32 %833 to i64
  %835 = mul nsw i64 %834, %803
  %836 = lshr i64 %835, 16
  %837 = trunc i64 %836 to i32
  store i32 %837, i32* %832, align 4
  %838 = add nsw i64 %831, 1
  %839 = load i32, i32* %406, align 4
  %840 = sext i32 %839 to i64
  %841 = icmp slt i64 %838, %840
  br i1 %841, label %830, label %842

842:                                              ; preds = %830, %798
  %843 = icmp eq i8 %536, 2
  br i1 %843, label %844, label %907

844:                                              ; preds = %842
  %845 = load i32, i32* %417, align 4
  %846 = icmp eq i32 %845, 0
  br i1 %846, label %847, label %907

847:                                              ; preds = %844
  %848 = load i32, i32* %408, align 4
  %849 = sub i32 -2, %539
  %850 = add i32 %848, %849
  %851 = icmp slt i32 %850, %848
  br i1 %851, label %852, label %907

852:                                              ; preds = %847
  %853 = sext i32 %648 to i64
  %854 = sext i32 %850 to i64
  %855 = sext i32 %848 to i64
  %856 = sub nsw i64 %855, %854
  %857 = xor i64 %854, -1
  %858 = add nsw i64 %857, %855
  %859 = and i64 %856, 3
  %860 = icmp eq i64 %859, 0
  br i1 %860, label %873, label %861

861:                                              ; preds = %852, %861
  %862 = phi i64 [ %870, %861 ], [ %854, %852 ]
  %863 = phi i64 [ %871, %861 ], [ %859, %852 ]
  %864 = getelementptr inbounds i32, i32* %395, i64 %862
  %865 = load i32, i32* %864, align 4
  %866 = sext i32 %865 to i64
  %867 = mul nsw i64 %866, %853
  %868 = lshr i64 %867, 16
  %869 = trunc i64 %868 to i32
  store i32 %869, i32* %864, align 4
  %870 = add nsw i64 %862, 1
  %871 = add i64 %863, -1
  %872 = icmp eq i64 %871, 0
  br i1 %872, label %873, label %861, !llvm.loop !5

873:                                              ; preds = %861, %852
  %874 = phi i64 [ %854, %852 ], [ %870, %861 ]
  %875 = icmp ult i64 %858, 3
  br i1 %875, label %907, label %876

876:                                              ; preds = %873, %876
  %877 = phi i64 [ %905, %876 ], [ %874, %873 ]
  %878 = getelementptr inbounds i32, i32* %395, i64 %877
  %879 = load i32, i32* %878, align 4
  %880 = sext i32 %879 to i64
  %881 = mul nsw i64 %880, %853
  %882 = lshr i64 %881, 16
  %883 = trunc i64 %882 to i32
  store i32 %883, i32* %878, align 4
  %884 = add nsw i64 %877, 1
  %885 = getelementptr inbounds i32, i32* %395, i64 %884
  %886 = load i32, i32* %885, align 4
  %887 = sext i32 %886 to i64
  %888 = mul nsw i64 %887, %853
  %889 = lshr i64 %888, 16
  %890 = trunc i64 %889 to i32
  store i32 %890, i32* %885, align 4
  %891 = add nsw i64 %877, 2
  %892 = getelementptr inbounds i32, i32* %395, i64 %891
  %893 = load i32, i32* %892, align 4
  %894 = sext i32 %893 to i64
  %895 = mul nsw i64 %894, %853
  %896 = lshr i64 %895, 16
  %897 = trunc i64 %896 to i32
  store i32 %897, i32* %892, align 4
  %898 = add nsw i64 %877, 3
  %899 = getelementptr inbounds i32, i32* %395, i64 %898
  %900 = load i32, i32* %899, align 4
  %901 = sext i32 %900 to i64
  %902 = mul nsw i64 %901, %853
  %903 = lshr i64 %902, 16
  %904 = trunc i64 %903 to i32
  store i32 %904, i32* %899, align 4
  %905 = add nsw i64 %877, 4
  %906 = icmp eq i64 %905, %855
  br i1 %906, label %907, label %876

907:                                              ; preds = %873, %876, %847, %844, %842
  %908 = sext i32 %648 to i64
  %909 = load i32, i32* %426, align 4
  %910 = sext i32 %909 to i64
  %911 = mul nsw i64 %910, %908
  %912 = lshr i64 %911, 16
  %913 = trunc i64 %912 to i32
  store i32 %913, i32* %426, align 4
  %914 = load i32, i32* %427, align 4
  %915 = sext i32 %914 to i64
  %916 = mul nsw i64 %915, %908
  %917 = lshr i64 %916, 16
  %918 = trunc i64 %917 to i32
  store i32 %918, i32* %427, align 4
  %919 = load i32, i32* %428, align 4
  %920 = sext i32 %919 to i64
  %921 = mul nsw i64 %920, %908
  %922 = lshr i64 %921, 16
  %923 = trunc i64 %922 to i32
  store i32 %923, i32* %428, align 4
  %924 = load i32, i32* %429, align 4
  %925 = sext i32 %924 to i64
  %926 = mul nsw i64 %925, %908
  %927 = lshr i64 %926, 16
  %928 = trunc i64 %927 to i32
  store i32 %928, i32* %429, align 4
  %929 = load i32, i32* %430, align 4
  %930 = sext i32 %929 to i64
  %931 = mul nsw i64 %930, %908
  %932 = lshr i64 %931, 16
  %933 = trunc i64 %932 to i32
  store i32 %933, i32* %430, align 4
  %934 = load i32, i32* %431, align 4
  %935 = sext i32 %934 to i64
  %936 = mul nsw i64 %935, %908
  %937 = lshr i64 %936, 16
  %938 = trunc i64 %937 to i32
  store i32 %938, i32* %431, align 4
  %939 = load i32, i32* %432, align 4
  %940 = sext i32 %939 to i64
  %941 = mul nsw i64 %940, %908
  %942 = lshr i64 %941, 16
  %943 = trunc i64 %942 to i32
  store i32 %943, i32* %432, align 4
  %944 = load i32, i32* %433, align 4
  %945 = sext i32 %944 to i64
  %946 = mul nsw i64 %945, %908
  %947 = lshr i64 %946, 16
  %948 = trunc i64 %947 to i32
  store i32 %948, i32* %433, align 4
  %949 = load i32, i32* %434, align 4
  %950 = sext i32 %949 to i64
  %951 = mul nsw i64 %950, %908
  %952 = lshr i64 %951, 16
  %953 = trunc i64 %952 to i32
  store i32 %953, i32* %434, align 4
  %954 = load i32, i32* %435, align 4
  %955 = sext i32 %954 to i64
  %956 = mul nsw i64 %955, %908
  %957 = lshr i64 %956, 16
  %958 = trunc i64 %957 to i32
  store i32 %958, i32* %435, align 4
  %959 = load i32, i32* %436, align 4
  %960 = sext i32 %959 to i64
  %961 = mul nsw i64 %960, %908
  %962 = lshr i64 %961, 16
  %963 = trunc i64 %962 to i32
  store i32 %963, i32* %436, align 4
  %964 = load i32, i32* %437, align 4
  %965 = sext i32 %964 to i64
  %966 = mul nsw i64 %965, %908
  %967 = lshr i64 %966, 16
  %968 = trunc i64 %967 to i32
  store i32 %968, i32* %437, align 4
  %969 = load i32, i32* %438, align 4
  %970 = sext i32 %969 to i64
  %971 = mul nsw i64 %970, %908
  %972 = lshr i64 %971, 16
  %973 = trunc i64 %972 to i32
  store i32 %973, i32* %438, align 4
  %974 = load i32, i32* %439, align 4
  %975 = sext i32 %974 to i64
  %976 = mul nsw i64 %975, %908
  %977 = lshr i64 %976, 16
  %978 = trunc i64 %977 to i32
  store i32 %978, i32* %439, align 4
  %979 = load i32, i32* %440, align 4
  %980 = sext i32 %979 to i64
  %981 = mul nsw i64 %980, %908
  %982 = lshr i64 %981, 16
  %983 = trunc i64 %982 to i32
  store i32 %983, i32* %440, align 4
  %984 = load i32, i32* %441, align 4
  %985 = sext i32 %984 to i64
  %986 = mul nsw i64 %985, %908
  %987 = lshr i64 %986, 16
  %988 = trunc i64 %987 to i32
  store i32 %988, i32* %441, align 4
  %989 = load i32, i32* %442, align 4
  %990 = sext i32 %989 to i64
  %991 = mul nsw i64 %990, %908
  %992 = lshr i64 %991, 16
  %993 = trunc i64 %992 to i32
  store i32 %993, i32* %442, align 4
  %994 = load i32, i32* %443, align 4
  %995 = sext i32 %994 to i64
  %996 = mul nsw i64 %995, %908
  %997 = lshr i64 %996, 16
  %998 = trunc i64 %997 to i32
  store i32 %998, i32* %443, align 4
  %999 = load i32, i32* %444, align 4
  %1000 = sext i32 %999 to i64
  %1001 = mul nsw i64 %1000, %908
  %1002 = lshr i64 %1001, 16
  %1003 = trunc i64 %1002 to i32
  store i32 %1003, i32* %444, align 4
  %1004 = load i32, i32* %445, align 4
  %1005 = sext i32 %1004 to i64
  %1006 = mul nsw i64 %1005, %908
  %1007 = lshr i64 %1006, 16
  %1008 = trunc i64 %1007 to i32
  store i32 %1008, i32* %445, align 4
  %1009 = load i32, i32* %446, align 4
  %1010 = sext i32 %1009 to i64
  %1011 = mul nsw i64 %1010, %908
  %1012 = lshr i64 %1011, 16
  %1013 = trunc i64 %1012 to i32
  store i32 %1013, i32* %446, align 4
  %1014 = load i32, i32* %447, align 4
  %1015 = sext i32 %1014 to i64
  %1016 = mul nsw i64 %1015, %908
  %1017 = lshr i64 %1016, 16
  %1018 = trunc i64 %1017 to i32
  store i32 %1018, i32* %447, align 4
  %1019 = load i32, i32* %448, align 4
  %1020 = sext i32 %1019 to i64
  %1021 = mul nsw i64 %1020, %908
  %1022 = lshr i64 %1021, 16
  %1023 = trunc i64 %1022 to i32
  store i32 %1023, i32* %448, align 4
  %1024 = load i32, i32* %449, align 4
  %1025 = sext i32 %1024 to i64
  %1026 = mul nsw i64 %1025, %908
  %1027 = lshr i64 %1026, 16
  %1028 = trunc i64 %1027 to i32
  store i32 %1028, i32* %449, align 4
  %1029 = load i32, i32* %450, align 4
  %1030 = sext i32 %1029 to i64
  %1031 = mul nsw i64 %1030, %908
  %1032 = lshr i64 %1031, 16
  %1033 = trunc i64 %1032 to i32
  store i32 %1033, i32* %450, align 4
  %1034 = load i32, i32* %451, align 4
  %1035 = sext i32 %1034 to i64
  %1036 = mul nsw i64 %1035, %908
  %1037 = lshr i64 %1036, 16
  %1038 = trunc i64 %1037 to i32
  store i32 %1038, i32* %451, align 4
  %1039 = load i32, i32* %452, align 4
  %1040 = sext i32 %1039 to i64
  %1041 = mul nsw i64 %1040, %908
  %1042 = lshr i64 %1041, 16
  %1043 = trunc i64 %1042 to i32
  store i32 %1043, i32* %452, align 4
  %1044 = load i32, i32* %453, align 4
  %1045 = sext i32 %1044 to i64
  %1046 = mul nsw i64 %1045, %908
  %1047 = lshr i64 %1046, 16
  %1048 = trunc i64 %1047 to i32
  store i32 %1048, i32* %453, align 4
  %1049 = load i32, i32* %454, align 4
  %1050 = sext i32 %1049 to i64
  %1051 = mul nsw i64 %1050, %908
  %1052 = lshr i64 %1051, 16
  %1053 = trunc i64 %1052 to i32
  store i32 %1053, i32* %454, align 4
  %1054 = load i32, i32* %455, align 4
  %1055 = sext i32 %1054 to i64
  %1056 = mul nsw i64 %1055, %908
  %1057 = lshr i64 %1056, 16
  %1058 = trunc i64 %1057 to i32
  store i32 %1058, i32* %455, align 4
  %1059 = load i32, i32* %456, align 4
  %1060 = sext i32 %1059 to i64
  %1061 = mul nsw i64 %1060, %908
  %1062 = lshr i64 %1061, 16
  %1063 = trunc i64 %1062 to i32
  store i32 %1063, i32* %456, align 4
  %1064 = load i32, i32* %457, align 4
  %1065 = sext i32 %1064 to i64
  %1066 = mul nsw i64 %1065, %908
  %1067 = lshr i64 %1066, 16
  %1068 = trunc i64 %1067 to i32
  store i32 %1068, i32* %457, align 4
  %1069 = load i32, i32* %458, align 4
  %1070 = sext i32 %1069 to i64
  %1071 = mul nsw i64 %1070, %908
  %1072 = lshr i64 %1071, 16
  %1073 = trunc i64 %1072 to i32
  store i32 %1073, i32* %458, align 4
  %1074 = load i32, i32* %459, align 4
  %1075 = sext i32 %1074 to i64
  %1076 = mul nsw i64 %1075, %908
  %1077 = lshr i64 %1076, 16
  %1078 = trunc i64 %1077 to i32
  store i32 %1078, i32* %459, align 4
  %1079 = load i32, i32* %460, align 4
  %1080 = sext i32 %1079 to i64
  %1081 = mul nsw i64 %1080, %908
  %1082 = lshr i64 %1081, 16
  %1083 = trunc i64 %1082 to i32
  store i32 %1083, i32* %460, align 4
  %1084 = load i32, i32* %461, align 4
  %1085 = sext i32 %1084 to i64
  %1086 = mul nsw i64 %1085, %908
  %1087 = lshr i64 %1086, 16
  %1088 = trunc i64 %1087 to i32
  store i32 %1088, i32* %461, align 4
  %1089 = load i32, i32* %462, align 4
  %1090 = sext i32 %1089 to i64
  %1091 = mul nsw i64 %1090, %908
  %1092 = lshr i64 %1091, 16
  %1093 = trunc i64 %1092 to i32
  store i32 %1093, i32* %462, align 4
  %1094 = load i32, i32* %463, align 4
  %1095 = sext i32 %1094 to i64
  %1096 = mul nsw i64 %1095, %908
  %1097 = lshr i64 %1096, 16
  %1098 = trunc i64 %1097 to i32
  store i32 %1098, i32* %463, align 4
  %1099 = load i32, i32* %464, align 4
  %1100 = sext i32 %1099 to i64
  %1101 = mul nsw i64 %1100, %908
  %1102 = lshr i64 %1101, 16
  %1103 = trunc i64 %1102 to i32
  store i32 %1103, i32* %464, align 4
  %1104 = load i32, i32* %465, align 4
  %1105 = sext i32 %1104 to i64
  %1106 = mul nsw i64 %1105, %908
  %1107 = lshr i64 %1106, 16
  %1108 = trunc i64 %1107 to i32
  store i32 %1108, i32* %465, align 4
  %1109 = load i32, i32* %466, align 4
  %1110 = sext i32 %1109 to i64
  %1111 = mul nsw i64 %1110, %908
  %1112 = lshr i64 %1111, 16
  %1113 = trunc i64 %1112 to i32
  store i32 %1113, i32* %466, align 4
  br label %1114

1114:                                             ; preds = %781, %907
  %1115 = load i32, i32* %467, align 4
  %1116 = icmp eq i32 %1115, 10
  br i1 %1116, label %1117, label %1120, !prof !6

1117:                                             ; preds = %1114
  %1118 = load i32, i32* %420, align 8
  %1119 = icmp eq i32 %1118, 16
  br label %1120

1120:                                             ; preds = %1117, %1114
  %1121 = phi i1 [ false, %1114 ], [ %1119, %1117 ]
  %1122 = load i8, i8* %24, align 1
  %1123 = getelementptr inbounds i32, i32* %9, i64 %484
  %1124 = load i32, i32* %1123, align 4
  %1125 = getelementptr inbounds i32, i32* %10, i64 %484
  %1126 = load i32, i32* %1125, align 4
  %1127 = load i32, i32* %540, align 4
  %1128 = load i32, i32* %400, align 4
  br i1 %1121, label %1129, label %1649, !prof !6

1129:                                             ; preds = %1120
  %1130 = ashr i32 %1127, 6
  %1131 = load i32, i32* %426, align 4
  %1132 = load <16 x i8>, <16 x i8>* %470, align 1
  %1133 = load <16 x i8>, <16 x i8>* %471, align 1
  %1134 = shufflevector <16 x i8> %1132, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 4, i32 5, i32 8, i32 9, i32 12, i32 13, i32 2, i32 3, i32 6, i32 7, i32 10, i32 11, i32 14, i32 15>
  %1135 = bitcast <16 x i8> %1134 to <2 x i64>
  %1136 = shufflevector <16 x i8> %1133, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 4, i32 5, i32 8, i32 9, i32 12, i32 13, i32 2, i32 3, i32 6, i32 7, i32 10, i32 11, i32 14, i32 15>
  %1137 = bitcast <16 x i8> %1136 to <2 x i64>
  %1138 = load <16 x i8>, <16 x i8>* %472, align 1
  %1139 = load <16 x i8>, <16 x i8>* %473, align 1
  %1140 = shufflevector <16 x i8> %1138, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 4, i32 5, i32 8, i32 9, i32 12, i32 13, i32 2, i32 3, i32 6, i32 7, i32 10, i32 11, i32 14, i32 15>
  %1141 = bitcast <16 x i8> %1140 to <2 x i64>
  %1142 = shufflevector <16 x i8> %1139, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 4, i32 5, i32 8, i32 9, i32 12, i32 13, i32 2, i32 3, i32 6, i32 7, i32 10, i32 11, i32 14, i32 15>
  %1143 = bitcast <16 x i8> %1142 to <2 x i64>
  %1144 = load <16 x i8>, <16 x i8>* %475, align 1
  %1145 = load <16 x i8>, <16 x i8>* %476, align 1
  %1146 = shufflevector <16 x i8> %1144, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 4, i32 5, i32 8, i32 9, i32 12, i32 13, i32 2, i32 3, i32 6, i32 7, i32 10, i32 11, i32 14, i32 15>
  %1147 = bitcast <16 x i8> %1146 to <2 x i64>
  %1148 = shufflevector <16 x i8> %1145, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 4, i32 5, i32 8, i32 9, i32 12, i32 13, i32 2, i32 3, i32 6, i32 7, i32 10, i32 11, i32 14, i32 15>
  %1149 = bitcast <16 x i8> %1148 to <2 x i64>
  %1150 = shufflevector <2 x i64> %1147, <2 x i64> %1149, <2 x i32> <i32 1, i32 3>
  %1151 = shufflevector <2 x i64> %1147, <2 x i64> %1149, <2 x i32> <i32 0, i32 2>
  %1152 = icmp sgt i32 %1128, 0
  br i1 %1152, label %1153, label %1468

1153:                                             ; preds = %1129
  %1154 = bitcast i16* %500 to <8 x i16>*
  %1155 = load <8 x i16>, <8 x i16>* %1154, align 1
  %1156 = getelementptr inbounds i16, i16* %494, i64 8
  %1157 = bitcast i16* %1156 to <16 x i8>*
  %1158 = load <16 x i8>, <16 x i8>* %1157, align 1
  %1159 = shufflevector <16 x i8> %1158, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %1160 = bitcast i16* %494 to <16 x i8>*
  %1161 = load <16 x i8>, <16 x i8>* %1160, align 1
  %1162 = shufflevector <16 x i8> %1161, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 12, i32 13, i32 10, i32 11, i32 8, i32 9, i32 6, i32 7, i32 4, i32 5, i32 2, i32 3, i32 0, i32 1>
  %1163 = shufflevector <2 x i64> %1141, <2 x i64> %1143, <2 x i32> <i32 0, i32 2>
  %1164 = shufflevector <2 x i64> %1141, <2 x i64> %1143, <2 x i32> <i32 1, i32 3>
  %1165 = shufflevector <2 x i64> %1135, <2 x i64> %1137, <2 x i32> <i32 0, i32 2>
  %1166 = shufflevector <2 x i64> %1135, <2 x i64> %1137, <2 x i32> <i32 1, i32 3>
  %1167 = load i32, i32* %442, align 4
  %1168 = sub i32 2, %537
  %1169 = load i32, i32* %408, align 4
  %1170 = add i32 %1168, %1169
  %1171 = sext i32 %1170 to i64
  %1172 = getelementptr inbounds i32, i32* %395, i64 %1171
  %1173 = sub i32 1, %537
  %1174 = load i32, i32* %406, align 4
  %1175 = add i32 %1173, %1174
  %1176 = sext i32 %1175 to i64
  %1177 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 1, i64 %1176
  %1178 = bitcast <16 x i8> %1162 to <8 x i16>
  %1179 = bitcast <16 x i8> %1159 to <8 x i16>
  %1180 = icmp eq i8 %1122, 2
  %1181 = bitcast i16* %497 to i64*
  %1182 = getelementptr inbounds i16, i16* %497, i64 4
  %1183 = getelementptr inbounds i16, i16* %500, i64 8
  %1184 = getelementptr inbounds i16, i16* %500, i64 9
  %1185 = zext i32 %1124 to i64
  %1186 = shl i64 %1185, 48
  %1187 = ashr exact i64 %1186, 48
  %1188 = zext i32 %1126 to i64
  %1189 = shl i64 %1188, 48
  %1190 = ashr exact i64 %1189, 48
  %1191 = ashr i32 %1126, 16
  %1192 = sext i32 %1191 to i64
  %1193 = icmp sgt i32 %537, 0
  %1194 = zext i32 %503 to i64
  %1195 = shl i64 %1194, 48
  %1196 = ashr exact i64 %1195, 48
  %1197 = ashr i32 %506, 16
  %1198 = sext i32 %1197 to i64
  %1199 = zext i32 %1128 to i64
  br label %1200

1200:                                             ; preds = %1402, %1153
  %1201 = phi i32 [ %1174, %1153 ], [ %1460, %1402 ]
  %1202 = phi i64 [ 0, %1153 ], [ %1466, %1402 ]
  %1203 = phi i32 [ 0, %1153 ], [ %1309, %1402 ]
  %1204 = phi <2 x i64> [ %1151, %1153 ], [ %1327, %1402 ]
  %1205 = phi <2 x i64> [ %1150, %1153 ], [ %1324, %1402 ]
  %1206 = phi <2 x i64> [ %1165, %1153 ], [ %1222, %1402 ]
  %1207 = phi <2 x i64> [ %1163, %1153 ], [ %1233, %1402 ]
  %1208 = phi <2 x i64> [ %1166, %1153 ], [ %1218, %1402 ]
  %1209 = phi <2 x i64> [ %1164, %1153 ], [ %1229, %1402 ]
  %1210 = phi i32* [ %1172, %1153 ], [ %1308, %1402 ]
  %1211 = phi i32* [ %1177, %1153 ], [ %1404, %1402 ]
  %1212 = phi i32* [ %442, %1153 ], [ %1447, %1402 ]
  %1213 = phi i32 [ %1131, %1153 ], [ %1449, %1402 ]
  %1214 = phi i32 [ %1167, %1153 ], [ %1446, %1402 ]
  %1215 = bitcast <2 x i64> %1209 to <16 x i8>
  %1216 = bitcast <2 x i64> %1208 to <16 x i8>
  %1217 = shufflevector <16 x i8> %1216, <16 x i8> %1215, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1218 = bitcast <16 x i8> %1217 to <2 x i64>
  %1219 = bitcast <2 x i64> %1207 to <16 x i8>
  %1220 = bitcast <2 x i64> %1206 to <16 x i8>
  %1221 = shufflevector <16 x i8> %1220, <16 x i8> %1219, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1222 = bitcast <16 x i8> %1221 to <2 x i64>
  %1223 = shufflevector <16 x i8> %1215, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef>
  %1224 = shufflevector <16 x i8> %1219, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef>
  %1225 = bitcast <16 x i8> %1223 to <8 x i16>
  %1226 = lshr i32 %1214, 16
  %1227 = trunc i32 %1226 to i16
  %1228 = insertelement <8 x i16> %1225, i16 %1227, i64 7
  %1229 = bitcast <8 x i16> %1228 to <2 x i64>
  %1230 = bitcast <16 x i8> %1224 to <8 x i16>
  %1231 = trunc i32 %1214 to i16
  %1232 = insertelement <8 x i16> %1230, i16 %1231, i64 7
  %1233 = bitcast <8 x i16> %1232 to <2 x i64>
  %1234 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1228, <8 x i16> %1178) #6
  %1235 = bitcast <16 x i8> %1217 to <8 x i16>
  %1236 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1235, <8 x i16> %1179) #6
  %1237 = ashr <8 x i16> %1232, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %1238 = bitcast <16 x i8> %1221 to <8 x i16>
  %1239 = ashr <8 x i16> %1238, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %1240 = call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %1232, <8 x i16> %1178) #6
  %1241 = call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %1238, <8 x i16> %1179) #6
  %1242 = and <8 x i16> %1237, %1178
  %1243 = add <8 x i16> %1242, %1240
  %1244 = and <8 x i16> %1239, %1179
  %1245 = add <8 x i16> %1241, %1244
  %1246 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1243, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %1247 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1245, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %1248 = add <4 x i32> %1236, %1234
  %1249 = add <4 x i32> %1248, %1246
  %1250 = add <4 x i32> %1249, %1247
  %1251 = bitcast <4 x i32> %1250 to <2 x i64>
  %1252 = shufflevector <2 x i64> %1251, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %1253 = bitcast <2 x i64> %1252 to <4 x i32>
  %1254 = add <4 x i32> %1250, %1253
  %1255 = bitcast <4 x i32> %1254 to <8 x i16>
  %1256 = shufflevector <8 x i16> %1255, <8 x i16> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1257 = bitcast <8 x i16> %1256 to <4 x i32>
  %1258 = add <4 x i32> %1254, %1257
  %1259 = extractelement <4 x i32> %1258, i32 0
  %1260 = add nsw i32 %1259, 8
  br i1 %1180, label %1261, label %1307, !prof !6

1261:                                             ; preds = %1200
  %1262 = load i64, i64* %1181, align 1
  %1263 = insertelement <2 x i64> undef, i64 %1262, i32 0
  %1264 = bitcast <2 x i64> %1263 to <8 x i16>
  %1265 = shufflevector <8 x i16> %1264, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1266 = sext <4 x i16> %1265 to <4 x i32>
  %1267 = bitcast <4 x i32> %1266 to <2 x i64>
  %1268 = shufflevector <4 x i32> %1266, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %1269 = bitcast <4 x i32> %1268 to <2 x i64>
  %1270 = getelementptr inbounds i32, i32* %1210, i64 -3
  %1271 = bitcast i32* %1270 to <2 x i64>*
  %1272 = load <2 x i64>, <2 x i64>* %1271, align 1
  %1273 = bitcast <2 x i64> %1272 to <4 x i32>
  %1274 = shufflevector <4 x i32> %1273, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %1275 = bitcast <4 x i32> %1274 to <2 x i64>
  %1276 = shl <2 x i64> %1275, <i64 32, i64 32>
  %1277 = ashr exact <2 x i64> %1276, <i64 32, i64 32>
  %1278 = shl <2 x i64> %1267, <i64 32, i64 32>
  %1279 = ashr exact <2 x i64> %1278, <i64 32, i64 32>
  %1280 = mul nsw <2 x i64> %1279, %1277
  %1281 = bitcast <2 x i64> %1280 to <16 x i8>
  %1282 = shufflevector <16 x i8> %1281, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1283 = shl <2 x i64> %1272, <i64 32, i64 32>
  %1284 = ashr exact <2 x i64> %1283, <i64 32, i64 32>
  %1285 = shl <2 x i64> %1269, <i64 32, i64 32>
  %1286 = ashr exact <2 x i64> %1285, <i64 32, i64 32>
  %1287 = mul nsw <2 x i64> %1286, %1284
  %1288 = bitcast <2 x i64> %1287 to <16 x i8>
  %1289 = shufflevector <16 x i8> %1288, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1290 = bitcast <16 x i8> %1289 to <4 x i32>
  %1291 = bitcast <16 x i8> %1282 to <4 x i32>
  %1292 = add <4 x i32> %1290, %1291
  %1293 = shufflevector <4 x i32> %1292, <4 x i32> undef, <4 x i32> <i32 2, i32 undef, i32 undef, i32 undef>
  %1294 = add <4 x i32> %1293, %1292
  %1295 = extractelement <4 x i32> %1294, i32 0
  %1296 = getelementptr inbounds i32, i32* %1210, i64 -4
  %1297 = load i32, i32* %1296, align 4
  %1298 = sext i32 %1297 to i64
  %1299 = load i16, i16* %1182, align 2
  %1300 = sext i16 %1299 to i64
  %1301 = mul nsw i64 %1300, %1298
  %1302 = lshr i64 %1301, 16
  %1303 = trunc i64 %1302 to i32
  %1304 = add i32 %1303, 2
  %1305 = add i32 %1304, %1295
  %1306 = getelementptr inbounds i32, i32* %1210, i64 1
  br label %1307

1307:                                             ; preds = %1261, %1200
  %1308 = phi i32* [ %1306, %1261 ], [ %1210, %1200 ]
  %1309 = phi i32 [ %1305, %1261 ], [ %1203, %1200 ]
  %1310 = load i32, i32* %451, align 4
  store i32 %1310, i32* %452, align 4
  %1311 = bitcast <2 x i64> %1204 to <8 x i16>
  %1312 = bitcast <2 x i64> %1205 to <8 x i16>
  %1313 = shufflevector <8 x i16> %1311, <8 x i16> %1312, <8 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 7, i32 15>
  %1314 = bitcast <8 x i16> %1313 to <16 x i8>
  %1315 = shufflevector <16 x i8> %1314, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1316 = bitcast <16 x i8> %1315 to <4 x i32>
  %1317 = extractelement <4 x i32> %1316, i32 0
  store i32 %1317, i32* %451, align 4
  %1318 = bitcast <2 x i64> %1205 to <16 x i8>
  %1319 = shufflevector <16 x i8> %1318, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13>
  %1320 = bitcast <2 x i64> %1204 to <16 x i8>
  %1321 = shufflevector <16 x i8> %1320, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13>
  %1322 = bitcast <16 x i8> %1319 to <8 x i16>
  %1323 = insertelement <8 x i16> %1322, i16 %1227, i64 0
  %1324 = bitcast <8 x i16> %1323 to <2 x i64>
  %1325 = bitcast <16 x i8> %1321 to <8 x i16>
  %1326 = insertelement <8 x i16> %1325, i16 %1231, i64 0
  %1327 = bitcast <8 x i16> %1326 to <2 x i64>
  %1328 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1323, <8 x i16> %1155) #6
  %1329 = ashr <8 x i16> %1326, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %1330 = call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %1326, <8 x i16> %1155) #6
  %1331 = and <8 x i16> %1329, %1155
  %1332 = add <8 x i16> %1330, %1331
  %1333 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1332, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %1334 = add <4 x i32> %1333, %1328
  %1335 = bitcast <4 x i32> %1334 to <2 x i64>
  %1336 = shufflevector <2 x i64> %1335, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %1337 = bitcast <2 x i64> %1336 to <4 x i32>
  %1338 = add <4 x i32> %1334, %1337
  %1339 = bitcast <4 x i32> %1338 to <8 x i16>
  %1340 = shufflevector <8 x i16> %1339, <8 x i16> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1341 = bitcast <8 x i16> %1340 to <4 x i32>
  %1342 = add <4 x i32> %1338, %1341
  %1343 = extractelement <4 x i32> %1342, i32 0
  %1344 = sext i32 %1317 to i64
  %1345 = load i16, i16* %1183, align 2
  %1346 = sext i16 %1345 to i64
  %1347 = mul nsw i64 %1346, %1344
  %1348 = lshr i64 %1347, 16
  %1349 = trunc i64 %1348 to i32
  %1350 = sext i32 %1310 to i64
  %1351 = load i16, i16* %1184, align 2
  %1352 = sext i16 %1351 to i64
  %1353 = mul nsw i64 %1352, %1350
  %1354 = lshr i64 %1353, 16
  %1355 = trunc i64 %1354 to i32
  %1356 = add i32 %1349, 5
  %1357 = add i32 %1356, %1355
  %1358 = add i32 %1357, %1343
  %1359 = shl i32 %1358, 1
  %1360 = sext i32 %1213 to i64
  %1361 = mul nsw i64 %1187, %1360
  %1362 = lshr i64 %1361, 16
  %1363 = trunc i64 %1362 to i32
  %1364 = add i32 %1359, %1363
  %1365 = add nsw i32 %1201, -1
  %1366 = sext i32 %1365 to i64
  %1367 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 1, i64 %1366
  %1368 = load i32, i32* %1367, align 4
  %1369 = sext i32 %1368 to i64
  %1370 = mul nsw i64 %1190, %1369
  %1371 = lshr i64 %1370, 16
  %1372 = mul nsw i64 %1360, %1192
  %1373 = lshr i64 %1372, 16
  %1374 = add nuw nsw i64 %1371, %1373
  %1375 = trunc i64 %1374 to i32
  %1376 = shl i32 %1260, 2
  %1377 = sub nsw i32 %1376, %1364
  %1378 = sub i32 %1377, %1375
  br i1 %1193, label %1379, label %1400

1379:                                             ; preds = %1307
  %1380 = load i32, i32* %1211, align 4
  %1381 = getelementptr inbounds i32, i32* %1211, i64 -2
  %1382 = load i32, i32* %1381, align 4
  %1383 = add nsw i32 %1382, %1380
  %1384 = sext i32 %1383 to i64
  %1385 = mul nsw i64 %1196, %1384
  %1386 = lshr i64 %1385, 16
  %1387 = getelementptr inbounds i32, i32* %1211, i64 -1
  %1388 = load i32, i32* %1387, align 4
  %1389 = sext i32 %1388 to i64
  %1390 = mul nsw i64 %1389, %1198
  %1391 = lshr i64 %1390, 16
  %1392 = add nuw nsw i64 %1386, %1391
  %1393 = trunc i64 %1392 to i32
  %1394 = shl i32 %1393, 1
  %1395 = getelementptr inbounds i32, i32* %1211, i64 1
  %1396 = shl i32 %1378, 1
  %1397 = add i32 %1396, %1309
  %1398 = sub i32 %1397, %1394
  %1399 = ashr i32 %1398, 2
  br label %1402

1400:                                             ; preds = %1307
  %1401 = ashr i32 %1378, 1
  br label %1402

1402:                                             ; preds = %1400, %1379
  %1403 = phi i32 [ %1399, %1379 ], [ %1401, %1400 ]
  %1404 = phi i32* [ %1395, %1379 ], [ %1211, %1400 ]
  %1405 = add nsw i32 %1403, 1
  %1406 = ashr i32 %1405, 1
  %1407 = getelementptr inbounds i32, i32* %404, i64 %1202
  %1408 = load i32, i32* %1407, align 4
  %1409 = sub nsw i32 %1408, %1406
  %1410 = load i32, i32* %21, align 4
  %1411 = mul i32 %1410, 196314165
  %1412 = add i32 %1411, 907633515
  store i32 %1412, i32* %21, align 4
  %1413 = icmp slt i32 %1412, 0
  %1414 = sub nsw i32 0, %1409
  %1415 = select i1 %1413, i32 %1414, i32 %1409
  %1416 = icmp sgt i32 %1415, -31744
  %1417 = select i1 %1416, i32 %1415, i32 -31744
  %1418 = icmp slt i32 %1417, 30720
  %1419 = select i1 %1418, i32 %1417, i32 30720
  %1420 = sub nsw i32 %1419, %33
  %1421 = ashr i32 %1420, 10
  %1422 = sext i32 %1421 to i64
  %1423 = getelementptr inbounds [4 x i32], [4 x i32]* %35, i64 %1422, i64 0
  %1424 = getelementptr inbounds [4 x i32], [4 x i32]* %35, i64 %1422, i64 2
  %1425 = load i32, i32* %1424, align 8
  %1426 = mul nsw i32 %1419, %1425
  %1427 = getelementptr inbounds [4 x i32], [4 x i32]* %35, i64 %1422, i64 3
  %1428 = load i32, i32* %1427, align 4
  %1429 = icmp slt i32 %1426, %1428
  %1430 = getelementptr inbounds [4 x i32], [4 x i32]* %35, i64 %1422, i64 1
  %1431 = select i1 %1429, i32* %1430, i32* %1423
  %1432 = load i32, i32* %1431, align 4
  %1433 = lshr i32 %1432, 9
  %1434 = add nuw nsw i32 %1433, 1
  %1435 = lshr i32 %1434, 1
  %1436 = trunc i32 %1435 to i8
  %1437 = getelementptr inbounds i8, i8* %488, i64 %1202
  store i8 %1436, i8* %1437, align 1
  %1438 = shl i32 %1432, 4
  %1439 = load i32, i32* %21, align 4
  %1440 = icmp slt i32 %1439, 0
  %1441 = sub nsw i32 0, %1438
  %1442 = select i1 %1440, i32 %1441, i32 %1438
  %1443 = shl i32 %1309, 1
  %1444 = add nsw i32 %1442, %1443
  %1445 = shl i32 %1260, 4
  %1446 = add nsw i32 %1444, %1445
  %1447 = getelementptr inbounds i32, i32* %1212, i64 1
  store i32 %1446, i32* %1447, align 4
  %1448 = shl i32 %1364, 2
  %1449 = sub nsw i32 %1446, %1448
  %1450 = shl i32 %1375, 2
  %1451 = sub nsw i32 %1449, %1450
  %1452 = load i32, i32* %406, align 4
  %1453 = sext i32 %1452 to i64
  %1454 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 1, i64 %1453
  store i32 %1451, i32* %1454, align 4
  %1455 = shl i32 %1444, 1
  %1456 = load i32, i32* %408, align 4
  %1457 = sext i32 %1456 to i64
  %1458 = getelementptr inbounds i32, i32* %395, i64 %1457
  store i32 %1455, i32* %1458, align 4
  %1459 = load i32, i32* %406, align 4
  %1460 = add nsw i32 %1459, 1
  store i32 %1460, i32* %406, align 4
  %1461 = add nsw i32 %1456, 1
  store i32 %1461, i32* %408, align 4
  %1462 = load i32, i32* %21, align 4
  %1463 = load i8, i8* %1437, align 1
  %1464 = sext i8 %1463 to i32
  %1465 = add i32 %1462, %1464
  store i32 %1465, i32* %21, align 4
  %1466 = add nuw nsw i64 %1202, 1
  %1467 = icmp eq i64 %1466, %1199
  br i1 %1467, label %1468, label %1200

1468:                                             ; preds = %1402, %1129
  %1469 = phi i32 [ %1131, %1129 ], [ %1449, %1402 ]
  %1470 = phi <2 x i64> [ %1150, %1129 ], [ %1324, %1402 ]
  %1471 = phi <2 x i64> [ %1151, %1129 ], [ %1327, %1402 ]
  store i32 %1469, i32* %426, align 4
  %1472 = bitcast <2 x i64> %1471 to <8 x i16>
  %1473 = bitcast <2 x i64> %1470 to <8 x i16>
  %1474 = shufflevector <8 x i16> %1472, <8 x i16> %1473, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1475 = shufflevector <8 x i16> %1472, <8 x i16> %1473, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  store <8 x i16> %1474, <8 x i16>* %478, align 1
  store <8 x i16> %1475, <8 x i16>* %479, align 1
  %1476 = add nsw i32 %1128, -7
  %1477 = icmp sgt i32 %1476, 0
  br i1 %1477, label %1478, label %1487

1478:                                             ; preds = %1468
  %1479 = insertelement <4 x i32> undef, i32 %1130, i32 0
  %1480 = shufflevector <4 x i32> %1479, <4 x i32> undef, <4 x i32> zeroinitializer
  %1481 = bitcast <4 x i32> %1480 to <2 x i64>
  %1482 = shl <2 x i64> %1481, <i64 32, i64 32>
  %1483 = ashr exact <2 x i64> %1482, <i64 32, i64 32>
  %1484 = sext i32 %1476 to i64
  br label %1562

1485:                                             ; preds = %1562
  %1486 = trunc i64 %1608 to i32
  br label %1487

1487:                                             ; preds = %1485, %1468
  %1488 = phi i32 [ 0, %1468 ], [ %1486, %1485 ]
  %1489 = icmp slt i32 %1488, %1128
  br i1 %1489, label %1490, label %1645

1490:                                             ; preds = %1487
  %1491 = sext i32 %1130 to i64
  %1492 = zext i32 %1488 to i64
  %1493 = zext i32 %1128 to i64
  %1494 = sub nsw i64 %1493, %1492
  %1495 = icmp ult i64 %1494, 4
  br i1 %1495, label %1496, label %1523

1496:                                             ; preds = %1560, %1523, %1490
  %1497 = phi i64 [ %1492, %1523 ], [ %1492, %1490 ], [ %1535, %1560 ]
  %1498 = sub nsw i64 %1493, %1497
  %1499 = xor i64 %1497, -1
  %1500 = and i64 %1498, 1
  %1501 = icmp eq i64 %1500, 0
  br i1 %1501, label %1519, label %1502

1502:                                             ; preds = %1496
  %1503 = getelementptr inbounds i32, i32* %477, i64 %1497
  %1504 = load i32, i32* %1503, align 4
  %1505 = sext i32 %1504 to i64
  %1506 = mul nsw i64 %1505, %1491
  %1507 = lshr i64 %1506, 16
  %1508 = trunc i64 %1507 to i32
  %1509 = ashr i32 %1508, 7
  %1510 = add nsw i32 %1509, 1
  %1511 = lshr i32 %1510, 1
  %1512 = icmp sgt i32 %1508, 8388479
  %1513 = icmp slt i32 %1510, -65536
  %1514 = select i1 %1513, i32 32768, i32 %1511
  %1515 = select i1 %1512, i32 32767, i32 %1514
  %1516 = trunc i32 %1515 to i16
  %1517 = getelementptr inbounds i16, i16* %485, i64 %1497
  store i16 %1516, i16* %1517, align 2
  %1518 = add nuw nsw i64 %1497, 1
  br label %1519

1519:                                             ; preds = %1502, %1496
  %1520 = phi i64 [ %1518, %1502 ], [ %1497, %1496 ]
  %1521 = sub nsw i64 0, %1493
  %1522 = icmp eq i64 %1499, %1521
  br i1 %1522, label %1645, label %1610

1523:                                             ; preds = %1490
  %1524 = getelementptr i16, i16* %485, i64 %1492
  %1525 = getelementptr i16, i16* %485, i64 %1493
  %1526 = getelementptr i32, i32* %481, i64 %1492
  %1527 = getelementptr i32, i32* %482, i64 %1493
  %1528 = bitcast i32* %1527 to i16*
  %1529 = icmp ult i16* %1524, %1528
  %1530 = bitcast i16* %1525 to i32*
  %1531 = icmp ult i32* %1526, %1530
  %1532 = and i1 %1529, %1531
  br i1 %1532, label %1496, label %1533

1533:                                             ; preds = %1523
  %1534 = and i64 %1494, -4
  %1535 = add nsw i64 %1534, %1492
  %1536 = insertelement <4 x i64> undef, i64 %1491, i32 0
  %1537 = shufflevector <4 x i64> %1536, <4 x i64> undef, <4 x i32> zeroinitializer
  br label %1538

1538:                                             ; preds = %1538, %1533
  %1539 = phi i64 [ 0, %1533 ], [ %1558, %1538 ]
  %1540 = add i64 %1539, %1492
  %1541 = getelementptr inbounds i32, i32* %477, i64 %1540
  %1542 = bitcast i32* %1541 to <4 x i32>*
  %1543 = load <4 x i32>, <4 x i32>* %1542, align 4, !alias.scope !7
  %1544 = sext <4 x i32> %1543 to <4 x i64>
  %1545 = mul nsw <4 x i64> %1537, %1544
  %1546 = lshr <4 x i64> %1545, <i64 16, i64 16, i64 16, i64 16>
  %1547 = trunc <4 x i64> %1546 to <4 x i32>
  %1548 = ashr <4 x i32> %1547, <i32 7, i32 7, i32 7, i32 7>
  %1549 = add nsw <4 x i32> %1548, <i32 1, i32 1, i32 1, i32 1>
  %1550 = lshr <4 x i32> %1549, <i32 1, i32 1, i32 1, i32 1>
  %1551 = icmp sgt <4 x i32> %1547, <i32 8388479, i32 8388479, i32 8388479, i32 8388479>
  %1552 = icmp slt <4 x i32> %1549, <i32 -65536, i32 -65536, i32 -65536, i32 -65536>
  %1553 = select <4 x i1> %1552, <4 x i32> <i32 32768, i32 32768, i32 32768, i32 32768>, <4 x i32> %1550
  %1554 = select <4 x i1> %1551, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>, <4 x i32> %1553
  %1555 = trunc <4 x i32> %1554 to <4 x i16>
  %1556 = getelementptr inbounds i16, i16* %485, i64 %1540
  %1557 = bitcast i16* %1556 to <4 x i16>*
  store <4 x i16> %1555, <4 x i16>* %1557, align 2, !alias.scope !10, !noalias !7
  %1558 = add i64 %1539, 4
  %1559 = icmp eq i64 %1558, %1534
  br i1 %1559, label %1560, label %1538, !llvm.loop !12

1560:                                             ; preds = %1538
  %1561 = icmp eq i64 %1494, %1534
  br i1 %1561, label %1645, label %1496

1562:                                             ; preds = %1562, %1478
  %1563 = phi i64 [ 0, %1478 ], [ %1608, %1562 ]
  %1564 = getelementptr inbounds i32, i32* %477, i64 %1563
  %1565 = bitcast i32* %1564 to <2 x i64>*
  %1566 = load <2 x i64>, <2 x i64>* %1565, align 1
  %1567 = or i64 %1563, 4
  %1568 = getelementptr inbounds i32, i32* %477, i64 %1567
  %1569 = bitcast i32* %1568 to <2 x i64>*
  %1570 = load <2 x i64>, <2 x i64>* %1569, align 1
  %1571 = bitcast <2 x i64> %1566 to <4 x i32>
  %1572 = shufflevector <4 x i32> %1571, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
  %1573 = bitcast <4 x i32> %1572 to <2 x i64>
  %1574 = bitcast <2 x i64> %1570 to <4 x i32>
  %1575 = shufflevector <4 x i32> %1574, <4 x i32> undef, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
  %1576 = bitcast <4 x i32> %1575 to <2 x i64>
  %1577 = shl <2 x i64> %1566, <i64 32, i64 32>
  %1578 = ashr exact <2 x i64> %1577, <i64 32, i64 32>
  %1579 = mul nsw <2 x i64> %1578, %1483
  %1580 = shl <2 x i64> %1573, <i64 32, i64 32>
  %1581 = ashr exact <2 x i64> %1580, <i64 32, i64 32>
  %1582 = mul nsw <2 x i64> %1581, %1483
  %1583 = shl <2 x i64> %1570, <i64 32, i64 32>
  %1584 = ashr exact <2 x i64> %1583, <i64 32, i64 32>
  %1585 = mul nsw <2 x i64> %1584, %1483
  %1586 = shl <2 x i64> %1576, <i64 32, i64 32>
  %1587 = ashr exact <2 x i64> %1586, <i64 32, i64 32>
  %1588 = mul nsw <2 x i64> %1587, %1483
  %1589 = lshr <2 x i64> %1579, <i64 16, i64 16>
  %1590 = shl <2 x i64> %1582, <i64 16, i64 16>
  %1591 = lshr <2 x i64> %1585, <i64 16, i64 16>
  %1592 = shl <2 x i64> %1588, <i64 16, i64 16>
  %1593 = bitcast <2 x i64> %1589 to <8 x i16>
  %1594 = bitcast <2 x i64> %1590 to <8 x i16>
  %1595 = shufflevector <8 x i16> %1593, <8 x i16> %1594, <8 x i32> <i32 0, i32 1, i32 10, i32 11, i32 4, i32 5, i32 14, i32 15>
  %1596 = bitcast <2 x i64> %1591 to <8 x i16>
  %1597 = bitcast <2 x i64> %1592 to <8 x i16>
  %1598 = shufflevector <8 x i16> %1596, <8 x i16> %1597, <8 x i32> <i32 0, i32 1, i32 10, i32 11, i32 4, i32 5, i32 14, i32 15>
  %1599 = bitcast <8 x i16> %1595 to <4 x i32>
  %1600 = add <4 x i32> %1599, <i32 128, i32 128, i32 128, i32 128>
  %1601 = bitcast <8 x i16> %1598 to <4 x i32>
  %1602 = add <4 x i32> %1601, <i32 128, i32 128, i32 128, i32 128>
  %1603 = ashr <4 x i32> %1600, <i32 8, i32 8, i32 8, i32 8>
  %1604 = ashr <4 x i32> %1602, <i32 8, i32 8, i32 8, i32 8>
  %1605 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1603, <4 x i32> %1604) #6
  %1606 = getelementptr inbounds i16, i16* %485, i64 %1563
  %1607 = bitcast i16* %1606 to <8 x i16>*
  store <8 x i16> %1605, <8 x i16>* %1607, align 1
  %1608 = add nuw nsw i64 %1563, 8
  %1609 = icmp slt i64 %1608, %1484
  br i1 %1609, label %1562, label %1485

1610:                                             ; preds = %1519, %1610
  %1611 = phi i64 [ %1643, %1610 ], [ %1520, %1519 ]
  %1612 = getelementptr inbounds i32, i32* %477, i64 %1611
  %1613 = load i32, i32* %1612, align 4
  %1614 = sext i32 %1613 to i64
  %1615 = mul nsw i64 %1614, %1491
  %1616 = lshr i64 %1615, 16
  %1617 = trunc i64 %1616 to i32
  %1618 = ashr i32 %1617, 7
  %1619 = add nsw i32 %1618, 1
  %1620 = lshr i32 %1619, 1
  %1621 = icmp sgt i32 %1617, 8388479
  %1622 = icmp slt i32 %1619, -65536
  %1623 = select i1 %1622, i32 32768, i32 %1620
  %1624 = select i1 %1621, i32 32767, i32 %1623
  %1625 = trunc i32 %1624 to i16
  %1626 = getelementptr inbounds i16, i16* %485, i64 %1611
  store i16 %1625, i16* %1626, align 2
  %1627 = add nuw nsw i64 %1611, 1
  %1628 = getelementptr inbounds i32, i32* %477, i64 %1627
  %1629 = load i32, i32* %1628, align 4
  %1630 = sext i32 %1629 to i64
  %1631 = mul nsw i64 %1630, %1491
  %1632 = lshr i64 %1631, 16
  %1633 = trunc i64 %1632 to i32
  %1634 = ashr i32 %1633, 7
  %1635 = add nsw i32 %1634, 1
  %1636 = lshr i32 %1635, 1
  %1637 = icmp sgt i32 %1633, 8388479
  %1638 = icmp slt i32 %1635, -65536
  %1639 = select i1 %1638, i32 32768, i32 %1636
  %1640 = select i1 %1637, i32 32767, i32 %1639
  %1641 = trunc i32 %1640 to i16
  %1642 = getelementptr inbounds i16, i16* %485, i64 %1627
  store i16 %1641, i16* %1642, align 2
  %1643 = add nuw nsw i64 %1611, 2
  %1644 = icmp eq i64 %1643, %1493
  br i1 %1644, label %1645, label %1610, !llvm.loop !14

1645:                                             ; preds = %1519, %1610, %1560, %1487
  %1646 = sext i32 %1128 to i64
  %1647 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 2, i64 %1646
  %1648 = bitcast i32* %1647 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %480, i8* align 4 %1648, i64 64, i1 false) #6
  br label %1653

1649:                                             ; preds = %1120
  %1650 = sext i8 %1122 to i32
  %1651 = load i32, i32* %420, align 8
  %1652 = load i32, i32* %421, align 4
  call void @silk_noise_shape_quantizer(%struct.silk_nsq_state* %1, i32 %1650, i32* nonnull %404, i8* %488, i16* %485, i32* nonnull %395, i16* %494, i16* %497, i16* %500, i32 %537, i32 %506, i32 %1124, i32 %1126, i32 %1127, i32 %13, i32 %33, i32 %1128, i32 %1115, i32 %1651, i32 %1652) #6
  br label %1653

1653:                                             ; preds = %1649, %1645
  %1654 = load i32, i32* %400, align 4
  %1655 = sext i32 %1654 to i64
  %1656 = getelementptr inbounds i32, i32* %487, i64 %1655
  %1657 = getelementptr inbounds i8, i8* %488, i64 %1655
  %1658 = getelementptr inbounds i16, i16* %485, i64 %1655
  %1659 = add nuw nsw i64 %484, 1
  %1660 = load i32, i32* %409, align 4
  %1661 = sext i32 %1660 to i64
  %1662 = icmp slt i64 %1659, %1661
  br i1 %1662, label %483, label %1663

1663:                                             ; preds = %1653, %15
  %1664 = phi i32 [ %410, %15 ], [ %1660, %1653 ]
  %1665 = add nsw i32 %1664, -1
  %1666 = sext i32 %1665 to i64
  %1667 = getelementptr inbounds i32, i32* %12, i64 %1666
  %1668 = load i32, i32* %1667, align 4
  store i32 %1668, i32* %22, align 4
  %1669 = bitcast %struct.silk_nsq_state* %1 to i8*
  %1670 = load i32, i32* %390, align 8
  %1671 = sext i32 %1670 to i64
  %1672 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 0, i64 %1671
  %1673 = bitcast i16* %1672 to i8*
  %1674 = load i32, i32* %388, align 8
  %1675 = sext i32 %1674 to i64
  %1676 = shl nsw i64 %1675, 1
  call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %1669, i8* align 2 %1673, i64 %1676, i1 false)
  %1677 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 1
  %1678 = bitcast [640 x i32]* %1677 to i8*
  %1679 = load i32, i32* %390, align 8
  %1680 = sext i32 %1679 to i64
  %1681 = getelementptr inbounds %struct.silk_nsq_state, %struct.silk_nsq_state* %1, i64 0, i32 1, i64 %1680
  %1682 = bitcast i32* %1681 to i8*
  %1683 = load i32, i32* %388, align 8
  %1684 = sext i32 %1683 to i64
  %1685 = shl nsw i64 %1684, 2
  call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %1678, i8* align 4 %1682, i64 %1685, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %17) #6
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: noreturn
declare void @celt_fatal(i8*, i8*, i32) local_unnamed_addr #2

declare void @silk_LPC_analysis_filter(i16*, i16*, i16*, i32, i32, i32) local_unnamed_addr #3

declare void @silk_noise_shape_quantizer(%struct.silk_nsq_state*, i32, i32*, i8*, i16*, i32*, i16*, i16*, i16*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #3

; Function Attrs: argmemonly nounwind
declare void @llvm.memmove.p0i8.p0i8.i64(i8* nocapture, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #4

; Function Attrs: nounwind readnone speculatable
declare i32 @llvm.ctlz.i32(i32, i1 immarg) #5

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind readnone speculatable }
attributes #6 = { nounwind }
attributes #7 = { noreturn nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 0, i32 33}
!3 = distinct !{!3, !4}
!4 = !{!"llvm.loop.unroll.disable"}
!5 = distinct !{!5, !4}
!6 = !{!"branch_weights", i32 2000, i32 1}
!7 = !{!8}
!8 = distinct !{!8, !9}
!9 = distinct !{!9, !"LVerDomain"}
!10 = !{!11}
!11 = distinct !{!11, !9}
!12 = distinct !{!12, !13}
!13 = !{!"llvm.loop.isvectorized", i32 1}
!14 = distinct !{!14, !13}
