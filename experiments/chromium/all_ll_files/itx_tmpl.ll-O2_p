; ModuleID = '../../third_party/dav1d/libdav1d/src/itx_tmpl.c'
source_filename = "../../third_party/dav1d/libdav1d/src/itx_tmpl.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.Dav1dInvTxfmDSPContext = type { [19 x [17 x void (i8*, i64, i16*, i32)*]] }

; Function Attrs: cold nounwind optsize ssp uwtable
define hidden void @dav1d_itx_dsp_init_8bpc(%struct.Dav1dInvTxfmDSPContext*, i32) local_unnamed_addr #0 {
  %3 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 0, i64 2
  %4 = bitcast %struct.Dav1dInvTxfmDSPContext* %0 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_4x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_4x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %4, align 8
  %5 = bitcast void (i8*, i64, i16*, i32)** %3 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_4x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_4x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %5, align 8
  %6 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 0, i64 8
  %7 = bitcast void (i8*, i64, i16*, i32)** %6 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_4x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_4x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %7, align 8
  %8 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 0, i64 4
  %9 = bitcast void (i8*, i64, i16*, i32)** %8 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_4x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_4x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %9, align 8
  %10 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 0, i64 6
  %11 = bitcast void (i8*, i64, i16*, i32)** %10 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_4x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_4x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %11, align 8
  %12 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 0, i64 10
  %13 = bitcast void (i8*, i64, i16*, i32)** %12 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_4x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_4x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %13, align 8
  %14 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 0, i64 15
  %15 = bitcast void (i8*, i64, i16*, i32)** %14 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_identity_4x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_wht_wht_4x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %15, align 8
  %16 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 0, i64 13
  %17 = bitcast void (i8*, i64, i16*, i32)** %16 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_identity_4x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_flipadst_4x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %17, align 8
  %18 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 0, i64 12
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_adst_4x4_c, void (i8*, i64, i16*, i32)** %18, align 8
  %19 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 0
  %20 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 2
  %21 = bitcast void (i8*, i64, i16*, i32)** %19 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_4x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_4x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %21, align 8
  %22 = bitcast void (i8*, i64, i16*, i32)** %20 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_4x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_4x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %22, align 8
  %23 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 8
  %24 = bitcast void (i8*, i64, i16*, i32)** %23 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_4x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_4x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %24, align 8
  %25 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 4
  %26 = bitcast void (i8*, i64, i16*, i32)** %25 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_4x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_4x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %26, align 8
  %27 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 6
  %28 = bitcast void (i8*, i64, i16*, i32)** %27 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_4x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_4x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %28, align 8
  %29 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 10
  %30 = bitcast void (i8*, i64, i16*, i32)** %29 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_4x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_4x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %30, align 8
  %31 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 15
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_identity_4x8_c, void (i8*, i64, i16*, i32)** %31, align 8
  %32 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 13
  %33 = bitcast void (i8*, i64, i16*, i32)** %32 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_identity_4x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_flipadst_4x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %33, align 8
  %34 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 5, i64 12
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_adst_4x8_c, void (i8*, i64, i16*, i32)** %34, align 8
  %35 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 0
  %36 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 2
  %37 = bitcast void (i8*, i64, i16*, i32)** %35 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_4x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_4x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %37, align 8
  %38 = bitcast void (i8*, i64, i16*, i32)** %36 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_4x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_4x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %38, align 8
  %39 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 8
  %40 = bitcast void (i8*, i64, i16*, i32)** %39 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_4x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_4x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %40, align 8
  %41 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 4
  %42 = bitcast void (i8*, i64, i16*, i32)** %41 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_4x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_4x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %42, align 8
  %43 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 6
  %44 = bitcast void (i8*, i64, i16*, i32)** %43 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_4x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_4x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %44, align 8
  %45 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 10
  %46 = bitcast void (i8*, i64, i16*, i32)** %45 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_4x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_4x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %46, align 8
  %47 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 15
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_identity_4x16_c, void (i8*, i64, i16*, i32)** %47, align 8
  %48 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 13
  %49 = bitcast void (i8*, i64, i16*, i32)** %48 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_identity_4x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_flipadst_4x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %49, align 8
  %50 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 13, i64 12
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_adst_4x16_c, void (i8*, i64, i16*, i32)** %50, align 8
  %51 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 0
  %52 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 2
  %53 = bitcast void (i8*, i64, i16*, i32)** %51 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_8x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_8x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %53, align 8
  %54 = bitcast void (i8*, i64, i16*, i32)** %52 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_8x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_8x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %54, align 8
  %55 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 8
  %56 = bitcast void (i8*, i64, i16*, i32)** %55 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_8x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_8x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %56, align 8
  %57 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 4
  %58 = bitcast void (i8*, i64, i16*, i32)** %57 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_8x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_8x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %58, align 8
  %59 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 6
  %60 = bitcast void (i8*, i64, i16*, i32)** %59 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_8x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_8x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %60, align 8
  %61 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 10
  %62 = bitcast void (i8*, i64, i16*, i32)** %61 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_8x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_8x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %62, align 8
  %63 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 15
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_identity_8x4_c, void (i8*, i64, i16*, i32)** %63, align 8
  %64 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 13
  %65 = bitcast void (i8*, i64, i16*, i32)** %64 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_identity_8x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_flipadst_8x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %65, align 8
  %66 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 6, i64 12
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_adst_8x4_c, void (i8*, i64, i16*, i32)** %66, align 8
  %67 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 0
  %68 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 2
  %69 = bitcast void (i8*, i64, i16*, i32)** %67 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_8x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_8x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %69, align 8
  %70 = bitcast void (i8*, i64, i16*, i32)** %68 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_8x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_8x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %70, align 8
  %71 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 8
  %72 = bitcast void (i8*, i64, i16*, i32)** %71 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_8x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_8x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %72, align 8
  %73 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 4
  %74 = bitcast void (i8*, i64, i16*, i32)** %73 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_8x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_8x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %74, align 8
  %75 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 6
  %76 = bitcast void (i8*, i64, i16*, i32)** %75 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_8x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_8x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %76, align 8
  %77 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 10
  %78 = bitcast void (i8*, i64, i16*, i32)** %77 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_8x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_8x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %78, align 8
  %79 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 15
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_identity_8x8_c, void (i8*, i64, i16*, i32)** %79, align 8
  %80 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 13
  %81 = bitcast void (i8*, i64, i16*, i32)** %80 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_identity_8x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_flipadst_8x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %81, align 8
  %82 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 1, i64 12
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_adst_8x8_c, void (i8*, i64, i16*, i32)** %82, align 8
  %83 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 0
  %84 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 2
  %85 = bitcast void (i8*, i64, i16*, i32)** %83 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_8x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_8x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %85, align 8
  %86 = bitcast void (i8*, i64, i16*, i32)** %84 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_8x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_8x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %86, align 8
  %87 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 8
  %88 = bitcast void (i8*, i64, i16*, i32)** %87 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_8x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_8x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %88, align 8
  %89 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 4
  %90 = bitcast void (i8*, i64, i16*, i32)** %89 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_8x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_8x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %90, align 8
  %91 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 6
  %92 = bitcast void (i8*, i64, i16*, i32)** %91 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_8x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_8x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %92, align 8
  %93 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 10
  %94 = bitcast void (i8*, i64, i16*, i32)** %93 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_8x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_8x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %94, align 8
  %95 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 15
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_identity_8x16_c, void (i8*, i64, i16*, i32)** %95, align 8
  %96 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 13
  %97 = bitcast void (i8*, i64, i16*, i32)** %96 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_identity_8x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_flipadst_8x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %97, align 8
  %98 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 7, i64 12
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_adst_8x16_c, void (i8*, i64, i16*, i32)** %98, align 8
  %99 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 15, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_8x32_c, void (i8*, i64, i16*, i32)** %99, align 8
  %100 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 15, i64 9
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_8x32_c, void (i8*, i64, i16*, i32)** %100, align 8
  %101 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 0
  %102 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 2
  %103 = bitcast void (i8*, i64, i16*, i32)** %101 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_16x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_16x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %103, align 8
  %104 = bitcast void (i8*, i64, i16*, i32)** %102 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_16x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_16x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %104, align 8
  %105 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 8
  %106 = bitcast void (i8*, i64, i16*, i32)** %105 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_16x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_16x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %106, align 8
  %107 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 4
  %108 = bitcast void (i8*, i64, i16*, i32)** %107 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_16x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_16x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %108, align 8
  %109 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 6
  %110 = bitcast void (i8*, i64, i16*, i32)** %109 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_16x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_16x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %110, align 8
  %111 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 10
  %112 = bitcast void (i8*, i64, i16*, i32)** %111 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_16x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_16x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %112, align 8
  %113 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 15
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_identity_16x4_c, void (i8*, i64, i16*, i32)** %113, align 8
  %114 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 14
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_flipadst_16x4_c, void (i8*, i64, i16*, i32)** %114, align 8
  %115 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 14, i64 12
  %116 = bitcast void (i8*, i64, i16*, i32)** %115 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_adst_16x4_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_identity_16x4_c>, <2 x void (i8*, i64, i16*, i32)*>* %116, align 8
  %117 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 0
  %118 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 2
  %119 = bitcast void (i8*, i64, i16*, i32)** %117 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_16x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_16x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %119, align 8
  %120 = bitcast void (i8*, i64, i16*, i32)** %118 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_16x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_16x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %120, align 8
  %121 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 8
  %122 = bitcast void (i8*, i64, i16*, i32)** %121 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_16x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_16x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %122, align 8
  %123 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 4
  %124 = bitcast void (i8*, i64, i16*, i32)** %123 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_16x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_16x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %124, align 8
  %125 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 6
  %126 = bitcast void (i8*, i64, i16*, i32)** %125 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_16x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_16x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %126, align 8
  %127 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 10
  %128 = bitcast void (i8*, i64, i16*, i32)** %127 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_16x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_16x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %128, align 8
  %129 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 15
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_identity_16x8_c, void (i8*, i64, i16*, i32)** %129, align 8
  %130 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 14
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_flipadst_16x8_c, void (i8*, i64, i16*, i32)** %130, align 8
  %131 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 8, i64 12
  %132 = bitcast void (i8*, i64, i16*, i32)** %131 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_adst_16x8_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_identity_16x8_c>, <2 x void (i8*, i64, i16*, i32)*>* %132, align 8
  %133 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 2, i64 0
  %134 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 2, i64 2
  %135 = bitcast void (i8*, i64, i16*, i32)** %133 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_16x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_adst_16x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %135, align 8
  %136 = bitcast void (i8*, i64, i16*, i32)** %134 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_dct_16x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_adst_16x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %136, align 8
  %137 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 2, i64 8
  %138 = bitcast void (i8*, i64, i16*, i32)** %137 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_adst_flipadst_16x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_16x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %138, align 8
  %139 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 2, i64 4
  %140 = bitcast void (i8*, i64, i16*, i32)** %139 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_flipadst_16x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_dct_16x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %140, align 8
  %141 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 2, i64 6
  %142 = bitcast void (i8*, i64, i16*, i32)** %141 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_flipadst_16x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_flipadst_adst_16x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %142, align 8
  %143 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 2, i64 10
  %144 = bitcast void (i8*, i64, i16*, i32)** %143 to <2 x void (i8*, i64, i16*, i32)*>*
  store <2 x void (i8*, i64, i16*, i32)*> <void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_dct_16x16_c, void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_identity_16x16_c>, <2 x void (i8*, i64, i16*, i32)*>* %144, align 8
  %145 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 9, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_16x32_c, void (i8*, i64, i16*, i32)** %145, align 8
  %146 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 9, i64 9
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_16x32_c, void (i8*, i64, i16*, i32)** %146, align 8
  %147 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 17, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_16x64_c, void (i8*, i64, i16*, i32)** %147, align 8
  %148 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 16, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_32x8_c, void (i8*, i64, i16*, i32)** %148, align 8
  %149 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 16, i64 9
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_32x8_c, void (i8*, i64, i16*, i32)** %149, align 8
  %150 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 10, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_32x16_c, void (i8*, i64, i16*, i32)** %150, align 8
  %151 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 10, i64 9
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_32x16_c, void (i8*, i64, i16*, i32)** %151, align 8
  %152 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 3, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_32x32_c, void (i8*, i64, i16*, i32)** %152, align 8
  %153 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 3, i64 9
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_identity_identity_32x32_c, void (i8*, i64, i16*, i32)** %153, align 8
  %154 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 11, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_32x64_c, void (i8*, i64, i16*, i32)** %154, align 8
  %155 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 18, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_64x16_c, void (i8*, i64, i16*, i32)** %155, align 8
  %156 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 12, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_64x32_c, void (i8*, i64, i16*, i32)** %156, align 8
  %157 = getelementptr inbounds %struct.Dav1dInvTxfmDSPContext, %struct.Dav1dInvTxfmDSPContext* %0, i64 0, i32 0, i64 4, i64 0
  store void (i8*, i64, i16*, i32)* @inv_txfm_add_dct_dct_64x64_c, void (i8*, i64, i16*, i32)** %157, align 8
  tail call void @dav1d_itx_dsp_init_x86_8bpc(%struct.Dav1dInvTxfmDSPContext* %0, i32 %1) #5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_wht_wht_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  %5 = alloca [16 x i32], align 16
  %6 = bitcast [16 x i32]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %6) #5
  %7 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 4
  %8 = bitcast i32* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 48, i1 false)
  %9 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 0
  %10 = load i16, i16* %2, align 2
  %11 = getelementptr inbounds i16, i16* %2, i64 4
  %12 = load i16, i16* %11, align 2
  %13 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 1
  %14 = getelementptr inbounds i16, i16* %2, i64 8
  %15 = load i16, i16* %14, align 2
  %16 = getelementptr inbounds i16, i16* %2, i64 12
  %17 = load i16, i16* %16, align 2
  %18 = insertelement <4 x i16> undef, i16 %10, i32 0
  %19 = insertelement <4 x i16> %18, i16 %12, i32 1
  %20 = insertelement <4 x i16> %19, i16 %15, i32 2
  %21 = insertelement <4 x i16> %20, i16 %17, i32 3
  %22 = ashr <4 x i16> %21, <i16 2, i16 2, i16 2, i16 2>
  %23 = sext <4 x i16> %22 to <4 x i32>
  %24 = bitcast [16 x i32]* %5 to <4 x i32>*
  store <4 x i32> %23, <4 x i32>* %24, align 16
  call void @dav1d_inv_wht4_1d_c(i32* nonnull %9, i64 1) #5
  %25 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 4
  %26 = getelementptr inbounds i16, i16* %2, i64 1
  %27 = load i16, i16* %26, align 2
  %28 = getelementptr inbounds i16, i16* %2, i64 5
  %29 = load i16, i16* %28, align 2
  %30 = getelementptr inbounds i16, i16* %2, i64 9
  %31 = load i16, i16* %30, align 2
  %32 = getelementptr inbounds i16, i16* %2, i64 13
  %33 = load i16, i16* %32, align 2
  %34 = insertelement <4 x i16> undef, i16 %27, i32 0
  %35 = insertelement <4 x i16> %34, i16 %29, i32 1
  %36 = insertelement <4 x i16> %35, i16 %31, i32 2
  %37 = insertelement <4 x i16> %36, i16 %33, i32 3
  %38 = ashr <4 x i16> %37, <i16 2, i16 2, i16 2, i16 2>
  %39 = sext <4 x i16> %38 to <4 x i32>
  %40 = bitcast i32* %25 to <4 x i32>*
  store <4 x i32> %39, <4 x i32>* %40, align 16
  call void @dav1d_inv_wht4_1d_c(i32* %25, i64 1) #5
  %41 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 8
  %42 = getelementptr inbounds i16, i16* %2, i64 2
  %43 = load i16, i16* %42, align 2
  %44 = getelementptr inbounds i16, i16* %2, i64 6
  %45 = load i16, i16* %44, align 2
  %46 = getelementptr inbounds i16, i16* %2, i64 10
  %47 = load i16, i16* %46, align 2
  %48 = getelementptr inbounds i16, i16* %2, i64 14
  %49 = load i16, i16* %48, align 2
  %50 = insertelement <4 x i16> undef, i16 %43, i32 0
  %51 = insertelement <4 x i16> %50, i16 %45, i32 1
  %52 = insertelement <4 x i16> %51, i16 %47, i32 2
  %53 = insertelement <4 x i16> %52, i16 %49, i32 3
  %54 = ashr <4 x i16> %53, <i16 2, i16 2, i16 2, i16 2>
  %55 = sext <4 x i16> %54 to <4 x i32>
  %56 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %55, <4 x i32>* %56, align 16
  call void @dav1d_inv_wht4_1d_c(i32* %41, i64 1) #5
  %57 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 12
  %58 = getelementptr inbounds i16, i16* %2, i64 3
  %59 = load i16, i16* %58, align 2
  %60 = getelementptr inbounds i16, i16* %2, i64 7
  %61 = load i16, i16* %60, align 2
  %62 = getelementptr inbounds i16, i16* %2, i64 11
  %63 = load i16, i16* %62, align 2
  %64 = getelementptr inbounds i16, i16* %2, i64 15
  %65 = load i16, i16* %64, align 2
  %66 = insertelement <4 x i16> undef, i16 %59, i32 0
  %67 = insertelement <4 x i16> %66, i16 %61, i32 1
  %68 = insertelement <4 x i16> %67, i16 %63, i32 2
  %69 = insertelement <4 x i16> %68, i16 %65, i32 3
  %70 = ashr <4 x i16> %69, <i16 2, i16 2, i16 2, i16 2>
  %71 = sext <4 x i16> %70 to <4 x i32>
  %72 = bitcast i32* %57 to <4 x i32>*
  store <4 x i32> %71, <4 x i32>* %72, align 16
  call void @dav1d_inv_wht4_1d_c(i32* %57, i64 1) #5
  %73 = bitcast i16* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 2 %73, i8 0, i64 32, i1 false)
  call void @dav1d_inv_wht4_1d_c(i32* nonnull %9, i64 4) #5
  %74 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 1
  call void @dav1d_inv_wht4_1d_c(i32* %74, i64 4) #5
  %75 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 2
  call void @dav1d_inv_wht4_1d_c(i32* %75, i64 4) #5
  %76 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 3
  call void @dav1d_inv_wht4_1d_c(i32* %76, i64 4) #5
  %77 = load i8, i8* %0, align 1
  %78 = zext i8 %77 to i32
  %79 = load i32, i32* %9, align 16
  %80 = add nsw i32 %79, %78
  %81 = icmp slt i32 %80, 255
  %82 = select i1 %81, i32 %80, i32 255
  %83 = icmp sgt i32 %82, 0
  %84 = select i1 %83, i32 %82, i32 0
  %85 = trunc i32 %84 to i8
  store i8 %85, i8* %0, align 1
  %86 = getelementptr inbounds i8, i8* %0, i64 1
  %87 = load i8, i8* %86, align 1
  %88 = zext i8 %87 to i32
  %89 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 2
  %90 = load i32, i32* %13, align 4
  %91 = add nsw i32 %90, %88
  %92 = icmp slt i32 %91, 255
  %93 = select i1 %92, i32 %91, i32 255
  %94 = icmp sgt i32 %93, 0
  %95 = select i1 %94, i32 %93, i32 0
  %96 = trunc i32 %95 to i8
  store i8 %96, i8* %86, align 1
  %97 = getelementptr inbounds i8, i8* %0, i64 2
  %98 = load i8, i8* %97, align 1
  %99 = zext i8 %98 to i32
  %100 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 3
  %101 = load i32, i32* %89, align 8
  %102 = add nsw i32 %101, %99
  %103 = icmp slt i32 %102, 255
  %104 = select i1 %103, i32 %102, i32 255
  %105 = icmp sgt i32 %104, 0
  %106 = select i1 %105, i32 %104, i32 0
  %107 = trunc i32 %106 to i8
  store i8 %107, i8* %97, align 1
  %108 = getelementptr inbounds i8, i8* %0, i64 3
  %109 = load i8, i8* %108, align 1
  %110 = zext i8 %109 to i32
  %111 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 4
  %112 = load i32, i32* %100, align 4
  %113 = add nsw i32 %112, %110
  %114 = icmp slt i32 %113, 255
  %115 = select i1 %114, i32 %113, i32 255
  %116 = icmp sgt i32 %115, 0
  %117 = select i1 %116, i32 %115, i32 0
  %118 = trunc i32 %117 to i8
  store i8 %118, i8* %108, align 1
  %119 = getelementptr inbounds i8, i8* %0, i64 %1
  %120 = load i8, i8* %119, align 1
  %121 = zext i8 %120 to i32
  %122 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 5
  %123 = load i32, i32* %111, align 16
  %124 = add nsw i32 %123, %121
  %125 = icmp slt i32 %124, 255
  %126 = select i1 %125, i32 %124, i32 255
  %127 = icmp sgt i32 %126, 0
  %128 = select i1 %127, i32 %126, i32 0
  %129 = trunc i32 %128 to i8
  store i8 %129, i8* %119, align 1
  %130 = getelementptr inbounds i8, i8* %119, i64 1
  %131 = load i8, i8* %130, align 1
  %132 = zext i8 %131 to i32
  %133 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 6
  %134 = load i32, i32* %122, align 4
  %135 = add nsw i32 %134, %132
  %136 = icmp slt i32 %135, 255
  %137 = select i1 %136, i32 %135, i32 255
  %138 = icmp sgt i32 %137, 0
  %139 = select i1 %138, i32 %137, i32 0
  %140 = trunc i32 %139 to i8
  store i8 %140, i8* %130, align 1
  %141 = getelementptr inbounds i8, i8* %119, i64 2
  %142 = load i8, i8* %141, align 1
  %143 = zext i8 %142 to i32
  %144 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 7
  %145 = load i32, i32* %133, align 8
  %146 = add nsw i32 %145, %143
  %147 = icmp slt i32 %146, 255
  %148 = select i1 %147, i32 %146, i32 255
  %149 = icmp sgt i32 %148, 0
  %150 = select i1 %149, i32 %148, i32 0
  %151 = trunc i32 %150 to i8
  store i8 %151, i8* %141, align 1
  %152 = getelementptr inbounds i8, i8* %119, i64 3
  %153 = load i8, i8* %152, align 1
  %154 = zext i8 %153 to i32
  %155 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 8
  %156 = load i32, i32* %144, align 4
  %157 = add nsw i32 %156, %154
  %158 = icmp slt i32 %157, 255
  %159 = select i1 %158, i32 %157, i32 255
  %160 = icmp sgt i32 %159, 0
  %161 = select i1 %160, i32 %159, i32 0
  %162 = trunc i32 %161 to i8
  store i8 %162, i8* %152, align 1
  %163 = getelementptr inbounds i8, i8* %119, i64 %1
  %164 = load i8, i8* %163, align 1
  %165 = zext i8 %164 to i32
  %166 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 9
  %167 = load i32, i32* %155, align 16
  %168 = add nsw i32 %167, %165
  %169 = icmp slt i32 %168, 255
  %170 = select i1 %169, i32 %168, i32 255
  %171 = icmp sgt i32 %170, 0
  %172 = select i1 %171, i32 %170, i32 0
  %173 = trunc i32 %172 to i8
  store i8 %173, i8* %163, align 1
  %174 = getelementptr inbounds i8, i8* %163, i64 1
  %175 = load i8, i8* %174, align 1
  %176 = zext i8 %175 to i32
  %177 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 10
  %178 = load i32, i32* %166, align 4
  %179 = add nsw i32 %178, %176
  %180 = icmp slt i32 %179, 255
  %181 = select i1 %180, i32 %179, i32 255
  %182 = icmp sgt i32 %181, 0
  %183 = select i1 %182, i32 %181, i32 0
  %184 = trunc i32 %183 to i8
  store i8 %184, i8* %174, align 1
  %185 = getelementptr inbounds i8, i8* %163, i64 2
  %186 = load i8, i8* %185, align 1
  %187 = zext i8 %186 to i32
  %188 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 11
  %189 = load i32, i32* %177, align 8
  %190 = add nsw i32 %189, %187
  %191 = icmp slt i32 %190, 255
  %192 = select i1 %191, i32 %190, i32 255
  %193 = icmp sgt i32 %192, 0
  %194 = select i1 %193, i32 %192, i32 0
  %195 = trunc i32 %194 to i8
  store i8 %195, i8* %185, align 1
  %196 = getelementptr inbounds i8, i8* %163, i64 3
  %197 = load i8, i8* %196, align 1
  %198 = zext i8 %197 to i32
  %199 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 12
  %200 = load i32, i32* %188, align 4
  %201 = add nsw i32 %200, %198
  %202 = icmp slt i32 %201, 255
  %203 = select i1 %202, i32 %201, i32 255
  %204 = icmp sgt i32 %203, 0
  %205 = select i1 %204, i32 %203, i32 0
  %206 = trunc i32 %205 to i8
  store i8 %206, i8* %196, align 1
  %207 = getelementptr inbounds i8, i8* %163, i64 %1
  %208 = load i8, i8* %207, align 1
  %209 = zext i8 %208 to i32
  %210 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 13
  %211 = load i32, i32* %199, align 16
  %212 = add nsw i32 %211, %209
  %213 = icmp slt i32 %212, 255
  %214 = select i1 %213, i32 %212, i32 255
  %215 = icmp sgt i32 %214, 0
  %216 = select i1 %215, i32 %214, i32 0
  %217 = trunc i32 %216 to i8
  store i8 %217, i8* %207, align 1
  %218 = getelementptr inbounds i8, i8* %207, i64 1
  %219 = load i8, i8* %218, align 1
  %220 = zext i8 %219 to i32
  %221 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 14
  %222 = load i32, i32* %210, align 4
  %223 = add nsw i32 %222, %220
  %224 = icmp slt i32 %223, 255
  %225 = select i1 %224, i32 %223, i32 255
  %226 = icmp sgt i32 %225, 0
  %227 = select i1 %226, i32 %225, i32 0
  %228 = trunc i32 %227 to i8
  store i8 %228, i8* %218, align 1
  %229 = getelementptr inbounds i8, i8* %207, i64 2
  %230 = load i8, i8* %229, align 1
  %231 = zext i8 %230 to i32
  %232 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 15
  %233 = load i32, i32* %221, align 8
  %234 = add nsw i32 %233, %231
  %235 = icmp slt i32 %234, 255
  %236 = select i1 %235, i32 %234, i32 255
  %237 = icmp sgt i32 %236, 0
  %238 = select i1 %237, i32 %236, i32 0
  %239 = trunc i32 %238 to i8
  store i8 %239, i8* %229, align 1
  %240 = getelementptr inbounds i8, i8* %207, i64 3
  %241 = load i8, i8* %240, align 1
  %242 = zext i8 %241 to i32
  %243 = load i32, i32* %232, align 4
  %244 = add nsw i32 %243, %242
  %245 = icmp slt i32 %244, 255
  %246 = select i1 %245, i32 %244, i32 255
  %247 = icmp sgt i32 %246, 0
  %248 = select i1 %247, i32 %246, i32 0
  %249 = trunc i32 %248 to i8
  store i8 %249, i8* %240, align 1
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %6) #5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_identity_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_flipadst_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_identity_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_adst_4x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_identity_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_flipadst_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_identity_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_adst_4x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 8, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_identity_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_flipadst_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_identity_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_adst_4x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 4, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_identity_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_flipadst_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_identity_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_adst_8x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 4, i32 0, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_identity_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_flipadst_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_identity_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_adst_8x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_identity_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_flipadst_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_identity_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_adst_8x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_8x32_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 32, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct32_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_8x32_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 8, i32 32, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity32_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_identity_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_flipadst_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_identity_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_adst_16x4_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 4, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst4_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_identity_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_flipadst_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_identity_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_adst_16x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 8, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_dct_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_adst_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_adst_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_adst_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_adst_flipadst_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_adst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_dct_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_flipadst_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_flipadst_flipadst_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_flipadst16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_identity_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_dct_16x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_16x32_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 32, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct32_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_16x32_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 32, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity32_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_16x64_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 16, i32 64, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct64_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_32x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 32, i32 8, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct32_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct8_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_32x8_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 32, i32 8, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity32_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity8_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_32x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 32, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct32_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_32x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 32, i32 16, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity32_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity16_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_32x32_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 32, i32 32, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct32_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct32_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_identity_identity_32x32_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 32, i32 32, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity32_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_identity32_1d_c, i32 0)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_32x64_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 32, i32 64, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct32_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct64_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_64x16_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 64, i32 16, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct64_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct16_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_64x32_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 64, i32 32, i32 1, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct64_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct32_1d_c, i32 1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @inv_txfm_add_dct_dct_64x64_c(i8* nocapture, i64, i16* nocapture, i32) #1 {
  tail call fastcc void @inv_txfm_add_c(i8* %0, i64 %1, i16* %2, i32 %3, i32 64, i32 64, i32 2, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct64_1d_c, void (i32*, i64, i32, i32)* nonnull @dav1d_inv_dct64_1d_c, i32 1)
  ret void
}

declare void @dav1d_itx_dsp_init_x86_8bpc(%struct.Dav1dInvTxfmDSPContext*, i32) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #3

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #3

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #3

declare void @dav1d_inv_wht4_1d_c(i32*, i64) local_unnamed_addr #2

; Function Attrs: noinline nounwind ssp uwtable
define internal fastcc void @inv_txfm_add_c(i8* nocapture, i64, i16* nocapture, i32, i32, i32, i32, void (i32*, i64, i32, i32)* nocapture, void (i32*, i64, i32, i32)* nocapture, i32) unnamed_addr #4 {
  %11 = alloca [4096 x i32], align 16
  %12 = icmp sgt i32 %3, -1
  tail call void @llvm.assume(i1 %12)
  %13 = shl nsw i32 %4, 1
  %14 = icmp eq i32 %13, %5
  %15 = shl nsw i32 %5, 1
  %16 = icmp eq i32 %15, %4
  %17 = or i1 %14, %16
  %18 = shl i32 1, %6
  %19 = ashr i32 %18, 1
  %20 = icmp slt i32 %3, %9
  br i1 %20, label %21, label %123

21:                                               ; preds = %10
  %22 = load i16, i16* %2, align 2
  %23 = sext i16 %22 to i32
  store i16 0, i16* %2, align 2
  br i1 %17, label %24, label %28

24:                                               ; preds = %21
  %25 = mul nsw i32 %23, 181
  %26 = add nsw i32 %25, 128
  %27 = ashr i32 %26, 8
  br label %28

28:                                               ; preds = %24, %21
  %29 = phi i32 [ %27, %24 ], [ %23, %21 ]
  %30 = mul nsw i32 %29, 181
  %31 = add nsw i32 %30, 128
  %32 = ashr i32 %31, 8
  %33 = add nsw i32 %32, %19
  %34 = ashr i32 %33, %6
  %35 = mul nsw i32 %34, 181
  %36 = add nsw i32 %35, 2176
  %37 = ashr i32 %36, 12
  %38 = icmp sgt i32 %5, 0
  br i1 %38, label %39, label %400

39:                                               ; preds = %28
  %40 = icmp sgt i32 %4, 0
  %41 = zext i32 %4 to i64
  %42 = and i64 %41, 4294967280
  %43 = add nsw i64 %42, -16
  %44 = lshr exact i64 %43, 4
  %45 = add nuw nsw i64 %44, 1
  %46 = icmp ult i32 %4, 16
  %47 = and i64 %41, 4294967280
  %48 = insertelement <16 x i32> undef, i32 %37, i32 0
  %49 = shufflevector <16 x i32> %48, <16 x i32> undef, <16 x i32> zeroinitializer
  %50 = and i64 %45, 1
  %51 = icmp eq i64 %43, 0
  %52 = sub nuw nsw i64 %45, %50
  %53 = icmp eq i64 %50, 0
  %54 = icmp eq i64 %47, %41
  br label %55

55:                                               ; preds = %106, %39
  %56 = phi i8* [ %0, %39 ], [ %108, %106 ]
  %57 = phi i32 [ 0, %39 ], [ %107, %106 ]
  br i1 %40, label %58, label %106

58:                                               ; preds = %55
  br i1 %46, label %59, label %61

59:                                               ; preds = %105, %58
  %60 = phi i64 [ 0, %58 ], [ %47, %105 ]
  br label %110

61:                                               ; preds = %58
  br i1 %51, label %91, label %62

62:                                               ; preds = %61, %62
  %63 = phi i64 [ %88, %62 ], [ 0, %61 ]
  %64 = phi i64 [ %89, %62 ], [ %52, %61 ]
  %65 = getelementptr inbounds i8, i8* %56, i64 %63
  %66 = bitcast i8* %65 to <16 x i8>*
  %67 = load <16 x i8>, <16 x i8>* %66, align 1
  %68 = zext <16 x i8> %67 to <16 x i32>
  %69 = add nsw <16 x i32> %49, %68
  %70 = icmp slt <16 x i32> %69, <i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255>
  %71 = select <16 x i1> %70, <16 x i32> %69, <16 x i32> <i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255>
  %72 = icmp sgt <16 x i32> %71, zeroinitializer
  %73 = select <16 x i1> %72, <16 x i32> %71, <16 x i32> zeroinitializer
  %74 = trunc <16 x i32> %73 to <16 x i8>
  %75 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %74, <16 x i8>* %75, align 1
  %76 = or i64 %63, 16
  %77 = getelementptr inbounds i8, i8* %56, i64 %76
  %78 = bitcast i8* %77 to <16 x i8>*
  %79 = load <16 x i8>, <16 x i8>* %78, align 1
  %80 = zext <16 x i8> %79 to <16 x i32>
  %81 = add nsw <16 x i32> %49, %80
  %82 = icmp slt <16 x i32> %81, <i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255>
  %83 = select <16 x i1> %82, <16 x i32> %81, <16 x i32> <i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255>
  %84 = icmp sgt <16 x i32> %83, zeroinitializer
  %85 = select <16 x i1> %84, <16 x i32> %83, <16 x i32> zeroinitializer
  %86 = trunc <16 x i32> %85 to <16 x i8>
  %87 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %86, <16 x i8>* %87, align 1
  %88 = add i64 %63, 32
  %89 = add i64 %64, -2
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %91, label %62, !llvm.loop !2

91:                                               ; preds = %62, %61
  %92 = phi i64 [ 0, %61 ], [ %88, %62 ]
  br i1 %53, label %105, label %93

93:                                               ; preds = %91
  %94 = getelementptr inbounds i8, i8* %56, i64 %92
  %95 = bitcast i8* %94 to <16 x i8>*
  %96 = load <16 x i8>, <16 x i8>* %95, align 1
  %97 = zext <16 x i8> %96 to <16 x i32>
  %98 = add nsw <16 x i32> %49, %97
  %99 = icmp slt <16 x i32> %98, <i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255>
  %100 = select <16 x i1> %99, <16 x i32> %98, <16 x i32> <i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255>
  %101 = icmp sgt <16 x i32> %100, zeroinitializer
  %102 = select <16 x i1> %101, <16 x i32> %100, <16 x i32> zeroinitializer
  %103 = trunc <16 x i32> %102 to <16 x i8>
  %104 = bitcast i8* %94 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 1
  br label %105

105:                                              ; preds = %91, %93
  br i1 %54, label %106, label %59

106:                                              ; preds = %110, %105, %55
  %107 = add nuw nsw i32 %57, 1
  %108 = getelementptr inbounds i8, i8* %56, i64 %1
  %109 = icmp eq i32 %107, %5
  br i1 %109, label %400, label %55

110:                                              ; preds = %59, %110
  %111 = phi i64 [ %121, %110 ], [ %60, %59 ]
  %112 = getelementptr inbounds i8, i8* %56, i64 %111
  %113 = load i8, i8* %112, align 1
  %114 = zext i8 %113 to i32
  %115 = add nsw i32 %37, %114
  %116 = icmp slt i32 %115, 255
  %117 = select i1 %116, i32 %115, i32 255
  %118 = icmp sgt i32 %117, 0
  %119 = select i1 %118, i32 %117, i32 0
  %120 = trunc i32 %119 to i8
  store i8 %120, i8* %112, align 1
  %121 = add nuw nsw i64 %111, 1
  %122 = icmp eq i64 %121, %41
  br i1 %122, label %106, label %110, !llvm.loop !4

123:                                              ; preds = %10
  %124 = icmp slt i32 %5, 32
  %125 = select i1 %124, i32 %5, i32 32
  %126 = icmp slt i32 %4, 32
  %127 = select i1 %126, i32 %4, i32 32
  %128 = bitcast [4096 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16384, i8* nonnull %128) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %128, i8 -86, i64 16384, i1 false)
  %129 = getelementptr inbounds [4096 x i32], [4096 x i32]* %11, i64 0, i64 0
  %130 = icmp sgt i32 %5, 0
  br i1 %130, label %134, label %131

131:                                              ; preds = %123
  %132 = sext i32 %127 to i64
  %133 = sext i32 %125 to i64
  br label %139

134:                                              ; preds = %123
  %135 = icmp sgt i32 %4, 0
  %136 = sext i32 %4 to i64
  %137 = sext i32 %125 to i64
  %138 = sext i32 %127 to i64
  br label %188

139:                                              ; preds = %216, %131
  %140 = phi i64 [ %133, %131 ], [ %137, %216 ]
  %141 = phi i64 [ %132, %131 ], [ %138, %216 ]
  %142 = bitcast i16* %2 to i8*
  %143 = shl nsw i64 %141, 1
  %144 = mul i64 %143, %140
  call void @llvm.memset.p0i8.i64(i8* align 2 %142, i8 0, i64 %144, i1 false)
  %145 = mul nsw i32 %125, %4
  %146 = icmp sgt i32 %145, 0
  br i1 %146, label %147, label %220

147:                                              ; preds = %139
  %148 = sext i32 %145 to i64
  %149 = icmp ult i32 %145, 8
  br i1 %149, label %150, label %152

150:                                              ; preds = %186, %147
  %151 = phi i64 [ 0, %147 ], [ %153, %186 ]
  br label %225

152:                                              ; preds = %147
  %153 = and i64 %148, -8
  %154 = insertelement <4 x i32> undef, i32 %19, i32 0
  %155 = shufflevector <4 x i32> %154, <4 x i32> undef, <4 x i32> zeroinitializer
  %156 = insertelement <4 x i32> undef, i32 %19, i32 0
  %157 = shufflevector <4 x i32> %156, <4 x i32> undef, <4 x i32> zeroinitializer
  %158 = insertelement <4 x i32> undef, i32 %6, i32 0
  %159 = shufflevector <4 x i32> %158, <4 x i32> undef, <4 x i32> zeroinitializer
  %160 = insertelement <4 x i32> undef, i32 %6, i32 0
  %161 = shufflevector <4 x i32> %160, <4 x i32> undef, <4 x i32> zeroinitializer
  br label %162

162:                                              ; preds = %162, %152
  %163 = phi i64 [ 0, %152 ], [ %184, %162 ]
  %164 = getelementptr inbounds [4096 x i32], [4096 x i32]* %11, i64 0, i64 %163
  %165 = bitcast i32* %164 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = getelementptr inbounds i32, i32* %164, i64 4
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16
  %170 = add nsw <4 x i32> %166, %155
  %171 = add nsw <4 x i32> %169, %157
  %172 = ashr <4 x i32> %170, %159
  %173 = ashr <4 x i32> %171, %161
  %174 = icmp slt <4 x i32> %172, <i32 32767, i32 32767, i32 32767, i32 32767>
  %175 = icmp slt <4 x i32> %173, <i32 32767, i32 32767, i32 32767, i32 32767>
  %176 = select <4 x i1> %174, <4 x i32> %172, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %177 = select <4 x i1> %175, <4 x i32> %173, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %178 = icmp sgt <4 x i32> %176, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %179 = icmp sgt <4 x i32> %177, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %180 = select <4 x i1> %178, <4 x i32> %176, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %181 = select <4 x i1> %179, <4 x i32> %177, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %182 = bitcast i32* %164 to <4 x i32>*
  store <4 x i32> %180, <4 x i32>* %182, align 16
  %183 = bitcast i32* %167 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %183, align 16
  %184 = add i64 %163, 8
  %185 = icmp eq i64 %184, %153
  br i1 %185, label %186, label %162, !llvm.loop !6

186:                                              ; preds = %162
  %187 = icmp eq i64 %153, %148
  br i1 %187, label %220, label %150

188:                                              ; preds = %134, %216
  %189 = phi i64 [ 0, %134 ], [ %217, %216 ]
  %190 = phi i32* [ %129, %134 ], [ %218, %216 ]
  br i1 %17, label %192, label %191

191:                                              ; preds = %188
  br i1 %135, label %206, label %216

192:                                              ; preds = %188
  br i1 %135, label %193, label %216

193:                                              ; preds = %192, %193
  %194 = phi i64 [ %204, %193 ], [ 0, %192 ]
  %195 = mul nsw i64 %194, %137
  %196 = add nsw i64 %195, %189
  %197 = getelementptr inbounds i16, i16* %2, i64 %196
  %198 = load i16, i16* %197, align 2
  %199 = sext i16 %198 to i32
  %200 = mul nsw i32 %199, 181
  %201 = add nsw i32 %200, 128
  %202 = ashr i32 %201, 8
  %203 = getelementptr inbounds i32, i32* %190, i64 %194
  store i32 %202, i32* %203, align 4
  %204 = add nuw nsw i64 %194, 1
  %205 = icmp slt i64 %204, %138
  br i1 %205, label %193, label %216

206:                                              ; preds = %191, %206
  %207 = phi i64 [ %214, %206 ], [ 0, %191 ]
  %208 = mul nsw i64 %207, %137
  %209 = add nsw i64 %208, %189
  %210 = getelementptr inbounds i16, i16* %2, i64 %209
  %211 = load i16, i16* %210, align 2
  %212 = sext i16 %211 to i32
  %213 = getelementptr inbounds i32, i32* %190, i64 %207
  store i32 %212, i32* %213, align 4
  %214 = add nuw nsw i64 %207, 1
  %215 = icmp slt i64 %214, %138
  br i1 %215, label %206, label %216

216:                                              ; preds = %206, %193, %191, %192
  call void %7(i32* %190, i64 1, i32 -32768, i32 32767) #5
  %217 = add nuw nsw i64 %189, 1
  %218 = getelementptr inbounds i32, i32* %190, i64 %136
  %219 = icmp slt i64 %217, %137
  br i1 %219, label %188, label %139

220:                                              ; preds = %225, %186, %139
  %221 = icmp sgt i32 %4, 0
  br i1 %221, label %222, label %237

222:                                              ; preds = %220
  %223 = sext i32 %4 to i64
  %224 = zext i32 %4 to i64
  br label %254

225:                                              ; preds = %150, %225
  %226 = phi i64 [ %235, %225 ], [ %151, %150 ]
  %227 = getelementptr inbounds [4096 x i32], [4096 x i32]* %11, i64 0, i64 %226
  %228 = load i32, i32* %227, align 4
  %229 = add nsw i32 %228, %19
  %230 = ashr i32 %229, %6
  %231 = icmp slt i32 %230, 32767
  %232 = select i1 %231, i32 %230, i32 32767
  %233 = icmp sgt i32 %232, -32768
  %234 = select i1 %233, i32 %232, i32 -32768
  store i32 %234, i32* %227, align 4
  %235 = add nuw nsw i64 %226, 1
  %236 = icmp slt i64 %235, %148
  br i1 %236, label %225, label %220, !llvm.loop !7

237:                                              ; preds = %254, %220
  br i1 %130, label %238, label %361

238:                                              ; preds = %237
  %239 = zext i32 %4 to i64
  %240 = and i64 %239, 4294967292
  %241 = add nsw i64 %240, -4
  %242 = lshr exact i64 %241, 2
  %243 = add nuw nsw i64 %242, 1
  %244 = icmp ult i32 %4, 4
  %245 = and i64 %239, 4294967292
  %246 = and i64 %243, 1
  %247 = icmp eq i64 %241, 0
  %248 = sub nuw nsw i64 %243, %246
  %249 = icmp eq i64 %246, 0
  %250 = icmp eq i64 %245, %239
  %251 = and i64 %239, 1
  %252 = icmp eq i64 %251, 0
  %253 = sub nsw i64 0, %239
  br label %259

254:                                              ; preds = %254, %222
  %255 = phi i64 [ 0, %222 ], [ %257, %254 ]
  %256 = getelementptr inbounds [4096 x i32], [4096 x i32]* %11, i64 0, i64 %255
  call void %8(i32* %256, i64 %223, i32 -32768, i32 32767) #5
  %257 = add nuw nsw i64 %255, 1
  %258 = icmp eq i64 %257, %224
  br i1 %258, label %237, label %254

259:                                              ; preds = %362, %238
  %260 = phi i64 [ %367, %362 ], [ 0, %238 ]
  %261 = phi i32 [ %364, %362 ], [ 0, %238 ]
  %262 = phi i32* [ %363, %362 ], [ %129, %238 ]
  %263 = phi i8* [ %365, %362 ], [ %0, %238 ]
  %264 = bitcast i32* %262 to i8*
  %265 = mul i64 %260, %1
  %266 = getelementptr i8, i8* %0, i64 %265
  %267 = add i64 %265, %239
  %268 = getelementptr i8, i8* %0, i64 %267
  br i1 %221, label %269, label %362

269:                                              ; preds = %259
  br i1 %244, label %270, label %294

270:                                              ; preds = %360, %294, %269
  %271 = phi i64 [ 0, %294 ], [ 0, %269 ], [ %245, %360 ]
  %272 = phi i32* [ %262, %294 ], [ %262, %269 ], [ %301, %360 ]
  %273 = xor i64 %271, -1
  br i1 %252, label %289, label %274

274:                                              ; preds = %270
  %275 = getelementptr inbounds i8, i8* %263, i64 %271
  %276 = load i8, i8* %275, align 1
  %277 = zext i8 %276 to i32
  %278 = getelementptr inbounds i32, i32* %272, i64 1
  %279 = load i32, i32* %272, align 4
  %280 = add nsw i32 %279, 8
  %281 = ashr i32 %280, 4
  %282 = add nsw i32 %281, %277
  %283 = icmp slt i32 %282, 255
  %284 = select i1 %283, i32 %282, i32 255
  %285 = icmp sgt i32 %284, 0
  %286 = select i1 %285, i32 %284, i32 0
  %287 = trunc i32 %286 to i8
  store i8 %287, i8* %275, align 1
  %288 = or i64 %271, 1
  br label %289

289:                                              ; preds = %274, %270
  %290 = phi i32* [ %278, %274 ], [ undef, %270 ]
  %291 = phi i64 [ %288, %274 ], [ %271, %270 ]
  %292 = phi i32* [ %278, %274 ], [ %272, %270 ]
  %293 = icmp eq i64 %273, %253
  br i1 %293, label %362, label %368

294:                                              ; preds = %269
  %295 = getelementptr i32, i32* %262, i64 %239
  %296 = bitcast i32* %295 to i8*
  %297 = icmp ult i8* %266, %296
  %298 = icmp ugt i8* %268, %264
  %299 = and i1 %297, %298
  br i1 %299, label %270, label %300

300:                                              ; preds = %294
  %301 = getelementptr i32, i32* %262, i64 %245
  br i1 %247, label %341, label %302

302:                                              ; preds = %300, %302
  %303 = phi i64 [ %338, %302 ], [ 0, %300 ]
  %304 = phi i64 [ %339, %302 ], [ %248, %300 ]
  %305 = getelementptr i32, i32* %262, i64 %303
  %306 = getelementptr inbounds i8, i8* %263, i64 %303
  %307 = bitcast i8* %306 to <4 x i8>*
  %308 = load <4 x i8>, <4 x i8>* %307, align 1, !alias.scope !8, !noalias !11
  %309 = zext <4 x i8> %308 to <4 x i32>
  %310 = bitcast i32* %305 to <4 x i32>*
  %311 = load <4 x i32>, <4 x i32>* %310, align 4, !alias.scope !11
  %312 = add nsw <4 x i32> %311, <i32 8, i32 8, i32 8, i32 8>
  %313 = ashr <4 x i32> %312, <i32 4, i32 4, i32 4, i32 4>
  %314 = add nsw <4 x i32> %313, %309
  %315 = icmp slt <4 x i32> %314, <i32 255, i32 255, i32 255, i32 255>
  %316 = select <4 x i1> %315, <4 x i32> %314, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %317 = icmp sgt <4 x i32> %316, zeroinitializer
  %318 = select <4 x i1> %317, <4 x i32> %316, <4 x i32> zeroinitializer
  %319 = trunc <4 x i32> %318 to <4 x i8>
  %320 = bitcast i8* %306 to <4 x i8>*
  store <4 x i8> %319, <4 x i8>* %320, align 1, !alias.scope !8, !noalias !11
  %321 = or i64 %303, 4
  %322 = getelementptr i32, i32* %262, i64 %321
  %323 = getelementptr inbounds i8, i8* %263, i64 %321
  %324 = bitcast i8* %323 to <4 x i8>*
  %325 = load <4 x i8>, <4 x i8>* %324, align 1, !alias.scope !8, !noalias !11
  %326 = zext <4 x i8> %325 to <4 x i32>
  %327 = bitcast i32* %322 to <4 x i32>*
  %328 = load <4 x i32>, <4 x i32>* %327, align 4, !alias.scope !11
  %329 = add nsw <4 x i32> %328, <i32 8, i32 8, i32 8, i32 8>
  %330 = ashr <4 x i32> %329, <i32 4, i32 4, i32 4, i32 4>
  %331 = add nsw <4 x i32> %330, %326
  %332 = icmp slt <4 x i32> %331, <i32 255, i32 255, i32 255, i32 255>
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %334 = icmp sgt <4 x i32> %333, zeroinitializer
  %335 = select <4 x i1> %334, <4 x i32> %333, <4 x i32> zeroinitializer
  %336 = trunc <4 x i32> %335 to <4 x i8>
  %337 = bitcast i8* %323 to <4 x i8>*
  store <4 x i8> %336, <4 x i8>* %337, align 1, !alias.scope !8, !noalias !11
  %338 = add i64 %303, 8
  %339 = add i64 %304, -2
  %340 = icmp eq i64 %339, 0
  br i1 %340, label %341, label %302, !llvm.loop !13

341:                                              ; preds = %302, %300
  %342 = phi i64 [ 0, %300 ], [ %338, %302 ]
  br i1 %249, label %360, label %343

343:                                              ; preds = %341
  %344 = getelementptr i32, i32* %262, i64 %342
  %345 = getelementptr inbounds i8, i8* %263, i64 %342
  %346 = bitcast i8* %345 to <4 x i8>*
  %347 = load <4 x i8>, <4 x i8>* %346, align 1, !alias.scope !8, !noalias !11
  %348 = zext <4 x i8> %347 to <4 x i32>
  %349 = bitcast i32* %344 to <4 x i32>*
  %350 = load <4 x i32>, <4 x i32>* %349, align 4, !alias.scope !11
  %351 = add nsw <4 x i32> %350, <i32 8, i32 8, i32 8, i32 8>
  %352 = ashr <4 x i32> %351, <i32 4, i32 4, i32 4, i32 4>
  %353 = add nsw <4 x i32> %352, %348
  %354 = icmp slt <4 x i32> %353, <i32 255, i32 255, i32 255, i32 255>
  %355 = select <4 x i1> %354, <4 x i32> %353, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %356 = icmp sgt <4 x i32> %355, zeroinitializer
  %357 = select <4 x i1> %356, <4 x i32> %355, <4 x i32> zeroinitializer
  %358 = trunc <4 x i32> %357 to <4 x i8>
  %359 = bitcast i8* %345 to <4 x i8>*
  store <4 x i8> %358, <4 x i8>* %359, align 1, !alias.scope !8, !noalias !11
  br label %360

360:                                              ; preds = %341, %343
  br i1 %250, label %362, label %270

361:                                              ; preds = %362, %237
  call void @llvm.lifetime.end.p0i8(i64 16384, i8* nonnull %128) #5
  br label %400

362:                                              ; preds = %289, %368, %360, %259
  %363 = phi i32* [ %262, %259 ], [ %301, %360 ], [ %290, %289 ], [ %388, %368 ]
  %364 = add nuw nsw i32 %261, 1
  %365 = getelementptr inbounds i8, i8* %263, i64 %1
  %366 = icmp eq i32 %364, %5
  %367 = add i64 %260, 1
  br i1 %366, label %361, label %259

368:                                              ; preds = %289, %368
  %369 = phi i64 [ %398, %368 ], [ %291, %289 ]
  %370 = phi i32* [ %388, %368 ], [ %292, %289 ]
  %371 = getelementptr inbounds i8, i8* %263, i64 %369
  %372 = load i8, i8* %371, align 1
  %373 = zext i8 %372 to i32
  %374 = getelementptr inbounds i32, i32* %370, i64 1
  %375 = load i32, i32* %370, align 4
  %376 = add nsw i32 %375, 8
  %377 = ashr i32 %376, 4
  %378 = add nsw i32 %377, %373
  %379 = icmp slt i32 %378, 255
  %380 = select i1 %379, i32 %378, i32 255
  %381 = icmp sgt i32 %380, 0
  %382 = select i1 %381, i32 %380, i32 0
  %383 = trunc i32 %382 to i8
  store i8 %383, i8* %371, align 1
  %384 = add nuw nsw i64 %369, 1
  %385 = getelementptr inbounds i8, i8* %263, i64 %384
  %386 = load i8, i8* %385, align 1
  %387 = zext i8 %386 to i32
  %388 = getelementptr inbounds i32, i32* %370, i64 2
  %389 = load i32, i32* %374, align 4
  %390 = add nsw i32 %389, 8
  %391 = ashr i32 %390, 4
  %392 = add nsw i32 %391, %387
  %393 = icmp slt i32 %392, 255
  %394 = select i1 %393, i32 %392, i32 255
  %395 = icmp sgt i32 %394, 0
  %396 = select i1 %395, i32 %394, i32 0
  %397 = trunc i32 %396 to i8
  store i8 %397, i8* %385, align 1
  %398 = add nuw nsw i64 %369, 2
  %399 = icmp eq i64 %398, %239
  br i1 %399, label %362, label %368, !llvm.loop !14

400:                                              ; preds = %106, %28, %361
  ret void
}

declare void @dav1d_inv_dct4_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_identity4_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_adst4_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_flipadst4_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_dct8_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_identity8_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_adst8_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_flipadst8_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_dct16_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_identity16_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_adst16_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_flipadst16_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_dct32_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_identity32_1d_c(i32*, i64, i32, i32) #2

declare void @dav1d_inv_dct64_1d_c(i32*, i64, i32, i32) #2

; Function Attrs: nounwind
declare void @llvm.assume(i1) #5

attributes #0 = { cold nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { argmemonly nounwind }
attributes #4 = { noinline nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = distinct !{!2, !3}
!3 = !{!"llvm.loop.isvectorized", i32 1}
!4 = distinct !{!4, !5, !3}
!5 = !{!"llvm.loop.unroll.runtime.disable"}
!6 = distinct !{!6, !3}
!7 = distinct !{!7, !5, !3}
!8 = !{!9}
!9 = distinct !{!9, !10}
!10 = distinct !{!10, !"LVerDomain"}
!11 = !{!12}
!12 = distinct !{!12, !10}
!13 = distinct !{!13, !3}
!14 = distinct !{!14, !3}
