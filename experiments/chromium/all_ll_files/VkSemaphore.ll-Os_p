; ModuleID = '../../third_party/swiftshader/src/Vulkan/VkSemaphore.cpp'
source_filename = "../../third_party/swiftshader/src/Vulkan/VkSemaphore.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.marl::Allocator" = type { i32 (...)** }
%"struct.std::__1::__function::__policy" = type { i8* (i8*)*, void (i8*)*, i8, %"class.std::type_info"* }
%"class.std::type_info" = type { i32 (...)**, i8* }
%"struct.vk::SemaphoreCreateInfo" = type { i8, i32, i32, i64 }
%struct.VkSemaphoreCreateInfo = type { i32, i8*, i32 }
%"class.vk::Semaphore" = type { i32 (...)**, i32, %"class.marl::mutex" }
%"class.marl::mutex" = type { %"class.std::__1::mutex" }
%"class.std::__1::mutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.vk::BinarySemaphore" = type { %"class.vk::Semaphore", %struct.VkAllocationCallbacks*, i32, %"class.marl::Event", %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"* }
%"class.marl::Event" = type { %"class.std::__1::shared_ptr" }
%"class.std::__1::shared_ptr" = type { %"struct.marl::Event::Shared"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::Event::Shared" = type <{ %"class.marl::mutex", %"class.marl::ConditionVariable", %"class.marl::containers::vector", i8, i8, [6 x i8] }>
%"class.marl::ConditionVariable" = type { %"class.marl::mutex", %"class.marl::containers::list", %"class.std::__1::condition_variable", %"struct.std::__1::atomic", %"struct.std::__1::atomic" }
%"class.marl::containers::list" = type { %"class.marl::Allocator"*, i64, i64, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain" = type { %"struct.marl::Allocation", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* }
%"struct.marl::Allocation" = type { i8*, %"struct.marl::Allocation::Request" }
%"struct.marl::Allocation::Request" = type <{ i64, i64, i8, i8, [6 x i8] }>
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry" = type { %"class.marl::Scheduler::Fiber"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"class.marl::Scheduler::Fiber" = type <{ i32, [4 x i8], %"class.std::__1::unique_ptr", %"class.marl::Scheduler::Worker"*, i32, [4 x i8] }>
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair.46" }
%"class.std::__1::__compressed_pair.46" = type { %"struct.std::__1::__compressed_pair_elem.47", %"struct.std::__1::__compressed_pair_elem.48" }
%"struct.std::__1::__compressed_pair_elem.47" = type { %"class.marl::OSFiber"* }
%"class.marl::OSFiber" = type opaque
%"struct.std::__1::__compressed_pair_elem.48" = type { %"struct.marl::Allocator::Deleter" }
%"struct.marl::Allocator::Deleter" = type { %"class.marl::Allocator"*, i64 }
%"class.marl::Scheduler::Worker" = type <{ i32, i32, %"class.marl::Scheduler"*, %"class.std::__1::unique_ptr.73", %"class.marl::Scheduler::Fiber"*, %"class.marl::Thread", %"struct.marl::Scheduler::Worker::Work", %"class.std::__1::unordered_set", %"class.marl::containers::vector.155", %"class.marl::Scheduler::Worker::FastRnd", i8, [7 x i8] }>
%"class.marl::Scheduler" = type { %"struct.marl::Scheduler::Config", %"struct.std::__1::array", %"struct.std::__1::atomic.50", %"struct.std::__1::atomic.50", %"struct.std::__1::array.55", %"struct.marl::Scheduler::SingleThreadedWorkers" }
%"struct.marl::Scheduler::Config" = type { %"struct.marl::Scheduler::Config::WorkerThread", %"class.marl::Allocator"*, i64 }
%"struct.marl::Scheduler::Config::WorkerThread" = type { i32, %"class.std::__1::function", %"class.std::__1::shared_ptr.49" }
%"class.std::__1::function" = type { %"class.std::__1::__function::__policy_func" }
%"class.std::__1::__function::__policy_func" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker", %"struct.std::__1::__function::__policy"* }
%"union.std::__1::__function::__policy_storage" = type { i8*, [8 x i8] }
%"struct.std::__1::__function::__policy_invoker" = type { void (%"union.std::__1::__function::__policy_storage"*, i32)* }
%"class.std::__1::shared_ptr.49" = type { %"class.marl::Thread::Affinity::Policy"*, %"class.std::__1::__shared_weak_count"* }
%"class.marl::Thread::Affinity::Policy" = type { i32 (...)** }
%"struct.std::__1::array" = type { [8 x %"struct.std::__1::atomic"] }
%"struct.std::__1::atomic.50" = type { %"struct.std::__1::__atomic_base.51" }
%"struct.std::__1::__atomic_base.51" = type { %"struct.std::__1::__atomic_base.52" }
%"struct.std::__1::__atomic_base.52" = type { %"struct.std::__1::__cxx_atomic_impl.53" }
%"struct.std::__1::__cxx_atomic_impl.53" = type { %"struct.std::__1::__cxx_atomic_base_impl.54" }
%"struct.std::__1::__cxx_atomic_base_impl.54" = type { i32 }
%"struct.std::__1::array.55" = type { [256 x %"class.marl::Scheduler::Worker"*] }
%"struct.marl::Scheduler::SingleThreadedWorkers" = type { %"class.marl::mutex", %"class.std::__1::condition_variable", %"class.std::__1::unordered_map" }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.56", %"class.std::__1::__compressed_pair.63", %"class.std::__1::__compressed_pair.67", %"class.std::__1::__compressed_pair.70", [4 x i8] }>
%"class.std::__1::unique_ptr.56" = type { %"class.std::__1::__compressed_pair.57" }
%"class.std::__1::__compressed_pair.57" = type { %"struct.std::__1::__compressed_pair_elem.58", %"struct.std::__1::__compressed_pair_elem.59" }
%"struct.std::__1::__compressed_pair_elem.58" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.59" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.60" }
%"class.std::__1::__compressed_pair.60" = type { %"struct.std::__1::__compressed_pair_elem.61", %"struct.std::__1::__compressed_pair_elem.62" }
%"struct.std::__1::__compressed_pair_elem.61" = type { i64 }
%"struct.std::__1::__compressed_pair_elem.62" = type { %"struct.marl::StlAllocator" }
%"struct.marl::StlAllocator" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.63" = type { %"struct.std::__1::__compressed_pair_elem.64", %"struct.std::__1::__compressed_pair_elem.65" }
%"struct.std::__1::__compressed_pair_elem.64" = type { %"struct.std::__1::__hash_node_base" }
%"struct.std::__1::__compressed_pair_elem.65" = type { %"struct.marl::StlAllocator.66" }
%"struct.marl::StlAllocator.66" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.67" = type { %"struct.std::__1::__compressed_pair_elem.61" }
%"class.std::__1::__compressed_pair.70" = type { %"struct.std::__1::__compressed_pair_elem.71" }
%"struct.std::__1::__compressed_pair_elem.71" = type { float }
%"class.std::__1::unique_ptr.73" = type { %"class.std::__1::__compressed_pair.74" }
%"class.std::__1::__compressed_pair.74" = type { %"struct.std::__1::__compressed_pair_elem.75", %"struct.std::__1::__compressed_pair_elem.48" }
%"struct.std::__1::__compressed_pair_elem.75" = type { %"class.marl::Scheduler::Fiber"* }
%"class.marl::Thread" = type { %"class.marl::Thread::Impl"* }
%"class.marl::Thread::Impl" = type opaque
%"struct.marl::Scheduler::Worker::Work" = type { %"struct.std::__1::atomic.76", i64, %"class.std::__1::deque", %"class.std::__1::deque.93", %"struct.marl::Scheduler::WaitingFibers", i8, %"class.std::__1::condition_variable", %"class.marl::mutex" }
%"struct.std::__1::atomic.76" = type { %"struct.std::__1::__atomic_base.77" }
%"struct.std::__1::__atomic_base.77" = type { %"struct.std::__1::__atomic_base.78" }
%"struct.std::__1::__atomic_base.78" = type { %"struct.std::__1::__cxx_atomic_impl.79" }
%"struct.std::__1::__cxx_atomic_impl.79" = type { %"struct.std::__1::__cxx_atomic_base_impl.80" }
%"struct.std::__1::__cxx_atomic_base_impl.80" = type { i64 }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.90" }
%"struct.std::__1::__split_buffer" = type { %"class.marl::Task"**, %"class.marl::Task"**, %"class.marl::Task"**, %"class.std::__1::__compressed_pair.86" }
%"class.marl::Task" = type <{ %"class.std::__1::function.81", i32, [4 x i8] }>
%"class.std::__1::function.81" = type { %"class.std::__1::__function::__policy_func.84" }
%"class.std::__1::__function::__policy_func.84" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker.85", %"struct.std::__1::__function::__policy"* }
%"struct.std::__1::__function::__policy_invoker.85" = type { void (%"union.std::__1::__function::__policy_storage"*)* }
%"class.std::__1::__compressed_pair.86" = type { %"struct.std::__1::__compressed_pair_elem.87", %"struct.std::__1::__compressed_pair_elem.88" }
%"struct.std::__1::__compressed_pair_elem.87" = type { %"class.marl::Task"** }
%"struct.std::__1::__compressed_pair_elem.88" = type { %"struct.marl::StlAllocator.89" }
%"struct.marl::StlAllocator.89" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.90" = type { %"struct.std::__1::__compressed_pair_elem.61", %"struct.std::__1::__compressed_pair_elem.91" }
%"struct.std::__1::__compressed_pair_elem.91" = type { %"struct.marl::StlAllocator.92" }
%"struct.marl::StlAllocator.92" = type { %"class.marl::Allocator"* }
%"class.std::__1::deque.93" = type { %"class.std::__1::__deque_base.94" }
%"class.std::__1::__deque_base.94" = type { %"struct.std::__1::__split_buffer.95", i64, %"class.std::__1::__compressed_pair.100" }
%"struct.std::__1::__split_buffer.95" = type { %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.std::__1::__compressed_pair.96" }
%"class.std::__1::__compressed_pair.96" = type { %"struct.std::__1::__compressed_pair_elem.97", %"struct.std::__1::__compressed_pair_elem.98" }
%"struct.std::__1::__compressed_pair_elem.97" = type { %"class.marl::Scheduler::Fiber"*** }
%"struct.std::__1::__compressed_pair_elem.98" = type { %"struct.marl::StlAllocator.99" }
%"struct.marl::StlAllocator.99" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.100" = type { %"struct.std::__1::__compressed_pair_elem.61", %"struct.std::__1::__compressed_pair_elem.101" }
%"struct.std::__1::__compressed_pair_elem.101" = type { %"struct.marl::StlAllocator.102" }
%"struct.marl::StlAllocator.102" = type { %"class.marl::Allocator"* }
%"struct.marl::Scheduler::WaitingFibers" = type { %"class.std::__1::set", %"class.std::__1::unordered_map.110" }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.103", %"class.std::__1::__compressed_pair.107" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type opaque
%"class.std::__1::__compressed_pair.103" = type { %"struct.std::__1::__compressed_pair_elem.104", %"struct.std::__1::__compressed_pair_elem.105" }
%"struct.std::__1::__compressed_pair_elem.104" = type { %"class.std::__1::__tree_end_node" }
%"struct.std::__1::__compressed_pair_elem.105" = type { %"struct.marl::StlAllocator.106" }
%"struct.marl::StlAllocator.106" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.107" = type { %"struct.std::__1::__compressed_pair_elem.61" }
%"class.std::__1::unordered_map.110" = type { %"class.std::__1::__hash_table.111" }
%"class.std::__1::__hash_table.111" = type <{ %"class.std::__1::unique_ptr.112", %"class.std::__1::__compressed_pair.121", %"class.std::__1::__compressed_pair.125", %"class.std::__1::__compressed_pair.130", [4 x i8] }>
%"class.std::__1::unique_ptr.112" = type { %"class.std::__1::__compressed_pair.113" }
%"class.std::__1::__compressed_pair.113" = type { %"struct.std::__1::__compressed_pair_elem.114", %"struct.std::__1::__compressed_pair_elem.116" }
%"struct.std::__1::__compressed_pair_elem.114" = type { %"struct.std::__1::__hash_node_base.115"** }
%"struct.std::__1::__hash_node_base.115" = type { %"struct.std::__1::__hash_node_base.115"* }
%"struct.std::__1::__compressed_pair_elem.116" = type { %"class.std::__1::__bucket_list_deallocator.117" }
%"class.std::__1::__bucket_list_deallocator.117" = type { %"class.std::__1::__compressed_pair.118" }
%"class.std::__1::__compressed_pair.118" = type { %"struct.std::__1::__compressed_pair_elem.61", %"struct.std::__1::__compressed_pair_elem.119" }
%"struct.std::__1::__compressed_pair_elem.119" = type { %"struct.marl::StlAllocator.120" }
%"struct.marl::StlAllocator.120" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.121" = type { %"struct.std::__1::__compressed_pair_elem.122", %"struct.std::__1::__compressed_pair_elem.123" }
%"struct.std::__1::__compressed_pair_elem.122" = type { %"struct.std::__1::__hash_node_base.115" }
%"struct.std::__1::__compressed_pair_elem.123" = type { %"struct.marl::StlAllocator.124" }
%"struct.marl::StlAllocator.124" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.125" = type { %"struct.std::__1::__compressed_pair_elem.61" }
%"class.std::__1::__compressed_pair.130" = type { %"struct.std::__1::__compressed_pair_elem.71" }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.136" }
%"class.std::__1::__hash_table.136" = type <{ %"class.std::__1::unique_ptr.137", %"class.std::__1::__compressed_pair.146", %"class.std::__1::__compressed_pair.150", %"class.std::__1::__compressed_pair.152", [4 x i8] }>
%"class.std::__1::unique_ptr.137" = type { %"class.std::__1::__compressed_pair.138" }
%"class.std::__1::__compressed_pair.138" = type { %"struct.std::__1::__compressed_pair_elem.139", %"struct.std::__1::__compressed_pair_elem.141" }
%"struct.std::__1::__compressed_pair_elem.139" = type { %"struct.std::__1::__hash_node_base.140"** }
%"struct.std::__1::__hash_node_base.140" = type { %"struct.std::__1::__hash_node_base.140"* }
%"struct.std::__1::__compressed_pair_elem.141" = type { %"class.std::__1::__bucket_list_deallocator.142" }
%"class.std::__1::__bucket_list_deallocator.142" = type { %"class.std::__1::__compressed_pair.143" }
%"class.std::__1::__compressed_pair.143" = type { %"struct.std::__1::__compressed_pair_elem.61", %"struct.std::__1::__compressed_pair_elem.144" }
%"struct.std::__1::__compressed_pair_elem.144" = type { %"struct.marl::StlAllocator.145" }
%"struct.marl::StlAllocator.145" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.146" = type { %"struct.std::__1::__compressed_pair_elem.147", %"struct.std::__1::__compressed_pair_elem.148" }
%"struct.std::__1::__compressed_pair_elem.147" = type { %"struct.std::__1::__hash_node_base.140" }
%"struct.std::__1::__compressed_pair_elem.148" = type { %"struct.marl::StlAllocator.149" }
%"struct.marl::StlAllocator.149" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.150" = type { %"struct.std::__1::__compressed_pair_elem.61" }
%"class.std::__1::__compressed_pair.152" = type { %"struct.std::__1::__compressed_pair_elem.71" }
%"class.marl::containers::vector.155" = type { %"class.marl::Allocator"*, i64, i64, [16 x %"struct.marl::aligned_storage<24, 8>::type"], %"struct.marl::aligned_storage<24, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<24, 8>::type" = type { [24 x i8] }
%"class.marl::Scheduler::Worker::FastRnd" = type { i64 }
%"class.std::__1::condition_variable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon.37, %union.anon.39, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon.37 = type { i64 }
%union.anon.39 = type { i64 }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.41" }
%"struct.std::__1::__atomic_base.41" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"class.marl::containers::vector" = type { %"class.marl::Allocator"*, i64, i64, [1 x %"struct.marl::aligned_storage<16, 8>::type"], %"struct.marl::aligned_storage<16, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<16, 8>::type" = type { [16 x i8] }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.vk::BinarySemaphore::External" = type { i32 (...)**, %"class.vk::BinarySemaphore::External"* }
%struct.VkAllocationCallbacks = type { i8*, i8* (i8*, i64, i64, i32)*, i8* (i8*, i8*, i64, i64, i32)*, void (i8*, i8*)*, void (i8*, i64, i32, i32)*, void (i8*, i64, i32, i32)* }
%class.VkNonDispatchableHandle = type { i64 }
%class.VkNonDispatchableHandle.0 = type { i64 }
%class.VkNonDispatchableHandle.1 = type { i64 }
%class.VkNonDispatchableHandle.2 = type { i64 }
%class.VkNonDispatchableHandle.3 = type { i64 }
%class.VkNonDispatchableHandle.4 = type { i64 }
%class.VkNonDispatchableHandle.5 = type { i64 }
%class.VkNonDispatchableHandle.6 = type { i64 }
%class.VkNonDispatchableHandle.7 = type { i64 }
%class.VkNonDispatchableHandle.8 = type { i64 }
%class.VkNonDispatchableHandle.9 = type { i64 }
%class.VkNonDispatchableHandle.10 = type { i64 }
%class.VkNonDispatchableHandle.11 = type { i64 }
%class.VkNonDispatchableHandle.12 = type { i64 }
%class.VkNonDispatchableHandle.13 = type { i64 }
%class.VkNonDispatchableHandle.14 = type { i64 }
%class.VkNonDispatchableHandle.15 = type { i64 }
%class.VkNonDispatchableHandle.16 = type { i64 }
%class.VkNonDispatchableHandle.17 = type { i64 }
%class.VkNonDispatchableHandle.18 = type { i64 }
%class.VkNonDispatchableHandle.19 = type { i64 }
%class.VkNonDispatchableHandle.20 = type { i64 }
%class.VkNonDispatchableHandle.21 = type { i64 }
%class.VkNonDispatchableHandle.22 = type { i64 }
%class.VkNonDispatchableHandle.23 = type { i64 }
%class.VkNonDispatchableHandle.24 = type { i64 }
%class.VkNonDispatchableHandle.25 = type { i64 }
%class.VkNonDispatchableHandle.26 = type { i64 }
%class.VkNonDispatchableHandle.27 = type { i64 }
%class.VkNonDispatchableHandle.28 = type { i64 }
%class.VkNonDispatchableHandle.29 = type { i64 }
%class.VkNonDispatchableHandle.30 = type { i64 }
%class.VkNonDispatchableHandle.31 = type { i64 }
%class.VkNonDispatchableHandle.32 = type { i64 }
%class.VkNonDispatchableHandle.33 = type { i64 }
%class.VkNonDispatchableHandle.34 = type { i64 }
%class.VkNonDispatchableHandle.35 = type { i64 }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon }
%union.anon = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%struct.VkBaseInStructure = type { i32, %struct.VkBaseInStructure* }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__short" = type { [23 x i8], %struct.anon }
%struct.anon = type { i8 }
%"class.marl::lock" = type { %"class.std::__1::unique_lock" }
%"class.std::__1::unique_lock" = type <{ %"class.std::__1::mutex"*, i8, [7 x i8] }>
%class.anon.156 = type { %"struct.marl::Event::Shared"* }
%class.anon.193 = type { %"class.marl::WaitGroup"* }
%"class.marl::WaitGroup" = type { %"class.std::__1::shared_ptr.171" }
%"class.std::__1::shared_ptr.171" = type { %"struct.marl::WaitGroup::Data"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::WaitGroup::Data" = type { %"struct.std::__1::atomic.50", %"class.marl::ConditionVariable", %"class.marl::mutex" }
%"class.std::__1::unique_ptr.184" = type { %"class.std::__1::__compressed_pair.185" }
%"class.std::__1::__compressed_pair.185" = type { %"struct.std::__1::__compressed_pair_elem.186" }
%"struct.std::__1::__compressed_pair_elem.186" = type { %"class.std::__1::tuple"* }
%"class.std::__1::tuple" = type { %"struct.std::__1::__tuple_impl" }
%"struct.std::__1::__tuple_impl" = type { %"class.std::__1::__tuple_leaf", %"class.std::__1::__tuple_leaf.187" }
%"class.std::__1::__tuple_leaf" = type { %"class.std::__1::unique_ptr.180" }
%"class.std::__1::unique_ptr.180" = type { %"class.std::__1::__compressed_pair.181" }
%"class.std::__1::__compressed_pair.181" = type { %"struct.std::__1::__compressed_pair_elem.182" }
%"struct.std::__1::__compressed_pair_elem.182" = type { %"class.std::__1::__thread_struct"* }
%"class.std::__1::__thread_struct" = type { %"class.std::__1::__thread_struct_imp"* }
%"class.std::__1::__thread_struct_imp" = type opaque
%"class.std::__1::__tuple_leaf.187" = type { %class.anon.172 }
%class.anon.172 = type { %"class.marl::WaitGroup", %"class.marl::Scheduler"**, %class.anon* }
%class.anon = type { %"class.vk::BinarySemaphore::External"* }
%"class.std::__1::thread" = type { i64 }
%union.pthread_attr_t = type { i64, [48 x i8] }
%class.SharedSemaphore = type <{ %union.pthread_mutex_t, %union.pthread_cond_t, i32, i8, [3 x i8] }>
%"class.std::__1::function.157" = type { %"class.std::__1::__function::__policy_func.160" }
%"class.std::__1::__function::__policy_func.160" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker.161", %"struct.std::__1::__function::__policy"* }
%"struct.std::__1::__function::__policy_invoker.161" = type { i1 (%"union.std::__1::__function::__policy_storage"*)* }
%"class.std::__1::__shared_ptr_pointer" = type { %"class.std::__1::__shared_weak_count", %"class.std::__1::__compressed_pair.162" }
%"class.std::__1::__compressed_pair.162" = type { %"struct.std::__1::__compressed_pair_elem.163" }
%"struct.std::__1::__compressed_pair_elem.163" = type { %"class.std::__1::__compressed_pair.164" }
%"class.std::__1::__compressed_pair.164" = type { %"struct.std::__1::__compressed_pair_elem.165", %"struct.std::__1::__compressed_pair_elem.48" }
%"struct.std::__1::__compressed_pair_elem.165" = type { %"struct.marl::Event::Shared"* }
%"struct.std::__1::__shared_ptr_emplace" = type { %"class.std::__1::__shared_weak_count", %"struct.std::__1::__shared_ptr_emplace<marl::WaitGroup::Data, std::__1::allocator<marl::WaitGroup::Data> >::_Storage" }
%"struct.std::__1::__shared_ptr_emplace<marl::WaitGroup::Data, std::__1::allocator<marl::WaitGroup::Data> >::_Storage" = type { [192 x i8] }
%"class.std::__1::__thread_specific_ptr" = type { i32 }
%"class.vk::OpaqueFdExternalSemaphore" = type { %"class.vk::BinarySemaphore::External", %class.LinuxMemFd, %class.SharedSemaphore* }
%class.LinuxMemFd = type { i32 }
%union.pthread_mutexattr_t = type { i32 }
%union.pthread_condattr_t = type { i32 }

$_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm = comdat any

$_ZN2vk15BinarySemaphoreD2Ev = comdat any

$_ZN2vk15BinarySemaphoreD0Ev = comdat any

$_ZN2vk9SemaphoreD2Ev = comdat any

$_ZN2vk9SemaphoreD0Ev = comdat any

$_ZN2vk9Semaphore7destroyEPK21VkAllocationCallbacks = comdat any

$_ZNSt3__111unique_lockINS_5mutexEE6unlockEv = comdat any

$_ZNSt3__111unique_lockINS_5mutexEE4lockEv = comdat any

$_ZN4marl17ConditionVariable4waitIZNS_5Event6Shared4waitEvEUlvE_EEvRNS_4lockEOT_ = comdat any

$_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE = comdat any

$_ZN4marl5Event6Shared6signalEv = comdat any

$_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEED0Ev = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv = comdat any

$_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED2Ev = comdat any

$_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED0Ev = comdat any

$_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE16__on_zero_sharedEv = comdat any

$_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE21__on_zero_shared_weakEv = comdat any

$_ZNSt3__110shared_ptrIN4marl9WaitGroup4DataEED2Ev = comdat any

$_ZNSt3__110unique_ptrINS_15__thread_structENS_14default_deleteIS1_EEE5resetEPS1_ = comdat any

$_ZN4marl17ConditionVariable4waitIZNKS_9WaitGroup4waitEvEUlvE_EEvRNS_4lockEOT_ = comdat any

$_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZNK4marl9WaitGroup4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE = comdat any

$_ZN2vk25OpaqueFdExternalSemaphoreD2Ev = comdat any

$_ZN2vk25OpaqueFdExternalSemaphoreD0Ev = comdat any

$_ZN2vk25OpaqueFdExternalSemaphore4initEb = comdat any

$_ZN2vk25OpaqueFdExternalSemaphore7tryWaitEv = comdat any

$_ZN2vk25OpaqueFdExternalSemaphore4waitEv = comdat any

$_ZN2vk25OpaqueFdExternalSemaphore6signalEv = comdat any

$_ZN2vk25OpaqueFdExternalSemaphore14importOpaqueFdEi = comdat any

$_ZN2vk25OpaqueFdExternalSemaphore14exportOpaqueFdEPi = comdat any

$_ZN2vk25OpaqueFdExternalSemaphore11unmapRegionEv = comdat any

$_ZN2vk25OpaqueFdExternalSemaphore9mapRegionEmbb = comdat any

$_ZN15SharedSemaphoreC2Eb = comdat any

$_ZN15SharedSemaphore7tryWaitEv = comdat any

$_ZN15SharedSemaphore4waitEv = comdat any

$_ZN15SharedSemaphore6signalEv = comdat any

$_ZTVN2vk9SemaphoreE = comdat any

$_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_ = comdat any

$_ZTVNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEEE = comdat any

$_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE = comdat any

$_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZNK4marl9WaitGroup4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_ = comdat any

$_ZTVN2vk25OpaqueFdExternalSemaphoreE = comdat any

$_ZZN2vk25OpaqueFdExternalSemaphore4initEbE7counter = comdat any

@.str = private unnamed_addr constant [74 x i8] c"%s:%d WARNING: UNSUPPORTED: exportInfo->handleTypes 0x%X (supports 0x%X)\0A\00", align 1
@.str.1 = private unnamed_addr constant [57 x i8] c"../../third_party/swiftshader/src/Vulkan/VkSemaphore.cpp\00", align 1
@.str.2 = private unnamed_addr constant [37 x i8] c"%s:%d WARNING: nextInfo->sType = %s\0A\00", align 1
@_ZTVN2vk9SemaphoreE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.vk::Semaphore"*)* @_ZN2vk9SemaphoreD2Ev to i8*), i8* bitcast (void (%"class.vk::Semaphore"*)* @_ZN2vk9SemaphoreD0Ev to i8*), i8* bitcast (void (%"class.vk::Semaphore"*, %struct.VkAllocationCallbacks*)* @_ZN2vk9Semaphore7destroyEPK21VkAllocationCallbacks to i8*)] }, comdat, align 8
@_ZTVN2vk15BinarySemaphoreE = hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.vk::BinarySemaphore"*)* @_ZN2vk15BinarySemaphoreD2Ev to i8*), i8* bitcast (void (%"class.vk::BinarySemaphore"*)* @_ZN2vk15BinarySemaphoreD0Ev to i8*), i8* bitcast (void (%"class.vk::BinarySemaphore"*, %struct.VkAllocationCallbacks*)* @_ZN2vk15BinarySemaphore7destroyEPK21VkAllocationCallbacks to i8*)] }, align 8
@_ZN4marl9Allocator7DefaultE = external local_unnamed_addr global %"class.marl::Allocator"*, align 8
@.str.3 = private unnamed_addr constant [92 x i8] c"%s:%d TRACE: Cannot export semaphore as opaque FD (exportableHandleType = 0x%X, want 0x%X)\0A\00", align 1
@.str.4 = private unnamed_addr constant [32 x i8] c"unique_lock::unlock: not locked\00", align 1
@.str.5 = private unnamed_addr constant [41 x i8] c"unique_lock::lock: references null mutex\00", align 1
@.str.6 = private unnamed_addr constant [34 x i8] c"unique_lock::lock: already locked\00", align 1
@_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_ = linkonce_odr hidden constant %"struct.std::__1::__function::__policy" zeroinitializer, comdat, align 8
@_ZTVNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEEE = linkonce_odr hidden unnamed_addr constant { [7 x i8*] } { [7 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.std::__1::__shared_weak_count"*)* @_ZNSt3__119__shared_weak_countD2Ev to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEED0Ev to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv to i8*), i8* bitcast (i8* (%"class.std::__1::__shared_weak_count"*, %"class.std::type_info"*)* @_ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv to i8*)] }, comdat, align 8
@_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE = linkonce_odr hidden unnamed_addr constant { [7 x i8*] } { [7 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.std::__1::__shared_ptr_emplace"*)* @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED2Ev to i8*), i8* bitcast (void (%"struct.std::__1::__shared_ptr_emplace"*)* @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED0Ev to i8*), i8* bitcast (void (%"struct.std::__1::__shared_ptr_emplace"*)* @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE16__on_zero_sharedEv to i8*), i8* bitcast (i8* (%"class.std::__1::__shared_weak_count"*, %"class.std::type_info"*)* @_ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info to i8*), i8* bitcast (void (%"struct.std::__1::__shared_ptr_emplace"*)* @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE21__on_zero_shared_weakEv to i8*)] }, comdat, align 8
@.str.8 = private unnamed_addr constant [26 x i8] c"thread constructor failed\00", align 1
@_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZNK4marl9WaitGroup4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_ = linkonce_odr hidden constant %"struct.std::__1::__function::__policy" zeroinitializer, comdat, align 8
@_ZTVN2vk25OpaqueFdExternalSemaphoreE = linkonce_odr hidden unnamed_addr constant { [10 x i8*] } { [10 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.vk::OpaqueFdExternalSemaphore"*)* @_ZN2vk25OpaqueFdExternalSemaphoreD2Ev to i8*), i8* bitcast (void (%"class.vk::OpaqueFdExternalSemaphore"*)* @_ZN2vk25OpaqueFdExternalSemaphoreD0Ev to i8*), i8* bitcast (i32 (%"class.vk::OpaqueFdExternalSemaphore"*, i1)* @_ZN2vk25OpaqueFdExternalSemaphore4initEb to i8*), i8* bitcast (i1 (%"class.vk::OpaqueFdExternalSemaphore"*)* @_ZN2vk25OpaqueFdExternalSemaphore7tryWaitEv to i8*), i8* bitcast (void (%"class.vk::OpaqueFdExternalSemaphore"*)* @_ZN2vk25OpaqueFdExternalSemaphore4waitEv to i8*), i8* bitcast (void (%"class.vk::OpaqueFdExternalSemaphore"*)* @_ZN2vk25OpaqueFdExternalSemaphore6signalEv to i8*), i8* bitcast (i32 (%"class.vk::OpaqueFdExternalSemaphore"*, i32)* @_ZN2vk25OpaqueFdExternalSemaphore14importOpaqueFdEi to i8*), i8* bitcast (i32 (%"class.vk::OpaqueFdExternalSemaphore"*, i32*)* @_ZN2vk25OpaqueFdExternalSemaphore14exportOpaqueFdEPi to i8*)] }, comdat, align 8
@_ZZN2vk25OpaqueFdExternalSemaphore4initEbE7counter = linkonce_odr hidden local_unnamed_addr global i32 0, comdat, align 4
@.str.9 = private unnamed_addr constant [25 x i8] c"SwiftShader.Semaphore.%d\00", align 1
@.str.10 = private unnamed_addr constant [43 x i8] c"%s:%d TRACE: memfd.allocate() returned %s\0A\00", align 1
@.str.11 = private unnamed_addr constant [70 x i8] c"../../third_party/swiftshader/src/Vulkan/VkSemaphoreExternalLinux.hpp\00", align 1
@.str.12 = private unnamed_addr constant [32 x i8] c"%s:%d TRACE: mmap() failed: %s\0A\00", align 1
@.str.13 = private unnamed_addr constant [63 x i8] c"%s:%d TRACE: Cannot export semaphore with a temporary import!\0A\00", align 1

@_ZN2vk19SemaphoreCreateInfoC1EPK21VkSemaphoreCreateInfo = hidden unnamed_addr alias void (%"struct.vk::SemaphoreCreateInfo"*, %struct.VkSemaphoreCreateInfo*), void (%"struct.vk::SemaphoreCreateInfo"*, %struct.VkSemaphoreCreateInfo*)* @_ZN2vk19SemaphoreCreateInfoC2EPK21VkSemaphoreCreateInfo
@_ZN2vk9SemaphoreC1E15VkSemaphoreType = hidden unnamed_addr alias void (%"class.vk::Semaphore"*, i32), void (%"class.vk::Semaphore"*, i32)* @_ZN2vk9SemaphoreC2E15VkSemaphoreType
@_ZN2vk15BinarySemaphoreC1EPK21VkSemaphoreCreateInfoPvPK21VkAllocationCallbacks = hidden unnamed_addr alias void (%"class.vk::BinarySemaphore"*, %struct.VkSemaphoreCreateInfo*, i8*, %struct.VkAllocationCallbacks*), void (%"class.vk::BinarySemaphore"*, %struct.VkSemaphoreCreateInfo*, i8*, %struct.VkAllocationCallbacks*)* @_ZN2vk15BinarySemaphoreC2EPK21VkSemaphoreCreateInfoPvPK21VkAllocationCallbacks

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv(%class.VkNonDispatchableHandle*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm(%class.VkNonDispatchableHandle*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle, %class.VkNonDispatchableHandle* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv(%class.VkNonDispatchableHandle.0*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.0* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm(%class.VkNonDispatchableHandle.0*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.0, %class.VkNonDispatchableHandle.0* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv(%class.VkNonDispatchableHandle.1*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.1* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm(%class.VkNonDispatchableHandle.1*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.1, %class.VkNonDispatchableHandle.1* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv(%class.VkNonDispatchableHandle.2*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.2* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm(%class.VkNonDispatchableHandle.2*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.2, %class.VkNonDispatchableHandle.2* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv(%class.VkNonDispatchableHandle.3*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.3* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm(%class.VkNonDispatchableHandle.3*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.3, %class.VkNonDispatchableHandle.3* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv(%class.VkNonDispatchableHandle.4*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.4* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm(%class.VkNonDispatchableHandle.4*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.4, %class.VkNonDispatchableHandle.4* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv(%class.VkNonDispatchableHandle.5*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.5* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm(%class.VkNonDispatchableHandle.5*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.5, %class.VkNonDispatchableHandle.5* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv(%class.VkNonDispatchableHandle.6*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.6* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm(%class.VkNonDispatchableHandle.6*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.6, %class.VkNonDispatchableHandle.6* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv(%class.VkNonDispatchableHandle.7*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.7* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm(%class.VkNonDispatchableHandle.7*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.7, %class.VkNonDispatchableHandle.7* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv(%class.VkNonDispatchableHandle.8*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.8* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm(%class.VkNonDispatchableHandle.8*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.8, %class.VkNonDispatchableHandle.8* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv(%class.VkNonDispatchableHandle.9*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.9* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm(%class.VkNonDispatchableHandle.9*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.9, %class.VkNonDispatchableHandle.9* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv(%class.VkNonDispatchableHandle.10*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.10* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm(%class.VkNonDispatchableHandle.10*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.10, %class.VkNonDispatchableHandle.10* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv(%class.VkNonDispatchableHandle.11*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.11* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm(%class.VkNonDispatchableHandle.11*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.11, %class.VkNonDispatchableHandle.11* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv(%class.VkNonDispatchableHandle.12*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.12* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm(%class.VkNonDispatchableHandle.12*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.12, %class.VkNonDispatchableHandle.12* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv(%class.VkNonDispatchableHandle.13*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.13* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm(%class.VkNonDispatchableHandle.13*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.13, %class.VkNonDispatchableHandle.13* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv(%class.VkNonDispatchableHandle.14*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.14* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm(%class.VkNonDispatchableHandle.14*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.14, %class.VkNonDispatchableHandle.14* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv(%class.VkNonDispatchableHandle.15*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.15* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm(%class.VkNonDispatchableHandle.15*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.15, %class.VkNonDispatchableHandle.15* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv(%class.VkNonDispatchableHandle.16*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.16* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm(%class.VkNonDispatchableHandle.16*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.16, %class.VkNonDispatchableHandle.16* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv(%class.VkNonDispatchableHandle.17*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.17* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm(%class.VkNonDispatchableHandle.17*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.17, %class.VkNonDispatchableHandle.17* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv(%class.VkNonDispatchableHandle.18*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.18* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm(%class.VkNonDispatchableHandle.18*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.18, %class.VkNonDispatchableHandle.18* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv(%class.VkNonDispatchableHandle.19*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.19* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm(%class.VkNonDispatchableHandle.19*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.19, %class.VkNonDispatchableHandle.19* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv(%class.VkNonDispatchableHandle.20*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.20* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm(%class.VkNonDispatchableHandle.20*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.20, %class.VkNonDispatchableHandle.20* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv(%class.VkNonDispatchableHandle.21*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.21* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm(%class.VkNonDispatchableHandle.21*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.21, %class.VkNonDispatchableHandle.21* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv(%class.VkNonDispatchableHandle.22*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.22* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm(%class.VkNonDispatchableHandle.22*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.22, %class.VkNonDispatchableHandle.22* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv(%class.VkNonDispatchableHandle.23*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.23* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm(%class.VkNonDispatchableHandle.23*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.23, %class.VkNonDispatchableHandle.23* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv(%class.VkNonDispatchableHandle.24*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.24* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm(%class.VkNonDispatchableHandle.24*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.24, %class.VkNonDispatchableHandle.24* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv(%class.VkNonDispatchableHandle.25*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.25* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm(%class.VkNonDispatchableHandle.25*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.25, %class.VkNonDispatchableHandle.25* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv(%class.VkNonDispatchableHandle.26*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.26* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm(%class.VkNonDispatchableHandle.26*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.26, %class.VkNonDispatchableHandle.26* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv(%class.VkNonDispatchableHandle.27*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.27* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm(%class.VkNonDispatchableHandle.27*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.27, %class.VkNonDispatchableHandle.27* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv(%class.VkNonDispatchableHandle.28*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.28* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm(%class.VkNonDispatchableHandle.28*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.28, %class.VkNonDispatchableHandle.28* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv(%class.VkNonDispatchableHandle.29*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.29* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm(%class.VkNonDispatchableHandle.29*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.29, %class.VkNonDispatchableHandle.29* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv(%class.VkNonDispatchableHandle.30*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.30* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm(%class.VkNonDispatchableHandle.30*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.30, %class.VkNonDispatchableHandle.30* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv(%class.VkNonDispatchableHandle.31*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.31* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm(%class.VkNonDispatchableHandle.31*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.31, %class.VkNonDispatchableHandle.31* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv(%class.VkNonDispatchableHandle.32*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.32* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm(%class.VkNonDispatchableHandle.32*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.32, %class.VkNonDispatchableHandle.32* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv(%class.VkNonDispatchableHandle.33*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.33* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm(%class.VkNonDispatchableHandle.33*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.33, %class.VkNonDispatchableHandle.33* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv(%class.VkNonDispatchableHandle.34*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.34* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm(%class.VkNonDispatchableHandle.34*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.34, %class.VkNonDispatchableHandle.34* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv(%class.VkNonDispatchableHandle.35*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.35* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm(%class.VkNonDispatchableHandle.35*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.35, %class.VkNonDispatchableHandle.35* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk19SemaphoreCreateInfoC2EPK21VkSemaphoreCreateInfo(%"struct.vk::SemaphoreCreateInfo"* nocapture, %struct.VkSemaphoreCreateInfo* nocapture readonly) unnamed_addr #0 align 2 {
  %3 = alloca %"class.std::__1::basic_string", align 8
  %4 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %0, i64 0, i32 0
  store i8 0, i8* %4, align 8
  %5 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %0, i64 0, i32 1
  store i32 0, i32* %5, align 4
  %6 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %0, i64 0, i32 2
  store i32 0, i32* %6, align 8
  %7 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %0, i64 0, i32 3
  store i64 0, i64* %7, align 8
  %8 = getelementptr inbounds %struct.VkSemaphoreCreateInfo, %struct.VkSemaphoreCreateInfo* %1, i64 0, i32 1
  %9 = bitcast i8** %8 to %struct.VkBaseInStructure**
  %10 = load %struct.VkBaseInStructure*, %struct.VkBaseInStructure** %9, align 8
  %11 = icmp eq %struct.VkBaseInStructure* %10, null
  br i1 %11, label %17, label %12

12:                                               ; preds = %2
  %13 = bitcast %"class.std::__1::basic_string"* %3 to i8*
  %14 = bitcast %"class.std::__1::basic_string"* %3 to %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__short"*
  %15 = getelementptr inbounds %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__short", %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__short"* %14, i64 0, i32 1, i32 0
  %16 = getelementptr inbounds %"class.std::__1::basic_string", %"class.std::__1::basic_string"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %18

17:                                               ; preds = %43, %2
  ret void

18:                                               ; preds = %12, %43
  %19 = phi %struct.VkBaseInStructure* [ %10, %12 ], [ %45, %43 ]
  %20 = getelementptr inbounds %struct.VkBaseInStructure, %struct.VkBaseInStructure* %19, i64 0, i32 0
  %21 = load i32, i32* %20, align 8
  switch i32 %21, label %33 [
    i32 1000077000, label %22
    i32 1000207002, label %27
  ]

22:                                               ; preds = %18
  store i8 1, i8* %4, align 8
  %23 = getelementptr inbounds %struct.VkBaseInStructure, %struct.VkBaseInStructure* %19, i64 1, i32 0
  %24 = load i32, i32* %23, align 8
  store i32 %24, i32* %5, align 4
  %25 = icmp ugt i32 %24, 1
  br i1 %25, label %26, label %43

26:                                               ; preds = %22
  call void (i8*, ...) @_ZN2sw4warnEPKcz(i8* getelementptr inbounds ([74 x i8], [74 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.1, i64 0, i64 0), i32 112, i32 %24, i32 1) #12
  br label %43

27:                                               ; preds = %18
  %28 = getelementptr inbounds %struct.VkBaseInStructure, %struct.VkBaseInStructure* %19, i64 1, i32 0
  %29 = load i32, i32* %28, align 8
  store i32 %29, i32* %6, align 8
  %30 = getelementptr inbounds %struct.VkBaseInStructure, %struct.VkBaseInStructure* %19, i64 1, i32 1
  %31 = bitcast %struct.VkBaseInStructure** %30 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %7, align 8
  br label %43

33:                                               ; preds = %18
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %13) #13
  call void @_ZN2vk9StringifyE15VkStructureType(%"class.std::__1::basic_string"* nonnull sret %3, i32 %21) #12
  %34 = load i8, i8* %15, align 1
  %35 = icmp slt i8 %34, 0
  %36 = load i8*, i8** %16, align 8
  %37 = select i1 %35, i8* %36, i8* %13
  call void (i8*, ...) @_ZN2sw4warnEPKcz(i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.2, i64 0, i64 0), i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.1, i64 0, i64 0), i32 124, i8* %37) #12
  %38 = load i8, i8* %15, align 1
  %39 = icmp slt i8 %38, 0
  br i1 %39, label %40, label %42

40:                                               ; preds = %33
  %41 = load i8*, i8** %16, align 8
  call void @_ZdlPv(i8* %41) #14
  br label %42

42:                                               ; preds = %33, %40
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %13) #13
  br label %43

43:                                               ; preds = %22, %26, %27, %42
  %44 = getelementptr inbounds %struct.VkBaseInStructure, %struct.VkBaseInStructure* %19, i64 0, i32 1
  %45 = load %struct.VkBaseInStructure*, %struct.VkBaseInStructure** %44, align 8
  %46 = icmp eq %struct.VkBaseInStructure* %45, null
  br i1 %46, label %17, label %18
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: optsize
declare void @_ZN2sw4warnEPKcz(i8*, ...) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: optsize
declare void @_ZN2vk9StringifyE15VkStructureType(%"class.std::__1::basic_string"* sret, i32) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk9SemaphoreC2E15VkSemaphoreType(%"class.vk::Semaphore"* nocapture, i32) unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::Semaphore", %"class.vk::Semaphore"* %0, i64 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2vk9SemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %3, align 8
  %4 = getelementptr inbounds %"class.vk::Semaphore", %"class.vk::Semaphore"* %0, i64 0, i32 1
  store i32 %1, i32* %4, align 8
  %5 = getelementptr inbounds %"class.vk::Semaphore", %"class.vk::Semaphore"* %0, i64 0, i32 2
  %6 = bitcast %"class.marl::mutex"* %5 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %6, i8 0, i64 40, i1 false) #13
  ret void
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i32 @_ZNK2vk9Semaphore16getSemaphoreTypeEv(%"class.vk::Semaphore"* nocapture readonly) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds %"class.vk::Semaphore", %"class.vk::Semaphore"* %0, i64 0, i32 1
  %3 = load i32, i32* %2, align 8
  ret i32 %3
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk15BinarySemaphore4waitEv(%"class.vk::BinarySemaphore"*) local_unnamed_addr #0 align 2 {
  %2 = alloca %"class.marl::lock", align 8
  %3 = alloca %class.anon.156, align 8
  %4 = alloca %"class.marl::lock", align 8
  %5 = alloca %class.anon.193, align 8
  %6 = alloca %"class.std::__1::unique_ptr.184", align 8
  %7 = alloca %"class.marl::WaitGroup", align 8
  %8 = alloca %"class.marl::Scheduler"*, align 8
  %9 = alloca %"class.std::__1::thread", align 8
  %10 = alloca %"class.marl::lock", align 8
  %11 = alloca %class.anon, align 8
  %12 = bitcast %"class.marl::lock"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %12) #13
  %13 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %10, i64 0, i32 0, i32 0
  %14 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %10, i64 0, i32 0, i32 1
  %15 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 2, i32 0
  %16 = bitcast %"class.marl::lock"* %10 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 16, i1 false)
  store %"class.std::__1::mutex"* %15, %"class.std::__1::mutex"** %13, align 8
  store i8 1, i8* %14, align 8
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %15) #12
  %17 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 5
  %18 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %17, align 8
  %19 = icmp eq %"class.vk::BinarySemaphore::External"* %18, null
  br i1 %19, label %20, label %24

20:                                               ; preds = %1
  %21 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 4
  %22 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %21, align 8
  %23 = icmp eq %"class.vk::BinarySemaphore::External"* %22, null
  br i1 %23, label %161, label %24

24:                                               ; preds = %1, %20
  %25 = phi %"class.vk::BinarySemaphore::External"* [ %22, %20 ], [ %18, %1 ]
  %26 = bitcast %"class.vk::BinarySemaphore::External"* %25 to i1 (%"class.vk::BinarySemaphore::External"*)***
  %27 = load i1 (%"class.vk::BinarySemaphore::External"*)**, i1 (%"class.vk::BinarySemaphore::External"*)*** %26, align 8
  %28 = getelementptr inbounds i1 (%"class.vk::BinarySemaphore::External"*)*, i1 (%"class.vk::BinarySemaphore::External"*)** %27, i64 3
  %29 = load i1 (%"class.vk::BinarySemaphore::External"*)*, i1 (%"class.vk::BinarySemaphore::External"*)** %28, align 8
  %30 = tail call zeroext i1 %29(%"class.vk::BinarySemaphore::External"* nonnull %25) #12
  br i1 %30, label %147, label %31

31:                                               ; preds = %24
  %32 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %10, i64 0, i32 0
  call void @_ZNSt3__111unique_lockINS_5mutexEE6unlockEv(%"class.std::__1::unique_lock"* nonnull %32) #12
  %33 = bitcast %class.anon* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %33) #13
  %34 = getelementptr inbounds %class.anon, %class.anon* %11, i64 0, i32 0
  store %"class.vk::BinarySemaphore::External"* %25, %"class.vk::BinarySemaphore::External"** %34, align 8
  %35 = bitcast %"class.marl::WaitGroup"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %35) #13
  %36 = getelementptr inbounds %"class.marl::WaitGroup", %"class.marl::WaitGroup"* %7, i64 0, i32 0, i32 0
  %37 = getelementptr inbounds %"class.marl::WaitGroup", %"class.marl::WaitGroup"* %7, i64 0, i32 0, i32 1
  %38 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %39 = call i8* @_Znwm(i64 216) #14
  %40 = bitcast i8* %39 to i32 (...)***
  %41 = getelementptr inbounds i8, i8* %39, i64 8
  call void @llvm.memset.p0i8.i64(i8* align 8 %41, i8 0, i64 16, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %40, align 8
  %42 = getelementptr inbounds i8, i8* %39, i64 24
  %43 = bitcast i8* %42 to i32*
  store i32 0, i32* %43, align 4
  %44 = getelementptr inbounds i8, i8* %39, i64 32
  call void @llvm.memset.p0i8.i64(i8* align 8 %44, i8 0, i64 40, i1 false) #13
  %45 = getelementptr inbounds i8, i8* %39, i64 72
  %46 = bitcast i8* %45 to i64*
  store i64 %38, i64* %46, align 8
  %47 = getelementptr inbounds i8, i8* %39, i64 80
  call void @llvm.memset.p0i8.i64(i8* align 8 %47, i8 0, i64 136, i1 false) #13
  %48 = bitcast %"class.marl::WaitGroup"* %7 to i8**
  store i8* %42, i8** %48, align 8
  %49 = bitcast %"class.std::__1::__shared_weak_count"** %37 to i8**
  store i8* %39, i8** %49, align 8
  store atomic i32 1, i32* %43 seq_cst, align 4
  %50 = bitcast %"class.marl::Scheduler"** %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %50) #13
  %51 = call %"class.marl::Scheduler"* @_ZN4marl9Scheduler3getEv() #12
  store %"class.marl::Scheduler"* %51, %"class.marl::Scheduler"** %8, align 8
  %52 = bitcast %"class.std::__1::thread"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %52) #13
  %53 = getelementptr inbounds %"class.std::__1::thread", %"class.std::__1::thread"* %9, i64 0, i32 0
  store i64 -6148914691236517206, i64* %53, align 8
  %54 = bitcast %"class.marl::WaitGroup"* %7 to i64*
  %55 = load i64, i64* %54, align 8
  %56 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %37, align 8
  %57 = icmp eq %"class.std::__1::__shared_weak_count"* %56, null
  br i1 %57, label %61, label %58

58:                                               ; preds = %31
  %59 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %56, i64 0, i32 0, i32 1
  %60 = atomicrmw add i64* %59, i64 1 monotonic
  br label %61

61:                                               ; preds = %58, %31
  %62 = call i8* @_Znwm(i64 8) #14
  %63 = bitcast i8* %62 to %"class.std::__1::__thread_struct"*
  call void @_ZNSt3__115__thread_structC1Ev(%"class.std::__1::__thread_struct"* nonnull %63) #12
  %64 = ptrtoint i8* %62 to i64
  %65 = bitcast %"class.std::__1::unique_ptr.184"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %65) #13
  %66 = getelementptr inbounds %"class.std::__1::unique_ptr.184", %"class.std::__1::unique_ptr.184"* %6, i64 0, i32 0, i32 0, i32 0
  store %"class.std::__1::tuple"* inttoptr (i64 -6148914691236517206 to %"class.std::__1::tuple"*), %"class.std::__1::tuple"** %66, align 8
  %67 = call i8* @_Znwm(i64 40) #14
  br i1 %57, label %68, label %80

68:                                               ; preds = %61
  %69 = bitcast i8* %67 to i64*
  store i64 %64, i64* %69, align 8
  %70 = getelementptr inbounds i8, i8* %67, i64 8
  %71 = bitcast i8* %70 to i64*
  store i64 %55, i64* %71, align 8
  %72 = getelementptr inbounds i8, i8* %67, i64 16
  %73 = bitcast i8* %72 to %"class.std::__1::__shared_weak_count"**
  store %"class.std::__1::__shared_weak_count"* null, %"class.std::__1::__shared_weak_count"** %73, align 8
  %74 = getelementptr inbounds i8, i8* %67, i64 24
  %75 = bitcast i8* %74 to %"class.marl::Scheduler"***
  store %"class.marl::Scheduler"** %8, %"class.marl::Scheduler"*** %75, align 8
  %76 = getelementptr inbounds i8, i8* %67, i64 32
  %77 = bitcast i8* %76 to %class.anon**
  store %class.anon* %11, %class.anon** %77, align 8
  %78 = ptrtoint i8* %67 to i64
  %79 = bitcast %"class.std::__1::unique_ptr.184"* %6 to i64*
  store i64 %78, i64* %79, align 8
  br label %103

80:                                               ; preds = %61
  %81 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %56, i64 0, i32 0, i32 1
  %82 = atomicrmw add i64* %81, i64 1 monotonic, !noalias !2
  %83 = bitcast i8* %67 to i64*
  store i64 %64, i64* %83, align 8
  %84 = getelementptr inbounds i8, i8* %67, i64 8
  %85 = bitcast i8* %84 to i64*
  store i64 %55, i64* %85, align 8
  %86 = getelementptr inbounds i8, i8* %67, i64 16
  %87 = bitcast i8* %86 to %"class.std::__1::__shared_weak_count"**
  store %"class.std::__1::__shared_weak_count"* %56, %"class.std::__1::__shared_weak_count"** %87, align 8
  %88 = atomicrmw add i64* %81, i64 1 monotonic
  %89 = getelementptr inbounds i8, i8* %67, i64 24
  %90 = bitcast i8* %89 to %"class.marl::Scheduler"***
  store %"class.marl::Scheduler"** %8, %"class.marl::Scheduler"*** %90, align 8
  %91 = getelementptr inbounds i8, i8* %67, i64 32
  %92 = bitcast i8* %91 to %class.anon**
  store %class.anon* %11, %class.anon** %92, align 8
  %93 = ptrtoint i8* %67 to i64
  %94 = bitcast %"class.std::__1::unique_ptr.184"* %6 to i64*
  store i64 %93, i64* %94, align 8
  %95 = atomicrmw add i64* %81, i64 -1 acq_rel
  %96 = icmp eq i64 %95, 0
  br i1 %96, label %97, label %103

97:                                               ; preds = %80
  %98 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %56, i64 0, i32 0
  %99 = bitcast %"class.std::__1::__shared_weak_count"* %56 to void (%"class.std::__1::__shared_count"*)***
  %100 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %99, align 8
  %101 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %100, i64 2
  %102 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %101, align 8
  call void %102(%"class.std::__1::__shared_count"* %98) #12
  call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %56) #12
  br label %103

103:                                              ; preds = %97, %80, %68
  %104 = bitcast %"class.std::__1::unique_ptr.184"* %6 to i8**
  %105 = load i8*, i8** %104, align 8
  %106 = call i32 @pthread_create(i64* nonnull %53, %union.pthread_attr_t* null, i8* (i8*)* nonnull @"_ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEEZN4marl6detail11OnNewThreadIvE4callIZN2vk15BinarySemaphore4waitEvE3$_0JEEEvOT_DpOT0_EUlvE_EEEEEPvSM_", i8* %105) #12
  %107 = icmp eq i32 %106, 0
  br i1 %107, label %109, label %108

108:                                              ; preds = %103
  call void @_ZNSt3__120__throw_system_errorEiPKc(i32 %106, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.8, i64 0, i64 0)) #15
  unreachable

109:                                              ; preds = %103
  store %"class.std::__1::tuple"* null, %"class.std::__1::tuple"** %66, align 8
  call fastcc void @"_ZNSt3__110unique_ptrINS_5tupleIJNS0_INS_15__thread_structENS_14default_deleteIS2_EEEEZN4marl6detail11OnNewThreadIvE4callIZN2vk15BinarySemaphore4waitEvE3$_0JEEEvOT_DpOT0_EUlvE_EEENS3_ISK_EEED2Ev"(%"class.std::__1::unique_ptr.184"* nonnull %6) #12
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %65) #13
  br i1 %57, label %120, label %110

110:                                              ; preds = %109
  %111 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %56, i64 0, i32 0, i32 1
  %112 = atomicrmw add i64* %111, i64 -1 acq_rel
  %113 = icmp eq i64 %112, 0
  br i1 %113, label %114, label %120

114:                                              ; preds = %110
  %115 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %56, i64 0, i32 0
  %116 = bitcast %"class.std::__1::__shared_weak_count"* %56 to void (%"class.std::__1::__shared_count"*)***
  %117 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %116, align 8
  %118 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %117, i64 2
  %119 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %118, align 8
  call void %119(%"class.std::__1::__shared_count"* %115) #12
  call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %56) #12
  br label %120

120:                                              ; preds = %114, %110, %109
  %121 = bitcast %"class.marl::lock"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #13
  %122 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %4, i64 0, i32 0, i32 0
  %123 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %4, i64 0, i32 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %121, i8 -86, i64 16, i1 false) #13
  %124 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %36, align 8
  %125 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %124, i64 0, i32 2, i32 0
  store %"class.std::__1::mutex"* %125, %"class.std::__1::mutex"** %122, align 8
  store i8 1, i8* %123, align 8
  call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %125) #12
  %126 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %124, i64 0, i32 1
  %127 = bitcast %class.anon.193* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %127) #13
  %128 = getelementptr inbounds %class.anon.193, %class.anon.193* %5, i64 0, i32 0
  store %"class.marl::WaitGroup"* %7, %"class.marl::WaitGroup"** %128, align 8
  call void @_ZN4marl17ConditionVariable4waitIZNKS_9WaitGroup4waitEvEUlvE_EEvRNS_4lockEOT_(%"class.marl::ConditionVariable"* %126, %"class.marl::lock"* nonnull dereferenceable(16) %4, %class.anon.193* nonnull dereferenceable(8) %5) #12
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %127) #13
  %129 = load i8, i8* %123, align 8, !range !5
  %130 = icmp eq i8 %129, 0
  br i1 %130, label %133, label %131

131:                                              ; preds = %120
  %132 = load %"class.std::__1::mutex"*, %"class.std::__1::mutex"** %122, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %132) #12
  br label %133

133:                                              ; preds = %131, %120
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #13
  call void @_ZNSt3__16thread4joinEv(%"class.std::__1::thread"* nonnull %9) #12
  call void @_ZNSt3__16threadD1Ev(%"class.std::__1::thread"* nonnull %9) #12
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %52) #13
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %50) #13
  %134 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %37, align 8
  %135 = icmp eq %"class.std::__1::__shared_weak_count"* %134, null
  br i1 %135, label %146, label %136

136:                                              ; preds = %133
  %137 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %134, i64 0, i32 0, i32 1
  %138 = atomicrmw add i64* %137, i64 -1 acq_rel
  %139 = icmp eq i64 %138, 0
  br i1 %139, label %140, label %146

140:                                              ; preds = %136
  %141 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %134, i64 0, i32 0
  %142 = bitcast %"class.std::__1::__shared_weak_count"* %134 to void (%"class.std::__1::__shared_count"*)***
  %143 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %142, align 8
  %144 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %143, i64 2
  %145 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %144, align 8
  call void %145(%"class.std::__1::__shared_count"* %141) #12
  call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %134) #12
  br label %146

146:                                              ; preds = %133, %136, %140
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %35) #13
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %33) #13
  call void @_ZNSt3__111unique_lockINS_5mutexEE4lockEv(%"class.std::__1::unique_lock"* nonnull %32) #12
  br label %147

147:                                              ; preds = %146, %24
  %148 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %17, align 8
  %149 = icmp eq %"class.vk::BinarySemaphore::External"* %25, %148
  br i1 %149, label %150, label %182

150:                                              ; preds = %147
  %151 = getelementptr inbounds %"class.vk::BinarySemaphore::External", %"class.vk::BinarySemaphore::External"* %25, i64 0, i32 1
  %152 = bitcast %"class.vk::BinarySemaphore::External"** %151 to i64*
  %153 = load i64, i64* %152, align 8
  %154 = bitcast %"class.vk::BinarySemaphore::External"** %17 to i64*
  store i64 %153, i64* %154, align 8
  %155 = bitcast %"class.vk::BinarySemaphore::External"* %25 to void (%"class.vk::BinarySemaphore::External"*)***
  %156 = load void (%"class.vk::BinarySemaphore::External"*)**, void (%"class.vk::BinarySemaphore::External"*)*** %155, align 8
  %157 = load void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %156, align 8
  call void %157(%"class.vk::BinarySemaphore::External"* nonnull %25) #12
  %158 = bitcast %"class.vk::BinarySemaphore::External"* %25 to i8*
  %159 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 1
  %160 = load %struct.VkAllocationCallbacks*, %struct.VkAllocationCallbacks** %159, align 8
  call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* %158, %struct.VkAllocationCallbacks* %160) #12
  br label %182

161:                                              ; preds = %20
  %162 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 3, i32 0, i32 0
  %163 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %162, align 8
  %164 = bitcast %"class.marl::lock"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %164) #13
  %165 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %2, i64 0, i32 0, i32 0
  %166 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %2, i64 0, i32 0, i32 1
  %167 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %163, i64 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %164, i8 -86, i64 16, i1 false) #13
  store %"class.std::__1::mutex"* %167, %"class.std::__1::mutex"** %165, align 8
  store i8 1, i8* %166, align 8
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %167) #12
  %168 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %163, i64 0, i32 1
  %169 = bitcast %class.anon.156* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %169) #13
  %170 = getelementptr inbounds %class.anon.156, %class.anon.156* %3, i64 0, i32 0
  store %"struct.marl::Event::Shared"* %163, %"struct.marl::Event::Shared"** %170, align 8
  call void @_ZN4marl17ConditionVariable4waitIZNS_5Event6Shared4waitEvEUlvE_EEvRNS_4lockEOT_(%"class.marl::ConditionVariable"* %168, %"class.marl::lock"* nonnull dereferenceable(16) %2, %class.anon.156* nonnull dereferenceable(8) %3) #12
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %169) #13
  %171 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %163, i64 0, i32 3
  %172 = load i8, i8* %171, align 8
  %173 = icmp eq i8 %172, 0
  br i1 %173, label %174, label %176

174:                                              ; preds = %161
  %175 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %163, i64 0, i32 4
  store i8 0, i8* %175, align 1
  br label %176

176:                                              ; preds = %174, %161
  %177 = load i8, i8* %166, align 8, !range !5
  %178 = icmp eq i8 %177, 0
  br i1 %178, label %181, label %179

179:                                              ; preds = %176
  %180 = load %"class.std::__1::mutex"*, %"class.std::__1::mutex"** %165, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %180) #12
  br label %181

181:                                              ; preds = %176, %179
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %164) #13
  br label %182

182:                                              ; preds = %147, %150, %181
  %183 = load i8, i8* %14, align 8, !range !5
  %184 = icmp eq i8 %183, 0
  br i1 %184, label %187, label %185

185:                                              ; preds = %182
  %186 = load %"class.std::__1::mutex"*, %"class.std::__1::mutex"** %13, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %186) #12
  br label %187

187:                                              ; preds = %182, %185
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %12) #13
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk15BinarySemaphore18deallocateExternalEPNS0_8ExternalE(%"class.vk::BinarySemaphore"* nocapture readonly, %"class.vk::BinarySemaphore::External"*) local_unnamed_addr #0 align 2 {
  %3 = bitcast %"class.vk::BinarySemaphore::External"* %1 to void (%"class.vk::BinarySemaphore::External"*)***
  %4 = load void (%"class.vk::BinarySemaphore::External"*)**, void (%"class.vk::BinarySemaphore::External"*)*** %3, align 8
  %5 = load void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %4, align 8
  tail call void %5(%"class.vk::BinarySemaphore::External"* %1) #12
  %6 = bitcast %"class.vk::BinarySemaphore::External"* %1 to i8*
  %7 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 1
  %8 = load %struct.VkAllocationCallbacks*, %struct.VkAllocationCallbacks** %7, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* %6, %struct.VkAllocationCallbacks* %8) #12
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk15BinarySemaphore6signalEv(%"class.vk::BinarySemaphore"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 2, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %2) #12
  %3 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 5
  %4 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %3, align 8
  %5 = icmp eq %"class.vk::BinarySemaphore::External"* %4, null
  br i1 %5, label %6, label %10

6:                                                ; preds = %1
  %7 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 4
  %8 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %7, align 8
  %9 = icmp eq %"class.vk::BinarySemaphore::External"* %8, null
  br i1 %9, label %16, label %10

10:                                               ; preds = %1, %6
  %11 = phi %"class.vk::BinarySemaphore::External"* [ %8, %6 ], [ %4, %1 ]
  %12 = bitcast %"class.vk::BinarySemaphore::External"* %11 to void (%"class.vk::BinarySemaphore::External"*)***
  %13 = load void (%"class.vk::BinarySemaphore::External"*)**, void (%"class.vk::BinarySemaphore::External"*)*** %12, align 8
  %14 = getelementptr inbounds void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %13, i64 5
  %15 = load void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %14, align 8
  tail call void %15(%"class.vk::BinarySemaphore::External"* nonnull %11) #12
  br label %19

16:                                               ; preds = %6
  %17 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 3, i32 0, i32 0
  %18 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %17, align 8
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %18) #12
  br label %19

19:                                               ; preds = %16, %10
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %2) #12
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk15BinarySemaphoreC2EPK21VkSemaphoreCreateInfoPvPK21VkAllocationCallbacks(%"class.vk::BinarySemaphore"* nocapture, %struct.VkSemaphoreCreateInfo* nocapture readonly, i8* nocapture readnone, %struct.VkAllocationCallbacks*) unnamed_addr #0 align 2 {
  %5 = alloca %"struct.marl::Allocation::Request", align 16
  %6 = alloca %"struct.marl::Allocation", align 8
  %7 = alloca %"struct.vk::SemaphoreCreateInfo", align 8
  %8 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 0
  %9 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 1
  store i32 0, i32* %9, align 8
  %10 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 2
  %11 = bitcast %"class.marl::mutex"* %10 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %11, i8 0, i64 40, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2vk15BinarySemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %8, align 8
  %12 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 1
  store %struct.VkAllocationCallbacks* %3, %struct.VkAllocationCallbacks** %12, align 8
  %13 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 2
  store i32 0, i32* %13, align 8
  %14 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE, align 8
  %15 = ptrtoint %"class.marl::Allocator"* %14 to i64
  %16 = bitcast %"struct.marl::Allocation::Request"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %16) #13
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 -86, i64 24, i1 false) #13
  %17 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %5, i64 0, i32 2
  %18 = bitcast i8* %17 to i16*
  store i16 512, i16* %18, align 16
  %19 = bitcast %"struct.marl::Allocation::Request"* %5 to <2 x i64>*
  store <2 x i64> <i64 272, i64 8>, <2 x i64>* %19, align 16
  %20 = bitcast %"struct.marl::Allocation"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %20) #13
  %21 = bitcast %"class.marl::Allocator"* %14 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %20, i8 -86, i64 32, i1 false) #13
  %22 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %21, align 8
  %23 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %22, i64 2
  %24 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %23, align 8
  call void %24(%"struct.marl::Allocation"* nonnull sret %6, %"class.marl::Allocator"* %14, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %5) #12
  %25 = bitcast %"struct.marl::Allocation"* %6 to %"struct.marl::Event::Shared"**
  %26 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %25, align 8
  %27 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 1, i32 1, i32 0
  %28 = bitcast %"struct.marl::Event::Shared"* %26 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %28, i8 0, i64 80, i1 false) #13
  %29 = bitcast %"class.marl::Allocator"** %27 to i64*
  store i64 %15, i64* %29, align 8
  %30 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 1, i32 1, i32 1
  %31 = bitcast i64* %30 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %31, i8 0, i64 96, i1 false) #13
  %32 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 2
  %33 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %34 = bitcast %"class.marl::containers::vector"* %32 to i64*
  store i64 %33, i64* %34, align 8
  %35 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 2, i32 1
  %36 = bitcast i64* %35 to <2 x i64>*
  store <2 x i64> <i64 0, i64 1>, <2 x i64>* %36, align 8
  %37 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 2, i32 4
  %38 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 2, i32 3, i64 0
  store %"struct.marl::aligned_storage<16, 8>::type"* %38, %"struct.marl::aligned_storage<16, 8>::type"** %37, align 8
  %39 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 2, i32 5
  %40 = bitcast %"struct.marl::Allocation"* %39 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %40, i8 0, i64 26, i1 false) #13
  %41 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 3
  store i8 0, i8* %41, align 8
  %42 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %26, i64 0, i32 4
  store i8 0, i8* %42, align 1
  %43 = call i8* @_Znwm(i64 48) #14
  %44 = ptrtoint %"struct.marl::Event::Shared"* %26 to i64
  %45 = bitcast i8* %43 to i32 (...)***
  %46 = getelementptr inbounds i8, i8* %43, i64 8
  call void @llvm.memset.p0i8.i64(i8* align 8 %46, i8 0, i64 16, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %45, align 8
  %47 = getelementptr inbounds i8, i8* %43, i64 24
  %48 = bitcast i8* %47 to i64*
  store i64 %44, i64* %48, align 8
  %49 = getelementptr inbounds i8, i8* %43, i64 32
  %50 = bitcast i8* %49 to %"class.marl::Allocator"**
  store %"class.marl::Allocator"* %14, %"class.marl::Allocator"** %50, align 8
  %51 = getelementptr inbounds i8, i8* %43, i64 40
  %52 = bitcast i8* %51 to i64*
  store i64 1, i64* %52, align 8
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %20) #13
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %16) #13
  %53 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 3, i32 0, i32 0
  store %"struct.marl::Event::Shared"* %26, %"struct.marl::Event::Shared"** %53, align 8
  %54 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 3, i32 0, i32 1
  %55 = bitcast %"class.std::__1::__shared_weak_count"** %54 to i8**
  store i8* %43, i8** %55, align 8
  %56 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 4
  %57 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %7, i64 0, i32 0
  %58 = bitcast %"class.vk::BinarySemaphore::External"** %56 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %58, i8 0, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %57) #13
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %57, i8 -86, i64 24, i1 false)
  call void @_ZN2vk19SemaphoreCreateInfoC2EPK21VkSemaphoreCreateInfo(%"struct.vk::SemaphoreCreateInfo"* nonnull %7, %struct.VkSemaphoreCreateInfo* %1) #16
  %59 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %7, i64 0, i32 1
  %60 = load i32, i32* %59, align 4
  store i32 %60, i32* %13, align 8
  %61 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %7, i64 0, i32 2
  %62 = load i32, i32* %61, align 8
  store i32 %62, i32* %9, align 8
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %57) #13
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk15BinarySemaphore7destroyEPK21VkAllocationCallbacks(%"class.vk::BinarySemaphore"*, %struct.VkAllocationCallbacks* nocapture readnone) unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 2, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %3) #12
  %4 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 5
  %5 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %4, align 8
  %6 = icmp eq %"class.vk::BinarySemaphore::External"* %5, null
  br i1 %6, label %22, label %7

7:                                                ; preds = %2
  %8 = bitcast %"class.vk::BinarySemaphore::External"** %4 to i64*
  %9 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 1
  br label %10

10:                                               ; preds = %7, %10
  %11 = phi %"class.vk::BinarySemaphore::External"* [ %5, %7 ], [ %20, %10 ]
  %12 = getelementptr inbounds %"class.vk::BinarySemaphore::External", %"class.vk::BinarySemaphore::External"* %11, i64 0, i32 1
  %13 = bitcast %"class.vk::BinarySemaphore::External"** %12 to i64*
  %14 = load i64, i64* %13, align 8
  store i64 %14, i64* %8, align 8
  %15 = bitcast %"class.vk::BinarySemaphore::External"* %11 to void (%"class.vk::BinarySemaphore::External"*)***
  %16 = load void (%"class.vk::BinarySemaphore::External"*)**, void (%"class.vk::BinarySemaphore::External"*)*** %15, align 8
  %17 = load void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %16, align 8
  tail call void %17(%"class.vk::BinarySemaphore::External"* nonnull %11) #12
  %18 = bitcast %"class.vk::BinarySemaphore::External"* %11 to i8*
  %19 = load %struct.VkAllocationCallbacks*, %struct.VkAllocationCallbacks** %9, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* nonnull %18, %struct.VkAllocationCallbacks* %19) #12
  %20 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %4, align 8
  %21 = icmp eq %"class.vk::BinarySemaphore::External"* %20, null
  br i1 %21, label %22, label %10

22:                                               ; preds = %10, %2
  %23 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 4
  %24 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %23, align 8
  %25 = icmp eq %"class.vk::BinarySemaphore::External"* %24, null
  br i1 %25, label %33, label %26

26:                                               ; preds = %22
  %27 = bitcast %"class.vk::BinarySemaphore::External"* %24 to void (%"class.vk::BinarySemaphore::External"*)***
  %28 = load void (%"class.vk::BinarySemaphore::External"*)**, void (%"class.vk::BinarySemaphore::External"*)*** %27, align 8
  %29 = load void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %28, align 8
  tail call void %29(%"class.vk::BinarySemaphore::External"* nonnull %24) #12
  %30 = bitcast %"class.vk::BinarySemaphore::External"* %24 to i8*
  %31 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 1
  %32 = load %struct.VkAllocationCallbacks*, %struct.VkAllocationCallbacks** %31, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* nonnull %30, %struct.VkAllocationCallbacks* %32) #12
  store %"class.vk::BinarySemaphore::External"* null, %"class.vk::BinarySemaphore::External"** %23, align 8
  br label %33

33:                                               ; preds = %22, %26
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %3) #12
  ret void
}

; Function Attrs: norecurse nounwind optsize readnone ssp uwtable
define hidden i64 @_ZN2vk15BinarySemaphore29ComputeRequiredAllocationSizeEPK21VkSemaphoreCreateInfo(%struct.VkSemaphoreCreateInfo* nocapture readnone) local_unnamed_addr #4 align 2 {
  ret i64 0
}

; Function Attrs: optsize
declare void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8*, %struct.VkAllocationCallbacks*) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk15BinarySemaphore8importFdEib(%"class.vk::BinarySemaphore"*, i32, i1 zeroext) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 2, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %4) #12
  %5 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 4
  %6 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %5, align 8
  %7 = xor i1 %2, true
  %8 = icmp ne %"class.vk::BinarySemaphore::External"* %6, null
  %9 = and i1 %8, %7
  br i1 %9, label %21, label %10

10:                                               ; preds = %3
  %11 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 1
  %12 = load %struct.VkAllocationCallbacks*, %struct.VkAllocationCallbacks** %11, align 8
  %13 = tail call i8* @_ZN2vk8allocateEmmPK21VkAllocationCallbacks23VkSystemAllocationScope(i64 32, i64 8, %struct.VkAllocationCallbacks* %12, i32 1) #12
  %14 = bitcast i8* %13 to %"class.vk::BinarySemaphore::External"*
  %15 = bitcast i8* %13 to i32 (...)***
  %16 = getelementptr inbounds i8, i8* %13, i64 8
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %16, i8 0, i64 16, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [10 x i8*] }, { [10 x i8*] }* @_ZTVN2vk25OpaqueFdExternalSemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %15, align 8
  %17 = getelementptr inbounds i8, i8* %13, i64 16
  %18 = bitcast i8* %17 to i32*
  store i32 -1, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %13, i64 24
  %20 = bitcast i8* %19 to %class.SharedSemaphore**
  store %class.SharedSemaphore* null, %class.SharedSemaphore** %20, align 8
  br label %21

21:                                               ; preds = %10, %3
  %22 = phi %"class.vk::BinarySemaphore::External"* [ %6, %3 ], [ %14, %10 ]
  %23 = bitcast %"class.vk::BinarySemaphore::External"* %22 to i32 (%"class.vk::BinarySemaphore::External"*, i32)***
  %24 = load i32 (%"class.vk::BinarySemaphore::External"*, i32)**, i32 (%"class.vk::BinarySemaphore::External"*, i32)*** %23, align 8
  %25 = getelementptr inbounds i32 (%"class.vk::BinarySemaphore::External"*, i32)*, i32 (%"class.vk::BinarySemaphore::External"*, i32)** %24, i64 6
  %26 = load i32 (%"class.vk::BinarySemaphore::External"*, i32)*, i32 (%"class.vk::BinarySemaphore::External"*, i32)** %25, align 8
  %27 = tail call i32 %26(%"class.vk::BinarySemaphore::External"* %22, i32 %1) #12
  %28 = icmp eq i32 %27, 0
  br i1 %28, label %40, label %29

29:                                               ; preds = %21
  br i1 %2, label %33, label %30

30:                                               ; preds = %29
  %31 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %5, align 8
  %32 = icmp eq %"class.vk::BinarySemaphore::External"* %31, null
  br i1 %32, label %33, label %51

33:                                               ; preds = %30, %29
  %34 = bitcast %"class.vk::BinarySemaphore::External"* %22 to void (%"class.vk::BinarySemaphore::External"*)***
  %35 = load void (%"class.vk::BinarySemaphore::External"*)**, void (%"class.vk::BinarySemaphore::External"*)*** %34, align 8
  %36 = load void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %35, align 8
  tail call void %36(%"class.vk::BinarySemaphore::External"* %22) #12
  %37 = bitcast %"class.vk::BinarySemaphore::External"* %22 to i8*
  %38 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 1
  %39 = load %struct.VkAllocationCallbacks*, %struct.VkAllocationCallbacks** %38, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* %37, %struct.VkAllocationCallbacks* %39) #12
  br label %51

40:                                               ; preds = %21
  br i1 %2, label %41, label %47

41:                                               ; preds = %40
  %42 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 5
  %43 = bitcast %"class.vk::BinarySemaphore::External"** %42 to i64*
  %44 = load i64, i64* %43, align 8
  %45 = getelementptr inbounds %"class.vk::BinarySemaphore::External", %"class.vk::BinarySemaphore::External"* %22, i64 0, i32 1
  %46 = bitcast %"class.vk::BinarySemaphore::External"** %45 to i64*
  store i64 %44, i64* %46, align 8
  store %"class.vk::BinarySemaphore::External"* %22, %"class.vk::BinarySemaphore::External"** %42, align 8
  br label %51

47:                                               ; preds = %40
  %48 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %5, align 8
  %49 = icmp eq %"class.vk::BinarySemaphore::External"* %48, null
  br i1 %49, label %50, label %51

50:                                               ; preds = %47
  store %"class.vk::BinarySemaphore::External"* %22, %"class.vk::BinarySemaphore::External"** %5, align 8
  br label %51

51:                                               ; preds = %30, %33, %41, %47, %50
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %4) #12
  ret i32 %27
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk15BinarySemaphore8exportFdEPi(%"class.vk::BinarySemaphore"*, i32*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 2
  %4 = load i32, i32* %3, align 8
  %5 = and i32 %4, 1
  %6 = icmp eq i32 %5, 0
  br i1 %6, label %7, label %8

7:                                                ; preds = %2
  tail call void (i8*, ...) @_ZN2sw5traceEPKcz(i8* getelementptr inbounds ([92 x i8], [92 x i8]* @.str.3, i64 0, i64 0), i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.1, i64 0, i64 0), i32 317, i32 %4, i32 1) #12
  br label %58

8:                                                ; preds = %2
  %9 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 2, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %9) #12
  %10 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 5
  %11 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %10, align 8
  %12 = icmp eq %"class.vk::BinarySemaphore::External"* %11, null
  br i1 %12, label %14, label %13

13:                                               ; preds = %8
  tail call void (i8*, ...) @_ZN2sw5traceEPKcz(i8* getelementptr inbounds ([63 x i8], [63 x i8]* @.str.13, i64 0, i64 0), i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.1, i64 0, i64 0), i32 280) #12
  br label %56

14:                                               ; preds = %8
  %15 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 4
  %16 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %15, align 8
  %17 = icmp eq %"class.vk::BinarySemaphore::External"* %16, null
  br i1 %17, label %18, label %49

18:                                               ; preds = %14
  %19 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 1
  %20 = load %struct.VkAllocationCallbacks*, %struct.VkAllocationCallbacks** %19, align 8
  %21 = tail call i8* @_ZN2vk8allocateEmmPK21VkAllocationCallbacks23VkSystemAllocationScope(i64 32, i64 8, %struct.VkAllocationCallbacks* %20, i32 1) #12
  %22 = bitcast i8* %21 to %"class.vk::BinarySemaphore::External"*
  %23 = bitcast i8* %21 to i32 (...)***
  %24 = getelementptr inbounds i8, i8* %21, i64 8
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %24, i8 0, i64 16, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [10 x i8*] }, { [10 x i8*] }* @_ZTVN2vk25OpaqueFdExternalSemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %23, align 8
  %25 = getelementptr inbounds i8, i8* %21, i64 16
  %26 = bitcast i8* %25 to i32*
  store i32 -1, i32* %26, align 4
  %27 = getelementptr inbounds i8, i8* %21, i64 24
  %28 = bitcast i8* %27 to %class.SharedSemaphore**
  store %class.SharedSemaphore* null, %class.SharedSemaphore** %28, align 8
  %29 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 3, i32 0, i32 0
  %30 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %29, align 8
  %31 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %30, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %31) #12
  %32 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %29, align 8
  %33 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %32, i64 0, i32 4
  %34 = load i8, i8* %33, align 1, !range !5
  %35 = icmp ne i8 %34, 0
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %31) #12
  %36 = bitcast i8* %21 to i32 (%"class.vk::BinarySemaphore::External"*, i1)***
  %37 = load i32 (%"class.vk::BinarySemaphore::External"*, i1)**, i32 (%"class.vk::BinarySemaphore::External"*, i1)*** %36, align 8
  %38 = getelementptr inbounds i32 (%"class.vk::BinarySemaphore::External"*, i1)*, i32 (%"class.vk::BinarySemaphore::External"*, i1)** %37, i64 2
  %39 = load i32 (%"class.vk::BinarySemaphore::External"*, i1)*, i32 (%"class.vk::BinarySemaphore::External"*, i1)** %38, align 8
  %40 = tail call i32 %39(%"class.vk::BinarySemaphore::External"* %22, i1 zeroext %35) #12
  %41 = icmp eq i32 %40, 0
  br i1 %41, label %47, label %42

42:                                               ; preds = %18
  %43 = bitcast i8* %21 to void (%"class.vk::BinarySemaphore::External"*)***
  %44 = load void (%"class.vk::BinarySemaphore::External"*)**, void (%"class.vk::BinarySemaphore::External"*)*** %43, align 8
  %45 = load void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %44, align 8
  tail call void %45(%"class.vk::BinarySemaphore::External"* %22) #12
  %46 = load %struct.VkAllocationCallbacks*, %struct.VkAllocationCallbacks** %19, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* %21, %struct.VkAllocationCallbacks* %46) #12
  br label %56

47:                                               ; preds = %18
  %48 = bitcast %"class.vk::BinarySemaphore::External"** %15 to i8**
  store i8* %21, i8** %48, align 8
  br label %49

49:                                               ; preds = %47, %14
  %50 = phi %"class.vk::BinarySemaphore::External"* [ %22, %47 ], [ %16, %14 ]
  %51 = bitcast %"class.vk::BinarySemaphore::External"* %50 to i32 (%"class.vk::BinarySemaphore::External"*, i32*)***
  %52 = load i32 (%"class.vk::BinarySemaphore::External"*, i32*)**, i32 (%"class.vk::BinarySemaphore::External"*, i32*)*** %51, align 8
  %53 = getelementptr inbounds i32 (%"class.vk::BinarySemaphore::External"*, i32*)*, i32 (%"class.vk::BinarySemaphore::External"*, i32*)** %52, i64 7
  %54 = load i32 (%"class.vk::BinarySemaphore::External"*, i32*)*, i32 (%"class.vk::BinarySemaphore::External"*, i32*)** %53, align 8
  %55 = tail call i32 %54(%"class.vk::BinarySemaphore::External"* %50, i32* %1) #12
  br label %56

56:                                               ; preds = %13, %42, %49
  %57 = phi i32 [ -1000072003, %13 ], [ %55, %49 ], [ %40, %42 ]
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %9) #12
  br label %58

58:                                               ; preds = %56, %7
  %59 = phi i32 [ -1000072003, %7 ], [ %57, %56 ]
  ret i32 %59
}

; Function Attrs: optsize
declare void @_ZN2sw5traceEPKcz(i8*, ...) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk15BinarySemaphoreD2Ev(%"class.vk::BinarySemaphore"*) unnamed_addr #5 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2vk15BinarySemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 3, i32 0
  tail call void @_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev(%"class.std::__1::shared_ptr"* %3) #12
  ret void
}

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk15BinarySemaphoreD0Ev(%"class.vk::BinarySemaphore"*) unnamed_addr #5 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2vk15BinarySemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.vk::BinarySemaphore", %"class.vk::BinarySemaphore"* %0, i64 0, i32 3, i32 0
  tail call void @_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev(%"class.std::__1::shared_ptr"* %3) #12
  %4 = bitcast %"class.vk::BinarySemaphore"* %0 to i8*
  tail call void @_ZdlPv(i8* %4) #14
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk9SemaphoreD2Ev(%"class.vk::Semaphore"*) unnamed_addr #0 comdat align 2 {
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk9SemaphoreD0Ev(%"class.vk::Semaphore"*) unnamed_addr #0 comdat align 2 {
  %2 = bitcast %"class.vk::Semaphore"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #14
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk9Semaphore7destroyEPK21VkAllocationCallbacks(%"class.vk::Semaphore"*, %struct.VkAllocationCallbacks*) unnamed_addr #0 comdat align 2 {
  ret void
}

; Function Attrs: optsize
declare void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"*) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__111unique_lockINS_5mutexEE6unlockEv(%"class.std::__1::unique_lock"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::unique_lock", %"class.std::__1::unique_lock"* %0, i64 0, i32 1
  %3 = load i8, i8* %2, align 8, !range !5
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %6

5:                                                ; preds = %1
  tail call void @_ZNSt3__120__throw_system_errorEiPKc(i32 1, i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.4, i64 0, i64 0)) #15
  unreachable

6:                                                ; preds = %1
  %7 = getelementptr inbounds %"class.std::__1::unique_lock", %"class.std::__1::unique_lock"* %0, i64 0, i32 0
  %8 = load %"class.std::__1::mutex"*, %"class.std::__1::mutex"** %7, align 8
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %8) #12
  store i8 0, i8* %2, align 8
  ret void
}

; Function Attrs: noreturn optsize
declare void @_ZNSt3__120__throw_system_errorEiPKc(i32, i8*) local_unnamed_addr #6

; Function Attrs: nounwind optsize
declare void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"*) local_unnamed_addr #7

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__111unique_lockINS_5mutexEE4lockEv(%"class.std::__1::unique_lock"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::unique_lock", %"class.std::__1::unique_lock"* %0, i64 0, i32 0
  %3 = load %"class.std::__1::mutex"*, %"class.std::__1::mutex"** %2, align 8
  %4 = icmp eq %"class.std::__1::mutex"* %3, null
  br i1 %4, label %5, label %6

5:                                                ; preds = %1
  tail call void @_ZNSt3__120__throw_system_errorEiPKc(i32 1, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.5, i64 0, i64 0)) #15
  unreachable

6:                                                ; preds = %1
  %7 = getelementptr inbounds %"class.std::__1::unique_lock", %"class.std::__1::unique_lock"* %0, i64 0, i32 1
  %8 = load i8, i8* %7, align 8, !range !5
  %9 = icmp eq i8 %8, 0
  br i1 %9, label %11, label %10

10:                                               ; preds = %6
  tail call void @_ZNSt3__120__throw_system_errorEiPKc(i32 35, i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.6, i64 0, i64 0)) #15
  unreachable

11:                                               ; preds = %6
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* nonnull %3) #12
  store i8 1, i8* %7, align 8
  ret void
}

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN4marl17ConditionVariable4waitIZNS_5Event6Shared4waitEvEUlvE_EEvRNS_4lockEOT_(%"class.marl::ConditionVariable"*, %"class.marl::lock"* dereferenceable(16), %class.anon.156* dereferenceable(8)) local_unnamed_addr #5 comdat align 2 {
  %4 = alloca %"struct.marl::Allocation::Request", align 8
  %5 = alloca %"struct.marl::Allocation", align 8
  %6 = alloca %"class.std::__1::function.157", align 8
  %7 = getelementptr inbounds %class.anon.156, %class.anon.156* %2, i64 0, i32 0
  %8 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %7, align 8
  %9 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %8, i64 0, i32 4
  %10 = load i8, i8* %9, align 1, !range !5
  %11 = icmp eq i8 %10, 0
  br i1 %11, label %12, label %167

12:                                               ; preds = %3
  %13 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %14 = atomicrmw add i32* %13, i32 1 seq_cst
  %15 = tail call %"class.marl::Scheduler::Fiber"* @_ZN4marl9Scheduler5Fiber7currentEv() #12
  %16 = ptrtoint %"class.marl::Scheduler::Fiber"* %15 to i64
  %17 = icmp eq %"class.marl::Scheduler::Fiber"* %15, null
  br i1 %17, label %151, label %18

18:                                               ; preds = %12
  %19 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %19) #12
  %20 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 4
  %21 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %22 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %21, null
  br i1 %22, label %25, label %23

23:                                               ; preds = %18
  %24 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20 to i64*
  br label %74

25:                                               ; preds = %18
  %26 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 2
  %27 = load i64, i64* %26, align 8
  %28 = icmp ugt i64 %27, 8
  %29 = select i1 %28, i64 %27, i64 8
  %30 = mul i64 %29, 24
  %31 = add i64 %30, 40
  %32 = bitcast %"struct.marl::Allocation::Request"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %32) #13
  %33 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 0
  %34 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %32, i8 -86, i64 24, i1 false) #13
  %35 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 2
  %36 = bitcast i8* %35 to i16*
  store i16 1024, i16* %36, align 8
  store i64 %31, i64* %33, align 8
  store i64 8, i64* %34, align 8
  %37 = bitcast %"struct.marl::Allocation"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %37) #13
  %38 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %37, i8 -86, i64 32, i1 false) #13
  %39 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %38, align 8
  %40 = bitcast %"class.marl::Allocator"* %39 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  %41 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %40, align 8
  %42 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %41, i64 2
  %43 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %42, align 8
  call void %43(%"struct.marl::Allocation"* nonnull sret %5, %"class.marl::Allocator"* %39, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %4) #12
  %44 = bitcast %"struct.marl::Allocation"* %5 to %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"**
  %45 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %44, align 8
  %46 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20 to i64*
  br label %47

47:                                               ; preds = %58, %25
  %48 = phi i64 [ 0, %25 ], [ %59, %58 ]
  %49 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %45, i64 %48
  %50 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %45, i64 %48, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* null, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %50, align 8
  %51 = load i64, i64* %46, align 8
  %52 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %45, i64 %48, i32 1
  %53 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %52 to i64*
  store i64 %51, i64* %53, align 8
  %54 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %55 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %54, null
  br i1 %55, label %58, label %56

56:                                               ; preds = %47
  %57 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %54, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %49, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %57, align 8
  br label %58

58:                                               ; preds = %56, %47
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %49, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %59 = add nuw i64 %48, 1
  %60 = icmp eq i64 %59, %29
  br i1 %60, label %61, label %47

61:                                               ; preds = %58
  %62 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %5, i64 0, i32 0
  %63 = load i8*, i8** %62, align 8
  %64 = getelementptr inbounds i8, i8* %63, i64 %30
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %64, i8* nonnull align 8 %37, i64 32, i1 false) #13
  %65 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 3
  %66 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %65 to i64*
  %67 = load i64, i64* %66, align 8
  %68 = getelementptr inbounds i8, i8* %64, i64 32
  %69 = bitcast i8* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %65 to i8**
  store i8* %64, i8** %70, align 8
  %71 = load i64, i64* %26, align 8
  %72 = add i64 %71, %29
  store i64 %72, i64* %26, align 8
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %37) #13
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %32) #13
  %73 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  br label %74

74:                                               ; preds = %61, %23
  %75 = phi i64* [ %24, %23 ], [ %46, %61 ]
  %76 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %21, %23 ], [ %73, %61 ]
  %77 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, i64 0, i32 1
  %78 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77 to i64*
  %79 = load i64, i64* %78, align 8
  store i64 %79, i64* %75, align 8
  %80 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, i64 0, i32 2
  %81 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %80, align 8
  %82 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %81, null
  br i1 %82, label %87, label %83

83:                                               ; preds = %74
  %84 = load i64, i64* %78, align 8
  %85 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %81, i64 0, i32 1
  %86 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %85 to i64*
  store i64 %84, i64* %86, align 8
  br label %87

87:                                               ; preds = %83, %74
  %88 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77, align 8
  %89 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %88, null
  br i1 %89, label %95, label %90

90:                                               ; preds = %87
  %91 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %80 to i64*
  %92 = load i64, i64* %91, align 8
  %93 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %88, i64 0, i32 2
  %94 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %93 to i64*
  store i64 %92, i64* %94, align 8
  br label %95

95:                                               ; preds = %90, %87
  %96 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %96, i8 0, i64 16, i1 false) #13
  %97 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 5
  %98 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97, align 8
  %99 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %98, null
  br i1 %99, label %103, label %100

100:                                              ; preds = %95
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %98, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77, align 8
  %101 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97, align 8
  %102 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %101, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %102, align 8
  br label %103

103:                                              ; preds = %95, %100
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97, align 8
  %104 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76 to i64*
  store i64 %16, i64* %104, align 8
  %105 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 1
  %106 = load i64, i64* %105, align 8
  %107 = add i64 %106, 1
  store i64 %107, i64* %105, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %19) #12
  %108 = bitcast %"class.std::__1::function.157"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %108) #13
  %109 = bitcast %class.anon.156* %2 to i64*
  %110 = load i64, i64* %109, align 8
  %111 = getelementptr inbounds %"class.std::__1::function.157", %"class.std::__1::function.157"* %6, i64 0, i32 0, i32 1, i32 0
  %112 = getelementptr inbounds %"class.std::__1::function.157", %"class.std::__1::function.157"* %6, i64 0, i32 0, i32 2
  store i1 (%"union.std::__1::__function::__policy_storage"*)* @_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE, i1 (%"union.std::__1::__function::__policy_storage"*)** %111, align 8
  store %"struct.std::__1::__function::__policy"* @_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_, %"struct.std::__1::__function::__policy"** %112, align 8
  %113 = bitcast %"class.std::__1::function.157"* %6 to i64*
  store i64 %110, i64* %113, align 8
  call void @_ZN4marl9Scheduler5Fiber4waitERNS_4lockERKNSt3__18functionIFbvEEE(%"class.marl::Scheduler::Fiber"* nonnull %15, %"class.marl::lock"* dereferenceable(16) %1, %"class.std::__1::function.157"* nonnull dereferenceable(32) %6) #12
  %114 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %112, align 8
  %115 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %114, i64 0, i32 1
  %116 = load void (i8*)*, void (i8*)** %115, align 8
  %117 = icmp eq void (i8*)* %116, null
  br i1 %117, label %121, label %118

118:                                              ; preds = %103
  %119 = getelementptr inbounds %"class.std::__1::function.157", %"class.std::__1::function.157"* %6, i64 0, i32 0, i32 0, i32 0
  %120 = load i8*, i8** %119, align 8
  call void %116(i8* %120) #12
  br label %121

121:                                              ; preds = %103, %118
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %108) #13
  call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %19) #12
  %122 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97, align 8
  %123 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %122, %76
  br i1 %123, label %124, label %127

124:                                              ; preds = %121
  %125 = load i64, i64* %78, align 8
  %126 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %97 to i64*
  store i64 %125, i64* %126, align 8
  br label %127

127:                                              ; preds = %124, %121
  %128 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %80, align 8
  %129 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %128, null
  br i1 %129, label %134, label %130

130:                                              ; preds = %127
  %131 = load i64, i64* %78, align 8
  %132 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %128, i64 0, i32 1
  %133 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %132 to i64*
  store i64 %131, i64* %133, align 8
  br label %134

134:                                              ; preds = %130, %127
  %135 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77, align 8
  %136 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %135, null
  br i1 %136, label %142, label %137

137:                                              ; preds = %134
  %138 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %80 to i64*
  %139 = load i64, i64* %138, align 8
  %140 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %135, i64 0, i32 2
  %141 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %140 to i64*
  store i64 %139, i64* %141, align 8
  br label %142

142:                                              ; preds = %137, %134
  call void @llvm.memset.p0i8.i64(i8* align 8 %96, i8 0, i64 16, i1 false) #13
  %143 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %144 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %143, null
  br i1 %144, label %148, label %145

145:                                              ; preds = %142
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %143, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %77, align 8
  %146 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %147 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %146, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %147, align 8
  br label %148

148:                                              ; preds = %142, %145
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %76, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %20, align 8
  %149 = load i64, i64* %105, align 8
  %150 = add i64 %149, -1
  store i64 %150, i64* %105, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %19) #12
  br label %165

151:                                              ; preds = %12
  %152 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %153 = atomicrmw add i32* %152, i32 1 seq_cst
  %154 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 2
  %155 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %1, i64 0, i32 0
  %156 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %7, align 8
  %157 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %156, i64 0, i32 4
  %158 = load i8, i8* %157, align 1, !range !5
  %159 = icmp eq i8 %158, 0
  br i1 %159, label %160, label %163

160:                                              ; preds = %151, %160
  tail call void @_ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE(%"class.std::__1::condition_variable"* %154, %"class.std::__1::unique_lock"* dereferenceable(16) %155) #12
  %161 = load i8, i8* %157, align 1, !range !5
  %162 = icmp eq i8 %161, 0
  br i1 %162, label %160, label %163

163:                                              ; preds = %160, %151
  %164 = atomicrmw sub i32* %152, i32 1 seq_cst
  br label %165

165:                                              ; preds = %163, %148
  %166 = atomicrmw sub i32* %13, i32 1 seq_cst
  br label %167

167:                                              ; preds = %3, %165
  ret void
}

; Function Attrs: optsize
declare %"class.marl::Scheduler::Fiber"* @_ZN4marl9Scheduler5Fiber7currentEv() local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler5Fiber4waitERNS_4lockERKNSt3__18functionIFbvEEE(%"class.marl::Scheduler::Fiber"*, %"class.marl::lock"* dereferenceable(16), %"class.std::__1::function.157"* dereferenceable(32)) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZN4marl5Event6Shared4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE(%"union.std::__1::__function::__policy_storage"*) #0 comdat align 2 {
  %2 = bitcast %"union.std::__1::__function::__policy_storage"* %0 to %"struct.marl::Event::Shared"**
  %3 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %2, align 8
  %4 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %3, i64 0, i32 4
  %5 = load i8, i8* %4, align 1, !range !5
  %6 = icmp ne i8 %5, 0
  ret i1 %6
}

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE(%"class.std::__1::condition_variable"*, %"class.std::__1::unique_lock"* dereferenceable(16)) local_unnamed_addr #7

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"*) local_unnamed_addr #5 comdat align 2 {
  %2 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %2) #12
  %3 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 4
  %4 = load i8, i8* %3, align 1, !range !5
  %5 = icmp eq i8 %4, 0
  br i1 %5, label %6, label %82

6:                                                ; preds = %1
  store i8 1, i8* %3, align 1
  %7 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 3
  %8 = load i8, i8* %7, align 8
  %9 = icmp eq i8 %8, 0
  %10 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1
  %11 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = load atomic i32, i32* %11 seq_cst, align 4
  %13 = icmp eq i32 %12, 0
  br i1 %9, label %14, label %31

14:                                               ; preds = %6
  br i1 %13, label %50, label %15

15:                                               ; preds = %14
  %16 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %10, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %16) #12
  %17 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 1
  %18 = load i64, i64* %17, align 8
  %19 = icmp eq i64 %18, 0
  br i1 %19, label %25, label %20

20:                                               ; preds = %15
  %21 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %22 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %21, align 8
  %23 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %22, i64 0, i32 0
  %24 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %23, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %24) #12
  br label %25

25:                                               ; preds = %20, %15
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %16) #12
  %26 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %27 = load atomic i32, i32* %26 seq_cst, align 4
  %28 = icmp sgt i32 %27, 0
  br i1 %28, label %29, label %50

29:                                               ; preds = %25
  %30 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_oneEv(%"class.std::__1::condition_variable"* %30) #12
  br label %50

31:                                               ; preds = %6
  br i1 %13, label %50, label %32

32:                                               ; preds = %31
  %33 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %10, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %33) #12
  %34 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %35 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %34, align 8
  %36 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %35, null
  br i1 %36, label %37, label %41

37:                                               ; preds = %41, %32
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %33) #12
  %38 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %39 = load atomic i32, i32* %38 seq_cst, align 4
  %40 = icmp sgt i32 %39, 0
  br i1 %40, label %48, label %50

41:                                               ; preds = %32, %41
  %42 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %46, %41 ], [ %35, %32 ]
  %43 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %42, i64 0, i32 0
  %44 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %43, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %44) #12
  %45 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %42, i64 0, i32 1
  %46 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %45, align 8
  %47 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %46, null
  br i1 %47, label %37, label %41

48:                                               ; preds = %37
  %49 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"* %49) #12
  br label %50

50:                                               ; preds = %48, %37, %31, %29, %25, %14
  %51 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 2, i32 4
  %52 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %51 to %"class.std::__1::shared_ptr"**
  %53 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %52, align 8
  %54 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %0, i64 0, i32 2, i32 1
  %55 = load i64, i64* %54, align 8
  %56 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %53, i64 %55
  %57 = icmp eq i64 %55, 0
  br i1 %57, label %82, label %58

58:                                               ; preds = %50, %79
  %59 = phi %"class.std::__1::shared_ptr"* [ %80, %79 ], [ %53, %50 ]
  %60 = bitcast %"class.std::__1::shared_ptr"* %59 to i64*
  %61 = load i64, i64* %60, align 8
  %62 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %59, i64 0, i32 1
  %63 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %62, align 8
  %64 = icmp eq %"class.std::__1::__shared_weak_count"* %63, null
  br i1 %64, label %65, label %67

65:                                               ; preds = %58
  %66 = inttoptr i64 %61 to %"struct.marl::Event::Shared"*
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %66) #16
  br label %79

67:                                               ; preds = %58
  %68 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %63, i64 0, i32 0, i32 1
  %69 = atomicrmw add i64* %68, i64 1 monotonic
  %70 = inttoptr i64 %61 to %"struct.marl::Event::Shared"*
  tail call void @_ZN4marl5Event6Shared6signalEv(%"struct.marl::Event::Shared"* %70) #16
  %71 = atomicrmw add i64* %68, i64 -1 acq_rel
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %73, label %79

73:                                               ; preds = %67
  %74 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %63, i64 0, i32 0
  %75 = bitcast %"class.std::__1::__shared_weak_count"* %63 to void (%"class.std::__1::__shared_count"*)***
  %76 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %75, align 8
  %77 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %76, i64 2
  %78 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %77, align 8
  tail call void %78(%"class.std::__1::__shared_count"* %74) #12
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %63) #12
  br label %79

79:                                               ; preds = %65, %67, %73
  %80 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %59, i64 1
  %81 = icmp eq %"class.std::__1::shared_ptr"* %80, %56
  br i1 %81, label %82, label %58

82:                                               ; preds = %79, %50, %1
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %2) #12
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev(%"class.std::__1::shared_ptr"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %0, i64 0, i32 1
  %3 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %2, align 8
  %4 = icmp eq %"class.std::__1::__shared_weak_count"* %3, null
  br i1 %4, label %15, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0, i32 1
  %7 = atomicrmw add i64* %6, i64 -1 acq_rel
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %9, label %15

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0
  %11 = bitcast %"class.std::__1::__shared_weak_count"* %3 to void (%"class.std::__1::__shared_count"*)***
  %12 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %11, align 8
  %13 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %12, i64 2
  %14 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %13, align 8
  tail call void %14(%"class.std::__1::__shared_count"* %10) #12
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %3) #12
  br label %15

15:                                               ; preds = %9, %5, %1
  ret void
}

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"*) local_unnamed_addr #2

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable10notify_oneEv(%"class.std::__1::condition_variable"*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"*) local_unnamed_addr #7

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nobuiltin nofree optsize
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #8

; Function Attrs: nounwind optsize
declare void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"*) unnamed_addr #7

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEED0Ev(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #5 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 0
  tail call void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"* %2) #12
  %3 = bitcast %"class.std::__1::__shared_ptr_pointer"* %0 to i8*
  tail call void @_ZdlPv(i8* %3) #14
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #0 comdat align 2 {
  %2 = alloca %"struct.marl::Allocation", align 8
  %3 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %4 = load %"struct.marl::Event::Shared"*, %"struct.marl::Event::Shared"** %3, align 8
  %5 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = icmp eq i64 %6, 0
  br i1 %7, label %11, label %8

8:                                                ; preds = %1
  %9 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 4
  %10 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %9 to %"class.std::__1::shared_ptr"**
  br label %16

11:                                               ; preds = %16, %1
  %12 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 5
  %13 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %12, i64 0, i32 0
  %14 = load i8*, i8** %13, align 8
  %15 = icmp eq i8* %14, null
  br i1 %15, label %32, label %23

16:                                               ; preds = %16, %8
  %17 = phi i64 [ 0, %8 ], [ %20, %16 ]
  %18 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %10, align 8
  %19 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %18, i64 %17
  tail call void @_ZNSt3__110shared_ptrIN4marl5Event6SharedEED2Ev(%"class.std::__1::shared_ptr"* %19) #12
  %20 = add nuw i64 %17, 1
  %21 = load i64, i64* %5, align 8
  %22 = icmp ult i64 %20, %21
  br i1 %22, label %16, label %11

23:                                               ; preds = %11
  %24 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 0
  %25 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %24, align 8
  %26 = bitcast %"class.marl::Allocator"* %25 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %27 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %26, align 8
  %28 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %27, i64 3
  %29 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %28, align 8
  tail call void %29(%"class.marl::Allocator"* %25, %"struct.marl::Allocation"* dereferenceable(32) %12) #12
  %30 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 2, i32 4
  %31 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %30 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %31, i8 0, i64 34, i1 false) #13
  br label %32

32:                                               ; preds = %23, %11
  %33 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variableD1Ev(%"class.std::__1::condition_variable"* %33) #12
  %34 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 1, i32 1, i32 5
  br label %35

35:                                               ; preds = %35, %32
  %36 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** [ %34, %32 ], [ %39, %35 ]
  %37 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %36, align 8
  %38 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %37, null
  %39 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %37, i64 0, i32 1
  br i1 %38, label %40, label %35

40:                                               ; preds = %35
  %41 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 1, i32 1, i32 3
  %42 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %41, align 8
  %43 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %42, null
  br i1 %43, label %57, label %44

44:                                               ; preds = %40
  %45 = getelementptr inbounds %"struct.marl::Event::Shared", %"struct.marl::Event::Shared"* %4, i64 0, i32 1, i32 1, i32 0
  br label %46

46:                                               ; preds = %46, %44
  %47 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* [ %42, %44 ], [ %49, %46 ]
  %48 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %47, i64 0, i32 1
  %49 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %48, align 8
  %50 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %45, align 8
  %51 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %47, i64 0, i32 0
  %52 = bitcast %"class.marl::Allocator"* %50 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %53 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %52, align 8
  %54 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %53, i64 3
  %55 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %54, align 8
  tail call void %55(%"class.marl::Allocator"* %50, %"struct.marl::Allocation"* dereferenceable(32) %51) #12
  %56 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %49, null
  br i1 %56, label %57, label %46

57:                                               ; preds = %46, %40
  %58 = bitcast %"struct.marl::Allocation"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %58) #13
  %59 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 0
  %60 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %58, i8 -86, i64 32, i1 false) #13
  %61 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 2
  %62 = bitcast i8* %61 to i16*
  store i16 512, i16* %62, align 8
  %63 = bitcast %"struct.marl::Allocation"* %2 to %"struct.marl::Event::Shared"**
  store %"struct.marl::Event::Shared"* %4, %"struct.marl::Event::Shared"** %63, align 8
  %64 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 1, i32 0, i32 1
  %65 = load i64, i64* %64, align 8
  %66 = mul i64 %65, 272
  store i64 %66, i64* %59, align 8
  store i64 8, i64* %60, align 8
  %67 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 1, i32 0, i32 0
  %68 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %67, align 8
  %69 = bitcast %"class.marl::Allocator"* %68 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %70 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %69, align 8
  %71 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %70, i64 3
  %72 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %71, align 8
  call void %72(%"class.marl::Allocator"* %68, %"struct.marl::Allocation"* nonnull dereferenceable(32) %2) #12
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %58) #13
  ret void
}

; Function Attrs: nounwind optsize
declare i8* @_ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info(%"class.std::__1::__shared_weak_count"*, %"class.std::type_info"* dereferenceable(16)) unnamed_addr #7

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN4marl5Event6SharedENS1_9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #0 comdat align 2 {
  %2 = bitcast %"class.std::__1::__shared_ptr_pointer"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #14
  ret void
}

; Function Attrs: nobuiltin nounwind optsize
declare void @_ZdlPv(i8*) local_unnamed_addr #9

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variableD1Ev(%"class.std::__1::condition_variable"*) unnamed_addr #7

; Function Attrs: optsize
declare %"class.marl::Scheduler"* @_ZN4marl9Scheduler3getEv() local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZNSt3__16thread4joinEv(%"class.std::__1::thread"*) local_unnamed_addr #2

; Function Attrs: nounwind optsize
declare void @_ZNSt3__16threadD1Ev(%"class.std::__1::thread"*) unnamed_addr #7

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED2Ev(%"struct.std::__1::__shared_ptr_emplace"*) unnamed_addr #5 comdat align 2 {
  %2 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 0
  tail call void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"* %3) #12
  ret void
}

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEED0Ev(%"struct.std::__1::__shared_ptr_emplace"*) unnamed_addr #5 comdat align 2 {
  %2 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 0
  tail call void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"* %3) #12
  %4 = bitcast %"struct.std::__1::__shared_ptr_emplace"* %0 to i8*
  tail call void @_ZdlPv(i8* %4) #14
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE16__on_zero_sharedEv(%"struct.std::__1::__shared_ptr_emplace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 1, i32 0, i64 96
  %3 = bitcast i8* %2 to %"class.std::__1::condition_variable"*
  tail call void @_ZNSt3__118condition_variableD1Ev(%"class.std::__1::condition_variable"* %3) #12
  %4 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 1, i32 0, i64 88
  %5 = bitcast i8* %4 to %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"**
  br label %6

6:                                                ; preds = %6, %1
  %7 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** [ %5, %1 ], [ %10, %6 ]
  %8 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %7, align 8
  %9 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %8, null
  %10 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %8, i64 0, i32 1
  br i1 %9, label %11, label %6

11:                                               ; preds = %6
  %12 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 1, i32 0, i64 72
  %13 = bitcast i8* %12 to %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"**
  %14 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %13, align 8
  %15 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %14, null
  br i1 %15, label %30, label %16

16:                                               ; preds = %11
  %17 = getelementptr inbounds %"struct.std::__1::__shared_ptr_emplace", %"struct.std::__1::__shared_ptr_emplace"* %0, i64 0, i32 1, i32 0, i64 48
  %18 = bitcast i8* %17 to %"class.marl::Allocator"**
  br label %19

19:                                               ; preds = %19, %16
  %20 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* [ %14, %16 ], [ %22, %19 ]
  %21 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %20, i64 0, i32 1
  %22 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %21, align 8
  %23 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %18, align 8
  %24 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %20, i64 0, i32 0
  %25 = bitcast %"class.marl::Allocator"* %23 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %26 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %25, align 8
  %27 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %26, i64 3
  %28 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %27, align 8
  tail call void %28(%"class.marl::Allocator"* %23, %"struct.marl::Allocation"* dereferenceable(32) %24) #12
  %29 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %22, null
  br i1 %29, label %30, label %19

30:                                               ; preds = %19, %11
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_emplaceIN4marl9WaitGroup4DataENS_9allocatorIS3_EEE21__on_zero_shared_weakEv(%"struct.std::__1::__shared_ptr_emplace"*) unnamed_addr #0 comdat align 2 {
  %2 = bitcast %"struct.std::__1::__shared_ptr_emplace"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #14
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__110shared_ptrIN4marl9WaitGroup4DataEED2Ev(%"class.std::__1::shared_ptr.171"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::shared_ptr.171", %"class.std::__1::shared_ptr.171"* %0, i64 0, i32 1
  %3 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %2, align 8
  %4 = icmp eq %"class.std::__1::__shared_weak_count"* %3, null
  br i1 %4, label %15, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0, i32 1
  %7 = atomicrmw add i64* %6, i64 -1 acq_rel
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %9, label %15

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0
  %11 = bitcast %"class.std::__1::__shared_weak_count"* %3 to void (%"class.std::__1::__shared_count"*)***
  %12 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %11, align 8
  %13 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %12, i64 2
  %14 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %13, align 8
  tail call void %14(%"class.std::__1::__shared_count"* %10) #12
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %3) #12
  br label %15

15:                                               ; preds = %9, %5, %1
  ret void
}

; Function Attrs: optsize
declare void @_ZNSt3__115__thread_structC1Ev(%"class.std::__1::__thread_struct"*) unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define internal noalias i8* @"_ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEEZN4marl6detail11OnNewThreadIvE4callIZN2vk15BinarySemaphore4waitEvE3$_0JEEEvOT_DpOT0_EUlvE_EEEEEPvSM_"(i8*) #0 {
  %2 = alloca %"class.std::__1::unique_ptr.184", align 8
  %3 = bitcast %"class.std::__1::unique_ptr.184"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %3) #13
  %4 = ptrtoint i8* %0 to i64
  %5 = bitcast %"class.std::__1::unique_ptr.184"* %2 to i64*
  store i64 %4, i64* %5, align 8
  %6 = tail call dereferenceable(4) %"class.std::__1::__thread_specific_ptr"* @_ZNSt3__119__thread_local_dataEv() #12
  %7 = bitcast i8* %0 to %"class.std::__1::__thread_struct"**
  %8 = bitcast i8* %0 to i8**
  %9 = load i8*, i8** %8, align 8
  store %"class.std::__1::__thread_struct"* null, %"class.std::__1::__thread_struct"** %7, align 8
  %10 = getelementptr inbounds %"class.std::__1::__thread_specific_ptr", %"class.std::__1::__thread_specific_ptr"* %6, i64 0, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = tail call i32 @pthread_setspecific(i32 %11, i8* %9) #12
  %13 = getelementptr inbounds i8, i8* %0, i64 24
  %14 = bitcast i8* %13 to %"class.marl::Scheduler"***
  %15 = load %"class.marl::Scheduler"**, %"class.marl::Scheduler"*** %14, align 8
  %16 = load %"class.marl::Scheduler"*, %"class.marl::Scheduler"** %15, align 8
  %17 = icmp eq %"class.marl::Scheduler"* %16, null
  br i1 %17, label %19, label %18

18:                                               ; preds = %1
  tail call void @_ZN4marl9Scheduler4bindEv(%"class.marl::Scheduler"* nonnull %16) #12
  br label %19

19:                                               ; preds = %18, %1
  %20 = getelementptr inbounds i8, i8* %0, i64 32
  %21 = bitcast i8* %20 to %class.anon**
  %22 = load %class.anon*, %class.anon** %21, align 8
  %23 = getelementptr inbounds %class.anon, %class.anon* %22, i64 0, i32 0
  %24 = load %"class.vk::BinarySemaphore::External"*, %"class.vk::BinarySemaphore::External"** %23, align 8
  %25 = bitcast %"class.vk::BinarySemaphore::External"* %24 to void (%"class.vk::BinarySemaphore::External"*)***
  %26 = load void (%"class.vk::BinarySemaphore::External"*)**, void (%"class.vk::BinarySemaphore::External"*)*** %25, align 8
  %27 = getelementptr inbounds void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %26, i64 4
  %28 = load void (%"class.vk::BinarySemaphore::External"*)*, void (%"class.vk::BinarySemaphore::External"*)** %27, align 8
  tail call void %28(%"class.vk::BinarySemaphore::External"* %24) #12
  %29 = load %"class.marl::Scheduler"**, %"class.marl::Scheduler"*** %14, align 8
  %30 = load %"class.marl::Scheduler"*, %"class.marl::Scheduler"** %29, align 8
  %31 = icmp eq %"class.marl::Scheduler"* %30, null
  br i1 %31, label %33, label %32

32:                                               ; preds = %19
  tail call void @_ZN4marl9Scheduler6unbindEv() #12
  br label %33

33:                                               ; preds = %32, %19
  %34 = getelementptr inbounds i8, i8* %0, i64 8
  %35 = bitcast i8* %34 to %"struct.marl::WaitGroup::Data"**
  %36 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %35, align 8
  %37 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %36, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %38 = atomicrmw sub i32* %37, i32 1 seq_cst
  %39 = icmp eq i32 %38, 1
  br i1 %39, label %40, label %66

40:                                               ; preds = %33
  %41 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %35, align 8
  %42 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %41, i64 0, i32 2, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %42) #12
  %43 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %35, align 8
  %44 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %43, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %45 = load atomic i32, i32* %44 seq_cst, align 4
  %46 = icmp eq i32 %45, 0
  br i1 %46, label %65, label %47

47:                                               ; preds = %40
  %48 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %43, i64 0, i32 1, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %48) #12
  %49 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %43, i64 0, i32 1, i32 1, i32 5
  %50 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %49, align 8
  %51 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %50, null
  br i1 %51, label %52, label %56

52:                                               ; preds = %56, %47
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %48) #12
  %53 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %43, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %54 = load atomic i32, i32* %53 seq_cst, align 4
  %55 = icmp sgt i32 %54, 0
  br i1 %55, label %63, label %65

56:                                               ; preds = %47, %56
  %57 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %61, %56 ], [ %50, %47 ]
  %58 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %57, i64 0, i32 0
  %59 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %58, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %59) #12
  %60 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %57, i64 0, i32 1
  %61 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %60, align 8
  %62 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %61, null
  br i1 %62, label %52, label %56

63:                                               ; preds = %52
  %64 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %43, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"* %64) #12
  br label %65

65:                                               ; preds = %63, %52, %40
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %42) #12
  br label %66

66:                                               ; preds = %33, %65
  call fastcc void @"_ZNSt3__110unique_ptrINS_5tupleIJNS0_INS_15__thread_structENS_14default_deleteIS2_EEEEZN4marl6detail11OnNewThreadIvE4callIZN2vk15BinarySemaphore4waitEvE3$_0JEEEvOT_DpOT0_EUlvE_EEENS3_ISK_EEED2Ev"(%"class.std::__1::unique_ptr.184"* nonnull %2) #12
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %3) #13
  ret i8* null
}

; Function Attrs: nounwind optsize ssp uwtable
define internal fastcc void @"_ZNSt3__110unique_ptrINS_5tupleIJNS0_INS_15__thread_structENS_14default_deleteIS2_EEEEZN4marl6detail11OnNewThreadIvE4callIZN2vk15BinarySemaphore4waitEvE3$_0JEEEvOT_DpOT0_EUlvE_EEENS3_ISK_EEED2Ev"(%"class.std::__1::unique_ptr.184"* nocapture) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.std::__1::unique_ptr.184", %"class.std::__1::unique_ptr.184"* %0, i64 0, i32 0, i32 0, i32 0
  %3 = load %"class.std::__1::tuple"*, %"class.std::__1::tuple"** %2, align 8
  store %"class.std::__1::tuple"* null, %"class.std::__1::tuple"** %2, align 8
  %4 = icmp eq %"class.std::__1::tuple"* %3, null
  br i1 %4, label %9, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %3, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  tail call void @_ZNSt3__110shared_ptrIN4marl9WaitGroup4DataEED2Ev(%"class.std::__1::shared_ptr.171"* %6) #12
  %7 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %3, i64 0, i32 0, i32 0, i32 0
  tail call void @_ZNSt3__110unique_ptrINS_15__thread_structENS_14default_deleteIS1_EEE5resetEPS1_(%"class.std::__1::unique_ptr.180"* %7, %"class.std::__1::__thread_struct"* null) #12
  %8 = bitcast %"class.std::__1::tuple"* %3 to i8*
  tail call void @_ZdlPv(i8* %8) #14
  br label %9

9:                                                ; preds = %1, %5
  ret void
}

; Function Attrs: nounwind optsize
declare i32 @pthread_create(i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*) local_unnamed_addr #7

; Function Attrs: optsize
declare dereferenceable(4) %"class.std::__1::__thread_specific_ptr"* @_ZNSt3__119__thread_local_dataEv() local_unnamed_addr #2

; Function Attrs: nounwind optsize
declare i32 @pthread_setspecific(i32, i8*) local_unnamed_addr #7

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler4bindEv(%"class.marl::Scheduler"*) local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler6unbindEv() local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__110unique_ptrINS_15__thread_structENS_14default_deleteIS1_EEE5resetEPS1_(%"class.std::__1::unique_ptr.180"*, %"class.std::__1::__thread_struct"*) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"class.std::__1::unique_ptr.180", %"class.std::__1::unique_ptr.180"* %0, i64 0, i32 0, i32 0, i32 0
  %4 = load %"class.std::__1::__thread_struct"*, %"class.std::__1::__thread_struct"** %3, align 8
  store %"class.std::__1::__thread_struct"* %1, %"class.std::__1::__thread_struct"** %3, align 8
  %5 = icmp eq %"class.std::__1::__thread_struct"* %4, null
  br i1 %5, label %8, label %6

6:                                                ; preds = %2
  tail call void @_ZNSt3__115__thread_structD1Ev(%"class.std::__1::__thread_struct"* nonnull %4) #12
  %7 = bitcast %"class.std::__1::__thread_struct"* %4 to i8*
  tail call void @_ZdlPv(i8* %7) #14
  br label %8

8:                                                ; preds = %2, %6
  ret void
}

; Function Attrs: nounwind optsize
declare void @_ZNSt3__115__thread_structD1Ev(%"class.std::__1::__thread_struct"*) unnamed_addr #7

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN4marl17ConditionVariable4waitIZNKS_9WaitGroup4waitEvEUlvE_EEvRNS_4lockEOT_(%"class.marl::ConditionVariable"*, %"class.marl::lock"* dereferenceable(16), %class.anon.193* dereferenceable(8)) local_unnamed_addr #5 comdat align 2 {
  %4 = alloca %"struct.marl::Allocation::Request", align 8
  %5 = alloca %"struct.marl::Allocation", align 8
  %6 = alloca %"class.std::__1::function.157", align 8
  %7 = getelementptr inbounds %class.anon.193, %class.anon.193* %2, i64 0, i32 0
  %8 = load %"class.marl::WaitGroup"*, %"class.marl::WaitGroup"** %7, align 8
  %9 = getelementptr inbounds %"class.marl::WaitGroup", %"class.marl::WaitGroup"* %8, i64 0, i32 0, i32 0
  %10 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %9, align 8
  %11 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %10, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = load atomic i32, i32* %11 seq_cst, align 4
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %173, label %14

14:                                               ; preds = %3
  %15 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %16 = atomicrmw add i32* %15, i32 1 seq_cst
  %17 = tail call %"class.marl::Scheduler::Fiber"* @_ZN4marl9Scheduler5Fiber7currentEv() #12
  %18 = ptrtoint %"class.marl::Scheduler::Fiber"* %17 to i64
  %19 = icmp eq %"class.marl::Scheduler::Fiber"* %17, null
  br i1 %19, label %153, label %20

20:                                               ; preds = %14
  %21 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %21) #12
  %22 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 4
  %23 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22, align 8
  %24 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %23, null
  br i1 %24, label %27, label %25

25:                                               ; preds = %20
  %26 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22 to i64*
  br label %76

27:                                               ; preds = %20
  %28 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 2
  %29 = load i64, i64* %28, align 8
  %30 = icmp ugt i64 %29, 8
  %31 = select i1 %30, i64 %29, i64 8
  %32 = mul i64 %31, 24
  %33 = add i64 %32, 40
  %34 = bitcast %"struct.marl::Allocation::Request"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %34) #13
  %35 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 0
  %36 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false) #13
  %37 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %4, i64 0, i32 2
  %38 = bitcast i8* %37 to i16*
  store i16 1024, i16* %38, align 8
  store i64 %33, i64* %35, align 8
  store i64 8, i64* %36, align 8
  %39 = bitcast %"struct.marl::Allocation"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %39) #13
  %40 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %39, i8 -86, i64 32, i1 false) #13
  %41 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %40, align 8
  %42 = bitcast %"class.marl::Allocator"* %41 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  %43 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %42, align 8
  %44 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %43, i64 2
  %45 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %44, align 8
  call void %45(%"struct.marl::Allocation"* nonnull sret %5, %"class.marl::Allocator"* %41, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %4) #12
  %46 = bitcast %"struct.marl::Allocation"* %5 to %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"**
  %47 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %46, align 8
  %48 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22 to i64*
  br label %49

49:                                               ; preds = %60, %27
  %50 = phi i64 [ 0, %27 ], [ %61, %60 ]
  %51 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %47, i64 %50
  %52 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %47, i64 %50, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* null, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %52, align 8
  %53 = load i64, i64* %48, align 8
  %54 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %47, i64 %50, i32 1
  %55 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %54 to i64*
  store i64 %53, i64* %55, align 8
  %56 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22, align 8
  %57 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %56, null
  br i1 %57, label %60, label %58

58:                                               ; preds = %49
  %59 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %56, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %51, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %59, align 8
  br label %60

60:                                               ; preds = %58, %49
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %51, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22, align 8
  %61 = add nuw i64 %50, 1
  %62 = icmp eq i64 %61, %31
  br i1 %62, label %63, label %49

63:                                               ; preds = %60
  %64 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %5, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds i8, i8* %65, i64 %32
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %66, i8* nonnull align 8 %39, i64 32, i1 false) #13
  %67 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 3
  %68 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %67 to i64*
  %69 = load i64, i64* %68, align 8
  %70 = getelementptr inbounds i8, i8* %66, i64 32
  %71 = bitcast i8* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %67 to i8**
  store i8* %66, i8** %72, align 8
  %73 = load i64, i64* %28, align 8
  %74 = add i64 %73, %31
  store i64 %74, i64* %28, align 8
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %39) #13
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %34) #13
  %75 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22, align 8
  br label %76

76:                                               ; preds = %63, %25
  %77 = phi i64* [ %26, %25 ], [ %48, %63 ]
  %78 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %23, %25 ], [ %75, %63 ]
  %79 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %78, i64 0, i32 1
  %80 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %79 to i64*
  %81 = load i64, i64* %80, align 8
  store i64 %81, i64* %77, align 8
  %82 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %78, i64 0, i32 2
  %83 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %82, align 8
  %84 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %83, null
  br i1 %84, label %89, label %85

85:                                               ; preds = %76
  %86 = load i64, i64* %80, align 8
  %87 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %83, i64 0, i32 1
  %88 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %87 to i64*
  store i64 %86, i64* %88, align 8
  br label %89

89:                                               ; preds = %85, %76
  %90 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %79, align 8
  %91 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %90, null
  br i1 %91, label %97, label %92

92:                                               ; preds = %89
  %93 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %82 to i64*
  %94 = load i64, i64* %93, align 8
  %95 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %90, i64 0, i32 2
  %96 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %95 to i64*
  store i64 %94, i64* %96, align 8
  br label %97

97:                                               ; preds = %92, %89
  %98 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %79 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %98, i8 0, i64 16, i1 false) #13
  %99 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 5
  %100 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %99, align 8
  %101 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %100, null
  br i1 %101, label %105, label %102

102:                                              ; preds = %97
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %100, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %79, align 8
  %103 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %99, align 8
  %104 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %103, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %78, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %104, align 8
  br label %105

105:                                              ; preds = %97, %102
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %78, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %99, align 8
  %106 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %78 to i64*
  store i64 %18, i64* %106, align 8
  %107 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 1, i32 1
  %108 = load i64, i64* %107, align 8
  %109 = add i64 %108, 1
  store i64 %109, i64* %107, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %21) #12
  %110 = bitcast %"class.std::__1::function.157"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %110) #13
  %111 = bitcast %class.anon.193* %2 to i64*
  %112 = load i64, i64* %111, align 8
  %113 = getelementptr inbounds %"class.std::__1::function.157", %"class.std::__1::function.157"* %6, i64 0, i32 0, i32 1, i32 0
  %114 = getelementptr inbounds %"class.std::__1::function.157", %"class.std::__1::function.157"* %6, i64 0, i32 0, i32 2
  store i1 (%"union.std::__1::__function::__policy_storage"*)* @_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZNK4marl9WaitGroup4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE, i1 (%"union.std::__1::__function::__policy_storage"*)** %113, align 8
  store %"struct.std::__1::__function::__policy"* @_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZNK4marl9WaitGroup4waitEvEUlvE_FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_, %"struct.std::__1::__function::__policy"** %114, align 8
  %115 = bitcast %"class.std::__1::function.157"* %6 to i64*
  store i64 %112, i64* %115, align 8
  call void @_ZN4marl9Scheduler5Fiber4waitERNS_4lockERKNSt3__18functionIFbvEEE(%"class.marl::Scheduler::Fiber"* nonnull %17, %"class.marl::lock"* dereferenceable(16) %1, %"class.std::__1::function.157"* nonnull dereferenceable(32) %6) #12
  %116 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %114, align 8
  %117 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %116, i64 0, i32 1
  %118 = load void (i8*)*, void (i8*)** %117, align 8
  %119 = icmp eq void (i8*)* %118, null
  br i1 %119, label %123, label %120

120:                                              ; preds = %105
  %121 = getelementptr inbounds %"class.std::__1::function.157", %"class.std::__1::function.157"* %6, i64 0, i32 0, i32 0, i32 0
  %122 = load i8*, i8** %121, align 8
  call void %118(i8* %122) #12
  br label %123

123:                                              ; preds = %105, %120
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %110) #13
  call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %21) #12
  %124 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %99, align 8
  %125 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %124, %78
  br i1 %125, label %126, label %129

126:                                              ; preds = %123
  %127 = load i64, i64* %80, align 8
  %128 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %99 to i64*
  store i64 %127, i64* %128, align 8
  br label %129

129:                                              ; preds = %126, %123
  %130 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %82, align 8
  %131 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %130, null
  br i1 %131, label %136, label %132

132:                                              ; preds = %129
  %133 = load i64, i64* %80, align 8
  %134 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %130, i64 0, i32 1
  %135 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %134 to i64*
  store i64 %133, i64* %135, align 8
  br label %136

136:                                              ; preds = %132, %129
  %137 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %79, align 8
  %138 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %137, null
  br i1 %138, label %144, label %139

139:                                              ; preds = %136
  %140 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %82 to i64*
  %141 = load i64, i64* %140, align 8
  %142 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %137, i64 0, i32 2
  %143 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %142 to i64*
  store i64 %141, i64* %143, align 8
  br label %144

144:                                              ; preds = %139, %136
  call void @llvm.memset.p0i8.i64(i8* align 8 %98, i8 0, i64 16, i1 false) #13
  %145 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22, align 8
  %146 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %145, null
  br i1 %146, label %150, label %147

147:                                              ; preds = %144
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %145, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %79, align 8
  %148 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22, align 8
  %149 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %148, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %78, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %149, align 8
  br label %150

150:                                              ; preds = %144, %147
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %78, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %22, align 8
  %151 = load i64, i64* %107, align 8
  %152 = add i64 %151, -1
  store i64 %152, i64* %107, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %21) #12
  br label %171

153:                                              ; preds = %14
  %154 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %155 = atomicrmw add i32* %154, i32 1 seq_cst
  %156 = getelementptr inbounds %"class.marl::ConditionVariable", %"class.marl::ConditionVariable"* %0, i64 0, i32 2
  %157 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %1, i64 0, i32 0
  %158 = load %"class.marl::WaitGroup"*, %"class.marl::WaitGroup"** %7, align 8
  %159 = getelementptr inbounds %"class.marl::WaitGroup", %"class.marl::WaitGroup"* %158, i64 0, i32 0, i32 0
  %160 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %159, align 8
  %161 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %160, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %162 = load atomic i32, i32* %161 seq_cst, align 4
  %163 = icmp eq i32 %162, 0
  br i1 %163, label %169, label %164

164:                                              ; preds = %153, %164
  tail call void @_ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE(%"class.std::__1::condition_variable"* %156, %"class.std::__1::unique_lock"* dereferenceable(16) %157) #12
  %165 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %159, align 8
  %166 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %165, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %167 = load atomic i32, i32* %166 seq_cst, align 4
  %168 = icmp eq i32 %167, 0
  br i1 %168, label %169, label %164

169:                                              ; preds = %164, %153
  %170 = atomicrmw sub i32* %154, i32 1 seq_cst
  br label %171

171:                                              ; preds = %169, %150
  %172 = atomicrmw sub i32* %15, i32 1 seq_cst
  br label %173

173:                                              ; preds = %3, %171
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZNK4marl9WaitGroup4waitEvEUlvE_S2_EEEEbPKNS0_16__policy_storageE(%"union.std::__1::__function::__policy_storage"*) #0 comdat align 2 {
  %2 = bitcast %"union.std::__1::__function::__policy_storage"* %0 to %"class.marl::WaitGroup"**
  %3 = load %"class.marl::WaitGroup"*, %"class.marl::WaitGroup"** %2, align 8
  %4 = getelementptr inbounds %"class.marl::WaitGroup", %"class.marl::WaitGroup"* %3, i64 0, i32 0, i32 0
  %5 = load %"struct.marl::WaitGroup::Data"*, %"struct.marl::WaitGroup::Data"** %4, align 8
  %6 = getelementptr inbounds %"struct.marl::WaitGroup::Data", %"struct.marl::WaitGroup::Data"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load atomic i32, i32* %6 seq_cst, align 4
  %8 = icmp eq i32 %7, 0
  ret i1 %8
}

; Function Attrs: optsize
declare i8* @_ZN2vk8allocateEmmPK21VkAllocationCallbacks23VkSystemAllocationScope(i64, i64, %struct.VkAllocationCallbacks*, i32) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk25OpaqueFdExternalSemaphoreD2Ev(%"class.vk::OpaqueFdExternalSemaphore"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [10 x i8*] }, { [10 x i8*] }* @_ZTVN2vk25OpaqueFdExternalSemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  tail call void @_ZN2vk25OpaqueFdExternalSemaphore11unmapRegionEv(%"class.vk::OpaqueFdExternalSemaphore"* %0) #16
  %3 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 1
  tail call void @_ZN10LinuxMemFdD1Ev(%class.LinuxMemFd* %3) #12
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk25OpaqueFdExternalSemaphoreD0Ev(%"class.vk::OpaqueFdExternalSemaphore"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [10 x i8*] }, { [10 x i8*] }* @_ZTVN2vk25OpaqueFdExternalSemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  tail call void @_ZN2vk25OpaqueFdExternalSemaphore11unmapRegionEv(%"class.vk::OpaqueFdExternalSemaphore"* %0) #12
  %3 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 1
  tail call void @_ZN10LinuxMemFdD1Ev(%class.LinuxMemFd* %3) #12
  %4 = bitcast %"class.vk::OpaqueFdExternalSemaphore"* %0 to i8*
  tail call void @_ZdlPv(i8* %4) #14
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden i32 @_ZN2vk25OpaqueFdExternalSemaphore4initEb(%"class.vk::OpaqueFdExternalSemaphore"*, i1 zeroext) unnamed_addr #0 comdat align 2 {
  %3 = alloca [40 x i8], align 16
  %4 = tail call i64 @_ZN2sw14memoryPageSizeEv() #12
  %5 = getelementptr inbounds [40 x i8], [40 x i8]* %3, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %5) #13
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %5, i8 -86, i64 40, i1 false)
  %6 = load i32, i32* @_ZZN2vk25OpaqueFdExternalSemaphore4initEbE7counter, align 4
  %7 = add nsw i32 %6, 1
  store i32 %7, i32* @_ZZN2vk25OpaqueFdExternalSemaphore4initEbE7counter, align 4
  %8 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %5, i64 40, i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.9, i64 0, i64 0), i32 %7) #12
  %9 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 1
  %10 = call zeroext i1 @_ZN10LinuxMemFd8allocateEPKcm(%class.LinuxMemFd* %9, i8* nonnull %5, i64 %4) #12
  br i1 %10, label %15, label %11

11:                                               ; preds = %2
  %12 = tail call i32* @__errno_location() #17
  %13 = load i32, i32* %12, align 4
  %14 = call i8* @strerror(i32 %13) #12
  call void (i8*, ...) @_ZN2sw5traceEPKcz(i8* getelementptr inbounds ([43 x i8], [43 x i8]* @.str.10, i64 0, i64 0), i8* getelementptr inbounds ([70 x i8], [70 x i8]* @.str.11, i64 0, i64 0), i32 150, i8* %14) #12
  br label %18

15:                                               ; preds = %2
  %16 = call zeroext i1 @_ZN2vk25OpaqueFdExternalSemaphore9mapRegionEmbb(%"class.vk::OpaqueFdExternalSemaphore"* %0, i64 %4, i1 zeroext true, i1 zeroext %1) #16
  %17 = select i1 %16, i32 0, i32 -3
  br label %18

18:                                               ; preds = %15, %11
  %19 = phi i32 [ -3, %11 ], [ %17, %15 ]
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %5) #13
  ret i32 %19
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN2vk25OpaqueFdExternalSemaphore7tryWaitEv(%"class.vk::OpaqueFdExternalSemaphore"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 2
  %3 = load %class.SharedSemaphore*, %class.SharedSemaphore** %2, align 8
  %4 = tail call zeroext i1 @_ZN15SharedSemaphore7tryWaitEv(%class.SharedSemaphore* %3) #16
  ret i1 %4
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk25OpaqueFdExternalSemaphore4waitEv(%"class.vk::OpaqueFdExternalSemaphore"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 2
  %3 = load %class.SharedSemaphore*, %class.SharedSemaphore** %2, align 8
  tail call void @_ZN15SharedSemaphore4waitEv(%class.SharedSemaphore* %3) #16
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk25OpaqueFdExternalSemaphore6signalEv(%"class.vk::OpaqueFdExternalSemaphore"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 2
  %3 = load %class.SharedSemaphore*, %class.SharedSemaphore** %2, align 8
  tail call void @_ZN15SharedSemaphore6signalEv(%class.SharedSemaphore* %3) #16
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden i32 @_ZN2vk25OpaqueFdExternalSemaphore14importOpaqueFdEi(%"class.vk::OpaqueFdExternalSemaphore"*, i32) unnamed_addr #0 comdat align 2 {
  tail call void @_ZN2vk25OpaqueFdExternalSemaphore11unmapRegionEv(%"class.vk::OpaqueFdExternalSemaphore"* %0) #16
  %3 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 1
  tail call void @_ZN10LinuxMemFd8importFdEi(%class.LinuxMemFd* %3, i32 %1) #12
  %4 = tail call i64 @_ZN2sw14memoryPageSizeEv() #12
  %5 = tail call zeroext i1 @_ZN2vk25OpaqueFdExternalSemaphore9mapRegionEmbb(%"class.vk::OpaqueFdExternalSemaphore"* %0, i64 %4, i1 zeroext false, i1 zeroext false) #16
  %6 = select i1 %5, i32 0, i32 -3
  ret i32 %6
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden i32 @_ZN2vk25OpaqueFdExternalSemaphore14exportOpaqueFdEPi(%"class.vk::OpaqueFdExternalSemaphore"*, i32*) unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 1
  %4 = tail call i32 @_ZNK10LinuxMemFd8exportFdEv(%class.LinuxMemFd* %3) #12
  %5 = icmp slt i32 %4, 0
  br i1 %5, label %7, label %6

6:                                                ; preds = %2
  store i32 %4, i32* %1, align 4
  br label %7

7:                                                ; preds = %2, %6
  %8 = phi i32 [ 0, %6 ], [ -1000072003, %2 ]
  ret i32 %8
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk25OpaqueFdExternalSemaphore11unmapRegionEv(%"class.vk::OpaqueFdExternalSemaphore"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 2
  %3 = load %class.SharedSemaphore*, %class.SharedSemaphore** %2, align 8
  %4 = icmp eq %class.SharedSemaphore* %3, null
  br i1 %4, label %25, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %3, i64 0, i32 0
  %7 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %6) #12
  %8 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %3, i64 0, i32 2
  %9 = load i32, i32* %8, align 8
  %10 = add nsw i32 %9, -1
  store i32 %10, i32* %8, align 8
  %11 = icmp eq i32 %10, 0
  %12 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %6) #12
  br i1 %11, label %13, label %19

13:                                               ; preds = %5
  %14 = load %class.SharedSemaphore*, %class.SharedSemaphore** %2, align 8
  %15 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %14, i64 0, i32 1
  %16 = tail call i32 @pthread_cond_destroy(%union.pthread_cond_t* %15) #12
  %17 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %14, i64 0, i32 0
  %18 = tail call i32 @pthread_mutex_destroy(%union.pthread_mutex_t* %17) #12
  br label %19

19:                                               ; preds = %13, %5
  %20 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 1
  %21 = bitcast %class.SharedSemaphore** %2 to i8**
  %22 = load i8*, i8** %21, align 8
  %23 = tail call i64 @_ZN2sw14memoryPageSizeEv() #12
  %24 = tail call zeroext i1 @_ZN10LinuxMemFd5unmapEPvm(%class.LinuxMemFd* %20, i8* %22, i64 %23) #12
  tail call void @_ZN10LinuxMemFd5closeEv(%class.LinuxMemFd* %20) #12
  store %class.SharedSemaphore* null, %class.SharedSemaphore** %2, align 8
  br label %25

25:                                               ; preds = %1, %19
  ret void
}

; Function Attrs: nounwind optsize
declare void @_ZN10LinuxMemFdD1Ev(%class.LinuxMemFd*) unnamed_addr #7

; Function Attrs: optsize
declare zeroext i1 @_ZN10LinuxMemFd5unmapEPvm(%class.LinuxMemFd*, i8*, i64) local_unnamed_addr #2

; Function Attrs: optsize
declare i64 @_ZN2sw14memoryPageSizeEv() local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZN10LinuxMemFd5closeEv(%class.LinuxMemFd*) local_unnamed_addr #2

; Function Attrs: nounwind optsize
declare i32 @pthread_mutex_lock(%union.pthread_mutex_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_mutex_unlock(%union.pthread_mutex_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_cond_destroy(%union.pthread_cond_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_mutex_destroy(%union.pthread_mutex_t*) local_unnamed_addr #7

; Function Attrs: nofree nounwind optsize
declare i32 @snprintf(i8* nocapture, i64, i8* nocapture readonly, ...) local_unnamed_addr #10

; Function Attrs: optsize
declare zeroext i1 @_ZN10LinuxMemFd8allocateEPKcm(%class.LinuxMemFd*, i8*, i64) local_unnamed_addr #2

; Function Attrs: nounwind optsize
declare i8* @strerror(i32) local_unnamed_addr #7

; Function Attrs: nounwind optsize readnone
declare i32* @__errno_location() local_unnamed_addr #11

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN2vk25OpaqueFdExternalSemaphore9mapRegionEmbb(%"class.vk::OpaqueFdExternalSemaphore"*, i64, i1 zeroext, i1 zeroext) local_unnamed_addr #0 comdat align 2 {
  %5 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 1
  %6 = tail call i8* @_ZN10LinuxMemFd12mapReadWriteEmm(%class.LinuxMemFd* %5, i64 0, i64 %1) #12
  %7 = icmp eq i8* %6, null
  br i1 %7, label %8, label %12

8:                                                ; preds = %4
  %9 = tail call i32* @__errno_location() #17
  %10 = load i32, i32* %9, align 4
  %11 = tail call i8* @strerror(i32 %10) #12
  tail call void (i8*, ...) @_ZN2sw5traceEPKcz(i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.12, i64 0, i64 0), i8* getelementptr inbounds ([70 x i8], [70 x i8]* @.str.11, i64 0, i64 0), i32 221, i8* %11) #12
  br label %25

12:                                               ; preds = %4
  %13 = getelementptr inbounds %"class.vk::OpaqueFdExternalSemaphore", %"class.vk::OpaqueFdExternalSemaphore"* %0, i64 0, i32 2
  %14 = bitcast %class.SharedSemaphore** %13 to i8**
  store i8* %6, i8** %14, align 8
  br i1 %2, label %15, label %17

15:                                               ; preds = %12
  %16 = bitcast i8* %6 to %class.SharedSemaphore*
  tail call void @_ZN15SharedSemaphoreC2Eb(%class.SharedSemaphore* nonnull %16, i1 zeroext %3) #16
  br label %25

17:                                               ; preds = %12
  %18 = bitcast i8* %6 to %union.pthread_mutex_t*
  %19 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %18) #12
  %20 = getelementptr inbounds i8, i8* %6, i64 88
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 8
  %23 = add nsw i32 %22, 1
  store i32 %23, i32* %21, align 8
  %24 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %18) #12
  br label %25

25:                                               ; preds = %15, %17, %8
  %26 = phi i1 [ false, %8 ], [ true, %17 ], [ true, %15 ]
  ret i1 %26
}

; Function Attrs: optsize
declare i8* @_ZN10LinuxMemFd12mapReadWriteEmm(%class.LinuxMemFd*, i64, i64) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN15SharedSemaphoreC2Eb(%class.SharedSemaphore*, i1 zeroext) unnamed_addr #0 comdat align 2 {
  %3 = alloca %union.pthread_mutexattr_t, align 4
  %4 = alloca %union.pthread_condattr_t, align 4
  %5 = zext i1 %1 to i8
  %6 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 2
  store i32 1, i32* %6, align 8
  %7 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 3
  store i8 %5, i8* %7, align 4
  %8 = bitcast %union.pthread_mutexattr_t* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %8) #13
  %9 = getelementptr inbounds %union.pthread_mutexattr_t, %union.pthread_mutexattr_t* %3, i64 0, i32 0
  store i32 -1431655766, i32* %9, align 4
  %10 = call i32 @pthread_mutexattr_init(%union.pthread_mutexattr_t* nonnull %3) #12
  %11 = call i32 @pthread_mutexattr_setpshared(%union.pthread_mutexattr_t* nonnull %3, i32 1) #12
  %12 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 0
  %13 = call i32 @pthread_mutex_init(%union.pthread_mutex_t* %12, %union.pthread_mutexattr_t* nonnull %3) #12
  %14 = call i32 @pthread_mutexattr_destroy(%union.pthread_mutexattr_t* nonnull %3) #12
  %15 = bitcast %union.pthread_condattr_t* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %15) #13
  %16 = getelementptr inbounds %union.pthread_condattr_t, %union.pthread_condattr_t* %4, i64 0, i32 0
  store i32 -1431655766, i32* %16, align 4
  %17 = call i32 @pthread_condattr_init(%union.pthread_condattr_t* nonnull %4) #12
  %18 = call i32 @pthread_condattr_setpshared(%union.pthread_condattr_t* nonnull %4, i32 1) #12
  %19 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 1
  %20 = call i32 @pthread_cond_init(%union.pthread_cond_t* %19, %union.pthread_condattr_t* nonnull %4) #12
  %21 = call i32 @pthread_condattr_destroy(%union.pthread_condattr_t* nonnull %4) #12
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %15) #13
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %8) #13
  ret void
}

; Function Attrs: nounwind optsize
declare i32 @pthread_mutexattr_init(%union.pthread_mutexattr_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_mutexattr_setpshared(%union.pthread_mutexattr_t*, i32) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_mutex_init(%union.pthread_mutex_t*, %union.pthread_mutexattr_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_mutexattr_destroy(%union.pthread_mutexattr_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_condattr_init(%union.pthread_condattr_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_condattr_setpshared(%union.pthread_condattr_t*, i32) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_cond_init(%union.pthread_cond_t*, %union.pthread_condattr_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare i32 @pthread_condattr_destroy(%union.pthread_condattr_t*) local_unnamed_addr #7

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN15SharedSemaphore7tryWaitEv(%class.SharedSemaphore*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 0
  %3 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #12
  %4 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 3
  %5 = load i8, i8* %4, align 4, !range !5
  %6 = icmp ne i8 %5, 0
  br i1 %6, label %7, label %8

7:                                                ; preds = %1
  store i8 0, i8* %4, align 4
  br label %8

8:                                                ; preds = %7, %1
  %9 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #12
  ret i1 %6
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN15SharedSemaphore4waitEv(%class.SharedSemaphore*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 0
  %3 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #12
  %4 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 3
  %5 = load i8, i8* %4, align 4, !range !5
  %6 = icmp eq i8 %5, 0
  br i1 %6, label %7, label %13

7:                                                ; preds = %1
  %8 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 1
  br label %9

9:                                                ; preds = %7, %9
  %10 = tail call i32 @pthread_cond_wait(%union.pthread_cond_t* %8, %union.pthread_mutex_t* %2) #12
  %11 = load i8, i8* %4, align 4, !range !5
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %9, label %13

13:                                               ; preds = %9, %1
  store i8 0, i8* %4, align 4
  %14 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #12
  ret void
}

; Function Attrs: optsize
declare i32 @pthread_cond_wait(%union.pthread_cond_t*, %union.pthread_mutex_t*) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN15SharedSemaphore6signalEv(%class.SharedSemaphore*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 0
  %3 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #12
  %4 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 3
  store i8 1, i8* %4, align 4
  %5 = getelementptr inbounds %class.SharedSemaphore, %class.SharedSemaphore* %0, i64 0, i32 1
  %6 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %5) #12
  %7 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #12
  ret void
}

; Function Attrs: nounwind optsize
declare i32 @pthread_cond_broadcast(%union.pthread_cond_t*) local_unnamed_addr #7

; Function Attrs: optsize
declare void @_ZN10LinuxMemFd8importFdEi(%class.LinuxMemFd*, i32) local_unnamed_addr #2

; Function Attrs: optsize
declare i32 @_ZNK10LinuxMemFd8exportFdEv(%class.LinuxMemFd*) local_unnamed_addr #2

attributes #0 = { nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { norecurse nounwind optsize readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { norecurse nounwind optsize readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { inlinehint nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { noreturn optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nobuiltin nofree optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nobuiltin nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nofree nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { nounwind optsize readnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { nounwind optsize }
attributes #13 = { nounwind }
attributes #14 = { builtin nounwind optsize }
attributes #15 = { noreturn nounwind optsize }
attributes #16 = { optsize }
attributes #17 = { nounwind optsize readnone }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!3}
!3 = distinct !{!3, !4, !"_ZNSt3__112__decay_copyIZN4marl6detail11OnNewThreadIvE4callIZN2vk15BinarySemaphore4waitEvE3$_0JEEEvOT_DpOT0_EUlvE_EENS_5decayIS9_E4typeESA_: argument 0"}
!4 = distinct !{!4, !"_ZNSt3__112__decay_copyIZN4marl6detail11OnNewThreadIvE4callIZN2vk15BinarySemaphore4waitEvE3$_0JEEEvOT_DpOT0_EUlvE_EENS_5decayIS9_E4typeESA_"}
!5 = !{i8 0, i8 2}
