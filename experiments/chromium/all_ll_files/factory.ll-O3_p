; ModuleID = 'gen/v8/torque-generated/factory.cc'
source_filename = "gen/v8/torque-generated/factory.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.v8::internal::TorqueGeneratedFactory" = type { i8 }
%"class.v8::internal::FactoryBase" = type { i8 }
%"class.v8::internal::Isolate" = type { %"class.v8::internal::IsolateData", %"class.std::__1::unique_ptr", %"class.v8::internal::Heap", %"class.v8::internal::ReadOnlyHeap"*, %"class.std::__1::shared_ptr.648", %"class.std::__1::unique_ptr.669", i32, %"class.v8::internal::Isolate::EntryStackItem"*, i32, %"class.v8::internal::StringStream"*, [13 x i64], %"class.v8::internal::Bootstrapper"*, %"class.v8::internal::RuntimeProfiler"*, %"class.v8::internal::CompilationCache"*, %"class.std::__1::shared_ptr.679", %"class.v8::base::RecursiveMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::internal::Logger"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::Deoptimizer"*, i8, %"class.v8::internal::MaterializedObjectStore"*, i8, i32, i32, %"class.v8::internal::DescriptorLookupCache"*, %"struct.v8::internal::HandleScopeData", %"class.v8::internal::HandleScopeImplementer"*, %"class.v8::internal::UnicodeCache"*, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::InnerPointerToCodeCache"*, %"class.v8::internal::GlobalHandles"*, %"class.v8::internal::EternalHandles"*, %"class.v8::internal::ThreadManager"*, %"class.v8::bigint::Processor"*, %"class.v8::internal::RuntimeState", %"class.v8::internal::Builtins", %"class.v8::internal::SetupIsolateDelegate"*, %"class.v8::internal::RegExpStack"*, %"class.std::__1::vector.818", %"class.v8::internal::DateCache"*, %"class.v8::base::RandomNumberGenerator"*, %"class.v8::base::RandomNumberGenerator"*, %"struct.std::__1::atomic.831", void (i32, %"class.v8::SharedArrayBuffer"*, i64, i64, double, %"class.v8::Isolate::AtomicsWaitWakeHandle"*, i8*)*, i8*, void (i32, %"class.v8::Promise"*, %"class.v8::Value"*)*, {}*, {}*, %"struct.std::__1::atomic.841", void (%"class.v8::Context"*, %"class.v8::Module"*, %"class.v8::Object"*)*, %"class.v8::base::Mutex", double, %"class.std::__1::basic_string", %"class.std::__1::unordered_map.852", %"struct.std::__1::atomic.155", i8, i8, i8, i8, i8, i8, double, %"class.v8::internal::Debug"*, %"class.v8::internal::HeapProfiler"*, %"class.std::__1::unique_ptr.927", %"class.v8::internal::AstStringConstants"*, %"class.v8::internal::interpreter::Interpreter"*, %"class.v8::internal::compiler::PerIsolateCompilerCache"*, %"class.v8::internal::Zone"*, %"class.v8::internal::CompilerDispatcher"*, %"class.std::__1::queue", void (i8*, i8*)*, void (i8*, i1)*, void (i8*, i32)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*, i1)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::Context"*)*, void (%"class.v8::FunctionCallbackInfo"*)*, %"class.v8::String"* (%"class.v8::Isolate"*, i8*)*, i1 (%"class.v8::Context"*)*, i1 (%"class.v8::Context"*)*, %"class.v8::internal::Relocatable"*, %"class.std::__1::vector.970"*, %"class.v8::internal::Object", i64*, %"class.v8::internal::AddressToIndexHashMap"*, %"class.v8::internal::HeapObjectToIndexHashMap"*, %"class.v8::internal::MicrotaskQueue"*, %"class.v8::internal::CompilationStatistics"*, %"class.v8::internal::CodeTracer"*, i32, void (%"class.v8::PromiseRejectMessage"*)*, %"class.v8::StartupData"*, i32, i32, i32, i64, i8, i8, i32, i8, i32, %"class.v8_inspector::V8Inspector"*, i8, i8, i8, i32, i32, %"class.v8::internal::compiler::NodeObserver"*, i8, [128 x i32], [256 x i32], [251 x i32], [251 x i32], %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.std::__1::unique_ptr.982", i32, i8, i8, i32, i32, %"class.std::__1::vector.988", %"class.std::__1::vector.988", void (%"class.v8::Isolate"*, i32)*, %"class.std::__1::shared_ptr.995", i64, %"class.std::__1::unordered_map.996", i64, %"struct.v8::metrics::LongTaskStats", %"class.std::__1::vector.544", %"class.v8::internal::BuiltinsConstantsTableBuilder"*, i8*, i32, i8*, i32, %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::shared_ptr.163", %"class.v8::internal::FutexWaitListNode", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::debug::ConsoleDelegate"*, %"class.v8::debug::AsyncEventDelegate"*, i32, i32, %"class.std::__1::unique_ptr.1052", i1 (%"class.v8::Isolate"*)*, i8, %"class.v8::base::Mutex", %"struct.v8::internal::ManagedPtrDestructor"*, i64, i64, %"class.v8::internal::wasm::WasmEngine"*, %"class.std::__1::unique_ptr.1090", %"class.v8::internal::EmbeddedFileWriterInterface"*, %"class.v8::Context::BackupIncumbentScope"*, %"class.v8::Value"* (%"class.v8::Context"*, %"class.v8::Value"*, %"class.v8::Array"*)*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate::ThreadDataTable", i8, %"class.v8::internal::Isolate"*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"struct.std::__1::atomic.1124", %"class.std::__1::vector.1128", %"class.std::__1::vector.1128", void (i32, %"class.std::__1::basic_string"*)* }
%"class.v8::internal::IsolateData" = type { [4 x i8*], i64, i64, i64, i64, i64, %"class.v8::internal::StackGuard", %"class.v8::internal::RootsTable", %"class.v8::internal::ExternalReferenceTable", %"class.v8::internal::ThreadLocalTop", [1711 x i64], [1711 x i64], i8, [15 x i8] }
%"class.v8::internal::StackGuard" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::StackGuard::ThreadLocal" }
%"class.v8::internal::StackGuard::ThreadLocal" = type { i64, i64, i64, i64, %"class.v8::internal::InterruptsScope"*, i64 }
%"class.v8::internal::InterruptsScope" = type { i32 (...)**, %"class.v8::internal::StackGuard"*, i64, i64, i32, %"class.v8::internal::InterruptsScope"* }
%"class.v8::internal::RootsTable" = type { [669 x i64] }
%"class.v8::internal::ExternalReferenceTable" = type { [1042 x i64], i32, i32 }
%"class.v8::internal::ThreadLocalTop" = type { %"class.v8::TryCatch"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Context", %"struct.std::__1::atomic", %"class.v8::internal::Object", %"class.v8::internal::Context", i64, i64, i64, i64, i64, %"class.v8::internal::Object", i8, i8, %"class.v8::internal::Object", i64, i64, i64, %"class.v8::internal::PromiseOnStack"*, %"class.v8::internal::Simulator"*, i64, %"class.v8::internal::ExternalCallbackScope"*, i32, void (%"class.v8::Object"*, i32, %"class.v8::Value"*)*, i64 }
%"class.v8::TryCatch" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::TryCatch"*, i8*, i8*, i8*, i8, [7 x i8] }>
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { %"class.v8::internal::ThreadId" }
%"class.v8::internal::ThreadId" = type { i32 }
%"class.v8::internal::Context" = type { %"class.v8::internal::TorqueGeneratedContext" }
%"class.v8::internal::TorqueGeneratedContext" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::HeapObject" = type { %"class.v8::internal::Object" }
%"class.v8::internal::PromiseOnStack" = type { %"class.v8::internal::Handle.2", %"class.v8::internal::PromiseOnStack"* }
%"class.v8::internal::Handle.2" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HandleBase" = type { i64* }
%"class.v8::internal::Simulator" = type opaque
%"class.v8::internal::ExternalCallbackScope" = type opaque
%"class.v8::Object" = type { i8 }
%"class.v8::Value" = type { i8 }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.v8::internal::IsolateAllocator"* }
%"class.v8::internal::IsolateAllocator" = type { i8*, %"class.v8::PageAllocator"* }
%"class.v8::PageAllocator" = type { i32 (...)** }
%"class.v8::internal::Heap" = type { %"class.std::__1::unordered_map", %"struct.std::__1::atomic.22", %"class.v8::internal::Heap::ExternalMemoryAccounting", %"class.v8::internal::Isolate"*, i64, i64, i64, i64, %"struct.std::__1::atomic.22", i64, i64, i64, i64, i64, i8, i64, i64, %"struct.std::__1::atomic.22", i64, i64, %"struct.std::__1::atomic.22", %"struct.std::__1::atomic.32", %"class.std::__1::vector", i32, %"class.v8::internal::NewSpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::CodeSpace"*, %"class.v8::internal::MapSpace"*, %"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::MapSpace"*, %"class.std::__1::unique_ptr.149", %"class.std::__1::unique_ptr.149", [8 x %"class.v8::internal::Space"*], %"class.v8::internal::LocalHeap"*, %"class.v8::internal::ArrayBufferExtension"*, %"class.v8::internal::ArrayBufferExtension"*, i8, i64, %"struct.std::__1::atomic.164", i32, i32, i32, i32, %"class.v8::internal::AllocationObserver"*, %"class.v8::internal::StressScavengeObserver"*, double, i32, i32, i32, i64, i32, [128 x i64], %"struct.std::__1::atomic.22", i64, i8, %"struct.std::__1::atomic.22", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.std::__1::vector.168", %"class.std::__1::vector.168", i64 ()*, [113 x i32], i64, double, double, i64, i64, double, i32, i32, i32, i32, double, double, double, %"class.std::__1::unique_ptr.175", %"class.std::__1::unique_ptr.181", %"class.v8::internal::MinorMarkCompactCollector"*, %"class.std::__1::unique_ptr.311", %"class.std::__1::unique_ptr.317", %"class.std::__1::unique_ptr.323", %"class.std::__1::unique_ptr.362", %"class.std::__1::unique_ptr.401", %"class.std::__1::unique_ptr.431", %"class.std::__1::unique_ptr.437", %"class.std::__1::unique_ptr.447", %"class.std::__1::unique_ptr.453", %"class.std::__1::unique_ptr.453", %"class.std::__1::unique_ptr.459", %"class.std::__1::unique_ptr.465", %"class.std::__1::unique_ptr.465", %"class.std::__1::unique_ptr.471", %"class.std::__1::unique_ptr.477", %"class.std::__1::shared_ptr.483", %"class.v8::CppHeap"*, %"class.v8::EmbedderRootsHandler"*, %"class.v8::internal::StrongRootsEntry"*, %"class.v8::base::Mutex", i8, i64, i64, i64, i64, %"class.std::__1::unordered_map.506", %"class.std::__1::unique_ptr.532", [512 x i8], i8, i8, i64, i8, i32, i32, %"class.std::__1::unique_ptr.538", i8, %"class.v8::internal::Heap::ExternalStringTable", %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.551", i32, i8, i8, i8, i8, i8, %"class.v8::internal::HeapObject", %"class.v8::base::SharedMutex", %"class.v8::base::Mutex", %"class.std::__1::unordered_set.333", i8, [7 x i8], %"class.std::__1::unordered_map.557", %"class.std::__1::unordered_map.583", %"class.std::__1::unordered_map.557", %"class.std::__1::unordered_map.607", %"class.std::__1::vector.635", i8, %"class.std::__1::unique_ptr.642", i32, i32 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.5", %"class.std::__1::__compressed_pair.12", %"class.std::__1::__compressed_pair.17", %"class.std::__1::__compressed_pair.19", [4 x i8] }>
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7", %"struct.std::__1::__compressed_pair_elem.8" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.8" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.9" }
%"class.std::__1::__compressed_pair.9" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"struct.std::__1::__compressed_pair_elem.10" = type { i64 }
%"class.std::__1::__compressed_pair.12" = type { %"struct.std::__1::__compressed_pair_elem.13" }
%"struct.std::__1::__compressed_pair_elem.13" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.17" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.19" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"struct.std::__1::__compressed_pair_elem.20" = type { float }
%"class.v8::internal::Heap::ExternalMemoryAccounting" = type { %"struct.std::__1::atomic.27", %"struct.std::__1::atomic.27", %"struct.std::__1::atomic.27" }
%"struct.std::__1::atomic.27" = type { %"struct.std::__1::__atomic_base.28" }
%"struct.std::__1::__atomic_base.28" = type { %"struct.std::__1::__atomic_base.29" }
%"struct.std::__1::__atomic_base.29" = type { %"struct.std::__1::__cxx_atomic_impl.30" }
%"struct.std::__1::__cxx_atomic_impl.30" = type { %"struct.std::__1::__cxx_atomic_base_impl.31" }
%"struct.std::__1::__cxx_atomic_base_impl.31" = type { i64 }
%"struct.std::__1::atomic.32" = type { %"struct.std::__1::__atomic_base.33" }
%"struct.std::__1::__atomic_base.33" = type { %"struct.std::__1::__cxx_atomic_impl.34" }
%"struct.std::__1::__cxx_atomic_impl.34" = type { %"struct.std::__1::__cxx_atomic_base_impl.35" }
%"struct.std::__1::__cxx_atomic_base_impl.35" = type { i32 }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"struct.std::__1::pair"*, %"struct.std::__1::pair"*, %"class.std::__1::__compressed_pair.36" }
%"struct.std::__1::pair" = type opaque
%"class.std::__1::__compressed_pair.36" = type { %"struct.std::__1::__compressed_pair_elem.37" }
%"struct.std::__1::__compressed_pair_elem.37" = type { %"struct.std::__1::pair"* }
%"class.v8::internal::NewSpace" = type { %"class.v8::internal::SpaceWithLinearArea", %"class.v8::base::Mutex", %"struct.std::__1::atomic.22", %"struct.std::__1::atomic.22", %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace", %"class.v8::internal::VirtualMemory", %"class.std::__1::vector.106" }
%"class.v8::internal::SpaceWithLinearArea" = type { %"class.v8::internal::Space", %"class.v8::internal::LinearAllocationArea", [3 x i64] }
%"class.v8::internal::Space" = type { %"class.v8::internal::BaseSpace", %"class.v8::internal::AllocationCounter", %"class.v8::internal::heap::List", %"struct.std::__1::atomic.22"*, %"class.std::__1::unique_ptr.100" }
%"class.v8::internal::BaseSpace" = type { i32 (...)**, %"class.v8::internal::Heap"*, i32, %"struct.std::__1::atomic.22", i64 }
%"class.v8::internal::AllocationCounter" = type <{ %"class.std::__1::vector.41", %"class.std::__1::vector.41", %"class.std::__1::unordered_set", i8, [7 x i8], i64, i64, i8, [7 x i8] }>
%"class.std::__1::vector.41" = type { %"class.std::__1::__vector_base.42" }
%"class.std::__1::__vector_base.42" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"class.std::__1::__compressed_pair.43" }
%"struct.v8::internal::AllocationCounter::AllocationObserverCounter" = type { %"class.v8::internal::AllocationObserver"*, i64, i64 }
%"class.std::__1::__compressed_pair.43" = type { %"struct.std::__1::__compressed_pair_elem.44" }
%"struct.std::__1::__compressed_pair_elem.44" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.48" }
%"class.std::__1::__hash_table.48" = type <{ %"class.std::__1::unique_ptr.49", %"class.std::__1::__compressed_pair.59", %"class.std::__1::__compressed_pair.64", %"class.std::__1::__compressed_pair.66", [4 x i8] }>
%"class.std::__1::unique_ptr.49" = type { %"class.std::__1::__compressed_pair.50" }
%"class.std::__1::__compressed_pair.50" = type { %"struct.std::__1::__compressed_pair_elem.51", %"struct.std::__1::__compressed_pair_elem.53" }
%"struct.std::__1::__compressed_pair_elem.51" = type { %"struct.std::__1::__hash_node_base.52"** }
%"struct.std::__1::__hash_node_base.52" = type { %"struct.std::__1::__hash_node_base.52"* }
%"struct.std::__1::__compressed_pair_elem.53" = type { %"class.std::__1::__bucket_list_deallocator.54" }
%"class.std::__1::__bucket_list_deallocator.54" = type { %"class.std::__1::__compressed_pair.55" }
%"class.std::__1::__compressed_pair.55" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.59" = type { %"struct.std::__1::__compressed_pair_elem.60" }
%"struct.std::__1::__compressed_pair_elem.60" = type { %"struct.std::__1::__hash_node_base.52" }
%"class.std::__1::__compressed_pair.64" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.66" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.v8::internal::heap::List" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::MemoryChunk" = type { %"class.v8::internal::BasicMemoryChunk", [2 x %"class.v8::internal::SlotSet"*], %"struct.std::__1::atomic.22", %"struct.std::__1::atomic.27", %"class.v8::internal::SlotSet"*, [2 x %"class.v8::internal::TypedSlotSet"*], [2 x %"class.std::__1::set"*], %"class.v8::base::Mutex"*, %"struct.std::__1::atomic.89", %"class.v8::base::Mutex"*, i64, [2 x %"struct.std::__1::atomic.22"], %"class.v8::internal::heap::ListNode", %"class.v8::internal::FreeListCategory"**, %"struct.std::__1::atomic.27", %"class.v8::internal::Bitmap"*, %"class.v8::internal::CodeObjectRegistry"*, %"class.v8::internal::PossiblyEmptyBuckets" }
%"class.v8::internal::BasicMemoryChunk" = type { i64, i64, %"class.v8::internal::Heap"*, i64, i64, i64, i64, %"struct.std::__1::atomic.27", %"struct.std::__1::atomic.71", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.71" = type { %"struct.std::__1::__atomic_base.72" }
%"struct.std::__1::__atomic_base.72" = type { %"struct.std::__1::__cxx_atomic_impl.73" }
%"struct.std::__1::__cxx_atomic_impl.73" = type { %"struct.std::__1::__cxx_atomic_base_impl.74" }
%"struct.std::__1::__cxx_atomic_base_impl.74" = type { %"class.v8::internal::BaseSpace"* }
%"class.v8::internal::SlotSet" = type { i8 }
%"class.v8::internal::TypedSlotSet" = type { %"class.v8::internal::TypedSlots", i64 }
%"class.v8::internal::TypedSlots" = type { i32 (...)**, %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"* }
%"struct.v8::internal::TypedSlots::Chunk" = type { %"struct.v8::internal::TypedSlots::Chunk"*, %"class.std::__1::vector.75" }
%"class.std::__1::vector.75" = type { %"class.std::__1::__vector_base.76" }
%"class.std::__1::__vector_base.76" = type { %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"*, %"class.std::__1::__compressed_pair.77" }
%"struct.v8::internal::TypedSlots::TypedSlot" = type { i32 }
%"class.std::__1::__compressed_pair.77" = type { %"struct.std::__1::__compressed_pair_elem.78" }
%"struct.std::__1::__compressed_pair_elem.78" = type { %"struct.v8::internal::TypedSlots::TypedSlot"* }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.82", %"class.std::__1::__compressed_pair.87" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.82" = type { %"struct.std::__1::__compressed_pair_elem.83" }
%"struct.std::__1::__compressed_pair_elem.83" = type { %"class.std::__1::__tree_end_node" }
%"class.std::__1::__compressed_pair.87" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"struct.std::__1::atomic.89" = type { %"struct.std::__1::__atomic_base.90" }
%"struct.std::__1::__atomic_base.90" = type { %"struct.std::__1::__cxx_atomic_impl.91" }
%"struct.std::__1::__cxx_atomic_impl.91" = type { %"struct.std::__1::__cxx_atomic_base_impl.92" }
%"struct.std::__1::__cxx_atomic_base_impl.92" = type { i64 }
%"class.v8::internal::heap::ListNode" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::FreeListCategory" = type { i32, i32, %"class.v8::internal::FreeSpace", %"class.v8::internal::FreeListCategory"*, %"class.v8::internal::FreeListCategory"* }
%"class.v8::internal::FreeSpace" = type { %"class.v8::internal::TorqueGeneratedFreeSpace" }
%"class.v8::internal::TorqueGeneratedFreeSpace" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Bitmap" = type { i8 }
%"class.v8::internal::CodeObjectRegistry" = type <{ %"class.std::__1::vector.93", i8, [7 x i8] }>
%"class.std::__1::vector.93" = type { %"class.std::__1::__vector_base.94" }
%"class.std::__1::__vector_base.94" = type { i64*, i64*, %"class.std::__1::__compressed_pair.95" }
%"class.std::__1::__compressed_pair.95" = type { %"struct.std::__1::__compressed_pair_elem.96" }
%"struct.std::__1::__compressed_pair_elem.96" = type { i64* }
%"class.v8::internal::PossiblyEmptyBuckets" = type { i64 }
%"class.std::__1::unique_ptr.100" = type { %"class.std::__1::__compressed_pair.101" }
%"class.std::__1::__compressed_pair.101" = type { %"struct.std::__1::__compressed_pair_elem.102" }
%"struct.std::__1::__compressed_pair_elem.102" = type { %"class.v8::internal::FreeList"* }
%"class.v8::internal::FreeList" = type { i32 (...)**, i32, i32, i64, %"struct.std::__1::atomic.22", %"class.v8::internal::FreeListCategory"**, i64 }
%"class.v8::internal::LinearAllocationArea" = type { i64, i64, i64 }
%"class.v8::internal::SemiSpace" = type { %"class.v8::internal::Space", i64, i64, i64, i64, i64, i32, %"class.v8::internal::Page"* }
%"class.v8::internal::Page" = type { %"class.v8::internal::MemoryChunk" }
%"class.v8::internal::VirtualMemory" = type { %"class.v8::PageAllocator"*, %"class.v8::base::AddressRegion" }
%"class.v8::base::AddressRegion" = type { i64, i64 }
%"class.std::__1::vector.106" = type { %"class.std::__1::__vector_base.107" }
%"class.std::__1::__vector_base.107" = type { %"struct.std::__1::pair.108"*, %"struct.std::__1::pair.108"*, %"class.std::__1::__compressed_pair.109" }
%"struct.std::__1::pair.108" = type { i32, i64 }
%"class.std::__1::__compressed_pair.109" = type { %"struct.std::__1::__compressed_pair_elem.110" }
%"struct.std::__1::__compressed_pair_elem.110" = type { %"struct.std::__1::pair.108"* }
%"class.v8::internal::CodeSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::PagedSpace" = type { %"class.v8::internal::SpaceWithLinearArea", i32, i32, i64, %"class.v8::internal::AllocationStats", %"class.v8::base::Mutex", i64, i64 }
%"class.v8::internal::AllocationStats" = type { %"struct.std::__1::atomic.22", i64, %"struct.std::__1::atomic.22" }
%"class.v8::internal::OldLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace" }
%"class.v8::internal::LargeObjectSpace" = type { %"class.v8::internal::Space", %"struct.std::__1::atomic.22", i32, %"struct.std::__1::atomic.22", %"class.v8::base::Mutex", %"struct.std::__1::atomic.22" }
%"class.v8::internal::CodeLargeObjectSpace" = type { %"class.v8::internal::OldLargeObjectSpace", %"class.std::__1::unordered_map.114" }
%"class.std::__1::unordered_map.114" = type { %"class.std::__1::__hash_table.115" }
%"class.std::__1::__hash_table.115" = type <{ %"class.std::__1::unique_ptr.116", %"class.std::__1::__compressed_pair.126", %"class.std::__1::__compressed_pair.131", %"class.std::__1::__compressed_pair.136", [4 x i8] }>
%"class.std::__1::unique_ptr.116" = type { %"class.std::__1::__compressed_pair.117" }
%"class.std::__1::__compressed_pair.117" = type { %"struct.std::__1::__compressed_pair_elem.118", %"struct.std::__1::__compressed_pair_elem.120" }
%"struct.std::__1::__compressed_pair_elem.118" = type { %"struct.std::__1::__hash_node_base.119"** }
%"struct.std::__1::__hash_node_base.119" = type { %"struct.std::__1::__hash_node_base.119"* }
%"struct.std::__1::__compressed_pair_elem.120" = type { %"class.std::__1::__bucket_list_deallocator.121" }
%"class.std::__1::__bucket_list_deallocator.121" = type { %"class.std::__1::__compressed_pair.122" }
%"class.std::__1::__compressed_pair.122" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.126" = type { %"struct.std::__1::__compressed_pair_elem.127" }
%"struct.std::__1::__compressed_pair_elem.127" = type { %"struct.std::__1::__hash_node_base.119" }
%"class.std::__1::__compressed_pair.131" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.136" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.v8::internal::NewLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace", i64 }
%"class.v8::internal::ReadOnlySpace" = type { %"class.v8::internal::BaseSpace", i8, %"class.v8::internal::AllocationStats", %"class.std::__1::vector.142", i64, i64, i8, i64, i64 }
%"class.std::__1::vector.142" = type { %"class.std::__1::__vector_base.143" }
%"class.std::__1::__vector_base.143" = type { %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"**, %"class.std::__1::__compressed_pair.144" }
%"class.v8::internal::ReadOnlyPage" = type { %"class.v8::internal::BasicMemoryChunk" }
%"class.std::__1::__compressed_pair.144" = type { %"struct.std::__1::__compressed_pair_elem.145" }
%"struct.std::__1::__compressed_pair_elem.145" = type { %"class.v8::internal::ReadOnlyPage"** }
%"class.v8::internal::OldSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::MapSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.std::__1::unique_ptr.149" = type { %"class.std::__1::__compressed_pair.150" }
%"class.std::__1::__compressed_pair.150" = type { %"struct.std::__1::__compressed_pair_elem.151" }
%"struct.std::__1::__compressed_pair_elem.151" = type { %"class.v8::internal::ConcurrentAllocator"* }
%"class.v8::internal::ConcurrentAllocator" = type { %"class.v8::internal::LocalHeap"*, %"class.v8::internal::PagedSpace"*, %"class.v8::internal::LocalAllocationBuffer" }
%"class.v8::internal::LocalAllocationBuffer" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::LinearAllocationArea" }
%"class.v8::internal::LocalHeap" = type { %"class.v8::internal::Heap"*, i8, %"struct.std::__1::atomic.1057", i8, i8, %"class.v8::internal::LocalHeap"*, %"class.v8::internal::LocalHeap"*, %"class.std::__1::unique_ptr.1061", %"class.std::__1::unique_ptr.1067", %"class.std::__1::unique_ptr.477", %"class.std::__1::vector.1073", %"class.v8::internal::ConcurrentAllocator" }
%"struct.std::__1::atomic.1057" = type { %"struct.std::__1::__atomic_base.1058" }
%"struct.std::__1::__atomic_base.1058" = type { %"struct.std::__1::__cxx_atomic_impl.1059" }
%"struct.std::__1::__cxx_atomic_impl.1059" = type { %"struct.std::__1::__cxx_atomic_base_impl.1060" }
%"struct.std::__1::__cxx_atomic_base_impl.1060" = type { i32 }
%"class.std::__1::unique_ptr.1061" = type { %"class.std::__1::__compressed_pair.1062" }
%"class.std::__1::__compressed_pair.1062" = type { %"struct.std::__1::__compressed_pair_elem.1063" }
%"struct.std::__1::__compressed_pair_elem.1063" = type { %"class.v8::internal::LocalHandles"* }
%"class.v8::internal::LocalHandles" = type { %"struct.v8::internal::HandleScopeData", %"class.std::__1::vector.811" }
%"class.std::__1::vector.811" = type { %"class.std::__1::__vector_base.812" }
%"class.std::__1::__vector_base.812" = type { i64**, i64**, %"class.std::__1::__compressed_pair.813" }
%"class.std::__1::__compressed_pair.813" = type { %"struct.std::__1::__compressed_pair_elem.814" }
%"struct.std::__1::__compressed_pair_elem.814" = type { i64** }
%"class.std::__1::unique_ptr.1067" = type { %"class.std::__1::__compressed_pair.1068" }
%"class.std::__1::__compressed_pair.1068" = type { %"struct.std::__1::__compressed_pair_elem.1069" }
%"struct.std::__1::__compressed_pair_elem.1069" = type { %"class.v8::internal::PersistentHandles"* }
%"class.v8::internal::PersistentHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::vector.811", i64*, i64*, %"class.v8::internal::PersistentHandles"*, %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.1073" = type { %"class.std::__1::__vector_base.1074" }
%"class.std::__1::__vector_base.1074" = type { %"struct.std::__1::pair.1075"*, %"struct.std::__1::pair.1075"*, %"class.std::__1::__compressed_pair.1076" }
%"struct.std::__1::pair.1075" = type opaque
%"class.std::__1::__compressed_pair.1076" = type { %"struct.std::__1::__compressed_pair_elem.1077" }
%"struct.std::__1::__compressed_pair_elem.1077" = type { %"struct.std::__1::pair.1075"* }
%"class.v8::internal::ArrayBufferExtension" = type { %"struct.std::__1::atomic.155", %"struct.std::__1::atomic.159", %"class.std::__1::shared_ptr", %"class.v8::internal::ArrayBufferExtension"*, %"struct.std::__1::atomic.22" }
%"struct.std::__1::atomic.159" = type { %"struct.std::__1::__atomic_base.160" }
%"struct.std::__1::__atomic_base.160" = type { %"struct.std::__1::__cxx_atomic_impl.161" }
%"struct.std::__1::__cxx_atomic_impl.161" = type { %"struct.std::__1::__cxx_atomic_base_impl.162" }
%"struct.std::__1::__cxx_atomic_base_impl.162" = type { i8 }
%"class.std::__1::shared_ptr" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::BackingStore" = type <{ i8*, %"struct.std::__1::atomic.22", i64, %"union.v8::internal::BackingStore::TypeSpecificData", i16, [6 x i8] }>
%"union.v8::internal::BackingStore::TypeSpecificData" = type { %"class.std::__1::shared_ptr.163" }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"struct.std::__1::atomic.164" = type { %"struct.std::__1::__atomic_base.165" }
%"struct.std::__1::__atomic_base.165" = type { %"struct.std::__1::__cxx_atomic_impl.166" }
%"struct.std::__1::__cxx_atomic_impl.166" = type { %"struct.std::__1::__cxx_atomic_base_impl.167" }
%"struct.std::__1::__cxx_atomic_base_impl.167" = type { i32 }
%"class.v8::internal::AllocationObserver" = type { i32 (...)**, i64 }
%"class.v8::internal::StressScavengeObserver" = type opaque
%"struct.std::__1::atomic.22" = type { %"struct.std::__1::__atomic_base.23" }
%"struct.std::__1::__atomic_base.23" = type { %"struct.std::__1::__atomic_base.24" }
%"struct.std::__1::__atomic_base.24" = type { %"struct.std::__1::__cxx_atomic_impl.25" }
%"struct.std::__1::__cxx_atomic_impl.25" = type { %"struct.std::__1::__cxx_atomic_base_impl.26" }
%"struct.std::__1::__cxx_atomic_base_impl.26" = type { i64 }
%"class.std::__1::vector.168" = type { %"class.std::__1::__vector_base.169" }
%"class.std::__1::__vector_base.169" = type { %"struct.v8::internal::Heap::GCCallbackTuple"*, %"struct.v8::internal::Heap::GCCallbackTuple"*, %"class.std::__1::__compressed_pair.170" }
%"struct.v8::internal::Heap::GCCallbackTuple" = type { void (%"class.v8::Isolate"*, i32, i32, i8*)*, i32, i8* }
%"class.v8::Isolate" = type { i8 }
%"class.std::__1::__compressed_pair.170" = type { %"struct.std::__1::__compressed_pair_elem.171" }
%"struct.std::__1::__compressed_pair_elem.171" = type { %"struct.v8::internal::Heap::GCCallbackTuple"* }
%"class.std::__1::unique_ptr.175" = type { %"class.std::__1::__compressed_pair.176" }
%"class.std::__1::__compressed_pair.176" = type { %"struct.std::__1::__compressed_pair_elem.177" }
%"struct.std::__1::__compressed_pair_elem.177" = type { %"class.v8::internal::GCTracer"* }
%"class.v8::internal::GCTracer" = type opaque
%"class.std::__1::unique_ptr.181" = type { %"class.std::__1::__compressed_pair.182" }
%"class.std::__1::__compressed_pair.182" = type { %"struct.std::__1::__compressed_pair_elem.183" }
%"struct.std::__1::__compressed_pair_elem.183" = type { %"class.v8::internal::MarkCompactCollector"* }
%"class.v8::internal::MarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::base::Mutex", %"class.v8::base::Semaphore", i8, i8, i8, i8, i8, i8, [2 x i8], %"class.v8::internal::MarkingWorklists", %"class.v8::internal::WeakObjects", %"struct.v8::internal::EphemeronMarking", %"class.std::__1::unique_ptr.223", %"class.std::__1::unique_ptr.229", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", %"class.std::__1::vector.283", %"class.std::__1::vector.283", %"class.std::__1::vector.283", %"class.std::__1::vector.290", %"class.v8::internal::Sweeper"*, %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", [2 x i8], i32, i32, [4 x i8] }>
%"class.v8::internal::MarkCompactCollectorBase" = type { i32 (...)**, %"class.v8::internal::Heap"* }
%"class.v8::base::Semaphore" = type { %union.sem_t }
%union.sem_t = type { i64, [24 x i8] }
%"class.v8::internal::MarkingWorklists" = type { %"class.heap::base::Worklist", %"class.heap::base::Worklist", %"class.heap::base::Worklist.184", %"class.std::__1::vector.185", %"class.std::__1::vector.192", %"class.heap::base::Worklist" }
%"class.heap::base::Worklist.184" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment" = type opaque
%"class.std::__1::vector.185" = type { %"class.std::__1::__vector_base.186" }
%"class.std::__1::__vector_base.186" = type { %"struct.v8::internal::ContextWorklistPair"*, %"struct.v8::internal::ContextWorklistPair"*, %"class.std::__1::__compressed_pair.187" }
%"struct.v8::internal::ContextWorklistPair" = type { i64, %"class.heap::base::Worklist"* }
%"class.std::__1::__compressed_pair.187" = type { %"struct.std::__1::__compressed_pair_elem.188" }
%"struct.std::__1::__compressed_pair_elem.188" = type { %"struct.v8::internal::ContextWorklistPair"* }
%"class.std::__1::vector.192" = type { %"class.std::__1::__vector_base.193" }
%"class.std::__1::__vector_base.193" = type { %"class.std::__1::unique_ptr.194"*, %"class.std::__1::unique_ptr.194"*, %"class.std::__1::__compressed_pair.195" }
%"class.std::__1::unique_ptr.194" = type opaque
%"class.std::__1::__compressed_pair.195" = type { %"struct.std::__1::__compressed_pair_elem.196" }
%"struct.std::__1::__compressed_pair_elem.196" = type { %"class.std::__1::unique_ptr.194"* }
%"class.heap::base::Worklist" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment" = type opaque
%"class.v8::internal::WeakObjects" = type { %"class.v8::internal::Worklist", %"class.v8::internal::Worklist.200", %"class.v8::internal::Worklist.202", %"class.v8::internal::Worklist.202", %"class.v8::internal::Worklist.202", %"class.v8::internal::Worklist.204", %"class.v8::internal::Worklist.206", %"class.v8::internal::Worklist.208", %"class.v8::internal::Worklist.210", %"class.v8::internal::Worklist.212", %"class.v8::internal::Worklist.214" }
%"class.v8::internal::Worklist" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.v8::internal::Worklist.200" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.v8::internal::Worklist.202" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.v8::internal::Worklist.204" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.v8::internal::Worklist.206" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.v8::internal::Worklist.208" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.v8::internal::Worklist.210" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.v8::internal::Worklist.212" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"class.v8::internal::Worklist.214" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"struct.std::__1::atomic.22" }
%"struct.v8::internal::EphemeronMarking" = type { %"class.std::__1::vector.216", i8, i64 }
%"class.std::__1::vector.216" = type { %"class.std::__1::__vector_base.217" }
%"class.std::__1::__vector_base.217" = type { %"class.v8::internal::HeapObject"*, %"class.v8::internal::HeapObject"*, %"class.std::__1::__compressed_pair.218" }
%"class.std::__1::__compressed_pair.218" = type { %"struct.std::__1::__compressed_pair_elem.219" }
%"struct.std::__1::__compressed_pair_elem.219" = type { %"class.v8::internal::HeapObject"* }
%"class.std::__1::unique_ptr.223" = type { %"class.std::__1::__compressed_pair.224" }
%"class.std::__1::__compressed_pair.224" = type { %"struct.std::__1::__compressed_pair_elem.225" }
%"struct.std::__1::__compressed_pair_elem.225" = type { %"class.v8::internal::MainMarkingVisitor"* }
%"class.v8::internal::MainMarkingVisitor" = type opaque
%"class.std::__1::unique_ptr.229" = type { %"class.std::__1::__compressed_pair.230" }
%"class.std::__1::__compressed_pair.230" = type { %"struct.std::__1::__compressed_pair_elem.231" }
%"struct.std::__1::__compressed_pair_elem.231" = type { %"class.v8::internal::MarkingWorklists::Local"* }
%"class.v8::internal::MarkingWorklists::Local" = type { %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", i64, %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local"*, i8, [7 x i8], %"class.std::__1::unordered_map.232" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local" = type { %"class.heap::base::Worklist.184"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.heap::base::internal::SegmentBase" = type { i16, i16 }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local" = type { %"class.heap::base::Worklist"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.std::__1::unordered_map.232" = type { %"class.std::__1::__hash_table.233" }
%"class.std::__1::__hash_table.233" = type <{ %"class.std::__1::unique_ptr.234", %"class.std::__1::__compressed_pair.244", %"class.std::__1::__compressed_pair.249", %"class.std::__1::__compressed_pair.252", [4 x i8] }>
%"class.std::__1::unique_ptr.234" = type { %"class.std::__1::__compressed_pair.235" }
%"class.std::__1::__compressed_pair.235" = type { %"struct.std::__1::__compressed_pair_elem.236", %"struct.std::__1::__compressed_pair_elem.238" }
%"struct.std::__1::__compressed_pair_elem.236" = type { %"struct.std::__1::__hash_node_base.237"** }
%"struct.std::__1::__hash_node_base.237" = type { %"struct.std::__1::__hash_node_base.237"* }
%"struct.std::__1::__compressed_pair_elem.238" = type { %"class.std::__1::__bucket_list_deallocator.239" }
%"class.std::__1::__bucket_list_deallocator.239" = type { %"class.std::__1::__compressed_pair.240" }
%"class.std::__1::__compressed_pair.240" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.244" = type { %"struct.std::__1::__compressed_pair_elem.245" }
%"struct.std::__1::__compressed_pair_elem.245" = type { %"struct.std::__1::__hash_node_base.237" }
%"class.std::__1::__compressed_pair.249" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.252" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.v8::internal::NativeContextInferrer" = type { i8 }
%"class.v8::internal::NativeContextStats" = type { %"class.std::__1::unordered_map.259" }
%"class.std::__1::unordered_map.259" = type { %"class.std::__1::__hash_table.260" }
%"class.std::__1::__hash_table.260" = type <{ %"class.std::__1::unique_ptr.261", %"class.std::__1::__compressed_pair.271", %"class.std::__1::__compressed_pair.276", %"class.std::__1::__compressed_pair.279", [4 x i8] }>
%"class.std::__1::unique_ptr.261" = type { %"class.std::__1::__compressed_pair.262" }
%"class.std::__1::__compressed_pair.262" = type { %"struct.std::__1::__compressed_pair_elem.263", %"struct.std::__1::__compressed_pair_elem.265" }
%"struct.std::__1::__compressed_pair_elem.263" = type { %"struct.std::__1::__hash_node_base.264"** }
%"struct.std::__1::__hash_node_base.264" = type { %"struct.std::__1::__hash_node_base.264"* }
%"struct.std::__1::__compressed_pair_elem.265" = type { %"class.std::__1::__bucket_list_deallocator.266" }
%"class.std::__1::__bucket_list_deallocator.266" = type { %"class.std::__1::__compressed_pair.267" }
%"class.std::__1::__compressed_pair.267" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.271" = type { %"struct.std::__1::__compressed_pair_elem.272" }
%"struct.std::__1::__compressed_pair_elem.272" = type { %"struct.std::__1::__hash_node_base.264" }
%"class.std::__1::__compressed_pair.276" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.279" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.std::__1::vector.283" = type { %"class.std::__1::__vector_base.284" }
%"class.std::__1::__vector_base.284" = type { %"class.v8::internal::Page"**, %"class.v8::internal::Page"**, %"class.std::__1::__compressed_pair.285" }
%"class.std::__1::__compressed_pair.285" = type { %"struct.std::__1::__compressed_pair_elem.286" }
%"struct.std::__1::__compressed_pair_elem.286" = type { %"class.v8::internal::Page"** }
%"class.std::__1::vector.290" = type { %"class.std::__1::__vector_base.291" }
%"class.std::__1::__vector_base.291" = type { %"struct.std::__1::pair.292"*, %"struct.std::__1::pair.292"*, %"class.std::__1::__compressed_pair.293" }
%"struct.std::__1::pair.292" = type opaque
%"class.std::__1::__compressed_pair.293" = type { %"struct.std::__1::__compressed_pair_elem.294" }
%"struct.std::__1::__compressed_pair_elem.294" = type { %"struct.std::__1::pair.292"* }
%"class.v8::internal::Sweeper" = type <{ %"class.v8::internal::Heap"*, %"class.v8::internal::MajorNonAtomicMarkingState"*, %"class.std::__1::unique_ptr.298", %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.283"], [3 x %"class.std::__1::vector.283"], i8, %"struct.std::__1::atomic.155", [6 x i8], %"class.std::__1::vector.283", i64, %"class.v8::base::Semaphore", i8, i8, i8, [5 x i8] }>
%"class.std::__1::unique_ptr.298" = type { %"class.std::__1::__compressed_pair.299" }
%"class.std::__1::__compressed_pair.299" = type { %"struct.std::__1::__compressed_pair_elem.300" }
%"struct.std::__1::__compressed_pair_elem.300" = type { %"class.v8::JobHandle"* }
%"class.v8::JobHandle" = type { i32 (...)** }
%"class.v8::internal::MajorMarkingState" = type { i8 }
%"class.v8::internal::MajorNonAtomicMarkingState" = type { i8 }
%"class.v8::internal::MinorMarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::internal::Worklist.308"*, %"class.v8::internal::YoungGenerationMarkingVisitor"*, %"class.v8::base::Semaphore", %"class.std::__1::vector.283", %"class.std::__1::vector.283", %"class.v8::internal::MinorMarkingState", %"class.v8::internal::MinorNonAtomicMarkingState", [6 x i8] }>
%"class.v8::internal::Worklist.308" = type opaque
%"class.v8::internal::YoungGenerationMarkingVisitor" = type opaque
%"class.v8::internal::MinorMarkingState" = type { i8 }
%"class.v8::internal::MinorNonAtomicMarkingState" = type { i8 }
%"class.std::__1::unique_ptr.311" = type { %"class.std::__1::__compressed_pair.312" }
%"class.std::__1::__compressed_pair.312" = type { %"struct.std::__1::__compressed_pair_elem.313" }
%"struct.std::__1::__compressed_pair_elem.313" = type { %"class.v8::internal::ScavengerCollector"* }
%"class.v8::internal::ScavengerCollector" = type opaque
%"class.std::__1::unique_ptr.317" = type { %"class.std::__1::__compressed_pair.318" }
%"class.std::__1::__compressed_pair.318" = type { %"struct.std::__1::__compressed_pair_elem.319" }
%"struct.std::__1::__compressed_pair_elem.319" = type { %"class.v8::internal::ArrayBufferSweeper"* }
%"class.v8::internal::ArrayBufferSweeper" = type opaque
%"class.std::__1::unique_ptr.323" = type { %"class.std::__1::__compressed_pair.324" }
%"class.std::__1::__compressed_pair.324" = type { %"struct.std::__1::__compressed_pair_elem.325" }
%"struct.std::__1::__compressed_pair_elem.325" = type { %"class.v8::internal::MemoryAllocator"* }
%"class.v8::internal::MemoryAllocator" = type { %"class.v8::internal::Isolate"*, %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"*, i64, %"struct.std::__1::atomic.22", %"struct.std::__1::atomic.22", %"struct.std::__1::atomic.22", %"struct.std::__1::atomic.22", %"class.v8::internal::VirtualMemory", %"class.v8::internal::MemoryAllocator::Unmapper", %"class.std::__1::unordered_set.333", %"class.v8::base::Mutex" }
%"class.v8::internal::MemoryAllocator::Unmapper" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MemoryAllocator"*, %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.326"], %"class.std::__1::unique_ptr.298" }
%"class.std::__1::vector.326" = type { %"class.std::__1::__vector_base.327" }
%"class.std::__1::__vector_base.327" = type { %"class.v8::internal::MemoryChunk"**, %"class.v8::internal::MemoryChunk"**, %"class.std::__1::__compressed_pair.328" }
%"class.std::__1::__compressed_pair.328" = type { %"struct.std::__1::__compressed_pair_elem.329" }
%"struct.std::__1::__compressed_pair_elem.329" = type { %"class.v8::internal::MemoryChunk"** }
%"class.std::__1::unique_ptr.362" = type { %"class.std::__1::__compressed_pair.363" }
%"class.std::__1::__compressed_pair.363" = type { %"struct.std::__1::__compressed_pair_elem.364" }
%"struct.std::__1::__compressed_pair_elem.364" = type { %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::IncrementalMarking" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MarkCompactCollector"*, %"class.v8::internal::WeakObjects"*, double, double, i64, i64, i64, i64, double, i64, %"struct.std::__1::atomic.365", i8, i8, i8, i8, [3 x i8], %"class.v8::internal::IncrementalMarkingJob", %"struct.std::__1::atomic.369", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorAtomicMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", %"class.v8::base::Mutex", %"class.std::__1::unordered_map.374" }
%"struct.std::__1::atomic.365" = type { %"struct.std::__1::__atomic_base.366" }
%"struct.std::__1::__atomic_base.366" = type { %"struct.std::__1::__cxx_atomic_impl.367" }
%"struct.std::__1::__cxx_atomic_impl.367" = type { %"struct.std::__1::__cxx_atomic_base_impl.368" }
%"struct.std::__1::__cxx_atomic_base_impl.368" = type { i8 }
%"class.v8::internal::IncrementalMarkingJob" = type <{ %"class.v8::base::Mutex", double, i8, i8, [6 x i8] }>
%"struct.std::__1::atomic.369" = type { %"struct.std::__1::__atomic_base.370" }
%"struct.std::__1::__atomic_base.370" = type { %"struct.std::__1::__cxx_atomic_impl.371" }
%"struct.std::__1::__cxx_atomic_impl.371" = type { %"struct.std::__1::__cxx_atomic_base_impl.372" }
%"struct.std::__1::__cxx_atomic_base_impl.372" = type { i32 }
%"class.v8::internal::IncrementalMarking::Observer" = type { %"class.v8::internal::AllocationObserver", %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::MajorAtomicMarkingState" = type { i8 }
%"class.std::__1::unordered_map.374" = type { %"class.std::__1::__hash_table.375" }
%"class.std::__1::__hash_table.375" = type <{ %"class.std::__1::unique_ptr.376", %"class.std::__1::__compressed_pair.386", %"class.std::__1::__compressed_pair.391", %"class.std::__1::__compressed_pair.394", [4 x i8] }>
%"class.std::__1::unique_ptr.376" = type { %"class.std::__1::__compressed_pair.377" }
%"class.std::__1::__compressed_pair.377" = type { %"struct.std::__1::__compressed_pair_elem.378", %"struct.std::__1::__compressed_pair_elem.380" }
%"struct.std::__1::__compressed_pair_elem.378" = type { %"struct.std::__1::__hash_node_base.379"** }
%"struct.std::__1::__hash_node_base.379" = type { %"struct.std::__1::__hash_node_base.379"* }
%"struct.std::__1::__compressed_pair_elem.380" = type { %"class.std::__1::__bucket_list_deallocator.381" }
%"class.std::__1::__bucket_list_deallocator.381" = type { %"class.std::__1::__compressed_pair.382" }
%"class.std::__1::__compressed_pair.382" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.386" = type { %"struct.std::__1::__compressed_pair_elem.387" }
%"struct.std::__1::__compressed_pair_elem.387" = type { %"struct.std::__1::__hash_node_base.379" }
%"class.std::__1::__compressed_pair.391" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.394" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.std::__1::unique_ptr.401" = type { %"class.std::__1::__compressed_pair.402" }
%"class.std::__1::__compressed_pair.402" = type { %"struct.std::__1::__compressed_pair_elem.403" }
%"struct.std::__1::__compressed_pair_elem.403" = type { %"class.v8::internal::ConcurrentMarking"* }
%"class.v8::internal::ConcurrentMarking" = type <{ %"class.std::__1::unique_ptr.298", %"class.v8::internal::Heap"*, %"class.v8::internal::MarkingWorklists"*, %"class.v8::internal::WeakObjects"*, [8 x %"struct.v8::internal::ConcurrentMarking::TaskState"], %"struct.std::__1::atomic.22", %"struct.std::__1::atomic.155", [7 x i8] }>
%"struct.v8::internal::ConcurrentMarking::TaskState" = type { i64, %"class.std::__1::unordered_map.404", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", [64 x i8] }
%"class.std::__1::unordered_map.404" = type { %"class.std::__1::__hash_table.405" }
%"class.std::__1::__hash_table.405" = type <{ %"class.std::__1::unique_ptr.406", %"class.std::__1::__compressed_pair.416", %"class.std::__1::__compressed_pair.421", %"class.std::__1::__compressed_pair.424", [4 x i8] }>
%"class.std::__1::unique_ptr.406" = type { %"class.std::__1::__compressed_pair.407" }
%"class.std::__1::__compressed_pair.407" = type { %"struct.std::__1::__compressed_pair_elem.408", %"struct.std::__1::__compressed_pair_elem.410" }
%"struct.std::__1::__compressed_pair_elem.408" = type { %"struct.std::__1::__hash_node_base.409"** }
%"struct.std::__1::__hash_node_base.409" = type { %"struct.std::__1::__hash_node_base.409"* }
%"struct.std::__1::__compressed_pair_elem.410" = type { %"class.std::__1::__bucket_list_deallocator.411" }
%"class.std::__1::__bucket_list_deallocator.411" = type { %"class.std::__1::__compressed_pair.412" }
%"class.std::__1::__compressed_pair.412" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.416" = type { %"struct.std::__1::__compressed_pair_elem.417" }
%"struct.std::__1::__compressed_pair_elem.417" = type { %"struct.std::__1::__hash_node_base.409" }
%"class.std::__1::__compressed_pair.421" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.424" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.std::__1::unique_ptr.431" = type { %"class.std::__1::__compressed_pair.432" }
%"class.std::__1::__compressed_pair.432" = type { %"struct.std::__1::__compressed_pair_elem.433" }
%"struct.std::__1::__compressed_pair_elem.433" = type { %"class.v8::internal::GCIdleTimeHandler"* }
%"class.v8::internal::GCIdleTimeHandler" = type opaque
%"class.std::__1::unique_ptr.437" = type { %"class.std::__1::__compressed_pair.438" }
%"class.std::__1::__compressed_pair.438" = type { %"struct.std::__1::__compressed_pair_elem.439" }
%"struct.std::__1::__compressed_pair_elem.439" = type { %"class.v8::internal::MemoryMeasurement"* }
%"class.v8::internal::MemoryMeasurement" = type { %"class.std::__1::list", %"class.std::__1::list", %"class.std::__1::list", %"class.v8::internal::Isolate"*, i8, i8, i8, %"class.v8::base::RandomNumberGenerator" }
%"class.std::__1::list" = type { %"class.std::__1::__list_imp" }
%"class.std::__1::__list_imp" = type { %"struct.std::__1::__list_node_base", %"class.std::__1::__compressed_pair.440" }
%"struct.std::__1::__list_node_base" = type { %"struct.std::__1::__list_node_base"*, %"struct.std::__1::__list_node_base"* }
%"class.std::__1::__compressed_pair.440" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.v8::base::RandomNumberGenerator" = type { i64, i64, i64 }
%"class.std::__1::unique_ptr.447" = type { %"class.std::__1::__compressed_pair.448" }
%"class.std::__1::__compressed_pair.448" = type { %"struct.std::__1::__compressed_pair_elem.449" }
%"struct.std::__1::__compressed_pair_elem.449" = type { %"class.v8::internal::MemoryReducer"* }
%"class.v8::internal::MemoryReducer" = type opaque
%"class.std::__1::unique_ptr.453" = type { %"class.std::__1::__compressed_pair.454" }
%"class.std::__1::__compressed_pair.454" = type { %"struct.std::__1::__compressed_pair_elem.455" }
%"struct.std::__1::__compressed_pair_elem.455" = type { %"class.v8::internal::ObjectStats"* }
%"class.v8::internal::ObjectStats" = type opaque
%"class.std::__1::unique_ptr.459" = type { %"class.std::__1::__compressed_pair.460" }
%"class.std::__1::__compressed_pair.460" = type { %"struct.std::__1::__compressed_pair_elem.461" }
%"struct.std::__1::__compressed_pair_elem.461" = type { %"class.v8::internal::ScavengeJob"* }
%"class.v8::internal::ScavengeJob" = type opaque
%"class.std::__1::unique_ptr.465" = type { %"class.std::__1::__compressed_pair.466" }
%"class.std::__1::__compressed_pair.466" = type { %"struct.std::__1::__compressed_pair_elem.467" }
%"struct.std::__1::__compressed_pair_elem.467" = type { %"class.v8::internal::AllocationObserver"* }
%"class.std::__1::unique_ptr.471" = type { %"class.std::__1::__compressed_pair.472" }
%"class.std::__1::__compressed_pair.472" = type { %"struct.std::__1::__compressed_pair_elem.473" }
%"struct.std::__1::__compressed_pair_elem.473" = type { %"class.v8::internal::LocalEmbedderHeapTracer"* }
%"class.v8::internal::LocalEmbedderHeapTracer" = type opaque
%"class.std::__1::unique_ptr.477" = type { %"class.std::__1::__compressed_pair.478" }
%"class.std::__1::__compressed_pair.478" = type { %"struct.std::__1::__compressed_pair_elem.479" }
%"struct.std::__1::__compressed_pair_elem.479" = type { %"class.v8::internal::MarkingBarrier"* }
%"class.v8::internal::MarkingBarrier" = type opaque
%"class.std::__1::shared_ptr.483" = type { %"class.v8::internal::CodeRange"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::CodeRange" = type { %"class.v8::internal::VirtualMemoryCage", %"struct.std::__1::atomic.502", %"class.v8::base::Mutex" }
%"class.v8::internal::VirtualMemoryCage" = type { i32 (...)**, i64, %"class.std::__1::unique_ptr.484", %"class.v8::internal::VirtualMemory" }
%"class.std::__1::unique_ptr.484" = type { %"class.std::__1::__compressed_pair.485" }
%"class.std::__1::__compressed_pair.485" = type { %"struct.std::__1::__compressed_pair_elem.486" }
%"struct.std::__1::__compressed_pair_elem.486" = type { %"class.v8::base::BoundedPageAllocator"* }
%"class.v8::base::BoundedPageAllocator" = type { %"class.v8::PageAllocator", %"class.v8::base::Mutex", i64, i64, %"class.v8::PageAllocator"*, %"class.v8::base::RegionAllocator" }
%"class.v8::base::RegionAllocator" = type { %"class.v8::base::RegionAllocator::Region", i64, i64, i64, i64, %"class.std::__1::set.487", %"class.std::__1::set.495" }
%"class.v8::base::RegionAllocator::Region" = type <{ %"class.v8::base::AddressRegion", i32, [4 x i8] }>
%"class.std::__1::set.487" = type { %"class.std::__1::__tree.488" }
%"class.std::__1::__tree.488" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.489", %"class.std::__1::__compressed_pair.493" }
%"class.std::__1::__compressed_pair.489" = type { %"struct.std::__1::__compressed_pair_elem.83" }
%"class.std::__1::__compressed_pair.493" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::set.495" = type { %"class.std::__1::__tree.496" }
%"class.std::__1::__tree.496" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.489", %"class.std::__1::__compressed_pair.497" }
%"class.std::__1::__compressed_pair.497" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"struct.std::__1::atomic.502" = type { %"struct.std::__1::__atomic_base.503" }
%"struct.std::__1::__atomic_base.503" = type { %"struct.std::__1::__cxx_atomic_impl.504" }
%"struct.std::__1::__cxx_atomic_impl.504" = type { %"struct.std::__1::__cxx_atomic_base_impl.505" }
%"struct.std::__1::__cxx_atomic_base_impl.505" = type { i8* }
%"class.v8::CppHeap" = type opaque
%"class.v8::EmbedderRootsHandler" = type { i32 (...)** }
%"class.v8::internal::StrongRootsEntry" = type { %"class.v8::internal::FullObjectSlot", %"class.v8::internal::FullObjectSlot", %"class.v8::internal::StrongRootsEntry"*, %"class.v8::internal::StrongRootsEntry"* }
%"class.v8::internal::FullObjectSlot" = type { %"class.v8::internal::SlotBase" }
%"class.v8::internal::SlotBase" = type { i64 }
%"class.std::__1::unordered_map.506" = type { %"class.std::__1::__hash_table.507" }
%"class.std::__1::__hash_table.507" = type <{ %"class.std::__1::unique_ptr.508", %"class.std::__1::__compressed_pair.518", %"class.std::__1::__compressed_pair.523", %"class.std::__1::__compressed_pair.526", [4 x i8] }>
%"class.std::__1::unique_ptr.508" = type { %"class.std::__1::__compressed_pair.509" }
%"class.std::__1::__compressed_pair.509" = type { %"struct.std::__1::__compressed_pair_elem.510", %"struct.std::__1::__compressed_pair_elem.512" }
%"struct.std::__1::__compressed_pair_elem.510" = type { %"struct.std::__1::__hash_node_base.511"** }
%"struct.std::__1::__hash_node_base.511" = type { %"struct.std::__1::__hash_node_base.511"* }
%"struct.std::__1::__compressed_pair_elem.512" = type { %"class.std::__1::__bucket_list_deallocator.513" }
%"class.std::__1::__bucket_list_deallocator.513" = type { %"class.std::__1::__compressed_pair.514" }
%"class.std::__1::__compressed_pair.514" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.518" = type { %"struct.std::__1::__compressed_pair_elem.519" }
%"struct.std::__1::__compressed_pair_elem.519" = type { %"struct.std::__1::__hash_node_base.511" }
%"class.std::__1::__compressed_pair.523" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.526" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.std::__1::unique_ptr.532" = type { %"class.std::__1::__compressed_pair.533" }
%"class.std::__1::__compressed_pair.533" = type { %"struct.std::__1::__compressed_pair_elem.534" }
%"struct.std::__1::__compressed_pair_elem.534" = type { %"class.v8::internal::GlobalHandleVector"* }
%"class.v8::internal::GlobalHandleVector" = type opaque
%"class.std::__1::unique_ptr.538" = type { %"class.std::__1::__compressed_pair.539" }
%"class.std::__1::__compressed_pair.539" = type { %"struct.std::__1::__compressed_pair_elem.540" }
%"struct.std::__1::__compressed_pair_elem.540" = type { %"class.v8::internal::GlobalSafepoint"* }
%"class.v8::internal::GlobalSafepoint" = type opaque
%"class.v8::internal::Heap::ExternalStringTable" = type { %"class.v8::internal::Heap"*, %"class.std::__1::vector.544", %"class.std::__1::vector.544" }
%"class.std::__1::unique_ptr.551" = type { %"class.std::__1::__compressed_pair.552" }
%"class.std::__1::__compressed_pair.552" = type { %"struct.std::__1::__compressed_pair_elem.553" }
%"struct.std::__1::__compressed_pair_elem.553" = type { %"class.v8::internal::CollectionBarrier"* }
%"class.v8::internal::CollectionBarrier" = type opaque
%"class.std::__1::unordered_set.333" = type { %"class.std::__1::__hash_table.334" }
%"class.std::__1::__hash_table.334" = type <{ %"class.std::__1::unique_ptr.335", %"class.std::__1::__compressed_pair.345", %"class.std::__1::__compressed_pair.350", %"class.std::__1::__compressed_pair.354", [4 x i8] }>
%"class.std::__1::unique_ptr.335" = type { %"class.std::__1::__compressed_pair.336" }
%"class.std::__1::__compressed_pair.336" = type { %"struct.std::__1::__compressed_pair_elem.337", %"struct.std::__1::__compressed_pair_elem.339" }
%"struct.std::__1::__compressed_pair_elem.337" = type { %"struct.std::__1::__hash_node_base.338"** }
%"struct.std::__1::__hash_node_base.338" = type { %"struct.std::__1::__hash_node_base.338"* }
%"struct.std::__1::__compressed_pair_elem.339" = type { %"class.std::__1::__bucket_list_deallocator.340" }
%"class.std::__1::__bucket_list_deallocator.340" = type { %"class.std::__1::__compressed_pair.341" }
%"class.std::__1::__compressed_pair.341" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.345" = type { %"struct.std::__1::__compressed_pair_elem.346" }
%"struct.std::__1::__compressed_pair_elem.346" = type { %"struct.std::__1::__hash_node_base.338" }
%"class.std::__1::__compressed_pair.350" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.354" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.std::__1::unordered_map.583" = type { %"class.std::__1::__hash_table.584" }
%"class.std::__1::__hash_table.584" = type <{ %"class.std::__1::unique_ptr.585", %"class.std::__1::__compressed_pair.595", %"class.std::__1::__compressed_pair.600", %"class.std::__1::__compressed_pair.603", [4 x i8] }>
%"class.std::__1::unique_ptr.585" = type { %"class.std::__1::__compressed_pair.586" }
%"class.std::__1::__compressed_pair.586" = type { %"struct.std::__1::__compressed_pair_elem.587", %"struct.std::__1::__compressed_pair_elem.589" }
%"struct.std::__1::__compressed_pair_elem.587" = type { %"struct.std::__1::__hash_node_base.588"** }
%"struct.std::__1::__hash_node_base.588" = type { %"struct.std::__1::__hash_node_base.588"* }
%"struct.std::__1::__compressed_pair_elem.589" = type { %"class.std::__1::__bucket_list_deallocator.590" }
%"class.std::__1::__bucket_list_deallocator.590" = type { %"class.std::__1::__compressed_pair.591" }
%"class.std::__1::__compressed_pair.591" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.595" = type { %"struct.std::__1::__compressed_pair_elem.596" }
%"struct.std::__1::__compressed_pair_elem.596" = type { %"struct.std::__1::__hash_node_base.588" }
%"class.std::__1::__compressed_pair.600" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.603" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.std::__1::unordered_map.557" = type { %"class.std::__1::__hash_table.558" }
%"class.std::__1::__hash_table.558" = type <{ %"class.std::__1::unique_ptr.559", %"class.std::__1::__compressed_pair.569", %"class.std::__1::__compressed_pair.574", %"class.std::__1::__compressed_pair.577", [4 x i8] }>
%"class.std::__1::unique_ptr.559" = type { %"class.std::__1::__compressed_pair.560" }
%"class.std::__1::__compressed_pair.560" = type { %"struct.std::__1::__compressed_pair_elem.561", %"struct.std::__1::__compressed_pair_elem.563" }
%"struct.std::__1::__compressed_pair_elem.561" = type { %"struct.std::__1::__hash_node_base.562"** }
%"struct.std::__1::__hash_node_base.562" = type { %"struct.std::__1::__hash_node_base.562"* }
%"struct.std::__1::__compressed_pair_elem.563" = type { %"class.std::__1::__bucket_list_deallocator.564" }
%"class.std::__1::__bucket_list_deallocator.564" = type { %"class.std::__1::__compressed_pair.565" }
%"class.std::__1::__compressed_pair.565" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.569" = type { %"struct.std::__1::__compressed_pair_elem.570" }
%"struct.std::__1::__compressed_pair_elem.570" = type { %"struct.std::__1::__hash_node_base.562" }
%"class.std::__1::__compressed_pair.574" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.577" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.std::__1::unordered_map.607" = type { %"class.std::__1::__hash_table.608" }
%"class.std::__1::__hash_table.608" = type <{ %"class.std::__1::unique_ptr.609", %"class.std::__1::__compressed_pair.619", %"class.std::__1::__compressed_pair.624", %"class.std::__1::__compressed_pair.629", [4 x i8] }>
%"class.std::__1::unique_ptr.609" = type { %"class.std::__1::__compressed_pair.610" }
%"class.std::__1::__compressed_pair.610" = type { %"struct.std::__1::__compressed_pair_elem.611", %"struct.std::__1::__compressed_pair_elem.613" }
%"struct.std::__1::__compressed_pair_elem.611" = type { %"struct.std::__1::__hash_node_base.612"** }
%"struct.std::__1::__hash_node_base.612" = type { %"struct.std::__1::__hash_node_base.612"* }
%"struct.std::__1::__compressed_pair_elem.613" = type { %"class.std::__1::__bucket_list_deallocator.614" }
%"class.std::__1::__bucket_list_deallocator.614" = type { %"class.std::__1::__compressed_pair.615" }
%"class.std::__1::__compressed_pair.615" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.619" = type { %"struct.std::__1::__compressed_pair_elem.620" }
%"struct.std::__1::__compressed_pair_elem.620" = type { %"struct.std::__1::__hash_node_base.612" }
%"class.std::__1::__compressed_pair.624" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.629" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.std::__1::vector.635" = type { %"class.std::__1::__vector_base.636" }
%"class.std::__1::__vector_base.636" = type { %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.std::__1::__compressed_pair.637" }
%"class.v8::internal::HeapObjectAllocationTracker" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.637" = type { %"struct.std::__1::__compressed_pair_elem.638" }
%"struct.std::__1::__compressed_pair_elem.638" = type { %"class.v8::internal::HeapObjectAllocationTracker"** }
%"class.std::__1::unique_ptr.642" = type { %"class.std::__1::__compressed_pair.643" }
%"class.std::__1::__compressed_pair.643" = type { %"struct.std::__1::__compressed_pair_elem.644" }
%"struct.std::__1::__compressed_pair_elem.644" = type { %"class.v8::internal::third_party_heap::Heap"* }
%"class.v8::internal::third_party_heap::Heap" = type { i8 }
%"class.v8::internal::ReadOnlyHeap" = type { i32 (...)**, i8, %"class.v8::internal::ReadOnlySpace"*, %"class.std::__1::vector.544" }
%"class.std::__1::shared_ptr.648" = type { %"class.v8::internal::ReadOnlyArtifacts"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::ReadOnlyArtifacts" = type { i32 (...)**, %"class.std::__1::vector.142", %"class.v8::internal::AllocationStats", %"class.std::__1::unique_ptr.649", %"class.std::__1::unique_ptr.663" }
%"class.std::__1::unique_ptr.649" = type { %"class.std::__1::__compressed_pair.650" }
%"class.std::__1::__compressed_pair.650" = type { %"struct.std::__1::__compressed_pair_elem.651" }
%"struct.std::__1::__compressed_pair_elem.651" = type { %"class.v8::internal::SharedReadOnlySpace"* }
%"class.v8::internal::SharedReadOnlySpace" = type { %"class.v8::internal::ReadOnlySpace", %"class.std::__1::vector.652" }
%"class.std::__1::vector.652" = type { %"class.std::__1::__vector_base.653" }
%"class.std::__1::__vector_base.653" = type { %"class.std::__1::unique_ptr.654"*, %"class.std::__1::unique_ptr.654"*, %"class.std::__1::__compressed_pair.655" }
%"class.std::__1::unique_ptr.654" = type { %"class.std::__1::__compressed_pair.1146" }
%"class.std::__1::__compressed_pair.1146" = type { %"struct.std::__1::__compressed_pair_elem.1147" }
%"struct.std::__1::__compressed_pair_elem.1147" = type { %"class.v8::PageAllocator::SharedMemoryMapping"* }
%"class.v8::PageAllocator::SharedMemoryMapping" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.655" = type { %"struct.std::__1::__compressed_pair_elem.656" }
%"struct.std::__1::__compressed_pair_elem.656" = type { %"class.std::__1::unique_ptr.654"* }
%"class.std::__1::unique_ptr.663" = type { %"class.std::__1::__compressed_pair.664" }
%"class.std::__1::__compressed_pair.664" = type { %"struct.std::__1::__compressed_pair_elem.665" }
%"struct.std::__1::__compressed_pair_elem.665" = type { %"class.v8::internal::ReadOnlyHeap"* }
%"class.std::__1::unique_ptr.669" = type { %"class.std::__1::__compressed_pair.670" }
%"class.std::__1::__compressed_pair.670" = type { %"struct.std::__1::__compressed_pair_elem.671" }
%"struct.std::__1::__compressed_pair_elem.671" = type { %"class.v8::internal::StringTable"* }
%"class.v8::internal::StringTable" = type { %"struct.std::__1::atomic.672", %"class.v8::base::Mutex" }
%"struct.std::__1::atomic.672" = type { %"struct.std::__1::__atomic_base.673" }
%"struct.std::__1::__atomic_base.673" = type { %"struct.std::__1::__cxx_atomic_impl.674" }
%"struct.std::__1::__cxx_atomic_impl.674" = type { %"struct.std::__1::__cxx_atomic_base_impl.675" }
%"struct.std::__1::__cxx_atomic_base_impl.675" = type { %"class.v8::internal::StringTable::Data"* }
%"class.v8::internal::StringTable::Data" = type opaque
%"class.v8::internal::Isolate::EntryStackItem" = type { i32, %"class.v8::internal::Isolate::PerIsolateThreadData"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate::EntryStackItem"* }
%"class.v8::internal::Isolate::PerIsolateThreadData" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::ThreadId", i64, %"class.v8::internal::ThreadState"* }
%"class.v8::internal::ThreadState" = type opaque
%"class.v8::internal::StringStream" = type opaque
%"class.v8::internal::Bootstrapper" = type { %"class.v8::internal::Isolate"*, i32, %"class.v8::internal::SourceCodeCache" }
%"class.v8::internal::SourceCodeCache" = type { i32, %"class.v8::internal::FixedArray" }
%"class.v8::internal::FixedArray" = type { %"class.v8::internal::TorqueGeneratedFixedArray" }
%"class.v8::internal::TorqueGeneratedFixedArray" = type { %"class.v8::internal::FixedArrayBase" }
%"class.v8::internal::FixedArrayBase" = type { %"class.v8::internal::TorqueGeneratedFixedArrayBase" }
%"class.v8::internal::TorqueGeneratedFixedArrayBase" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::RuntimeProfiler" = type opaque
%"class.v8::internal::CompilationCache" = type opaque
%"class.std::__1::shared_ptr.679" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::Counters" = type { %"class.std::__1::enable_shared_from_this", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::AggregatableHistogramTimer", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::RuntimeCallStats", %"class.v8::internal::WorkerThreadRuntimeCallStats", %"class.v8::internal::Isolate"*, %"class.v8::internal::StatsTable" }
%"class.std::__1::enable_shared_from_this" = type { %"class.std::__1::weak_ptr" }
%"class.std::__1::weak_ptr" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::HistogramTimer" = type { %"class.v8::internal::TimedHistogram.base", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::TimedHistogram.base" = type <{ %"class.v8::internal::Histogram", i32 }>
%"class.v8::base::ElapsedTimer" = type { %"class.v8::base::TimeTicks" }
%"class.v8::base::TimeTicks" = type { %"class.v8::base::time_internal::TimeBase" }
%"class.v8::base::time_internal::TimeBase" = type { i64 }
%"class.v8::internal::TimedHistogram" = type <{ %"class.v8::internal::Histogram", i32, [4 x i8] }>
%"class.v8::internal::AggregatableHistogramTimer" = type { %"class.v8::internal::Histogram", %"class.v8::base::TimeDelta" }
%"class.v8::base::TimeDelta" = type { i64 }
%"class.v8::internal::Histogram" = type { i8*, i32, i32, i32, i8*, %"class.v8::internal::Counters"* }
%"class.v8::internal::StatsCounterThreadSafe" = type { %"class.v8::internal::StatsCounterBase", %"class.v8::base::Mutex" }
%"class.v8::internal::StatsCounterBase" = type { %"class.v8::internal::Counters"*, i8*, i32* }
%"class.v8::internal::StatsCounter" = type <{ %"class.v8::internal::StatsCounterBase", i8, [7 x i8] }>
%"class.v8::internal::RuntimeCallStats" = type { %"class.v8::base::AtomicValue", %"class.v8::base::AtomicValue.680", i8, i32, %"class.v8::internal::ThreadId", [1370 x %"class.v8::internal::RuntimeCallCounter"] }
%"class.v8::base::AtomicValue" = type { i64 }
%"class.v8::base::AtomicValue.680" = type { i64 }
%"class.v8::internal::RuntimeCallCounter" = type { i8*, i64, i64 }
%"class.v8::internal::WorkerThreadRuntimeCallStats" = type <{ %"class.v8::base::Mutex", %"class.std::__1::vector.681", %"class.v8::base::Optional", %"class.v8::internal::ThreadId", [4 x i8] }>
%"class.std::__1::vector.681" = type { %"class.std::__1::__vector_base.682" }
%"class.std::__1::__vector_base.682" = type { %"class.std::__1::unique_ptr.683"*, %"class.std::__1::unique_ptr.683"*, %"class.std::__1::__compressed_pair.684" }
%"class.std::__1::unique_ptr.683" = type opaque
%"class.std::__1::__compressed_pair.684" = type { %"struct.std::__1::__compressed_pair_elem.685" }
%"struct.std::__1::__compressed_pair_elem.685" = type { %"class.std::__1::unique_ptr.683"* }
%"class.v8::base::Optional" = type { %"class.v8::base::internal::OptionalBase" }
%"class.v8::base::internal::OptionalBase" = type { %"struct.v8::base::internal::OptionalStorage" }
%"struct.v8::base::internal::OptionalStorage" = type { %"struct.v8::base::internal::OptionalStorageBase" }
%"struct.v8::base::internal::OptionalStorageBase" = type { i8, %union.anon }
%union.anon = type { i32 }
%"class.v8::internal::StatsTable" = type { i32* (i8*)*, i8* (i8*, i32, i32, i64)*, void (i8*, i32)* }
%"class.v8::base::RecursiveMutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.v8::base::SharedMutex" = type { %union.pthread_rwlock_t }
%union.pthread_rwlock_t = type { %struct.__pthread_rwlock_arch_t }
%struct.__pthread_rwlock_arch_t = type { i32, i32, i32, i32, i32, i32, i32, i32, i8, [7 x i8], i64, i32 }
%"class.v8::internal::Logger" = type { %"class.v8::internal::CodeEventListener", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.689", %"class.std::__1::unique_ptr.695", %"struct.std::__1::atomic.155", %"class.std::__1::unique_ptr.701", %"class.std::__1::unique_ptr.707", %"class.std::__1::unique_ptr.713", %"class.std::__1::unique_ptr.719", %"class.std::__1::unique_ptr.725", %"class.std::__1::set.731", i32, i8, %"class.v8::internal::ExistingCodeLogger", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::CodeEventListener" = type { i32 (...)** }
%"class.std::__1::unique_ptr.689" = type { %"class.std::__1::__compressed_pair.690" }
%"class.std::__1::__compressed_pair.690" = type { %"struct.std::__1::__compressed_pair_elem.691" }
%"struct.std::__1::__compressed_pair_elem.691" = type { %"class.v8::internal::Ticker"* }
%"class.v8::internal::Ticker" = type opaque
%"class.std::__1::unique_ptr.695" = type { %"class.std::__1::__compressed_pair.696" }
%"class.std::__1::__compressed_pair.696" = type { %"struct.std::__1::__compressed_pair_elem.697" }
%"struct.std::__1::__compressed_pair_elem.697" = type { %"class.v8::internal::Profiler"* }
%"class.v8::internal::Profiler" = type opaque
%"class.std::__1::unique_ptr.701" = type { %"class.std::__1::__compressed_pair.702" }
%"class.std::__1::__compressed_pair.702" = type { %"struct.std::__1::__compressed_pair_elem.703" }
%"struct.std::__1::__compressed_pair_elem.703" = type { %"class.v8::internal::Log"* }
%"class.v8::internal::Log" = type opaque
%"class.std::__1::unique_ptr.707" = type { %"class.std::__1::__compressed_pair.708" }
%"class.std::__1::__compressed_pair.708" = type { %"struct.std::__1::__compressed_pair_elem.709" }
%"struct.std::__1::__compressed_pair_elem.709" = type { %"class.v8::internal::PerfBasicLogger"* }
%"class.v8::internal::PerfBasicLogger" = type opaque
%"class.std::__1::unique_ptr.713" = type { %"class.std::__1::__compressed_pair.714" }
%"class.std::__1::__compressed_pair.714" = type { %"struct.std::__1::__compressed_pair_elem.715" }
%"struct.std::__1::__compressed_pair_elem.715" = type { %"class.v8::internal::PerfJitLogger"* }
%"class.v8::internal::PerfJitLogger" = type opaque
%"class.std::__1::unique_ptr.719" = type { %"class.std::__1::__compressed_pair.720" }
%"class.std::__1::__compressed_pair.720" = type { %"struct.std::__1::__compressed_pair_elem.721" }
%"struct.std::__1::__compressed_pair_elem.721" = type { %"class.v8::internal::LowLevelLogger"* }
%"class.v8::internal::LowLevelLogger" = type opaque
%"class.std::__1::unique_ptr.725" = type { %"class.std::__1::__compressed_pair.726" }
%"class.std::__1::__compressed_pair.726" = type { %"struct.std::__1::__compressed_pair_elem.727" }
%"struct.std::__1::__compressed_pair_elem.727" = type { %"class.v8::internal::JitLogger"* }
%"class.v8::internal::JitLogger" = type opaque
%"class.std::__1::set.731" = type { %"class.std::__1::__tree.732" }
%"class.std::__1::__tree.732" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.733", %"class.std::__1::__compressed_pair.737" }
%"class.std::__1::__compressed_pair.733" = type { %"struct.std::__1::__compressed_pair_elem.83" }
%"class.std::__1::__compressed_pair.737" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.v8::internal::ExistingCodeLogger" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::CodeEventListener"* }
%"class.v8::internal::StubCache" = type { [2048 x %"struct.v8::internal::StubCache::Entry"], [512 x %"struct.v8::internal::StubCache::Entry"], %"class.v8::internal::Isolate"* }
%"struct.v8::internal::StubCache::Entry" = type { %"class.v8::internal::StrongTaggedValue", %"class.v8::internal::TaggedValue", %"class.v8::internal::StrongTaggedValue" }
%"class.v8::internal::TaggedValue" = type { %"class.v8::internal::TaggedImpl.740" }
%"class.v8::internal::TaggedImpl.740" = type { i32 }
%"class.v8::internal::StrongTaggedValue" = type { %"class.v8::internal::TaggedImpl.739" }
%"class.v8::internal::TaggedImpl.739" = type { i32 }
%"class.v8::internal::Deoptimizer" = type opaque
%"class.v8::internal::MaterializedObjectStore" = type opaque
%"class.v8::internal::DescriptorLookupCache" = type { [64 x %"struct.v8::internal::DescriptorLookupCache::Key"], [64 x i32] }
%"struct.v8::internal::DescriptorLookupCache::Key" = type { %"class.v8::internal::Map", %"class.v8::internal::Name" }
%"class.v8::internal::Map" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Name" = type { %"class.v8::internal::TorqueGeneratedName" }
%"class.v8::internal::TorqueGeneratedName" = type { %"class.v8::internal::PrimitiveHeapObject" }
%"class.v8::internal::PrimitiveHeapObject" = type { %"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" }
%"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" = type { %"class.v8::internal::HeapObject" }
%"struct.v8::internal::HandleScopeData" = type { i64*, i64*, i32, i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::CanonicalHandleScope" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::Zone"*, %"class.v8::internal::RootIndexMap"*, %"class.std::__1::unique_ptr.747", i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::OptimizedCompilationInfo" = type opaque
%"class.v8::internal::RootIndexMap" = type opaque
%"class.std::__1::unique_ptr.747" = type { %"class.std::__1::__compressed_pair.748" }
%"class.std::__1::__compressed_pair.748" = type { %"struct.std::__1::__compressed_pair_elem.749" }
%"struct.std::__1::__compressed_pair_elem.749" = type { %"class.v8::internal::IdentityMap"* }
%"class.v8::internal::IdentityMap" = type opaque
%"class.v8::internal::HandleScopeImplementer" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::DetachableVector", %"class.v8::internal::DetachableVector.753", %"class.v8::internal::DetachableVector.754", %"class.v8::internal::DetachableVector.753", i64*, i64*, %"struct.v8::internal::HandleScopeData" }
%"class.v8::internal::DetachableVector" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVectorBase" = type { i8*, i64, i64 }
%"class.v8::internal::DetachableVector.754" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVector.753" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::UnicodeCache" = type opaque
%"class.v8::internal::AccountingAllocator" = type { i32 (...)**, %"struct.std::__1::atomic.22", %"struct.std::__1::atomic.22", %"class.std::__1::unique_ptr.741", %"class.std::__1::unique_ptr.484" }
%"class.std::__1::unique_ptr.741" = type { %"class.std::__1::__compressed_pair.742" }
%"class.std::__1::__compressed_pair.742" = type { %"struct.std::__1::__compressed_pair_elem.743" }
%"struct.std::__1::__compressed_pair_elem.743" = type { %"class.v8::internal::VirtualMemory"* }
%"class.v8::internal::InnerPointerToCodeCache" = type opaque
%"class.v8::internal::GlobalHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.755", %"class.std::__1::vector.761", %"class.std::__1::unique_ptr.768", %"class.std::__1::vector.775", %"class.std::__1::unique_ptr.782", i64, %"class.std::__1::vector.788", %"class.std::__1::vector.796", %"class.std::__1::vector.804", i8, i8, i32 }
%"class.std::__1::unique_ptr.755" = type { %"class.std::__1::__compressed_pair.756" }
%"class.std::__1::__compressed_pair.756" = type { %"struct.std::__1::__compressed_pair_elem.757" }
%"struct.std::__1::__compressed_pair_elem.757" = type { %"class.v8::internal::GlobalHandles::NodeSpace"* }
%"class.v8::internal::GlobalHandles::NodeSpace" = type opaque
%"class.std::__1::vector.761" = type { %"class.std::__1::__vector_base.762" }
%"class.std::__1::__vector_base.762" = type { %"class.v8::internal::GlobalHandles::Node"**, %"class.v8::internal::GlobalHandles::Node"**, %"class.std::__1::__compressed_pair.763" }
%"class.v8::internal::GlobalHandles::Node" = type opaque
%"class.std::__1::__compressed_pair.763" = type { %"struct.std::__1::__compressed_pair_elem.764" }
%"struct.std::__1::__compressed_pair_elem.764" = type { %"class.v8::internal::GlobalHandles::Node"** }
%"class.std::__1::unique_ptr.768" = type { %"class.std::__1::__compressed_pair.769" }
%"class.std::__1::__compressed_pair.769" = type { %"struct.std::__1::__compressed_pair_elem.770" }
%"struct.std::__1::__compressed_pair_elem.770" = type { %"class.v8::internal::GlobalHandles::NodeSpace.771"* }
%"class.v8::internal::GlobalHandles::NodeSpace.771" = type opaque
%"class.std::__1::vector.775" = type { %"class.std::__1::__vector_base.776" }
%"class.std::__1::__vector_base.776" = type { %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.std::__1::__compressed_pair.777" }
%"class.v8::internal::GlobalHandles::TracedNode" = type opaque
%"class.std::__1::__compressed_pair.777" = type { %"struct.std::__1::__compressed_pair_elem.778" }
%"struct.std::__1::__compressed_pair_elem.778" = type { %"class.v8::internal::GlobalHandles::TracedNode"** }
%"class.std::__1::unique_ptr.782" = type { %"class.std::__1::__compressed_pair.783" }
%"class.std::__1::__compressed_pair.783" = type { %"struct.std::__1::__compressed_pair_elem.784" }
%"struct.std::__1::__compressed_pair_elem.784" = type { %"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace"* }
%"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace" = type opaque
%"class.std::__1::vector.788" = type { %"class.std::__1::__vector_base.789" }
%"class.std::__1::__vector_base.789" = type { %"struct.std::__1::pair.790"*, %"struct.std::__1::pair.790"*, %"class.std::__1::__compressed_pair.791" }
%"struct.std::__1::pair.790" = type opaque
%"class.std::__1::__compressed_pair.791" = type { %"struct.std::__1::__compressed_pair_elem.792" }
%"struct.std::__1::__compressed_pair_elem.792" = type { %"struct.std::__1::pair.790"* }
%"class.std::__1::vector.796" = type { %"class.std::__1::__vector_base.797" }
%"class.std::__1::__vector_base.797" = type { %"struct.std::__1::pair.798"*, %"struct.std::__1::pair.798"*, %"class.std::__1::__compressed_pair.799" }
%"struct.std::__1::pair.798" = type opaque
%"class.std::__1::__compressed_pair.799" = type { %"struct.std::__1::__compressed_pair_elem.800" }
%"struct.std::__1::__compressed_pair_elem.800" = type { %"struct.std::__1::pair.798"* }
%"class.std::__1::vector.804" = type { %"class.std::__1::__vector_base.805" }
%"class.std::__1::__vector_base.805" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.std::__1::__compressed_pair.806" }
%"class.v8::internal::GlobalHandles::PendingPhantomCallback" = type { void (%"class.v8::WeakCallbackInfo"*)*, i8*, [2 x i8*] }
%"class.v8::WeakCallbackInfo" = type { %"class.v8::Isolate"*, i8*, {}**, [2 x i8*] }
%"class.std::__1::__compressed_pair.806" = type { %"struct.std::__1::__compressed_pair_elem.807" }
%"struct.std::__1::__compressed_pair_elem.807" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"* }
%"class.v8::internal::EternalHandles" = type { i32, %"class.std::__1::vector.811", %"class.std::__1::vector.818" }
%"class.v8::internal::ThreadManager" = type opaque
%"class.v8::bigint::Processor" = type opaque
%"class.v8::internal::RuntimeState" = type { %"class.std::__1::unique_ptr.825" }
%"class.std::__1::unique_ptr.825" = type { %"class.std::__1::__compressed_pair.826" }
%"class.std::__1::__compressed_pair.826" = type { %"struct.std::__1::__compressed_pair_elem.827" }
%"struct.std::__1::__compressed_pair_elem.827" = type { %"struct.v8::internal::Runtime::Function"* }
%"struct.v8::internal::Runtime::Function" = type { i32, i32, i8*, i64, i8, i8 }
%"class.v8::internal::Builtins" = type { %"class.v8::internal::Isolate"*, i8, i32 }
%"class.v8::internal::SetupIsolateDelegate" = type opaque
%"class.v8::internal::RegExpStack" = type opaque
%"class.std::__1::vector.818" = type { %"class.std::__1::__vector_base.819" }
%"class.std::__1::__vector_base.819" = type { i32*, i32*, %"class.std::__1::__compressed_pair.820" }
%"class.std::__1::__compressed_pair.820" = type { %"struct.std::__1::__compressed_pair_elem.821" }
%"struct.std::__1::__compressed_pair_elem.821" = type { i32* }
%"class.v8::internal::DateCache" = type opaque
%"struct.std::__1::atomic.831" = type { %"struct.std::__1::__atomic_base.832" }
%"struct.std::__1::__atomic_base.832" = type { %"struct.std::__1::__cxx_atomic_impl.833" }
%"struct.std::__1::__cxx_atomic_impl.833" = type { %"struct.std::__1::__cxx_atomic_base_impl.834" }
%"struct.std::__1::__cxx_atomic_base_impl.834" = type { i32 }
%"class.v8::SharedArrayBuffer" = type { i8 }
%"class.v8::Isolate::AtomicsWaitWakeHandle" = type { i8 }
%"class.v8::Promise" = type { i8 }
%"struct.std::__1::atomic.841" = type { %"struct.std::__1::__atomic_base.842" }
%"struct.std::__1::__atomic_base.842" = type { %"struct.std::__1::__cxx_atomic_impl.843" }
%"struct.std::__1::__cxx_atomic_impl.843" = type { %"struct.std::__1::__cxx_atomic_base_impl.844" }
%"struct.std::__1::__cxx_atomic_base_impl.844" = type { i32 }
%"class.v8::Context" = type { i8 }
%"class.v8::Module" = type { i8 }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair.846" }
%"class.std::__1::__compressed_pair.846" = type { %"struct.std::__1::__compressed_pair_elem.847" }
%"struct.std::__1::__compressed_pair_elem.847" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon.848 }
%union.anon.848 = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%"class.std::__1::unordered_map.852" = type { %"class.std::__1::__hash_table.853" }
%"class.std::__1::__hash_table.853" = type <{ %"class.std::__1::unique_ptr.854", %"class.std::__1::__compressed_pair.864", %"class.std::__1::__compressed_pair.869", %"class.std::__1::__compressed_pair.872", [4 x i8] }>
%"class.std::__1::unique_ptr.854" = type { %"class.std::__1::__compressed_pair.855" }
%"class.std::__1::__compressed_pair.855" = type { %"struct.std::__1::__compressed_pair_elem.856", %"struct.std::__1::__compressed_pair_elem.858" }
%"struct.std::__1::__compressed_pair_elem.856" = type { %"struct.std::__1::__hash_node_base.857"** }
%"struct.std::__1::__hash_node_base.857" = type { %"struct.std::__1::__hash_node_base.857"* }
%"struct.std::__1::__compressed_pair_elem.858" = type { %"class.std::__1::__bucket_list_deallocator.859" }
%"class.std::__1::__bucket_list_deallocator.859" = type { %"class.std::__1::__compressed_pair.860" }
%"class.std::__1::__compressed_pair.860" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.864" = type { %"struct.std::__1::__compressed_pair_elem.865" }
%"struct.std::__1::__compressed_pair_elem.865" = type { %"struct.std::__1::__hash_node_base.857" }
%"class.std::__1::__compressed_pair.869" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.872" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"struct.std::__1::atomic.155" = type { %"struct.std::__1::__atomic_base.156" }
%"struct.std::__1::__atomic_base.156" = type { %"struct.std::__1::__cxx_atomic_impl.157" }
%"struct.std::__1::__cxx_atomic_impl.157" = type { %"struct.std::__1::__cxx_atomic_base_impl.158" }
%"struct.std::__1::__cxx_atomic_base_impl.158" = type { i8 }
%"class.v8::internal::Debug" = type { %"class.v8::debug::DebugDelegate"*, i8, i8, i8, i8, i8, i8, i8, i8, i8, %"class.v8::internal::DebugInfoListNode"*, %"class.std::__1::unique_ptr.878", %"class.v8::internal::Handle.884", %"class.v8::internal::DebugFeatureTracker", %"class.v8::internal::Debug::ThreadLocal", %"class.v8::internal::Handle.885", %"class.v8::internal::Isolate"* }
%"class.v8::debug::DebugDelegate" = type { i32 (...)** }
%"class.v8::internal::DebugInfoListNode" = type { i64*, %"class.v8::internal::DebugInfoListNode"* }
%"class.std::__1::unique_ptr.878" = type { %"class.std::__1::__compressed_pair.879" }
%"class.std::__1::__compressed_pair.879" = type { %"struct.std::__1::__compressed_pair_elem.880" }
%"struct.std::__1::__compressed_pair_elem.880" = type { %"class.v8::internal::Debug::TemporaryObjectsTracker"* }
%"class.v8::internal::Debug::TemporaryObjectsTracker" = type opaque
%"class.v8::internal::Handle.884" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::DebugFeatureTracker" = type <{ %"class.v8::internal::Isolate"*, i32, [4 x i8] }>
%"class.v8::internal::Debug::ThreadLocal" = type <{ i64, i32, i8, [3 x i8], %"class.v8::internal::Object", i8, [3 x i8], i32, i32, i32, %"class.v8::internal::Object", %"class.v8::internal::Object", i32, i8, [3 x i8] }>
%"class.v8::internal::Handle.885" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HeapProfiler" = type { %"class.v8::internal::HeapObjectAllocationTracker", %"class.std::__1::unique_ptr.886", %"class.std::__1::vector.892", %"class.std::__1::unique_ptr.900", %"class.std::__1::unique_ptr.906", i8, i8, %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.912", %"class.std::__1::vector.918", %"struct.std::__1::pair.926" }
%"class.std::__1::unique_ptr.886" = type { %"class.std::__1::__compressed_pair.887" }
%"class.std::__1::__compressed_pair.887" = type { %"struct.std::__1::__compressed_pair_elem.888" }
%"struct.std::__1::__compressed_pair_elem.888" = type { %"class.v8::internal::HeapObjectsMap"* }
%"class.v8::internal::HeapObjectsMap" = type opaque
%"class.std::__1::vector.892" = type { %"class.std::__1::__vector_base.893" }
%"class.std::__1::__vector_base.893" = type { %"class.std::__1::unique_ptr.894"*, %"class.std::__1::unique_ptr.894"*, %"class.std::__1::__compressed_pair.895" }
%"class.std::__1::unique_ptr.894" = type opaque
%"class.std::__1::__compressed_pair.895" = type { %"struct.std::__1::__compressed_pair_elem.896" }
%"struct.std::__1::__compressed_pair_elem.896" = type { %"class.std::__1::unique_ptr.894"* }
%"class.std::__1::unique_ptr.900" = type { %"class.std::__1::__compressed_pair.901" }
%"class.std::__1::__compressed_pair.901" = type { %"struct.std::__1::__compressed_pair_elem.902" }
%"struct.std::__1::__compressed_pair_elem.902" = type { %"class.v8::internal::StringsStorage"* }
%"class.v8::internal::StringsStorage" = type opaque
%"class.std::__1::unique_ptr.906" = type { %"class.std::__1::__compressed_pair.907" }
%"class.std::__1::__compressed_pair.907" = type { %"struct.std::__1::__compressed_pair_elem.908" }
%"struct.std::__1::__compressed_pair_elem.908" = type { %"class.v8::internal::AllocationTracker"* }
%"class.v8::internal::AllocationTracker" = type opaque
%"class.std::__1::unique_ptr.912" = type { %"class.std::__1::__compressed_pair.913" }
%"class.std::__1::__compressed_pair.913" = type { %"struct.std::__1::__compressed_pair_elem.914" }
%"struct.std::__1::__compressed_pair_elem.914" = type { %"class.v8::internal::SamplingHeapProfiler"* }
%"class.v8::internal::SamplingHeapProfiler" = type opaque
%"class.std::__1::vector.918" = type { %"class.std::__1::__vector_base.919" }
%"class.std::__1::__vector_base.919" = type { %"struct.std::__1::pair.920"*, %"struct.std::__1::pair.920"*, %"class.std::__1::__compressed_pair.921" }
%"struct.std::__1::pair.920" = type opaque
%"class.std::__1::__compressed_pair.921" = type { %"struct.std::__1::__compressed_pair_elem.922" }
%"struct.std::__1::__compressed_pair_elem.922" = type { %"struct.std::__1::pair.920"* }
%"struct.std::__1::pair.926" = type { i8 (%"class.v8::Isolate"*, %"class.v8::Local.3"*, i16, i8*)*, i8* }
%"class.v8::Local.3" = type { %"class.v8::Value"* }
%"class.std::__1::unique_ptr.927" = type { %"class.std::__1::__compressed_pair.928" }
%"class.std::__1::__compressed_pair.928" = type { %"struct.std::__1::__compressed_pair_elem.929" }
%"struct.std::__1::__compressed_pair_elem.929" = type { %"class.v8::internal::CodeEventDispatcher"* }
%"class.v8::internal::CodeEventDispatcher" = type { %"class.v8::internal::CodeEventListener", %"class.std::__1::unordered_set.930", %"class.v8::base::Mutex" }
%"class.std::__1::unordered_set.930" = type { %"class.std::__1::__hash_table.931" }
%"class.std::__1::__hash_table.931" = type <{ %"class.std::__1::unique_ptr.932", %"class.std::__1::__compressed_pair.942", %"class.std::__1::__compressed_pair.947", %"class.std::__1::__compressed_pair.951", [4 x i8] }>
%"class.std::__1::unique_ptr.932" = type { %"class.std::__1::__compressed_pair.933" }
%"class.std::__1::__compressed_pair.933" = type { %"struct.std::__1::__compressed_pair_elem.934", %"struct.std::__1::__compressed_pair_elem.936" }
%"struct.std::__1::__compressed_pair_elem.934" = type { %"struct.std::__1::__hash_node_base.935"** }
%"struct.std::__1::__hash_node_base.935" = type { %"struct.std::__1::__hash_node_base.935"* }
%"struct.std::__1::__compressed_pair_elem.936" = type { %"class.std::__1::__bucket_list_deallocator.937" }
%"class.std::__1::__bucket_list_deallocator.937" = type { %"class.std::__1::__compressed_pair.938" }
%"class.std::__1::__compressed_pair.938" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.942" = type { %"struct.std::__1::__compressed_pair_elem.943" }
%"struct.std::__1::__compressed_pair_elem.943" = type { %"struct.std::__1::__hash_node_base.935" }
%"class.std::__1::__compressed_pair.947" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.951" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.v8::internal::AstStringConstants" = type opaque
%"class.v8::internal::interpreter::Interpreter" = type opaque
%"class.v8::internal::compiler::PerIsolateCompilerCache" = type opaque
%"class.v8::internal::Zone" = type <{ i64, i64, i64, i64, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::Segment"*, i8*, i8, i8, [6 x i8] }>
%"class.v8::internal::Segment" = type { %"class.v8::internal::Zone"*, %"class.v8::internal::Segment"*, i64 }
%"class.v8::internal::CompilerDispatcher" = type opaque
%"class.std::__1::queue" = type { %"class.std::__1::deque" }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.965" }
%"struct.std::__1::__split_buffer" = type { %"struct.std::__1::pair.959"**, %"struct.std::__1::pair.959"**, %"struct.std::__1::pair.959"**, %"class.std::__1::__compressed_pair.960" }
%"struct.std::__1::pair.959" = type opaque
%"class.std::__1::__compressed_pair.960" = type { %"struct.std::__1::__compressed_pair_elem.961" }
%"struct.std::__1::__compressed_pair_elem.961" = type { %"struct.std::__1::pair.959"** }
%"class.std::__1::__compressed_pair.965" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.v8::String" = type { i8 }
%"class.v8::FunctionCallbackInfo" = type <{ i64*, i64*, i32, [4 x i8] }>
%"class.v8::internal::Relocatable" = type { i32 (...)**, %"class.v8::internal::Isolate"*, %"class.v8::internal::Relocatable"* }
%"class.std::__1::vector.970" = type { %"class.std::__1::__vector_base.971" }
%"class.std::__1::__vector_base.971" = type { %"class.v8::internal::Handle.972"*, %"class.v8::internal::Handle.972"*, %"class.std::__1::__compressed_pair.973" }
%"class.v8::internal::Handle.972" = type { %"class.v8::internal::HandleBase" }
%"class.std::__1::__compressed_pair.973" = type { %"struct.std::__1::__compressed_pair_elem.974" }
%"struct.std::__1::__compressed_pair_elem.974" = type { %"class.v8::internal::Handle.972"* }
%"class.v8::internal::Object" = type { %"class.v8::internal::TaggedImpl" }
%"class.v8::internal::TaggedImpl" = type { i64 }
%"class.v8::internal::AddressToIndexHashMap" = type opaque
%"class.v8::internal::HeapObjectToIndexHashMap" = type opaque
%"class.v8::internal::MicrotaskQueue" = type { %"class.v8::MicrotaskQueue", i64, i64, i64, i64*, i64, %"class.v8::internal::MicrotaskQueue"*, %"class.v8::internal::MicrotaskQueue"*, i32, i32, i32, i8, %"class.std::__1::vector.978" }
%"class.v8::MicrotaskQueue" = type { i32 (...)** }
%"class.std::__1::vector.978" = type { %"class.std::__1::__vector_base.979" }
%"class.std::__1::__vector_base.979" = type { %"struct.std::__1::pair.959"*, %"struct.std::__1::pair.959"*, %"class.std::__1::__compressed_pair.980" }
%"class.std::__1::__compressed_pair.980" = type { %"struct.std::__1::__compressed_pair_elem.981" }
%"struct.std::__1::__compressed_pair_elem.981" = type { %"struct.std::__1::pair.959"* }
%"class.v8::internal::CompilationStatistics" = type opaque
%"class.v8::internal::CodeTracer" = type <{ %"class.v8::internal::EmbeddedVector", %struct._IO_FILE*, i32, [4 x i8] }>
%"class.v8::internal::EmbeddedVector" = type { %"class.v8::internal::Vector", [128 x i8] }
%"class.v8::internal::Vector" = type { i8*, i64 }
%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%"class.v8::PromiseRejectMessage" = type { %"class.v8::Local.836", i32, %"class.v8::Local.3" }
%"class.v8::Local.836" = type { %"class.v8::Promise"* }
%"class.v8::StartupData" = type { i8*, i32 }
%"class.v8_inspector::V8Inspector" = type opaque
%"class.v8::internal::compiler::NodeObserver" = type opaque
%"class.v8::internal::OptimizingCompileDispatcher" = type opaque
%"class.std::__1::unique_ptr.982" = type { %"class.std::__1::__compressed_pair.983" }
%"class.std::__1::__compressed_pair.983" = type { %"struct.std::__1::__compressed_pair_elem.984" }
%"struct.std::__1::__compressed_pair_elem.984" = type { %"class.v8::internal::PersistentHandlesList"* }
%"class.v8::internal::PersistentHandlesList" = type { %"class.v8::base::Mutex", %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.988" = type { %"class.std::__1::__vector_base.989" }
%"class.std::__1::__vector_base.989" = type { void (%"class.v8::Isolate"*)**, void (%"class.v8::Isolate"*)**, %"class.std::__1::__compressed_pair.990" }
%"class.std::__1::__compressed_pair.990" = type { %"struct.std::__1::__compressed_pair_elem.991" }
%"struct.std::__1::__compressed_pair_elem.991" = type { void (%"class.v8::Isolate"*)** }
%"class.std::__1::shared_ptr.995" = type { %"class.v8::internal::metrics::Recorder"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::metrics::Recorder" = type opaque
%"class.std::__1::unordered_map.996" = type { %"class.std::__1::__hash_table.997" }
%"class.std::__1::__hash_table.997" = type <{ %"class.std::__1::unique_ptr.998", %"class.std::__1::__compressed_pair.1008", %"class.std::__1::__compressed_pair.1013", %"class.std::__1::__compressed_pair.1016", [4 x i8] }>
%"class.std::__1::unique_ptr.998" = type { %"class.std::__1::__compressed_pair.999" }
%"class.std::__1::__compressed_pair.999" = type { %"struct.std::__1::__compressed_pair_elem.1000", %"struct.std::__1::__compressed_pair_elem.1002" }
%"struct.std::__1::__compressed_pair_elem.1000" = type { %"struct.std::__1::__hash_node_base.1001"** }
%"struct.std::__1::__hash_node_base.1001" = type { %"struct.std::__1::__hash_node_base.1001"* }
%"struct.std::__1::__compressed_pair_elem.1002" = type { %"class.std::__1::__bucket_list_deallocator.1003" }
%"class.std::__1::__bucket_list_deallocator.1003" = type { %"class.std::__1::__compressed_pair.1004" }
%"class.std::__1::__compressed_pair.1004" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.1008" = type { %"struct.std::__1::__compressed_pair_elem.1009" }
%"struct.std::__1::__compressed_pair_elem.1009" = type { %"struct.std::__1::__hash_node_base.1001" }
%"class.std::__1::__compressed_pair.1013" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.1016" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"struct.v8::metrics::LongTaskStats" = type { i64, i64, i64 }
%"class.std::__1::vector.544" = type { %"class.std::__1::__vector_base.545" }
%"class.std::__1::__vector_base.545" = type { %"class.v8::internal::Object"*, %"class.v8::internal::Object"*, %"class.std::__1::__compressed_pair.546" }
%"class.std::__1::__compressed_pair.546" = type { %"struct.std::__1::__compressed_pair_elem.547" }
%"struct.std::__1::__compressed_pair_elem.547" = type { %"class.v8::internal::Object"* }
%"class.v8::internal::BuiltinsConstantsTableBuilder" = type opaque
%"class.v8::ArrayBuffer::Allocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.163" = type { %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::FutexWaitListNode" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::shared_ptr.1020", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::base::ConditionVariable", %"class.v8::internal::FutexWaitListNode"*, %"class.v8::internal::FutexWaitListNode"*, %"class.std::__1::weak_ptr.1049", i64, i8*, i8, i8, %"class.v8::Global", %"class.v8::Global.1050", %"class.v8::base::TimeTicks", i64 }
%"class.std::__1::shared_ptr.1020" = type { %"class.v8::TaskRunner"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::TaskRunner" = type { i32 (...)** }
%"class.v8::base::ConditionVariable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon.1045, %union.anon.1047, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon.1045 = type { i64 }
%union.anon.1047 = type { i64 }
%"class.std::__1::weak_ptr.1049" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::Global" = type { %"class.v8::PersistentBase" }
%"class.v8::PersistentBase" = type { %"class.v8::Promise"* }
%"class.v8::Global.1050" = type { %"class.v8::PersistentBase.1051" }
%"class.v8::PersistentBase.1051" = type { %"class.v8::Context"* }
%"class.v8::internal::CancelableTaskManager" = type <{ i64, %"class.std::__1::unordered_map.1021", %"class.v8::base::ConditionVariable", %"class.v8::base::Mutex", i8, [7 x i8] }>
%"class.std::__1::unordered_map.1021" = type { %"class.std::__1::__hash_table.1022" }
%"class.std::__1::__hash_table.1022" = type <{ %"class.std::__1::unique_ptr.1023", %"class.std::__1::__compressed_pair.1033", %"class.std::__1::__compressed_pair.1038", %"class.std::__1::__compressed_pair.1041", [4 x i8] }>
%"class.std::__1::unique_ptr.1023" = type { %"class.std::__1::__compressed_pair.1024" }
%"class.std::__1::__compressed_pair.1024" = type { %"struct.std::__1::__compressed_pair_elem.1025", %"struct.std::__1::__compressed_pair_elem.1027" }
%"struct.std::__1::__compressed_pair_elem.1025" = type { %"struct.std::__1::__hash_node_base.1026"** }
%"struct.std::__1::__hash_node_base.1026" = type { %"struct.std::__1::__hash_node_base.1026"* }
%"struct.std::__1::__compressed_pair_elem.1027" = type { %"class.std::__1::__bucket_list_deallocator.1028" }
%"class.std::__1::__bucket_list_deallocator.1028" = type { %"class.std::__1::__compressed_pair.1029" }
%"class.std::__1::__compressed_pair.1029" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.1033" = type { %"struct.std::__1::__compressed_pair_elem.1034" }
%"struct.std::__1::__compressed_pair_elem.1034" = type { %"struct.std::__1::__hash_node_base.1026" }
%"class.std::__1::__compressed_pair.1038" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.1041" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.v8::debug::ConsoleDelegate" = type { i32 (...)** }
%"class.v8::debug::AsyncEventDelegate" = type { i32 (...)** }
%"class.std::__1::unique_ptr.1052" = type { %"class.std::__1::__compressed_pair.1053" }
%"class.std::__1::__compressed_pair.1053" = type { %"struct.std::__1::__compressed_pair_elem.1054" }
%"struct.std::__1::__compressed_pair_elem.1054" = type { %"class.v8::internal::LocalIsolate"* }
%"class.v8::internal::LocalIsolate" = type { %"class.v8::internal::HiddenLocalFactory", %"class.v8::internal::LocalHeap", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.1081", %"class.v8::internal::ThreadId", i64, %"class.v8::internal::RuntimeCallStats"* }
%"class.v8::internal::HiddenLocalFactory" = type { %"class.v8::internal::LocalFactory" }
%"class.v8::internal::LocalFactory" = type { %"class.v8::internal::ReadOnlyRoots" }
%"class.v8::internal::ReadOnlyRoots" = type { i64* }
%"class.std::__1::unique_ptr.1081" = type { %"class.std::__1::__compressed_pair.1082" }
%"class.std::__1::__compressed_pair.1082" = type { %"struct.std::__1::__compressed_pair_elem.1083" }
%"struct.std::__1::__compressed_pair_elem.1083" = type { %"class.v8::internal::LocalLogger"* }
%"class.v8::internal::LocalLogger" = type opaque
%"struct.v8::internal::ManagedPtrDestructor" = type { i64, %"struct.v8::internal::ManagedPtrDestructor"*, %"struct.v8::internal::ManagedPtrDestructor"*, i8*, void (i8*)*, i64* }
%"class.v8::internal::wasm::WasmEngine" = type opaque
%"class.std::__1::unique_ptr.1090" = type { %"class.std::__1::__compressed_pair.1091" }
%"class.std::__1::__compressed_pair.1091" = type { %"struct.std::__1::__compressed_pair_elem.1092" }
%"struct.std::__1::__compressed_pair_elem.1092" = type { %"class.v8::internal::TracingCpuProfilerImpl"* }
%"class.v8::internal::TracingCpuProfilerImpl" = type opaque
%"class.v8::internal::EmbeddedFileWriterInterface" = type opaque
%"class.v8::Context::BackupIncumbentScope" = type { %"class.v8::Local.837", i64, %"class.v8::Context::BackupIncumbentScope"* }
%"class.v8::Local.837" = type { %"class.v8::Context"* }
%"class.v8::Array" = type { i8 }
%"class.v8::internal::Isolate::ThreadDataTable" = type { %"class.std::__1::unordered_map.1098" }
%"class.std::__1::unordered_map.1098" = type { %"class.std::__1::__hash_table.1099" }
%"class.std::__1::__hash_table.1099" = type <{ %"class.std::__1::unique_ptr.1100", %"class.std::__1::__compressed_pair.1110", %"class.std::__1::__compressed_pair.1115", %"class.std::__1::__compressed_pair.1118", [4 x i8] }>
%"class.std::__1::unique_ptr.1100" = type { %"class.std::__1::__compressed_pair.1101" }
%"class.std::__1::__compressed_pair.1101" = type { %"struct.std::__1::__compressed_pair_elem.1102", %"struct.std::__1::__compressed_pair_elem.1104" }
%"struct.std::__1::__compressed_pair_elem.1102" = type { %"struct.std::__1::__hash_node_base.1103"** }
%"struct.std::__1::__hash_node_base.1103" = type { %"struct.std::__1::__hash_node_base.1103"* }
%"struct.std::__1::__compressed_pair_elem.1104" = type { %"class.std::__1::__bucket_list_deallocator.1105" }
%"class.std::__1::__bucket_list_deallocator.1105" = type { %"class.std::__1::__compressed_pair.1106" }
%"class.std::__1::__compressed_pair.1106" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.1110" = type { %"struct.std::__1::__compressed_pair_elem.1111" }
%"struct.std::__1::__compressed_pair_elem.1111" = type { %"struct.std::__1::__hash_node_base.1103" }
%"class.std::__1::__compressed_pair.1115" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"class.std::__1::__compressed_pair.1118" = type { %"struct.std::__1::__compressed_pair_elem.20" }
%"class.v8::base::Mutex" = type { %union.pthread_mutex_t }
%"struct.std::__1::atomic.1124" = type { %"struct.std::__1::__atomic_base.1125" }
%"struct.std::__1::__atomic_base.1125" = type { %"struct.std::__1::__cxx_atomic_impl.1126" }
%"struct.std::__1::__cxx_atomic_impl.1126" = type { %"struct.std::__1::__cxx_atomic_base_impl.1127" }
%"struct.std::__1::__cxx_atomic_base_impl.1127" = type { %"class.std::__1::vector.1128"* }
%"class.std::__1::vector.1128" = type { %"class.std::__1::__vector_base.1129" }
%"class.std::__1::__vector_base.1129" = type { %"struct.v8::MemoryRange"*, %"struct.v8::MemoryRange"*, %"class.std::__1::__compressed_pair.1130" }
%"struct.v8::MemoryRange" = type { i8*, i64 }
%"class.std::__1::__compressed_pair.1130" = type { %"struct.std::__1::__compressed_pair_elem.1131" }
%"struct.std::__1::__compressed_pair_elem.1131" = type { %"struct.v8::MemoryRange"* }
%"class.v8::internal::TorqueGeneratedFactory.1056" = type { i8 }
%"class.v8::internal::FactoryBase.1055" = type { i8 }

$_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE26NewSloppyArgumentsElementsEiNS0_6HandleINS0_7ContextEEENS4_INS0_10FixedArrayEEENS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE26NewSloppyArgumentsElementsEiNS0_6HandleINS0_7ContextEEENS4_INS0_10FixedArrayEEENS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE18NewDescriptorArrayEttttNS0_6HandleINS0_9EnumCacheEEENS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE18NewDescriptorArrayEttttNS0_6HandleINS0_9EnumCacheEEENS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE36NewUncompiledDataWithoutPreparseDataENS0_6HandleINS0_6StringEEEiiNS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE36NewUncompiledDataWithoutPreparseDataENS0_6HandleINS0_6StringEEEiiNS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE33NewUncompiledDataWithPreparseDataENS0_6HandleINS0_6StringEEEiiNS4_INS0_12PreparseDataEEENS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE33NewUncompiledDataWithPreparseDataENS0_6HandleINS0_6StringEEEiiNS4_INS0_12PreparseDataEEENS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE31NewOnHeapBasicBlockProfilerDataENS0_6HandleINS0_9ByteArrayEEES6_NS4_INS0_6StringEEES8_S8_iNS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE31NewOnHeapBasicBlockProfilerDataENS0_6HandleINS0_9ByteArrayEEES6_NS4_INS0_6StringEEES8_S8_iNS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE23NewExportedSubClassBaseENS0_6HandleINS0_10HeapObjectEEES6_NS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE23NewExportedSubClassBaseENS0_6HandleINS0_10HeapObjectEEES6_NS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE19NewExportedSubClassENS0_6HandleINS0_10HeapObjectEEES6_iiiNS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE19NewExportedSubClassENS0_6HandleINS0_10HeapObjectEEES6_iiiNS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE20NewExportedSubClass2ENS0_6HandleINS0_10HeapObjectEEES6_iiiNS0_14AllocationTypeE = comdat any

$_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE20NewExportedSubClass2ENS0_6HandleINS0_10HeapObjectEEES6_iiiNS0_14AllocationTypeE = comdat any

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE26NewSloppyArgumentsElementsEiNS0_6HandleINS0_7ContextEEENS4_INS0_10FixedArrayEEENS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory"*, i32, i64*, i64*, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %6 = shl i32 %1, 2
  %7 = add nsw i32 %6, 16
  %8 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::FactoryBase"*
  %9 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 4616
  %10 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"* %8, i32 %7, i8 zeroext %4, i64 %11, i32 0) #2
  %13 = icmp eq i8 %4, 0
  %14 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::Isolate"*
  %15 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45608
  %16 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %15 to %"class.v8::internal::CanonicalHandleScope"**
  %17 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %16, align 8
  %18 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %17, null
  br i1 %18, label %22, label %19

19:                                               ; preds = %5
  %20 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %17, i64 %12) #2
  %21 = load i64, i64* %20, align 8
  br label %37

22:                                               ; preds = %5
  %23 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45584
  %24 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %23 to i64**
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45592
  %27 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %26 to i64**
  %28 = load i64*, i64** %27, align 8
  %29 = icmp eq i64* %25, %28
  br i1 %29, label %30, label %32

30:                                               ; preds = %22
  %31 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %14) #2
  br label %32

32:                                               ; preds = %30, %22
  %33 = phi i64* [ %31, %30 ], [ %25, %22 ]
  %34 = ptrtoint i64* %33 to i64
  %35 = add i64 %34, 8
  %36 = inttoptr i64 %35 to i64*
  store i64* %36, i64** %24, align 8
  store i64 %12, i64* %33, align 8
  br label %37

37:                                               ; preds = %19, %32
  %38 = phi i64 [ %21, %19 ], [ %12, %32 ]
  %39 = phi i64* [ %20, %19 ], [ %33, %32 ]
  %40 = shl i32 %1, 1
  %41 = add i64 %38, 3
  %42 = inttoptr i64 %41 to i32*
  store atomic volatile i32 %40, i32* %42 monotonic, align 4
  %43 = load i64, i64* %39, align 8
  %44 = load i64, i64* %2, align 8
  %45 = add i64 %43, 7
  %46 = inttoptr i64 %45 to i32*
  %47 = trunc i64 %44 to i32
  store atomic volatile i32 %47, i32* %46 monotonic, align 4
  br i1 %13, label %48, label %54

48:                                               ; preds = %37
  %49 = load i64, i64* %39, align 8
  %50 = load i64, i64* %3, align 8
  %51 = add i64 %49, 11
  %52 = inttoptr i64 %51 to i32*
  %53 = trunc i64 %50 to i32
  store atomic volatile i32 %53, i32* %52 monotonic, align 4
  br label %117

54:                                               ; preds = %37
  %55 = and i64 %44, 1
  %56 = icmp eq i64 %55, 0
  br i1 %56, label %68, label %57

57:                                               ; preds = %54
  %58 = and i64 %43, -262144
  %59 = or i64 %58, 8
  %60 = inttoptr i64 %59 to i64*
  %61 = load i64, i64* %60, align 8
  %62 = and i64 %61, 262144
  %63 = icmp eq i64 %62, 0
  br i1 %63, label %68, label %64

64:                                               ; preds = %57
  %65 = or i64 %58, 16
  %66 = inttoptr i64 %65 to %"class.v8::internal::Heap"**
  %67 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %66, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %67, i64 %43, i64 %45, i64 %44) #2
  br label %68

68:                                               ; preds = %64, %57, %54
  %69 = and i64 %44, -262144
  %70 = or i64 %69, 8
  %71 = inttoptr i64 %70 to i64*
  %72 = load i64, i64* %71, align 8
  %73 = and i64 %72, 24
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %83, label %75

75:                                               ; preds = %68
  %76 = and i64 %43, -262144
  %77 = or i64 %76, 8
  %78 = inttoptr i64 %77 to i64*
  %79 = load i64, i64* %78, align 8
  %80 = and i64 %79, 24
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %82, label %83

82:                                               ; preds = %75
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %43, i64 %45, i64 %44) #2
  br label %83

83:                                               ; preds = %82, %75, %68
  %84 = load i64, i64* %39, align 8
  %85 = load i64, i64* %3, align 8
  %86 = add i64 %84, 11
  %87 = inttoptr i64 %86 to i32*
  %88 = trunc i64 %85 to i32
  store atomic volatile i32 %88, i32* %87 monotonic, align 4
  %89 = and i64 %85, 1
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %102, label %91

91:                                               ; preds = %83
  %92 = and i64 %84, -262144
  %93 = or i64 %92, 8
  %94 = inttoptr i64 %93 to i64*
  %95 = load i64, i64* %94, align 8
  %96 = and i64 %95, 262144
  %97 = icmp eq i64 %96, 0
  br i1 %97, label %102, label %98

98:                                               ; preds = %91
  %99 = or i64 %92, 16
  %100 = inttoptr i64 %99 to %"class.v8::internal::Heap"**
  %101 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %100, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %101, i64 %84, i64 %86, i64 %85) #2
  br label %102

102:                                              ; preds = %98, %91, %83
  %103 = and i64 %85, -262144
  %104 = or i64 %103, 8
  %105 = inttoptr i64 %104 to i64*
  %106 = load i64, i64* %105, align 8
  %107 = and i64 %106, 24
  %108 = icmp eq i64 %107, 0
  br i1 %108, label %117, label %109

109:                                              ; preds = %102
  %110 = and i64 %84, -262144
  %111 = or i64 %110, 8
  %112 = inttoptr i64 %111 to i64*
  %113 = load i64, i64* %112, align 8
  %114 = and i64 %113, 24
  %115 = icmp eq i64 %114, 0
  br i1 %115, label %116, label %117

116:                                              ; preds = %109
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %84, i64 %86, i64 %85) #2
  br label %117

117:                                              ; preds = %48, %102, %109, %116
  ret i64* %39
}

declare i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"*, i32, i8 zeroext, i64, i32) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE26NewSloppyArgumentsElementsEiNS0_6HandleINS0_7ContextEEENS4_INS0_10FixedArrayEEENS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory.1056"*, i32, i64*, i64*, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %6 = shl i32 %1, 2
  %7 = add nsw i32 %6, 16
  %8 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to %"class.v8::internal::FactoryBase.1055"*
  %9 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to i64**
  %10 = load i64*, i64** %9, align 8
  %11 = getelementptr inbounds i64, i64* %10, i64 561
  %12 = load i64, i64* %11, align 8
  %13 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"* %8, i32 %7, i8 zeroext %4, i64 %12, i32 0) #2
  %14 = icmp eq i8 %4, 0
  %15 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 16, i32 0
  %16 = load i8, i8* %15, align 8, !range !2
  %17 = icmp eq i8 %16, 0
  br i1 %17, label %23, label %18

18:                                               ; preds = %5
  %19 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 8
  %20 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %19 to %"class.v8::internal::LocalHeap"*
  %21 = tail call i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"* %20, i64 %13) #2
  %22 = load i64, i64* %21, align 8
  br label %39

23:                                               ; preds = %5
  %24 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 48
  %25 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %24 to %"class.v8::internal::LocalHandles"**
  %26 = load %"class.v8::internal::LocalHandles"*, %"class.v8::internal::LocalHandles"** %25, align 8
  %27 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %26, i64 0, i32 0, i32 0
  %28 = load i64*, i64** %27, align 8
  %29 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %26, i64 0, i32 0, i32 1
  %30 = load i64*, i64** %29, align 8
  %31 = icmp eq i64* %28, %30
  br i1 %31, label %32, label %35

32:                                               ; preds = %23
  %33 = tail call i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"* %26) #2
  %34 = load i64*, i64** %27, align 8
  br label %35

35:                                               ; preds = %32, %23
  %36 = phi i64* [ %34, %32 ], [ %28, %23 ]
  %37 = phi i64* [ %33, %32 ], [ %28, %23 ]
  %38 = getelementptr inbounds i64, i64* %36, i64 1
  store i64* %38, i64** %27, align 8
  store i64 %13, i64* %37, align 8
  br label %39

39:                                               ; preds = %18, %35
  %40 = phi i64 [ %22, %18 ], [ %13, %35 ]
  %41 = phi i64* [ %21, %18 ], [ %37, %35 ]
  %42 = shl i32 %1, 1
  %43 = add i64 %40, 3
  %44 = inttoptr i64 %43 to i32*
  store atomic volatile i32 %42, i32* %44 monotonic, align 4
  %45 = load i64, i64* %41, align 8
  %46 = load i64, i64* %2, align 8
  %47 = add i64 %45, 7
  %48 = inttoptr i64 %47 to i32*
  %49 = trunc i64 %46 to i32
  store atomic volatile i32 %49, i32* %48 monotonic, align 4
  br i1 %14, label %50, label %56

50:                                               ; preds = %39
  %51 = load i64, i64* %41, align 8
  %52 = load i64, i64* %3, align 8
  %53 = add i64 %51, 11
  %54 = inttoptr i64 %53 to i32*
  %55 = trunc i64 %52 to i32
  store atomic volatile i32 %55, i32* %54 monotonic, align 4
  br label %119

56:                                               ; preds = %39
  %57 = and i64 %46, 1
  %58 = icmp eq i64 %57, 0
  br i1 %58, label %70, label %59

59:                                               ; preds = %56
  %60 = and i64 %45, -262144
  %61 = or i64 %60, 8
  %62 = inttoptr i64 %61 to i64*
  %63 = load i64, i64* %62, align 8
  %64 = and i64 %63, 262144
  %65 = icmp eq i64 %64, 0
  br i1 %65, label %70, label %66

66:                                               ; preds = %59
  %67 = or i64 %60, 16
  %68 = inttoptr i64 %67 to %"class.v8::internal::Heap"**
  %69 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %68, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %69, i64 %45, i64 %47, i64 %46) #2
  br label %70

70:                                               ; preds = %66, %59, %56
  %71 = and i64 %46, -262144
  %72 = or i64 %71, 8
  %73 = inttoptr i64 %72 to i64*
  %74 = load i64, i64* %73, align 8
  %75 = and i64 %74, 24
  %76 = icmp eq i64 %75, 0
  br i1 %76, label %85, label %77

77:                                               ; preds = %70
  %78 = and i64 %45, -262144
  %79 = or i64 %78, 8
  %80 = inttoptr i64 %79 to i64*
  %81 = load i64, i64* %80, align 8
  %82 = and i64 %81, 24
  %83 = icmp eq i64 %82, 0
  br i1 %83, label %84, label %85

84:                                               ; preds = %77
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %45, i64 %47, i64 %46) #2
  br label %85

85:                                               ; preds = %84, %77, %70
  %86 = load i64, i64* %41, align 8
  %87 = load i64, i64* %3, align 8
  %88 = add i64 %86, 11
  %89 = inttoptr i64 %88 to i32*
  %90 = trunc i64 %87 to i32
  store atomic volatile i32 %90, i32* %89 monotonic, align 4
  %91 = and i64 %87, 1
  %92 = icmp eq i64 %91, 0
  br i1 %92, label %104, label %93

93:                                               ; preds = %85
  %94 = and i64 %86, -262144
  %95 = or i64 %94, 8
  %96 = inttoptr i64 %95 to i64*
  %97 = load i64, i64* %96, align 8
  %98 = and i64 %97, 262144
  %99 = icmp eq i64 %98, 0
  br i1 %99, label %104, label %100

100:                                              ; preds = %93
  %101 = or i64 %94, 16
  %102 = inttoptr i64 %101 to %"class.v8::internal::Heap"**
  %103 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %102, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %103, i64 %86, i64 %88, i64 %87) #2
  br label %104

104:                                              ; preds = %100, %93, %85
  %105 = and i64 %87, -262144
  %106 = or i64 %105, 8
  %107 = inttoptr i64 %106 to i64*
  %108 = load i64, i64* %107, align 8
  %109 = and i64 %108, 24
  %110 = icmp eq i64 %109, 0
  br i1 %110, label %119, label %111

111:                                              ; preds = %104
  %112 = and i64 %86, -262144
  %113 = or i64 %112, 8
  %114 = inttoptr i64 %113 to i64*
  %115 = load i64, i64* %114, align 8
  %116 = and i64 %115, 24
  %117 = icmp eq i64 %116, 0
  br i1 %117, label %118, label %119

118:                                              ; preds = %111
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %86, i64 %88, i64 %87) #2
  br label %119

119:                                              ; preds = %50, %104, %111, %118
  ret i64* %41
}

declare i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"*, i32, i8 zeroext, i64, i32) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE18NewDescriptorArrayEttttNS0_6HandleINS0_9EnumCacheEEENS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory"*, i16 zeroext, i16 zeroext, i16 zeroext, i16 zeroext, i64*, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %8 = zext i16 %1 to i32
  %9 = mul nuw nsw i32 %8, 12
  %10 = add nuw nsw i32 %9, 16
  %11 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::FactoryBase"*
  %12 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 4624
  %13 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %12 to i64*
  %14 = load i64, i64* %13, align 8
  %15 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"* %11, i32 %10, i8 zeroext %6, i64 %14, i32 0) #2
  %16 = icmp eq i8 %6, 0
  %17 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::Isolate"*
  %18 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45608
  %19 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %18 to %"class.v8::internal::CanonicalHandleScope"**
  %20 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %19, align 8
  %21 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %20, null
  br i1 %21, label %25, label %22

22:                                               ; preds = %7
  %23 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %20, i64 %15) #2
  %24 = load i64, i64* %23, align 8
  br label %40

25:                                               ; preds = %7
  %26 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45584
  %27 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %26 to i64**
  %28 = load i64*, i64** %27, align 8
  %29 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45592
  %30 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %29 to i64**
  %31 = load i64*, i64** %30, align 8
  %32 = icmp eq i64* %28, %31
  br i1 %32, label %33, label %35

33:                                               ; preds = %25
  %34 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %17) #2
  br label %35

35:                                               ; preds = %33, %25
  %36 = phi i64* [ %34, %33 ], [ %28, %25 ]
  %37 = ptrtoint i64* %36 to i64
  %38 = add i64 %37, 8
  %39 = inttoptr i64 %38 to i64*
  store i64* %39, i64** %27, align 8
  store i64 %15, i64* %36, align 8
  br label %40

40:                                               ; preds = %22, %35
  %41 = phi i64 [ %24, %22 ], [ %15, %35 ]
  %42 = phi i64* [ %23, %22 ], [ %36, %35 ]
  %43 = add i64 %41, 3
  %44 = inttoptr i64 %43 to i16*
  store i16 %1, i16* %44, align 2
  %45 = load i64, i64* %42, align 8
  %46 = add i64 %45, 5
  %47 = inttoptr i64 %46 to i16*
  store i16 %2, i16* %47, align 2
  %48 = load i64, i64* %42, align 8
  %49 = add i64 %48, 7
  %50 = inttoptr i64 %49 to i16*
  store i16 %3, i16* %50, align 2
  %51 = load i64, i64* %42, align 8
  %52 = add i64 %51, 9
  %53 = inttoptr i64 %52 to i16*
  store i16 %4, i16* %53, align 2
  %54 = load i64, i64* %42, align 8
  %55 = load i64, i64* %5, align 8
  %56 = add i64 %54, 11
  %57 = inttoptr i64 %56 to i32*
  %58 = trunc i64 %55 to i32
  store atomic volatile i32 %58, i32* %57 monotonic, align 4
  br i1 %16, label %88, label %59

59:                                               ; preds = %40
  %60 = and i64 %55, 1
  %61 = icmp eq i64 %60, 0
  br i1 %61, label %73, label %62

62:                                               ; preds = %59
  %63 = and i64 %54, -262144
  %64 = or i64 %63, 8
  %65 = inttoptr i64 %64 to i64*
  %66 = load i64, i64* %65, align 8
  %67 = and i64 %66, 262144
  %68 = icmp eq i64 %67, 0
  br i1 %68, label %73, label %69

69:                                               ; preds = %62
  %70 = or i64 %63, 16
  %71 = inttoptr i64 %70 to %"class.v8::internal::Heap"**
  %72 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %71, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %72, i64 %54, i64 %56, i64 %55) #2
  br label %73

73:                                               ; preds = %69, %62, %59
  %74 = and i64 %55, -262144
  %75 = or i64 %74, 8
  %76 = inttoptr i64 %75 to i64*
  %77 = load i64, i64* %76, align 8
  %78 = and i64 %77, 24
  %79 = icmp eq i64 %78, 0
  br i1 %79, label %88, label %80

80:                                               ; preds = %73
  %81 = and i64 %54, -262144
  %82 = or i64 %81, 8
  %83 = inttoptr i64 %82 to i64*
  %84 = load i64, i64* %83, align 8
  %85 = and i64 %84, 24
  %86 = icmp eq i64 %85, 0
  br i1 %86, label %87, label %88

87:                                               ; preds = %80
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %54, i64 %56, i64 %55) #2
  br label %88

88:                                               ; preds = %40, %73, %80, %87
  ret i64* %42
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE18NewDescriptorArrayEttttNS0_6HandleINS0_9EnumCacheEEENS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory.1056"*, i16 zeroext, i16 zeroext, i16 zeroext, i16 zeroext, i64*, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %8 = zext i16 %1 to i32
  %9 = mul nuw nsw i32 %8, 12
  %10 = add nuw nsw i32 %9, 16
  %11 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to %"class.v8::internal::FactoryBase.1055"*
  %12 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to i64**
  %13 = load i64*, i64** %12, align 8
  %14 = getelementptr inbounds i64, i64* %13, i64 562
  %15 = load i64, i64* %14, align 8
  %16 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"* %11, i32 %10, i8 zeroext %6, i64 %15, i32 0) #2
  %17 = icmp eq i8 %6, 0
  %18 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 16, i32 0
  %19 = load i8, i8* %18, align 8, !range !2
  %20 = icmp eq i8 %19, 0
  br i1 %20, label %26, label %21

21:                                               ; preds = %7
  %22 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 8
  %23 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %22 to %"class.v8::internal::LocalHeap"*
  %24 = tail call i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"* %23, i64 %16) #2
  %25 = load i64, i64* %24, align 8
  br label %42

26:                                               ; preds = %7
  %27 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 48
  %28 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %27 to %"class.v8::internal::LocalHandles"**
  %29 = load %"class.v8::internal::LocalHandles"*, %"class.v8::internal::LocalHandles"** %28, align 8
  %30 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %29, i64 0, i32 0, i32 0
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %29, i64 0, i32 0, i32 1
  %33 = load i64*, i64** %32, align 8
  %34 = icmp eq i64* %31, %33
  br i1 %34, label %35, label %38

35:                                               ; preds = %26
  %36 = tail call i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"* %29) #2
  %37 = load i64*, i64** %30, align 8
  br label %38

38:                                               ; preds = %35, %26
  %39 = phi i64* [ %37, %35 ], [ %31, %26 ]
  %40 = phi i64* [ %36, %35 ], [ %31, %26 ]
  %41 = getelementptr inbounds i64, i64* %39, i64 1
  store i64* %41, i64** %30, align 8
  store i64 %16, i64* %40, align 8
  br label %42

42:                                               ; preds = %21, %38
  %43 = phi i64 [ %25, %21 ], [ %16, %38 ]
  %44 = phi i64* [ %24, %21 ], [ %40, %38 ]
  %45 = add i64 %43, 3
  %46 = inttoptr i64 %45 to i16*
  store i16 %1, i16* %46, align 2
  %47 = load i64, i64* %44, align 8
  %48 = add i64 %47, 5
  %49 = inttoptr i64 %48 to i16*
  store i16 %2, i16* %49, align 2
  %50 = load i64, i64* %44, align 8
  %51 = add i64 %50, 7
  %52 = inttoptr i64 %51 to i16*
  store i16 %3, i16* %52, align 2
  %53 = load i64, i64* %44, align 8
  %54 = add i64 %53, 9
  %55 = inttoptr i64 %54 to i16*
  store i16 %4, i16* %55, align 2
  %56 = load i64, i64* %44, align 8
  %57 = load i64, i64* %5, align 8
  %58 = add i64 %56, 11
  %59 = inttoptr i64 %58 to i32*
  %60 = trunc i64 %57 to i32
  store atomic volatile i32 %60, i32* %59 monotonic, align 4
  br i1 %17, label %90, label %61

61:                                               ; preds = %42
  %62 = and i64 %57, 1
  %63 = icmp eq i64 %62, 0
  br i1 %63, label %75, label %64

64:                                               ; preds = %61
  %65 = and i64 %56, -262144
  %66 = or i64 %65, 8
  %67 = inttoptr i64 %66 to i64*
  %68 = load i64, i64* %67, align 8
  %69 = and i64 %68, 262144
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %75, label %71

71:                                               ; preds = %64
  %72 = or i64 %65, 16
  %73 = inttoptr i64 %72 to %"class.v8::internal::Heap"**
  %74 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %73, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %74, i64 %56, i64 %58, i64 %57) #2
  br label %75

75:                                               ; preds = %71, %64, %61
  %76 = and i64 %57, -262144
  %77 = or i64 %76, 8
  %78 = inttoptr i64 %77 to i64*
  %79 = load i64, i64* %78, align 8
  %80 = and i64 %79, 24
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %90, label %82

82:                                               ; preds = %75
  %83 = and i64 %56, -262144
  %84 = or i64 %83, 8
  %85 = inttoptr i64 %84 to i64*
  %86 = load i64, i64* %85, align 8
  %87 = and i64 %86, 24
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %89, label %90

89:                                               ; preds = %82
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %56, i64 %58, i64 %57) #2
  br label %90

90:                                               ; preds = %42, %75, %82, %89
  ret i64* %44
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE36NewUncompiledDataWithoutPreparseDataENS0_6HandleINS0_6StringEEEiiNS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory"*, i64*, i32, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %6 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::FactoryBase"*
  %7 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 4640
  %8 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %7 to i64*
  %9 = load i64, i64* %8, align 8
  %10 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"* %6, i32 16, i8 zeroext %4, i64 %9, i32 0) #2
  %11 = icmp eq i8 %4, 0
  %12 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::Isolate"*
  %13 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45608
  %14 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %13 to %"class.v8::internal::CanonicalHandleScope"**
  %15 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %14, align 8
  %16 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %15, null
  br i1 %16, label %20, label %17

17:                                               ; preds = %5
  %18 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %15, i64 %10) #2
  %19 = load i64, i64* %18, align 8
  br label %35

20:                                               ; preds = %5
  %21 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45584
  %22 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %21 to i64**
  %23 = load i64*, i64** %22, align 8
  %24 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45592
  %25 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %24 to i64**
  %26 = load i64*, i64** %25, align 8
  %27 = icmp eq i64* %23, %26
  br i1 %27, label %28, label %30

28:                                               ; preds = %20
  %29 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %12) #2
  br label %30

30:                                               ; preds = %28, %20
  %31 = phi i64* [ %29, %28 ], [ %23, %20 ]
  %32 = ptrtoint i64* %31 to i64
  %33 = add i64 %32, 8
  %34 = inttoptr i64 %33 to i64*
  store i64* %34, i64** %22, align 8
  store i64 %10, i64* %31, align 8
  br label %35

35:                                               ; preds = %17, %30
  %36 = phi i64 [ %19, %17 ], [ %10, %30 ]
  %37 = phi i64* [ %18, %17 ], [ %31, %30 ]
  %38 = load i64, i64* %1, align 8
  %39 = add i64 %36, 3
  %40 = inttoptr i64 %39 to i32*
  %41 = trunc i64 %38 to i32
  store atomic volatile i32 %41, i32* %40 monotonic, align 4
  br i1 %11, label %71, label %42

42:                                               ; preds = %35
  %43 = and i64 %38, 1
  %44 = icmp eq i64 %43, 0
  br i1 %44, label %56, label %45

45:                                               ; preds = %42
  %46 = and i64 %36, -262144
  %47 = or i64 %46, 8
  %48 = inttoptr i64 %47 to i64*
  %49 = load i64, i64* %48, align 8
  %50 = and i64 %49, 262144
  %51 = icmp eq i64 %50, 0
  br i1 %51, label %56, label %52

52:                                               ; preds = %45
  %53 = or i64 %46, 16
  %54 = inttoptr i64 %53 to %"class.v8::internal::Heap"**
  %55 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %54, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %55, i64 %36, i64 %39, i64 %38) #2
  br label %56

56:                                               ; preds = %52, %45, %42
  %57 = and i64 %38, -262144
  %58 = or i64 %57, 8
  %59 = inttoptr i64 %58 to i64*
  %60 = load i64, i64* %59, align 8
  %61 = and i64 %60, 24
  %62 = icmp eq i64 %61, 0
  br i1 %62, label %71, label %63

63:                                               ; preds = %56
  %64 = and i64 %36, -262144
  %65 = or i64 %64, 8
  %66 = inttoptr i64 %65 to i64*
  %67 = load i64, i64* %66, align 8
  %68 = and i64 %67, 24
  %69 = icmp eq i64 %68, 0
  br i1 %69, label %70, label %71

70:                                               ; preds = %63
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %36, i64 %39, i64 %38) #2
  br label %71

71:                                               ; preds = %35, %56, %63, %70
  %72 = load i64, i64* %37, align 8
  %73 = add i64 %72, 7
  %74 = inttoptr i64 %73 to i32*
  store i32 %2, i32* %74, align 4
  %75 = load i64, i64* %37, align 8
  %76 = add i64 %75, 11
  %77 = inttoptr i64 %76 to i32*
  store i32 %3, i32* %77, align 4
  ret i64* %37
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE36NewUncompiledDataWithoutPreparseDataENS0_6HandleINS0_6StringEEEiiNS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory.1056"*, i64*, i32, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %6 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to %"class.v8::internal::FactoryBase.1055"*
  %7 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to i64**
  %8 = load i64*, i64** %7, align 8
  %9 = getelementptr inbounds i64, i64* %8, i64 564
  %10 = load i64, i64* %9, align 8
  %11 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"* %6, i32 16, i8 zeroext %4, i64 %10, i32 0) #2
  %12 = icmp eq i8 %4, 0
  %13 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 16, i32 0
  %14 = load i8, i8* %13, align 8, !range !2
  %15 = icmp eq i8 %14, 0
  br i1 %15, label %21, label %16

16:                                               ; preds = %5
  %17 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 8
  %18 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %17 to %"class.v8::internal::LocalHeap"*
  %19 = tail call i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"* %18, i64 %11) #2
  %20 = load i64, i64* %19, align 8
  br label %37

21:                                               ; preds = %5
  %22 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 48
  %23 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %22 to %"class.v8::internal::LocalHandles"**
  %24 = load %"class.v8::internal::LocalHandles"*, %"class.v8::internal::LocalHandles"** %23, align 8
  %25 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %24, i64 0, i32 0, i32 0
  %26 = load i64*, i64** %25, align 8
  %27 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %24, i64 0, i32 0, i32 1
  %28 = load i64*, i64** %27, align 8
  %29 = icmp eq i64* %26, %28
  br i1 %29, label %30, label %33

30:                                               ; preds = %21
  %31 = tail call i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"* %24) #2
  %32 = load i64*, i64** %25, align 8
  br label %33

33:                                               ; preds = %30, %21
  %34 = phi i64* [ %32, %30 ], [ %26, %21 ]
  %35 = phi i64* [ %31, %30 ], [ %26, %21 ]
  %36 = getelementptr inbounds i64, i64* %34, i64 1
  store i64* %36, i64** %25, align 8
  store i64 %11, i64* %35, align 8
  br label %37

37:                                               ; preds = %16, %33
  %38 = phi i64 [ %20, %16 ], [ %11, %33 ]
  %39 = phi i64* [ %19, %16 ], [ %35, %33 ]
  %40 = load i64, i64* %1, align 8
  %41 = add i64 %38, 3
  %42 = inttoptr i64 %41 to i32*
  %43 = trunc i64 %40 to i32
  store atomic volatile i32 %43, i32* %42 monotonic, align 4
  br i1 %12, label %73, label %44

44:                                               ; preds = %37
  %45 = and i64 %40, 1
  %46 = icmp eq i64 %45, 0
  br i1 %46, label %58, label %47

47:                                               ; preds = %44
  %48 = and i64 %38, -262144
  %49 = or i64 %48, 8
  %50 = inttoptr i64 %49 to i64*
  %51 = load i64, i64* %50, align 8
  %52 = and i64 %51, 262144
  %53 = icmp eq i64 %52, 0
  br i1 %53, label %58, label %54

54:                                               ; preds = %47
  %55 = or i64 %48, 16
  %56 = inttoptr i64 %55 to %"class.v8::internal::Heap"**
  %57 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %56, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %57, i64 %38, i64 %41, i64 %40) #2
  br label %58

58:                                               ; preds = %54, %47, %44
  %59 = and i64 %40, -262144
  %60 = or i64 %59, 8
  %61 = inttoptr i64 %60 to i64*
  %62 = load i64, i64* %61, align 8
  %63 = and i64 %62, 24
  %64 = icmp eq i64 %63, 0
  br i1 %64, label %73, label %65

65:                                               ; preds = %58
  %66 = and i64 %38, -262144
  %67 = or i64 %66, 8
  %68 = inttoptr i64 %67 to i64*
  %69 = load i64, i64* %68, align 8
  %70 = and i64 %69, 24
  %71 = icmp eq i64 %70, 0
  br i1 %71, label %72, label %73

72:                                               ; preds = %65
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %38, i64 %41, i64 %40) #2
  br label %73

73:                                               ; preds = %37, %58, %65, %72
  %74 = load i64, i64* %39, align 8
  %75 = add i64 %74, 7
  %76 = inttoptr i64 %75 to i32*
  store i32 %2, i32* %76, align 4
  %77 = load i64, i64* %39, align 8
  %78 = add i64 %77, 11
  %79 = inttoptr i64 %78 to i32*
  store i32 %3, i32* %79, align 4
  ret i64* %39
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE33NewUncompiledDataWithPreparseDataENS0_6HandleINS0_6StringEEEiiNS4_INS0_12PreparseDataEEENS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory"*, i64*, i32, i32, i64*, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %7 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::FactoryBase"*
  %8 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 4648
  %9 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"* %7, i32 20, i8 zeroext %5, i64 %10, i32 0) #2
  %12 = icmp eq i8 %5, 0
  %13 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::Isolate"*
  %14 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45608
  %15 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %14 to %"class.v8::internal::CanonicalHandleScope"**
  %16 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %15, align 8
  %17 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %16, null
  br i1 %17, label %21, label %18

18:                                               ; preds = %6
  %19 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %16, i64 %11) #2
  %20 = load i64, i64* %19, align 8
  br label %36

21:                                               ; preds = %6
  %22 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45584
  %23 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %22 to i64**
  %24 = load i64*, i64** %23, align 8
  %25 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45592
  %26 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %25 to i64**
  %27 = load i64*, i64** %26, align 8
  %28 = icmp eq i64* %24, %27
  br i1 %28, label %29, label %31

29:                                               ; preds = %21
  %30 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %13) #2
  br label %31

31:                                               ; preds = %29, %21
  %32 = phi i64* [ %30, %29 ], [ %24, %21 ]
  %33 = ptrtoint i64* %32 to i64
  %34 = add i64 %33, 8
  %35 = inttoptr i64 %34 to i64*
  store i64* %35, i64** %23, align 8
  store i64 %11, i64* %32, align 8
  br label %36

36:                                               ; preds = %18, %31
  %37 = phi i64 [ %20, %18 ], [ %11, %31 ]
  %38 = phi i64* [ %19, %18 ], [ %32, %31 ]
  %39 = load i64, i64* %1, align 8
  %40 = add i64 %37, 3
  %41 = inttoptr i64 %40 to i32*
  %42 = trunc i64 %39 to i32
  store atomic volatile i32 %42, i32* %41 monotonic, align 4
  br i1 %12, label %72, label %43

43:                                               ; preds = %36
  %44 = and i64 %39, 1
  %45 = icmp eq i64 %44, 0
  br i1 %45, label %57, label %46

46:                                               ; preds = %43
  %47 = and i64 %37, -262144
  %48 = or i64 %47, 8
  %49 = inttoptr i64 %48 to i64*
  %50 = load i64, i64* %49, align 8
  %51 = and i64 %50, 262144
  %52 = icmp eq i64 %51, 0
  br i1 %52, label %57, label %53

53:                                               ; preds = %46
  %54 = or i64 %47, 16
  %55 = inttoptr i64 %54 to %"class.v8::internal::Heap"**
  %56 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %55, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %56, i64 %37, i64 %40, i64 %39) #2
  br label %57

57:                                               ; preds = %53, %46, %43
  %58 = and i64 %39, -262144
  %59 = or i64 %58, 8
  %60 = inttoptr i64 %59 to i64*
  %61 = load i64, i64* %60, align 8
  %62 = and i64 %61, 24
  %63 = icmp eq i64 %62, 0
  br i1 %63, label %72, label %64

64:                                               ; preds = %57
  %65 = and i64 %37, -262144
  %66 = or i64 %65, 8
  %67 = inttoptr i64 %66 to i64*
  %68 = load i64, i64* %67, align 8
  %69 = and i64 %68, 24
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %71, label %72

71:                                               ; preds = %64
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %37, i64 %40, i64 %39) #2
  br label %72

72:                                               ; preds = %36, %57, %64, %71
  %73 = load i64, i64* %38, align 8
  %74 = add i64 %73, 7
  %75 = inttoptr i64 %74 to i32*
  store i32 %2, i32* %75, align 4
  %76 = load i64, i64* %38, align 8
  %77 = add i64 %76, 11
  %78 = inttoptr i64 %77 to i32*
  store i32 %3, i32* %78, align 4
  %79 = load i64, i64* %38, align 8
  %80 = load i64, i64* %4, align 8
  %81 = add i64 %79, 15
  %82 = inttoptr i64 %81 to i32*
  %83 = trunc i64 %80 to i32
  store atomic volatile i32 %83, i32* %82 monotonic, align 4
  br i1 %12, label %113, label %84

84:                                               ; preds = %72
  %85 = and i64 %80, 1
  %86 = icmp eq i64 %85, 0
  br i1 %86, label %98, label %87

87:                                               ; preds = %84
  %88 = and i64 %79, -262144
  %89 = or i64 %88, 8
  %90 = inttoptr i64 %89 to i64*
  %91 = load i64, i64* %90, align 8
  %92 = and i64 %91, 262144
  %93 = icmp eq i64 %92, 0
  br i1 %93, label %98, label %94

94:                                               ; preds = %87
  %95 = or i64 %88, 16
  %96 = inttoptr i64 %95 to %"class.v8::internal::Heap"**
  %97 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %96, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %97, i64 %79, i64 %81, i64 %80) #2
  br label %98

98:                                               ; preds = %94, %87, %84
  %99 = and i64 %80, -262144
  %100 = or i64 %99, 8
  %101 = inttoptr i64 %100 to i64*
  %102 = load i64, i64* %101, align 8
  %103 = and i64 %102, 24
  %104 = icmp eq i64 %103, 0
  br i1 %104, label %113, label %105

105:                                              ; preds = %98
  %106 = and i64 %79, -262144
  %107 = or i64 %106, 8
  %108 = inttoptr i64 %107 to i64*
  %109 = load i64, i64* %108, align 8
  %110 = and i64 %109, 24
  %111 = icmp eq i64 %110, 0
  br i1 %111, label %112, label %113

112:                                              ; preds = %105
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %79, i64 %81, i64 %80) #2
  br label %113

113:                                              ; preds = %72, %98, %105, %112
  ret i64* %38
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE33NewUncompiledDataWithPreparseDataENS0_6HandleINS0_6StringEEEiiNS4_INS0_12PreparseDataEEENS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory.1056"*, i64*, i32, i32, i64*, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %7 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to %"class.v8::internal::FactoryBase.1055"*
  %8 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to i64**
  %9 = load i64*, i64** %8, align 8
  %10 = getelementptr inbounds i64, i64* %9, i64 565
  %11 = load i64, i64* %10, align 8
  %12 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"* %7, i32 20, i8 zeroext %5, i64 %11, i32 0) #2
  %13 = icmp eq i8 %5, 0
  %14 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 16, i32 0
  %15 = load i8, i8* %14, align 8, !range !2
  %16 = icmp eq i8 %15, 0
  br i1 %16, label %22, label %17

17:                                               ; preds = %6
  %18 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 8
  %19 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %18 to %"class.v8::internal::LocalHeap"*
  %20 = tail call i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"* %19, i64 %12) #2
  %21 = load i64, i64* %20, align 8
  br label %38

22:                                               ; preds = %6
  %23 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 48
  %24 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %23 to %"class.v8::internal::LocalHandles"**
  %25 = load %"class.v8::internal::LocalHandles"*, %"class.v8::internal::LocalHandles"** %24, align 8
  %26 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %25, i64 0, i32 0, i32 0
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %25, i64 0, i32 0, i32 1
  %29 = load i64*, i64** %28, align 8
  %30 = icmp eq i64* %27, %29
  br i1 %30, label %31, label %34

31:                                               ; preds = %22
  %32 = tail call i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"* %25) #2
  %33 = load i64*, i64** %26, align 8
  br label %34

34:                                               ; preds = %31, %22
  %35 = phi i64* [ %33, %31 ], [ %27, %22 ]
  %36 = phi i64* [ %32, %31 ], [ %27, %22 ]
  %37 = getelementptr inbounds i64, i64* %35, i64 1
  store i64* %37, i64** %26, align 8
  store i64 %12, i64* %36, align 8
  br label %38

38:                                               ; preds = %17, %34
  %39 = phi i64 [ %21, %17 ], [ %12, %34 ]
  %40 = phi i64* [ %20, %17 ], [ %36, %34 ]
  %41 = load i64, i64* %1, align 8
  %42 = add i64 %39, 3
  %43 = inttoptr i64 %42 to i32*
  %44 = trunc i64 %41 to i32
  store atomic volatile i32 %44, i32* %43 monotonic, align 4
  br i1 %13, label %74, label %45

45:                                               ; preds = %38
  %46 = and i64 %41, 1
  %47 = icmp eq i64 %46, 0
  br i1 %47, label %59, label %48

48:                                               ; preds = %45
  %49 = and i64 %39, -262144
  %50 = or i64 %49, 8
  %51 = inttoptr i64 %50 to i64*
  %52 = load i64, i64* %51, align 8
  %53 = and i64 %52, 262144
  %54 = icmp eq i64 %53, 0
  br i1 %54, label %59, label %55

55:                                               ; preds = %48
  %56 = or i64 %49, 16
  %57 = inttoptr i64 %56 to %"class.v8::internal::Heap"**
  %58 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %57, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %58, i64 %39, i64 %42, i64 %41) #2
  br label %59

59:                                               ; preds = %55, %48, %45
  %60 = and i64 %41, -262144
  %61 = or i64 %60, 8
  %62 = inttoptr i64 %61 to i64*
  %63 = load i64, i64* %62, align 8
  %64 = and i64 %63, 24
  %65 = icmp eq i64 %64, 0
  br i1 %65, label %74, label %66

66:                                               ; preds = %59
  %67 = and i64 %39, -262144
  %68 = or i64 %67, 8
  %69 = inttoptr i64 %68 to i64*
  %70 = load i64, i64* %69, align 8
  %71 = and i64 %70, 24
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %73, label %74

73:                                               ; preds = %66
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %39, i64 %42, i64 %41) #2
  br label %74

74:                                               ; preds = %38, %59, %66, %73
  %75 = load i64, i64* %40, align 8
  %76 = add i64 %75, 7
  %77 = inttoptr i64 %76 to i32*
  store i32 %2, i32* %77, align 4
  %78 = load i64, i64* %40, align 8
  %79 = add i64 %78, 11
  %80 = inttoptr i64 %79 to i32*
  store i32 %3, i32* %80, align 4
  %81 = load i64, i64* %40, align 8
  %82 = load i64, i64* %4, align 8
  %83 = add i64 %81, 15
  %84 = inttoptr i64 %83 to i32*
  %85 = trunc i64 %82 to i32
  store atomic volatile i32 %85, i32* %84 monotonic, align 4
  br i1 %13, label %115, label %86

86:                                               ; preds = %74
  %87 = and i64 %82, 1
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %100, label %89

89:                                               ; preds = %86
  %90 = and i64 %81, -262144
  %91 = or i64 %90, 8
  %92 = inttoptr i64 %91 to i64*
  %93 = load i64, i64* %92, align 8
  %94 = and i64 %93, 262144
  %95 = icmp eq i64 %94, 0
  br i1 %95, label %100, label %96

96:                                               ; preds = %89
  %97 = or i64 %90, 16
  %98 = inttoptr i64 %97 to %"class.v8::internal::Heap"**
  %99 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %98, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %99, i64 %81, i64 %83, i64 %82) #2
  br label %100

100:                                              ; preds = %96, %89, %86
  %101 = and i64 %82, -262144
  %102 = or i64 %101, 8
  %103 = inttoptr i64 %102 to i64*
  %104 = load i64, i64* %103, align 8
  %105 = and i64 %104, 24
  %106 = icmp eq i64 %105, 0
  br i1 %106, label %115, label %107

107:                                              ; preds = %100
  %108 = and i64 %81, -262144
  %109 = or i64 %108, 8
  %110 = inttoptr i64 %109 to i64*
  %111 = load i64, i64* %110, align 8
  %112 = and i64 %111, 24
  %113 = icmp eq i64 %112, 0
  br i1 %113, label %114, label %115

114:                                              ; preds = %107
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %81, i64 %83, i64 %82) #2
  br label %115

115:                                              ; preds = %74, %100, %107, %114
  ret i64* %40
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE31NewOnHeapBasicBlockProfilerDataENS0_6HandleINS0_9ByteArrayEEES6_NS4_INS0_6StringEEES8_S8_iNS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory"*, i64*, i64*, i64*, i64*, i64*, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %9 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::FactoryBase"*
  %10 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 4656
  %11 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %10 to i64*
  %12 = load i64, i64* %11, align 8
  %13 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"* %9, i32 28, i8 zeroext %7, i64 %12, i32 0) #2
  %14 = icmp eq i8 %7, 0
  %15 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::Isolate"*
  %16 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45608
  %17 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %16 to %"class.v8::internal::CanonicalHandleScope"**
  %18 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %17, align 8
  %19 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %18, null
  br i1 %19, label %23, label %20

20:                                               ; preds = %8
  %21 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %18, i64 %13) #2
  %22 = load i64, i64* %21, align 8
  br label %38

23:                                               ; preds = %8
  %24 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45584
  %25 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %24 to i64**
  %26 = load i64*, i64** %25, align 8
  %27 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45592
  %28 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %27 to i64**
  %29 = load i64*, i64** %28, align 8
  %30 = icmp eq i64* %26, %29
  br i1 %30, label %31, label %33

31:                                               ; preds = %23
  %32 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %15) #2
  br label %33

33:                                               ; preds = %31, %23
  %34 = phi i64* [ %32, %31 ], [ %26, %23 ]
  %35 = ptrtoint i64* %34 to i64
  %36 = add i64 %35, 8
  %37 = inttoptr i64 %36 to i64*
  store i64* %37, i64** %25, align 8
  store i64 %13, i64* %34, align 8
  br label %38

38:                                               ; preds = %20, %33
  %39 = phi i64 [ %22, %20 ], [ %13, %33 ]
  %40 = phi i64* [ %21, %20 ], [ %34, %33 ]
  %41 = load i64, i64* %1, align 8
  %42 = add i64 %39, 3
  %43 = inttoptr i64 %42 to i32*
  %44 = trunc i64 %41 to i32
  store atomic volatile i32 %44, i32* %43 monotonic, align 4
  br i1 %14, label %176, label %45

45:                                               ; preds = %38
  %46 = and i64 %41, 1
  %47 = icmp eq i64 %46, 0
  br i1 %47, label %59, label %48

48:                                               ; preds = %45
  %49 = and i64 %39, -262144
  %50 = or i64 %49, 8
  %51 = inttoptr i64 %50 to i64*
  %52 = load i64, i64* %51, align 8
  %53 = and i64 %52, 262144
  %54 = icmp eq i64 %53, 0
  br i1 %54, label %59, label %55

55:                                               ; preds = %48
  %56 = or i64 %49, 16
  %57 = inttoptr i64 %56 to %"class.v8::internal::Heap"**
  %58 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %57, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %58, i64 %39, i64 %42, i64 %41) #2
  br label %59

59:                                               ; preds = %55, %48, %45
  %60 = and i64 %41, -262144
  %61 = or i64 %60, 8
  %62 = inttoptr i64 %61 to i64*
  %63 = load i64, i64* %62, align 8
  %64 = and i64 %63, 24
  %65 = icmp eq i64 %64, 0
  br i1 %65, label %74, label %66

66:                                               ; preds = %59
  %67 = and i64 %39, -262144
  %68 = or i64 %67, 8
  %69 = inttoptr i64 %68 to i64*
  %70 = load i64, i64* %69, align 8
  %71 = and i64 %70, 24
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %73, label %74

73:                                               ; preds = %66
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %39, i64 %42, i64 %41) #2
  br label %74

74:                                               ; preds = %73, %66, %59
  %75 = load i64, i64* %40, align 8
  %76 = load i64, i64* %2, align 8
  %77 = add i64 %75, 7
  %78 = inttoptr i64 %77 to i32*
  %79 = trunc i64 %76 to i32
  store atomic volatile i32 %79, i32* %78 monotonic, align 4
  %80 = and i64 %76, 1
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %93, label %82

82:                                               ; preds = %74
  %83 = and i64 %75, -262144
  %84 = or i64 %83, 8
  %85 = inttoptr i64 %84 to i64*
  %86 = load i64, i64* %85, align 8
  %87 = and i64 %86, 262144
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %93, label %89

89:                                               ; preds = %82
  %90 = or i64 %83, 16
  %91 = inttoptr i64 %90 to %"class.v8::internal::Heap"**
  %92 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %91, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %92, i64 %75, i64 %77, i64 %76) #2
  br label %93

93:                                               ; preds = %89, %82, %74
  %94 = and i64 %76, -262144
  %95 = or i64 %94, 8
  %96 = inttoptr i64 %95 to i64*
  %97 = load i64, i64* %96, align 8
  %98 = and i64 %97, 24
  %99 = icmp eq i64 %98, 0
  br i1 %99, label %108, label %100

100:                                              ; preds = %93
  %101 = and i64 %75, -262144
  %102 = or i64 %101, 8
  %103 = inttoptr i64 %102 to i64*
  %104 = load i64, i64* %103, align 8
  %105 = and i64 %104, 24
  %106 = icmp eq i64 %105, 0
  br i1 %106, label %107, label %108

107:                                              ; preds = %100
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %75, i64 %77, i64 %76) #2
  br label %108

108:                                              ; preds = %107, %100, %93
  %109 = load i64, i64* %40, align 8
  %110 = load i64, i64* %3, align 8
  %111 = add i64 %109, 11
  %112 = inttoptr i64 %111 to i32*
  %113 = trunc i64 %110 to i32
  store atomic volatile i32 %113, i32* %112 monotonic, align 4
  %114 = and i64 %110, 1
  %115 = icmp eq i64 %114, 0
  br i1 %115, label %127, label %116

116:                                              ; preds = %108
  %117 = and i64 %109, -262144
  %118 = or i64 %117, 8
  %119 = inttoptr i64 %118 to i64*
  %120 = load i64, i64* %119, align 8
  %121 = and i64 %120, 262144
  %122 = icmp eq i64 %121, 0
  br i1 %122, label %127, label %123

123:                                              ; preds = %116
  %124 = or i64 %117, 16
  %125 = inttoptr i64 %124 to %"class.v8::internal::Heap"**
  %126 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %125, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %126, i64 %109, i64 %111, i64 %110) #2
  br label %127

127:                                              ; preds = %123, %116, %108
  %128 = and i64 %110, -262144
  %129 = or i64 %128, 8
  %130 = inttoptr i64 %129 to i64*
  %131 = load i64, i64* %130, align 8
  %132 = and i64 %131, 24
  %133 = icmp eq i64 %132, 0
  br i1 %133, label %142, label %134

134:                                              ; preds = %127
  %135 = and i64 %109, -262144
  %136 = or i64 %135, 8
  %137 = inttoptr i64 %136 to i64*
  %138 = load i64, i64* %137, align 8
  %139 = and i64 %138, 24
  %140 = icmp eq i64 %139, 0
  br i1 %140, label %141, label %142

141:                                              ; preds = %134
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %109, i64 %111, i64 %110) #2
  br label %142

142:                                              ; preds = %141, %134, %127
  %143 = load i64, i64* %40, align 8
  %144 = load i64, i64* %4, align 8
  %145 = add i64 %143, 15
  %146 = inttoptr i64 %145 to i32*
  %147 = trunc i64 %144 to i32
  store atomic volatile i32 %147, i32* %146 monotonic, align 4
  %148 = and i64 %144, 1
  %149 = icmp eq i64 %148, 0
  br i1 %149, label %161, label %150

150:                                              ; preds = %142
  %151 = and i64 %143, -262144
  %152 = or i64 %151, 8
  %153 = inttoptr i64 %152 to i64*
  %154 = load i64, i64* %153, align 8
  %155 = and i64 %154, 262144
  %156 = icmp eq i64 %155, 0
  br i1 %156, label %161, label %157

157:                                              ; preds = %150
  %158 = or i64 %151, 16
  %159 = inttoptr i64 %158 to %"class.v8::internal::Heap"**
  %160 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %159, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %160, i64 %143, i64 %145, i64 %144) #2
  br label %161

161:                                              ; preds = %157, %150, %142
  %162 = and i64 %144, -262144
  %163 = or i64 %162, 8
  %164 = inttoptr i64 %163 to i64*
  %165 = load i64, i64* %164, align 8
  %166 = and i64 %165, 24
  %167 = icmp eq i64 %166, 0
  br i1 %167, label %197, label %168

168:                                              ; preds = %161
  %169 = and i64 %143, -262144
  %170 = or i64 %169, 8
  %171 = inttoptr i64 %170 to i64*
  %172 = load i64, i64* %171, align 8
  %173 = and i64 %172, 24
  %174 = icmp eq i64 %173, 0
  br i1 %174, label %175, label %197

175:                                              ; preds = %168
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %143, i64 %145, i64 %144) #2
  br label %197

176:                                              ; preds = %38
  %177 = load i64, i64* %40, align 8
  %178 = load i64, i64* %2, align 8
  %179 = add i64 %177, 7
  %180 = inttoptr i64 %179 to i32*
  %181 = trunc i64 %178 to i32
  store atomic volatile i32 %181, i32* %180 monotonic, align 4
  %182 = load i64, i64* %40, align 8
  %183 = load i64, i64* %3, align 8
  %184 = add i64 %182, 11
  %185 = inttoptr i64 %184 to i32*
  %186 = trunc i64 %183 to i32
  store atomic volatile i32 %186, i32* %185 monotonic, align 4
  %187 = load i64, i64* %40, align 8
  %188 = load i64, i64* %4, align 8
  %189 = add i64 %187, 15
  %190 = inttoptr i64 %189 to i32*
  %191 = trunc i64 %188 to i32
  store atomic volatile i32 %191, i32* %190 monotonic, align 4
  %192 = load i64, i64* %40, align 8
  %193 = load i64, i64* %5, align 8
  %194 = add i64 %192, 19
  %195 = inttoptr i64 %194 to i32*
  %196 = trunc i64 %193 to i32
  store atomic volatile i32 %196, i32* %195 monotonic, align 4
  br label %231

197:                                              ; preds = %175, %168, %161
  %198 = load i64, i64* %40, align 8
  %199 = load i64, i64* %5, align 8
  %200 = add i64 %198, 19
  %201 = inttoptr i64 %200 to i32*
  %202 = trunc i64 %199 to i32
  store atomic volatile i32 %202, i32* %201 monotonic, align 4
  %203 = and i64 %199, 1
  %204 = icmp eq i64 %203, 0
  br i1 %204, label %216, label %205

205:                                              ; preds = %197
  %206 = and i64 %198, -262144
  %207 = or i64 %206, 8
  %208 = inttoptr i64 %207 to i64*
  %209 = load i64, i64* %208, align 8
  %210 = and i64 %209, 262144
  %211 = icmp eq i64 %210, 0
  br i1 %211, label %216, label %212

212:                                              ; preds = %205
  %213 = or i64 %206, 16
  %214 = inttoptr i64 %213 to %"class.v8::internal::Heap"**
  %215 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %214, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %215, i64 %198, i64 %200, i64 %199) #2
  br label %216

216:                                              ; preds = %212, %205, %197
  %217 = and i64 %199, -262144
  %218 = or i64 %217, 8
  %219 = inttoptr i64 %218 to i64*
  %220 = load i64, i64* %219, align 8
  %221 = and i64 %220, 24
  %222 = icmp eq i64 %221, 0
  br i1 %222, label %231, label %223

223:                                              ; preds = %216
  %224 = and i64 %198, -262144
  %225 = or i64 %224, 8
  %226 = inttoptr i64 %225 to i64*
  %227 = load i64, i64* %226, align 8
  %228 = and i64 %227, 24
  %229 = icmp eq i64 %228, 0
  br i1 %229, label %230, label %231

230:                                              ; preds = %223
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %198, i64 %200, i64 %199) #2
  br label %231

231:                                              ; preds = %176, %216, %223, %230
  %232 = load i64, i64* %40, align 8
  %233 = shl i32 %6, 1
  %234 = add i64 %232, 23
  %235 = inttoptr i64 %234 to i32*
  store atomic volatile i32 %233, i32* %235 monotonic, align 4
  ret i64* %40
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE31NewOnHeapBasicBlockProfilerDataENS0_6HandleINS0_9ByteArrayEEES6_NS4_INS0_6StringEEES8_S8_iNS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory.1056"*, i64*, i64*, i64*, i64*, i64*, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %9 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to %"class.v8::internal::FactoryBase.1055"*
  %10 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to i64**
  %11 = load i64*, i64** %10, align 8
  %12 = getelementptr inbounds i64, i64* %11, i64 566
  %13 = load i64, i64* %12, align 8
  %14 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"* %9, i32 28, i8 zeroext %7, i64 %13, i32 0) #2
  %15 = icmp eq i8 %7, 0
  %16 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 16, i32 0
  %17 = load i8, i8* %16, align 8, !range !2
  %18 = icmp eq i8 %17, 0
  br i1 %18, label %24, label %19

19:                                               ; preds = %8
  %20 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 8
  %21 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %20 to %"class.v8::internal::LocalHeap"*
  %22 = tail call i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"* %21, i64 %14) #2
  %23 = load i64, i64* %22, align 8
  br label %40

24:                                               ; preds = %8
  %25 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 48
  %26 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %25 to %"class.v8::internal::LocalHandles"**
  %27 = load %"class.v8::internal::LocalHandles"*, %"class.v8::internal::LocalHandles"** %26, align 8
  %28 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %27, i64 0, i32 0, i32 0
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %27, i64 0, i32 0, i32 1
  %31 = load i64*, i64** %30, align 8
  %32 = icmp eq i64* %29, %31
  br i1 %32, label %33, label %36

33:                                               ; preds = %24
  %34 = tail call i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"* %27) #2
  %35 = load i64*, i64** %28, align 8
  br label %36

36:                                               ; preds = %33, %24
  %37 = phi i64* [ %35, %33 ], [ %29, %24 ]
  %38 = phi i64* [ %34, %33 ], [ %29, %24 ]
  %39 = getelementptr inbounds i64, i64* %37, i64 1
  store i64* %39, i64** %28, align 8
  store i64 %14, i64* %38, align 8
  br label %40

40:                                               ; preds = %19, %36
  %41 = phi i64 [ %23, %19 ], [ %14, %36 ]
  %42 = phi i64* [ %22, %19 ], [ %38, %36 ]
  %43 = load i64, i64* %1, align 8
  %44 = add i64 %41, 3
  %45 = inttoptr i64 %44 to i32*
  %46 = trunc i64 %43 to i32
  store atomic volatile i32 %46, i32* %45 monotonic, align 4
  br i1 %15, label %178, label %47

47:                                               ; preds = %40
  %48 = and i64 %43, 1
  %49 = icmp eq i64 %48, 0
  br i1 %49, label %61, label %50

50:                                               ; preds = %47
  %51 = and i64 %41, -262144
  %52 = or i64 %51, 8
  %53 = inttoptr i64 %52 to i64*
  %54 = load i64, i64* %53, align 8
  %55 = and i64 %54, 262144
  %56 = icmp eq i64 %55, 0
  br i1 %56, label %61, label %57

57:                                               ; preds = %50
  %58 = or i64 %51, 16
  %59 = inttoptr i64 %58 to %"class.v8::internal::Heap"**
  %60 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %59, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %60, i64 %41, i64 %44, i64 %43) #2
  br label %61

61:                                               ; preds = %57, %50, %47
  %62 = and i64 %43, -262144
  %63 = or i64 %62, 8
  %64 = inttoptr i64 %63 to i64*
  %65 = load i64, i64* %64, align 8
  %66 = and i64 %65, 24
  %67 = icmp eq i64 %66, 0
  br i1 %67, label %76, label %68

68:                                               ; preds = %61
  %69 = and i64 %41, -262144
  %70 = or i64 %69, 8
  %71 = inttoptr i64 %70 to i64*
  %72 = load i64, i64* %71, align 8
  %73 = and i64 %72, 24
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %75, label %76

75:                                               ; preds = %68
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %41, i64 %44, i64 %43) #2
  br label %76

76:                                               ; preds = %75, %68, %61
  %77 = load i64, i64* %42, align 8
  %78 = load i64, i64* %2, align 8
  %79 = add i64 %77, 7
  %80 = inttoptr i64 %79 to i32*
  %81 = trunc i64 %78 to i32
  store atomic volatile i32 %81, i32* %80 monotonic, align 4
  %82 = and i64 %78, 1
  %83 = icmp eq i64 %82, 0
  br i1 %83, label %95, label %84

84:                                               ; preds = %76
  %85 = and i64 %77, -262144
  %86 = or i64 %85, 8
  %87 = inttoptr i64 %86 to i64*
  %88 = load i64, i64* %87, align 8
  %89 = and i64 %88, 262144
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %95, label %91

91:                                               ; preds = %84
  %92 = or i64 %85, 16
  %93 = inttoptr i64 %92 to %"class.v8::internal::Heap"**
  %94 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %93, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %94, i64 %77, i64 %79, i64 %78) #2
  br label %95

95:                                               ; preds = %91, %84, %76
  %96 = and i64 %78, -262144
  %97 = or i64 %96, 8
  %98 = inttoptr i64 %97 to i64*
  %99 = load i64, i64* %98, align 8
  %100 = and i64 %99, 24
  %101 = icmp eq i64 %100, 0
  br i1 %101, label %110, label %102

102:                                              ; preds = %95
  %103 = and i64 %77, -262144
  %104 = or i64 %103, 8
  %105 = inttoptr i64 %104 to i64*
  %106 = load i64, i64* %105, align 8
  %107 = and i64 %106, 24
  %108 = icmp eq i64 %107, 0
  br i1 %108, label %109, label %110

109:                                              ; preds = %102
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %77, i64 %79, i64 %78) #2
  br label %110

110:                                              ; preds = %109, %102, %95
  %111 = load i64, i64* %42, align 8
  %112 = load i64, i64* %3, align 8
  %113 = add i64 %111, 11
  %114 = inttoptr i64 %113 to i32*
  %115 = trunc i64 %112 to i32
  store atomic volatile i32 %115, i32* %114 monotonic, align 4
  %116 = and i64 %112, 1
  %117 = icmp eq i64 %116, 0
  br i1 %117, label %129, label %118

118:                                              ; preds = %110
  %119 = and i64 %111, -262144
  %120 = or i64 %119, 8
  %121 = inttoptr i64 %120 to i64*
  %122 = load i64, i64* %121, align 8
  %123 = and i64 %122, 262144
  %124 = icmp eq i64 %123, 0
  br i1 %124, label %129, label %125

125:                                              ; preds = %118
  %126 = or i64 %119, 16
  %127 = inttoptr i64 %126 to %"class.v8::internal::Heap"**
  %128 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %127, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %128, i64 %111, i64 %113, i64 %112) #2
  br label %129

129:                                              ; preds = %125, %118, %110
  %130 = and i64 %112, -262144
  %131 = or i64 %130, 8
  %132 = inttoptr i64 %131 to i64*
  %133 = load i64, i64* %132, align 8
  %134 = and i64 %133, 24
  %135 = icmp eq i64 %134, 0
  br i1 %135, label %144, label %136

136:                                              ; preds = %129
  %137 = and i64 %111, -262144
  %138 = or i64 %137, 8
  %139 = inttoptr i64 %138 to i64*
  %140 = load i64, i64* %139, align 8
  %141 = and i64 %140, 24
  %142 = icmp eq i64 %141, 0
  br i1 %142, label %143, label %144

143:                                              ; preds = %136
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %111, i64 %113, i64 %112) #2
  br label %144

144:                                              ; preds = %143, %136, %129
  %145 = load i64, i64* %42, align 8
  %146 = load i64, i64* %4, align 8
  %147 = add i64 %145, 15
  %148 = inttoptr i64 %147 to i32*
  %149 = trunc i64 %146 to i32
  store atomic volatile i32 %149, i32* %148 monotonic, align 4
  %150 = and i64 %146, 1
  %151 = icmp eq i64 %150, 0
  br i1 %151, label %163, label %152

152:                                              ; preds = %144
  %153 = and i64 %145, -262144
  %154 = or i64 %153, 8
  %155 = inttoptr i64 %154 to i64*
  %156 = load i64, i64* %155, align 8
  %157 = and i64 %156, 262144
  %158 = icmp eq i64 %157, 0
  br i1 %158, label %163, label %159

159:                                              ; preds = %152
  %160 = or i64 %153, 16
  %161 = inttoptr i64 %160 to %"class.v8::internal::Heap"**
  %162 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %161, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %162, i64 %145, i64 %147, i64 %146) #2
  br label %163

163:                                              ; preds = %159, %152, %144
  %164 = and i64 %146, -262144
  %165 = or i64 %164, 8
  %166 = inttoptr i64 %165 to i64*
  %167 = load i64, i64* %166, align 8
  %168 = and i64 %167, 24
  %169 = icmp eq i64 %168, 0
  br i1 %169, label %199, label %170

170:                                              ; preds = %163
  %171 = and i64 %145, -262144
  %172 = or i64 %171, 8
  %173 = inttoptr i64 %172 to i64*
  %174 = load i64, i64* %173, align 8
  %175 = and i64 %174, 24
  %176 = icmp eq i64 %175, 0
  br i1 %176, label %177, label %199

177:                                              ; preds = %170
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %145, i64 %147, i64 %146) #2
  br label %199

178:                                              ; preds = %40
  %179 = load i64, i64* %42, align 8
  %180 = load i64, i64* %2, align 8
  %181 = add i64 %179, 7
  %182 = inttoptr i64 %181 to i32*
  %183 = trunc i64 %180 to i32
  store atomic volatile i32 %183, i32* %182 monotonic, align 4
  %184 = load i64, i64* %42, align 8
  %185 = load i64, i64* %3, align 8
  %186 = add i64 %184, 11
  %187 = inttoptr i64 %186 to i32*
  %188 = trunc i64 %185 to i32
  store atomic volatile i32 %188, i32* %187 monotonic, align 4
  %189 = load i64, i64* %42, align 8
  %190 = load i64, i64* %4, align 8
  %191 = add i64 %189, 15
  %192 = inttoptr i64 %191 to i32*
  %193 = trunc i64 %190 to i32
  store atomic volatile i32 %193, i32* %192 monotonic, align 4
  %194 = load i64, i64* %42, align 8
  %195 = load i64, i64* %5, align 8
  %196 = add i64 %194, 19
  %197 = inttoptr i64 %196 to i32*
  %198 = trunc i64 %195 to i32
  store atomic volatile i32 %198, i32* %197 monotonic, align 4
  br label %233

199:                                              ; preds = %177, %170, %163
  %200 = load i64, i64* %42, align 8
  %201 = load i64, i64* %5, align 8
  %202 = add i64 %200, 19
  %203 = inttoptr i64 %202 to i32*
  %204 = trunc i64 %201 to i32
  store atomic volatile i32 %204, i32* %203 monotonic, align 4
  %205 = and i64 %201, 1
  %206 = icmp eq i64 %205, 0
  br i1 %206, label %218, label %207

207:                                              ; preds = %199
  %208 = and i64 %200, -262144
  %209 = or i64 %208, 8
  %210 = inttoptr i64 %209 to i64*
  %211 = load i64, i64* %210, align 8
  %212 = and i64 %211, 262144
  %213 = icmp eq i64 %212, 0
  br i1 %213, label %218, label %214

214:                                              ; preds = %207
  %215 = or i64 %208, 16
  %216 = inttoptr i64 %215 to %"class.v8::internal::Heap"**
  %217 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %216, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %217, i64 %200, i64 %202, i64 %201) #2
  br label %218

218:                                              ; preds = %214, %207, %199
  %219 = and i64 %201, -262144
  %220 = or i64 %219, 8
  %221 = inttoptr i64 %220 to i64*
  %222 = load i64, i64* %221, align 8
  %223 = and i64 %222, 24
  %224 = icmp eq i64 %223, 0
  br i1 %224, label %233, label %225

225:                                              ; preds = %218
  %226 = and i64 %200, -262144
  %227 = or i64 %226, 8
  %228 = inttoptr i64 %227 to i64*
  %229 = load i64, i64* %228, align 8
  %230 = and i64 %229, 24
  %231 = icmp eq i64 %230, 0
  br i1 %231, label %232, label %233

232:                                              ; preds = %225
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %200, i64 %202, i64 %201) #2
  br label %233

233:                                              ; preds = %178, %218, %225, %232
  %234 = load i64, i64* %42, align 8
  %235 = shl i32 %6, 1
  %236 = add i64 %234, 23
  %237 = inttoptr i64 %236 to i32*
  store atomic volatile i32 %235, i32* %237 monotonic, align 4
  ret i64* %42
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE23NewExportedSubClassBaseENS0_6HandleINS0_10HeapObjectEEES6_NS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory"*, i64*, i64*, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %5 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::FactoryBase"*
  %6 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 4688
  %7 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %6 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"* %5, i32 12, i8 zeroext %3, i64 %8, i32 0) #2
  %10 = icmp eq i8 %3, 0
  %11 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::Isolate"*
  %12 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45608
  %13 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %12 to %"class.v8::internal::CanonicalHandleScope"**
  %14 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %13, align 8
  %15 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %14, null
  br i1 %15, label %19, label %16

16:                                               ; preds = %4
  %17 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %14, i64 %9) #2
  %18 = load i64, i64* %17, align 8
  br label %34

19:                                               ; preds = %4
  %20 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45584
  %21 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %20 to i64**
  %22 = load i64*, i64** %21, align 8
  %23 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45592
  %24 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %23 to i64**
  %25 = load i64*, i64** %24, align 8
  %26 = icmp eq i64* %22, %25
  br i1 %26, label %27, label %29

27:                                               ; preds = %19
  %28 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %11) #2
  br label %29

29:                                               ; preds = %27, %19
  %30 = phi i64* [ %28, %27 ], [ %22, %19 ]
  %31 = ptrtoint i64* %30 to i64
  %32 = add i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64* %33, i64** %21, align 8
  store i64 %9, i64* %30, align 8
  br label %34

34:                                               ; preds = %16, %29
  %35 = phi i64 [ %18, %16 ], [ %9, %29 ]
  %36 = phi i64* [ %17, %16 ], [ %30, %29 ]
  %37 = load i64, i64* %1, align 8
  %38 = add i64 %35, 3
  %39 = inttoptr i64 %38 to i32*
  %40 = trunc i64 %37 to i32
  store atomic volatile i32 %40, i32* %39 monotonic, align 4
  br i1 %10, label %41, label %47

41:                                               ; preds = %34
  %42 = load i64, i64* %36, align 8
  %43 = load i64, i64* %2, align 8
  %44 = add i64 %42, 7
  %45 = inttoptr i64 %44 to i32*
  %46 = trunc i64 %43 to i32
  store atomic volatile i32 %46, i32* %45 monotonic, align 4
  br label %110

47:                                               ; preds = %34
  %48 = and i64 %37, 1
  %49 = icmp eq i64 %48, 0
  br i1 %49, label %61, label %50

50:                                               ; preds = %47
  %51 = and i64 %35, -262144
  %52 = or i64 %51, 8
  %53 = inttoptr i64 %52 to i64*
  %54 = load i64, i64* %53, align 8
  %55 = and i64 %54, 262144
  %56 = icmp eq i64 %55, 0
  br i1 %56, label %61, label %57

57:                                               ; preds = %50
  %58 = or i64 %51, 16
  %59 = inttoptr i64 %58 to %"class.v8::internal::Heap"**
  %60 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %59, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %60, i64 %35, i64 %38, i64 %37) #2
  br label %61

61:                                               ; preds = %57, %50, %47
  %62 = and i64 %37, -262144
  %63 = or i64 %62, 8
  %64 = inttoptr i64 %63 to i64*
  %65 = load i64, i64* %64, align 8
  %66 = and i64 %65, 24
  %67 = icmp eq i64 %66, 0
  br i1 %67, label %76, label %68

68:                                               ; preds = %61
  %69 = and i64 %35, -262144
  %70 = or i64 %69, 8
  %71 = inttoptr i64 %70 to i64*
  %72 = load i64, i64* %71, align 8
  %73 = and i64 %72, 24
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %75, label %76

75:                                               ; preds = %68
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %35, i64 %38, i64 %37) #2
  br label %76

76:                                               ; preds = %75, %68, %61
  %77 = load i64, i64* %36, align 8
  %78 = load i64, i64* %2, align 8
  %79 = add i64 %77, 7
  %80 = inttoptr i64 %79 to i32*
  %81 = trunc i64 %78 to i32
  store atomic volatile i32 %81, i32* %80 monotonic, align 4
  %82 = and i64 %78, 1
  %83 = icmp eq i64 %82, 0
  br i1 %83, label %95, label %84

84:                                               ; preds = %76
  %85 = and i64 %77, -262144
  %86 = or i64 %85, 8
  %87 = inttoptr i64 %86 to i64*
  %88 = load i64, i64* %87, align 8
  %89 = and i64 %88, 262144
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %95, label %91

91:                                               ; preds = %84
  %92 = or i64 %85, 16
  %93 = inttoptr i64 %92 to %"class.v8::internal::Heap"**
  %94 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %93, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %94, i64 %77, i64 %79, i64 %78) #2
  br label %95

95:                                               ; preds = %91, %84, %76
  %96 = and i64 %78, -262144
  %97 = or i64 %96, 8
  %98 = inttoptr i64 %97 to i64*
  %99 = load i64, i64* %98, align 8
  %100 = and i64 %99, 24
  %101 = icmp eq i64 %100, 0
  br i1 %101, label %110, label %102

102:                                              ; preds = %95
  %103 = and i64 %77, -262144
  %104 = or i64 %103, 8
  %105 = inttoptr i64 %104 to i64*
  %106 = load i64, i64* %105, align 8
  %107 = and i64 %106, 24
  %108 = icmp eq i64 %107, 0
  br i1 %108, label %109, label %110

109:                                              ; preds = %102
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %77, i64 %79, i64 %78) #2
  br label %110

110:                                              ; preds = %41, %95, %102, %109
  ret i64* %36
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE23NewExportedSubClassBaseENS0_6HandleINS0_10HeapObjectEEES6_NS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory.1056"*, i64*, i64*, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %5 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to %"class.v8::internal::FactoryBase.1055"*
  %6 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to i64**
  %7 = load i64*, i64** %6, align 8
  %8 = getelementptr inbounds i64, i64* %7, i64 570
  %9 = load i64, i64* %8, align 8
  %10 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"* %5, i32 12, i8 zeroext %3, i64 %9, i32 0) #2
  %11 = icmp eq i8 %3, 0
  %12 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 16, i32 0
  %13 = load i8, i8* %12, align 8, !range !2
  %14 = icmp eq i8 %13, 0
  br i1 %14, label %20, label %15

15:                                               ; preds = %4
  %16 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 8
  %17 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %16 to %"class.v8::internal::LocalHeap"*
  %18 = tail call i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"* %17, i64 %10) #2
  %19 = load i64, i64* %18, align 8
  br label %36

20:                                               ; preds = %4
  %21 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 48
  %22 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %21 to %"class.v8::internal::LocalHandles"**
  %23 = load %"class.v8::internal::LocalHandles"*, %"class.v8::internal::LocalHandles"** %22, align 8
  %24 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %23, i64 0, i32 0, i32 0
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %23, i64 0, i32 0, i32 1
  %27 = load i64*, i64** %26, align 8
  %28 = icmp eq i64* %25, %27
  br i1 %28, label %29, label %32

29:                                               ; preds = %20
  %30 = tail call i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"* %23) #2
  %31 = load i64*, i64** %24, align 8
  br label %32

32:                                               ; preds = %29, %20
  %33 = phi i64* [ %31, %29 ], [ %25, %20 ]
  %34 = phi i64* [ %30, %29 ], [ %25, %20 ]
  %35 = getelementptr inbounds i64, i64* %33, i64 1
  store i64* %35, i64** %24, align 8
  store i64 %10, i64* %34, align 8
  br label %36

36:                                               ; preds = %15, %32
  %37 = phi i64 [ %19, %15 ], [ %10, %32 ]
  %38 = phi i64* [ %18, %15 ], [ %34, %32 ]
  %39 = load i64, i64* %1, align 8
  %40 = add i64 %37, 3
  %41 = inttoptr i64 %40 to i32*
  %42 = trunc i64 %39 to i32
  store atomic volatile i32 %42, i32* %41 monotonic, align 4
  br i1 %11, label %43, label %49

43:                                               ; preds = %36
  %44 = load i64, i64* %38, align 8
  %45 = load i64, i64* %2, align 8
  %46 = add i64 %44, 7
  %47 = inttoptr i64 %46 to i32*
  %48 = trunc i64 %45 to i32
  store atomic volatile i32 %48, i32* %47 monotonic, align 4
  br label %112

49:                                               ; preds = %36
  %50 = and i64 %39, 1
  %51 = icmp eq i64 %50, 0
  br i1 %51, label %63, label %52

52:                                               ; preds = %49
  %53 = and i64 %37, -262144
  %54 = or i64 %53, 8
  %55 = inttoptr i64 %54 to i64*
  %56 = load i64, i64* %55, align 8
  %57 = and i64 %56, 262144
  %58 = icmp eq i64 %57, 0
  br i1 %58, label %63, label %59

59:                                               ; preds = %52
  %60 = or i64 %53, 16
  %61 = inttoptr i64 %60 to %"class.v8::internal::Heap"**
  %62 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %61, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %62, i64 %37, i64 %40, i64 %39) #2
  br label %63

63:                                               ; preds = %59, %52, %49
  %64 = and i64 %39, -262144
  %65 = or i64 %64, 8
  %66 = inttoptr i64 %65 to i64*
  %67 = load i64, i64* %66, align 8
  %68 = and i64 %67, 24
  %69 = icmp eq i64 %68, 0
  br i1 %69, label %78, label %70

70:                                               ; preds = %63
  %71 = and i64 %37, -262144
  %72 = or i64 %71, 8
  %73 = inttoptr i64 %72 to i64*
  %74 = load i64, i64* %73, align 8
  %75 = and i64 %74, 24
  %76 = icmp eq i64 %75, 0
  br i1 %76, label %77, label %78

77:                                               ; preds = %70
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %37, i64 %40, i64 %39) #2
  br label %78

78:                                               ; preds = %77, %70, %63
  %79 = load i64, i64* %38, align 8
  %80 = load i64, i64* %2, align 8
  %81 = add i64 %79, 7
  %82 = inttoptr i64 %81 to i32*
  %83 = trunc i64 %80 to i32
  store atomic volatile i32 %83, i32* %82 monotonic, align 4
  %84 = and i64 %80, 1
  %85 = icmp eq i64 %84, 0
  br i1 %85, label %97, label %86

86:                                               ; preds = %78
  %87 = and i64 %79, -262144
  %88 = or i64 %87, 8
  %89 = inttoptr i64 %88 to i64*
  %90 = load i64, i64* %89, align 8
  %91 = and i64 %90, 262144
  %92 = icmp eq i64 %91, 0
  br i1 %92, label %97, label %93

93:                                               ; preds = %86
  %94 = or i64 %87, 16
  %95 = inttoptr i64 %94 to %"class.v8::internal::Heap"**
  %96 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %95, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %96, i64 %79, i64 %81, i64 %80) #2
  br label %97

97:                                               ; preds = %93, %86, %78
  %98 = and i64 %80, -262144
  %99 = or i64 %98, 8
  %100 = inttoptr i64 %99 to i64*
  %101 = load i64, i64* %100, align 8
  %102 = and i64 %101, 24
  %103 = icmp eq i64 %102, 0
  br i1 %103, label %112, label %104

104:                                              ; preds = %97
  %105 = and i64 %79, -262144
  %106 = or i64 %105, 8
  %107 = inttoptr i64 %106 to i64*
  %108 = load i64, i64* %107, align 8
  %109 = and i64 %108, 24
  %110 = icmp eq i64 %109, 0
  br i1 %110, label %111, label %112

111:                                              ; preds = %104
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %79, i64 %81, i64 %80) #2
  br label %112

112:                                              ; preds = %43, %97, %104, %111
  ret i64* %38
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE19NewExportedSubClassENS0_6HandleINS0_10HeapObjectEEES6_iiiNS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory"*, i64*, i64*, i32, i32, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %8 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::FactoryBase"*
  %9 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 4696
  %10 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"* %8, i32 24, i8 zeroext %6, i64 %11, i32 0) #2
  %13 = icmp eq i8 %6, 0
  %14 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::Isolate"*
  %15 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45608
  %16 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %15 to %"class.v8::internal::CanonicalHandleScope"**
  %17 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %16, align 8
  %18 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %17, null
  br i1 %18, label %22, label %19

19:                                               ; preds = %7
  %20 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %17, i64 %12) #2
  %21 = load i64, i64* %20, align 8
  br label %37

22:                                               ; preds = %7
  %23 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45584
  %24 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %23 to i64**
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45592
  %27 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %26 to i64**
  %28 = load i64*, i64** %27, align 8
  %29 = icmp eq i64* %25, %28
  br i1 %29, label %30, label %32

30:                                               ; preds = %22
  %31 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %14) #2
  br label %32

32:                                               ; preds = %30, %22
  %33 = phi i64* [ %31, %30 ], [ %25, %22 ]
  %34 = ptrtoint i64* %33 to i64
  %35 = add i64 %34, 8
  %36 = inttoptr i64 %35 to i64*
  store i64* %36, i64** %24, align 8
  store i64 %12, i64* %33, align 8
  br label %37

37:                                               ; preds = %19, %32
  %38 = phi i64 [ %21, %19 ], [ %12, %32 ]
  %39 = phi i64* [ %20, %19 ], [ %33, %32 ]
  %40 = load i64, i64* %1, align 8
  %41 = add i64 %38, 3
  %42 = inttoptr i64 %41 to i32*
  %43 = trunc i64 %40 to i32
  store atomic volatile i32 %43, i32* %42 monotonic, align 4
  br i1 %13, label %44, label %50

44:                                               ; preds = %37
  %45 = load i64, i64* %39, align 8
  %46 = load i64, i64* %2, align 8
  %47 = add i64 %45, 7
  %48 = inttoptr i64 %47 to i32*
  %49 = trunc i64 %46 to i32
  store atomic volatile i32 %49, i32* %48 monotonic, align 4
  br label %113

50:                                               ; preds = %37
  %51 = and i64 %40, 1
  %52 = icmp eq i64 %51, 0
  br i1 %52, label %64, label %53

53:                                               ; preds = %50
  %54 = and i64 %38, -262144
  %55 = or i64 %54, 8
  %56 = inttoptr i64 %55 to i64*
  %57 = load i64, i64* %56, align 8
  %58 = and i64 %57, 262144
  %59 = icmp eq i64 %58, 0
  br i1 %59, label %64, label %60

60:                                               ; preds = %53
  %61 = or i64 %54, 16
  %62 = inttoptr i64 %61 to %"class.v8::internal::Heap"**
  %63 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %62, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %63, i64 %38, i64 %41, i64 %40) #2
  br label %64

64:                                               ; preds = %60, %53, %50
  %65 = and i64 %40, -262144
  %66 = or i64 %65, 8
  %67 = inttoptr i64 %66 to i64*
  %68 = load i64, i64* %67, align 8
  %69 = and i64 %68, 24
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %79, label %71

71:                                               ; preds = %64
  %72 = and i64 %38, -262144
  %73 = or i64 %72, 8
  %74 = inttoptr i64 %73 to i64*
  %75 = load i64, i64* %74, align 8
  %76 = and i64 %75, 24
  %77 = icmp eq i64 %76, 0
  br i1 %77, label %78, label %79

78:                                               ; preds = %71
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %38, i64 %41, i64 %40) #2
  br label %79

79:                                               ; preds = %78, %71, %64
  %80 = load i64, i64* %39, align 8
  %81 = load i64, i64* %2, align 8
  %82 = add i64 %80, 7
  %83 = inttoptr i64 %82 to i32*
  %84 = trunc i64 %81 to i32
  store atomic volatile i32 %84, i32* %83 monotonic, align 4
  %85 = and i64 %81, 1
  %86 = icmp eq i64 %85, 0
  br i1 %86, label %98, label %87

87:                                               ; preds = %79
  %88 = and i64 %80, -262144
  %89 = or i64 %88, 8
  %90 = inttoptr i64 %89 to i64*
  %91 = load i64, i64* %90, align 8
  %92 = and i64 %91, 262144
  %93 = icmp eq i64 %92, 0
  br i1 %93, label %98, label %94

94:                                               ; preds = %87
  %95 = or i64 %88, 16
  %96 = inttoptr i64 %95 to %"class.v8::internal::Heap"**
  %97 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %96, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %97, i64 %80, i64 %82, i64 %81) #2
  br label %98

98:                                               ; preds = %94, %87, %79
  %99 = and i64 %81, -262144
  %100 = or i64 %99, 8
  %101 = inttoptr i64 %100 to i64*
  %102 = load i64, i64* %101, align 8
  %103 = and i64 %102, 24
  %104 = icmp eq i64 %103, 0
  br i1 %104, label %113, label %105

105:                                              ; preds = %98
  %106 = and i64 %80, -262144
  %107 = or i64 %106, 8
  %108 = inttoptr i64 %107 to i64*
  %109 = load i64, i64* %108, align 8
  %110 = and i64 %109, 24
  %111 = icmp eq i64 %110, 0
  br i1 %111, label %112, label %113

112:                                              ; preds = %105
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %80, i64 %82, i64 %81) #2
  br label %113

113:                                              ; preds = %44, %98, %105, %112
  %114 = load i64, i64* %39, align 8
  %115 = add i64 %114, 11
  %116 = inttoptr i64 %115 to i32*
  store i32 %3, i32* %116, align 4
  %117 = load i64, i64* %39, align 8
  %118 = add i64 %117, 15
  %119 = inttoptr i64 %118 to i32*
  store i32 %4, i32* %119, align 4
  %120 = load i64, i64* %39, align 8
  %121 = shl i32 %5, 1
  %122 = add i64 %120, 19
  %123 = inttoptr i64 %122 to i32*
  store atomic volatile i32 %121, i32* %123 monotonic, align 4
  ret i64* %39
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE19NewExportedSubClassENS0_6HandleINS0_10HeapObjectEEES6_iiiNS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory.1056"*, i64*, i64*, i32, i32, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %8 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to %"class.v8::internal::FactoryBase.1055"*
  %9 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to i64**
  %10 = load i64*, i64** %9, align 8
  %11 = getelementptr inbounds i64, i64* %10, i64 571
  %12 = load i64, i64* %11, align 8
  %13 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"* %8, i32 24, i8 zeroext %6, i64 %12, i32 0) #2
  %14 = icmp eq i8 %6, 0
  %15 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 16, i32 0
  %16 = load i8, i8* %15, align 8, !range !2
  %17 = icmp eq i8 %16, 0
  br i1 %17, label %23, label %18

18:                                               ; preds = %7
  %19 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 8
  %20 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %19 to %"class.v8::internal::LocalHeap"*
  %21 = tail call i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"* %20, i64 %13) #2
  %22 = load i64, i64* %21, align 8
  br label %39

23:                                               ; preds = %7
  %24 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 48
  %25 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %24 to %"class.v8::internal::LocalHandles"**
  %26 = load %"class.v8::internal::LocalHandles"*, %"class.v8::internal::LocalHandles"** %25, align 8
  %27 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %26, i64 0, i32 0, i32 0
  %28 = load i64*, i64** %27, align 8
  %29 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %26, i64 0, i32 0, i32 1
  %30 = load i64*, i64** %29, align 8
  %31 = icmp eq i64* %28, %30
  br i1 %31, label %32, label %35

32:                                               ; preds = %23
  %33 = tail call i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"* %26) #2
  %34 = load i64*, i64** %27, align 8
  br label %35

35:                                               ; preds = %32, %23
  %36 = phi i64* [ %34, %32 ], [ %28, %23 ]
  %37 = phi i64* [ %33, %32 ], [ %28, %23 ]
  %38 = getelementptr inbounds i64, i64* %36, i64 1
  store i64* %38, i64** %27, align 8
  store i64 %13, i64* %37, align 8
  br label %39

39:                                               ; preds = %18, %35
  %40 = phi i64 [ %22, %18 ], [ %13, %35 ]
  %41 = phi i64* [ %21, %18 ], [ %37, %35 ]
  %42 = load i64, i64* %1, align 8
  %43 = add i64 %40, 3
  %44 = inttoptr i64 %43 to i32*
  %45 = trunc i64 %42 to i32
  store atomic volatile i32 %45, i32* %44 monotonic, align 4
  br i1 %14, label %46, label %52

46:                                               ; preds = %39
  %47 = load i64, i64* %41, align 8
  %48 = load i64, i64* %2, align 8
  %49 = add i64 %47, 7
  %50 = inttoptr i64 %49 to i32*
  %51 = trunc i64 %48 to i32
  store atomic volatile i32 %51, i32* %50 monotonic, align 4
  br label %115

52:                                               ; preds = %39
  %53 = and i64 %42, 1
  %54 = icmp eq i64 %53, 0
  br i1 %54, label %66, label %55

55:                                               ; preds = %52
  %56 = and i64 %40, -262144
  %57 = or i64 %56, 8
  %58 = inttoptr i64 %57 to i64*
  %59 = load i64, i64* %58, align 8
  %60 = and i64 %59, 262144
  %61 = icmp eq i64 %60, 0
  br i1 %61, label %66, label %62

62:                                               ; preds = %55
  %63 = or i64 %56, 16
  %64 = inttoptr i64 %63 to %"class.v8::internal::Heap"**
  %65 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %64, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %65, i64 %40, i64 %43, i64 %42) #2
  br label %66

66:                                               ; preds = %62, %55, %52
  %67 = and i64 %42, -262144
  %68 = or i64 %67, 8
  %69 = inttoptr i64 %68 to i64*
  %70 = load i64, i64* %69, align 8
  %71 = and i64 %70, 24
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %81, label %73

73:                                               ; preds = %66
  %74 = and i64 %40, -262144
  %75 = or i64 %74, 8
  %76 = inttoptr i64 %75 to i64*
  %77 = load i64, i64* %76, align 8
  %78 = and i64 %77, 24
  %79 = icmp eq i64 %78, 0
  br i1 %79, label %80, label %81

80:                                               ; preds = %73
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %40, i64 %43, i64 %42) #2
  br label %81

81:                                               ; preds = %80, %73, %66
  %82 = load i64, i64* %41, align 8
  %83 = load i64, i64* %2, align 8
  %84 = add i64 %82, 7
  %85 = inttoptr i64 %84 to i32*
  %86 = trunc i64 %83 to i32
  store atomic volatile i32 %86, i32* %85 monotonic, align 4
  %87 = and i64 %83, 1
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %100, label %89

89:                                               ; preds = %81
  %90 = and i64 %82, -262144
  %91 = or i64 %90, 8
  %92 = inttoptr i64 %91 to i64*
  %93 = load i64, i64* %92, align 8
  %94 = and i64 %93, 262144
  %95 = icmp eq i64 %94, 0
  br i1 %95, label %100, label %96

96:                                               ; preds = %89
  %97 = or i64 %90, 16
  %98 = inttoptr i64 %97 to %"class.v8::internal::Heap"**
  %99 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %98, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %99, i64 %82, i64 %84, i64 %83) #2
  br label %100

100:                                              ; preds = %96, %89, %81
  %101 = and i64 %83, -262144
  %102 = or i64 %101, 8
  %103 = inttoptr i64 %102 to i64*
  %104 = load i64, i64* %103, align 8
  %105 = and i64 %104, 24
  %106 = icmp eq i64 %105, 0
  br i1 %106, label %115, label %107

107:                                              ; preds = %100
  %108 = and i64 %82, -262144
  %109 = or i64 %108, 8
  %110 = inttoptr i64 %109 to i64*
  %111 = load i64, i64* %110, align 8
  %112 = and i64 %111, 24
  %113 = icmp eq i64 %112, 0
  br i1 %113, label %114, label %115

114:                                              ; preds = %107
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %82, i64 %84, i64 %83) #2
  br label %115

115:                                              ; preds = %46, %100, %107, %114
  %116 = load i64, i64* %41, align 8
  %117 = add i64 %116, 11
  %118 = inttoptr i64 %117 to i32*
  store i32 %3, i32* %118, align 4
  %119 = load i64, i64* %41, align 8
  %120 = add i64 %119, 15
  %121 = inttoptr i64 %120 to i32*
  store i32 %4, i32* %121, align 4
  %122 = load i64, i64* %41, align 8
  %123 = shl i32 %5, 1
  %124 = add i64 %122, 19
  %125 = inttoptr i64 %124 to i32*
  store atomic volatile i32 %123, i32* %125 monotonic, align 4
  ret i64* %41
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_7FactoryEE20NewExportedSubClass2ENS0_6HandleINS0_10HeapObjectEEES6_iiiNS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory"*, i64*, i64*, i32, i32, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %8 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::FactoryBase"*
  %9 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 4736
  %10 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_7FactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase"* %8, i32 24, i8 zeroext %6, i64 %11, i32 0) #2
  %13 = icmp eq i8 %6, 0
  %14 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %0 to %"class.v8::internal::Isolate"*
  %15 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45608
  %16 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %15 to %"class.v8::internal::CanonicalHandleScope"**
  %17 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %16, align 8
  %18 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %17, null
  br i1 %18, label %22, label %19

19:                                               ; preds = %7
  %20 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %17, i64 %12) #2
  %21 = load i64, i64* %20, align 8
  br label %37

22:                                               ; preds = %7
  %23 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45584
  %24 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %23 to i64**
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory", %"class.v8::internal::TorqueGeneratedFactory"* %0, i64 45592
  %27 = bitcast %"class.v8::internal::TorqueGeneratedFactory"* %26 to i64**
  %28 = load i64*, i64** %27, align 8
  %29 = icmp eq i64* %25, %28
  br i1 %29, label %30, label %32

30:                                               ; preds = %22
  %31 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %14) #2
  br label %32

32:                                               ; preds = %30, %22
  %33 = phi i64* [ %31, %30 ], [ %25, %22 ]
  %34 = ptrtoint i64* %33 to i64
  %35 = add i64 %34, 8
  %36 = inttoptr i64 %35 to i64*
  store i64* %36, i64** %24, align 8
  store i64 %12, i64* %33, align 8
  br label %37

37:                                               ; preds = %19, %32
  %38 = phi i64 [ %21, %19 ], [ %12, %32 ]
  %39 = phi i64* [ %20, %19 ], [ %33, %32 ]
  %40 = load i64, i64* %1, align 8
  %41 = add i64 %38, 3
  %42 = inttoptr i64 %41 to i32*
  %43 = trunc i64 %40 to i32
  store atomic volatile i32 %43, i32* %42 monotonic, align 4
  br i1 %13, label %44, label %50

44:                                               ; preds = %37
  %45 = load i64, i64* %39, align 8
  %46 = load i64, i64* %2, align 8
  %47 = add i64 %45, 7
  %48 = inttoptr i64 %47 to i32*
  %49 = trunc i64 %46 to i32
  store atomic volatile i32 %49, i32* %48 monotonic, align 4
  br label %113

50:                                               ; preds = %37
  %51 = and i64 %40, 1
  %52 = icmp eq i64 %51, 0
  br i1 %52, label %64, label %53

53:                                               ; preds = %50
  %54 = and i64 %38, -262144
  %55 = or i64 %54, 8
  %56 = inttoptr i64 %55 to i64*
  %57 = load i64, i64* %56, align 8
  %58 = and i64 %57, 262144
  %59 = icmp eq i64 %58, 0
  br i1 %59, label %64, label %60

60:                                               ; preds = %53
  %61 = or i64 %54, 16
  %62 = inttoptr i64 %61 to %"class.v8::internal::Heap"**
  %63 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %62, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %63, i64 %38, i64 %41, i64 %40) #2
  br label %64

64:                                               ; preds = %60, %53, %50
  %65 = and i64 %40, -262144
  %66 = or i64 %65, 8
  %67 = inttoptr i64 %66 to i64*
  %68 = load i64, i64* %67, align 8
  %69 = and i64 %68, 24
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %79, label %71

71:                                               ; preds = %64
  %72 = and i64 %38, -262144
  %73 = or i64 %72, 8
  %74 = inttoptr i64 %73 to i64*
  %75 = load i64, i64* %74, align 8
  %76 = and i64 %75, 24
  %77 = icmp eq i64 %76, 0
  br i1 %77, label %78, label %79

78:                                               ; preds = %71
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %38, i64 %41, i64 %40) #2
  br label %79

79:                                               ; preds = %78, %71, %64
  %80 = load i64, i64* %39, align 8
  %81 = load i64, i64* %2, align 8
  %82 = add i64 %80, 7
  %83 = inttoptr i64 %82 to i32*
  %84 = trunc i64 %81 to i32
  store atomic volatile i32 %84, i32* %83 monotonic, align 4
  %85 = and i64 %81, 1
  %86 = icmp eq i64 %85, 0
  br i1 %86, label %98, label %87

87:                                               ; preds = %79
  %88 = and i64 %80, -262144
  %89 = or i64 %88, 8
  %90 = inttoptr i64 %89 to i64*
  %91 = load i64, i64* %90, align 8
  %92 = and i64 %91, 262144
  %93 = icmp eq i64 %92, 0
  br i1 %93, label %98, label %94

94:                                               ; preds = %87
  %95 = or i64 %88, 16
  %96 = inttoptr i64 %95 to %"class.v8::internal::Heap"**
  %97 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %96, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %97, i64 %80, i64 %82, i64 %81) #2
  br label %98

98:                                               ; preds = %94, %87, %79
  %99 = and i64 %81, -262144
  %100 = or i64 %99, 8
  %101 = inttoptr i64 %100 to i64*
  %102 = load i64, i64* %101, align 8
  %103 = and i64 %102, 24
  %104 = icmp eq i64 %103, 0
  br i1 %104, label %113, label %105

105:                                              ; preds = %98
  %106 = and i64 %80, -262144
  %107 = or i64 %106, 8
  %108 = inttoptr i64 %107 to i64*
  %109 = load i64, i64* %108, align 8
  %110 = and i64 %109, 24
  %111 = icmp eq i64 %110, 0
  br i1 %111, label %112, label %113

112:                                              ; preds = %105
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %80, i64 %82, i64 %81) #2
  br label %113

113:                                              ; preds = %44, %98, %105, %112
  %114 = load i64, i64* %39, align 8
  %115 = add i64 %114, 11
  %116 = inttoptr i64 %115 to i32*
  store i32 %3, i32* %116, align 4
  %117 = load i64, i64* %39, align 8
  %118 = add i64 %117, 15
  %119 = inttoptr i64 %118 to i32*
  store i32 %4, i32* %119, align 4
  %120 = load i64, i64* %39, align 8
  %121 = shl i32 %5, 1
  %122 = add i64 %120, 19
  %123 = inttoptr i64 %122 to i32*
  store atomic volatile i32 %121, i32* %123 monotonic, align 4
  ret i64* %39
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal22TorqueGeneratedFactoryINS0_12LocalFactoryEE20NewExportedSubClass2ENS0_6HandleINS0_10HeapObjectEEES6_iiiNS0_14AllocationTypeE(%"class.v8::internal::TorqueGeneratedFactory.1056"*, i64*, i64*, i32, i32, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %8 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to %"class.v8::internal::FactoryBase.1055"*
  %9 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %0 to i64**
  %10 = load i64*, i64** %9, align 8
  %11 = getelementptr inbounds i64, i64* %10, i64 576
  %12 = load i64, i64* %11, align 8
  %13 = tail call i64 @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE26AllocateRawWithImmortalMapEiNS0_14AllocationTypeENS0_3MapENS0_19AllocationAlignmentE(%"class.v8::internal::FactoryBase.1055"* %8, i32 24, i8 zeroext %6, i64 %12, i32 0) #2
  %14 = icmp eq i8 %6, 0
  %15 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 16, i32 0
  %16 = load i8, i8* %15, align 8, !range !2
  %17 = icmp eq i8 %16, 0
  br i1 %17, label %23, label %18

18:                                               ; preds = %7
  %19 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 8
  %20 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %19 to %"class.v8::internal::LocalHeap"*
  %21 = tail call i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"* %20, i64 %13) #2
  %22 = load i64, i64* %21, align 8
  br label %39

23:                                               ; preds = %7
  %24 = getelementptr inbounds %"class.v8::internal::TorqueGeneratedFactory.1056", %"class.v8::internal::TorqueGeneratedFactory.1056"* %0, i64 48
  %25 = bitcast %"class.v8::internal::TorqueGeneratedFactory.1056"* %24 to %"class.v8::internal::LocalHandles"**
  %26 = load %"class.v8::internal::LocalHandles"*, %"class.v8::internal::LocalHandles"** %25, align 8
  %27 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %26, i64 0, i32 0, i32 0
  %28 = load i64*, i64** %27, align 8
  %29 = getelementptr inbounds %"class.v8::internal::LocalHandles", %"class.v8::internal::LocalHandles"* %26, i64 0, i32 0, i32 1
  %30 = load i64*, i64** %29, align 8
  %31 = icmp eq i64* %28, %30
  br i1 %31, label %32, label %35

32:                                               ; preds = %23
  %33 = tail call i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"* %26) #2
  %34 = load i64*, i64** %27, align 8
  br label %35

35:                                               ; preds = %32, %23
  %36 = phi i64* [ %34, %32 ], [ %28, %23 ]
  %37 = phi i64* [ %33, %32 ], [ %28, %23 ]
  %38 = getelementptr inbounds i64, i64* %36, i64 1
  store i64* %38, i64** %27, align 8
  store i64 %13, i64* %37, align 8
  br label %39

39:                                               ; preds = %18, %35
  %40 = phi i64 [ %22, %18 ], [ %13, %35 ]
  %41 = phi i64* [ %21, %18 ], [ %37, %35 ]
  %42 = load i64, i64* %1, align 8
  %43 = add i64 %40, 3
  %44 = inttoptr i64 %43 to i32*
  %45 = trunc i64 %42 to i32
  store atomic volatile i32 %45, i32* %44 monotonic, align 4
  br i1 %14, label %46, label %52

46:                                               ; preds = %39
  %47 = load i64, i64* %41, align 8
  %48 = load i64, i64* %2, align 8
  %49 = add i64 %47, 7
  %50 = inttoptr i64 %49 to i32*
  %51 = trunc i64 %48 to i32
  store atomic volatile i32 %51, i32* %50 monotonic, align 4
  br label %115

52:                                               ; preds = %39
  %53 = and i64 %42, 1
  %54 = icmp eq i64 %53, 0
  br i1 %54, label %66, label %55

55:                                               ; preds = %52
  %56 = and i64 %40, -262144
  %57 = or i64 %56, 8
  %58 = inttoptr i64 %57 to i64*
  %59 = load i64, i64* %58, align 8
  %60 = and i64 %59, 262144
  %61 = icmp eq i64 %60, 0
  br i1 %61, label %66, label %62

62:                                               ; preds = %55
  %63 = or i64 %56, 16
  %64 = inttoptr i64 %63 to %"class.v8::internal::Heap"**
  %65 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %64, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %65, i64 %40, i64 %43, i64 %42) #2
  br label %66

66:                                               ; preds = %62, %55, %52
  %67 = and i64 %42, -262144
  %68 = or i64 %67, 8
  %69 = inttoptr i64 %68 to i64*
  %70 = load i64, i64* %69, align 8
  %71 = and i64 %70, 24
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %81, label %73

73:                                               ; preds = %66
  %74 = and i64 %40, -262144
  %75 = or i64 %74, 8
  %76 = inttoptr i64 %75 to i64*
  %77 = load i64, i64* %76, align 8
  %78 = and i64 %77, 24
  %79 = icmp eq i64 %78, 0
  br i1 %79, label %80, label %81

80:                                               ; preds = %73
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %40, i64 %43, i64 %42) #2
  br label %81

81:                                               ; preds = %80, %73, %66
  %82 = load i64, i64* %41, align 8
  %83 = load i64, i64* %2, align 8
  %84 = add i64 %82, 7
  %85 = inttoptr i64 %84 to i32*
  %86 = trunc i64 %83 to i32
  store atomic volatile i32 %86, i32* %85 monotonic, align 4
  %87 = and i64 %83, 1
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %100, label %89

89:                                               ; preds = %81
  %90 = and i64 %82, -262144
  %91 = or i64 %90, 8
  %92 = inttoptr i64 %91 to i64*
  %93 = load i64, i64* %92, align 8
  %94 = and i64 %93, 262144
  %95 = icmp eq i64 %94, 0
  br i1 %95, label %100, label %96

96:                                               ; preds = %89
  %97 = or i64 %90, 16
  %98 = inttoptr i64 %97 to %"class.v8::internal::Heap"**
  %99 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %98, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %99, i64 %82, i64 %84, i64 %83) #2
  br label %100

100:                                              ; preds = %96, %89, %81
  %101 = and i64 %83, -262144
  %102 = or i64 %101, 8
  %103 = inttoptr i64 %102 to i64*
  %104 = load i64, i64* %103, align 8
  %105 = and i64 %104, 24
  %106 = icmp eq i64 %105, 0
  br i1 %106, label %115, label %107

107:                                              ; preds = %100
  %108 = and i64 %82, -262144
  %109 = or i64 %108, 8
  %110 = inttoptr i64 %109 to i64*
  %111 = load i64, i64* %110, align 8
  %112 = and i64 %111, 24
  %113 = icmp eq i64 %112, 0
  br i1 %113, label %114, label %115

114:                                              ; preds = %107
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %82, i64 %84, i64 %83) #2
  br label %115

115:                                              ; preds = %46, %100, %107, %114
  %116 = load i64, i64* %41, align 8
  %117 = add i64 %116, 11
  %118 = inttoptr i64 %117 to i32*
  store i32 %3, i32* %118, align 4
  %119 = load i64, i64* %41, align 8
  %120 = add i64 %119, 15
  %121 = inttoptr i64 %120 to i32*
  store i32 %4, i32* %121, align 4
  %122 = load i64, i64* %41, align 8
  %123 = shl i32 %5, 1
  %124 = add i64 %122, 19
  %125 = inttoptr i64 %124 to i32*
  store atomic volatile i32 %123, i32* %125 monotonic, align 4
  ret i64* %41
}

declare void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"*, i64, i64, i64) local_unnamed_addr #1

declare void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64, i64, i64) local_unnamed_addr #1

declare i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"*, i64) local_unnamed_addr #1

declare i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"*) local_unnamed_addr #1

declare i64* @_ZN2v88internal16LocalHandleScope19GetMainThreadHandleEPNS0_9LocalHeapEm(%"class.v8::internal::LocalHeap"*, i64) local_unnamed_addr #1

declare i64* @_ZN2v88internal12LocalHandles8AddBlockEv(%"class.v8::internal::LocalHandles"*) local_unnamed_addr #1

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i8 0, i8 2}
