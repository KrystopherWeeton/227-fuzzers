; ModuleID = '../../third_party/libvpx/source/libvpx/vp9/common/x86/vp9_idct_intrin_sse2.c'
source_filename = "../../third_party/libvpx/source/libvpx/vp9/common/x86/vp9_idct_intrin_sse2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_iht4x4_16_add_sse2(i32* nocapture readonly, i8* nocapture, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [2 x <2 x i64>], align 16
  %6 = bitcast [2 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %6) #5
  %7 = getelementptr inbounds [2 x <2 x i64>], [2 x <2 x i64>]* %5, i64 0, i64 0
  %8 = getelementptr inbounds [2 x <2 x i64>], [2 x <2 x i64>]* %5, i64 0, i64 1
  %9 = bitcast i32* %0 to <4 x i32>*
  %10 = load <4 x i32>, <4 x i32>* %9, align 16
  %11 = getelementptr inbounds i32, i32* %0, i64 4
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 16
  %14 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %10, <4 x i32> %13) #5
  %15 = bitcast [2 x <2 x i64>]* %5 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 16
  %16 = getelementptr inbounds i32, i32* %0, i64 8
  %17 = bitcast i32* %16 to <4 x i32>*
  %18 = load <4 x i32>, <4 x i32>* %17, align 16
  %19 = getelementptr inbounds i32, i32* %0, i64 12
  %20 = bitcast i32* %19 to <4 x i32>*
  %21 = load <4 x i32>, <4 x i32>* %20, align 16
  %22 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %18, <4 x i32> %21) #5
  %23 = bitcast <2 x i64>* %8 to <8 x i16>*
  store <8 x i16> %22, <8 x i16>* %23, align 16
  switch i32 %3, label %27 [
    i32 0, label %24
    i32 1, label %25
    i32 2, label %26
  ]

24:                                               ; preds = %4
  call void @idct4_sse2(<2 x i64>* nonnull %7) #5
  call void @idct4_sse2(<2 x i64>* nonnull %7) #5
  br label %28

25:                                               ; preds = %4
  call void @idct4_sse2(<2 x i64>* nonnull %7) #5
  call void @iadst4_sse2(<2 x i64>* nonnull %7) #5
  br label %28

26:                                               ; preds = %4
  call void @iadst4_sse2(<2 x i64>* nonnull %7) #5
  call void @idct4_sse2(<2 x i64>* nonnull %7) #5
  br label %28

27:                                               ; preds = %4
  call void @iadst4_sse2(<2 x i64>* nonnull %7) #5
  call void @iadst4_sse2(<2 x i64>* nonnull %7) #5
  br label %28

28:                                               ; preds = %27, %26, %25, %24
  %29 = load <8 x i16>, <8 x i16>* %15, align 16
  %30 = add <8 x i16> %29, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %31 = load <8 x i16>, <8 x i16>* %23, align 16
  %32 = add <8 x i16> %31, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %33 = ashr <8 x i16> %30, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %34 = ashr <8 x i16> %32, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %35 = bitcast i8* %1 to i32*
  %36 = load i32, i32* %35, align 4
  %37 = insertelement <4 x i32> undef, i32 %36, i32 0
  %38 = mul nsw i32 %2, 3
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds i8, i8* %1, i64 %39
  %41 = bitcast i8* %40 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = sext i32 %2 to i64
  %44 = getelementptr inbounds i8, i8* %1, i64 %43
  %45 = bitcast i8* %44 to i32*
  %46 = load i32, i32* %45, align 4
  %47 = insertelement <4 x i32> %37, i32 %46, i32 1
  %48 = shl nsw i32 %2, 1
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds i8, i8* %1, i64 %49
  %51 = bitcast i8* %50 to i32*
  %52 = load i32, i32* %51, align 4
  %53 = insertelement <4 x i32> undef, i32 %52, i32 0
  %54 = insertelement <4 x i32> %53, i32 %42, i32 1
  %55 = bitcast <4 x i32> %47 to <16 x i8>
  %56 = shufflevector <16 x i8> %55, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %57 = bitcast <4 x i32> %54 to <16 x i8>
  %58 = shufflevector <16 x i8> %57, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %59 = bitcast <16 x i8> %56 to <8 x i16>
  %60 = add <8 x i16> %33, %59
  %61 = bitcast <16 x i8> %58 to <8 x i16>
  %62 = add <8 x i16> %34, %61
  %63 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %60, <8 x i16> %62) #5
  %64 = bitcast <16 x i8> %63 to <4 x i32>
  %65 = extractelement <4 x i32> %64, i32 0
  store i32 %65, i32* %35, align 4
  %66 = shufflevector <16 x i8> %63, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %67 = bitcast <16 x i8> %66 to <4 x i32>
  %68 = extractelement <4 x i32> %67, i32 0
  store i32 %68, i32* %45, align 4
  %69 = shufflevector <16 x i8> %66, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %70 = bitcast <16 x i8> %69 to <4 x i32>
  %71 = extractelement <4 x i32> %70, i32 0
  store i32 %71, i32* %51, align 4
  %72 = shufflevector <16 x i8> %69, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %73 = bitcast <16 x i8> %72 to <4 x i32>
  %74 = extractelement <4 x i32> %73, i32 0
  store i32 %74, i32* %41, align 4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %6) #5
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

declare void @idct4_sse2(<2 x i64>*) local_unnamed_addr #2

declare void @iadst4_sse2(<2 x i64>*) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_iht8x8_64_add_sse2(i32* nocapture readonly, i8* nocapture, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [8 x <2 x i64>], align 16
  %6 = bitcast [8 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %6) #5
  %7 = bitcast i32* %0 to <4 x i32>*
  %8 = load <4 x i32>, <4 x i32>* %7, align 16
  %9 = getelementptr inbounds i32, i32* %0, i64 4
  %10 = bitcast i32* %9 to <4 x i32>*
  %11 = load <4 x i32>, <4 x i32>* %10, align 16
  %12 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %8, <4 x i32> %11) #5
  %13 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 0
  %14 = bitcast [8 x <2 x i64>]* %5 to <8 x i16>*
  store <8 x i16> %12, <8 x i16>* %14, align 16
  %15 = getelementptr inbounds i32, i32* %0, i64 8
  %16 = bitcast i32* %15 to <4 x i32>*
  %17 = load <4 x i32>, <4 x i32>* %16, align 16
  %18 = getelementptr inbounds i32, i32* %0, i64 12
  %19 = bitcast i32* %18 to <4 x i32>*
  %20 = load <4 x i32>, <4 x i32>* %19, align 16
  %21 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %17, <4 x i32> %20) #5
  %22 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 1
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  store <8 x i16> %21, <8 x i16>* %23, align 16
  %24 = getelementptr inbounds i32, i32* %0, i64 16
  %25 = bitcast i32* %24 to <4 x i32>*
  %26 = load <4 x i32>, <4 x i32>* %25, align 16
  %27 = getelementptr inbounds i32, i32* %0, i64 20
  %28 = bitcast i32* %27 to <4 x i32>*
  %29 = load <4 x i32>, <4 x i32>* %28, align 16
  %30 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %26, <4 x i32> %29) #5
  %31 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 2
  %32 = bitcast <2 x i64>* %31 to <8 x i16>*
  store <8 x i16> %30, <8 x i16>* %32, align 16
  %33 = getelementptr inbounds i32, i32* %0, i64 24
  %34 = bitcast i32* %33 to <4 x i32>*
  %35 = load <4 x i32>, <4 x i32>* %34, align 16
  %36 = getelementptr inbounds i32, i32* %0, i64 28
  %37 = bitcast i32* %36 to <4 x i32>*
  %38 = load <4 x i32>, <4 x i32>* %37, align 16
  %39 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %35, <4 x i32> %38) #5
  %40 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 3
  %41 = bitcast <2 x i64>* %40 to <8 x i16>*
  store <8 x i16> %39, <8 x i16>* %41, align 16
  %42 = getelementptr inbounds i32, i32* %0, i64 32
  %43 = bitcast i32* %42 to <4 x i32>*
  %44 = load <4 x i32>, <4 x i32>* %43, align 16
  %45 = getelementptr inbounds i32, i32* %0, i64 36
  %46 = bitcast i32* %45 to <4 x i32>*
  %47 = load <4 x i32>, <4 x i32>* %46, align 16
  %48 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %44, <4 x i32> %47) #5
  %49 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 4
  %50 = bitcast <2 x i64>* %49 to <8 x i16>*
  store <8 x i16> %48, <8 x i16>* %50, align 16
  %51 = getelementptr inbounds i32, i32* %0, i64 40
  %52 = bitcast i32* %51 to <4 x i32>*
  %53 = load <4 x i32>, <4 x i32>* %52, align 16
  %54 = getelementptr inbounds i32, i32* %0, i64 44
  %55 = bitcast i32* %54 to <4 x i32>*
  %56 = load <4 x i32>, <4 x i32>* %55, align 16
  %57 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %53, <4 x i32> %56) #5
  %58 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 5
  %59 = bitcast <2 x i64>* %58 to <8 x i16>*
  store <8 x i16> %57, <8 x i16>* %59, align 16
  %60 = getelementptr inbounds i32, i32* %0, i64 48
  %61 = bitcast i32* %60 to <4 x i32>*
  %62 = load <4 x i32>, <4 x i32>* %61, align 16
  %63 = getelementptr inbounds i32, i32* %0, i64 52
  %64 = bitcast i32* %63 to <4 x i32>*
  %65 = load <4 x i32>, <4 x i32>* %64, align 16
  %66 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %62, <4 x i32> %65) #5
  %67 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 6
  %68 = bitcast <2 x i64>* %67 to <8 x i16>*
  store <8 x i16> %66, <8 x i16>* %68, align 16
  %69 = getelementptr inbounds i32, i32* %0, i64 56
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 16
  %72 = getelementptr inbounds i32, i32* %0, i64 60
  %73 = bitcast i32* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 16
  %75 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %71, <4 x i32> %74) #5
  %76 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 7
  %77 = bitcast <2 x i64>* %76 to <8 x i16>*
  store <8 x i16> %75, <8 x i16>* %77, align 16
  switch i32 %3, label %81 [
    i32 0, label %78
    i32 1, label %79
    i32 2, label %80
  ]

78:                                               ; preds = %4
  call void @vpx_idct8_sse2(<2 x i64>* nonnull %13) #5
  call void @vpx_idct8_sse2(<2 x i64>* nonnull %13) #5
  br label %82

79:                                               ; preds = %4
  call void @vpx_idct8_sse2(<2 x i64>* nonnull %13) #5
  call void @iadst8_sse2(<2 x i64>* nonnull %13) #5
  br label %82

80:                                               ; preds = %4
  call void @iadst8_sse2(<2 x i64>* nonnull %13) #5
  call void @vpx_idct8_sse2(<2 x i64>* nonnull %13) #5
  br label %82

81:                                               ; preds = %4
  call void @iadst8_sse2(<2 x i64>* nonnull %13) #5
  call void @iadst8_sse2(<2 x i64>* nonnull %13) #5
  br label %82

82:                                               ; preds = %81, %80, %79, %78
  %83 = load <8 x i16>, <8 x i16>* %14, align 16
  %84 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %83, <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>) #5
  %85 = load <8 x i16>, <8 x i16>* %23, align 16
  %86 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %85, <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>) #5
  %87 = load <8 x i16>, <8 x i16>* %32, align 16
  %88 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %87, <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>) #5
  %89 = load <8 x i16>, <8 x i16>* %41, align 16
  %90 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %89, <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>) #5
  %91 = load <8 x i16>, <8 x i16>* %50, align 16
  %92 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %91, <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>) #5
  %93 = load <8 x i16>, <8 x i16>* %59, align 16
  %94 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %93, <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>) #5
  %95 = load <8 x i16>, <8 x i16>* %68, align 16
  %96 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %95, <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>) #5
  %97 = load <8 x i16>, <8 x i16>* %77, align 16
  %98 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %97, <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>) #5
  %99 = ashr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  store <8 x i16> %99, <8 x i16>* %14, align 16
  %100 = ashr <8 x i16> %86, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  store <8 x i16> %100, <8 x i16>* %23, align 16
  %101 = ashr <8 x i16> %88, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  store <8 x i16> %101, <8 x i16>* %32, align 16
  %102 = ashr <8 x i16> %90, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  store <8 x i16> %102, <8 x i16>* %41, align 16
  %103 = ashr <8 x i16> %92, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  store <8 x i16> %103, <8 x i16>* %50, align 16
  %104 = ashr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  store <8 x i16> %104, <8 x i16>* %59, align 16
  %105 = ashr <8 x i16> %96, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  store <8 x i16> %105, <8 x i16>* %68, align 16
  %106 = ashr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  store <8 x i16> %106, <8 x i16>* %77, align 16
  %107 = bitcast i8* %1 to i64*
  %108 = load i64, i64* %107, align 1
  %109 = insertelement <2 x i64> undef, i64 %108, i32 0
  %110 = bitcast <2 x i64> %109 to <16 x i8>
  %111 = shufflevector <16 x i8> %110, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %112 = bitcast <16 x i8> %111 to <8 x i16>
  %113 = add <8 x i16> %99, %112
  %114 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %113, <8 x i16> undef) #5
  %115 = bitcast <16 x i8> %114 to <2 x i64>
  %116 = extractelement <2 x i64> %115, i32 0
  store i64 %116, i64* %107, align 1
  %117 = sext i32 %2 to i64
  %118 = getelementptr inbounds i8, i8* %1, i64 %117
  %119 = bitcast i8* %118 to i64*
  %120 = load i64, i64* %119, align 1
  %121 = insertelement <2 x i64> undef, i64 %120, i32 0
  %122 = bitcast <2 x i64> %121 to <16 x i8>
  %123 = shufflevector <16 x i8> %122, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %124 = bitcast <16 x i8> %123 to <8 x i16>
  %125 = add <8 x i16> %100, %124
  %126 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %125, <8 x i16> undef) #5
  %127 = bitcast <16 x i8> %126 to <2 x i64>
  %128 = extractelement <2 x i64> %127, i32 0
  store i64 %128, i64* %119, align 1
  %129 = shl nsw i32 %2, 1
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds i8, i8* %1, i64 %130
  %132 = bitcast i8* %131 to i64*
  %133 = load i64, i64* %132, align 1
  %134 = insertelement <2 x i64> undef, i64 %133, i32 0
  %135 = bitcast <2 x i64> %134 to <16 x i8>
  %136 = shufflevector <16 x i8> %135, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %137 = bitcast <16 x i8> %136 to <8 x i16>
  %138 = add <8 x i16> %101, %137
  %139 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %138, <8 x i16> undef) #5
  %140 = bitcast <16 x i8> %139 to <2 x i64>
  %141 = extractelement <2 x i64> %140, i32 0
  store i64 %141, i64* %132, align 1
  %142 = mul nsw i32 %2, 3
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds i8, i8* %1, i64 %143
  %145 = bitcast i8* %144 to i64*
  %146 = load i64, i64* %145, align 1
  %147 = insertelement <2 x i64> undef, i64 %146, i32 0
  %148 = bitcast <2 x i64> %147 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %150 = bitcast <16 x i8> %149 to <8 x i16>
  %151 = add <8 x i16> %102, %150
  %152 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %151, <8 x i16> undef) #5
  %153 = bitcast <16 x i8> %152 to <2 x i64>
  %154 = extractelement <2 x i64> %153, i32 0
  store i64 %154, i64* %145, align 1
  %155 = shl nsw i32 %2, 2
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds i8, i8* %1, i64 %156
  %158 = bitcast i8* %157 to i64*
  %159 = load i64, i64* %158, align 1
  %160 = insertelement <2 x i64> undef, i64 %159, i32 0
  %161 = bitcast <2 x i64> %160 to <16 x i8>
  %162 = shufflevector <16 x i8> %161, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %163 = bitcast <16 x i8> %162 to <8 x i16>
  %164 = add <8 x i16> %103, %163
  %165 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %164, <8 x i16> undef) #5
  %166 = bitcast <16 x i8> %165 to <2 x i64>
  %167 = extractelement <2 x i64> %166, i32 0
  store i64 %167, i64* %158, align 1
  %168 = mul nsw i32 %2, 5
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds i8, i8* %1, i64 %169
  %171 = bitcast i8* %170 to i64*
  %172 = load i64, i64* %171, align 1
  %173 = insertelement <2 x i64> undef, i64 %172, i32 0
  %174 = bitcast <2 x i64> %173 to <16 x i8>
  %175 = shufflevector <16 x i8> %174, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %176 = bitcast <16 x i8> %175 to <8 x i16>
  %177 = add <8 x i16> %104, %176
  %178 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %177, <8 x i16> undef) #5
  %179 = bitcast <16 x i8> %178 to <2 x i64>
  %180 = extractelement <2 x i64> %179, i32 0
  store i64 %180, i64* %171, align 1
  %181 = mul nsw i32 %2, 6
  %182 = sext i32 %181 to i64
  %183 = getelementptr inbounds i8, i8* %1, i64 %182
  %184 = bitcast i8* %183 to i64*
  %185 = load i64, i64* %184, align 1
  %186 = insertelement <2 x i64> undef, i64 %185, i32 0
  %187 = bitcast <2 x i64> %186 to <16 x i8>
  %188 = shufflevector <16 x i8> %187, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %189 = bitcast <16 x i8> %188 to <8 x i16>
  %190 = add <8 x i16> %105, %189
  %191 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %190, <8 x i16> undef) #5
  %192 = bitcast <16 x i8> %191 to <2 x i64>
  %193 = extractelement <2 x i64> %192, i32 0
  store i64 %193, i64* %184, align 1
  %194 = mul nsw i32 %2, 7
  %195 = sext i32 %194 to i64
  %196 = getelementptr inbounds i8, i8* %1, i64 %195
  %197 = bitcast i8* %196 to i64*
  %198 = load i64, i64* %197, align 1
  %199 = insertelement <2 x i64> undef, i64 %198, i32 0
  %200 = bitcast <2 x i64> %199 to <16 x i8>
  %201 = shufflevector <16 x i8> %200, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %202 = bitcast <16 x i8> %201 to <8 x i16>
  %203 = add <8 x i16> %106, %202
  %204 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %203, <8 x i16> undef) #5
  %205 = bitcast <16 x i8> %204 to <2 x i64>
  %206 = extractelement <2 x i64> %205, i32 0
  store i64 %206, i64* %197, align 1
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %6) #5
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

declare void @vpx_idct8_sse2(<2 x i64>*) local_unnamed_addr #2

declare void @iadst8_sse2(<2 x i64>*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_iht16x16_256_add_sse2(i32* readonly, i8* nocapture, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %7) #5
  %8 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 9
  %9 = bitcast <2 x i64>* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 112, i1 false)
  %10 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %10) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 -86, i64 256, i1 false)
  %11 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  %12 = bitcast i32* %0 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 16
  %14 = getelementptr inbounds i32, i32* %0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 16
  %17 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %13, <4 x i32> %16) #5
  %18 = bitcast [16 x <2 x i64>]* %5 to <8 x i16>*
  store <8 x i16> %17, <8 x i16>* %18, align 16
  %19 = getelementptr inbounds i32, i32* %0, i64 16
  %20 = bitcast i32* %19 to <4 x i32>*
  %21 = load <4 x i32>, <4 x i32>* %20, align 16
  %22 = getelementptr inbounds i32, i32* %0, i64 20
  %23 = bitcast i32* %22 to <4 x i32>*
  %24 = load <4 x i32>, <4 x i32>* %23, align 16
  %25 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %21, <4 x i32> %24) #5
  %26 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 1
  %27 = bitcast <2 x i64>* %26 to <8 x i16>*
  store <8 x i16> %25, <8 x i16>* %27, align 16
  %28 = getelementptr inbounds i32, i32* %0, i64 32
  %29 = bitcast i32* %28 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 16
  %31 = getelementptr inbounds i32, i32* %0, i64 36
  %32 = bitcast i32* %31 to <4 x i32>*
  %33 = load <4 x i32>, <4 x i32>* %32, align 16
  %34 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %30, <4 x i32> %33) #5
  %35 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 2
  %36 = bitcast <2 x i64>* %35 to <8 x i16>*
  store <8 x i16> %34, <8 x i16>* %36, align 16
  %37 = getelementptr inbounds i32, i32* %0, i64 48
  %38 = bitcast i32* %37 to <4 x i32>*
  %39 = load <4 x i32>, <4 x i32>* %38, align 16
  %40 = getelementptr inbounds i32, i32* %0, i64 52
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 16
  %43 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %39, <4 x i32> %42) #5
  %44 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 3
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  store <8 x i16> %43, <8 x i16>* %45, align 16
  %46 = getelementptr inbounds i32, i32* %0, i64 64
  %47 = bitcast i32* %46 to <4 x i32>*
  %48 = load <4 x i32>, <4 x i32>* %47, align 16
  %49 = getelementptr inbounds i32, i32* %0, i64 68
  %50 = bitcast i32* %49 to <4 x i32>*
  %51 = load <4 x i32>, <4 x i32>* %50, align 16
  %52 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %48, <4 x i32> %51) #5
  %53 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 4
  %54 = bitcast <2 x i64>* %53 to <8 x i16>*
  store <8 x i16> %52, <8 x i16>* %54, align 16
  %55 = getelementptr inbounds i32, i32* %0, i64 80
  %56 = bitcast i32* %55 to <4 x i32>*
  %57 = load <4 x i32>, <4 x i32>* %56, align 16
  %58 = getelementptr inbounds i32, i32* %0, i64 84
  %59 = bitcast i32* %58 to <4 x i32>*
  %60 = load <4 x i32>, <4 x i32>* %59, align 16
  %61 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %57, <4 x i32> %60) #5
  %62 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 5
  %63 = bitcast <2 x i64>* %62 to <8 x i16>*
  store <8 x i16> %61, <8 x i16>* %63, align 16
  %64 = getelementptr inbounds i32, i32* %0, i64 96
  %65 = bitcast i32* %64 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = getelementptr inbounds i32, i32* %0, i64 100
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  %70 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %66, <4 x i32> %69) #5
  %71 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 6
  %72 = bitcast <2 x i64>* %71 to <8 x i16>*
  store <8 x i16> %70, <8 x i16>* %72, align 16
  %73 = getelementptr inbounds i32, i32* %0, i64 112
  %74 = bitcast i32* %73 to <4 x i32>*
  %75 = load <4 x i32>, <4 x i32>* %74, align 16
  %76 = getelementptr inbounds i32, i32* %0, i64 116
  %77 = bitcast i32* %76 to <4 x i32>*
  %78 = load <4 x i32>, <4 x i32>* %77, align 16
  %79 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %75, <4 x i32> %78) #5
  %80 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 7
  %81 = bitcast <2 x i64>* %80 to <8 x i16>*
  store <8 x i16> %79, <8 x i16>* %81, align 16
  %82 = getelementptr inbounds i32, i32* %0, i64 128
  %83 = bitcast i32* %82 to <4 x i32>*
  %84 = load <4 x i32>, <4 x i32>* %83, align 16
  %85 = getelementptr inbounds i32, i32* %0, i64 132
  %86 = bitcast i32* %85 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16
  %88 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %84, <4 x i32> %87) #5
  %89 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 8
  %90 = bitcast <2 x i64>* %89 to <8 x i16>*
  store <8 x i16> %88, <8 x i16>* %90, align 16
  %91 = getelementptr inbounds i32, i32* %0, i64 144
  %92 = bitcast i32* %91 to <4 x i32>*
  %93 = load <4 x i32>, <4 x i32>* %92, align 16
  %94 = getelementptr inbounds i32, i32* %0, i64 148
  %95 = bitcast i32* %94 to <4 x i32>*
  %96 = load <4 x i32>, <4 x i32>* %95, align 16
  %97 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %93, <4 x i32> %96) #5
  %98 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 9
  %99 = bitcast <2 x i64>* %98 to <8 x i16>*
  store <8 x i16> %97, <8 x i16>* %99, align 16
  %100 = getelementptr inbounds i32, i32* %0, i64 160
  %101 = bitcast i32* %100 to <4 x i32>*
  %102 = load <4 x i32>, <4 x i32>* %101, align 16
  %103 = getelementptr inbounds i32, i32* %0, i64 164
  %104 = bitcast i32* %103 to <4 x i32>*
  %105 = load <4 x i32>, <4 x i32>* %104, align 16
  %106 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %102, <4 x i32> %105) #5
  %107 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 10
  %108 = bitcast <2 x i64>* %107 to <8 x i16>*
  store <8 x i16> %106, <8 x i16>* %108, align 16
  %109 = getelementptr inbounds i32, i32* %0, i64 176
  %110 = bitcast i32* %109 to <4 x i32>*
  %111 = load <4 x i32>, <4 x i32>* %110, align 16
  %112 = getelementptr inbounds i32, i32* %0, i64 180
  %113 = bitcast i32* %112 to <4 x i32>*
  %114 = load <4 x i32>, <4 x i32>* %113, align 16
  %115 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %111, <4 x i32> %114) #5
  %116 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 11
  %117 = bitcast <2 x i64>* %116 to <8 x i16>*
  store <8 x i16> %115, <8 x i16>* %117, align 16
  %118 = getelementptr inbounds i32, i32* %0, i64 192
  %119 = bitcast i32* %118 to <4 x i32>*
  %120 = load <4 x i32>, <4 x i32>* %119, align 16
  %121 = getelementptr inbounds i32, i32* %0, i64 196
  %122 = bitcast i32* %121 to <4 x i32>*
  %123 = load <4 x i32>, <4 x i32>* %122, align 16
  %124 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %120, <4 x i32> %123) #5
  %125 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 12
  %126 = bitcast <2 x i64>* %125 to <8 x i16>*
  store <8 x i16> %124, <8 x i16>* %126, align 16
  %127 = getelementptr inbounds i32, i32* %0, i64 208
  %128 = bitcast i32* %127 to <4 x i32>*
  %129 = load <4 x i32>, <4 x i32>* %128, align 16
  %130 = getelementptr inbounds i32, i32* %0, i64 212
  %131 = bitcast i32* %130 to <4 x i32>*
  %132 = load <4 x i32>, <4 x i32>* %131, align 16
  %133 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %129, <4 x i32> %132) #5
  %134 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 13
  %135 = bitcast <2 x i64>* %134 to <8 x i16>*
  store <8 x i16> %133, <8 x i16>* %135, align 16
  %136 = getelementptr inbounds i32, i32* %0, i64 224
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 16
  %139 = getelementptr inbounds i32, i32* %0, i64 228
  %140 = bitcast i32* %139 to <4 x i32>*
  %141 = load <4 x i32>, <4 x i32>* %140, align 16
  %142 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %138, <4 x i32> %141) #5
  %143 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 14
  %144 = bitcast <2 x i64>* %143 to <8 x i16>*
  store <8 x i16> %142, <8 x i16>* %144, align 16
  %145 = getelementptr inbounds i32, i32* %0, i64 240
  %146 = bitcast i32* %145 to <4 x i32>*
  %147 = load <4 x i32>, <4 x i32>* %146, align 16
  %148 = getelementptr inbounds i32, i32* %0, i64 244
  %149 = bitcast i32* %148 to <4 x i32>*
  %150 = load <4 x i32>, <4 x i32>* %149, align 16
  %151 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %147, <4 x i32> %150) #5
  %152 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 15
  %153 = bitcast <2 x i64>* %152 to <8 x i16>*
  store <8 x i16> %151, <8 x i16>* %153, align 16
  %154 = getelementptr inbounds i32, i32* %0, i64 8
  %155 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %156 = bitcast i32* %154 to <4 x i32>*
  %157 = load <4 x i32>, <4 x i32>* %156, align 16
  %158 = getelementptr inbounds i32, i32* %0, i64 12
  %159 = bitcast i32* %158 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %157, <4 x i32> %160) #5
  %162 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  store <8 x i16> %161, <8 x i16>* %162, align 16
  %163 = getelementptr inbounds i32, i32* %0, i64 24
  %164 = bitcast i32* %163 to <4 x i32>*
  %165 = load <4 x i32>, <4 x i32>* %164, align 16
  %166 = getelementptr inbounds i32, i32* %0, i64 28
  %167 = bitcast i32* %166 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %165, <4 x i32> %168) #5
  %170 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %171 = bitcast <2 x i64>* %170 to <8 x i16>*
  store <8 x i16> %169, <8 x i16>* %171, align 16
  %172 = getelementptr inbounds i32, i32* %0, i64 40
  %173 = bitcast i32* %172 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = getelementptr inbounds i32, i32* %0, i64 44
  %176 = bitcast i32* %175 to <4 x i32>*
  %177 = load <4 x i32>, <4 x i32>* %176, align 16
  %178 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %174, <4 x i32> %177) #5
  %179 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %180 = bitcast <2 x i64>* %179 to <8 x i16>*
  store <8 x i16> %178, <8 x i16>* %180, align 16
  %181 = getelementptr inbounds i32, i32* %0, i64 56
  %182 = bitcast i32* %181 to <4 x i32>*
  %183 = load <4 x i32>, <4 x i32>* %182, align 16
  %184 = getelementptr inbounds i32, i32* %0, i64 60
  %185 = bitcast i32* %184 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %183, <4 x i32> %186) #5
  %188 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %189 = bitcast <2 x i64>* %188 to <8 x i16>*
  store <8 x i16> %187, <8 x i16>* %189, align 16
  %190 = getelementptr inbounds i32, i32* %0, i64 72
  %191 = bitcast i32* %190 to <4 x i32>*
  %192 = load <4 x i32>, <4 x i32>* %191, align 16
  %193 = getelementptr inbounds i32, i32* %0, i64 76
  %194 = bitcast i32* %193 to <4 x i32>*
  %195 = load <4 x i32>, <4 x i32>* %194, align 16
  %196 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %192, <4 x i32> %195) #5
  %197 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %198 = bitcast <2 x i64>* %197 to <8 x i16>*
  store <8 x i16> %196, <8 x i16>* %198, align 16
  %199 = getelementptr inbounds i32, i32* %0, i64 88
  %200 = bitcast i32* %199 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = getelementptr inbounds i32, i32* %0, i64 92
  %203 = bitcast i32* %202 to <4 x i32>*
  %204 = load <4 x i32>, <4 x i32>* %203, align 16
  %205 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %201, <4 x i32> %204) #5
  %206 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %207 = bitcast <2 x i64>* %206 to <8 x i16>*
  store <8 x i16> %205, <8 x i16>* %207, align 16
  %208 = getelementptr inbounds i32, i32* %0, i64 104
  %209 = bitcast i32* %208 to <4 x i32>*
  %210 = load <4 x i32>, <4 x i32>* %209, align 16
  %211 = getelementptr inbounds i32, i32* %0, i64 108
  %212 = bitcast i32* %211 to <4 x i32>*
  %213 = load <4 x i32>, <4 x i32>* %212, align 16
  %214 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %210, <4 x i32> %213) #5
  %215 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %216 = bitcast <2 x i64>* %215 to <8 x i16>*
  store <8 x i16> %214, <8 x i16>* %216, align 16
  %217 = getelementptr inbounds i32, i32* %0, i64 120
  %218 = bitcast i32* %217 to <4 x i32>*
  %219 = load <4 x i32>, <4 x i32>* %218, align 16
  %220 = getelementptr inbounds i32, i32* %0, i64 124
  %221 = bitcast i32* %220 to <4 x i32>*
  %222 = load <4 x i32>, <4 x i32>* %221, align 16
  %223 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %219, <4 x i32> %222) #5
  %224 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %225 = bitcast <2 x i64>* %224 to <8 x i16>*
  store <8 x i16> %223, <8 x i16>* %225, align 16
  %226 = getelementptr inbounds i32, i32* %0, i64 136
  %227 = bitcast i32* %226 to <4 x i32>*
  %228 = load <4 x i32>, <4 x i32>* %227, align 16
  %229 = getelementptr inbounds i32, i32* %0, i64 140
  %230 = bitcast i32* %229 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %228, <4 x i32> %231) #5
  %233 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %234 = bitcast <2 x i64>* %233 to <8 x i16>*
  store <8 x i16> %232, <8 x i16>* %234, align 16
  %235 = getelementptr inbounds i32, i32* %0, i64 152
  %236 = bitcast i32* %235 to <4 x i32>*
  %237 = load <4 x i32>, <4 x i32>* %236, align 16
  %238 = getelementptr inbounds i32, i32* %0, i64 156
  %239 = bitcast i32* %238 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %237, <4 x i32> %240) #5
  %242 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %243 = bitcast <2 x i64>* %242 to <8 x i16>*
  store <8 x i16> %241, <8 x i16>* %243, align 16
  %244 = getelementptr inbounds i32, i32* %0, i64 168
  %245 = bitcast i32* %244 to <4 x i32>*
  %246 = load <4 x i32>, <4 x i32>* %245, align 16
  %247 = getelementptr inbounds i32, i32* %0, i64 172
  %248 = bitcast i32* %247 to <4 x i32>*
  %249 = load <4 x i32>, <4 x i32>* %248, align 16
  %250 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %246, <4 x i32> %249) #5
  %251 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %252 = bitcast <2 x i64>* %251 to <8 x i16>*
  store <8 x i16> %250, <8 x i16>* %252, align 16
  %253 = getelementptr inbounds i32, i32* %0, i64 184
  %254 = bitcast i32* %253 to <4 x i32>*
  %255 = load <4 x i32>, <4 x i32>* %254, align 16
  %256 = getelementptr inbounds i32, i32* %0, i64 188
  %257 = bitcast i32* %256 to <4 x i32>*
  %258 = load <4 x i32>, <4 x i32>* %257, align 16
  %259 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %255, <4 x i32> %258) #5
  %260 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %261 = bitcast <2 x i64>* %260 to <8 x i16>*
  store <8 x i16> %259, <8 x i16>* %261, align 16
  %262 = getelementptr inbounds i32, i32* %0, i64 200
  %263 = bitcast i32* %262 to <4 x i32>*
  %264 = load <4 x i32>, <4 x i32>* %263, align 16
  %265 = getelementptr inbounds i32, i32* %0, i64 204
  %266 = bitcast i32* %265 to <4 x i32>*
  %267 = load <4 x i32>, <4 x i32>* %266, align 16
  %268 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %264, <4 x i32> %267) #5
  %269 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %270 = bitcast <2 x i64>* %269 to <8 x i16>*
  store <8 x i16> %268, <8 x i16>* %270, align 16
  %271 = getelementptr inbounds i32, i32* %0, i64 216
  %272 = bitcast i32* %271 to <4 x i32>*
  %273 = load <4 x i32>, <4 x i32>* %272, align 16
  %274 = getelementptr inbounds i32, i32* %0, i64 220
  %275 = bitcast i32* %274 to <4 x i32>*
  %276 = load <4 x i32>, <4 x i32>* %275, align 16
  %277 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %273, <4 x i32> %276) #5
  %278 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %279 = bitcast <2 x i64>* %278 to <8 x i16>*
  store <8 x i16> %277, <8 x i16>* %279, align 16
  %280 = getelementptr inbounds i32, i32* %0, i64 232
  %281 = bitcast i32* %280 to <4 x i32>*
  %282 = load <4 x i32>, <4 x i32>* %281, align 16
  %283 = getelementptr inbounds i32, i32* %0, i64 236
  %284 = bitcast i32* %283 to <4 x i32>*
  %285 = load <4 x i32>, <4 x i32>* %284, align 16
  %286 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %282, <4 x i32> %285) #5
  %287 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %288 = bitcast <2 x i64>* %287 to <8 x i16>*
  store <8 x i16> %286, <8 x i16>* %288, align 16
  %289 = getelementptr inbounds i32, i32* %0, i64 248
  %290 = bitcast i32* %289 to <4 x i32>*
  %291 = load <4 x i32>, <4 x i32>* %290, align 16
  %292 = getelementptr inbounds i32, i32* %0, i64 252
  %293 = bitcast i32* %292 to <4 x i32>*
  %294 = load <4 x i32>, <4 x i32>* %293, align 16
  %295 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %291, <4 x i32> %294) #5
  %296 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %297 = bitcast <2 x i64>* %296 to <8 x i16>*
  store <8 x i16> %295, <8 x i16>* %297, align 16
  switch i32 %3, label %301 [
    i32 0, label %298
    i32 1, label %299
    i32 2, label %300
  ]

298:                                              ; preds = %4
  call void @idct16_sse2(<2 x i64>* nonnull %11, <2 x i64>* nonnull %155) #5
  call void @idct16_sse2(<2 x i64>* nonnull %11, <2 x i64>* nonnull %155) #5
  br label %302

299:                                              ; preds = %4
  call void @idct16_sse2(<2 x i64>* nonnull %11, <2 x i64>* nonnull %155) #5
  call void @iadst16_sse2(<2 x i64>* nonnull %11, <2 x i64>* nonnull %155) #5
  br label %302

300:                                              ; preds = %4
  call void @iadst16_sse2(<2 x i64>* nonnull %11, <2 x i64>* nonnull %155) #5
  call void @idct16_sse2(<2 x i64>* nonnull %11, <2 x i64>* nonnull %155) #5
  br label %302

301:                                              ; preds = %4
  call void @iadst16_sse2(<2 x i64>* nonnull %11, <2 x i64>* nonnull %155) #5
  call void @iadst16_sse2(<2 x i64>* nonnull %11, <2 x i64>* nonnull %155) #5
  br label %302

302:                                              ; preds = %301, %300, %299, %298
  %303 = load <8 x i16>, <8 x i16>* %18, align 16
  %304 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %303, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %305 = load <8 x i16>, <8 x i16>* %27, align 16
  %306 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %305, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %307 = load <8 x i16>, <8 x i16>* %36, align 16
  %308 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %307, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %309 = load <8 x i16>, <8 x i16>* %45, align 16
  %310 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %309, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %311 = load <8 x i16>, <8 x i16>* %54, align 16
  %312 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %311, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %313 = load <8 x i16>, <8 x i16>* %63, align 16
  %314 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %313, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %315 = load <8 x i16>, <8 x i16>* %72, align 16
  %316 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %315, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %317 = load <8 x i16>, <8 x i16>* %81, align 16
  %318 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %317, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %319 = load <8 x i16>, <8 x i16>* %90, align 16
  %320 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %319, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %321 = load <8 x i16>, <8 x i16>* %99, align 16
  %322 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %321, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %323 = load <8 x i16>, <8 x i16>* %108, align 16
  %324 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %323, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %325 = load <8 x i16>, <8 x i16>* %117, align 16
  %326 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %325, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %327 = load <8 x i16>, <8 x i16>* %126, align 16
  %328 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %327, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %329 = load <8 x i16>, <8 x i16>* %135, align 16
  %330 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %329, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %331 = load <8 x i16>, <8 x i16>* %144, align 16
  %332 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %331, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %333 = load <8 x i16>, <8 x i16>* %153, align 16
  %334 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %333, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %335 = ashr <8 x i16> %304, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %335, <8 x i16>* %18, align 16
  %336 = ashr <8 x i16> %306, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %336, <8 x i16>* %27, align 16
  %337 = ashr <8 x i16> %308, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %337, <8 x i16>* %36, align 16
  %338 = ashr <8 x i16> %310, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %338, <8 x i16>* %45, align 16
  %339 = ashr <8 x i16> %312, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %339, <8 x i16>* %54, align 16
  %340 = ashr <8 x i16> %314, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %340, <8 x i16>* %63, align 16
  %341 = ashr <8 x i16> %316, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %341, <8 x i16>* %72, align 16
  %342 = ashr <8 x i16> %318, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %342, <8 x i16>* %81, align 16
  %343 = ashr <8 x i16> %320, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %343, <8 x i16>* %90, align 16
  %344 = ashr <8 x i16> %322, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %344, <8 x i16>* %99, align 16
  %345 = ashr <8 x i16> %324, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %345, <8 x i16>* %108, align 16
  %346 = ashr <8 x i16> %326, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %346, <8 x i16>* %117, align 16
  %347 = ashr <8 x i16> %328, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %347, <8 x i16>* %126, align 16
  %348 = ashr <8 x i16> %330, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %348, <8 x i16>* %135, align 16
  %349 = ashr <8 x i16> %332, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %349, <8 x i16>* %144, align 16
  %350 = ashr <8 x i16> %334, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %350, <8 x i16>* %153, align 16
  %351 = bitcast i8* %1 to i64*
  %352 = load i64, i64* %351, align 1
  %353 = insertelement <2 x i64> undef, i64 %352, i32 0
  %354 = bitcast <2 x i64> %353 to <16 x i8>
  %355 = shufflevector <16 x i8> %354, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %356 = bitcast <16 x i8> %355 to <8 x i16>
  %357 = add <8 x i16> %335, %356
  %358 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %357, <8 x i16> undef) #5
  %359 = bitcast <16 x i8> %358 to <2 x i64>
  %360 = extractelement <2 x i64> %359, i32 0
  store i64 %360, i64* %351, align 1
  %361 = sext i32 %2 to i64
  %362 = getelementptr inbounds i8, i8* %1, i64 %361
  %363 = bitcast i8* %362 to i64*
  %364 = load i64, i64* %363, align 1
  %365 = insertelement <2 x i64> undef, i64 %364, i32 0
  %366 = bitcast <2 x i64> %365 to <16 x i8>
  %367 = shufflevector <16 x i8> %366, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %368 = bitcast <16 x i8> %367 to <8 x i16>
  %369 = add <8 x i16> %336, %368
  %370 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %369, <8 x i16> undef) #5
  %371 = bitcast <16 x i8> %370 to <2 x i64>
  %372 = extractelement <2 x i64> %371, i32 0
  store i64 %372, i64* %363, align 1
  %373 = shl nsw i32 %2, 1
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds i8, i8* %1, i64 %374
  %376 = bitcast i8* %375 to i64*
  %377 = load i64, i64* %376, align 1
  %378 = insertelement <2 x i64> undef, i64 %377, i32 0
  %379 = bitcast <2 x i64> %378 to <16 x i8>
  %380 = shufflevector <16 x i8> %379, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %381 = bitcast <16 x i8> %380 to <8 x i16>
  %382 = add <8 x i16> %337, %381
  %383 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %382, <8 x i16> undef) #5
  %384 = bitcast <16 x i8> %383 to <2 x i64>
  %385 = extractelement <2 x i64> %384, i32 0
  store i64 %385, i64* %376, align 1
  %386 = mul nsw i32 %2, 3
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i8, i8* %1, i64 %387
  %389 = bitcast i8* %388 to i64*
  %390 = load i64, i64* %389, align 1
  %391 = insertelement <2 x i64> undef, i64 %390, i32 0
  %392 = bitcast <2 x i64> %391 to <16 x i8>
  %393 = shufflevector <16 x i8> %392, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %394 = bitcast <16 x i8> %393 to <8 x i16>
  %395 = add <8 x i16> %338, %394
  %396 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %395, <8 x i16> undef) #5
  %397 = bitcast <16 x i8> %396 to <2 x i64>
  %398 = extractelement <2 x i64> %397, i32 0
  store i64 %398, i64* %389, align 1
  %399 = shl nsw i32 %2, 2
  %400 = sext i32 %399 to i64
  %401 = getelementptr inbounds i8, i8* %1, i64 %400
  %402 = bitcast i8* %401 to i64*
  %403 = load i64, i64* %402, align 1
  %404 = insertelement <2 x i64> undef, i64 %403, i32 0
  %405 = bitcast <2 x i64> %404 to <16 x i8>
  %406 = shufflevector <16 x i8> %405, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %407 = bitcast <16 x i8> %406 to <8 x i16>
  %408 = add <8 x i16> %339, %407
  %409 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %408, <8 x i16> undef) #5
  %410 = bitcast <16 x i8> %409 to <2 x i64>
  %411 = extractelement <2 x i64> %410, i32 0
  store i64 %411, i64* %402, align 1
  %412 = mul nsw i32 %2, 5
  %413 = sext i32 %412 to i64
  %414 = getelementptr inbounds i8, i8* %1, i64 %413
  %415 = bitcast i8* %414 to i64*
  %416 = load i64, i64* %415, align 1
  %417 = insertelement <2 x i64> undef, i64 %416, i32 0
  %418 = bitcast <2 x i64> %417 to <16 x i8>
  %419 = shufflevector <16 x i8> %418, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %420 = bitcast <16 x i8> %419 to <8 x i16>
  %421 = add <8 x i16> %340, %420
  %422 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %421, <8 x i16> undef) #5
  %423 = bitcast <16 x i8> %422 to <2 x i64>
  %424 = extractelement <2 x i64> %423, i32 0
  store i64 %424, i64* %415, align 1
  %425 = mul nsw i32 %2, 6
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds i8, i8* %1, i64 %426
  %428 = bitcast i8* %427 to i64*
  %429 = load i64, i64* %428, align 1
  %430 = insertelement <2 x i64> undef, i64 %429, i32 0
  %431 = bitcast <2 x i64> %430 to <16 x i8>
  %432 = shufflevector <16 x i8> %431, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %433 = bitcast <16 x i8> %432 to <8 x i16>
  %434 = add <8 x i16> %341, %433
  %435 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %434, <8 x i16> undef) #5
  %436 = bitcast <16 x i8> %435 to <2 x i64>
  %437 = extractelement <2 x i64> %436, i32 0
  store i64 %437, i64* %428, align 1
  %438 = mul nsw i32 %2, 7
  %439 = sext i32 %438 to i64
  %440 = getelementptr inbounds i8, i8* %1, i64 %439
  %441 = bitcast i8* %440 to i64*
  %442 = load i64, i64* %441, align 1
  %443 = insertelement <2 x i64> undef, i64 %442, i32 0
  %444 = bitcast <2 x i64> %443 to <16 x i8>
  %445 = shufflevector <16 x i8> %444, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %446 = bitcast <16 x i8> %445 to <8 x i16>
  %447 = add <8 x i16> %342, %446
  %448 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %447, <8 x i16> undef) #5
  %449 = bitcast <16 x i8> %448 to <2 x i64>
  %450 = extractelement <2 x i64> %449, i32 0
  store i64 %450, i64* %441, align 1
  %451 = shl nsw i32 %2, 3
  %452 = sext i32 %451 to i64
  %453 = getelementptr inbounds i8, i8* %1, i64 %452
  %454 = bitcast i8* %453 to i64*
  %455 = load i64, i64* %454, align 1
  %456 = insertelement <2 x i64> undef, i64 %455, i32 0
  %457 = bitcast <2 x i64> %456 to <16 x i8>
  %458 = shufflevector <16 x i8> %457, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %459 = bitcast <16 x i8> %458 to <8 x i16>
  %460 = add <8 x i16> %343, %459
  %461 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %460, <8 x i16> undef) #5
  %462 = bitcast <16 x i8> %461 to <2 x i64>
  %463 = extractelement <2 x i64> %462, i32 0
  store i64 %463, i64* %454, align 1
  %464 = mul nsw i32 %2, 9
  %465 = sext i32 %464 to i64
  %466 = getelementptr inbounds i8, i8* %1, i64 %465
  %467 = bitcast i8* %466 to i64*
  %468 = load i64, i64* %467, align 1
  %469 = insertelement <2 x i64> undef, i64 %468, i32 0
  %470 = bitcast <2 x i64> %469 to <16 x i8>
  %471 = shufflevector <16 x i8> %470, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %472 = bitcast <16 x i8> %471 to <8 x i16>
  %473 = add <8 x i16> %344, %472
  %474 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %473, <8 x i16> undef) #5
  %475 = bitcast <16 x i8> %474 to <2 x i64>
  %476 = extractelement <2 x i64> %475, i32 0
  store i64 %476, i64* %467, align 1
  %477 = mul nsw i32 %2, 10
  %478 = sext i32 %477 to i64
  %479 = getelementptr inbounds i8, i8* %1, i64 %478
  %480 = bitcast i8* %479 to i64*
  %481 = load i64, i64* %480, align 1
  %482 = insertelement <2 x i64> undef, i64 %481, i32 0
  %483 = bitcast <2 x i64> %482 to <16 x i8>
  %484 = shufflevector <16 x i8> %483, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %485 = bitcast <16 x i8> %484 to <8 x i16>
  %486 = add <8 x i16> %345, %485
  %487 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %486, <8 x i16> undef) #5
  %488 = bitcast <16 x i8> %487 to <2 x i64>
  %489 = extractelement <2 x i64> %488, i32 0
  store i64 %489, i64* %480, align 1
  %490 = mul nsw i32 %2, 11
  %491 = sext i32 %490 to i64
  %492 = getelementptr inbounds i8, i8* %1, i64 %491
  %493 = bitcast i8* %492 to i64*
  %494 = load i64, i64* %493, align 1
  %495 = insertelement <2 x i64> undef, i64 %494, i32 0
  %496 = bitcast <2 x i64> %495 to <16 x i8>
  %497 = shufflevector <16 x i8> %496, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %498 = bitcast <16 x i8> %497 to <8 x i16>
  %499 = add <8 x i16> %346, %498
  %500 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %499, <8 x i16> undef) #5
  %501 = bitcast <16 x i8> %500 to <2 x i64>
  %502 = extractelement <2 x i64> %501, i32 0
  store i64 %502, i64* %493, align 1
  %503 = mul nsw i32 %2, 12
  %504 = sext i32 %503 to i64
  %505 = getelementptr inbounds i8, i8* %1, i64 %504
  %506 = bitcast i8* %505 to i64*
  %507 = load i64, i64* %506, align 1
  %508 = insertelement <2 x i64> undef, i64 %507, i32 0
  %509 = bitcast <2 x i64> %508 to <16 x i8>
  %510 = shufflevector <16 x i8> %509, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %511 = bitcast <16 x i8> %510 to <8 x i16>
  %512 = add <8 x i16> %347, %511
  %513 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %512, <8 x i16> undef) #5
  %514 = bitcast <16 x i8> %513 to <2 x i64>
  %515 = extractelement <2 x i64> %514, i32 0
  store i64 %515, i64* %506, align 1
  %516 = mul nsw i32 %2, 13
  %517 = sext i32 %516 to i64
  %518 = getelementptr inbounds i8, i8* %1, i64 %517
  %519 = bitcast i8* %518 to i64*
  %520 = load i64, i64* %519, align 1
  %521 = insertelement <2 x i64> undef, i64 %520, i32 0
  %522 = bitcast <2 x i64> %521 to <16 x i8>
  %523 = shufflevector <16 x i8> %522, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %524 = bitcast <16 x i8> %523 to <8 x i16>
  %525 = add <8 x i16> %348, %524
  %526 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %525, <8 x i16> undef) #5
  %527 = bitcast <16 x i8> %526 to <2 x i64>
  %528 = extractelement <2 x i64> %527, i32 0
  store i64 %528, i64* %519, align 1
  %529 = mul nsw i32 %2, 14
  %530 = sext i32 %529 to i64
  %531 = getelementptr inbounds i8, i8* %1, i64 %530
  %532 = bitcast i8* %531 to i64*
  %533 = load i64, i64* %532, align 1
  %534 = insertelement <2 x i64> undef, i64 %533, i32 0
  %535 = bitcast <2 x i64> %534 to <16 x i8>
  %536 = shufflevector <16 x i8> %535, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %537 = bitcast <16 x i8> %536 to <8 x i16>
  %538 = add <8 x i16> %349, %537
  %539 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %538, <8 x i16> undef) #5
  %540 = bitcast <16 x i8> %539 to <2 x i64>
  %541 = extractelement <2 x i64> %540, i32 0
  store i64 %541, i64* %532, align 1
  %542 = mul nsw i32 %2, 15
  %543 = sext i32 %542 to i64
  %544 = getelementptr inbounds i8, i8* %1, i64 %543
  %545 = bitcast i8* %544 to i64*
  %546 = load i64, i64* %545, align 1
  %547 = insertelement <2 x i64> undef, i64 %546, i32 0
  %548 = bitcast <2 x i64> %547 to <16 x i8>
  %549 = shufflevector <16 x i8> %548, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %550 = bitcast <16 x i8> %549 to <8 x i16>
  %551 = add <8 x i16> %350, %550
  %552 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %551, <8 x i16> undef) #5
  %553 = bitcast <16 x i8> %552 to <2 x i64>
  %554 = extractelement <2 x i64> %553, i32 0
  store i64 %554, i64* %545, align 1
  %555 = getelementptr inbounds i8, i8* %1, i64 8
  %556 = load <8 x i16>, <8 x i16>* %162, align 16
  %557 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %556, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %558 = load <8 x i16>, <8 x i16>* %171, align 16
  %559 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %558, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %560 = load <8 x i16>, <8 x i16>* %180, align 16
  %561 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %560, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %562 = load <8 x i16>, <8 x i16>* %189, align 16
  %563 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %562, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %564 = load <8 x i16>, <8 x i16>* %198, align 16
  %565 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %564, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %566 = load <8 x i16>, <8 x i16>* %207, align 16
  %567 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %566, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %568 = load <8 x i16>, <8 x i16>* %216, align 16
  %569 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %568, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %570 = load <8 x i16>, <8 x i16>* %225, align 16
  %571 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %570, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %572 = load <8 x i16>, <8 x i16>* %234, align 16
  %573 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %572, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %574 = load <8 x i16>, <8 x i16>* %243, align 16
  %575 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %574, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %576 = load <8 x i16>, <8 x i16>* %252, align 16
  %577 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %576, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %578 = load <8 x i16>, <8 x i16>* %261, align 16
  %579 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %578, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %580 = load <8 x i16>, <8 x i16>* %270, align 16
  %581 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %580, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %582 = load <8 x i16>, <8 x i16>* %279, align 16
  %583 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %582, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %584 = load <8 x i16>, <8 x i16>* %288, align 16
  %585 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %584, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %586 = load <8 x i16>, <8 x i16>* %297, align 16
  %587 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %586, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %588 = ashr <8 x i16> %557, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %588, <8 x i16>* %162, align 16
  %589 = ashr <8 x i16> %559, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %589, <8 x i16>* %171, align 16
  %590 = ashr <8 x i16> %561, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %590, <8 x i16>* %180, align 16
  %591 = ashr <8 x i16> %563, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %591, <8 x i16>* %189, align 16
  %592 = ashr <8 x i16> %565, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %592, <8 x i16>* %198, align 16
  %593 = ashr <8 x i16> %567, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %593, <8 x i16>* %207, align 16
  %594 = ashr <8 x i16> %569, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %594, <8 x i16>* %216, align 16
  %595 = ashr <8 x i16> %571, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %595, <8 x i16>* %225, align 16
  %596 = ashr <8 x i16> %573, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %596, <8 x i16>* %234, align 16
  %597 = ashr <8 x i16> %575, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %597, <8 x i16>* %243, align 16
  %598 = ashr <8 x i16> %577, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %598, <8 x i16>* %252, align 16
  %599 = ashr <8 x i16> %579, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %599, <8 x i16>* %261, align 16
  %600 = ashr <8 x i16> %581, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %600, <8 x i16>* %270, align 16
  %601 = ashr <8 x i16> %583, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %601, <8 x i16>* %279, align 16
  %602 = ashr <8 x i16> %585, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %602, <8 x i16>* %288, align 16
  %603 = ashr <8 x i16> %587, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %603, <8 x i16>* %297, align 16
  %604 = bitcast i8* %555 to i64*
  %605 = load i64, i64* %604, align 1
  %606 = insertelement <2 x i64> undef, i64 %605, i32 0
  %607 = bitcast <2 x i64> %606 to <16 x i8>
  %608 = shufflevector <16 x i8> %607, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %609 = bitcast <16 x i8> %608 to <8 x i16>
  %610 = add <8 x i16> %588, %609
  %611 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %610, <8 x i16> undef) #5
  %612 = bitcast <16 x i8> %611 to <2 x i64>
  %613 = extractelement <2 x i64> %612, i32 0
  store i64 %613, i64* %604, align 1
  %614 = getelementptr inbounds i8, i8* %555, i64 %361
  %615 = bitcast i8* %614 to i64*
  %616 = load i64, i64* %615, align 1
  %617 = insertelement <2 x i64> undef, i64 %616, i32 0
  %618 = bitcast <2 x i64> %617 to <16 x i8>
  %619 = shufflevector <16 x i8> %618, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %620 = bitcast <16 x i8> %619 to <8 x i16>
  %621 = add <8 x i16> %589, %620
  %622 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %621, <8 x i16> undef) #5
  %623 = bitcast <16 x i8> %622 to <2 x i64>
  %624 = extractelement <2 x i64> %623, i32 0
  store i64 %624, i64* %615, align 1
  %625 = getelementptr inbounds i8, i8* %555, i64 %374
  %626 = bitcast i8* %625 to i64*
  %627 = load i64, i64* %626, align 1
  %628 = insertelement <2 x i64> undef, i64 %627, i32 0
  %629 = bitcast <2 x i64> %628 to <16 x i8>
  %630 = shufflevector <16 x i8> %629, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %631 = bitcast <16 x i8> %630 to <8 x i16>
  %632 = add <8 x i16> %590, %631
  %633 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %632, <8 x i16> undef) #5
  %634 = bitcast <16 x i8> %633 to <2 x i64>
  %635 = extractelement <2 x i64> %634, i32 0
  store i64 %635, i64* %626, align 1
  %636 = getelementptr inbounds i8, i8* %555, i64 %387
  %637 = bitcast i8* %636 to i64*
  %638 = load i64, i64* %637, align 1
  %639 = insertelement <2 x i64> undef, i64 %638, i32 0
  %640 = bitcast <2 x i64> %639 to <16 x i8>
  %641 = shufflevector <16 x i8> %640, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %642 = bitcast <16 x i8> %641 to <8 x i16>
  %643 = add <8 x i16> %591, %642
  %644 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %643, <8 x i16> undef) #5
  %645 = bitcast <16 x i8> %644 to <2 x i64>
  %646 = extractelement <2 x i64> %645, i32 0
  store i64 %646, i64* %637, align 1
  %647 = getelementptr inbounds i8, i8* %555, i64 %400
  %648 = bitcast i8* %647 to i64*
  %649 = load i64, i64* %648, align 1
  %650 = insertelement <2 x i64> undef, i64 %649, i32 0
  %651 = bitcast <2 x i64> %650 to <16 x i8>
  %652 = shufflevector <16 x i8> %651, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %653 = bitcast <16 x i8> %652 to <8 x i16>
  %654 = add <8 x i16> %592, %653
  %655 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %654, <8 x i16> undef) #5
  %656 = bitcast <16 x i8> %655 to <2 x i64>
  %657 = extractelement <2 x i64> %656, i32 0
  store i64 %657, i64* %648, align 1
  %658 = getelementptr inbounds i8, i8* %555, i64 %413
  %659 = bitcast i8* %658 to i64*
  %660 = load i64, i64* %659, align 1
  %661 = insertelement <2 x i64> undef, i64 %660, i32 0
  %662 = bitcast <2 x i64> %661 to <16 x i8>
  %663 = shufflevector <16 x i8> %662, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %664 = bitcast <16 x i8> %663 to <8 x i16>
  %665 = add <8 x i16> %593, %664
  %666 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %665, <8 x i16> undef) #5
  %667 = bitcast <16 x i8> %666 to <2 x i64>
  %668 = extractelement <2 x i64> %667, i32 0
  store i64 %668, i64* %659, align 1
  %669 = getelementptr inbounds i8, i8* %555, i64 %426
  %670 = bitcast i8* %669 to i64*
  %671 = load i64, i64* %670, align 1
  %672 = insertelement <2 x i64> undef, i64 %671, i32 0
  %673 = bitcast <2 x i64> %672 to <16 x i8>
  %674 = shufflevector <16 x i8> %673, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %675 = bitcast <16 x i8> %674 to <8 x i16>
  %676 = add <8 x i16> %594, %675
  %677 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %676, <8 x i16> undef) #5
  %678 = bitcast <16 x i8> %677 to <2 x i64>
  %679 = extractelement <2 x i64> %678, i32 0
  store i64 %679, i64* %670, align 1
  %680 = getelementptr inbounds i8, i8* %555, i64 %439
  %681 = bitcast i8* %680 to i64*
  %682 = load i64, i64* %681, align 1
  %683 = insertelement <2 x i64> undef, i64 %682, i32 0
  %684 = bitcast <2 x i64> %683 to <16 x i8>
  %685 = shufflevector <16 x i8> %684, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %686 = bitcast <16 x i8> %685 to <8 x i16>
  %687 = add <8 x i16> %595, %686
  %688 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %687, <8 x i16> undef) #5
  %689 = bitcast <16 x i8> %688 to <2 x i64>
  %690 = extractelement <2 x i64> %689, i32 0
  store i64 %690, i64* %681, align 1
  %691 = getelementptr inbounds i8, i8* %555, i64 %452
  %692 = bitcast i8* %691 to i64*
  %693 = load i64, i64* %692, align 1
  %694 = insertelement <2 x i64> undef, i64 %693, i32 0
  %695 = bitcast <2 x i64> %694 to <16 x i8>
  %696 = shufflevector <16 x i8> %695, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %697 = bitcast <16 x i8> %696 to <8 x i16>
  %698 = add <8 x i16> %596, %697
  %699 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %698, <8 x i16> undef) #5
  %700 = bitcast <16 x i8> %699 to <2 x i64>
  %701 = extractelement <2 x i64> %700, i32 0
  store i64 %701, i64* %692, align 1
  %702 = getelementptr inbounds i8, i8* %555, i64 %465
  %703 = bitcast i8* %702 to i64*
  %704 = load i64, i64* %703, align 1
  %705 = insertelement <2 x i64> undef, i64 %704, i32 0
  %706 = bitcast <2 x i64> %705 to <16 x i8>
  %707 = shufflevector <16 x i8> %706, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %708 = bitcast <16 x i8> %707 to <8 x i16>
  %709 = add <8 x i16> %597, %708
  %710 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %709, <8 x i16> undef) #5
  %711 = bitcast <16 x i8> %710 to <2 x i64>
  %712 = extractelement <2 x i64> %711, i32 0
  store i64 %712, i64* %703, align 1
  %713 = getelementptr inbounds i8, i8* %555, i64 %478
  %714 = bitcast i8* %713 to i64*
  %715 = load i64, i64* %714, align 1
  %716 = insertelement <2 x i64> undef, i64 %715, i32 0
  %717 = bitcast <2 x i64> %716 to <16 x i8>
  %718 = shufflevector <16 x i8> %717, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %719 = bitcast <16 x i8> %718 to <8 x i16>
  %720 = add <8 x i16> %598, %719
  %721 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %720, <8 x i16> undef) #5
  %722 = bitcast <16 x i8> %721 to <2 x i64>
  %723 = extractelement <2 x i64> %722, i32 0
  store i64 %723, i64* %714, align 1
  %724 = getelementptr inbounds i8, i8* %555, i64 %491
  %725 = bitcast i8* %724 to i64*
  %726 = load i64, i64* %725, align 1
  %727 = insertelement <2 x i64> undef, i64 %726, i32 0
  %728 = bitcast <2 x i64> %727 to <16 x i8>
  %729 = shufflevector <16 x i8> %728, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %730 = bitcast <16 x i8> %729 to <8 x i16>
  %731 = add <8 x i16> %599, %730
  %732 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %731, <8 x i16> undef) #5
  %733 = bitcast <16 x i8> %732 to <2 x i64>
  %734 = extractelement <2 x i64> %733, i32 0
  store i64 %734, i64* %725, align 1
  %735 = getelementptr inbounds i8, i8* %555, i64 %504
  %736 = bitcast i8* %735 to i64*
  %737 = load i64, i64* %736, align 1
  %738 = insertelement <2 x i64> undef, i64 %737, i32 0
  %739 = bitcast <2 x i64> %738 to <16 x i8>
  %740 = shufflevector <16 x i8> %739, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %741 = bitcast <16 x i8> %740 to <8 x i16>
  %742 = add <8 x i16> %600, %741
  %743 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %742, <8 x i16> undef) #5
  %744 = bitcast <16 x i8> %743 to <2 x i64>
  %745 = extractelement <2 x i64> %744, i32 0
  store i64 %745, i64* %736, align 1
  %746 = getelementptr inbounds i8, i8* %555, i64 %517
  %747 = bitcast i8* %746 to i64*
  %748 = load i64, i64* %747, align 1
  %749 = insertelement <2 x i64> undef, i64 %748, i32 0
  %750 = bitcast <2 x i64> %749 to <16 x i8>
  %751 = shufflevector <16 x i8> %750, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %752 = bitcast <16 x i8> %751 to <8 x i16>
  %753 = add <8 x i16> %601, %752
  %754 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %753, <8 x i16> undef) #5
  %755 = bitcast <16 x i8> %754 to <2 x i64>
  %756 = extractelement <2 x i64> %755, i32 0
  store i64 %756, i64* %747, align 1
  %757 = getelementptr inbounds i8, i8* %555, i64 %530
  %758 = bitcast i8* %757 to i64*
  %759 = load i64, i64* %758, align 1
  %760 = insertelement <2 x i64> undef, i64 %759, i32 0
  %761 = bitcast <2 x i64> %760 to <16 x i8>
  %762 = shufflevector <16 x i8> %761, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %763 = bitcast <16 x i8> %762 to <8 x i16>
  %764 = add <8 x i16> %602, %763
  %765 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %764, <8 x i16> undef) #5
  %766 = bitcast <16 x i8> %765 to <2 x i64>
  %767 = extractelement <2 x i64> %766, i32 0
  store i64 %767, i64* %758, align 1
  %768 = getelementptr inbounds i8, i8* %555, i64 %543
  %769 = bitcast i8* %768 to i64*
  %770 = load i64, i64* %769, align 1
  %771 = insertelement <2 x i64> undef, i64 %770, i32 0
  %772 = bitcast <2 x i64> %771 to <16 x i8>
  %773 = shufflevector <16 x i8> %772, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %774 = bitcast <16 x i8> %773 to <8 x i16>
  %775 = add <8 x i16> %603, %774
  %776 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %775, <8 x i16> undef) #5
  %777 = bitcast <16 x i8> %776 to <2 x i64>
  %778 = extractelement <2 x i64> %777, i32 0
  store i64 %778, i64* %769, align 1
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %10) #5
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %7) #5
  ret void
}

declare void @idct16_sse2(<2 x i64>*, <2 x i64>*) local_unnamed_addr #2

declare void @iadst16_sse2(<2 x i64>*, <2 x i64>*) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #3

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #4

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone }
attributes #4 = { nounwind readnone speculatable }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
