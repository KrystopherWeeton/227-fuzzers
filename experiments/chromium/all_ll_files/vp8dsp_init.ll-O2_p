; ModuleID = '../../third_party/ffmpeg/libavcodec/x86/vp8dsp_init.c'
source_filename = "../../third_party/ffmpeg/libavcodec/x86/vp8dsp_init.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"
module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"
module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.VP8DSPContext = type { void ([4 x [16 x i16]]*, i16*)*, void ([4 x [16 x i16]]*, i16*)*, void (i8*, i16*, i64)*, void (i8*, i16*, i64)*, void (i8*, [16 x i16]*, i64)*, void (i8*, [16 x i16]*, i64)*, void (i8*, i64, i32, i32, i32)*, void (i8*, i64, i32, i32, i32)*, void (i8*, i8*, i64, i32, i32, i32)*, void (i8*, i8*, i64, i32, i32, i32)*, void (i8*, i64, i32, i32, i32)*, void (i8*, i64, i32, i32, i32)*, void (i8*, i8*, i64, i32, i32, i32)*, void (i8*, i8*, i64, i32, i32, i32)*, void (i8*, i64, i32)*, void (i8*, i64, i32)*, [3 x [3 x [3 x void (i8*, i64, i8*, i64, i32, i32, i32)*]]], [3 x [3 x [3 x void (i8*, i64, i8*, i64, i32, i32, i32)*]]] }

; Function Attrs: cold nounwind optsize ssp uwtable
define hidden void @ff_vp78dsp_init_x86(%struct.VP8DSPContext*) local_unnamed_addr #0 {
  %2 = tail call i32 @av_get_cpu_flags() #4
  %3 = and i32 %2, 1
  %4 = icmp eq i32 %3, 0
  br i1 %4, label %8, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 0, i64 0
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_pixels8_mmx, void (i8*, i64, i8*, i64, i32, i32, i32)** %6, align 8
  %7 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 0, i64 0
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_pixels8_mmx, void (i8*, i64, i8*, i64, i32, i32, i32)** %7, align 8
  br label %8

8:                                                ; preds = %1, %5
  %9 = and i32 %2, 2
  %10 = icmp eq i32 %9, 0
  br i1 %10, label %28, label %11

11:                                               ; preds = %8
  %12 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 0, i64 1
  %13 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 1, i64 0
  %14 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %13 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_v4_mmxext, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h4v4_mmxext>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %14, align 8
  %15 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 1, i64 2
  %16 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 2, i64 1
  %17 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %12 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h4_mmxext, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h6_mmxext>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %17, align 8
  %18 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %15 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h6v4_mmxext, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_v6_mmxext>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %18, align 8
  %19 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %16 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h4v6_mmxext, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h6v6_mmxext>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %19, align 8
  %20 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 2, i64 0, i64 1
  %21 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %20 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_h_mmxext, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_h_mmxext>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %21, align 8
  %22 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 2, i64 1, i64 0
  %23 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %22 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_v_mmxext, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_hv_mmxext>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %23, align 8
  %24 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 2, i64 1, i64 2
  %25 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %24 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_hv_mmxext, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_v_mmxext>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %25, align 8
  %26 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 2, i64 2, i64 1
  %27 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %26 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_hv_mmxext, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_hv_mmxext>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %27, align 8
  br label %28

28:                                               ; preds = %8, %11
  %29 = and i32 %2, 8
  %30 = icmp eq i32 %29, 0
  br i1 %30, label %34, label %31

31:                                               ; preds = %28
  %32 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 0, i64 0
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_pixels16_sse, void (i8*, i64, i8*, i64, i32, i32, i32)** %32, align 8
  %33 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 0, i64 0, i64 0
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_pixels16_sse, void (i8*, i64, i8*, i64, i32, i32, i32)** %33, align 8
  br label %34

34:                                               ; preds = %28, %31
  %35 = and i32 %2, 16
  %36 = icmp eq i32 %35, 0
  br i1 %36, label %65, label %37

37:                                               ; preds = %34
  %38 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 0, i64 0, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel16_h6_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)** %38, align 8
  %39 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 0, i64 2, i64 0
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel16_v6_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)** %39, align 8
  %40 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 0, i64 2, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel16_h6v6_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)** %40, align 8
  %41 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 0, i64 1
  %42 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 1, i64 0
  %43 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %42 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_v4_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h4v4_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %43, align 8
  %44 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 1, i64 2
  %45 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 2, i64 1
  %46 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %41 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h4_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h6_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %46, align 8
  %47 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %44 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h6v4_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_v6_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %47, align 8
  %48 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %45 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h4v6_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h6v6_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %48, align 8
  %49 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 0, i64 1
  %50 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %49 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_h_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_h_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %50, align 8
  %51 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 1, i64 0
  %52 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %51 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_v_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_hv_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %52, align 8
  %53 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 1, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_hv_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)** %53, align 8
  %54 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 2, i64 0
  %55 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %54 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_v_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_hv_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %55, align 8
  %56 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 2, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_hv_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)** %56, align 8
  %57 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 0, i64 1
  %58 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %57 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_h_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_h_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %58, align 8
  %59 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 1, i64 0
  %60 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %59 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_v_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_hv_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %60, align 8
  %61 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 1, i64 2
  %62 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %61 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_hv_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_v_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %62, align 8
  %63 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 2, i64 1
  %64 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %63 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_hv_sse2, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_hv_sse2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %64, align 8
  br label %65

65:                                               ; preds = %34, %37
  %66 = trunc i32 %2 to i8
  %67 = icmp slt i8 %66, 0
  br i1 %67, label %68, label %112

68:                                               ; preds = %65
  %69 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 0, i64 0, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel16_h6_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %69, align 8
  %70 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 0, i64 2, i64 0
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel16_v6_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %70, align 8
  %71 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 0, i64 2, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel16_h6v6_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %71, align 8
  %72 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 0, i64 1
  %73 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 1, i64 0
  %74 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %73 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_v4_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h4v4_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %74, align 8
  %75 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 1, i64 2
  %76 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 1, i64 2, i64 1
  %77 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %72 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h4_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h6_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %77, align 8
  %78 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %75 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h6v4_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_v6_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %78, align 8
  %79 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %76 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h4v6_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel8_h6v6_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %79, align 8
  %80 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 0, i64 1
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h4_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %80, align 8
  %81 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 1, i64 0
  %82 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %81 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_v4_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h4v4_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %82, align 8
  %83 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 1, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h6v4_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %83, align 8
  %84 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 2, i64 1
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h4v6_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %84, align 8
  %85 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 0, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h6_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %85, align 8
  %86 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 2, i64 0
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_v6_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %86, align 8
  %87 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 16, i64 2, i64 2, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_epel4_h6v6_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %87, align 8
  %88 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 0, i64 1
  %89 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %88 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_h_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_h_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %89, align 8
  %90 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 1, i64 0
  %91 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %90 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_v_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_hv_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %91, align 8
  %92 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 1, i64 2
  %93 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %92 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_hv_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_v_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %93, align 8
  %94 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 0, i64 2, i64 1
  %95 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %94 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_hv_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear16_hv_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %95, align 8
  %96 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 0, i64 1
  %97 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %96 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_h_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_h_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %97, align 8
  %98 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 1, i64 0
  %99 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %98 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_v_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_hv_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %99, align 8
  %100 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 1, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_hv_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %100, align 8
  %101 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 2, i64 0
  %102 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %101 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_v_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_hv_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %102, align 8
  %103 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 1, i64 2, i64 2
  store void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear8_hv_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)** %103, align 8
  %104 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 2, i64 0, i64 1
  %105 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %104 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_h_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_h_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %105, align 8
  %106 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 2, i64 1, i64 0
  %107 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %106 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_v_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_hv_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %107, align 8
  %108 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 2, i64 1, i64 2
  %109 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %108 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_hv_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_v_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %109, align 8
  %110 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 17, i64 2, i64 2, i64 1
  %111 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32)** %110 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_hv_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32)* @ff_put_vp8_bilinear4_hv_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32)*>* %111, align 8
  br label %112

112:                                              ; preds = %68, %65
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

declare i32 @av_get_cpu_flags() local_unnamed_addr #2

declare void @ff_put_vp8_pixels8_mmx(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel4_h4_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel4_v4_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel4_h4v4_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [44 x i8], align 8
  %9 = getelementptr inbounds [44 x i8], [44 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 44, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 44, i1 false)
  %10 = getelementptr inbounds [44 x i8], [44 x i8]* %8, i64 0, i64 4
  %11 = sub i64 0, %3
  %12 = getelementptr inbounds i8, i8* %2, i64 %11
  %13 = add nsw i32 %4, 3
  call void @ff_put_vp8_epel4_h4_mmxext(i8* nonnull %9, i64 4, i8* %12, i64 %3, i32 %13, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel4_v4_mmxext(i8* %0, i64 %1, i8* %10, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 44, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel4_h6v4_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [44 x i8], align 8
  %9 = getelementptr inbounds [44 x i8], [44 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 44, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 44, i1 false)
  %10 = getelementptr inbounds [44 x i8], [44 x i8]* %8, i64 0, i64 4
  %11 = sub i64 0, %3
  %12 = getelementptr inbounds i8, i8* %2, i64 %11
  %13 = add nsw i32 %4, 3
  call void @ff_put_vp8_epel4_h6_mmxext(i8* nonnull %9, i64 4, i8* %12, i64 %3, i32 %13, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel4_v4_mmxext(i8* %0, i64 %1, i8* %10, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 44, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel4_h4v6_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [52 x i8], align 8
  %9 = getelementptr inbounds [52 x i8], [52 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 52, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 52, i1 false)
  %10 = getelementptr inbounds [52 x i8], [52 x i8]* %8, i64 0, i64 8
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel4_h4_mmxext(i8* nonnull %9, i64 4, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel4_v6_mmxext(i8* %0, i64 %1, i8* %10, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 52, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_epel4_h6_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel4_v6_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel4_h6v6_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [52 x i8], align 8
  %9 = getelementptr inbounds [52 x i8], [52 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 52, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 52, i1 false)
  %10 = getelementptr inbounds [52 x i8], [52 x i8]* %8, i64 0, i64 8
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel4_h6_mmxext(i8* nonnull %9, i64 4, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel4_v6_mmxext(i8* %0, i64 %1, i8* %10, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 52, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_bilinear4_h_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_bilinear4_v_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear4_hv_mmxext(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [40 x i8], align 8
  %9 = getelementptr inbounds [40 x i8], [40 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 40, i1 false)
  %10 = add nsw i32 %4, 1
  call void @ff_put_vp8_bilinear4_h_mmxext(i8* nonnull %9, i64 4, i8* %2, i64 %3, i32 %10, i32 %5, i32 %6) #4
  call void @ff_put_vp8_bilinear4_v_mmxext(i8* %0, i64 %1, i8* nonnull %9, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_pixels16_sse(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel16_h6_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  tail call void @ff_put_vp8_epel8_h6_sse2(i8* %0, i64 %1, i8* %2, i64 %3, i32 %4, i32 %5, i32 %6) #4
  %8 = getelementptr inbounds i8, i8* %0, i64 8
  %9 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @ff_put_vp8_epel8_h6_sse2(i8* %8, i64 %1, i8* %9, i64 %3, i32 %4, i32 %5, i32 %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel16_v6_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  tail call void @ff_put_vp8_epel8_v6_sse2(i8* %0, i64 %1, i8* %2, i64 %3, i32 %4, i32 %5, i32 %6) #4
  %8 = getelementptr inbounds i8, i8* %0, i64 8
  %9 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @ff_put_vp8_epel8_v6_sse2(i8* %8, i64 %1, i8* %9, i64 %3, i32 %4, i32 %5, i32 %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel16_h6v6_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [336 x i8], align 16
  %9 = getelementptr inbounds [336 x i8], [336 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 336, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 336, i1 false)
  %10 = getelementptr inbounds [336 x i8], [336 x i8]* %8, i64 0, i64 32
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel8_h6_sse2(i8* nonnull %9, i64 16, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  %15 = getelementptr inbounds [336 x i8], [336 x i8]* %8, i64 0, i64 8
  %16 = getelementptr inbounds i8, i8* %13, i64 8
  call void @ff_put_vp8_epel8_h6_sse2(i8* %15, i64 16, i8* %16, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v6_sse2(i8* %0, i64 %1, i8* %10, i64 16, i32 %4, i32 %5, i32 %6) #4
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = getelementptr inbounds [336 x i8], [336 x i8]* %8, i64 0, i64 40
  call void @ff_put_vp8_epel8_v6_sse2(i8* %17, i64 %1, i8* %18, i64 16, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 336, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_epel8_h4_sse2(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel8_v4_sse2(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel8_h4v4_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [152 x i8], align 16
  %9 = getelementptr inbounds [152 x i8], [152 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 152, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 152, i1 false)
  %10 = getelementptr inbounds [152 x i8], [152 x i8]* %8, i64 0, i64 8
  %11 = sub i64 0, %3
  %12 = getelementptr inbounds i8, i8* %2, i64 %11
  %13 = add nsw i32 %4, 3
  call void @ff_put_vp8_epel8_h4_sse2(i8* nonnull %9, i64 8, i8* %12, i64 %3, i32 %13, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v4_sse2(i8* %0, i64 %1, i8* %10, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 152, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel8_h6v4_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [152 x i8], align 16
  %9 = getelementptr inbounds [152 x i8], [152 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 152, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 152, i1 false)
  %10 = getelementptr inbounds [152 x i8], [152 x i8]* %8, i64 0, i64 8
  %11 = sub i64 0, %3
  %12 = getelementptr inbounds i8, i8* %2, i64 %11
  %13 = add nsw i32 %4, 3
  call void @ff_put_vp8_epel8_h6_sse2(i8* nonnull %9, i64 8, i8* %12, i64 %3, i32 %13, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v4_sse2(i8* %0, i64 %1, i8* %10, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 152, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel8_h4v6_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [168 x i8], align 16
  %9 = getelementptr inbounds [168 x i8], [168 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 168, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 168, i1 false)
  %10 = getelementptr inbounds [168 x i8], [168 x i8]* %8, i64 0, i64 16
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel8_h4_sse2(i8* nonnull %9, i64 8, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v6_sse2(i8* %0, i64 %1, i8* %10, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 168, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_epel8_h6_sse2(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel8_v6_sse2(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel8_h6v6_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [168 x i8], align 16
  %9 = getelementptr inbounds [168 x i8], [168 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 168, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 168, i1 false)
  %10 = getelementptr inbounds [168 x i8], [168 x i8]* %8, i64 0, i64 16
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel8_h6_sse2(i8* nonnull %9, i64 8, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v6_sse2(i8* %0, i64 %1, i8* %10, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 168, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear16_h_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  tail call void @ff_put_vp8_bilinear8_h_sse2(i8* %0, i64 %1, i8* %2, i64 %3, i32 %4, i32 %5, i32 %6) #4
  %8 = getelementptr inbounds i8, i8* %0, i64 8
  %9 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @ff_put_vp8_bilinear8_h_sse2(i8* %8, i64 %1, i8* %9, i64 %3, i32 %4, i32 %5, i32 %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear16_v_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  tail call void @ff_put_vp8_bilinear8_v_sse2(i8* %0, i64 %1, i8* %2, i64 %3, i32 %4, i32 %5, i32 %6) #4
  %8 = getelementptr inbounds i8, i8* %0, i64 8
  %9 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @ff_put_vp8_bilinear8_v_sse2(i8* %8, i64 %1, i8* %9, i64 %3, i32 %4, i32 %5, i32 %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear16_hv_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [288 x i8], align 8
  %9 = getelementptr inbounds [288 x i8], [288 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 288, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 288, i1 false)
  %10 = add nsw i32 %4, 1
  call void @ff_put_vp8_bilinear8_h_sse2(i8* nonnull %9, i64 16, i8* %2, i64 %3, i32 %10, i32 %5, i32 %6) #4
  %11 = getelementptr inbounds [288 x i8], [288 x i8]* %8, i64 0, i64 8
  %12 = getelementptr inbounds i8, i8* %2, i64 8
  call void @ff_put_vp8_bilinear8_h_sse2(i8* %11, i64 16, i8* %12, i64 %3, i32 %10, i32 %5, i32 %6) #4
  call void @ff_put_vp8_bilinear8_v_sse2(i8* %0, i64 %1, i8* nonnull %9, i64 16, i32 %4, i32 %5, i32 %6) #4
  %13 = getelementptr inbounds i8, i8* %0, i64 8
  call void @ff_put_vp8_bilinear8_v_sse2(i8* %13, i64 %1, i8* %11, i64 16, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 288, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_bilinear8_h_sse2(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_bilinear8_v_sse2(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear8_hv_sse2(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [144 x i8], align 8
  %9 = getelementptr inbounds [144 x i8], [144 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 144, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 144, i1 false)
  %10 = add nsw i32 %4, 1
  call void @ff_put_vp8_bilinear8_h_sse2(i8* nonnull %9, i64 8, i8* %2, i64 %3, i32 %10, i32 %5, i32 %6) #4
  call void @ff_put_vp8_bilinear8_v_sse2(i8* %0, i64 %1, i8* nonnull %9, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 144, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel16_h6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  tail call void @ff_put_vp8_epel8_h6_ssse3(i8* %0, i64 %1, i8* %2, i64 %3, i32 %4, i32 %5, i32 %6) #4
  %8 = getelementptr inbounds i8, i8* %0, i64 8
  %9 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @ff_put_vp8_epel8_h6_ssse3(i8* %8, i64 %1, i8* %9, i64 %3, i32 %4, i32 %5, i32 %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel16_v6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  tail call void @ff_put_vp8_epel8_v6_ssse3(i8* %0, i64 %1, i8* %2, i64 %3, i32 %4, i32 %5, i32 %6) #4
  %8 = getelementptr inbounds i8, i8* %0, i64 8
  %9 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @ff_put_vp8_epel8_v6_ssse3(i8* %8, i64 %1, i8* %9, i64 %3, i32 %4, i32 %5, i32 %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel16_h6v6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [336 x i8], align 16
  %9 = getelementptr inbounds [336 x i8], [336 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 336, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 336, i1 false)
  %10 = getelementptr inbounds [336 x i8], [336 x i8]* %8, i64 0, i64 32
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel8_h6_ssse3(i8* nonnull %9, i64 16, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  %15 = getelementptr inbounds [336 x i8], [336 x i8]* %8, i64 0, i64 8
  %16 = getelementptr inbounds i8, i8* %13, i64 8
  call void @ff_put_vp8_epel8_h6_ssse3(i8* %15, i64 16, i8* %16, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v6_ssse3(i8* %0, i64 %1, i8* %10, i64 16, i32 %4, i32 %5, i32 %6) #4
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = getelementptr inbounds [336 x i8], [336 x i8]* %8, i64 0, i64 40
  call void @ff_put_vp8_epel8_v6_ssse3(i8* %17, i64 %1, i8* %18, i64 16, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 336, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_epel8_h4_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel8_v4_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel8_h4v4_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [152 x i8], align 16
  %9 = getelementptr inbounds [152 x i8], [152 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 152, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 152, i1 false)
  %10 = getelementptr inbounds [152 x i8], [152 x i8]* %8, i64 0, i64 8
  %11 = sub i64 0, %3
  %12 = getelementptr inbounds i8, i8* %2, i64 %11
  %13 = add nsw i32 %4, 3
  call void @ff_put_vp8_epel8_h4_ssse3(i8* nonnull %9, i64 8, i8* %12, i64 %3, i32 %13, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v4_ssse3(i8* %0, i64 %1, i8* %10, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 152, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel8_h6v4_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [152 x i8], align 16
  %9 = getelementptr inbounds [152 x i8], [152 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 152, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 152, i1 false)
  %10 = getelementptr inbounds [152 x i8], [152 x i8]* %8, i64 0, i64 8
  %11 = sub i64 0, %3
  %12 = getelementptr inbounds i8, i8* %2, i64 %11
  %13 = add nsw i32 %4, 3
  call void @ff_put_vp8_epel8_h6_ssse3(i8* nonnull %9, i64 8, i8* %12, i64 %3, i32 %13, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v4_ssse3(i8* %0, i64 %1, i8* %10, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 152, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel8_h4v6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [168 x i8], align 16
  %9 = getelementptr inbounds [168 x i8], [168 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 168, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 168, i1 false)
  %10 = getelementptr inbounds [168 x i8], [168 x i8]* %8, i64 0, i64 16
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel8_h4_ssse3(i8* nonnull %9, i64 8, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v6_ssse3(i8* %0, i64 %1, i8* %10, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 168, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_epel8_h6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel8_v6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel8_h6v6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [168 x i8], align 16
  %9 = getelementptr inbounds [168 x i8], [168 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 168, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 168, i1 false)
  %10 = getelementptr inbounds [168 x i8], [168 x i8]* %8, i64 0, i64 16
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel8_h6_ssse3(i8* nonnull %9, i64 8, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel8_v6_ssse3(i8* %0, i64 %1, i8* %10, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 168, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_epel4_h4_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel4_v4_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel4_h4v4_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [44 x i8], align 16
  %9 = getelementptr inbounds [44 x i8], [44 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 44, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 44, i1 false)
  %10 = getelementptr inbounds [44 x i8], [44 x i8]* %8, i64 0, i64 4
  %11 = sub i64 0, %3
  %12 = getelementptr inbounds i8, i8* %2, i64 %11
  %13 = add nsw i32 %4, 3
  call void @ff_put_vp8_epel4_h4_ssse3(i8* nonnull %9, i64 4, i8* %12, i64 %3, i32 %13, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel4_v4_ssse3(i8* %0, i64 %1, i8* %10, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 44, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel4_h6v4_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [44 x i8], align 16
  %9 = getelementptr inbounds [44 x i8], [44 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 44, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 44, i1 false)
  %10 = getelementptr inbounds [44 x i8], [44 x i8]* %8, i64 0, i64 4
  %11 = sub i64 0, %3
  %12 = getelementptr inbounds i8, i8* %2, i64 %11
  %13 = add nsw i32 %4, 3
  call void @ff_put_vp8_epel4_h6_ssse3(i8* nonnull %9, i64 4, i8* %12, i64 %3, i32 %13, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel4_v4_ssse3(i8* %0, i64 %1, i8* %10, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 44, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel4_h4v6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [52 x i8], align 16
  %9 = getelementptr inbounds [52 x i8], [52 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 52, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 52, i1 false)
  %10 = getelementptr inbounds [52 x i8], [52 x i8]* %8, i64 0, i64 8
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel4_h4_ssse3(i8* nonnull %9, i64 4, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel4_v6_ssse3(i8* %0, i64 %1, i8* %10, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 52, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_epel4_h6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_epel4_v6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_epel4_h6v6_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [52 x i8], align 16
  %9 = getelementptr inbounds [52 x i8], [52 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 52, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 52, i1 false)
  %10 = getelementptr inbounds [52 x i8], [52 x i8]* %8, i64 0, i64 8
  %11 = shl nsw i64 %3, 1
  %12 = sub i64 0, %11
  %13 = getelementptr inbounds i8, i8* %2, i64 %12
  %14 = add nsw i32 %4, 5
  call void @ff_put_vp8_epel4_h6_ssse3(i8* nonnull %9, i64 4, i8* %13, i64 %3, i32 %14, i32 %5, i32 %6) #4
  call void @ff_put_vp8_epel4_v6_ssse3(i8* %0, i64 %1, i8* %10, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 52, i8* nonnull %9) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear16_h_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  tail call void @ff_put_vp8_bilinear8_h_ssse3(i8* %0, i64 %1, i8* %2, i64 %3, i32 %4, i32 %5, i32 %6) #4
  %8 = getelementptr inbounds i8, i8* %0, i64 8
  %9 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @ff_put_vp8_bilinear8_h_ssse3(i8* %8, i64 %1, i8* %9, i64 %3, i32 %4, i32 %5, i32 %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear16_v_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  tail call void @ff_put_vp8_bilinear8_v_ssse3(i8* %0, i64 %1, i8* %2, i64 %3, i32 %4, i32 %5, i32 %6) #4
  %8 = getelementptr inbounds i8, i8* %0, i64 8
  %9 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @ff_put_vp8_bilinear8_v_ssse3(i8* %8, i64 %1, i8* %9, i64 %3, i32 %4, i32 %5, i32 %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear16_hv_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [288 x i8], align 8
  %9 = getelementptr inbounds [288 x i8], [288 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 288, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 288, i1 false)
  %10 = add nsw i32 %4, 1
  call void @ff_put_vp8_bilinear8_h_ssse3(i8* nonnull %9, i64 16, i8* %2, i64 %3, i32 %10, i32 %5, i32 %6) #4
  %11 = getelementptr inbounds [288 x i8], [288 x i8]* %8, i64 0, i64 8
  %12 = getelementptr inbounds i8, i8* %2, i64 8
  call void @ff_put_vp8_bilinear8_h_ssse3(i8* %11, i64 16, i8* %12, i64 %3, i32 %10, i32 %5, i32 %6) #4
  call void @ff_put_vp8_bilinear8_v_ssse3(i8* %0, i64 %1, i8* nonnull %9, i64 16, i32 %4, i32 %5, i32 %6) #4
  %13 = getelementptr inbounds i8, i8* %0, i64 8
  call void @ff_put_vp8_bilinear8_v_ssse3(i8* %13, i64 %1, i8* %11, i64 16, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 288, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_bilinear8_h_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_bilinear8_v_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear8_hv_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [144 x i8], align 8
  %9 = getelementptr inbounds [144 x i8], [144 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 144, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 144, i1 false)
  %10 = add nsw i32 %4, 1
  call void @ff_put_vp8_bilinear8_h_ssse3(i8* nonnull %9, i64 8, i8* %2, i64 %3, i32 %10, i32 %5, i32 %6) #4
  call void @ff_put_vp8_bilinear8_v_ssse3(i8* %0, i64 %1, i8* nonnull %9, i64 8, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 144, i8* nonnull %9) #4
  ret void
}

declare void @ff_put_vp8_bilinear4_h_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

declare void @ff_put_vp8_bilinear4_v_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #2

; Function Attrs: nounwind ssp uwtable
define internal void @ff_put_vp8_bilinear4_hv_ssse3(i8*, i64, i8*, i64, i32, i32, i32) #3 {
  %8 = alloca [40 x i8], align 8
  %9 = getelementptr inbounds [40 x i8], [40 x i8]* %8, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %9, i8 -86, i64 40, i1 false)
  %10 = add nsw i32 %4, 1
  call void @ff_put_vp8_bilinear4_h_ssse3(i8* nonnull %9, i64 4, i8* %2, i64 %3, i32 %10, i32 %5, i32 %6) #4
  call void @ff_put_vp8_bilinear4_v_ssse3(i8* %0, i64 %1, i8* nonnull %9, i64 4, i32 %4, i32 %5, i32 %6) #4
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %9) #4
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: cold nounwind optsize ssp uwtable
define hidden void @ff_vp8dsp_init_x86(%struct.VP8DSPContext*) local_unnamed_addr #0 {
  %2 = tail call i32 @av_get_cpu_flags() #4
  %3 = and i32 %2, 1
  %4 = icmp eq i32 %3, 0
  br i1 %4, label %7, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 5
  store void (i8*, [16 x i16]*, i64)* @ff_vp8_idct_dc_add4uv_mmx, void (i8*, [16 x i16]*, i64)** %6, align 8
  br label %7

7:                                                ; preds = %1, %5
  %8 = and i32 %2, 8
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %13, label %10

10:                                               ; preds = %7
  %11 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 2
  store void (i8*, i16*, i64)* @ff_vp8_idct_add_sse, void (i8*, i16*, i64)** %11, align 8
  %12 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 0
  store void ([4 x [16 x i16]]*, i16*)* @ff_vp8_luma_dc_wht_sse, void ([4 x [16 x i16]]*, i16*)** %12, align 8
  br label %13

13:                                               ; preds = %7, %10
  %14 = and i32 %2, 16
  %15 = icmp eq i32 %14, 0
  br i1 %15, label %29, label %16

16:                                               ; preds = %13
  %17 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 14
  %18 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 10
  %19 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 12
  %20 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 6
  %21 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 8
  %22 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 3
  store void (i8*, i16*, i64)* @ff_vp8_idct_dc_add_sse2, void (i8*, i16*, i64)** %22, align 8
  %23 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 4
  store void (i8*, [16 x i16]*, i64)* @ff_vp8_idct_dc_add4y_sse2, void (i8*, [16 x i16]*, i64)** %23, align 8
  %24 = bitcast void (i8*, i64, i32)** %17 to <2 x void (i8*, i64, i32)*>*
  store <2 x void (i8*, i64, i32)*> <void (i8*, i64, i32)* @ff_vp8_v_loop_filter_simple_sse2, void (i8*, i64, i32)* @ff_vp8_h_loop_filter_simple_sse2>, <2 x void (i8*, i64, i32)*>* %24, align 8
  %25 = bitcast void (i8*, i64, i32, i32, i32)** %18 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @ff_vp8_v_loop_filter16y_inner_sse2, void (i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter16y_inner_sse2>, <2 x void (i8*, i64, i32, i32, i32)*>* %25, align 8
  %26 = bitcast void (i8*, i8*, i64, i32, i32, i32)** %19 to <2 x void (i8*, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i8*, i64, i32, i32, i32)*> <void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_v_loop_filter8uv_inner_sse2, void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter8uv_inner_sse2>, <2 x void (i8*, i8*, i64, i32, i32, i32)*>* %26, align 8
  %27 = bitcast void (i8*, i64, i32, i32, i32)** %20 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @ff_vp8_v_loop_filter16y_mbedge_sse2, void (i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter16y_mbedge_sse2>, <2 x void (i8*, i64, i32, i32, i32)*>* %27, align 8
  %28 = bitcast void (i8*, i8*, i64, i32, i32, i32)** %21 to <2 x void (i8*, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i8*, i64, i32, i32, i32)*> <void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_v_loop_filter8uv_mbedge_sse2, void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter8uv_mbedge_sse2>, <2 x void (i8*, i8*, i64, i32, i32, i32)*>* %28, align 8
  br label %29

29:                                               ; preds = %13, %16
  %30 = trunc i32 %2 to i8
  %31 = icmp slt i8 %30, 0
  br i1 %31, label %32, label %43

32:                                               ; preds = %29
  %33 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 14
  %34 = bitcast void (i8*, i64, i32)** %33 to <2 x void (i8*, i64, i32)*>*
  store <2 x void (i8*, i64, i32)*> <void (i8*, i64, i32)* @ff_vp8_v_loop_filter_simple_ssse3, void (i8*, i64, i32)* @ff_vp8_h_loop_filter_simple_ssse3>, <2 x void (i8*, i64, i32)*>* %34, align 8
  %35 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 10
  %36 = bitcast void (i8*, i64, i32, i32, i32)** %35 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @ff_vp8_v_loop_filter16y_inner_ssse3, void (i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter16y_inner_ssse3>, <2 x void (i8*, i64, i32, i32, i32)*>* %36, align 8
  %37 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 12
  %38 = bitcast void (i8*, i8*, i64, i32, i32, i32)** %37 to <2 x void (i8*, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i8*, i64, i32, i32, i32)*> <void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_v_loop_filter8uv_inner_ssse3, void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter8uv_inner_ssse3>, <2 x void (i8*, i8*, i64, i32, i32, i32)*>* %38, align 8
  %39 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 6
  %40 = bitcast void (i8*, i64, i32, i32, i32)** %39 to <2 x void (i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i32, i32, i32)*> <void (i8*, i64, i32, i32, i32)* @ff_vp8_v_loop_filter16y_mbedge_ssse3, void (i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter16y_mbedge_ssse3>, <2 x void (i8*, i64, i32, i32, i32)*>* %40, align 8
  %41 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 8
  %42 = bitcast void (i8*, i8*, i64, i32, i32, i32)** %41 to <2 x void (i8*, i8*, i64, i32, i32, i32)*>*
  store <2 x void (i8*, i8*, i64, i32, i32, i32)*> <void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_v_loop_filter8uv_mbedge_ssse3, void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter8uv_mbedge_ssse3>, <2 x void (i8*, i8*, i64, i32, i32, i32)*>* %42, align 8
  br label %43

43:                                               ; preds = %32, %29
  %44 = and i32 %2, 256
  %45 = icmp eq i32 %44, 0
  br i1 %45, label %51, label %46

46:                                               ; preds = %43
  %47 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 3
  store void (i8*, i16*, i64)* @ff_vp8_idct_dc_add_sse4, void (i8*, i16*, i64)** %47, align 8
  %48 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 15
  store void (i8*, i64, i32)* @ff_vp8_h_loop_filter_simple_sse4, void (i8*, i64, i32)** %48, align 8
  %49 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 7
  store void (i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter16y_mbedge_sse4, void (i8*, i64, i32, i32, i32)** %49, align 8
  %50 = getelementptr inbounds %struct.VP8DSPContext, %struct.VP8DSPContext* %0, i64 0, i32 9
  store void (i8*, i8*, i64, i32, i32, i32)* @ff_vp8_h_loop_filter8uv_mbedge_sse4, void (i8*, i8*, i64, i32, i32, i32)** %50, align 8
  br label %51

51:                                               ; preds = %43, %46
  ret void
}

declare void @ff_vp8_idct_dc_add4uv_mmx(i8*, [16 x i16]*, i64) #2

declare void @ff_vp8_idct_add_sse(i8*, i16*, i64) #2

declare void @ff_vp8_luma_dc_wht_sse([4 x [16 x i16]]*, i16*) #2

declare void @ff_vp8_v_loop_filter_simple_sse2(i8*, i64, i32) #2

declare void @ff_vp8_v_loop_filter16y_inner_sse2(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_v_loop_filter8uv_inner_sse2(i8*, i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_v_loop_filter16y_mbedge_sse2(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_v_loop_filter8uv_mbedge_sse2(i8*, i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_idct_dc_add_sse2(i8*, i16*, i64) #2

declare void @ff_vp8_idct_dc_add4y_sse2(i8*, [16 x i16]*, i64) #2

declare void @ff_vp8_h_loop_filter_simple_sse2(i8*, i64, i32) #2

declare void @ff_vp8_h_loop_filter16y_inner_sse2(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_h_loop_filter8uv_inner_sse2(i8*, i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_h_loop_filter16y_mbedge_sse2(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_h_loop_filter8uv_mbedge_sse2(i8*, i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_v_loop_filter_simple_ssse3(i8*, i64, i32) #2

declare void @ff_vp8_h_loop_filter_simple_ssse3(i8*, i64, i32) #2

declare void @ff_vp8_v_loop_filter16y_inner_ssse3(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_h_loop_filter16y_inner_ssse3(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_v_loop_filter8uv_inner_ssse3(i8*, i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_h_loop_filter8uv_inner_ssse3(i8*, i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_v_loop_filter16y_mbedge_ssse3(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_h_loop_filter16y_mbedge_ssse3(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_v_loop_filter8uv_mbedge_ssse3(i8*, i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_h_loop_filter8uv_mbedge_ssse3(i8*, i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_idct_dc_add_sse4(i8*, i16*, i64) #2

declare void @ff_vp8_h_loop_filter_simple_sse4(i8*, i64, i32) #2

declare void @ff_vp8_h_loop_filter16y_mbedge_sse4(i8*, i64, i32, i32, i32) #2

declare void @ff_vp8_h_loop_filter8uv_mbedge_sse4(i8*, i8*, i64, i32, i32, i32) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

attributes #0 = { cold nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
