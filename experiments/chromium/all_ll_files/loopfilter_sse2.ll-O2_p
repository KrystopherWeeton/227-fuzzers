; ModuleID = '../../third_party/libvpx/source/libvpx/vpx_dsp/x86/loopfilter_sse2.c'
source_filename = "../../third_party/libvpx/source/libvpx/vpx_dsp/x86/loopfilter_sse2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@vpx_lpf_horizontal_16 = external local_unnamed_addr global void (i8*, i32, i8*, i8*, i8*)*, align 8
@vpx_lpf_horizontal_16_dual = external local_unnamed_addr global void (i8*, i32, i8*, i8*, i8*)*, align 8

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_lpf_horizontal_4_sse2(i8* nocapture, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #0 {
  %6 = bitcast i8* %2 to i64*
  %7 = load i64, i64* %6, align 1
  %8 = insertelement <2 x i64> undef, i64 %7, i32 0
  %9 = bitcast i8* %3 to i64*
  %10 = load i64, i64* %9, align 1
  %11 = insertelement <2 x i64> %8, i64 %10, i32 1
  %12 = bitcast i8* %4 to i64*
  %13 = load i64, i64* %12, align 1
  %14 = insertelement <2 x i64> undef, i64 %13, i32 0
  %15 = bitcast <2 x i64> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %17 = mul nsw i32 %1, 3
  %18 = sext i32 %17 to i64
  %19 = sub nsw i64 0, %18
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = bitcast i8* %20 to i64*
  %22 = load i64, i64* %21, align 1
  %23 = insertelement <2 x i64> undef, i64 %22, i32 0
  %24 = shl nsw i32 %1, 2
  %25 = sext i32 %24 to i64
  %26 = sub nsw i64 0, %25
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to i64*
  %29 = load i64, i64* %28, align 1
  %30 = insertelement <2 x i64> %23, i64 %29, i32 1
  %31 = shl nsw i32 %1, 1
  %32 = sext i32 %31 to i64
  %33 = sub nsw i64 0, %32
  %34 = getelementptr inbounds i8, i8* %0, i64 %33
  %35 = bitcast i8* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = sext i32 %1 to i64
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = bitcast i8* %39 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> %37, i64 %41, i32 1
  %43 = sub nsw i64 0, %38
  %44 = getelementptr inbounds i8, i8* %0, i64 %43
  %45 = bitcast i8* %44 to i64*
  %46 = load i64, i64* %45, align 1
  %47 = insertelement <2 x i64> undef, i64 %46, i32 0
  %48 = bitcast i8* %0 to i64*
  %49 = load i64, i64* %48, align 1
  %50 = insertelement <2 x i64> %47, i64 %49, i32 1
  %51 = getelementptr inbounds i8, i8* %0, i64 %32
  %52 = bitcast i8* %51 to i64*
  %53 = load i64, i64* %52, align 1
  %54 = insertelement <2 x i64> undef, i64 %53, i32 0
  %55 = getelementptr inbounds i8, i8* %0, i64 %18
  %56 = bitcast i8* %55 to i64*
  %57 = load i64, i64* %56, align 1
  %58 = insertelement <2 x i64> %54, i64 %57, i32 1
  %59 = shufflevector <2 x i64> %50, <2 x i64> %42, <2 x i32> <i32 0, i32 2>
  %60 = shufflevector <2 x i64> %42, <2 x i64> %30, <2 x i32> <i32 0, i32 2>
  %61 = insertelement <2 x i64> %42, i64 %49, i32 0
  %62 = bitcast <2 x i64> %42 to <16 x i8>
  %63 = shufflevector <16 x i8> %62, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %64 = bitcast <16 x i8> %63 to <2 x i64>
  %65 = shufflevector <2 x i64> %64, <2 x i64> %58, <2 x i32> <i32 0, i32 2>
  %66 = bitcast <2 x i64> %50 to <16 x i8>
  %67 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %62, <16 x i8> %66) #5
  %68 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %66, <16 x i8> %62) #5
  %69 = or <16 x i8> %68, %67
  %70 = bitcast <2 x i64> %59 to <16 x i8>
  %71 = bitcast <2 x i64> %61 to <16 x i8>
  %72 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %70, <16 x i8> %71) #5
  %73 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %71, <16 x i8> %70) #5
  %74 = or <16 x i8> %73, %72
  %75 = shufflevector <16 x i8> %69, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %76 = icmp ugt <16 x i8> %69, %75
  %77 = select <16 x i1> %76, <16 x i8> %69, <16 x i8> %75
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = bitcast <16 x i8> %78 to <8 x i16>
  %80 = bitcast <16 x i8> %16 to <8 x i16>
  %81 = icmp sgt <8 x i16> %79, %80
  %82 = sext <8 x i1> %81 to <8 x i16>
  %83 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %82, <8 x i16> %82) #5
  %84 = bitcast <16 x i8> %83 to <2 x i64>
  %85 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %74, <16 x i8> %74) #5
  %86 = shufflevector <16 x i8> %74, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %87 = bitcast <16 x i8> %86 to <8 x i16>
  %88 = lshr <8 x i16> %87, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %89 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %88, <8 x i16> %88) #5
  %90 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %85, <16 x i8> %89) #5
  %91 = bitcast <16 x i8> %90 to <2 x i64>
  %92 = bitcast <2 x i64> %30 to <16 x i8>
  %93 = bitcast <2 x i64> %60 to <16 x i8>
  %94 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %92, <16 x i8> %93) #5
  %95 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %93, <16 x i8> %92) #5
  %96 = or <16 x i8> %95, %94
  %97 = icmp ugt <16 x i8> %96, %69
  %98 = select <16 x i1> %97, <16 x i8> %96, <16 x i8> %69
  %99 = bitcast <2 x i64> %58 to <16 x i8>
  %100 = bitcast <2 x i64> %65 to <16 x i8>
  %101 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %99, <16 x i8> %100) #5
  %102 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %100, <16 x i8> %99) #5
  %103 = or <16 x i8> %102, %101
  %104 = icmp ugt <16 x i8> %103, %98
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> %98
  %106 = shufflevector <16 x i8> %105, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %107 = icmp ugt <16 x i8> %105, %106
  %108 = select <16 x i1> %107, <16 x i8> %105, <16 x i8> %106
  %109 = bitcast <16 x i8> %108 to <2 x i64>
  %110 = shufflevector <2 x i64> %91, <2 x i64> %109, <2 x i32> <i32 0, i32 2>
  %111 = bitcast <2 x i64> %110 to <16 x i8>
  %112 = bitcast <2 x i64> %11 to <16 x i8>
  %113 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %112) #5
  %114 = icmp eq <16 x i8> %113, zeroinitializer
  %115 = sext <16 x i1> %114 to <16 x i8>
  %116 = shufflevector <16 x i8> %115, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %117 = xor <16 x i8> %70, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %118 = xor <16 x i8> %71, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %119 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %117, <16 x i8> %118) #5
  %120 = shufflevector <16 x i8> %119, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %121 = and <16 x i8> %120, %83
  %122 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %121, <16 x i8> %119) #5
  %123 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %122, <16 x i8> %119) #5
  %124 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %123, <16 x i8> %119) #5
  %125 = and <16 x i8> %124, %115
  %126 = and <16 x i8> %125, %116
  %127 = bitcast <16 x i8> %126 to <2 x i64>
  %128 = shufflevector <2 x i64> %127, <2 x i64> undef, <2 x i32> zeroinitializer
  %129 = bitcast <2 x i64> %128 to <16 x i8>
  %130 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #5
  %131 = shufflevector <16 x i8> %130, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %132 = shufflevector <16 x i8> %130, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %133 = bitcast <16 x i8> %132 to <8 x i16>
  %134 = ashr <8 x i16> %133, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %135 = bitcast <16 x i8> %131 to <8 x i16>
  %136 = ashr <8 x i16> %135, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %137 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %134, <8 x i16> %136) #5
  %138 = bitcast <16 x i8> %137 to <2 x i64>
  %139 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %137, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>)
  %140 = shufflevector <16 x i8> %139, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %141 = bitcast <16 x i8> %140 to <8 x i16>
  %142 = ashr <8 x i16> %141, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %143 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %142, <8 x i16> %142) #5
  %144 = bitcast <16 x i8> %143 to <2 x i64>
  %145 = xor <2 x i64> %84, <i64 -1, i64 -1>
  %146 = and <2 x i64> %144, %145
  %147 = shufflevector <2 x i64> %138, <2 x i64> %146, <2 x i32> <i32 1, i32 3>
  %148 = shufflevector <2 x i64> %138, <2 x i64> %146, <2 x i32> <i32 0, i32 2>
  %149 = bitcast <2 x i64> %148 to <16 x i8>
  %150 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %118, <16 x i8> %149) #5
  %151 = bitcast <16 x i8> %150 to <2 x i64>
  %152 = bitcast <2 x i64> %147 to <16 x i8>
  %153 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %117, <16 x i8> %152) #5
  %154 = bitcast <16 x i8> %153 to <2 x i64>
  %155 = xor <2 x i64> %151, <i64 -9187201950435737472, i64 -9187201950435737472>
  %156 = xor <2 x i64> %154, <i64 -9187201950435737472, i64 -9187201950435737472>
  %157 = bitcast <2 x i64> %156 to <4 x float>
  %158 = shufflevector <4 x float> %157, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %159 = bitcast i8* %34 to <2 x float>*
  store <2 x float> %158, <2 x float>* %159, align 1
  %160 = extractelement <2 x i64> %156, i32 0
  store i64 %160, i64* %45, align 1
  %161 = extractelement <2 x i64> %155, i32 0
  store i64 %161, i64* %48, align 1
  %162 = bitcast <2 x i64> %155 to <4 x float>
  %163 = shufflevector <4 x float> %162, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %164 = bitcast i8* %39 to <2 x float>*
  store <2 x float> %163, <2 x float>* %164, align 1
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_lpf_vertical_4_sse2(i8* nocapture, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #0 {
  %6 = bitcast i8* %2 to i64*
  %7 = load i64, i64* %6, align 1
  %8 = insertelement <2 x i64> undef, i64 %7, i32 0
  %9 = bitcast i8* %3 to i64*
  %10 = load i64, i64* %9, align 1
  %11 = insertelement <2 x i64> %8, i64 %10, i32 1
  %12 = bitcast i8* %4 to i64*
  %13 = load i64, i64* %12, align 1
  %14 = insertelement <2 x i64> undef, i64 %13, i32 0
  %15 = bitcast <2 x i64> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %17 = getelementptr inbounds i8, i8* %0, i64 -4
  %18 = bitcast i8* %17 to i64*
  %19 = load i64, i64* %18, align 1
  %20 = insertelement <2 x i64> undef, i64 %19, i32 0
  %21 = sext i32 %1 to i64
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = getelementptr inbounds i8, i8* %22, i64 -4
  %24 = bitcast i8* %23 to i64*
  %25 = load i64, i64* %24, align 1
  %26 = insertelement <2 x i64> undef, i64 %25, i32 0
  %27 = bitcast <2 x i64> %20 to <16 x i8>
  %28 = bitcast <2 x i64> %26 to <16 x i8>
  %29 = shufflevector <16 x i8> %27, <16 x i8> %28, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %30 = shl nsw i32 %1, 1
  %31 = sext i32 %30 to i64
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = getelementptr inbounds i8, i8* %32, i64 -4
  %34 = bitcast i8* %33 to i64*
  %35 = load i64, i64* %34, align 1
  %36 = insertelement <2 x i64> undef, i64 %35, i32 0
  %37 = mul nsw i32 %1, 3
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = getelementptr inbounds i8, i8* %39, i64 -4
  %41 = bitcast i8* %40 to i64*
  %42 = load i64, i64* %41, align 1
  %43 = insertelement <2 x i64> undef, i64 %42, i32 0
  %44 = bitcast <2 x i64> %36 to <16 x i8>
  %45 = bitcast <2 x i64> %43 to <16 x i8>
  %46 = shufflevector <16 x i8> %44, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %47 = shl nsw i32 %1, 2
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = getelementptr inbounds i8, i8* %49, i64 -4
  %51 = bitcast i8* %50 to i64*
  %52 = load i64, i64* %51, align 1
  %53 = insertelement <2 x i64> undef, i64 %52, i32 0
  %54 = mul nsw i32 %1, 5
  %55 = sext i32 %54 to i64
  %56 = getelementptr inbounds i8, i8* %0, i64 %55
  %57 = getelementptr inbounds i8, i8* %56, i64 -4
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> undef, i64 %59, i32 0
  %61 = bitcast <2 x i64> %53 to <16 x i8>
  %62 = bitcast <2 x i64> %60 to <16 x i8>
  %63 = shufflevector <16 x i8> %61, <16 x i8> %62, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %64 = mul nsw i32 %1, 6
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds i8, i8* %0, i64 %65
  %67 = getelementptr inbounds i8, i8* %66, i64 -4
  %68 = bitcast i8* %67 to i64*
  %69 = load i64, i64* %68, align 1
  %70 = insertelement <2 x i64> undef, i64 %69, i32 0
  %71 = mul nsw i32 %1, 7
  %72 = sext i32 %71 to i64
  %73 = getelementptr inbounds i8, i8* %0, i64 %72
  %74 = getelementptr inbounds i8, i8* %73, i64 -4
  %75 = bitcast i8* %74 to i64*
  %76 = load i64, i64* %75, align 1
  %77 = insertelement <2 x i64> undef, i64 %76, i32 0
  %78 = bitcast <2 x i64> %70 to <16 x i8>
  %79 = bitcast <2 x i64> %77 to <16 x i8>
  %80 = shufflevector <16 x i8> %78, <16 x i8> %79, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %81 = bitcast <16 x i8> %29 to <8 x i16>
  %82 = bitcast <16 x i8> %46 to <8 x i16>
  %83 = shufflevector <8 x i16> %81, <8 x i16> %82, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %84 = bitcast <16 x i8> %63 to <8 x i16>
  %85 = bitcast <16 x i8> %80 to <8 x i16>
  %86 = shufflevector <8 x i16> %84, <8 x i16> %85, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %87 = bitcast <8 x i16> %83 to <4 x i32>
  %88 = bitcast <8 x i16> %86 to <4 x i32>
  %89 = shufflevector <4 x i32> %87, <4 x i32> %88, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %90 = bitcast <4 x i32> %89 to <2 x i64>
  %91 = shufflevector <4 x i32> %87, <4 x i32> %88, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %92 = bitcast <4 x i32> %91 to <2 x i64>
  %93 = bitcast <4 x i32> %89 to <16 x i8>
  %94 = shufflevector <16 x i8> %93, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %95 = bitcast <16 x i8> %94 to <2 x i64>
  %96 = shufflevector <2 x i64> %90, <2 x i64> %95, <2 x i32> <i32 1, i32 3>
  %97 = bitcast <4 x i32> %91 to <16 x i8>
  %98 = shufflevector <16 x i8> %97, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %99 = bitcast <16 x i8> %98 to <2 x i64>
  %100 = shufflevector <2 x i64> %92, <2 x i64> %99, <2 x i32> <i32 1, i32 3>
  %101 = shufflevector <8 x i16> %81, <8 x i16> %82, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %102 = shufflevector <8 x i16> %84, <8 x i16> %85, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %103 = bitcast <8 x i16> %101 to <4 x i32>
  %104 = bitcast <8 x i16> %102 to <4 x i32>
  %105 = shufflevector <4 x i32> %103, <4 x i32> %104, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %106 = bitcast <4 x i32> %105 to <2 x i64>
  %107 = shufflevector <4 x i32> %103, <4 x i32> %104, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %108 = bitcast <4 x i32> %107 to <2 x i64>
  %109 = shufflevector <2 x i64> %100, <2 x i64> %108, <2 x i32> <i32 0, i32 2>
  %110 = shufflevector <2 x i64> %100, <2 x i64> %108, <2 x i32> <i32 1, i32 3>
  %111 = shufflevector <2 x i64> %109, <2 x i64> %110, <2 x i32> <i32 0, i32 2>
  %112 = shufflevector <2 x i64> %110, <2 x i64> %96, <2 x i32> <i32 0, i32 2>
  %113 = bitcast <2 x i64> %110 to <16 x i8>
  %114 = shufflevector <16 x i8> %113, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %115 = bitcast <16 x i8> %114 to <2 x i64>
  %116 = shufflevector <2 x i64> %115, <2 x i64> %106, <2 x i32> <i32 0, i32 2>
  %117 = bitcast <2 x i64> %109 to <16 x i8>
  %118 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %113, <16 x i8> %117) #5
  %119 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %117, <16 x i8> %113) #5
  %120 = or <16 x i8> %119, %118
  %121 = bitcast <2 x i64> %111 to <16 x i8>
  %122 = bitcast <4 x i32> %107 to <16 x i8>
  %123 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %121, <16 x i8> %122) #5
  %124 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %122, <16 x i8> %121) #5
  %125 = or <16 x i8> %124, %123
  %126 = shufflevector <16 x i8> %120, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %127 = icmp ugt <16 x i8> %120, %126
  %128 = select <16 x i1> %127, <16 x i8> %120, <16 x i8> %126
  %129 = shufflevector <16 x i8> %128, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %130 = bitcast <16 x i8> %129 to <8 x i16>
  %131 = bitcast <16 x i8> %16 to <8 x i16>
  %132 = icmp sgt <8 x i16> %130, %131
  %133 = sext <8 x i1> %132 to <8 x i16>
  %134 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %133, <8 x i16> %133) #5
  %135 = bitcast <16 x i8> %134 to <2 x i64>
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %125, <16 x i8> %125) #5
  %137 = shufflevector <16 x i8> %125, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %138 = bitcast <16 x i8> %137 to <8 x i16>
  %139 = lshr <8 x i16> %138, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %140 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %139, <8 x i16> %139) #5
  %141 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %136, <16 x i8> %140) #5
  %142 = bitcast <16 x i8> %141 to <2 x i64>
  %143 = bitcast <2 x i64> %96 to <16 x i8>
  %144 = bitcast <2 x i64> %112 to <16 x i8>
  %145 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %143, <16 x i8> %144) #5
  %146 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %144, <16 x i8> %143) #5
  %147 = or <16 x i8> %146, %145
  %148 = icmp ugt <16 x i8> %147, %120
  %149 = select <16 x i1> %148, <16 x i8> %147, <16 x i8> %120
  %150 = bitcast <4 x i32> %105 to <16 x i8>
  %151 = bitcast <2 x i64> %116 to <16 x i8>
  %152 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %150, <16 x i8> %151) #5
  %153 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %151, <16 x i8> %150) #5
  %154 = or <16 x i8> %153, %152
  %155 = icmp ugt <16 x i8> %154, %149
  %156 = select <16 x i1> %155, <16 x i8> %154, <16 x i8> %149
  %157 = shufflevector <16 x i8> %156, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %158 = icmp ugt <16 x i8> %156, %157
  %159 = select <16 x i1> %158, <16 x i8> %156, <16 x i8> %157
  %160 = bitcast <16 x i8> %159 to <2 x i64>
  %161 = shufflevector <2 x i64> %142, <2 x i64> %160, <2 x i32> <i32 0, i32 2>
  %162 = bitcast <2 x i64> %161 to <16 x i8>
  %163 = bitcast <2 x i64> %11 to <16 x i8>
  %164 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %162, <16 x i8> %163) #5
  %165 = icmp eq <16 x i8> %164, zeroinitializer
  %166 = sext <16 x i1> %165 to <16 x i8>
  %167 = shufflevector <16 x i8> %166, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %168 = xor <16 x i8> %121, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %169 = xor <16 x i8> %122, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %170 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %168, <16 x i8> %169) #5
  %171 = shufflevector <16 x i8> %170, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %172 = and <16 x i8> %171, %134
  %173 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %172, <16 x i8> %170) #5
  %174 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %173, <16 x i8> %170) #5
  %175 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %174, <16 x i8> %170) #5
  %176 = and <16 x i8> %175, %166
  %177 = and <16 x i8> %176, %167
  %178 = bitcast <16 x i8> %177 to <2 x i64>
  %179 = shufflevector <2 x i64> %178, <2 x i64> undef, <2 x i32> zeroinitializer
  %180 = bitcast <2 x i64> %179 to <16 x i8>
  %181 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %180, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #5
  %182 = shufflevector <16 x i8> %181, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %183 = shufflevector <16 x i8> %181, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %184 = bitcast <16 x i8> %183 to <8 x i16>
  %185 = ashr <8 x i16> %184, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %186 = bitcast <16 x i8> %182 to <8 x i16>
  %187 = ashr <8 x i16> %186, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %188 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %185, <8 x i16> %187) #5
  %189 = bitcast <16 x i8> %188 to <2 x i64>
  %190 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %188, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>)
  %191 = shufflevector <16 x i8> %190, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %192 = bitcast <16 x i8> %191 to <8 x i16>
  %193 = ashr <8 x i16> %192, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %194 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %193, <8 x i16> %193) #5
  %195 = bitcast <16 x i8> %194 to <2 x i64>
  %196 = xor <2 x i64> %135, <i64 -1, i64 -1>
  %197 = and <2 x i64> %195, %196
  %198 = shufflevector <2 x i64> %189, <2 x i64> %197, <2 x i32> <i32 1, i32 3>
  %199 = shufflevector <2 x i64> %189, <2 x i64> %197, <2 x i32> <i32 0, i32 2>
  %200 = bitcast <2 x i64> %199 to <16 x i8>
  %201 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %169, <16 x i8> %200) #5
  %202 = bitcast <2 x i64> %198 to <16 x i8>
  %203 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %168, <16 x i8> %202) #5
  %204 = bitcast <16 x i8> %203 to <2 x i64>
  %205 = xor <2 x i64> %204, <i64 -9187201950435737472, i64 -9187201950435737472>
  %206 = bitcast <2 x i64> %205 to <16 x i8>
  %207 = shufflevector <16 x i8> %206, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %208 = bitcast <16 x i8> %207 to <2 x i64>
  %209 = shufflevector <2 x i64> %205, <2 x i64> %208, <2 x i32> <i32 1, i32 3>
  %210 = bitcast <2 x i64> %209 to <16 x i8>
  %211 = xor <16 x i8> %201, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %212 = shufflevector <16 x i8> %210, <16 x i8> %211, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %213 = shufflevector <16 x i8> %210, <16 x i8> %211, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %214 = shufflevector <16 x i8> %213, <16 x i8> %212, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %215 = shufflevector <16 x i8> %213, <16 x i8> %212, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %216 = getelementptr inbounds i8, i8* %0, i64 -2
  %217 = bitcast <16 x i8> %215 to <4 x i32>
  %218 = extractelement <4 x i32> %217, i32 0
  %219 = bitcast i8* %216 to i32*
  store i32 %218, i32* %219, align 1
  %220 = shufflevector <16 x i8> %215, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %221 = getelementptr inbounds i8, i8* %22, i64 -2
  %222 = bitcast <16 x i8> %220 to <4 x i32>
  %223 = extractelement <4 x i32> %222, i32 0
  %224 = bitcast i8* %221 to i32*
  store i32 %223, i32* %224, align 1
  %225 = shufflevector <16 x i8> %220, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %226 = getelementptr inbounds i8, i8* %32, i64 -2
  %227 = bitcast <16 x i8> %225 to <4 x i32>
  %228 = extractelement <4 x i32> %227, i32 0
  %229 = bitcast i8* %226 to i32*
  store i32 %228, i32* %229, align 1
  %230 = shufflevector <16 x i8> %225, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %231 = getelementptr inbounds i8, i8* %39, i64 -2
  %232 = bitcast <16 x i8> %230 to <4 x i32>
  %233 = extractelement <4 x i32> %232, i32 0
  %234 = bitcast i8* %231 to i32*
  store i32 %233, i32* %234, align 1
  %235 = getelementptr inbounds i8, i8* %49, i64 -2
  %236 = bitcast <16 x i8> %214 to <4 x i32>
  %237 = extractelement <4 x i32> %236, i32 0
  %238 = bitcast i8* %235 to i32*
  store i32 %237, i32* %238, align 1
  %239 = shufflevector <16 x i8> %214, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %240 = getelementptr inbounds i8, i8* %56, i64 -2
  %241 = bitcast <16 x i8> %239 to <4 x i32>
  %242 = extractelement <4 x i32> %241, i32 0
  %243 = bitcast i8* %240 to i32*
  store i32 %242, i32* %243, align 1
  %244 = shufflevector <16 x i8> %239, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %245 = getelementptr inbounds i8, i8* %66, i64 -2
  %246 = bitcast <16 x i8> %244 to <4 x i32>
  %247 = extractelement <4 x i32> %246, i32 0
  %248 = bitcast i8* %245 to i32*
  store i32 %247, i32* %248, align 1
  %249 = shufflevector <16 x i8> %244, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %250 = getelementptr inbounds i8, i8* %73, i64 -2
  %251 = bitcast <16 x i8> %249 to <4 x i32>
  %252 = extractelement <4 x i32> %251, i32 0
  %253 = bitcast i8* %250 to i32*
  store i32 %252, i32* %253, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_lpf_horizontal_16_sse2(i8* nocapture, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #0 {
  %6 = bitcast i8* %2 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 16
  %8 = bitcast i8* %3 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 16
  %10 = bitcast i8* %4 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 16
  %12 = mul nsw i32 %1, 5
  %13 = sext i32 %12 to i64
  %14 = sub nsw i64 0, %13
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = bitcast i8* %15 to i64*
  %17 = load i64, i64* %16, align 1
  %18 = insertelement <2 x i64> undef, i64 %17, i32 0
  %19 = bitcast <2 x i64> %18 to <4 x float>
  %20 = shl nsw i32 %1, 2
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = bitcast i8* %22 to <2 x float>*
  %24 = load <2 x float>, <2 x float>* %23, align 1
  %25 = shufflevector <2 x float> %24, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %26 = shufflevector <4 x float> %19, <4 x float> %25, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %27 = bitcast <4 x float> %26 to <2 x i64>
  %28 = sub nsw i64 0, %21
  %29 = getelementptr inbounds i8, i8* %0, i64 %28
  %30 = bitcast i8* %29 to i64*
  %31 = load i64, i64* %30, align 1
  %32 = insertelement <2 x i64> undef, i64 %31, i32 0
  %33 = bitcast <2 x i64> %32 to <4 x float>
  %34 = mul nsw i32 %1, 3
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = bitcast i8* %36 to <2 x float>*
  %38 = load <2 x float>, <2 x float>* %37, align 1
  %39 = shufflevector <2 x float> %38, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %40 = shufflevector <4 x float> %33, <4 x float> %39, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %41 = bitcast <4 x float> %40 to <2 x i64>
  %42 = sub nsw i64 0, %35
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> undef, i64 %45, i32 0
  %47 = bitcast <2 x i64> %46 to <4 x float>
  %48 = shl nsw i32 %1, 1
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = bitcast i8* %50 to <2 x float>*
  %52 = load <2 x float>, <2 x float>* %51, align 1
  %53 = shufflevector <2 x float> %52, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %54 = shufflevector <4 x float> %47, <4 x float> %53, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %55 = bitcast <4 x float> %54 to <2 x i64>
  %56 = sub nsw i64 0, %49
  %57 = getelementptr inbounds i8, i8* %0, i64 %56
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> undef, i64 %59, i32 0
  %61 = bitcast <2 x i64> %60 to <4 x float>
  %62 = sext i32 %1 to i64
  %63 = getelementptr inbounds i8, i8* %0, i64 %62
  %64 = bitcast i8* %63 to <2 x float>*
  %65 = load <2 x float>, <2 x float>* %64, align 1
  %66 = shufflevector <2 x float> %65, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %67 = shufflevector <4 x float> %61, <4 x float> %66, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %68 = bitcast <4 x float> %67 to <4 x i32>
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %70 = sub nsw i64 0, %62
  %71 = getelementptr inbounds i8, i8* %0, i64 %70
  %72 = bitcast i8* %71 to i64*
  %73 = load i64, i64* %72, align 1
  %74 = insertelement <2 x i64> undef, i64 %73, i32 0
  %75 = bitcast <2 x i64> %74 to <4 x float>
  %76 = bitcast i8* %0 to <2 x float>*
  %77 = load <2 x float>, <2 x float>* %76, align 1
  %78 = shufflevector <2 x float> %77, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %79 = shufflevector <4 x float> %75, <4 x float> %78, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %80 = bitcast <4 x float> %79 to <4 x i32>
  %81 = shufflevector <4 x i32> %80, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %82 = bitcast <4 x float> %67 to <16 x i8>
  %83 = bitcast <4 x float> %79 to <16 x i8>
  %84 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %82, <16 x i8> %83) #5
  %85 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %82) #5
  %86 = or <16 x i8> %85, %84
  %87 = shufflevector <16 x i8> %86, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %88 = bitcast <4 x i32> %81 to <16 x i8>
  %89 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %88) #5
  %90 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %83) #5
  %91 = or <16 x i8> %90, %89
  %92 = bitcast <4 x i32> %69 to <16 x i8>
  %93 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %82, <16 x i8> %92) #5
  %94 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %92, <16 x i8> %82) #5
  %95 = or <16 x i8> %94, %93
  %96 = icmp ugt <16 x i8> %86, %87
  %97 = select <16 x i1> %96, <16 x i8> %86, <16 x i8> %87
  %98 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %97, <16 x i8> %11) #5
  %99 = icmp ne <16 x i8> %98, zeroinitializer
  %100 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %91, <16 x i8> %91) #5
  %101 = bitcast <16 x i8> %95 to <8 x i16>
  %102 = lshr <8 x i16> %101, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %103 = bitcast <8 x i16> %102 to <16 x i8>
  %104 = and <16 x i8> %103, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %105 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> %104) #5
  %106 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %105, <16 x i8> %7) #5
  %107 = icmp ne <16 x i8> %106, zeroinitializer
  %108 = sext <16 x i1> %107 to <16 x i8>
  %109 = icmp ugt <16 x i8> %86, %108
  %110 = select <16 x i1> %109, <16 x i8> %86, <16 x i8> %108
  %111 = bitcast <4 x float> %54 to <16 x i8>
  %112 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %82) #5
  %113 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %82, <16 x i8> %111) #5
  %114 = or <16 x i8> %113, %112
  %115 = bitcast <4 x float> %40 to <16 x i8>
  %116 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %115, <16 x i8> %111) #5
  %117 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %115) #5
  %118 = or <16 x i8> %117, %116
  %119 = icmp ugt <16 x i8> %114, %118
  %120 = select <16 x i1> %119, <16 x i8> %114, <16 x i8> %118
  %121 = icmp ugt <16 x i8> %120, %110
  %122 = select <16 x i1> %121, <16 x i8> %120, <16 x i8> %110
  %123 = shufflevector <16 x i8> %122, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %124 = icmp ugt <16 x i8> %122, %123
  %125 = select <16 x i1> %124, <16 x i8> %122, <16 x i8> %123
  %126 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %125, <16 x i8> %9) #5
  %127 = icmp eq <16 x i8> %126, zeroinitializer
  %128 = xor <16 x i8> %82, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %129 = xor <16 x i8> %92, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %130 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %128, <16 x i8> %129) #5
  %131 = xor <16 x i8> %88, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %132 = xor <16 x i8> %83, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %133 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %131, <16 x i8> %132) #5
  %134 = sext <16 x i1> %99 to <16 x i8>
  %135 = and <16 x i8> %130, %134
  %136 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %135, <16 x i8> %133) #5
  %137 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %136, <16 x i8> %133) #5
  %138 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %137, <16 x i8> %133) #5
  %139 = select <16 x i1> %127, <16 x i8> %138, <16 x i8> zeroinitializer
  %140 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %139, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %141 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %139, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #5
  %142 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %140, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %143 = bitcast <16 x i8> %142 to <8 x i16>
  %144 = ashr <8 x i16> %143, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %145 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %141, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %146 = bitcast <16 x i8> %145 to <8 x i16>
  %147 = ashr <8 x i16> %146, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %148 = sub nsw <8 x i16> zeroinitializer, %144
  %149 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %147, <8 x i16> %148) #5
  %150 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %132, <16 x i8> %149) #5
  %151 = bitcast <16 x i8> %150 to <2 x i64>
  %152 = xor <2 x i64> %151, <i64 -9187201950435737472, i64 -9187201950435737472>
  %153 = add nsw <8 x i16> %144, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %154 = ashr <8 x i16> %153, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %155 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %134, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %156 = bitcast <16 x i8> %155 to <8 x i16>
  %157 = ashr <8 x i16> %156, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %158 = xor <8 x i16> %157, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %159 = and <8 x i16> %154, %158
  %160 = sub nsw <8 x i16> zeroinitializer, %159
  %161 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %159, <8 x i16> %160) #5
  %162 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %128, <16 x i8> %161) #5
  %163 = bitcast <16 x i8> %162 to <2 x i64>
  %164 = xor <2 x i64> %163, <i64 -9187201950435737472, i64 -9187201950435737472>
  %165 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %83) #5
  %166 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %111) #5
  %167 = or <16 x i8> %166, %165
  %168 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %115, <16 x i8> %83) #5
  %169 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %115) #5
  %170 = or <16 x i8> %169, %168
  %171 = icmp ugt <16 x i8> %167, %170
  %172 = select <16 x i1> %171, <16 x i8> %167, <16 x i8> %170
  %173 = icmp ugt <16 x i8> %86, %172
  %174 = select <16 x i1> %173, <16 x i8> %86, <16 x i8> %172
  %175 = shufflevector <16 x i8> %174, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %176 = icmp ugt <16 x i8> %174, %175
  %177 = select <16 x i1> %176, <16 x i8> %174, <16 x i8> %175
  %178 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %177, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %179 = icmp eq <16 x i8> %178, zeroinitializer
  %180 = and <16 x i1> %127, %179
  %181 = sext <16 x i1> %180 to <16 x i8>
  %182 = mul nsw i32 %1, 6
  %183 = sext i32 %182 to i64
  %184 = sub nsw i64 0, %183
  %185 = getelementptr inbounds i8, i8* %0, i64 %184
  %186 = bitcast i8* %185 to i64*
  %187 = load i64, i64* %186, align 1
  %188 = insertelement <2 x i64> undef, i64 %187, i32 0
  %189 = bitcast <2 x i64> %188 to <4 x float>
  %190 = getelementptr inbounds i8, i8* %0, i64 %13
  %191 = bitcast i8* %190 to <2 x float>*
  %192 = load <2 x float>, <2 x float>* %191, align 1
  %193 = shufflevector <2 x float> %192, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %194 = shufflevector <4 x float> %189, <4 x float> %193, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %195 = bitcast <4 x float> %194 to <2 x i64>
  %196 = mul nsw i32 %1, 7
  %197 = sext i32 %196 to i64
  %198 = sub nsw i64 0, %197
  %199 = getelementptr inbounds i8, i8* %0, i64 %198
  %200 = bitcast i8* %199 to i64*
  %201 = load i64, i64* %200, align 1
  %202 = insertelement <2 x i64> undef, i64 %201, i32 0
  %203 = bitcast <2 x i64> %202 to <4 x float>
  %204 = getelementptr inbounds i8, i8* %0, i64 %183
  %205 = bitcast i8* %204 to <2 x float>*
  %206 = load <2 x float>, <2 x float>* %205, align 1
  %207 = shufflevector <2 x float> %206, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %208 = shufflevector <4 x float> %203, <4 x float> %207, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %209 = bitcast <4 x float> %208 to <2 x i64>
  %210 = bitcast <4 x float> %26 to <16 x i8>
  %211 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %210, <16 x i8> %83) #5
  %212 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %210) #5
  %213 = or <16 x i8> %212, %211
  %214 = bitcast <4 x float> %194 to <16 x i8>
  %215 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %214, <16 x i8> %83) #5
  %216 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %214) #5
  %217 = or <16 x i8> %216, %215
  %218 = icmp ugt <16 x i8> %213, %217
  %219 = select <16 x i1> %218, <16 x i8> %213, <16 x i8> %217
  %220 = shl nsw i32 %1, 3
  %221 = sext i32 %220 to i64
  %222 = sub nsw i64 0, %221
  %223 = getelementptr inbounds i8, i8* %0, i64 %222
  %224 = bitcast i8* %223 to i64*
  %225 = load i64, i64* %224, align 1
  %226 = insertelement <2 x i64> undef, i64 %225, i32 0
  %227 = bitcast <2 x i64> %226 to <4 x float>
  %228 = getelementptr inbounds i8, i8* %0, i64 %197
  %229 = bitcast i8* %228 to <2 x float>*
  %230 = load <2 x float>, <2 x float>* %229, align 1
  %231 = shufflevector <2 x float> %230, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %232 = shufflevector <4 x float> %227, <4 x float> %231, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %233 = bitcast <4 x float> %208 to <16 x i8>
  %234 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %233, <16 x i8> %83) #5
  %235 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %233) #5
  %236 = or <16 x i8> %235, %234
  %237 = bitcast <4 x float> %232 to <16 x i8>
  %238 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %237, <16 x i8> %83) #5
  %239 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %83, <16 x i8> %237) #5
  %240 = or <16 x i8> %239, %238
  %241 = icmp ugt <16 x i8> %236, %240
  %242 = select <16 x i1> %241, <16 x i8> %236, <16 x i8> %240
  %243 = icmp ugt <16 x i8> %242, %219
  %244 = select <16 x i1> %243, <16 x i8> %242, <16 x i8> %219
  %245 = shufflevector <16 x i8> %244, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %246 = icmp ugt <16 x i8> %244, %245
  %247 = select <16 x i1> %246, <16 x i8> %244, <16 x i8> %245
  %248 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %247, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %249 = icmp eq <16 x i8> %248, zeroinitializer
  %250 = and <16 x i1> %180, %249
  %251 = sext <16 x i1> %250 to <16 x i8>
  %252 = shufflevector <16 x i8> %237, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %253 = shufflevector <16 x i8> %233, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %254 = shufflevector <16 x i8> %214, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %255 = shufflevector <16 x i8> %210, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %256 = shufflevector <16 x i8> %115, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %257 = shufflevector <16 x i8> %111, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %258 = shufflevector <16 x i8> %82, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %259 = shufflevector <16 x i8> %83, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %260 = shufflevector <16 x i8> %83, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %261 = shufflevector <16 x i8> %82, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %262 = shufflevector <16 x i8> %111, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %263 = shufflevector <16 x i8> %115, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %264 = shufflevector <16 x i8> %210, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %265 = shufflevector <16 x i8> %214, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %266 = shufflevector <16 x i8> %233, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %267 = shufflevector <16 x i8> %237, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %268 = bitcast <16 x i8> %253 to <8 x i16>
  %269 = bitcast <16 x i8> %254 to <8 x i16>
  %270 = bitcast <16 x i8> %255 to <8 x i16>
  %271 = bitcast <16 x i8> %256 to <8 x i16>
  %272 = bitcast <16 x i8> %266 to <8 x i16>
  %273 = bitcast <16 x i8> %265 to <8 x i16>
  %274 = bitcast <16 x i8> %264 to <8 x i16>
  %275 = bitcast <16 x i8> %263 to <8 x i16>
  %276 = bitcast <16 x i8> %257 to <8 x i16>
  %277 = bitcast <16 x i8> %258 to <8 x i16>
  %278 = add <8 x i16> %277, %276
  %279 = bitcast <16 x i8> %259 to <8 x i16>
  %280 = add <8 x i16> %278, %279
  %281 = bitcast <16 x i8> %262 to <8 x i16>
  %282 = bitcast <16 x i8> %261 to <8 x i16>
  %283 = add <8 x i16> %282, %281
  %284 = bitcast <16 x i8> %260 to <8 x i16>
  %285 = add <8 x i16> %283, %284
  %286 = add <8 x i16> %274, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %287 = add <8 x i16> %286, %270
  %288 = add <8 x i16> %287, %275
  %289 = add <8 x i16> %288, %271
  %290 = add <8 x i16> %289, %285
  %291 = add <8 x i16> %290, %280
  %292 = add <8 x i16> %291, %273
  %293 = add <8 x i16> %292, %269
  %294 = add <8 x i16> %293, %272
  %295 = add <8 x i16> %294, %268
  %296 = add <8 x i16> %280, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %297 = add <8 x i16> %296, %285
  %298 = bitcast <16 x i8> %252 to <8 x i16>
  %299 = add <8 x i16> %298, %279
  %300 = add <8 x i16> %299, %295
  %301 = lshr <8 x i16> %300, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %302 = bitcast <16 x i8> %267 to <8 x i16>
  %303 = add <8 x i16> %302, %284
  %304 = add <8 x i16> %303, %295
  %305 = lshr <8 x i16> %304, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %306 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %301, <8 x i16> %305) #5
  %307 = bitcast <16 x i8> %306 to <2 x i64>
  %308 = add <8 x i16> %279, %271
  %309 = add <8 x i16> %308, %297
  %310 = lshr <8 x i16> %309, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %311 = add <8 x i16> %284, %275
  %312 = add <8 x i16> %311, %297
  %313 = lshr <8 x i16> %312, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %310, <8 x i16> %313) #5
  %315 = bitcast <16 x i8> %314 to <2 x i64>
  %316 = shl <8 x i16> %298, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %317 = shl <8 x i16> %302, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %318 = shl <8 x i16> %271, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %319 = shl <8 x i16> %275, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %320 = sub <8 x i16> %295, %272
  %321 = add <8 x i16> %316, %277
  %322 = add <8 x i16> %321, %320
  %323 = lshr <8 x i16> %322, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %324 = add <8 x i16> %317, %282
  %325 = add <8 x i16> %324, %294
  %326 = lshr <8 x i16> %325, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %327 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %323, <8 x i16> %326) #5
  %328 = bitcast <16 x i8> %327 to <2 x i64>
  %329 = sub <8 x i16> %297, %276
  %330 = sub <8 x i16> %297, %281
  %331 = add <8 x i16> %318, %277
  %332 = add <8 x i16> %331, %330
  %333 = lshr <8 x i16> %332, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %334 = add <8 x i16> %319, %282
  %335 = add <8 x i16> %334, %329
  %336 = lshr <8 x i16> %335, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %337 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %333, <8 x i16> %336) #5
  %338 = bitcast <16 x i8> %337 to <2 x i64>
  %339 = mul <8 x i16> %298, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %340 = mul <8 x i16> %302, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %341 = mul <8 x i16> %271, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %342 = mul <8 x i16> %275, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %343 = sub <8 x i16> %320, %273
  %344 = sub <8 x i16> %294, %269
  %345 = add <8 x i16> %339, %276
  %346 = add <8 x i16> %345, %343
  %347 = lshr <8 x i16> %346, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %348 = add <8 x i16> %340, %281
  %349 = add <8 x i16> %348, %344
  %350 = lshr <8 x i16> %349, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %351 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %350) #5
  %352 = bitcast <16 x i8> %351 to <2 x i64>
  %353 = add <8 x i16> %341, %276
  %354 = sub <8 x i16> %353, %282
  %355 = add <8 x i16> %354, %330
  %356 = lshr <8 x i16> %355, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %357 = add <8 x i16> %342, %281
  %358 = sub <8 x i16> %357, %277
  %359 = add <8 x i16> %358, %329
  %360 = lshr <8 x i16> %359, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %361 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %356, <8 x i16> %360) #5
  %362 = bitcast <16 x i8> %361 to <2 x i64>
  %363 = shl <8 x i16> %298, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %364 = shl <8 x i16> %302, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %365 = sub <8 x i16> %343, %274
  %366 = sub <8 x i16> %344, %270
  %367 = add <8 x i16> %363, %271
  %368 = add <8 x i16> %367, %365
  %369 = lshr <8 x i16> %368, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %370 = add <8 x i16> %364, %275
  %371 = add <8 x i16> %370, %366
  %372 = lshr <8 x i16> %371, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %373 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %369, <8 x i16> %372) #5
  %374 = bitcast <16 x i8> %373 to <2 x i64>
  %375 = mul <8 x i16> %298, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %376 = mul <8 x i16> %302, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %377 = sub <8 x i16> %365, %275
  %378 = sub <8 x i16> %366, %271
  %379 = add <8 x i16> %375, %270
  %380 = add <8 x i16> %379, %377
  %381 = lshr <8 x i16> %380, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %382 = add <8 x i16> %376, %274
  %383 = add <8 x i16> %382, %378
  %384 = lshr <8 x i16> %383, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %385 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %381, <8 x i16> %384) #5
  %386 = bitcast <16 x i8> %385 to <2 x i64>
  %387 = mul <8 x i16> %298, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %388 = mul <8 x i16> %302, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %389 = sub <8 x i16> %377, %281
  %390 = sub <8 x i16> %378, %276
  %391 = add <8 x i16> %387, %269
  %392 = add <8 x i16> %391, %389
  %393 = lshr <8 x i16> %392, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %394 = add <8 x i16> %388, %273
  %395 = add <8 x i16> %394, %390
  %396 = lshr <8 x i16> %395, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %397 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %393, <8 x i16> %396) #5
  %398 = bitcast <16 x i8> %397 to <2 x i64>
  %399 = mul <8 x i16> %298, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %400 = mul <8 x i16> %302, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %401 = sub <8 x i16> %268, %282
  %402 = add <8 x i16> %401, %399
  %403 = add <8 x i16> %402, %389
  %404 = lshr <8 x i16> %403, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %405 = sub <8 x i16> %272, %277
  %406 = add <8 x i16> %405, %400
  %407 = add <8 x i16> %406, %390
  %408 = lshr <8 x i16> %407, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %409 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %404, <8 x i16> %408) #5
  %410 = bitcast <16 x i8> %409 to <2 x i64>
  %411 = bitcast <16 x i8> %181 to <4 x i32>
  %412 = shufflevector <4 x i32> %411, <4 x i32> undef, <4 x i32> <i32 0, i32 1, i32 0, i32 1>
  %413 = bitcast <4 x i32> %412 to <2 x i64>
  %414 = bitcast <16 x i8> %251 to <4 x i32>
  %415 = shufflevector <4 x i32> %414, <4 x i32> undef, <4 x i32> <i32 0, i32 1, i32 0, i32 1>
  %416 = bitcast <4 x i32> %415 to <2 x i64>
  %417 = xor <2 x i64> %413, <i64 -1, i64 -1>
  %418 = and <2 x i64> %417, %55
  %419 = and <2 x i64> %413, %362
  %420 = or <2 x i64> %419, %418
  %421 = and <2 x i64> %164, %417
  %422 = and <2 x i64> %413, %338
  %423 = or <2 x i64> %422, %421
  %424 = and <2 x i64> %152, %417
  %425 = and <2 x i64> %413, %315
  %426 = or <2 x i64> %425, %424
  %427 = xor <2 x i64> %416, <i64 -1, i64 -1>
  %428 = and <2 x i64> %427, %209
  %429 = and <2 x i64> %416, %410
  %430 = or <2 x i64> %429, %428
  %431 = extractelement <2 x i64> %430, i32 0
  store i64 %431, i64* %200, align 1
  %432 = bitcast <2 x i64> %430 to <4 x float>
  %433 = shufflevector <4 x float> %432, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %433, <2 x float>* %205, align 1
  %434 = and <2 x i64> %427, %195
  %435 = and <2 x i64> %416, %398
  %436 = or <2 x i64> %435, %434
  %437 = extractelement <2 x i64> %436, i32 0
  store i64 %437, i64* %186, align 1
  %438 = bitcast <2 x i64> %436 to <4 x float>
  %439 = shufflevector <4 x float> %438, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %439, <2 x float>* %191, align 1
  %440 = and <2 x i64> %427, %27
  %441 = and <2 x i64> %416, %386
  %442 = or <2 x i64> %441, %440
  %443 = extractelement <2 x i64> %442, i32 0
  store i64 %443, i64* %16, align 1
  %444 = bitcast <2 x i64> %442 to <4 x float>
  %445 = shufflevector <4 x float> %444, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %445, <2 x float>* %23, align 1
  %446 = and <2 x i64> %427, %41
  %447 = and <2 x i64> %416, %374
  %448 = or <2 x i64> %447, %446
  %449 = extractelement <2 x i64> %448, i32 0
  store i64 %449, i64* %30, align 1
  %450 = bitcast <2 x i64> %448 to <4 x float>
  %451 = shufflevector <4 x float> %450, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %451, <2 x float>* %37, align 1
  %452 = and <2 x i64> %420, %427
  %453 = and <2 x i64> %416, %352
  %454 = or <2 x i64> %452, %453
  %455 = extractelement <2 x i64> %454, i32 0
  store i64 %455, i64* %44, align 1
  %456 = bitcast <2 x i64> %454 to <4 x float>
  %457 = shufflevector <4 x float> %456, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %457, <2 x float>* %51, align 1
  %458 = and <2 x i64> %423, %427
  %459 = and <2 x i64> %416, %328
  %460 = or <2 x i64> %458, %459
  %461 = extractelement <2 x i64> %460, i32 0
  store i64 %461, i64* %58, align 1
  %462 = bitcast <2 x i64> %460 to <4 x float>
  %463 = shufflevector <4 x float> %462, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %463, <2 x float>* %64, align 1
  %464 = and <2 x i64> %426, %427
  %465 = and <2 x i64> %416, %307
  %466 = or <2 x i64> %464, %465
  %467 = extractelement <2 x i64> %466, i32 0
  store i64 %467, i64* %72, align 1
  %468 = bitcast <2 x i64> %466 to <4 x float>
  %469 = shufflevector <4 x float> %468, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  store <2 x float> %469, <2 x float>* %76, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_lpf_horizontal_16_dual_sse2(i8* nocapture, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #2 {
  %6 = bitcast i8* %2 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 16
  %8 = bitcast i8* %3 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 16
  %10 = bitcast i8* %4 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 16
  %12 = shl nsw i32 %1, 3
  %13 = sext i32 %12 to i64
  %14 = sub nsw i64 0, %13
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = bitcast i8* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 1
  %18 = mul nsw i32 %1, 7
  %19 = sext i32 %18 to i64
  %20 = sub nsw i64 0, %19
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = bitcast i8* %21 to <2 x i64>*
  %23 = load <2 x i64>, <2 x i64>* %22, align 1
  %24 = mul nsw i32 %1, 6
  %25 = sext i32 %24 to i64
  %26 = sub nsw i64 0, %25
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to <2 x i64>*
  %29 = load <2 x i64>, <2 x i64>* %28, align 1
  %30 = mul nsw i32 %1, 5
  %31 = sext i32 %30 to i64
  %32 = sub nsw i64 0, %31
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = bitcast i8* %33 to <2 x i64>*
  %35 = load <2 x i64>, <2 x i64>* %34, align 1
  %36 = shl nsw i32 %1, 2
  %37 = sext i32 %36 to i64
  %38 = sub nsw i64 0, %37
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = bitcast i8* %39 to <2 x i64>*
  %41 = load <2 x i64>, <2 x i64>* %40, align 1
  %42 = mul nsw i32 %1, 3
  %43 = sext i32 %42 to i64
  %44 = sub nsw i64 0, %43
  %45 = getelementptr inbounds i8, i8* %0, i64 %44
  %46 = bitcast i8* %45 to <2 x i64>*
  %47 = load <2 x i64>, <2 x i64>* %46, align 1
  %48 = shl nsw i32 %1, 1
  %49 = sext i32 %48 to i64
  %50 = sub nsw i64 0, %49
  %51 = getelementptr inbounds i8, i8* %0, i64 %50
  %52 = bitcast i8* %51 to <2 x i64>*
  %53 = bitcast i8* %51 to <16 x i8>*
  %54 = load <16 x i8>, <16 x i8>* %53, align 1
  %55 = sext i32 %1 to i64
  %56 = sub nsw i64 0, %55
  %57 = getelementptr inbounds i8, i8* %0, i64 %56
  %58 = bitcast i8* %57 to <2 x i64>*
  %59 = bitcast i8* %57 to <16 x i8>*
  %60 = load <16 x i8>, <16 x i8>* %59, align 1
  %61 = bitcast i8* %0 to <2 x i64>*
  %62 = bitcast i8* %0 to <16 x i8>*
  %63 = load <16 x i8>, <16 x i8>* %62, align 1
  %64 = getelementptr inbounds i8, i8* %0, i64 %55
  %65 = bitcast i8* %64 to <2 x i64>*
  %66 = bitcast i8* %64 to <16 x i8>*
  %67 = load <16 x i8>, <16 x i8>* %66, align 1
  %68 = getelementptr inbounds i8, i8* %0, i64 %49
  %69 = bitcast i8* %68 to <2 x i64>*
  %70 = load <2 x i64>, <2 x i64>* %69, align 1
  %71 = getelementptr inbounds i8, i8* %0, i64 %43
  %72 = bitcast i8* %71 to <2 x i64>*
  %73 = load <2 x i64>, <2 x i64>* %72, align 1
  %74 = getelementptr inbounds i8, i8* %0, i64 %37
  %75 = bitcast i8* %74 to <2 x i64>*
  %76 = load <2 x i64>, <2 x i64>* %75, align 1
  %77 = getelementptr inbounds i8, i8* %0, i64 %31
  %78 = bitcast i8* %77 to <2 x i64>*
  %79 = load <2 x i64>, <2 x i64>* %78, align 1
  %80 = getelementptr inbounds i8, i8* %0, i64 %25
  %81 = bitcast i8* %80 to <2 x i64>*
  %82 = load <2 x i64>, <2 x i64>* %81, align 1
  %83 = getelementptr inbounds i8, i8* %0, i64 %19
  %84 = bitcast i8* %83 to <16 x i8>*
  %85 = load <16 x i8>, <16 x i8>* %84, align 1
  %86 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %54, <16 x i8> %60) #5
  %87 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %54) #5
  %88 = or <16 x i8> %87, %86
  %89 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %67, <16 x i8> %63) #5
  %90 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %67) #5
  %91 = or <16 x i8> %90, %89
  %92 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %63) #5
  %93 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %60) #5
  %94 = or <16 x i8> %93, %92
  %95 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %54, <16 x i8> %67) #5
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %67, <16 x i8> %54) #5
  %97 = or <16 x i8> %96, %95
  %98 = icmp ugt <16 x i8> %88, %91
  %99 = select <16 x i1> %98, <16 x i8> %88, <16 x i8> %91
  %100 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %94, <16 x i8> %94) #5
  %101 = bitcast <16 x i8> %97 to <8 x i16>
  %102 = lshr <8 x i16> %101, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %103 = bitcast <8 x i16> %102 to <16 x i8>
  %104 = and <16 x i8> %103, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %105 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> %104) #5
  %106 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %105, <16 x i8> %7) #5
  %107 = icmp ne <16 x i8> %106, zeroinitializer
  %108 = sext <16 x i1> %107 to <16 x i8>
  %109 = icmp ugt <16 x i8> %99, %108
  %110 = select <16 x i1> %109, <16 x i8> %99, <16 x i8> %108
  %111 = bitcast <2 x i64> %47 to <16 x i8>
  %112 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %54) #5
  %113 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %54, <16 x i8> %111) #5
  %114 = or <16 x i8> %113, %112
  %115 = bitcast <2 x i64> %41 to <16 x i8>
  %116 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %115, <16 x i8> %111) #5
  %117 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %115) #5
  %118 = or <16 x i8> %117, %116
  %119 = icmp ugt <16 x i8> %114, %118
  %120 = select <16 x i1> %119, <16 x i8> %114, <16 x i8> %118
  %121 = icmp ugt <16 x i8> %120, %110
  %122 = select <16 x i1> %121, <16 x i8> %120, <16 x i8> %110
  %123 = bitcast <2 x i64> %70 to <16 x i8>
  %124 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %123, <16 x i8> %67) #5
  %125 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %67, <16 x i8> %123) #5
  %126 = or <16 x i8> %125, %124
  %127 = bitcast <2 x i64> %73 to <16 x i8>
  %128 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %127, <16 x i8> %123) #5
  %129 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %123, <16 x i8> %127) #5
  %130 = or <16 x i8> %129, %128
  %131 = icmp ugt <16 x i8> %126, %130
  %132 = select <16 x i1> %131, <16 x i8> %126, <16 x i8> %130
  %133 = icmp ugt <16 x i8> %132, %122
  %134 = select <16 x i1> %133, <16 x i8> %132, <16 x i8> %122
  %135 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %134, <16 x i8> %9) #5
  %136 = icmp eq <16 x i8> %135, zeroinitializer
  %137 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %60) #5
  %138 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %111) #5
  %139 = or <16 x i8> %138, %137
  %140 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %123, <16 x i8> %63) #5
  %141 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %123) #5
  %142 = or <16 x i8> %141, %140
  %143 = icmp ugt <16 x i8> %139, %142
  %144 = select <16 x i1> %143, <16 x i8> %139, <16 x i8> %142
  %145 = icmp ugt <16 x i8> %144, %99
  %146 = select <16 x i1> %145, <16 x i8> %144, <16 x i8> %99
  %147 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %115, <16 x i8> %60) #5
  %148 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %115) #5
  %149 = or <16 x i8> %148, %147
  %150 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %127, <16 x i8> %63) #5
  %151 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %127) #5
  %152 = or <16 x i8> %151, %150
  %153 = icmp ugt <16 x i8> %149, %152
  %154 = select <16 x i1> %153, <16 x i8> %149, <16 x i8> %152
  %155 = icmp ugt <16 x i8> %154, %146
  %156 = select <16 x i1> %155, <16 x i8> %154, <16 x i8> %146
  %157 = bitcast <2 x i64> %35 to <16 x i8>
  %158 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %157, <16 x i8> %60) #5
  %159 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %157) #5
  %160 = or <16 x i8> %159, %158
  %161 = bitcast <2 x i64> %76 to <16 x i8>
  %162 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %161, <16 x i8> %63) #5
  %163 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %161) #5
  %164 = or <16 x i8> %163, %162
  %165 = icmp ugt <16 x i8> %160, %164
  %166 = select <16 x i1> %165, <16 x i8> %160, <16 x i8> %164
  %167 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %156, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %168 = icmp eq <16 x i8> %167, zeroinitializer
  %169 = and <16 x i1> %136, %168
  %170 = sext <16 x i1> %169 to <16 x i8>
  %171 = bitcast <16 x i8> %170 to <2 x i64>
  %172 = bitcast <2 x i64> %29 to <16 x i8>
  %173 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %172, <16 x i8> %60) #5
  %174 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %172) #5
  %175 = or <16 x i8> %174, %173
  %176 = bitcast <2 x i64> %79 to <16 x i8>
  %177 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %176, <16 x i8> %63) #5
  %178 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %176) #5
  %179 = or <16 x i8> %178, %177
  %180 = icmp ugt <16 x i8> %175, %179
  %181 = select <16 x i1> %180, <16 x i8> %175, <16 x i8> %179
  %182 = icmp ugt <16 x i8> %166, %181
  %183 = select <16 x i1> %182, <16 x i8> %166, <16 x i8> %181
  %184 = bitcast <2 x i64> %23 to <16 x i8>
  %185 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %184, <16 x i8> %60) #5
  %186 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %184) #5
  %187 = or <16 x i8> %186, %185
  %188 = bitcast <2 x i64> %82 to <16 x i8>
  %189 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %188, <16 x i8> %63) #5
  %190 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %188) #5
  %191 = or <16 x i8> %190, %189
  %192 = icmp ugt <16 x i8> %187, %191
  %193 = select <16 x i1> %192, <16 x i8> %187, <16 x i8> %191
  %194 = icmp ugt <16 x i8> %193, %183
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> %183
  %196 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %17, <16 x i8> %60) #5
  %197 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %17) #5
  %198 = or <16 x i8> %197, %196
  %199 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %85, <16 x i8> %63) #5
  %200 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %63, <16 x i8> %85) #5
  %201 = or <16 x i8> %200, %199
  %202 = icmp ugt <16 x i8> %198, %201
  %203 = select <16 x i1> %202, <16 x i8> %198, <16 x i8> %201
  %204 = icmp ugt <16 x i8> %203, %195
  %205 = select <16 x i1> %204, <16 x i8> %203, <16 x i8> %195
  %206 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %205, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %207 = icmp eq <16 x i8> %206, zeroinitializer
  %208 = and <16 x i1> %169, %207
  %209 = sext <16 x i1> %208 to <16 x i8>
  %210 = bitcast <16 x i8> %209 to <2 x i64>
  %211 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %99, <16 x i8> %11) #5
  %212 = icmp eq <16 x i8> %211, zeroinitializer
  %213 = sext <16 x i1> %212 to <16 x i8>
  %214 = xor <16 x i8> %54, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %215 = xor <16 x i8> %67, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %216 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %214, <16 x i8> %215) #5
  %217 = xor <16 x i8> %63, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %218 = xor <16 x i8> %60, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %219 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %217, <16 x i8> %218) #5
  %220 = xor <16 x i8> %213, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %221 = and <16 x i8> %216, %220
  %222 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %221, <16 x i8> %219) #5
  %223 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %222, <16 x i8> %219) #5
  %224 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %223, <16 x i8> %219) #5
  %225 = select <16 x i1> %136, <16 x i8> %224, <16 x i8> zeroinitializer
  %226 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %225, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %227 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %225, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #5
  %228 = ashr <16 x i8> %226, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %229 = bitcast <16 x i8> %228 to <2 x i64>
  %230 = bitcast <16 x i8> %226 to <8 x i16>
  %231 = lshr <8 x i16> %230, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %232 = bitcast <8 x i16> %231 to <2 x i64>
  %233 = and <2 x i64> %229, <i64 -2242545357980376864, i64 -2242545357980376864>
  %234 = and <2 x i64> %232, <i64 2242545357980376863, i64 2242545357980376863>
  %235 = or <2 x i64> %234, %233
  %236 = bitcast <2 x i64> %235 to <16 x i8>
  %237 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %217, <16 x i8> %236) #5
  %238 = bitcast <16 x i8> %237 to <2 x i64>
  %239 = xor <2 x i64> %238, <i64 -9187201950435737472, i64 -9187201950435737472>
  %240 = ashr <16 x i8> %227, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %241 = bitcast <16 x i8> %240 to <2 x i64>
  %242 = bitcast <16 x i8> %227 to <8 x i16>
  %243 = lshr <8 x i16> %242, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %244 = bitcast <8 x i16> %243 to <2 x i64>
  %245 = and <2 x i64> %241, <i64 -2242545357980376864, i64 -2242545357980376864>
  %246 = and <2 x i64> %244, <i64 2242545357980376863, i64 2242545357980376863>
  %247 = or <2 x i64> %246, %245
  %248 = bitcast <2 x i64> %247 to <16 x i8>
  %249 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %218, <16 x i8> %248) #5
  %250 = bitcast <16 x i8> %249 to <2 x i64>
  %251 = xor <2 x i64> %250, <i64 -9187201950435737472, i64 -9187201950435737472>
  %252 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %236, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %253 = ashr <16 x i8> %252, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %254 = bitcast <16 x i8> %253 to <2 x i64>
  %255 = bitcast <16 x i8> %252 to <8 x i16>
  %256 = lshr <8 x i16> %255, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %257 = bitcast <8 x i16> %256 to <2 x i64>
  %258 = and <2 x i64> %254, <i64 -9187201950435737472, i64 -9187201950435737472>
  %259 = and <2 x i64> %257, <i64 9187201950435737471, i64 9187201950435737471>
  %260 = or <2 x i64> %259, %258
  %261 = bitcast <2 x i64> %260 to <16 x i8>
  %262 = and <16 x i8> %261, %213
  %263 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %214, <16 x i8> %262) #5
  %264 = bitcast <16 x i8> %263 to <2 x i64>
  %265 = xor <2 x i64> %264, <i64 -9187201950435737472, i64 -9187201950435737472>
  %266 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %215, <16 x i8> %262) #5
  %267 = bitcast <16 x i8> %266 to <2 x i64>
  %268 = xor <2 x i64> %267, <i64 -9187201950435737472, i64 -9187201950435737472>
  %269 = shufflevector <16 x i8> %115, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %270 = shufflevector <16 x i8> %111, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %271 = shufflevector <16 x i8> %54, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %272 = shufflevector <16 x i8> %60, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %273 = shufflevector <16 x i8> %63, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %274 = shufflevector <16 x i8> %67, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %275 = shufflevector <16 x i8> %123, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %276 = shufflevector <16 x i8> %127, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %277 = shufflevector <16 x i8> %115, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %278 = shufflevector <16 x i8> %111, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %279 = shufflevector <16 x i8> %54, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %280 = shufflevector <16 x i8> %60, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %281 = shufflevector <16 x i8> %63, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %282 = shufflevector <16 x i8> %67, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %283 = shufflevector <16 x i8> %123, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %284 = shufflevector <16 x i8> %127, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %285 = bitcast <16 x i8> %269 to <8 x i16>
  %286 = bitcast <16 x i8> %270 to <8 x i16>
  %287 = bitcast <16 x i8> %271 to <8 x i16>
  %288 = add <8 x i16> %287, %286
  %289 = bitcast <16 x i8> %272 to <8 x i16>
  %290 = bitcast <16 x i8> %273 to <8 x i16>
  %291 = add <8 x i16> %290, %289
  %292 = mul <8 x i16> %285, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %293 = add <8 x i16> %291, %288
  %294 = add <8 x i16> %293, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %295 = add <8 x i16> %294, %286
  %296 = add <8 x i16> %295, %292
  %297 = bitcast <16 x i8> %277 to <8 x i16>
  %298 = bitcast <16 x i8> %278 to <8 x i16>
  %299 = bitcast <16 x i8> %279 to <8 x i16>
  %300 = add <8 x i16> %299, %298
  %301 = bitcast <16 x i8> %280 to <8 x i16>
  %302 = bitcast <16 x i8> %281 to <8 x i16>
  %303 = add <8 x i16> %302, %301
  %304 = mul <8 x i16> %297, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %305 = add <8 x i16> %303, %300
  %306 = add <8 x i16> %305, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %307 = add <8 x i16> %306, %298
  %308 = add <8 x i16> %307, %304
  %309 = lshr <8 x i16> %296, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %310 = lshr <8 x i16> %308, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %311 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %309, <8 x i16> %310) #5
  %312 = and <16 x i8> %311, %170
  %313 = bitcast <16 x i8> %312 to <2 x i64>
  %314 = xor <2 x i64> %171, <i64 -1, i64 -1>
  %315 = and <2 x i64> %47, %314
  %316 = or <2 x i64> %315, %313
  %317 = bitcast <16 x i8> %274 to <8 x i16>
  %318 = add <8 x i16> %286, %285
  %319 = sub <8 x i16> %287, %318
  %320 = add <8 x i16> %319, %317
  %321 = add <8 x i16> %320, %296
  %322 = bitcast <16 x i8> %282 to <8 x i16>
  %323 = add <8 x i16> %298, %297
  %324 = sub <8 x i16> %299, %323
  %325 = add <8 x i16> %324, %322
  %326 = add <8 x i16> %325, %308
  %327 = lshr <8 x i16> %321, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %328 = lshr <8 x i16> %326, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %329 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %327, <8 x i16> %328) #5
  %330 = and <16 x i8> %329, %170
  %331 = bitcast <16 x i8> %330 to <2 x i64>
  %332 = and <2 x i64> %265, %314
  %333 = or <2 x i64> %332, %331
  %334 = bitcast <16 x i8> %275 to <8 x i16>
  %335 = add <8 x i16> %287, %285
  %336 = sub <8 x i16> %289, %335
  %337 = add <8 x i16> %336, %334
  %338 = add <8 x i16> %337, %321
  %339 = bitcast <16 x i8> %283 to <8 x i16>
  %340 = add <8 x i16> %299, %297
  %341 = sub <8 x i16> %301, %340
  %342 = add <8 x i16> %341, %339
  %343 = add <8 x i16> %342, %326
  %344 = lshr <8 x i16> %338, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %345 = lshr <8 x i16> %343, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %346 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %344, <8 x i16> %345) #5
  %347 = and <16 x i8> %346, %170
  %348 = bitcast <16 x i8> %347 to <2 x i64>
  %349 = and <2 x i64> %251, %314
  %350 = or <2 x i64> %349, %348
  %351 = bitcast <16 x i8> %276 to <8 x i16>
  %352 = add <8 x i16> %289, %285
  %353 = sub <8 x i16> %290, %352
  %354 = add <8 x i16> %353, %351
  %355 = add <8 x i16> %354, %338
  %356 = bitcast <16 x i8> %284 to <8 x i16>
  %357 = add <8 x i16> %301, %297
  %358 = sub <8 x i16> %302, %357
  %359 = add <8 x i16> %358, %356
  %360 = add <8 x i16> %359, %343
  %361 = lshr <8 x i16> %355, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %362 = lshr <8 x i16> %360, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %363 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %361, <8 x i16> %362) #5
  %364 = and <16 x i8> %363, %170
  %365 = bitcast <16 x i8> %364 to <2 x i64>
  %366 = and <2 x i64> %239, %314
  %367 = or <2 x i64> %366, %365
  %368 = add <8 x i16> %290, %286
  %369 = sub <8 x i16> %317, %368
  %370 = add <8 x i16> %369, %351
  %371 = add <8 x i16> %370, %355
  %372 = add <8 x i16> %302, %298
  %373 = sub <8 x i16> %322, %372
  %374 = add <8 x i16> %373, %356
  %375 = add <8 x i16> %374, %360
  %376 = lshr <8 x i16> %371, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %377 = lshr <8 x i16> %375, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %378 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %376, <8 x i16> %377) #5
  %379 = and <16 x i8> %378, %170
  %380 = bitcast <16 x i8> %379 to <2 x i64>
  %381 = and <2 x i64> %268, %314
  %382 = or <2 x i64> %381, %380
  %383 = add <8 x i16> %317, %287
  %384 = sub <8 x i16> %334, %383
  %385 = add <8 x i16> %384, %351
  %386 = add <8 x i16> %385, %371
  %387 = add <8 x i16> %322, %299
  %388 = sub <8 x i16> %339, %387
  %389 = add <8 x i16> %388, %356
  %390 = add <8 x i16> %389, %375
  %391 = lshr <8 x i16> %386, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %392 = lshr <8 x i16> %390, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %393 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %391, <8 x i16> %392) #5
  %394 = and <16 x i8> %393, %170
  %395 = bitcast <16 x i8> %394 to <2 x i64>
  %396 = and <2 x i64> %70, %314
  %397 = or <2 x i64> %396, %395
  %398 = shufflevector <16 x i8> %17, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %399 = shufflevector <16 x i8> %184, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %400 = shufflevector <16 x i8> %172, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %401 = shufflevector <16 x i8> %157, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %402 = shufflevector <16 x i8> %161, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %403 = shufflevector <16 x i8> %176, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %404 = shufflevector <16 x i8> %188, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %405 = shufflevector <16 x i8> %85, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %406 = shufflevector <16 x i8> %17, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %407 = shufflevector <16 x i8> %184, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %408 = shufflevector <16 x i8> %172, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %409 = shufflevector <16 x i8> %157, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %410 = shufflevector <16 x i8> %161, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %411 = shufflevector <16 x i8> %176, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %412 = shufflevector <16 x i8> %188, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %413 = shufflevector <16 x i8> %85, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %414 = bitcast <16 x i8> %398 to <8 x i16>
  %415 = mul <8 x i16> %414, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %416 = bitcast <16 x i8> %399 to <8 x i16>
  %417 = shl <8 x i16> %416, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %418 = bitcast <16 x i8> %401 to <8 x i16>
  %419 = bitcast <16 x i8> %400 to <8 x i16>
  %420 = add <8 x i16> %288, %285
  %421 = add <8 x i16> %420, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %422 = add <8 x i16> %421, %415
  %423 = add <8 x i16> %422, %419
  %424 = add <8 x i16> %423, %417
  %425 = add <8 x i16> %424, %418
  %426 = add <8 x i16> %425, %291
  %427 = bitcast <16 x i8> %406 to <8 x i16>
  %428 = mul <8 x i16> %427, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %429 = bitcast <16 x i8> %407 to <8 x i16>
  %430 = shl <8 x i16> %429, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %431 = bitcast <16 x i8> %409 to <8 x i16>
  %432 = bitcast <16 x i8> %408 to <8 x i16>
  %433 = add <8 x i16> %300, %297
  %434 = add <8 x i16> %433, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %435 = add <8 x i16> %434, %428
  %436 = add <8 x i16> %435, %432
  %437 = add <8 x i16> %436, %430
  %438 = add <8 x i16> %437, %431
  %439 = add <8 x i16> %438, %303
  %440 = lshr <8 x i16> %426, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %441 = lshr <8 x i16> %439, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %442 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %440, <8 x i16> %441) #5
  %443 = and <16 x i8> %442, %209
  %444 = bitcast <16 x i8> %443 to <2 x i64>
  %445 = xor <2 x i64> %210, <i64 -1, i64 -1>
  %446 = and <2 x i64> %23, %445
  %447 = or <2 x i64> %446, %444
  store <2 x i64> %447, <2 x i64>* %22, align 1
  %448 = add <8 x i16> %416, %414
  %449 = sub <8 x i16> %419, %448
  %450 = add <8 x i16> %449, %317
  %451 = add <8 x i16> %450, %426
  %452 = add <8 x i16> %429, %427
  %453 = sub <8 x i16> %432, %452
  %454 = add <8 x i16> %453, %322
  %455 = add <8 x i16> %454, %439
  %456 = lshr <8 x i16> %451, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %457 = lshr <8 x i16> %455, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %458 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %456, <8 x i16> %457) #5
  %459 = and <16 x i8> %458, %209
  %460 = bitcast <16 x i8> %459 to <2 x i64>
  %461 = and <2 x i64> %29, %445
  %462 = or <2 x i64> %461, %460
  store <2 x i64> %462, <2 x i64>* %28, align 1
  %463 = add <8 x i16> %419, %414
  %464 = sub <8 x i16> %418, %463
  %465 = add <8 x i16> %464, %334
  %466 = add <8 x i16> %465, %451
  %467 = add <8 x i16> %432, %427
  %468 = sub <8 x i16> %431, %467
  %469 = add <8 x i16> %468, %339
  %470 = add <8 x i16> %469, %455
  %471 = lshr <8 x i16> %466, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %473 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %472) #5
  %474 = and <16 x i8> %473, %209
  %475 = bitcast <16 x i8> %474 to <2 x i64>
  %476 = and <2 x i64> %35, %445
  %477 = or <2 x i64> %476, %475
  store <2 x i64> %477, <2 x i64>* %34, align 1
  %478 = add <8 x i16> %418, %414
  %479 = sub <8 x i16> %285, %478
  %480 = add <8 x i16> %479, %351
  %481 = add <8 x i16> %480, %466
  %482 = add <8 x i16> %431, %427
  %483 = sub <8 x i16> %297, %482
  %484 = add <8 x i16> %483, %356
  %485 = add <8 x i16> %484, %470
  %486 = lshr <8 x i16> %481, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %487 = lshr <8 x i16> %485, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %488 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %486, <8 x i16> %487) #5
  %489 = and <16 x i8> %488, %209
  %490 = bitcast <16 x i8> %489 to <2 x i64>
  %491 = and <2 x i64> %41, %445
  %492 = or <2 x i64> %491, %490
  store <2 x i64> %492, <2 x i64>* %40, align 1
  %493 = bitcast <16 x i8> %402 to <8 x i16>
  %494 = add <8 x i16> %285, %414
  %495 = sub <8 x i16> %286, %494
  %496 = add <8 x i16> %495, %493
  %497 = add <8 x i16> %496, %481
  %498 = bitcast <16 x i8> %410 to <8 x i16>
  %499 = add <8 x i16> %297, %427
  %500 = sub <8 x i16> %298, %499
  %501 = add <8 x i16> %500, %498
  %502 = add <8 x i16> %501, %485
  %503 = lshr <8 x i16> %497, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %504 = lshr <8 x i16> %502, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %505 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %503, <8 x i16> %504) #5
  %506 = and <16 x i8> %505, %209
  %507 = bitcast <16 x i8> %506 to <2 x i64>
  %508 = and <2 x i64> %316, %445
  %509 = or <2 x i64> %508, %507
  store <2 x i64> %509, <2 x i64>* %46, align 1
  %510 = bitcast <16 x i8> %403 to <8 x i16>
  %511 = add <8 x i16> %286, %414
  %512 = sub <8 x i16> %287, %511
  %513 = add <8 x i16> %512, %510
  %514 = add <8 x i16> %513, %497
  %515 = bitcast <16 x i8> %411 to <8 x i16>
  %516 = add <8 x i16> %298, %427
  %517 = sub <8 x i16> %299, %516
  %518 = add <8 x i16> %517, %515
  %519 = add <8 x i16> %518, %502
  %520 = lshr <8 x i16> %514, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %521 = lshr <8 x i16> %519, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %522 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %520, <8 x i16> %521) #5
  %523 = and <16 x i8> %522, %209
  %524 = bitcast <16 x i8> %523 to <2 x i64>
  %525 = and <2 x i64> %333, %445
  %526 = or <2 x i64> %525, %524
  store <2 x i64> %526, <2 x i64>* %52, align 1
  %527 = bitcast <16 x i8> %404 to <8 x i16>
  %528 = add <8 x i16> %287, %414
  %529 = sub <8 x i16> %289, %528
  %530 = add <8 x i16> %529, %527
  %531 = add <8 x i16> %530, %514
  %532 = bitcast <16 x i8> %412 to <8 x i16>
  %533 = add <8 x i16> %299, %427
  %534 = sub <8 x i16> %301, %533
  %535 = add <8 x i16> %534, %532
  %536 = add <8 x i16> %535, %519
  %537 = lshr <8 x i16> %531, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %538 = lshr <8 x i16> %536, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %539 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %537, <8 x i16> %538) #5
  %540 = and <16 x i8> %539, %209
  %541 = bitcast <16 x i8> %540 to <2 x i64>
  %542 = and <2 x i64> %350, %445
  %543 = or <2 x i64> %542, %541
  store <2 x i64> %543, <2 x i64>* %58, align 1
  %544 = bitcast <16 x i8> %405 to <8 x i16>
  %545 = add <8 x i16> %289, %414
  %546 = sub <8 x i16> %290, %545
  %547 = add <8 x i16> %546, %544
  %548 = add <8 x i16> %547, %531
  %549 = bitcast <16 x i8> %413 to <8 x i16>
  %550 = add <8 x i16> %301, %427
  %551 = sub <8 x i16> %302, %550
  %552 = add <8 x i16> %551, %549
  %553 = add <8 x i16> %552, %536
  %554 = lshr <8 x i16> %548, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %555 = lshr <8 x i16> %553, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %556 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %554, <8 x i16> %555) #5
  %557 = and <16 x i8> %556, %209
  %558 = bitcast <16 x i8> %557 to <2 x i64>
  %559 = and <2 x i64> %367, %445
  %560 = or <2 x i64> %559, %558
  store <2 x i64> %560, <2 x i64>* %61, align 1
  %561 = add <8 x i16> %290, %416
  %562 = sub <8 x i16> %317, %561
  %563 = add <8 x i16> %562, %544
  %564 = add <8 x i16> %563, %548
  %565 = add <8 x i16> %302, %429
  %566 = sub <8 x i16> %322, %565
  %567 = add <8 x i16> %566, %549
  %568 = add <8 x i16> %567, %553
  %569 = lshr <8 x i16> %564, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %570 = lshr <8 x i16> %568, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %571 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %569, <8 x i16> %570) #5
  %572 = and <16 x i8> %571, %209
  %573 = bitcast <16 x i8> %572 to <2 x i64>
  %574 = and <2 x i64> %382, %445
  %575 = or <2 x i64> %574, %573
  store <2 x i64> %575, <2 x i64>* %65, align 1
  %576 = add <8 x i16> %317, %419
  %577 = sub <8 x i16> %334, %576
  %578 = add <8 x i16> %577, %544
  %579 = add <8 x i16> %578, %564
  %580 = add <8 x i16> %322, %432
  %581 = sub <8 x i16> %339, %580
  %582 = add <8 x i16> %581, %549
  %583 = add <8 x i16> %582, %568
  %584 = lshr <8 x i16> %579, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %585 = lshr <8 x i16> %583, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %586 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %584, <8 x i16> %585) #5
  %587 = and <16 x i8> %586, %209
  %588 = bitcast <16 x i8> %587 to <2 x i64>
  %589 = and <2 x i64> %397, %445
  %590 = or <2 x i64> %589, %588
  store <2 x i64> %590, <2 x i64>* %69, align 1
  %591 = add <8 x i16> %334, %418
  %592 = sub <8 x i16> %351, %591
  %593 = add <8 x i16> %592, %544
  %594 = add <8 x i16> %593, %579
  %595 = add <8 x i16> %339, %431
  %596 = sub <8 x i16> %356, %595
  %597 = add <8 x i16> %596, %549
  %598 = add <8 x i16> %597, %583
  %599 = lshr <8 x i16> %594, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %600 = lshr <8 x i16> %598, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %601 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %599, <8 x i16> %600) #5
  %602 = and <16 x i8> %601, %209
  %603 = bitcast <16 x i8> %602 to <2 x i64>
  %604 = and <2 x i64> %73, %445
  %605 = or <2 x i64> %604, %603
  store <2 x i64> %605, <2 x i64>* %72, align 1
  %606 = add <8 x i16> %351, %285
  %607 = sub <8 x i16> %493, %606
  %608 = add <8 x i16> %607, %544
  %609 = add <8 x i16> %608, %594
  %610 = add <8 x i16> %356, %297
  %611 = sub <8 x i16> %498, %610
  %612 = add <8 x i16> %611, %549
  %613 = add <8 x i16> %612, %598
  %614 = lshr <8 x i16> %609, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %615 = lshr <8 x i16> %613, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %616 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %614, <8 x i16> %615) #5
  %617 = and <16 x i8> %616, %209
  %618 = bitcast <16 x i8> %617 to <2 x i64>
  %619 = and <2 x i64> %76, %445
  %620 = or <2 x i64> %619, %618
  store <2 x i64> %620, <2 x i64>* %75, align 1
  %621 = add <8 x i16> %493, %286
  %622 = sub <8 x i16> %510, %621
  %623 = add <8 x i16> %622, %544
  %624 = add <8 x i16> %623, %609
  %625 = add <8 x i16> %498, %298
  %626 = sub <8 x i16> %515, %625
  %627 = add <8 x i16> %626, %549
  %628 = add <8 x i16> %627, %613
  %629 = lshr <8 x i16> %624, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %630 = lshr <8 x i16> %628, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %631 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %629, <8 x i16> %630) #5
  %632 = and <16 x i8> %631, %209
  %633 = bitcast <16 x i8> %632 to <2 x i64>
  %634 = and <2 x i64> %79, %445
  %635 = or <2 x i64> %634, %633
  store <2 x i64> %635, <2 x i64>* %78, align 1
  %636 = add <8 x i16> %510, %287
  %637 = sub <8 x i16> %544, %636
  %638 = add <8 x i16> %637, %527
  %639 = add <8 x i16> %638, %624
  %640 = add <8 x i16> %515, %299
  %641 = sub <8 x i16> %549, %640
  %642 = add <8 x i16> %641, %532
  %643 = add <8 x i16> %642, %628
  %644 = lshr <8 x i16> %639, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %645 = lshr <8 x i16> %643, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %646 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %644, <8 x i16> %645) #5
  %647 = and <16 x i8> %646, %209
  %648 = bitcast <16 x i8> %647 to <2 x i64>
  %649 = and <2 x i64> %82, %445
  %650 = or <2 x i64> %649, %648
  store <2 x i64> %650, <2 x i64>* %81, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_lpf_horizontal_8_sse2(i8* nocapture, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #2 {
  %6 = bitcast i8* %2 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 16
  %8 = bitcast i8* %3 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 16
  %10 = bitcast i8* %4 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 16
  %12 = shl nsw i32 %1, 2
  %13 = sext i32 %12 to i64
  %14 = sub nsw i64 0, %13
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = bitcast i8* %15 to i64*
  %17 = load i64, i64* %16, align 1
  %18 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %17, i32 0
  %19 = mul nsw i32 %1, 3
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = bitcast i8* %21 to i64*
  %23 = load i64, i64* %22, align 1
  %24 = insertelement <2 x i64> undef, i64 %23, i32 0
  %25 = insertelement <2 x i64> %18, i64 %23, i32 1
  %26 = sub nsw i64 0, %20
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to <2 x i64>*
  %29 = bitcast i8* %27 to i64*
  %30 = load i64, i64* %29, align 1
  %31 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %30, i32 0
  %32 = shl nsw i32 %1, 1
  %33 = sext i32 %32 to i64
  %34 = getelementptr inbounds i8, i8* %0, i64 %33
  %35 = bitcast i8* %34 to <2 x i64>*
  %36 = bitcast i8* %34 to i64*
  %37 = load i64, i64* %36, align 1
  %38 = insertelement <2 x i64> undef, i64 %37, i32 0
  %39 = insertelement <2 x i64> %31, i64 %37, i32 1
  %40 = sub nsw i64 0, %33
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = bitcast i8* %41 to i64*
  %43 = load i64, i64* %42, align 1
  %44 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %43, i32 0
  %45 = sext i32 %1 to i64
  %46 = getelementptr inbounds i8, i8* %0, i64 %45
  %47 = bitcast i8* %46 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %48, i32 0
  %50 = insertelement <2 x i64> %44, i64 %48, i32 1
  %51 = sub nsw i64 0, %45
  %52 = getelementptr inbounds i8, i8* %0, i64 %51
  %53 = bitcast i8* %52 to i64*
  %54 = load i64, i64* %53, align 1
  %55 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %54, i32 0
  %56 = bitcast i8* %0 to i64*
  %57 = load i64, i64* %56, align 1
  %58 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %57, i32 0
  %59 = insertelement <2 x i64> %55, i64 %57, i32 1
  %60 = bitcast <2 x i64> %50 to <4 x i32>
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %62 = bitcast <2 x i64> %59 to <4 x i32>
  %63 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %64 = bitcast <2 x i64> %50 to <16 x i8>
  %65 = bitcast <2 x i64> %59 to <16 x i8>
  %66 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %64, <16 x i8> %65) #5
  %67 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %65, <16 x i8> %64) #5
  %68 = or <16 x i8> %67, %66
  %69 = shufflevector <16 x i8> %68, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %70 = bitcast <4 x i32> %63 to <16 x i8>
  %71 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %65, <16 x i8> %70) #5
  %72 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %70, <16 x i8> %65) #5
  %73 = or <16 x i8> %72, %71
  %74 = bitcast <4 x i32> %61 to <16 x i8>
  %75 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %64, <16 x i8> %74) #5
  %76 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %74, <16 x i8> %64) #5
  %77 = or <16 x i8> %76, %75
  %78 = icmp ugt <16 x i8> %68, %69
  %79 = select <16 x i1> %78, <16 x i8> %68, <16 x i8> %69
  %80 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %79, <16 x i8> %11) #5
  %81 = icmp eq <16 x i8> %80, zeroinitializer
  %82 = sext <16 x i1> %81 to <16 x i8>
  %83 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %73, <16 x i8> %73) #5
  %84 = bitcast <16 x i8> %77 to <8 x i16>
  %85 = lshr <8 x i16> %84, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %86 = bitcast <8 x i16> %85 to <16 x i8>
  %87 = and <16 x i8> %86, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %88 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %83, <16 x i8> %87) #5
  %89 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %88, <16 x i8> %7) #5
  %90 = icmp ne <16 x i8> %89, zeroinitializer
  %91 = sext <16 x i1> %90 to <16 x i8>
  %92 = icmp ugt <16 x i8> %68, %91
  %93 = select <16 x i1> %92, <16 x i8> %68, <16 x i8> %91
  %94 = bitcast <2 x i64> %39 to <16 x i8>
  %95 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %94, <16 x i8> %64) #5
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %64, <16 x i8> %94) #5
  %97 = or <16 x i8> %96, %95
  %98 = bitcast <2 x i64> %25 to <16 x i8>
  %99 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %98, <16 x i8> %94) #5
  %100 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %94, <16 x i8> %98) #5
  %101 = or <16 x i8> %100, %99
  %102 = icmp ugt <16 x i8> %97, %101
  %103 = select <16 x i1> %102, <16 x i8> %97, <16 x i8> %101
  %104 = icmp ugt <16 x i8> %103, %93
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> %93
  %106 = shufflevector <16 x i8> %105, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %107 = icmp ugt <16 x i8> %105, %106
  %108 = select <16 x i1> %107, <16 x i8> %105, <16 x i8> %106
  %109 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %108, <16 x i8> %9) #5
  %110 = icmp eq <16 x i8> %109, zeroinitializer
  %111 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %94, <16 x i8> %65) #5
  %112 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %65, <16 x i8> %94) #5
  %113 = or <16 x i8> %112, %111
  %114 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %98, <16 x i8> %65) #5
  %115 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %65, <16 x i8> %98) #5
  %116 = or <16 x i8> %115, %114
  %117 = icmp ugt <16 x i8> %113, %116
  %118 = select <16 x i1> %117, <16 x i8> %113, <16 x i8> %116
  %119 = icmp ugt <16 x i8> %68, %118
  %120 = select <16 x i1> %119, <16 x i8> %68, <16 x i8> %118
  %121 = shufflevector <16 x i8> %120, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %122 = icmp ugt <16 x i8> %120, %121
  %123 = select <16 x i1> %122, <16 x i8> %120, <16 x i8> %121
  %124 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %123, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %125 = icmp eq <16 x i8> %124, zeroinitializer
  %126 = and <16 x i1> %110, %125
  %127 = sext <16 x i1> %126 to <16 x i8>
  %128 = bitcast <16 x i8> %127 to <2 x i64>
  %129 = bitcast <2 x i64> %18 to <16 x i8>
  %130 = shufflevector <16 x i8> %129, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %131 = bitcast <2 x i64> %31 to <16 x i8>
  %132 = shufflevector <16 x i8> %131, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %133 = bitcast <2 x i64> %44 to <16 x i8>
  %134 = shufflevector <16 x i8> %133, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %135 = bitcast <2 x i64> %55 to <16 x i8>
  %136 = shufflevector <16 x i8> %135, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %137 = bitcast <2 x i64> %58 to <16 x i8>
  %138 = shufflevector <16 x i8> %137, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %139 = bitcast <2 x i64> %49 to <16 x i8>
  %140 = shufflevector <16 x i8> %139, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %141 = bitcast <2 x i64> %38 to <16 x i8>
  %142 = shufflevector <16 x i8> %141, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %143 = bitcast <2 x i64> %24 to <16 x i8>
  %144 = shufflevector <16 x i8> %143, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %145 = bitcast <16 x i8> %130 to <8 x i16>
  %146 = shl <8 x i16> %145, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %147 = bitcast <16 x i8> %132 to <8 x i16>
  %148 = bitcast <16 x i8> %134 to <8 x i16>
  %149 = bitcast <16 x i8> %136 to <8 x i16>
  %150 = add <8 x i16> %146, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = add <8 x i16> %150, %147
  %152 = add <8 x i16> %151, %148
  %153 = add <8 x i16> %152, %149
  %154 = bitcast <16 x i8> %138 to <8 x i16>
  %155 = add <8 x i16> %147, %145
  %156 = add <8 x i16> %155, %154
  %157 = add <8 x i16> %156, %153
  %158 = lshr <8 x i16> %157, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %159 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %158, <8 x i16> undef) #5
  %160 = bitcast <16 x i8> %140 to <8 x i16>
  %161 = add <8 x i16> %154, %160
  %162 = add <8 x i16> %161, %148
  %163 = add <8 x i16> %162, %153
  %164 = lshr <8 x i16> %163, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %165 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %164, <8 x i16> undef) #5
  %166 = sub <8 x i16> %153, %145
  %167 = bitcast <16 x i8> %142 to <8 x i16>
  %168 = add <8 x i16> %166, %167
  %169 = add <8 x i16> %161, %149
  %170 = add <8 x i16> %169, %168
  %171 = lshr <8 x i16> %170, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %172 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %171, <8 x i16> undef) #5
  %173 = sub <8 x i16> %168, %145
  %174 = bitcast <16 x i8> %144 to <8 x i16>
  %175 = add <8 x i16> %173, %174
  %176 = add <8 x i16> %161, %154
  %177 = add <8 x i16> %176, %175
  %178 = lshr <8 x i16> %177, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %179 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %178, <8 x i16> undef) #5
  %180 = sub <8 x i16> %175, %147
  %181 = add <8 x i16> %180, %174
  %182 = add <8 x i16> %161, %160
  %183 = add <8 x i16> %182, %181
  %184 = lshr <8 x i16> %183, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %185 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %184, <8 x i16> undef) #5
  %186 = add <8 x i16> %167, %174
  %187 = sub <8 x i16> %186, %148
  %188 = add <8 x i16> %187, %161
  %189 = add <8 x i16> %188, %181
  %190 = lshr <8 x i16> %189, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %190, <8 x i16> undef) #5
  %192 = xor <16 x i8> %133, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %193 = xor <16 x i8> %139, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %194 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %192, <16 x i8> %193) #5
  %195 = xor <16 x i8> %137, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %196 = xor <16 x i8> %135, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %197 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %195, <16 x i8> %196) #5
  %198 = xor <16 x i8> %82, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %199 = and <16 x i8> %194, %198
  %200 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %199, <16 x i8> %197) #5
  %201 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %200, <16 x i8> %197) #5
  %202 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %201, <16 x i8> %197) #5
  %203 = select <16 x i1> %110, <16 x i8> %202, <16 x i8> zeroinitializer
  %204 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %203, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %205 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %203, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #5
  %206 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %204, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %207 = bitcast <16 x i8> %206 to <8 x i16>
  %208 = ashr <8 x i16> %207, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %209 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %208, <8 x i16> %208) #5
  %210 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %205, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %211 = bitcast <16 x i8> %210 to <8 x i16>
  %212 = ashr <8 x i16> %211, <i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11, i16 11>
  %213 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %212, <8 x i16> zeroinitializer) #5
  %214 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %209, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %215 = shufflevector <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i8> %214, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %216 = bitcast <16 x i8> %215 to <8 x i16>
  %217 = ashr <8 x i16> %216, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %218 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %217, <8 x i16> zeroinitializer) #5
  %219 = and <16 x i8> %218, %82
  %220 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %195, <16 x i8> %209) #5
  %221 = bitcast <16 x i8> %220 to <2 x i64>
  %222 = and <16 x i8> %179, %127
  %223 = bitcast <16 x i8> %222 to <2 x i64>
  %224 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %193, <16 x i8> %219) #5
  %225 = bitcast <16 x i8> %224 to <2 x i64>
  %226 = and <16 x i8> %185, %127
  %227 = bitcast <16 x i8> %226 to <2 x i64>
  %228 = load <2 x i64>, <2 x i64>* %35, align 1
  %229 = and <16 x i8> %191, %127
  %230 = bitcast <16 x i8> %229 to <2 x i64>
  %231 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %196, <16 x i8> %213) #5
  %232 = bitcast <16 x i8> %231 to <2 x i64>
  %233 = and <16 x i8> %172, %127
  %234 = bitcast <16 x i8> %233 to <2 x i64>
  %235 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %192, <16 x i8> %219) #5
  %236 = bitcast <16 x i8> %235 to <2 x i64>
  %237 = and <16 x i8> %165, %127
  %238 = bitcast <16 x i8> %237 to <2 x i64>
  %239 = load <2 x i64>, <2 x i64>* %28, align 1
  %240 = and <16 x i8> %159, %127
  %241 = bitcast <16 x i8> %240 to <2 x i64>
  %242 = extractelement <2 x i64> %241, i32 0
  %243 = extractelement <2 x i64> %239, i32 0
  %244 = extractelement <2 x i64> %128, i32 0
  %245 = xor i64 %244, -1
  %246 = and i64 %243, %245
  %247 = or i64 %242, %246
  store i64 %247, i64* %29, align 1
  %248 = extractelement <2 x i64> %238, i32 0
  %249 = extractelement <2 x i64> %236, i32 0
  %250 = xor i64 %249, -9187201950435737472
  %251 = and i64 %250, %245
  %252 = or i64 %248, %251
  store i64 %252, i64* %42, align 1
  %253 = extractelement <2 x i64> %234, i32 0
  %254 = extractelement <2 x i64> %232, i32 0
  %255 = xor i64 %254, -9187201950435737472
  %256 = and i64 %255, %245
  %257 = or i64 %253, %256
  store i64 %257, i64* %53, align 1
  %258 = extractelement <2 x i64> %223, i32 0
  %259 = extractelement <2 x i64> %221, i32 0
  %260 = xor i64 %259, -9187201950435737472
  %261 = and i64 %260, %245
  %262 = or i64 %258, %261
  store i64 %262, i64* %56, align 1
  %263 = extractelement <2 x i64> %227, i32 0
  %264 = extractelement <2 x i64> %225, i32 0
  %265 = xor i64 %264, -9187201950435737472
  %266 = and i64 %265, %245
  %267 = or i64 %263, %266
  store i64 %267, i64* %47, align 1
  %268 = extractelement <2 x i64> %230, i32 0
  %269 = extractelement <2 x i64> %228, i32 0
  %270 = and i64 %269, %245
  %271 = or i64 %268, %270
  store i64 %271, i64* %36, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_lpf_horizontal_8_dual_sse2(i8* nocapture, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #2 {
  %9 = alloca <2 x i64>, align 16
  %10 = bitcast <2 x i64>* %9 to [16 x i8]*
  %11 = alloca <2 x i64>, align 16
  %12 = bitcast <2 x i64>* %11 to [16 x i8]*
  %13 = alloca <2 x i64>, align 16
  %14 = bitcast <2 x i64>* %13 to [16 x i8]*
  %15 = alloca <2 x i64>, align 16
  %16 = bitcast <2 x i64>* %15 to [16 x i8]*
  %17 = alloca <2 x i64>, align 16
  %18 = bitcast <2 x i64>* %17 to [16 x i8]*
  %19 = alloca <2 x i64>, align 16
  %20 = bitcast <2 x i64>* %19 to [16 x i8]*
  %21 = bitcast <2 x i64>* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %21) #5
  %22 = bitcast <2 x i64>* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %21, i8 -86, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %22) #5
  %23 = bitcast <2 x i64>* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %23) #5
  %24 = bitcast <2 x i64>* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %23, i8 -86, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %24) #5
  %25 = bitcast <2 x i64>* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %24, i8 -86, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %25) #5
  %26 = bitcast <2 x i64>* %19 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %25, i8 -86, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %26) #5
  %27 = bitcast i8* %2 to <2 x i64>*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %26, i8 -86, i64 16, i1 false)
  %28 = load <2 x i64>, <2 x i64>* %27, align 16
  %29 = bitcast i8* %5 to <2 x i64>*
  %30 = load <2 x i64>, <2 x i64>* %29, align 16
  %31 = shufflevector <2 x i64> %28, <2 x i64> %30, <2 x i32> <i32 0, i32 2>
  %32 = bitcast i8* %3 to <2 x i64>*
  %33 = load <2 x i64>, <2 x i64>* %32, align 16
  %34 = bitcast i8* %6 to <2 x i64>*
  %35 = load <2 x i64>, <2 x i64>* %34, align 16
  %36 = shufflevector <2 x i64> %33, <2 x i64> %35, <2 x i32> <i32 0, i32 2>
  %37 = bitcast i8* %4 to <2 x i64>*
  %38 = load <2 x i64>, <2 x i64>* %37, align 16
  %39 = bitcast i8* %7 to <2 x i64>*
  %40 = load <2 x i64>, <2 x i64>* %39, align 16
  %41 = shufflevector <2 x i64> %38, <2 x i64> %40, <2 x i32> <i32 0, i32 2>
  %42 = shl nsw i32 %1, 2
  %43 = sext i32 %42 to i64
  %44 = sub nsw i64 0, %43
  %45 = getelementptr inbounds i8, i8* %0, i64 %44
  %46 = bitcast i8* %45 to <16 x i8>*
  %47 = load <16 x i8>, <16 x i8>* %46, align 1
  %48 = mul nsw i32 %1, 3
  %49 = sext i32 %48 to i64
  %50 = sub nsw i64 0, %49
  %51 = getelementptr inbounds i8, i8* %0, i64 %50
  %52 = bitcast i8* %51 to <2 x i64>*
  %53 = load <2 x i64>, <2 x i64>* %52, align 1
  %54 = shl nsw i32 %1, 1
  %55 = sext i32 %54 to i64
  %56 = sub nsw i64 0, %55
  %57 = getelementptr inbounds i8, i8* %0, i64 %56
  %58 = bitcast i8* %57 to <2 x i64>*
  %59 = bitcast i8* %57 to <16 x i8>*
  %60 = load <16 x i8>, <16 x i8>* %59, align 1
  %61 = sext i32 %1 to i64
  %62 = sub nsw i64 0, %61
  %63 = getelementptr inbounds i8, i8* %0, i64 %62
  %64 = bitcast i8* %63 to <2 x i64>*
  %65 = bitcast i8* %63 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 1
  %67 = bitcast i8* %0 to <2 x i64>*
  %68 = bitcast i8* %0 to <16 x i8>*
  %69 = load <16 x i8>, <16 x i8>* %68, align 1
  %70 = getelementptr inbounds i8, i8* %0, i64 %61
  %71 = bitcast i8* %70 to <2 x i64>*
  %72 = bitcast i8* %70 to <16 x i8>*
  %73 = load <16 x i8>, <16 x i8>* %72, align 1
  %74 = getelementptr inbounds i8, i8* %0, i64 %55
  %75 = bitcast i8* %74 to <2 x i64>*
  %76 = load <2 x i64>, <2 x i64>* %75, align 1
  %77 = getelementptr inbounds i8, i8* %0, i64 %49
  %78 = bitcast i8* %77 to <16 x i8>*
  %79 = load <16 x i8>, <16 x i8>* %78, align 1
  %80 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %66) #5
  %81 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %66, <16 x i8> %60) #5
  %82 = or <16 x i8> %81, %80
  %83 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %73, <16 x i8> %69) #5
  %84 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %69, <16 x i8> %73) #5
  %85 = or <16 x i8> %84, %83
  %86 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %66, <16 x i8> %69) #5
  %87 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %69, <16 x i8> %66) #5
  %88 = or <16 x i8> %87, %86
  %89 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %73) #5
  %90 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %73, <16 x i8> %60) #5
  %91 = or <16 x i8> %90, %89
  %92 = icmp ugt <16 x i8> %82, %85
  %93 = select <16 x i1> %92, <16 x i8> %82, <16 x i8> %85
  %94 = bitcast <2 x i64> %41 to <16 x i8>
  %95 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %93, <16 x i8> %94) #5
  %96 = icmp eq <16 x i8> %95, zeroinitializer
  %97 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %88, <16 x i8> %88) #5
  %98 = bitcast <16 x i8> %91 to <8 x i16>
  %99 = lshr <8 x i16> %98, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %100 = bitcast <8 x i16> %99 to <16 x i8>
  %101 = and <16 x i8> %100, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %102 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %97, <16 x i8> %101) #5
  %103 = bitcast <2 x i64> %31 to <16 x i8>
  %104 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %102, <16 x i8> %103) #5
  %105 = icmp ne <16 x i8> %104, zeroinitializer
  %106 = sext <16 x i1> %105 to <16 x i8>
  %107 = icmp ugt <16 x i8> %93, %106
  %108 = select <16 x i1> %107, <16 x i8> %93, <16 x i8> %106
  %109 = bitcast <2 x i64> %53 to <16 x i8>
  %110 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %109, <16 x i8> %60) #5
  %111 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %60, <16 x i8> %109) #5
  %112 = or <16 x i8> %111, %110
  %113 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %109) #5
  %114 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %109, <16 x i8> %47) #5
  %115 = or <16 x i8> %114, %113
  %116 = icmp ugt <16 x i8> %112, %115
  %117 = select <16 x i1> %116, <16 x i8> %112, <16 x i8> %115
  %118 = icmp ugt <16 x i8> %117, %108
  %119 = select <16 x i1> %118, <16 x i8> %117, <16 x i8> %108
  %120 = bitcast <2 x i64> %76 to <16 x i8>
  %121 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %120, <16 x i8> %73) #5
  %122 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %73, <16 x i8> %120) #5
  %123 = or <16 x i8> %122, %121
  %124 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %79, <16 x i8> %120) #5
  %125 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %120, <16 x i8> %79) #5
  %126 = or <16 x i8> %125, %124
  %127 = icmp ugt <16 x i8> %123, %126
  %128 = select <16 x i1> %127, <16 x i8> %123, <16 x i8> %126
  %129 = icmp ugt <16 x i8> %128, %119
  %130 = select <16 x i1> %129, <16 x i8> %128, <16 x i8> %119
  %131 = bitcast <2 x i64> %36 to <16 x i8>
  %132 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %130, <16 x i8> %131) #5
  %133 = icmp eq <16 x i8> %132, zeroinitializer
  %134 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %109, <16 x i8> %66) #5
  %135 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %66, <16 x i8> %109) #5
  %136 = or <16 x i8> %135, %134
  %137 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %120, <16 x i8> %69) #5
  %138 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %69, <16 x i8> %120) #5
  %139 = or <16 x i8> %138, %137
  %140 = icmp ugt <16 x i8> %136, %139
  %141 = select <16 x i1> %140, <16 x i8> %136, <16 x i8> %139
  %142 = icmp ugt <16 x i8> %141, %93
  %143 = select <16 x i1> %142, <16 x i8> %141, <16 x i8> %93
  %144 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %47, <16 x i8> %66) #5
  %145 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %66, <16 x i8> %47) #5
  %146 = or <16 x i8> %145, %144
  %147 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %79, <16 x i8> %69) #5
  %148 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %69, <16 x i8> %79) #5
  %149 = or <16 x i8> %148, %147
  %150 = icmp ugt <16 x i8> %146, %149
  %151 = select <16 x i1> %150, <16 x i8> %146, <16 x i8> %149
  %152 = icmp ugt <16 x i8> %151, %143
  %153 = select <16 x i1> %152, <16 x i8> %151, <16 x i8> %143
  %154 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %153, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %155 = icmp eq <16 x i8> %154, zeroinitializer
  %156 = and <16 x i1> %133, %155
  %157 = sext <16 x i1> %156 to <16 x i8>
  br label %158

158:                                              ; preds = %158, %8
  %159 = phi i32 [ 0, %8 ], [ 1, %158 ]
  %160 = phi i8* [ %0, %8 ], [ %281, %158 ]
  %161 = getelementptr inbounds i8, i8* %160, i64 %44
  %162 = bitcast i8* %161 to i64*
  %163 = load i64, i64* %162, align 1
  %164 = insertelement <2 x i64> undef, i64 %163, i32 0
  %165 = bitcast <2 x i64> %164 to <16 x i8>
  %166 = shufflevector <16 x i8> %165, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %167 = getelementptr inbounds i8, i8* %160, i64 %50
  %168 = bitcast i8* %167 to i64*
  %169 = load i64, i64* %168, align 1
  %170 = insertelement <2 x i64> undef, i64 %169, i32 0
  %171 = bitcast <2 x i64> %170 to <16 x i8>
  %172 = shufflevector <16 x i8> %171, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %173 = getelementptr inbounds i8, i8* %160, i64 %56
  %174 = bitcast i8* %173 to i64*
  %175 = load i64, i64* %174, align 1
  %176 = insertelement <2 x i64> undef, i64 %175, i32 0
  %177 = bitcast <2 x i64> %176 to <16 x i8>
  %178 = shufflevector <16 x i8> %177, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %179 = getelementptr inbounds i8, i8* %160, i64 %62
  %180 = bitcast i8* %179 to i64*
  %181 = load i64, i64* %180, align 1
  %182 = insertelement <2 x i64> undef, i64 %181, i32 0
  %183 = bitcast <2 x i64> %182 to <16 x i8>
  %184 = shufflevector <16 x i8> %183, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %185 = bitcast i8* %160 to i64*
  %186 = load i64, i64* %185, align 1
  %187 = insertelement <2 x i64> undef, i64 %186, i32 0
  %188 = bitcast <2 x i64> %187 to <16 x i8>
  %189 = shufflevector <16 x i8> %188, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %190 = getelementptr inbounds i8, i8* %160, i64 %61
  %191 = bitcast i8* %190 to i64*
  %192 = load i64, i64* %191, align 1
  %193 = insertelement <2 x i64> undef, i64 %192, i32 0
  %194 = bitcast <2 x i64> %193 to <16 x i8>
  %195 = shufflevector <16 x i8> %194, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %196 = getelementptr inbounds i8, i8* %160, i64 %55
  %197 = bitcast i8* %196 to i64*
  %198 = load i64, i64* %197, align 1
  %199 = insertelement <2 x i64> undef, i64 %198, i32 0
  %200 = bitcast <2 x i64> %199 to <16 x i8>
  %201 = shufflevector <16 x i8> %200, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %202 = getelementptr inbounds i8, i8* %160, i64 %49
  %203 = bitcast i8* %202 to i64*
  %204 = load i64, i64* %203, align 1
  %205 = insertelement <2 x i64> undef, i64 %204, i32 0
  %206 = bitcast <2 x i64> %205 to <16 x i8>
  %207 = shufflevector <16 x i8> %206, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %208 = bitcast <16 x i8> %166 to <8 x i16>
  %209 = shl <8 x i16> %208, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %210 = bitcast <16 x i8> %172 to <8 x i16>
  %211 = bitcast <16 x i8> %178 to <8 x i16>
  %212 = bitcast <16 x i8> %184 to <8 x i16>
  %213 = add <8 x i16> %210, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %214 = add <8 x i16> %213, %209
  %215 = add <8 x i16> %214, %211
  %216 = add <8 x i16> %215, %212
  %217 = bitcast <16 x i8> %189 to <8 x i16>
  %218 = add <8 x i16> %210, %208
  %219 = add <8 x i16> %218, %217
  %220 = add <8 x i16> %219, %216
  %221 = lshr <8 x i16> %220, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %222 = shl nuw nsw i32 %159, 3
  %223 = zext i32 %222 to i64
  %224 = getelementptr inbounds [16 x i8], [16 x i8]* %10, i64 0, i64 %223
  %225 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %221, <8 x i16> undef) #5
  %226 = bitcast <16 x i8> %225 to <2 x i64>
  %227 = extractelement <2 x i64> %226, i32 0
  %228 = bitcast i8* %224 to i64*
  store i64 %227, i64* %228, align 8
  %229 = bitcast <16 x i8> %195 to <8 x i16>
  %230 = add <8 x i16> %229, %217
  %231 = add <8 x i16> %230, %211
  %232 = add <8 x i16> %231, %216
  %233 = lshr <8 x i16> %232, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %234 = getelementptr inbounds [16 x i8], [16 x i8]* %12, i64 0, i64 %223
  %235 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %233, <8 x i16> undef) #5
  %236 = bitcast <16 x i8> %235 to <2 x i64>
  %237 = extractelement <2 x i64> %236, i32 0
  %238 = bitcast i8* %234 to i64*
  store i64 %237, i64* %238, align 8
  %239 = sub <8 x i16> %216, %208
  %240 = bitcast <16 x i8> %201 to <8 x i16>
  %241 = add <8 x i16> %239, %240
  %242 = add <8 x i16> %230, %212
  %243 = add <8 x i16> %242, %241
  %244 = lshr <8 x i16> %243, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %245 = getelementptr inbounds [16 x i8], [16 x i8]* %14, i64 0, i64 %223
  %246 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %244, <8 x i16> undef) #5
  %247 = bitcast <16 x i8> %246 to <2 x i64>
  %248 = extractelement <2 x i64> %247, i32 0
  %249 = bitcast i8* %245 to i64*
  store i64 %248, i64* %249, align 8
  %250 = sub <8 x i16> %241, %208
  %251 = bitcast <16 x i8> %207 to <8 x i16>
  %252 = add <8 x i16> %250, %251
  %253 = add <8 x i16> %230, %217
  %254 = add <8 x i16> %253, %252
  %255 = lshr <8 x i16> %254, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %256 = getelementptr inbounds [16 x i8], [16 x i8]* %20, i64 0, i64 %223
  %257 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %255, <8 x i16> undef) #5
  %258 = bitcast <16 x i8> %257 to <2 x i64>
  %259 = extractelement <2 x i64> %258, i32 0
  %260 = bitcast i8* %256 to i64*
  store i64 %259, i64* %260, align 8
  %261 = sub <8 x i16> %252, %210
  %262 = add <8 x i16> %261, %251
  %263 = add <8 x i16> %230, %229
  %264 = add <8 x i16> %263, %262
  %265 = lshr <8 x i16> %264, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %266 = getelementptr inbounds [16 x i8], [16 x i8]* %18, i64 0, i64 %223
  %267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %265, <8 x i16> undef) #5
  %268 = bitcast <16 x i8> %267 to <2 x i64>
  %269 = extractelement <2 x i64> %268, i32 0
  %270 = bitcast i8* %266 to i64*
  store i64 %269, i64* %270, align 8
  %271 = sub <8 x i16> %240, %211
  %272 = add <8 x i16> %271, %230
  %273 = add <8 x i16> %272, %251
  %274 = add <8 x i16> %273, %262
  %275 = lshr <8 x i16> %274, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %276 = getelementptr inbounds [16 x i8], [16 x i8]* %16, i64 0, i64 %223
  %277 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %275, <8 x i16> undef) #5
  %278 = bitcast <16 x i8> %277 to <2 x i64>
  %279 = extractelement <2 x i64> %278, i32 0
  %280 = bitcast i8* %276 to i64*
  store i64 %279, i64* %280, align 8
  %281 = getelementptr inbounds i8, i8* %160, i64 8
  %282 = icmp eq i32 %159, 1
  br i1 %282, label %283, label %158

283:                                              ; preds = %158
  %284 = sext <16 x i1> %96 to <16 x i8>
  %285 = bitcast <16 x i8> %157 to <2 x i64>
  %286 = xor <16 x i8> %60, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %287 = xor <16 x i8> %73, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %288 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %286, <16 x i8> %287) #5
  %289 = xor <16 x i8> %69, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %290 = xor <16 x i8> %66, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %291 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %289, <16 x i8> %290) #5
  %292 = xor <16 x i8> %284, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %293 = and <16 x i8> %288, %292
  %294 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %293, <16 x i8> %291) #5
  %295 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %294, <16 x i8> %291) #5
  %296 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %295, <16 x i8> %291) #5
  %297 = select <16 x i1> %133, <16 x i8> %296, <16 x i8> zeroinitializer
  %298 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %297, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %299 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %297, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #5
  %300 = ashr <16 x i8> %298, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %301 = bitcast <16 x i8> %300 to <2 x i64>
  %302 = bitcast <16 x i8> %298 to <8 x i16>
  %303 = lshr <8 x i16> %302, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %304 = bitcast <8 x i16> %303 to <2 x i64>
  %305 = and <2 x i64> %301, <i64 -2242545357980376864, i64 -2242545357980376864>
  %306 = and <2 x i64> %304, <i64 2242545357980376863, i64 2242545357980376863>
  %307 = or <2 x i64> %306, %305
  %308 = ashr <16 x i8> %299, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %309 = bitcast <16 x i8> %308 to <2 x i64>
  %310 = bitcast <16 x i8> %299 to <8 x i16>
  %311 = lshr <8 x i16> %310, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %312 = bitcast <8 x i16> %311 to <2 x i64>
  %313 = and <2 x i64> %309, <i64 -2242545357980376864, i64 -2242545357980376864>
  %314 = and <2 x i64> %312, <i64 2242545357980376863, i64 2242545357980376863>
  %315 = or <2 x i64> %314, %313
  %316 = bitcast <2 x i64> %307 to <16 x i8>
  %317 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %316, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %318 = ashr <16 x i8> %317, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %319 = bitcast <16 x i8> %318 to <2 x i64>
  %320 = bitcast <16 x i8> %317 to <8 x i16>
  %321 = lshr <8 x i16> %320, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %322 = bitcast <8 x i16> %321 to <2 x i64>
  %323 = and <2 x i64> %319, <i64 -9187201950435737472, i64 -9187201950435737472>
  %324 = and <2 x i64> %322, <i64 9187201950435737471, i64 9187201950435737471>
  %325 = or <2 x i64> %324, %323
  %326 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %289, <16 x i8> %316) #5
  %327 = bitcast <16 x i8> %326 to <2 x i64>
  %328 = xor <2 x i64> %327, <i64 -9187201950435737472, i64 -9187201950435737472>
  %329 = load <2 x i64>, <2 x i64>* %19, align 16
  %330 = xor <2 x i64> %285, <i64 -1, i64 -1>
  %331 = and <2 x i64> %328, %330
  %332 = and <2 x i64> %329, %285
  %333 = or <2 x i64> %332, %331
  %334 = bitcast <2 x i64> %325 to <16 x i8>
  %335 = and <16 x i8> %334, %284
  %336 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %287, <16 x i8> %335) #5
  %337 = bitcast <16 x i8> %336 to <2 x i64>
  %338 = xor <2 x i64> %337, <i64 -9187201950435737472, i64 -9187201950435737472>
  %339 = load <2 x i64>, <2 x i64>* %17, align 16
  %340 = and <2 x i64> %338, %330
  %341 = and <2 x i64> %339, %285
  %342 = or <2 x i64> %341, %340
  %343 = load <2 x i64>, <2 x i64>* %15, align 16
  %344 = and <2 x i64> %76, %330
  %345 = and <2 x i64> %343, %285
  %346 = or <2 x i64> %345, %344
  %347 = bitcast <2 x i64> %315 to <16 x i8>
  %348 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %290, <16 x i8> %347) #5
  %349 = bitcast <16 x i8> %348 to <2 x i64>
  %350 = xor <2 x i64> %349, <i64 -9187201950435737472, i64 -9187201950435737472>
  %351 = load <2 x i64>, <2 x i64>* %13, align 16
  %352 = and <2 x i64> %350, %330
  %353 = and <2 x i64> %351, %285
  %354 = or <2 x i64> %353, %352
  %355 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %286, <16 x i8> %335) #5
  %356 = bitcast <16 x i8> %355 to <2 x i64>
  %357 = xor <2 x i64> %356, <i64 -9187201950435737472, i64 -9187201950435737472>
  %358 = load <2 x i64>, <2 x i64>* %11, align 16
  %359 = and <2 x i64> %357, %330
  %360 = and <2 x i64> %358, %285
  %361 = or <2 x i64> %360, %359
  %362 = load <2 x i64>, <2 x i64>* %9, align 16
  %363 = and <2 x i64> %53, %330
  %364 = and <2 x i64> %362, %285
  %365 = or <2 x i64> %364, %363
  store <2 x i64> %365, <2 x i64>* %52, align 1
  store <2 x i64> %361, <2 x i64>* %58, align 1
  store <2 x i64> %354, <2 x i64>* %64, align 1
  store <2 x i64> %333, <2 x i64>* %67, align 1
  store <2 x i64> %342, <2 x i64>* %71, align 1
  store <2 x i64> %346, <2 x i64>* %75, align 1
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %26) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %25) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %24) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %23) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %22) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %21) #5
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_lpf_horizontal_4_dual_sse2(i8* nocapture, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #0 {
  %9 = bitcast i8* %2 to <2 x i64>*
  %10 = load <2 x i64>, <2 x i64>* %9, align 16
  %11 = bitcast i8* %5 to <2 x i64>*
  %12 = load <2 x i64>, <2 x i64>* %11, align 16
  %13 = shufflevector <2 x i64> %10, <2 x i64> %12, <2 x i32> <i32 0, i32 2>
  %14 = bitcast i8* %3 to <2 x i64>*
  %15 = load <2 x i64>, <2 x i64>* %14, align 16
  %16 = bitcast i8* %6 to <2 x i64>*
  %17 = load <2 x i64>, <2 x i64>* %16, align 16
  %18 = shufflevector <2 x i64> %15, <2 x i64> %17, <2 x i32> <i32 0, i32 2>
  %19 = bitcast i8* %4 to <2 x i64>*
  %20 = load <2 x i64>, <2 x i64>* %19, align 16
  %21 = bitcast i8* %7 to <2 x i64>*
  %22 = load <2 x i64>, <2 x i64>* %21, align 16
  %23 = shufflevector <2 x i64> %20, <2 x i64> %22, <2 x i32> <i32 0, i32 2>
  %24 = shl nsw i32 %1, 2
  %25 = sext i32 %24 to i64
  %26 = sub nsw i64 0, %25
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to <16 x i8>*
  %29 = load <16 x i8>, <16 x i8>* %28, align 1
  %30 = mul nsw i32 %1, 3
  %31 = sext i32 %30 to i64
  %32 = sub nsw i64 0, %31
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = bitcast i8* %33 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = shl nsw i32 %1, 1
  %37 = sext i32 %36 to i64
  %38 = sub nsw i64 0, %37
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = bitcast i8* %39 to <2 x i64>*
  %41 = bitcast i8* %39 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = sext i32 %1 to i64
  %44 = sub nsw i64 0, %43
  %45 = getelementptr inbounds i8, i8* %0, i64 %44
  %46 = bitcast i8* %45 to <2 x i64>*
  %47 = bitcast i8* %45 to <16 x i8>*
  %48 = load <16 x i8>, <16 x i8>* %47, align 1
  %49 = bitcast i8* %0 to <2 x i64>*
  %50 = bitcast i8* %0 to <16 x i8>*
  %51 = load <16 x i8>, <16 x i8>* %50, align 1
  %52 = getelementptr inbounds i8, i8* %0, i64 %43
  %53 = bitcast i8* %52 to <2 x i64>*
  %54 = bitcast i8* %52 to <16 x i8>*
  %55 = load <16 x i8>, <16 x i8>* %54, align 1
  %56 = getelementptr inbounds i8, i8* %0, i64 %37
  %57 = bitcast i8* %56 to <16 x i8>*
  %58 = load <16 x i8>, <16 x i8>* %57, align 1
  %59 = getelementptr inbounds i8, i8* %0, i64 %31
  %60 = bitcast i8* %59 to <16 x i8>*
  %61 = load <16 x i8>, <16 x i8>* %60, align 1
  %62 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %42, <16 x i8> %48) #5
  %63 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %48, <16 x i8> %42) #5
  %64 = or <16 x i8> %63, %62
  %65 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %55, <16 x i8> %51) #5
  %66 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %51, <16 x i8> %55) #5
  %67 = or <16 x i8> %66, %65
  %68 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %48, <16 x i8> %51) #5
  %69 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %51, <16 x i8> %48) #5
  %70 = or <16 x i8> %69, %68
  %71 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %42, <16 x i8> %55) #5
  %72 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %55, <16 x i8> %42) #5
  %73 = or <16 x i8> %72, %71
  %74 = icmp ugt <16 x i8> %64, %67
  %75 = select <16 x i1> %74, <16 x i8> %64, <16 x i8> %67
  %76 = bitcast <2 x i64> %23 to <16 x i8>
  %77 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %75, <16 x i8> %76) #5
  %78 = icmp eq <16 x i8> %77, zeroinitializer
  %79 = sext <16 x i1> %78 to <16 x i8>
  %80 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %70, <16 x i8> %70) #5
  %81 = bitcast <16 x i8> %73 to <8 x i16>
  %82 = lshr <8 x i16> %81, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %83 = bitcast <8 x i16> %82 to <16 x i8>
  %84 = and <16 x i8> %83, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %85 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %80, <16 x i8> %84) #5
  %86 = bitcast <2 x i64> %13 to <16 x i8>
  %87 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %85, <16 x i8> %86) #5
  %88 = icmp ne <16 x i8> %87, zeroinitializer
  %89 = sext <16 x i1> %88 to <16 x i8>
  %90 = icmp ugt <16 x i8> %75, %89
  %91 = select <16 x i1> %90, <16 x i8> %75, <16 x i8> %89
  %92 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %35, <16 x i8> %42) #5
  %93 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %42, <16 x i8> %35) #5
  %94 = or <16 x i8> %93, %92
  %95 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %29, <16 x i8> %35) #5
  %96 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %35, <16 x i8> %29) #5
  %97 = or <16 x i8> %96, %95
  %98 = icmp ugt <16 x i8> %94, %97
  %99 = select <16 x i1> %98, <16 x i8> %94, <16 x i8> %97
  %100 = icmp ugt <16 x i8> %99, %91
  %101 = select <16 x i1> %100, <16 x i8> %99, <16 x i8> %91
  %102 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %58, <16 x i8> %55) #5
  %103 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %55, <16 x i8> %58) #5
  %104 = or <16 x i8> %103, %102
  %105 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %61, <16 x i8> %58) #5
  %106 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %58, <16 x i8> %61) #5
  %107 = or <16 x i8> %106, %105
  %108 = icmp ugt <16 x i8> %104, %107
  %109 = select <16 x i1> %108, <16 x i8> %104, <16 x i8> %107
  %110 = icmp ugt <16 x i8> %109, %101
  %111 = select <16 x i1> %110, <16 x i8> %109, <16 x i8> %101
  %112 = bitcast <2 x i64> %18 to <16 x i8>
  %113 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %111, <16 x i8> %112) #5
  %114 = icmp eq <16 x i8> %113, zeroinitializer
  %115 = xor <16 x i8> %42, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %116 = xor <16 x i8> %55, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %117 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %115, <16 x i8> %116) #5
  %118 = xor <16 x i8> %51, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %119 = xor <16 x i8> %48, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %120 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %118, <16 x i8> %119) #5
  %121 = xor <16 x i8> %79, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %122 = and <16 x i8> %117, %121
  %123 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %122, <16 x i8> %120) #5
  %124 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %123, <16 x i8> %120) #5
  %125 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %124, <16 x i8> %120) #5
  %126 = select <16 x i1> %114, <16 x i8> %125, <16 x i8> zeroinitializer
  %127 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %126, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %128 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %126, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #5
  %129 = ashr <16 x i8> %127, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %130 = bitcast <16 x i8> %129 to <2 x i64>
  %131 = bitcast <16 x i8> %127 to <8 x i16>
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = bitcast <8 x i16> %132 to <2 x i64>
  %134 = and <2 x i64> %130, <i64 -2242545357980376864, i64 -2242545357980376864>
  %135 = and <2 x i64> %133, <i64 2242545357980376863, i64 2242545357980376863>
  %136 = or <2 x i64> %135, %134
  %137 = ashr <16 x i8> %128, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %138 = bitcast <16 x i8> %137 to <2 x i64>
  %139 = bitcast <16 x i8> %128 to <8 x i16>
  %140 = lshr <8 x i16> %139, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %141 = bitcast <8 x i16> %140 to <2 x i64>
  %142 = and <2 x i64> %138, <i64 -2242545357980376864, i64 -2242545357980376864>
  %143 = and <2 x i64> %141, <i64 2242545357980376863, i64 2242545357980376863>
  %144 = or <2 x i64> %143, %142
  %145 = bitcast <2 x i64> %136 to <16 x i8>
  %146 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %145, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %147 = ashr <16 x i8> %146, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %148 = bitcast <16 x i8> %147 to <2 x i64>
  %149 = bitcast <16 x i8> %146 to <8 x i16>
  %150 = lshr <8 x i16> %149, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %151 = bitcast <8 x i16> %150 to <2 x i64>
  %152 = and <2 x i64> %148, <i64 -9187201950435737472, i64 -9187201950435737472>
  %153 = and <2 x i64> %151, <i64 9187201950435737471, i64 9187201950435737471>
  %154 = or <2 x i64> %153, %152
  %155 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %118, <16 x i8> %145) #5
  %156 = bitcast <16 x i8> %155 to <2 x i64>
  %157 = xor <2 x i64> %156, <i64 -9187201950435737472, i64 -9187201950435737472>
  %158 = bitcast <2 x i64> %154 to <16 x i8>
  %159 = and <16 x i8> %158, %79
  %160 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %116, <16 x i8> %159) #5
  %161 = bitcast <16 x i8> %160 to <2 x i64>
  %162 = xor <2 x i64> %161, <i64 -9187201950435737472, i64 -9187201950435737472>
  %163 = bitcast <2 x i64> %144 to <16 x i8>
  %164 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %119, <16 x i8> %163) #5
  %165 = bitcast <16 x i8> %164 to <2 x i64>
  %166 = xor <2 x i64> %165, <i64 -9187201950435737472, i64 -9187201950435737472>
  %167 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %115, <16 x i8> %159) #5
  %168 = bitcast <16 x i8> %167 to <2 x i64>
  %169 = xor <2 x i64> %168, <i64 -9187201950435737472, i64 -9187201950435737472>
  store <2 x i64> %169, <2 x i64>* %40, align 1
  store <2 x i64> %166, <2 x i64>* %46, align 1
  store <2 x i64> %157, <2 x i64>* %49, align 1
  store <2 x i64> %162, <2 x i64>* %53, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_lpf_vertical_4_dual_sse2(i8*, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #2 {
  %9 = alloca [128 x i8], align 16
  %10 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %10) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 -86, i64 128, i1 false)
  %11 = getelementptr inbounds i8, i8* %0, i64 -4
  %12 = shl nsw i32 %1, 3
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i8, i8* %11, i64 %13
  %15 = bitcast i8* %11 to i64*
  %16 = load i64, i64* %15, align 1
  %17 = insertelement <2 x i64> undef, i64 %16, i32 0
  %18 = sext i32 %1 to i64
  %19 = getelementptr inbounds i8, i8* %11, i64 %18
  %20 = bitcast i8* %19 to i64*
  %21 = load i64, i64* %20, align 1
  %22 = insertelement <2 x i64> undef, i64 %21, i32 0
  %23 = bitcast <2 x i64> %17 to <16 x i8>
  %24 = bitcast <2 x i64> %22 to <16 x i8>
  %25 = shufflevector <16 x i8> %23, <16 x i8> %24, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %26 = shl nsw i32 %1, 1
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i8, i8* %11, i64 %27
  %29 = bitcast i8* %28 to i64*
  %30 = load i64, i64* %29, align 1
  %31 = insertelement <2 x i64> undef, i64 %30, i32 0
  %32 = mul nsw i32 %1, 3
  %33 = sext i32 %32 to i64
  %34 = getelementptr inbounds i8, i8* %11, i64 %33
  %35 = bitcast i8* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = bitcast <2 x i64> %31 to <16 x i8>
  %39 = bitcast <2 x i64> %37 to <16 x i8>
  %40 = shufflevector <16 x i8> %38, <16 x i8> %39, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %41 = shl nsw i32 %1, 2
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds i8, i8* %11, i64 %42
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> undef, i64 %45, i32 0
  %47 = mul nsw i32 %1, 5
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds i8, i8* %11, i64 %48
  %50 = bitcast i8* %49 to i64*
  %51 = load i64, i64* %50, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %46 to <16 x i8>
  %54 = bitcast <2 x i64> %52 to <16 x i8>
  %55 = shufflevector <16 x i8> %53, <16 x i8> %54, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %56 = mul nsw i32 %1, 6
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i8, i8* %11, i64 %57
  %59 = bitcast i8* %58 to i64*
  %60 = load i64, i64* %59, align 1
  %61 = insertelement <2 x i64> undef, i64 %60, i32 0
  %62 = mul nsw i32 %1, 7
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds i8, i8* %11, i64 %63
  %65 = bitcast i8* %64 to i64*
  %66 = load i64, i64* %65, align 1
  %67 = insertelement <2 x i64> undef, i64 %66, i32 0
  %68 = bitcast <2 x i64> %61 to <16 x i8>
  %69 = bitcast <2 x i64> %67 to <16 x i8>
  %70 = shufflevector <16 x i8> %68, <16 x i8> %69, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %71 = bitcast <16 x i8> %25 to <8 x i16>
  %72 = bitcast <16 x i8> %40 to <8 x i16>
  %73 = shufflevector <8 x i16> %71, <8 x i16> %72, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %74 = bitcast i8* %14 to i64*
  %75 = load i64, i64* %74, align 1
  %76 = insertelement <2 x i64> undef, i64 %75, i32 0
  %77 = getelementptr inbounds i8, i8* %14, i64 %18
  %78 = bitcast i8* %77 to i64*
  %79 = load i64, i64* %78, align 1
  %80 = insertelement <2 x i64> undef, i64 %79, i32 0
  %81 = bitcast <2 x i64> %76 to <16 x i8>
  %82 = bitcast <2 x i64> %80 to <16 x i8>
  %83 = shufflevector <16 x i8> %81, <16 x i8> %82, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %84 = bitcast <16 x i8> %55 to <8 x i16>
  %85 = bitcast <16 x i8> %70 to <8 x i16>
  %86 = shufflevector <8 x i16> %84, <8 x i16> %85, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %87 = getelementptr inbounds i8, i8* %14, i64 %27
  %88 = bitcast i8* %87 to i64*
  %89 = load i64, i64* %88, align 1
  %90 = insertelement <2 x i64> undef, i64 %89, i32 0
  %91 = getelementptr inbounds i8, i8* %14, i64 %33
  %92 = bitcast i8* %91 to i64*
  %93 = load i64, i64* %92, align 1
  %94 = insertelement <2 x i64> undef, i64 %93, i32 0
  %95 = bitcast <2 x i64> %90 to <16 x i8>
  %96 = bitcast <2 x i64> %94 to <16 x i8>
  %97 = shufflevector <16 x i8> %95, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %98 = getelementptr inbounds i8, i8* %14, i64 %42
  %99 = bitcast i8* %98 to i64*
  %100 = load i64, i64* %99, align 1
  %101 = insertelement <2 x i64> undef, i64 %100, i32 0
  %102 = getelementptr inbounds i8, i8* %14, i64 %48
  %103 = bitcast i8* %102 to i64*
  %104 = load i64, i64* %103, align 1
  %105 = insertelement <2 x i64> undef, i64 %104, i32 0
  %106 = bitcast <2 x i64> %101 to <16 x i8>
  %107 = bitcast <2 x i64> %105 to <16 x i8>
  %108 = shufflevector <16 x i8> %106, <16 x i8> %107, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %109 = bitcast <16 x i8> %83 to <8 x i16>
  %110 = bitcast <16 x i8> %97 to <8 x i16>
  %111 = shufflevector <8 x i16> %109, <8 x i16> %110, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %112 = getelementptr inbounds i8, i8* %14, i64 %57
  %113 = bitcast i8* %112 to i64*
  %114 = load i64, i64* %113, align 1
  %115 = insertelement <2 x i64> undef, i64 %114, i32 0
  %116 = getelementptr inbounds i8, i8* %14, i64 %63
  %117 = bitcast i8* %116 to i64*
  %118 = load i64, i64* %117, align 1
  %119 = insertelement <2 x i64> undef, i64 %118, i32 0
  %120 = bitcast <2 x i64> %115 to <16 x i8>
  %121 = bitcast <2 x i64> %119 to <16 x i8>
  %122 = shufflevector <16 x i8> %120, <16 x i8> %121, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %123 = bitcast <16 x i8> %108 to <8 x i16>
  %124 = bitcast <16 x i8> %122 to <8 x i16>
  %125 = shufflevector <8 x i16> %123, <8 x i16> %124, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %126 = bitcast <8 x i16> %73 to <4 x i32>
  %127 = bitcast <8 x i16> %86 to <4 x i32>
  %128 = shufflevector <4 x i32> %126, <4 x i32> %127, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %129 = bitcast <4 x i32> %128 to <2 x i64>
  %130 = shufflevector <4 x i32> %126, <4 x i32> %127, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %131 = bitcast <4 x i32> %130 to <2 x i64>
  %132 = bitcast <8 x i16> %111 to <4 x i32>
  %133 = bitcast <8 x i16> %125 to <4 x i32>
  %134 = shufflevector <4 x i32> %132, <4 x i32> %133, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %135 = bitcast <4 x i32> %134 to <2 x i64>
  %136 = shufflevector <4 x i32> %132, <4 x i32> %133, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %137 = bitcast <4 x i32> %136 to <2 x i64>
  %138 = bitcast [128 x i8]* %9 to <2 x i64>*
  %139 = shufflevector <2 x i64> %129, <2 x i64> %135, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %139, <2 x i64>* %138, align 16
  %140 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 16
  %141 = bitcast i8* %140 to <2 x i64>*
  %142 = shufflevector <2 x i64> %129, <2 x i64> %135, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %142, <2 x i64>* %141, align 16
  %143 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 32
  %144 = bitcast i8* %143 to <2 x i64>*
  %145 = shufflevector <2 x i64> %131, <2 x i64> %137, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %145, <2 x i64>* %144, align 16
  %146 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 48
  %147 = bitcast i8* %146 to <2 x i64>*
  %148 = shufflevector <2 x i64> %131, <2 x i64> %137, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %148, <2 x i64>* %147, align 16
  %149 = shufflevector <8 x i16> %71, <8 x i16> %72, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %150 = shufflevector <8 x i16> %84, <8 x i16> %85, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %109, <8 x i16> %110, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = shufflevector <8 x i16> %123, <8 x i16> %124, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = bitcast <8 x i16> %149 to <4 x i32>
  %154 = bitcast <8 x i16> %150 to <4 x i32>
  %155 = shufflevector <4 x i32> %153, <4 x i32> %154, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %156 = bitcast <4 x i32> %155 to <2 x i64>
  %157 = shufflevector <4 x i32> %153, <4 x i32> %154, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %158 = bitcast <4 x i32> %157 to <2 x i64>
  %159 = bitcast <8 x i16> %151 to <4 x i32>
  %160 = bitcast <8 x i16> %152 to <4 x i32>
  %161 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %164 = bitcast <4 x i32> %163 to <2 x i64>
  %165 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 64
  %166 = bitcast i8* %165 to <2 x i64>*
  %167 = shufflevector <2 x i64> %156, <2 x i64> %162, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %167, <2 x i64>* %166, align 16
  %168 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 80
  %169 = bitcast i8* %168 to <2 x i64>*
  %170 = shufflevector <2 x i64> %156, <2 x i64> %162, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %170, <2 x i64>* %169, align 16
  %171 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 96
  %172 = bitcast i8* %171 to <2 x i64>*
  %173 = shufflevector <2 x i64> %158, <2 x i64> %164, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %173, <2 x i64>* %172, align 16
  %174 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 112
  %175 = bitcast i8* %174 to <2 x i64>*
  %176 = shufflevector <2 x i64> %158, <2 x i64> %164, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %176, <2 x i64>* %175, align 16
  %177 = bitcast i8* %2 to <2 x i64>*
  %178 = load <2 x i64>, <2 x i64>* %177, align 16
  %179 = bitcast i8* %5 to <2 x i64>*
  %180 = load <2 x i64>, <2 x i64>* %179, align 16
  %181 = shufflevector <2 x i64> %178, <2 x i64> %180, <2 x i32> <i32 0, i32 2>
  %182 = bitcast i8* %3 to <2 x i64>*
  %183 = load <2 x i64>, <2 x i64>* %182, align 16
  %184 = bitcast i8* %6 to <2 x i64>*
  %185 = load <2 x i64>, <2 x i64>* %184, align 16
  %186 = shufflevector <2 x i64> %183, <2 x i64> %185, <2 x i32> <i32 0, i32 2>
  %187 = bitcast i8* %4 to <2 x i64>*
  %188 = load <2 x i64>, <2 x i64>* %187, align 16
  %189 = bitcast i8* %7 to <2 x i64>*
  %190 = load <2 x i64>, <2 x i64>* %189, align 16
  %191 = shufflevector <2 x i64> %188, <2 x i64> %190, <2 x i32> <i32 0, i32 2>
  %192 = bitcast <2 x i64> %139 to <16 x i8>
  %193 = bitcast <2 x i64> %142 to <16 x i8>
  %194 = bitcast <2 x i64> %145 to <16 x i8>
  %195 = bitcast <2 x i64> %148 to <16 x i8>
  %196 = bitcast <2 x i64> %167 to <16 x i8>
  %197 = bitcast <2 x i64> %170 to <16 x i8>
  %198 = bitcast <2 x i64> %173 to <16 x i8>
  %199 = bitcast <2 x i64> %176 to <16 x i8>
  %200 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %194, <16 x i8> %195) #5
  %201 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %195, <16 x i8> %194) #5
  %202 = or <16 x i8> %201, %200
  %203 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %197, <16 x i8> %196) #5
  %204 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %196, <16 x i8> %197) #5
  %205 = or <16 x i8> %204, %203
  %206 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %195, <16 x i8> %196) #5
  %207 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %196, <16 x i8> %195) #5
  %208 = or <16 x i8> %207, %206
  %209 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %194, <16 x i8> %197) #5
  %210 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %197, <16 x i8> %194) #5
  %211 = or <16 x i8> %210, %209
  %212 = icmp ugt <16 x i8> %202, %205
  %213 = select <16 x i1> %212, <16 x i8> %202, <16 x i8> %205
  %214 = bitcast <2 x i64> %191 to <16 x i8>
  %215 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %213, <16 x i8> %214) #5
  %216 = icmp eq <16 x i8> %215, zeroinitializer
  %217 = sext <16 x i1> %216 to <16 x i8>
  %218 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %208, <16 x i8> %208) #5
  %219 = bitcast <16 x i8> %211 to <8 x i16>
  %220 = lshr <8 x i16> %219, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %221 = bitcast <8 x i16> %220 to <16 x i8>
  %222 = and <16 x i8> %221, <i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127, i8 127>
  %223 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %218, <16 x i8> %222) #5
  %224 = bitcast <2 x i64> %181 to <16 x i8>
  %225 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %223, <16 x i8> %224) #5
  %226 = icmp ne <16 x i8> %225, zeroinitializer
  %227 = sext <16 x i1> %226 to <16 x i8>
  %228 = icmp ugt <16 x i8> %213, %227
  %229 = select <16 x i1> %228, <16 x i8> %213, <16 x i8> %227
  %230 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %193, <16 x i8> %194) #5
  %231 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %194, <16 x i8> %193) #5
  %232 = or <16 x i8> %231, %230
  %233 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %192, <16 x i8> %193) #5
  %234 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %193, <16 x i8> %192) #5
  %235 = or <16 x i8> %234, %233
  %236 = icmp ugt <16 x i8> %232, %235
  %237 = select <16 x i1> %236, <16 x i8> %232, <16 x i8> %235
  %238 = icmp ugt <16 x i8> %237, %229
  %239 = select <16 x i1> %238, <16 x i8> %237, <16 x i8> %229
  %240 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %198, <16 x i8> %197) #5
  %241 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %197, <16 x i8> %198) #5
  %242 = or <16 x i8> %241, %240
  %243 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %199, <16 x i8> %198) #5
  %244 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %198, <16 x i8> %199) #5
  %245 = or <16 x i8> %244, %243
  %246 = icmp ugt <16 x i8> %242, %245
  %247 = select <16 x i1> %246, <16 x i8> %242, <16 x i8> %245
  %248 = icmp ugt <16 x i8> %247, %239
  %249 = select <16 x i1> %248, <16 x i8> %247, <16 x i8> %239
  %250 = bitcast <2 x i64> %186 to <16 x i8>
  %251 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %249, <16 x i8> %250) #5
  %252 = icmp eq <16 x i8> %251, zeroinitializer
  %253 = xor <16 x i8> %194, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %254 = xor <16 x i8> %197, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %255 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %253, <16 x i8> %254) #5
  %256 = xor <16 x i8> %196, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %257 = xor <16 x i8> %195, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %258 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %256, <16 x i8> %257) #5
  %259 = xor <16 x i8> %217, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %260 = and <16 x i8> %255, %259
  %261 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %260, <16 x i8> %258) #5
  %262 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %261, <16 x i8> %258) #5
  %263 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %262, <16 x i8> %258) #5
  %264 = select <16 x i1> %252, <16 x i8> %263, <16 x i8> zeroinitializer
  %265 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %264, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %266 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %264, <16 x i8> <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>) #5
  %267 = ashr <16 x i8> %265, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %268 = bitcast <16 x i8> %267 to <2 x i64>
  %269 = bitcast <16 x i8> %265 to <8 x i16>
  %270 = lshr <8 x i16> %269, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %271 = bitcast <8 x i16> %270 to <2 x i64>
  %272 = and <2 x i64> %268, <i64 -2242545357980376864, i64 -2242545357980376864>
  %273 = and <2 x i64> %271, <i64 2242545357980376863, i64 2242545357980376863>
  %274 = or <2 x i64> %273, %272
  %275 = ashr <16 x i8> %266, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %276 = bitcast <16 x i8> %275 to <2 x i64>
  %277 = bitcast <16 x i8> %266 to <8 x i16>
  %278 = lshr <8 x i16> %277, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %279 = bitcast <8 x i16> %278 to <2 x i64>
  %280 = and <2 x i64> %276, <i64 -2242545357980376864, i64 -2242545357980376864>
  %281 = and <2 x i64> %279, <i64 2242545357980376863, i64 2242545357980376863>
  %282 = or <2 x i64> %281, %280
  %283 = bitcast <2 x i64> %274 to <16 x i8>
  %284 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %283, <16 x i8> <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>) #5
  %285 = ashr <16 x i8> %284, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %286 = bitcast <16 x i8> %285 to <2 x i64>
  %287 = bitcast <16 x i8> %284 to <8 x i16>
  %288 = lshr <8 x i16> %287, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %289 = bitcast <8 x i16> %288 to <2 x i64>
  %290 = and <2 x i64> %286, <i64 -9187201950435737472, i64 -9187201950435737472>
  %291 = and <2 x i64> %289, <i64 9187201950435737471, i64 9187201950435737471>
  %292 = or <2 x i64> %291, %290
  %293 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %256, <16 x i8> %283) #5
  %294 = bitcast <16 x i8> %293 to <2 x i64>
  %295 = xor <2 x i64> %294, <i64 -9187201950435737472, i64 -9187201950435737472>
  %296 = bitcast <2 x i64> %292 to <16 x i8>
  %297 = and <16 x i8> %296, %217
  %298 = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> %254, <16 x i8> %297) #5
  %299 = bitcast <16 x i8> %298 to <2 x i64>
  %300 = xor <2 x i64> %299, <i64 -9187201950435737472, i64 -9187201950435737472>
  %301 = bitcast <2 x i64> %282 to <16 x i8>
  %302 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %257, <16 x i8> %301) #5
  %303 = bitcast <16 x i8> %302 to <2 x i64>
  %304 = xor <2 x i64> %303, <i64 -9187201950435737472, i64 -9187201950435737472>
  %305 = tail call <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8> %253, <16 x i8> %297) #5
  %306 = bitcast <16 x i8> %305 to <2 x i64>
  %307 = xor <2 x i64> %306, <i64 -9187201950435737472, i64 -9187201950435737472>
  store <2 x i64> %307, <2 x i64>* %144, align 16
  store <2 x i64> %304, <2 x i64>* %147, align 16
  store <2 x i64> %295, <2 x i64>* %166, align 16
  store <2 x i64> %300, <2 x i64>* %169, align 16
  %308 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 8
  %309 = bitcast [128 x i8]* %9 to i64*
  %310 = load i64, i64* %309, align 16
  %311 = insertelement <2 x i64> undef, i64 %310, i32 0
  %312 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 16
  %313 = bitcast i8* %312 to i64*
  %314 = load i64, i64* %313, align 16
  %315 = insertelement <2 x i64> undef, i64 %314, i32 0
  %316 = bitcast <2 x i64> %311 to <16 x i8>
  %317 = bitcast <2 x i64> %315 to <16 x i8>
  %318 = shufflevector <16 x i8> %316, <16 x i8> %317, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %319 = bitcast <2 x i64> %307 to <16 x i8>
  %320 = bitcast <2 x i64> %304 to <16 x i8>
  %321 = shufflevector <16 x i8> %319, <16 x i8> %320, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %322 = bitcast <2 x i64> %295 to <16 x i8>
  %323 = bitcast <2 x i64> %300 to <16 x i8>
  %324 = shufflevector <16 x i8> %322, <16 x i8> %323, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %325 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 96
  %326 = bitcast i8* %325 to i64*
  %327 = load i64, i64* %326, align 16
  %328 = insertelement <2 x i64> undef, i64 %327, i32 0
  %329 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 112
  %330 = bitcast i8* %329 to i64*
  %331 = load i64, i64* %330, align 16
  %332 = insertelement <2 x i64> undef, i64 %331, i32 0
  %333 = bitcast <2 x i64> %328 to <16 x i8>
  %334 = bitcast <2 x i64> %332 to <16 x i8>
  %335 = shufflevector <16 x i8> %333, <16 x i8> %334, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %336 = bitcast <16 x i8> %318 to <8 x i16>
  %337 = bitcast <16 x i8> %321 to <8 x i16>
  %338 = shufflevector <8 x i16> %336, <8 x i16> %337, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %339 = bitcast <16 x i8> %324 to <8 x i16>
  %340 = bitcast <16 x i8> %335 to <8 x i16>
  %341 = shufflevector <8 x i16> %339, <8 x i16> %340, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %342 = bitcast <8 x i16> %338 to <4 x i32>
  %343 = bitcast <8 x i16> %341 to <4 x i32>
  %344 = shufflevector <4 x i32> %342, <4 x i32> %343, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %345 = bitcast <4 x i32> %344 to <2 x i64>
  %346 = extractelement <2 x i64> %345, i32 0
  store i64 %346, i64* %15, align 1
  %347 = extractelement <2 x i64> %345, i32 1
  store i64 %347, i64* %20, align 1
  %348 = shufflevector <4 x i32> %342, <4 x i32> %343, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %349 = bitcast <4 x i32> %348 to <2 x i64>
  %350 = extractelement <2 x i64> %349, i32 0
  store i64 %350, i64* %29, align 1
  %351 = extractelement <2 x i64> %349, i32 1
  store i64 %351, i64* %35, align 1
  %352 = shufflevector <8 x i16> %336, <8 x i16> %337, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %353 = shufflevector <8 x i16> %339, <8 x i16> %340, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %354 = bitcast <8 x i16> %352 to <4 x i32>
  %355 = bitcast <8 x i16> %353 to <4 x i32>
  %356 = shufflevector <4 x i32> %354, <4 x i32> %355, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %357 = bitcast <4 x i32> %356 to <2 x i64>
  %358 = extractelement <2 x i64> %357, i32 0
  store i64 %358, i64* %44, align 1
  %359 = extractelement <2 x i64> %357, i32 1
  store i64 %359, i64* %50, align 1
  %360 = shufflevector <4 x i32> %354, <4 x i32> %355, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %361 = bitcast <4 x i32> %360 to <2 x i64>
  %362 = extractelement <2 x i64> %361, i32 0
  store i64 %362, i64* %59, align 1
  %363 = extractelement <2 x i64> %361, i32 1
  store i64 %363, i64* %65, align 1
  %364 = bitcast i8* %308 to i64*
  %365 = load i64, i64* %364, align 8
  %366 = insertelement <2 x i64> undef, i64 %365, i32 0
  %367 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 24
  %368 = bitcast i8* %367 to i64*
  %369 = load i64, i64* %368, align 8
  %370 = insertelement <2 x i64> undef, i64 %369, i32 0
  %371 = bitcast <2 x i64> %366 to <16 x i8>
  %372 = bitcast <2 x i64> %370 to <16 x i8>
  %373 = shufflevector <16 x i8> %371, <16 x i8> %372, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %374 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 40
  %375 = bitcast i8* %374 to i64*
  %376 = load i64, i64* %375, align 8
  %377 = insertelement <2 x i64> undef, i64 %376, i32 0
  %378 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 56
  %379 = bitcast i8* %378 to i64*
  %380 = load i64, i64* %379, align 8
  %381 = insertelement <2 x i64> undef, i64 %380, i32 0
  %382 = bitcast <2 x i64> %377 to <16 x i8>
  %383 = bitcast <2 x i64> %381 to <16 x i8>
  %384 = shufflevector <16 x i8> %382, <16 x i8> %383, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %385 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 72
  %386 = bitcast i8* %385 to i64*
  %387 = load i64, i64* %386, align 8
  %388 = insertelement <2 x i64> undef, i64 %387, i32 0
  %389 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 88
  %390 = bitcast i8* %389 to i64*
  %391 = load i64, i64* %390, align 8
  %392 = insertelement <2 x i64> undef, i64 %391, i32 0
  %393 = bitcast <2 x i64> %388 to <16 x i8>
  %394 = bitcast <2 x i64> %392 to <16 x i8>
  %395 = shufflevector <16 x i8> %393, <16 x i8> %394, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %396 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 104
  %397 = bitcast i8* %396 to i64*
  %398 = load i64, i64* %397, align 8
  %399 = insertelement <2 x i64> undef, i64 %398, i32 0
  %400 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 120
  %401 = bitcast i8* %400 to i64*
  %402 = load i64, i64* %401, align 8
  %403 = insertelement <2 x i64> undef, i64 %402, i32 0
  %404 = bitcast <2 x i64> %399 to <16 x i8>
  %405 = bitcast <2 x i64> %403 to <16 x i8>
  %406 = shufflevector <16 x i8> %404, <16 x i8> %405, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %407 = bitcast <16 x i8> %373 to <8 x i16>
  %408 = bitcast <16 x i8> %384 to <8 x i16>
  %409 = shufflevector <8 x i16> %407, <8 x i16> %408, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %410 = bitcast <16 x i8> %395 to <8 x i16>
  %411 = bitcast <16 x i8> %406 to <8 x i16>
  %412 = shufflevector <8 x i16> %410, <8 x i16> %411, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %413 = bitcast <8 x i16> %409 to <4 x i32>
  %414 = bitcast <8 x i16> %412 to <4 x i32>
  %415 = shufflevector <4 x i32> %413, <4 x i32> %414, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %416 = bitcast <4 x i32> %415 to <2 x i64>
  %417 = extractelement <2 x i64> %416, i32 0
  store i64 %417, i64* %74, align 1
  %418 = extractelement <2 x i64> %416, i32 1
  store i64 %418, i64* %78, align 1
  %419 = shufflevector <4 x i32> %413, <4 x i32> %414, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %420 = bitcast <4 x i32> %419 to <2 x i64>
  %421 = extractelement <2 x i64> %420, i32 0
  store i64 %421, i64* %88, align 1
  %422 = extractelement <2 x i64> %420, i32 1
  store i64 %422, i64* %92, align 1
  %423 = shufflevector <8 x i16> %407, <8 x i16> %408, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %424 = shufflevector <8 x i16> %410, <8 x i16> %411, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %425 = bitcast <8 x i16> %423 to <4 x i32>
  %426 = bitcast <8 x i16> %424 to <4 x i32>
  %427 = shufflevector <4 x i32> %425, <4 x i32> %426, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %428 = bitcast <4 x i32> %427 to <2 x i64>
  %429 = extractelement <2 x i64> %428, i32 0
  store i64 %429, i64* %99, align 1
  %430 = extractelement <2 x i64> %428, i32 1
  store i64 %430, i64* %103, align 1
  %431 = shufflevector <4 x i32> %425, <4 x i32> %426, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %432 = bitcast <4 x i32> %431 to <2 x i64>
  %433 = extractelement <2 x i64> %432, i32 0
  store i64 %433, i64* %113, align 1
  %434 = extractelement <2 x i64> %432, i32 1
  store i64 %434, i64* %117, align 1
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %10) #5
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_lpf_vertical_8_sse2(i8*, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #2 {
  %6 = alloca [64 x i8], align 16
  %7 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %7) #5
  %8 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 48
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 16, i1 false)
  %9 = getelementptr inbounds i8, i8* %0, i64 -4
  %10 = sext i32 %1 to i64
  %11 = shl nsw i32 %1, 1
  %12 = sext i32 %11 to i64
  %13 = mul nsw i32 %1, 3
  %14 = sext i32 %13 to i64
  %15 = shl nsw i32 %1, 2
  %16 = sext i32 %15 to i64
  %17 = mul nsw i32 %1, 5
  %18 = sext i32 %17 to i64
  %19 = mul nsw i32 %1, 6
  %20 = sext i32 %19 to i64
  %21 = mul nsw i32 %1, 7
  %22 = sext i32 %21 to i64
  %23 = bitcast i8* %9 to i64*
  %24 = load i64, i64* %23, align 1
  %25 = insertelement <2 x i64> undef, i64 %24, i32 0
  %26 = getelementptr inbounds i8, i8* %9, i64 %10
  %27 = bitcast i8* %26 to i64*
  %28 = load i64, i64* %27, align 1
  %29 = insertelement <2 x i64> undef, i64 %28, i32 0
  %30 = bitcast <2 x i64> %25 to <16 x i8>
  %31 = bitcast <2 x i64> %29 to <16 x i8>
  %32 = shufflevector <16 x i8> %30, <16 x i8> %31, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %33 = getelementptr inbounds i8, i8* %9, i64 %12
  %34 = bitcast i8* %33 to i64*
  %35 = load i64, i64* %34, align 1
  %36 = insertelement <2 x i64> undef, i64 %35, i32 0
  %37 = getelementptr inbounds i8, i8* %9, i64 %14
  %38 = bitcast i8* %37 to i64*
  %39 = load i64, i64* %38, align 1
  %40 = insertelement <2 x i64> undef, i64 %39, i32 0
  %41 = bitcast <2 x i64> %36 to <16 x i8>
  %42 = bitcast <2 x i64> %40 to <16 x i8>
  %43 = shufflevector <16 x i8> %41, <16 x i8> %42, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %44 = getelementptr inbounds i8, i8* %9, i64 %16
  %45 = bitcast i8* %44 to i64*
  %46 = load i64, i64* %45, align 1
  %47 = insertelement <2 x i64> undef, i64 %46, i32 0
  %48 = getelementptr inbounds i8, i8* %9, i64 %18
  %49 = bitcast i8* %48 to i64*
  %50 = load i64, i64* %49, align 1
  %51 = insertelement <2 x i64> undef, i64 %50, i32 0
  %52 = bitcast <2 x i64> %47 to <16 x i8>
  %53 = bitcast <2 x i64> %51 to <16 x i8>
  %54 = shufflevector <16 x i8> %52, <16 x i8> %53, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = getelementptr inbounds i8, i8* %9, i64 %20
  %56 = bitcast i8* %55 to i64*
  %57 = load i64, i64* %56, align 1
  %58 = insertelement <2 x i64> undef, i64 %57, i32 0
  %59 = getelementptr inbounds i8, i8* %9, i64 %22
  %60 = bitcast i8* %59 to i64*
  %61 = load i64, i64* %60, align 1
  %62 = insertelement <2 x i64> undef, i64 %61, i32 0
  %63 = bitcast <2 x i64> %58 to <16 x i8>
  %64 = bitcast <2 x i64> %62 to <16 x i8>
  %65 = shufflevector <16 x i8> %63, <16 x i8> %64, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = bitcast <16 x i8> %32 to <8 x i16>
  %67 = bitcast <16 x i8> %43 to <8 x i16>
  %68 = shufflevector <8 x i16> %66, <8 x i16> %67, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %69 = bitcast <16 x i8> %54 to <8 x i16>
  %70 = bitcast <16 x i8> %65 to <8 x i16>
  %71 = shufflevector <8 x i16> %69, <8 x i16> %70, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %72 = bitcast <8 x i16> %68 to <4 x i32>
  %73 = bitcast <8 x i16> %71 to <4 x i32>
  %74 = shufflevector <4 x i32> %72, <4 x i32> %73, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %75 = bitcast [64 x i8]* %6 to i64*
  %76 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 8
  %77 = bitcast i8* %76 to i64*
  %78 = bitcast [64 x i8]* %6 to <4 x i32>*
  store <4 x i32> %74, <4 x i32>* %78, align 16
  %79 = shufflevector <4 x i32> %72, <4 x i32> %73, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %80 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 16
  %81 = bitcast i8* %80 to i64*
  %82 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 24
  %83 = bitcast i8* %82 to i64*
  %84 = bitcast i8* %80 to <4 x i32>*
  store <4 x i32> %79, <4 x i32>* %84, align 16
  %85 = shufflevector <8 x i16> %66, <8 x i16> %67, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %86 = shufflevector <8 x i16> %69, <8 x i16> %70, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %87 = bitcast <8 x i16> %85 to <4 x i32>
  %88 = bitcast <8 x i16> %86 to <4 x i32>
  %89 = shufflevector <4 x i32> %87, <4 x i32> %88, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %90 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 32
  %91 = bitcast i8* %90 to i64*
  %92 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 40
  %93 = bitcast i8* %92 to i64*
  %94 = bitcast i8* %90 to <4 x i32>*
  store <4 x i32> %89, <4 x i32>* %94, align 16
  %95 = shufflevector <4 x i32> %87, <4 x i32> %88, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %96 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 48
  %97 = bitcast i8* %96 to i64*
  %98 = getelementptr inbounds [64 x i8], [64 x i8]* %6, i64 0, i64 56
  %99 = bitcast i8* %98 to i64*
  %100 = bitcast i8* %96 to <4 x i32>*
  store <4 x i32> %95, <4 x i32>* %100, align 16
  call void @vpx_lpf_horizontal_8_sse2(i8* %90, i32 8, i8* %2, i8* %3, i8* %4)
  %101 = load i64, i64* %75, align 16
  %102 = insertelement <2 x i64> undef, i64 %101, i32 0
  %103 = load i64, i64* %77, align 8
  %104 = insertelement <2 x i64> undef, i64 %103, i32 0
  %105 = bitcast <2 x i64> %102 to <16 x i8>
  %106 = bitcast <2 x i64> %104 to <16 x i8>
  %107 = shufflevector <16 x i8> %105, <16 x i8> %106, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %108 = load i64, i64* %81, align 16
  %109 = insertelement <2 x i64> undef, i64 %108, i32 0
  %110 = load i64, i64* %83, align 8
  %111 = insertelement <2 x i64> undef, i64 %110, i32 0
  %112 = bitcast <2 x i64> %109 to <16 x i8>
  %113 = bitcast <2 x i64> %111 to <16 x i8>
  %114 = shufflevector <16 x i8> %112, <16 x i8> %113, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %115 = load i64, i64* %91, align 16
  %116 = insertelement <2 x i64> undef, i64 %115, i32 0
  %117 = load i64, i64* %93, align 8
  %118 = insertelement <2 x i64> undef, i64 %117, i32 0
  %119 = bitcast <2 x i64> %116 to <16 x i8>
  %120 = bitcast <2 x i64> %118 to <16 x i8>
  %121 = shufflevector <16 x i8> %119, <16 x i8> %120, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %122 = load i64, i64* %97, align 16
  %123 = insertelement <2 x i64> undef, i64 %122, i32 0
  %124 = load i64, i64* %99, align 8
  %125 = insertelement <2 x i64> undef, i64 %124, i32 0
  %126 = bitcast <2 x i64> %123 to <16 x i8>
  %127 = bitcast <2 x i64> %125 to <16 x i8>
  %128 = shufflevector <16 x i8> %126, <16 x i8> %127, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %129 = bitcast <16 x i8> %107 to <8 x i16>
  %130 = bitcast <16 x i8> %114 to <8 x i16>
  %131 = shufflevector <8 x i16> %129, <8 x i16> %130, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %132 = bitcast <16 x i8> %121 to <8 x i16>
  %133 = bitcast <16 x i8> %128 to <8 x i16>
  %134 = shufflevector <8 x i16> %132, <8 x i16> %133, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %135 = bitcast <8 x i16> %131 to <4 x i32>
  %136 = bitcast <8 x i16> %134 to <4 x i32>
  %137 = shufflevector <4 x i32> %135, <4 x i32> %136, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = extractelement <2 x i64> %138, i32 0
  store i64 %139, i64* %23, align 1
  %140 = extractelement <2 x i64> %138, i32 1
  store i64 %140, i64* %27, align 1
  %141 = shufflevector <4 x i32> %135, <4 x i32> %136, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %142 = bitcast <4 x i32> %141 to <2 x i64>
  %143 = extractelement <2 x i64> %142, i32 0
  store i64 %143, i64* %34, align 1
  %144 = extractelement <2 x i64> %142, i32 1
  store i64 %144, i64* %38, align 1
  %145 = shufflevector <8 x i16> %129, <8 x i16> %130, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %146 = shufflevector <8 x i16> %132, <8 x i16> %133, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %147 = bitcast <8 x i16> %145 to <4 x i32>
  %148 = bitcast <8 x i16> %146 to <4 x i32>
  %149 = shufflevector <4 x i32> %147, <4 x i32> %148, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %150 = bitcast <4 x i32> %149 to <2 x i64>
  %151 = extractelement <2 x i64> %150, i32 0
  store i64 %151, i64* %45, align 1
  %152 = extractelement <2 x i64> %150, i32 1
  store i64 %152, i64* %49, align 1
  %153 = shufflevector <4 x i32> %147, <4 x i32> %148, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %154 = bitcast <4 x i32> %153 to <2 x i64>
  %155 = extractelement <2 x i64> %154, i32 0
  store i64 %155, i64* %56, align 1
  %156 = extractelement <2 x i64> %154, i32 1
  store i64 %156, i64* %60, align 1
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %7) #5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_lpf_vertical_8_dual_sse2(i8*, i32, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly) local_unnamed_addr #2 {
  %9 = alloca [128 x i8], align 16
  %10 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %10) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 -86, i64 128, i1 false)
  %11 = getelementptr inbounds i8, i8* %0, i64 -4
  %12 = shl nsw i32 %1, 3
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i8, i8* %11, i64 %13
  %15 = bitcast i8* %11 to i64*
  %16 = load i64, i64* %15, align 1
  %17 = insertelement <2 x i64> undef, i64 %16, i32 0
  %18 = sext i32 %1 to i64
  %19 = getelementptr inbounds i8, i8* %11, i64 %18
  %20 = bitcast i8* %19 to i64*
  %21 = load i64, i64* %20, align 1
  %22 = insertelement <2 x i64> undef, i64 %21, i32 0
  %23 = bitcast <2 x i64> %17 to <16 x i8>
  %24 = bitcast <2 x i64> %22 to <16 x i8>
  %25 = shufflevector <16 x i8> %23, <16 x i8> %24, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %26 = shl nsw i32 %1, 1
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i8, i8* %11, i64 %27
  %29 = bitcast i8* %28 to i64*
  %30 = load i64, i64* %29, align 1
  %31 = insertelement <2 x i64> undef, i64 %30, i32 0
  %32 = mul nsw i32 %1, 3
  %33 = sext i32 %32 to i64
  %34 = getelementptr inbounds i8, i8* %11, i64 %33
  %35 = bitcast i8* %34 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = bitcast <2 x i64> %31 to <16 x i8>
  %39 = bitcast <2 x i64> %37 to <16 x i8>
  %40 = shufflevector <16 x i8> %38, <16 x i8> %39, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %41 = shl nsw i32 %1, 2
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds i8, i8* %11, i64 %42
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> undef, i64 %45, i32 0
  %47 = mul nsw i32 %1, 5
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds i8, i8* %11, i64 %48
  %50 = bitcast i8* %49 to i64*
  %51 = load i64, i64* %50, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %46 to <16 x i8>
  %54 = bitcast <2 x i64> %52 to <16 x i8>
  %55 = shufflevector <16 x i8> %53, <16 x i8> %54, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %56 = mul nsw i32 %1, 6
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i8, i8* %11, i64 %57
  %59 = bitcast i8* %58 to i64*
  %60 = load i64, i64* %59, align 1
  %61 = insertelement <2 x i64> undef, i64 %60, i32 0
  %62 = mul nsw i32 %1, 7
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds i8, i8* %11, i64 %63
  %65 = bitcast i8* %64 to i64*
  %66 = load i64, i64* %65, align 1
  %67 = insertelement <2 x i64> undef, i64 %66, i32 0
  %68 = bitcast <2 x i64> %61 to <16 x i8>
  %69 = bitcast <2 x i64> %67 to <16 x i8>
  %70 = shufflevector <16 x i8> %68, <16 x i8> %69, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %71 = bitcast <16 x i8> %25 to <8 x i16>
  %72 = bitcast <16 x i8> %40 to <8 x i16>
  %73 = shufflevector <8 x i16> %71, <8 x i16> %72, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %74 = bitcast i8* %14 to i64*
  %75 = load i64, i64* %74, align 1
  %76 = insertelement <2 x i64> undef, i64 %75, i32 0
  %77 = getelementptr inbounds i8, i8* %14, i64 %18
  %78 = bitcast i8* %77 to i64*
  %79 = load i64, i64* %78, align 1
  %80 = insertelement <2 x i64> undef, i64 %79, i32 0
  %81 = bitcast <2 x i64> %76 to <16 x i8>
  %82 = bitcast <2 x i64> %80 to <16 x i8>
  %83 = shufflevector <16 x i8> %81, <16 x i8> %82, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %84 = bitcast <16 x i8> %55 to <8 x i16>
  %85 = bitcast <16 x i8> %70 to <8 x i16>
  %86 = shufflevector <8 x i16> %84, <8 x i16> %85, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %87 = getelementptr inbounds i8, i8* %14, i64 %27
  %88 = bitcast i8* %87 to i64*
  %89 = load i64, i64* %88, align 1
  %90 = insertelement <2 x i64> undef, i64 %89, i32 0
  %91 = getelementptr inbounds i8, i8* %14, i64 %33
  %92 = bitcast i8* %91 to i64*
  %93 = load i64, i64* %92, align 1
  %94 = insertelement <2 x i64> undef, i64 %93, i32 0
  %95 = bitcast <2 x i64> %90 to <16 x i8>
  %96 = bitcast <2 x i64> %94 to <16 x i8>
  %97 = shufflevector <16 x i8> %95, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %98 = getelementptr inbounds i8, i8* %14, i64 %42
  %99 = bitcast i8* %98 to i64*
  %100 = load i64, i64* %99, align 1
  %101 = insertelement <2 x i64> undef, i64 %100, i32 0
  %102 = getelementptr inbounds i8, i8* %14, i64 %48
  %103 = bitcast i8* %102 to i64*
  %104 = load i64, i64* %103, align 1
  %105 = insertelement <2 x i64> undef, i64 %104, i32 0
  %106 = bitcast <2 x i64> %101 to <16 x i8>
  %107 = bitcast <2 x i64> %105 to <16 x i8>
  %108 = shufflevector <16 x i8> %106, <16 x i8> %107, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %109 = bitcast <16 x i8> %83 to <8 x i16>
  %110 = bitcast <16 x i8> %97 to <8 x i16>
  %111 = shufflevector <8 x i16> %109, <8 x i16> %110, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %112 = getelementptr inbounds i8, i8* %14, i64 %57
  %113 = bitcast i8* %112 to i64*
  %114 = load i64, i64* %113, align 1
  %115 = insertelement <2 x i64> undef, i64 %114, i32 0
  %116 = getelementptr inbounds i8, i8* %14, i64 %63
  %117 = bitcast i8* %116 to i64*
  %118 = load i64, i64* %117, align 1
  %119 = insertelement <2 x i64> undef, i64 %118, i32 0
  %120 = bitcast <2 x i64> %115 to <16 x i8>
  %121 = bitcast <2 x i64> %119 to <16 x i8>
  %122 = shufflevector <16 x i8> %120, <16 x i8> %121, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %123 = bitcast <16 x i8> %108 to <8 x i16>
  %124 = bitcast <16 x i8> %122 to <8 x i16>
  %125 = shufflevector <8 x i16> %123, <8 x i16> %124, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %126 = bitcast <8 x i16> %73 to <4 x i32>
  %127 = bitcast <8 x i16> %86 to <4 x i32>
  %128 = shufflevector <4 x i32> %126, <4 x i32> %127, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %129 = bitcast <4 x i32> %128 to <2 x i64>
  %130 = shufflevector <4 x i32> %126, <4 x i32> %127, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %131 = bitcast <4 x i32> %130 to <2 x i64>
  %132 = bitcast <8 x i16> %111 to <4 x i32>
  %133 = bitcast <8 x i16> %125 to <4 x i32>
  %134 = shufflevector <4 x i32> %132, <4 x i32> %133, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %135 = bitcast <4 x i32> %134 to <2 x i64>
  %136 = shufflevector <4 x i32> %132, <4 x i32> %133, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %137 = bitcast <4 x i32> %136 to <2 x i64>
  %138 = bitcast [128 x i8]* %9 to <2 x i64>*
  %139 = shufflevector <2 x i64> %129, <2 x i64> %135, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %139, <2 x i64>* %138, align 16
  %140 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 16
  %141 = bitcast i8* %140 to <2 x i64>*
  %142 = shufflevector <2 x i64> %129, <2 x i64> %135, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %142, <2 x i64>* %141, align 16
  %143 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 32
  %144 = bitcast i8* %143 to <2 x i64>*
  %145 = shufflevector <2 x i64> %131, <2 x i64> %137, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %145, <2 x i64>* %144, align 16
  %146 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 48
  %147 = bitcast i8* %146 to <2 x i64>*
  %148 = shufflevector <2 x i64> %131, <2 x i64> %137, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %148, <2 x i64>* %147, align 16
  %149 = shufflevector <8 x i16> %71, <8 x i16> %72, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %150 = shufflevector <8 x i16> %84, <8 x i16> %85, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %109, <8 x i16> %110, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = shufflevector <8 x i16> %123, <8 x i16> %124, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = bitcast <8 x i16> %149 to <4 x i32>
  %154 = bitcast <8 x i16> %150 to <4 x i32>
  %155 = shufflevector <4 x i32> %153, <4 x i32> %154, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %156 = bitcast <4 x i32> %155 to <2 x i64>
  %157 = shufflevector <4 x i32> %153, <4 x i32> %154, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %158 = bitcast <4 x i32> %157 to <2 x i64>
  %159 = bitcast <8 x i16> %151 to <4 x i32>
  %160 = bitcast <8 x i16> %152 to <4 x i32>
  %161 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %164 = bitcast <4 x i32> %163 to <2 x i64>
  %165 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 64
  %166 = bitcast i8* %165 to <2 x i64>*
  %167 = shufflevector <2 x i64> %156, <2 x i64> %162, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %167, <2 x i64>* %166, align 16
  %168 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 80
  %169 = bitcast i8* %168 to <2 x i64>*
  %170 = shufflevector <2 x i64> %156, <2 x i64> %162, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %170, <2 x i64>* %169, align 16
  %171 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 96
  %172 = bitcast i8* %171 to <2 x i64>*
  %173 = shufflevector <2 x i64> %158, <2 x i64> %164, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %173, <2 x i64>* %172, align 16
  %174 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 112
  %175 = bitcast i8* %174 to <2 x i64>*
  %176 = shufflevector <2 x i64> %158, <2 x i64> %164, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %176, <2 x i64>* %175, align 16
  call void @vpx_lpf_horizontal_8_dual_sse2(i8* %165, i32 16, i8* %2, i8* %3, i8* %4, i8* %5, i8* %6, i8* %7)
  %177 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 8
  %178 = bitcast [128 x i8]* %9 to i64*
  %179 = load i64, i64* %178, align 16
  %180 = insertelement <2 x i64> undef, i64 %179, i32 0
  %181 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 16
  %182 = bitcast i8* %181 to i64*
  %183 = load i64, i64* %182, align 16
  %184 = insertelement <2 x i64> undef, i64 %183, i32 0
  %185 = bitcast <2 x i64> %180 to <16 x i8>
  %186 = bitcast <2 x i64> %184 to <16 x i8>
  %187 = shufflevector <16 x i8> %185, <16 x i8> %186, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %188 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 32
  %189 = bitcast i8* %188 to i64*
  %190 = load i64, i64* %189, align 16
  %191 = insertelement <2 x i64> undef, i64 %190, i32 0
  %192 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 48
  %193 = bitcast i8* %192 to i64*
  %194 = load i64, i64* %193, align 16
  %195 = insertelement <2 x i64> undef, i64 %194, i32 0
  %196 = bitcast <2 x i64> %191 to <16 x i8>
  %197 = bitcast <2 x i64> %195 to <16 x i8>
  %198 = shufflevector <16 x i8> %196, <16 x i8> %197, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %199 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 64
  %200 = bitcast i8* %199 to i64*
  %201 = load i64, i64* %200, align 16
  %202 = insertelement <2 x i64> undef, i64 %201, i32 0
  %203 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 80
  %204 = bitcast i8* %203 to i64*
  %205 = load i64, i64* %204, align 16
  %206 = insertelement <2 x i64> undef, i64 %205, i32 0
  %207 = bitcast <2 x i64> %202 to <16 x i8>
  %208 = bitcast <2 x i64> %206 to <16 x i8>
  %209 = shufflevector <16 x i8> %207, <16 x i8> %208, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %210 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 96
  %211 = bitcast i8* %210 to i64*
  %212 = load i64, i64* %211, align 16
  %213 = insertelement <2 x i64> undef, i64 %212, i32 0
  %214 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 112
  %215 = bitcast i8* %214 to i64*
  %216 = load i64, i64* %215, align 16
  %217 = insertelement <2 x i64> undef, i64 %216, i32 0
  %218 = bitcast <2 x i64> %213 to <16 x i8>
  %219 = bitcast <2 x i64> %217 to <16 x i8>
  %220 = shufflevector <16 x i8> %218, <16 x i8> %219, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %221 = bitcast <16 x i8> %187 to <8 x i16>
  %222 = bitcast <16 x i8> %198 to <8 x i16>
  %223 = shufflevector <8 x i16> %221, <8 x i16> %222, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %224 = bitcast <16 x i8> %209 to <8 x i16>
  %225 = bitcast <16 x i8> %220 to <8 x i16>
  %226 = shufflevector <8 x i16> %224, <8 x i16> %225, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %227 = bitcast <8 x i16> %223 to <4 x i32>
  %228 = bitcast <8 x i16> %226 to <4 x i32>
  %229 = shufflevector <4 x i32> %227, <4 x i32> %228, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %230 = bitcast <4 x i32> %229 to <2 x i64>
  %231 = extractelement <2 x i64> %230, i32 0
  store i64 %231, i64* %15, align 1
  %232 = extractelement <2 x i64> %230, i32 1
  store i64 %232, i64* %20, align 1
  %233 = shufflevector <4 x i32> %227, <4 x i32> %228, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %234 = bitcast <4 x i32> %233 to <2 x i64>
  %235 = extractelement <2 x i64> %234, i32 0
  store i64 %235, i64* %29, align 1
  %236 = extractelement <2 x i64> %234, i32 1
  store i64 %236, i64* %35, align 1
  %237 = shufflevector <8 x i16> %221, <8 x i16> %222, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %238 = shufflevector <8 x i16> %224, <8 x i16> %225, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %239 = bitcast <8 x i16> %237 to <4 x i32>
  %240 = bitcast <8 x i16> %238 to <4 x i32>
  %241 = shufflevector <4 x i32> %239, <4 x i32> %240, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %242 = bitcast <4 x i32> %241 to <2 x i64>
  %243 = extractelement <2 x i64> %242, i32 0
  store i64 %243, i64* %44, align 1
  %244 = extractelement <2 x i64> %242, i32 1
  store i64 %244, i64* %50, align 1
  %245 = shufflevector <4 x i32> %239, <4 x i32> %240, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %246 = bitcast <4 x i32> %245 to <2 x i64>
  %247 = extractelement <2 x i64> %246, i32 0
  store i64 %247, i64* %59, align 1
  %248 = extractelement <2 x i64> %246, i32 1
  store i64 %248, i64* %65, align 1
  %249 = bitcast i8* %177 to i64*
  %250 = load i64, i64* %249, align 8
  %251 = insertelement <2 x i64> undef, i64 %250, i32 0
  %252 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 24
  %253 = bitcast i8* %252 to i64*
  %254 = load i64, i64* %253, align 8
  %255 = insertelement <2 x i64> undef, i64 %254, i32 0
  %256 = bitcast <2 x i64> %251 to <16 x i8>
  %257 = bitcast <2 x i64> %255 to <16 x i8>
  %258 = shufflevector <16 x i8> %256, <16 x i8> %257, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %259 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 40
  %260 = bitcast i8* %259 to i64*
  %261 = load i64, i64* %260, align 8
  %262 = insertelement <2 x i64> undef, i64 %261, i32 0
  %263 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 56
  %264 = bitcast i8* %263 to i64*
  %265 = load i64, i64* %264, align 8
  %266 = insertelement <2 x i64> undef, i64 %265, i32 0
  %267 = bitcast <2 x i64> %262 to <16 x i8>
  %268 = bitcast <2 x i64> %266 to <16 x i8>
  %269 = shufflevector <16 x i8> %267, <16 x i8> %268, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %270 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 72
  %271 = bitcast i8* %270 to i64*
  %272 = load i64, i64* %271, align 8
  %273 = insertelement <2 x i64> undef, i64 %272, i32 0
  %274 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 88
  %275 = bitcast i8* %274 to i64*
  %276 = load i64, i64* %275, align 8
  %277 = insertelement <2 x i64> undef, i64 %276, i32 0
  %278 = bitcast <2 x i64> %273 to <16 x i8>
  %279 = bitcast <2 x i64> %277 to <16 x i8>
  %280 = shufflevector <16 x i8> %278, <16 x i8> %279, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %281 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 104
  %282 = bitcast i8* %281 to i64*
  %283 = load i64, i64* %282, align 8
  %284 = insertelement <2 x i64> undef, i64 %283, i32 0
  %285 = getelementptr inbounds [128 x i8], [128 x i8]* %9, i64 0, i64 120
  %286 = bitcast i8* %285 to i64*
  %287 = load i64, i64* %286, align 8
  %288 = insertelement <2 x i64> undef, i64 %287, i32 0
  %289 = bitcast <2 x i64> %284 to <16 x i8>
  %290 = bitcast <2 x i64> %288 to <16 x i8>
  %291 = shufflevector <16 x i8> %289, <16 x i8> %290, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %292 = bitcast <16 x i8> %258 to <8 x i16>
  %293 = bitcast <16 x i8> %269 to <8 x i16>
  %294 = shufflevector <8 x i16> %292, <8 x i16> %293, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %295 = bitcast <16 x i8> %280 to <8 x i16>
  %296 = bitcast <16 x i8> %291 to <8 x i16>
  %297 = shufflevector <8 x i16> %295, <8 x i16> %296, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %298 = bitcast <8 x i16> %294 to <4 x i32>
  %299 = bitcast <8 x i16> %297 to <4 x i32>
  %300 = shufflevector <4 x i32> %298, <4 x i32> %299, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %301 = bitcast <4 x i32> %300 to <2 x i64>
  %302 = extractelement <2 x i64> %301, i32 0
  store i64 %302, i64* %74, align 1
  %303 = extractelement <2 x i64> %301, i32 1
  store i64 %303, i64* %78, align 1
  %304 = shufflevector <4 x i32> %298, <4 x i32> %299, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %305 = bitcast <4 x i32> %304 to <2 x i64>
  %306 = extractelement <2 x i64> %305, i32 0
  store i64 %306, i64* %88, align 1
  %307 = extractelement <2 x i64> %305, i32 1
  store i64 %307, i64* %92, align 1
  %308 = shufflevector <8 x i16> %292, <8 x i16> %293, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %309 = shufflevector <8 x i16> %295, <8 x i16> %296, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %310 = bitcast <8 x i16> %308 to <4 x i32>
  %311 = bitcast <8 x i16> %309 to <4 x i32>
  %312 = shufflevector <4 x i32> %310, <4 x i32> %311, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %313 = bitcast <4 x i32> %312 to <2 x i64>
  %314 = extractelement <2 x i64> %313, i32 0
  store i64 %314, i64* %99, align 1
  %315 = extractelement <2 x i64> %313, i32 1
  store i64 %315, i64* %103, align 1
  %316 = shufflevector <4 x i32> %310, <4 x i32> %311, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %317 = bitcast <4 x i32> %316 to <2 x i64>
  %318 = extractelement <2 x i64> %317, i32 0
  store i64 %318, i64* %113, align 1
  %319 = extractelement <2 x i64> %317, i32 1
  store i64 %319, i64* %117, align 1
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %10) #5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_lpf_vertical_16_sse2(i8*, i32, i8*, i8*, i8*) local_unnamed_addr #2 {
  %6 = alloca [128 x i8], align 16
  %7 = alloca [2 x i8*], align 16
  %8 = alloca [2 x i8*], align 16
  %9 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %9) #5
  %10 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 32
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 -86, i64 96, i1 false)
  %11 = bitcast [2 x i8*]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %11) #5
  %12 = getelementptr inbounds [2 x i8*], [2 x i8*]* %7, i64 0, i64 0
  %13 = getelementptr inbounds [2 x i8*], [2 x i8*]* %7, i64 0, i64 1
  %14 = bitcast [2 x i8*]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %14) #5
  %15 = getelementptr inbounds [2 x i8*], [2 x i8*]* %8, i64 0, i64 0
  %16 = getelementptr inbounds [2 x i8*], [2 x i8*]* %8, i64 0, i64 1
  %17 = getelementptr inbounds i8, i8* %0, i64 -8
  store i8* %17, i8** %12, align 16
  store i8* %0, i8** %13, align 8
  store i8* %9, i8** %15, align 16
  %18 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 64
  store i8* %18, i8** %16, align 8
  %19 = sext i32 %1 to i64
  %20 = shl nsw i32 %1, 1
  %21 = sext i32 %20 to i64
  %22 = mul nsw i32 %1, 3
  %23 = sext i32 %22 to i64
  %24 = shl nsw i32 %1, 2
  %25 = sext i32 %24 to i64
  %26 = mul nsw i32 %1, 5
  %27 = sext i32 %26 to i64
  %28 = mul nsw i32 %1, 6
  %29 = sext i32 %28 to i64
  %30 = mul nsw i32 %1, 7
  %31 = sext i32 %30 to i64
  %32 = bitcast i8* %17 to i64*
  %33 = load i64, i64* %32, align 1
  %34 = insertelement <2 x i64> undef, i64 %33, i32 0
  %35 = getelementptr inbounds i8, i8* %17, i64 %19
  %36 = bitcast i8* %35 to i64*
  %37 = load i64, i64* %36, align 1
  %38 = insertelement <2 x i64> undef, i64 %37, i32 0
  %39 = bitcast <2 x i64> %34 to <16 x i8>
  %40 = bitcast <2 x i64> %38 to <16 x i8>
  %41 = shufflevector <16 x i8> %39, <16 x i8> %40, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %42 = getelementptr inbounds i8, i8* %17, i64 %21
  %43 = bitcast i8* %42 to i64*
  %44 = load i64, i64* %43, align 1
  %45 = insertelement <2 x i64> undef, i64 %44, i32 0
  %46 = getelementptr inbounds i8, i8* %17, i64 %23
  %47 = bitcast i8* %46 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> undef, i64 %48, i32 0
  %50 = bitcast <2 x i64> %45 to <16 x i8>
  %51 = bitcast <2 x i64> %49 to <16 x i8>
  %52 = shufflevector <16 x i8> %50, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = getelementptr inbounds i8, i8* %17, i64 %25
  %54 = bitcast i8* %53 to i64*
  %55 = load i64, i64* %54, align 1
  %56 = insertelement <2 x i64> undef, i64 %55, i32 0
  %57 = getelementptr inbounds i8, i8* %17, i64 %27
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> undef, i64 %59, i32 0
  %61 = bitcast <2 x i64> %56 to <16 x i8>
  %62 = bitcast <2 x i64> %60 to <16 x i8>
  %63 = shufflevector <16 x i8> %61, <16 x i8> %62, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %64 = getelementptr inbounds i8, i8* %17, i64 %29
  %65 = bitcast i8* %64 to i64*
  %66 = load i64, i64* %65, align 1
  %67 = insertelement <2 x i64> undef, i64 %66, i32 0
  %68 = getelementptr inbounds i8, i8* %17, i64 %31
  %69 = bitcast i8* %68 to i64*
  %70 = load i64, i64* %69, align 1
  %71 = insertelement <2 x i64> undef, i64 %70, i32 0
  %72 = bitcast <2 x i64> %67 to <16 x i8>
  %73 = bitcast <2 x i64> %71 to <16 x i8>
  %74 = shufflevector <16 x i8> %72, <16 x i8> %73, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %75 = bitcast <16 x i8> %41 to <8 x i16>
  %76 = bitcast <16 x i8> %52 to <8 x i16>
  %77 = shufflevector <8 x i16> %75, <8 x i16> %76, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %78 = bitcast <16 x i8> %63 to <8 x i16>
  %79 = bitcast <16 x i8> %74 to <8 x i16>
  %80 = shufflevector <8 x i16> %78, <8 x i16> %79, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %81 = bitcast <8 x i16> %77 to <4 x i32>
  %82 = bitcast <8 x i16> %80 to <4 x i32>
  %83 = shufflevector <4 x i32> %81, <4 x i32> %82, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %84 = bitcast [128 x i8]* %6 to i64*
  %85 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 8
  %86 = bitcast i8* %85 to i64*
  %87 = bitcast [128 x i8]* %6 to <4 x i32>*
  store <4 x i32> %83, <4 x i32>* %87, align 16
  %88 = shufflevector <4 x i32> %81, <4 x i32> %82, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %89 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 16
  %90 = bitcast i8* %89 to i64*
  %91 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 24
  %92 = bitcast i8* %91 to i64*
  %93 = bitcast i8* %89 to <4 x i32>*
  store <4 x i32> %88, <4 x i32>* %93, align 16
  %94 = shufflevector <8 x i16> %75, <8 x i16> %76, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %95 = shufflevector <8 x i16> %78, <8 x i16> %79, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %96 = bitcast <8 x i16> %94 to <4 x i32>
  %97 = bitcast <8 x i16> %95 to <4 x i32>
  %98 = shufflevector <4 x i32> %96, <4 x i32> %97, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %99 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 32
  %100 = bitcast i8* %99 to i64*
  %101 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 40
  %102 = bitcast i8* %101 to i64*
  %103 = bitcast i8* %99 to <4 x i32>*
  store <4 x i32> %98, <4 x i32>* %103, align 16
  %104 = shufflevector <4 x i32> %96, <4 x i32> %97, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %105 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 48
  %106 = bitcast i8* %105 to i64*
  %107 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 56
  %108 = bitcast i8* %107 to i64*
  %109 = bitcast i8* %105 to <4 x i32>*
  store <4 x i32> %104, <4 x i32>* %109, align 16
  %110 = load i8*, i8** %13, align 8
  %111 = load i8*, i8** %16, align 8
  %112 = bitcast i8* %110 to i64*
  %113 = load i64, i64* %112, align 1
  %114 = insertelement <2 x i64> undef, i64 %113, i32 0
  %115 = getelementptr inbounds i8, i8* %110, i64 %19
  %116 = bitcast i8* %115 to i64*
  %117 = load i64, i64* %116, align 1
  %118 = insertelement <2 x i64> undef, i64 %117, i32 0
  %119 = bitcast <2 x i64> %114 to <16 x i8>
  %120 = bitcast <2 x i64> %118 to <16 x i8>
  %121 = shufflevector <16 x i8> %119, <16 x i8> %120, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %122 = getelementptr inbounds i8, i8* %110, i64 %21
  %123 = bitcast i8* %122 to i64*
  %124 = load i64, i64* %123, align 1
  %125 = insertelement <2 x i64> undef, i64 %124, i32 0
  %126 = getelementptr inbounds i8, i8* %110, i64 %23
  %127 = bitcast i8* %126 to i64*
  %128 = load i64, i64* %127, align 1
  %129 = insertelement <2 x i64> undef, i64 %128, i32 0
  %130 = bitcast <2 x i64> %125 to <16 x i8>
  %131 = bitcast <2 x i64> %129 to <16 x i8>
  %132 = shufflevector <16 x i8> %130, <16 x i8> %131, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %133 = getelementptr inbounds i8, i8* %110, i64 %25
  %134 = bitcast i8* %133 to i64*
  %135 = load i64, i64* %134, align 1
  %136 = insertelement <2 x i64> undef, i64 %135, i32 0
  %137 = getelementptr inbounds i8, i8* %110, i64 %27
  %138 = bitcast i8* %137 to i64*
  %139 = load i64, i64* %138, align 1
  %140 = insertelement <2 x i64> undef, i64 %139, i32 0
  %141 = bitcast <2 x i64> %136 to <16 x i8>
  %142 = bitcast <2 x i64> %140 to <16 x i8>
  %143 = shufflevector <16 x i8> %141, <16 x i8> %142, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %144 = getelementptr inbounds i8, i8* %110, i64 %29
  %145 = bitcast i8* %144 to i64*
  %146 = load i64, i64* %145, align 1
  %147 = insertelement <2 x i64> undef, i64 %146, i32 0
  %148 = getelementptr inbounds i8, i8* %110, i64 %31
  %149 = bitcast i8* %148 to i64*
  %150 = load i64, i64* %149, align 1
  %151 = insertelement <2 x i64> undef, i64 %150, i32 0
  %152 = bitcast <2 x i64> %147 to <16 x i8>
  %153 = bitcast <2 x i64> %151 to <16 x i8>
  %154 = shufflevector <16 x i8> %152, <16 x i8> %153, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %155 = bitcast <16 x i8> %121 to <8 x i16>
  %156 = bitcast <16 x i8> %132 to <8 x i16>
  %157 = shufflevector <8 x i16> %155, <8 x i16> %156, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %158 = bitcast <16 x i8> %143 to <8 x i16>
  %159 = bitcast <16 x i8> %154 to <8 x i16>
  %160 = shufflevector <8 x i16> %158, <8 x i16> %159, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %161 = bitcast <8 x i16> %157 to <4 x i32>
  %162 = bitcast <8 x i16> %160 to <4 x i32>
  %163 = shufflevector <4 x i32> %161, <4 x i32> %162, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %164 = bitcast i8* %111 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 1
  %165 = shufflevector <4 x i32> %161, <4 x i32> %162, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %166 = getelementptr inbounds i8, i8* %111, i64 16
  %167 = bitcast i8* %166 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %167, align 1
  %168 = shufflevector <8 x i16> %155, <8 x i16> %156, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %169 = shufflevector <8 x i16> %158, <8 x i16> %159, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %170 = bitcast <8 x i16> %168 to <4 x i32>
  %171 = bitcast <8 x i16> %169 to <4 x i32>
  %172 = shufflevector <4 x i32> %170, <4 x i32> %171, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %173 = getelementptr inbounds i8, i8* %111, i64 32
  %174 = bitcast i8* %173 to <4 x i32>*
  store <4 x i32> %172, <4 x i32>* %174, align 1
  %175 = shufflevector <4 x i32> %170, <4 x i32> %171, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %176 = getelementptr inbounds i8, i8* %111, i64 48
  %177 = bitcast i8* %176 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %177, align 1
  %178 = load void (i8*, i32, i8*, i8*, i8*)*, void (i8*, i32, i8*, i8*, i8*)** @vpx_lpf_horizontal_16, align 8
  call void %178(i8* %18, i32 8, i8* %2, i8* %3, i8* %4) #5
  store i8* %9, i8** %12, align 16
  store i8* %18, i8** %13, align 8
  store i8* %17, i8** %15, align 16
  store i8* %0, i8** %16, align 8
  %179 = load i64, i64* %84, align 16
  %180 = insertelement <2 x i64> undef, i64 %179, i32 0
  %181 = load i64, i64* %86, align 8
  %182 = insertelement <2 x i64> undef, i64 %181, i32 0
  %183 = bitcast <2 x i64> %180 to <16 x i8>
  %184 = bitcast <2 x i64> %182 to <16 x i8>
  %185 = shufflevector <16 x i8> %183, <16 x i8> %184, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %186 = load i64, i64* %90, align 16
  %187 = insertelement <2 x i64> undef, i64 %186, i32 0
  %188 = load i64, i64* %92, align 8
  %189 = insertelement <2 x i64> undef, i64 %188, i32 0
  %190 = bitcast <2 x i64> %187 to <16 x i8>
  %191 = bitcast <2 x i64> %189 to <16 x i8>
  %192 = shufflevector <16 x i8> %190, <16 x i8> %191, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %193 = load i64, i64* %100, align 16
  %194 = insertelement <2 x i64> undef, i64 %193, i32 0
  %195 = load i64, i64* %102, align 8
  %196 = insertelement <2 x i64> undef, i64 %195, i32 0
  %197 = bitcast <2 x i64> %194 to <16 x i8>
  %198 = bitcast <2 x i64> %196 to <16 x i8>
  %199 = shufflevector <16 x i8> %197, <16 x i8> %198, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %200 = load i64, i64* %106, align 16
  %201 = insertelement <2 x i64> undef, i64 %200, i32 0
  %202 = load i64, i64* %108, align 8
  %203 = insertelement <2 x i64> undef, i64 %202, i32 0
  %204 = bitcast <2 x i64> %201 to <16 x i8>
  %205 = bitcast <2 x i64> %203 to <16 x i8>
  %206 = shufflevector <16 x i8> %204, <16 x i8> %205, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %207 = bitcast <16 x i8> %185 to <8 x i16>
  %208 = bitcast <16 x i8> %192 to <8 x i16>
  %209 = shufflevector <8 x i16> %207, <8 x i16> %208, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %210 = bitcast <16 x i8> %199 to <8 x i16>
  %211 = bitcast <16 x i8> %206 to <8 x i16>
  %212 = shufflevector <8 x i16> %210, <8 x i16> %211, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %213 = bitcast <8 x i16> %209 to <4 x i32>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = shufflevector <4 x i32> %213, <4 x i32> %214, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %216 = bitcast <4 x i32> %215 to <2 x i64>
  %217 = extractelement <2 x i64> %216, i32 0
  store i64 %217, i64* %32, align 1
  %218 = extractelement <2 x i64> %216, i32 1
  store i64 %218, i64* %36, align 1
  %219 = shufflevector <4 x i32> %213, <4 x i32> %214, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %220 = bitcast <4 x i32> %219 to <2 x i64>
  %221 = extractelement <2 x i64> %220, i32 0
  store i64 %221, i64* %43, align 1
  %222 = extractelement <2 x i64> %220, i32 1
  store i64 %222, i64* %47, align 1
  %223 = shufflevector <8 x i16> %207, <8 x i16> %208, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %224 = shufflevector <8 x i16> %210, <8 x i16> %211, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %225 = bitcast <8 x i16> %223 to <4 x i32>
  %226 = bitcast <8 x i16> %224 to <4 x i32>
  %227 = shufflevector <4 x i32> %225, <4 x i32> %226, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %228 = bitcast <4 x i32> %227 to <2 x i64>
  %229 = extractelement <2 x i64> %228, i32 0
  store i64 %229, i64* %54, align 1
  %230 = extractelement <2 x i64> %228, i32 1
  store i64 %230, i64* %58, align 1
  %231 = shufflevector <4 x i32> %225, <4 x i32> %226, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %232 = bitcast <4 x i32> %231 to <2 x i64>
  %233 = extractelement <2 x i64> %232, i32 0
  store i64 %233, i64* %65, align 1
  %234 = extractelement <2 x i64> %232, i32 1
  store i64 %234, i64* %69, align 1
  %235 = bitcast i8* %18 to i64*
  %236 = load i64, i64* %235, align 16
  %237 = insertelement <2 x i64> undef, i64 %236, i32 0
  %238 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 72
  %239 = bitcast i8* %238 to i64*
  %240 = load i64, i64* %239, align 8
  %241 = insertelement <2 x i64> undef, i64 %240, i32 0
  %242 = bitcast <2 x i64> %237 to <16 x i8>
  %243 = bitcast <2 x i64> %241 to <16 x i8>
  %244 = shufflevector <16 x i8> %242, <16 x i8> %243, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %245 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 80
  %246 = bitcast i8* %245 to i64*
  %247 = load i64, i64* %246, align 16
  %248 = insertelement <2 x i64> undef, i64 %247, i32 0
  %249 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 88
  %250 = bitcast i8* %249 to i64*
  %251 = load i64, i64* %250, align 8
  %252 = insertelement <2 x i64> undef, i64 %251, i32 0
  %253 = bitcast <2 x i64> %248 to <16 x i8>
  %254 = bitcast <2 x i64> %252 to <16 x i8>
  %255 = shufflevector <16 x i8> %253, <16 x i8> %254, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %256 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 96
  %257 = bitcast i8* %256 to i64*
  %258 = load i64, i64* %257, align 16
  %259 = insertelement <2 x i64> undef, i64 %258, i32 0
  %260 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 104
  %261 = bitcast i8* %260 to i64*
  %262 = load i64, i64* %261, align 8
  %263 = insertelement <2 x i64> undef, i64 %262, i32 0
  %264 = bitcast <2 x i64> %259 to <16 x i8>
  %265 = bitcast <2 x i64> %263 to <16 x i8>
  %266 = shufflevector <16 x i8> %264, <16 x i8> %265, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %267 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 112
  %268 = bitcast i8* %267 to i64*
  %269 = load i64, i64* %268, align 16
  %270 = insertelement <2 x i64> undef, i64 %269, i32 0
  %271 = getelementptr inbounds [128 x i8], [128 x i8]* %6, i64 0, i64 120
  %272 = bitcast i8* %271 to i64*
  %273 = load i64, i64* %272, align 8
  %274 = insertelement <2 x i64> undef, i64 %273, i32 0
  %275 = bitcast <2 x i64> %270 to <16 x i8>
  %276 = bitcast <2 x i64> %274 to <16 x i8>
  %277 = shufflevector <16 x i8> %275, <16 x i8> %276, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %278 = bitcast <16 x i8> %244 to <8 x i16>
  %279 = bitcast <16 x i8> %255 to <8 x i16>
  %280 = shufflevector <8 x i16> %278, <8 x i16> %279, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %281 = bitcast <16 x i8> %266 to <8 x i16>
  %282 = bitcast <16 x i8> %277 to <8 x i16>
  %283 = shufflevector <8 x i16> %281, <8 x i16> %282, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %284 = bitcast <8 x i16> %280 to <4 x i32>
  %285 = bitcast <8 x i16> %283 to <4 x i32>
  %286 = shufflevector <4 x i32> %284, <4 x i32> %285, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %287 = bitcast <4 x i32> %286 to <2 x i64>
  %288 = bitcast i8* %0 to i64*
  %289 = extractelement <2 x i64> %287, i32 0
  store i64 %289, i64* %288, align 1
  %290 = getelementptr inbounds i8, i8* %0, i64 %19
  %291 = bitcast i8* %290 to i64*
  %292 = extractelement <2 x i64> %287, i32 1
  store i64 %292, i64* %291, align 1
  %293 = shufflevector <4 x i32> %284, <4 x i32> %285, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %294 = bitcast <4 x i32> %293 to <2 x i64>
  %295 = getelementptr inbounds i8, i8* %0, i64 %21
  %296 = bitcast i8* %295 to i64*
  %297 = extractelement <2 x i64> %294, i32 0
  store i64 %297, i64* %296, align 1
  %298 = getelementptr inbounds i8, i8* %0, i64 %23
  %299 = bitcast i8* %298 to i64*
  %300 = extractelement <2 x i64> %294, i32 1
  store i64 %300, i64* %299, align 1
  %301 = shufflevector <8 x i16> %278, <8 x i16> %279, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %302 = shufflevector <8 x i16> %281, <8 x i16> %282, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = bitcast <8 x i16> %301 to <4 x i32>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = shufflevector <4 x i32> %303, <4 x i32> %304, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %306 = bitcast <4 x i32> %305 to <2 x i64>
  %307 = getelementptr inbounds i8, i8* %0, i64 %25
  %308 = bitcast i8* %307 to i64*
  %309 = extractelement <2 x i64> %306, i32 0
  store i64 %309, i64* %308, align 1
  %310 = getelementptr inbounds i8, i8* %0, i64 %27
  %311 = bitcast i8* %310 to i64*
  %312 = extractelement <2 x i64> %306, i32 1
  store i64 %312, i64* %311, align 1
  %313 = shufflevector <4 x i32> %303, <4 x i32> %304, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %314 = bitcast <4 x i32> %313 to <2 x i64>
  %315 = getelementptr inbounds i8, i8* %0, i64 %29
  %316 = bitcast i8* %315 to i64*
  %317 = extractelement <2 x i64> %314, i32 0
  store i64 %317, i64* %316, align 1
  %318 = getelementptr inbounds i8, i8* %0, i64 %31
  %319 = bitcast i8* %318 to i64*
  %320 = extractelement <2 x i64> %314, i32 1
  store i64 %320, i64* %319, align 1
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %14) #5
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %11) #5
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %9) #5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_lpf_vertical_16_dual_sse2(i8* nocapture, i32, i8*, i8*, i8*) local_unnamed_addr #2 {
  %6 = alloca [256 x i8], align 16
  %7 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %7) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 -86, i64 256, i1 false)
  %8 = getelementptr inbounds i8, i8* %0, i64 -8
  %9 = shl nsw i32 %1, 3
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %8, i64 %10
  %12 = bitcast i8* %8 to i64*
  %13 = load i64, i64* %12, align 1
  %14 = insertelement <2 x i64> undef, i64 %13, i32 0
  %15 = sext i32 %1 to i64
  %16 = getelementptr inbounds i8, i8* %8, i64 %15
  %17 = bitcast i8* %16 to i64*
  %18 = load i64, i64* %17, align 1
  %19 = insertelement <2 x i64> undef, i64 %18, i32 0
  %20 = bitcast <2 x i64> %14 to <16 x i8>
  %21 = bitcast <2 x i64> %19 to <16 x i8>
  %22 = shufflevector <16 x i8> %20, <16 x i8> %21, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %23 = shl nsw i32 %1, 1
  %24 = sext i32 %23 to i64
  %25 = getelementptr inbounds i8, i8* %8, i64 %24
  %26 = bitcast i8* %25 to i64*
  %27 = load i64, i64* %26, align 1
  %28 = insertelement <2 x i64> undef, i64 %27, i32 0
  %29 = mul nsw i32 %1, 3
  %30 = sext i32 %29 to i64
  %31 = getelementptr inbounds i8, i8* %8, i64 %30
  %32 = bitcast i8* %31 to i64*
  %33 = load i64, i64* %32, align 1
  %34 = insertelement <2 x i64> undef, i64 %33, i32 0
  %35 = bitcast <2 x i64> %28 to <16 x i8>
  %36 = bitcast <2 x i64> %34 to <16 x i8>
  %37 = shufflevector <16 x i8> %35, <16 x i8> %36, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %38 = shl nsw i32 %1, 2
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds i8, i8* %8, i64 %39
  %41 = bitcast i8* %40 to i64*
  %42 = load i64, i64* %41, align 1
  %43 = insertelement <2 x i64> undef, i64 %42, i32 0
  %44 = mul nsw i32 %1, 5
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i8, i8* %8, i64 %45
  %47 = bitcast i8* %46 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> undef, i64 %48, i32 0
  %50 = bitcast <2 x i64> %43 to <16 x i8>
  %51 = bitcast <2 x i64> %49 to <16 x i8>
  %52 = shufflevector <16 x i8> %50, <16 x i8> %51, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %53 = mul nsw i32 %1, 6
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i8, i8* %8, i64 %54
  %56 = bitcast i8* %55 to i64*
  %57 = load i64, i64* %56, align 1
  %58 = insertelement <2 x i64> undef, i64 %57, i32 0
  %59 = mul nsw i32 %1, 7
  %60 = sext i32 %59 to i64
  %61 = getelementptr inbounds i8, i8* %8, i64 %60
  %62 = bitcast i8* %61 to i64*
  %63 = load i64, i64* %62, align 1
  %64 = insertelement <2 x i64> undef, i64 %63, i32 0
  %65 = bitcast <2 x i64> %58 to <16 x i8>
  %66 = bitcast <2 x i64> %64 to <16 x i8>
  %67 = shufflevector <16 x i8> %65, <16 x i8> %66, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %68 = bitcast <16 x i8> %22 to <8 x i16>
  %69 = bitcast <16 x i8> %37 to <8 x i16>
  %70 = shufflevector <8 x i16> %68, <8 x i16> %69, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %71 = bitcast i8* %11 to i64*
  %72 = load i64, i64* %71, align 1
  %73 = insertelement <2 x i64> undef, i64 %72, i32 0
  %74 = getelementptr inbounds i8, i8* %11, i64 %15
  %75 = bitcast i8* %74 to i64*
  %76 = load i64, i64* %75, align 1
  %77 = insertelement <2 x i64> undef, i64 %76, i32 0
  %78 = bitcast <2 x i64> %73 to <16 x i8>
  %79 = bitcast <2 x i64> %77 to <16 x i8>
  %80 = shufflevector <16 x i8> %78, <16 x i8> %79, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %81 = bitcast <16 x i8> %52 to <8 x i16>
  %82 = bitcast <16 x i8> %67 to <8 x i16>
  %83 = shufflevector <8 x i16> %81, <8 x i16> %82, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %84 = getelementptr inbounds i8, i8* %11, i64 %24
  %85 = bitcast i8* %84 to i64*
  %86 = load i64, i64* %85, align 1
  %87 = insertelement <2 x i64> undef, i64 %86, i32 0
  %88 = getelementptr inbounds i8, i8* %11, i64 %30
  %89 = bitcast i8* %88 to i64*
  %90 = load i64, i64* %89, align 1
  %91 = insertelement <2 x i64> undef, i64 %90, i32 0
  %92 = bitcast <2 x i64> %87 to <16 x i8>
  %93 = bitcast <2 x i64> %91 to <16 x i8>
  %94 = shufflevector <16 x i8> %92, <16 x i8> %93, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %95 = getelementptr inbounds i8, i8* %11, i64 %39
  %96 = bitcast i8* %95 to i64*
  %97 = load i64, i64* %96, align 1
  %98 = insertelement <2 x i64> undef, i64 %97, i32 0
  %99 = getelementptr inbounds i8, i8* %11, i64 %45
  %100 = bitcast i8* %99 to i64*
  %101 = load i64, i64* %100, align 1
  %102 = insertelement <2 x i64> undef, i64 %101, i32 0
  %103 = bitcast <2 x i64> %98 to <16 x i8>
  %104 = bitcast <2 x i64> %102 to <16 x i8>
  %105 = shufflevector <16 x i8> %103, <16 x i8> %104, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %106 = bitcast <16 x i8> %80 to <8 x i16>
  %107 = bitcast <16 x i8> %94 to <8 x i16>
  %108 = shufflevector <8 x i16> %106, <8 x i16> %107, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %109 = getelementptr inbounds i8, i8* %11, i64 %54
  %110 = bitcast i8* %109 to i64*
  %111 = load i64, i64* %110, align 1
  %112 = insertelement <2 x i64> undef, i64 %111, i32 0
  %113 = getelementptr inbounds i8, i8* %11, i64 %60
  %114 = bitcast i8* %113 to i64*
  %115 = load i64, i64* %114, align 1
  %116 = insertelement <2 x i64> undef, i64 %115, i32 0
  %117 = bitcast <2 x i64> %112 to <16 x i8>
  %118 = bitcast <2 x i64> %116 to <16 x i8>
  %119 = shufflevector <16 x i8> %117, <16 x i8> %118, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %120 = bitcast <16 x i8> %105 to <8 x i16>
  %121 = bitcast <16 x i8> %119 to <8 x i16>
  %122 = shufflevector <8 x i16> %120, <8 x i16> %121, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %123 = bitcast <8 x i16> %70 to <4 x i32>
  %124 = bitcast <8 x i16> %83 to <4 x i32>
  %125 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %126 = bitcast <4 x i32> %125 to <2 x i64>
  %127 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %128 = bitcast <4 x i32> %127 to <2 x i64>
  %129 = bitcast <8 x i16> %108 to <4 x i32>
  %130 = bitcast <8 x i16> %122 to <4 x i32>
  %131 = shufflevector <4 x i32> %129, <4 x i32> %130, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %132 = bitcast <4 x i32> %131 to <2 x i64>
  %133 = shufflevector <4 x i32> %129, <4 x i32> %130, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = bitcast [256 x i8]* %6 to <2 x i64>*
  %136 = shufflevector <2 x i64> %126, <2 x i64> %132, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %136, <2 x i64>* %135, align 16
  %137 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 16
  %138 = bitcast i8* %137 to <2 x i64>*
  %139 = shufflevector <2 x i64> %126, <2 x i64> %132, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %139, <2 x i64>* %138, align 16
  %140 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 32
  %141 = bitcast i8* %140 to <2 x i64>*
  %142 = shufflevector <2 x i64> %128, <2 x i64> %134, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %142, <2 x i64>* %141, align 16
  %143 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 48
  %144 = bitcast i8* %143 to <2 x i64>*
  %145 = shufflevector <2 x i64> %128, <2 x i64> %134, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %145, <2 x i64>* %144, align 16
  %146 = shufflevector <8 x i16> %68, <8 x i16> %69, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %147 = shufflevector <8 x i16> %81, <8 x i16> %82, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %148 = shufflevector <8 x i16> %106, <8 x i16> %107, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %149 = shufflevector <8 x i16> %120, <8 x i16> %121, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %150 = bitcast <8 x i16> %146 to <4 x i32>
  %151 = bitcast <8 x i16> %147 to <4 x i32>
  %152 = shufflevector <4 x i32> %150, <4 x i32> %151, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %153 = bitcast <4 x i32> %152 to <2 x i64>
  %154 = shufflevector <4 x i32> %150, <4 x i32> %151, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %155 = bitcast <4 x i32> %154 to <2 x i64>
  %156 = bitcast <8 x i16> %148 to <4 x i32>
  %157 = bitcast <8 x i16> %149 to <4 x i32>
  %158 = shufflevector <4 x i32> %156, <4 x i32> %157, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %159 = bitcast <4 x i32> %158 to <2 x i64>
  %160 = shufflevector <4 x i32> %156, <4 x i32> %157, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %161 = bitcast <4 x i32> %160 to <2 x i64>
  %162 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 64
  %163 = bitcast i8* %162 to <2 x i64>*
  %164 = shufflevector <2 x i64> %153, <2 x i64> %159, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %164, <2 x i64>* %163, align 16
  %165 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 80
  %166 = bitcast i8* %165 to <2 x i64>*
  %167 = shufflevector <2 x i64> %153, <2 x i64> %159, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %167, <2 x i64>* %166, align 16
  %168 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 96
  %169 = bitcast i8* %168 to <2 x i64>*
  %170 = shufflevector <2 x i64> %155, <2 x i64> %161, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %170, <2 x i64>* %169, align 16
  %171 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 112
  %172 = bitcast i8* %171 to <2 x i64>*
  %173 = shufflevector <2 x i64> %155, <2 x i64> %161, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %173, <2 x i64>* %172, align 16
  %174 = getelementptr inbounds i8, i8* %0, i64 %10
  %175 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 128
  %176 = bitcast i8* %0 to i64*
  %177 = load i64, i64* %176, align 1
  %178 = insertelement <2 x i64> undef, i64 %177, i32 0
  %179 = getelementptr inbounds i8, i8* %0, i64 %15
  %180 = bitcast i8* %179 to i64*
  %181 = load i64, i64* %180, align 1
  %182 = insertelement <2 x i64> undef, i64 %181, i32 0
  %183 = bitcast <2 x i64> %178 to <16 x i8>
  %184 = bitcast <2 x i64> %182 to <16 x i8>
  %185 = shufflevector <16 x i8> %183, <16 x i8> %184, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %186 = getelementptr inbounds i8, i8* %0, i64 %24
  %187 = bitcast i8* %186 to i64*
  %188 = load i64, i64* %187, align 1
  %189 = insertelement <2 x i64> undef, i64 %188, i32 0
  %190 = getelementptr inbounds i8, i8* %0, i64 %30
  %191 = bitcast i8* %190 to i64*
  %192 = load i64, i64* %191, align 1
  %193 = insertelement <2 x i64> undef, i64 %192, i32 0
  %194 = bitcast <2 x i64> %189 to <16 x i8>
  %195 = bitcast <2 x i64> %193 to <16 x i8>
  %196 = shufflevector <16 x i8> %194, <16 x i8> %195, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %197 = getelementptr inbounds i8, i8* %0, i64 %39
  %198 = bitcast i8* %197 to i64*
  %199 = load i64, i64* %198, align 1
  %200 = insertelement <2 x i64> undef, i64 %199, i32 0
  %201 = getelementptr inbounds i8, i8* %0, i64 %45
  %202 = bitcast i8* %201 to i64*
  %203 = load i64, i64* %202, align 1
  %204 = insertelement <2 x i64> undef, i64 %203, i32 0
  %205 = bitcast <2 x i64> %200 to <16 x i8>
  %206 = bitcast <2 x i64> %204 to <16 x i8>
  %207 = shufflevector <16 x i8> %205, <16 x i8> %206, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %208 = getelementptr inbounds i8, i8* %0, i64 %54
  %209 = bitcast i8* %208 to i64*
  %210 = load i64, i64* %209, align 1
  %211 = insertelement <2 x i64> undef, i64 %210, i32 0
  %212 = getelementptr inbounds i8, i8* %0, i64 %60
  %213 = bitcast i8* %212 to i64*
  %214 = load i64, i64* %213, align 1
  %215 = insertelement <2 x i64> undef, i64 %214, i32 0
  %216 = bitcast <2 x i64> %211 to <16 x i8>
  %217 = bitcast <2 x i64> %215 to <16 x i8>
  %218 = shufflevector <16 x i8> %216, <16 x i8> %217, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %219 = bitcast <16 x i8> %185 to <8 x i16>
  %220 = bitcast <16 x i8> %196 to <8 x i16>
  %221 = shufflevector <8 x i16> %219, <8 x i16> %220, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %222 = bitcast i8* %174 to i64*
  %223 = load i64, i64* %222, align 1
  %224 = insertelement <2 x i64> undef, i64 %223, i32 0
  %225 = getelementptr inbounds i8, i8* %174, i64 %15
  %226 = bitcast i8* %225 to i64*
  %227 = load i64, i64* %226, align 1
  %228 = insertelement <2 x i64> undef, i64 %227, i32 0
  %229 = bitcast <2 x i64> %224 to <16 x i8>
  %230 = bitcast <2 x i64> %228 to <16 x i8>
  %231 = shufflevector <16 x i8> %229, <16 x i8> %230, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %232 = bitcast <16 x i8> %207 to <8 x i16>
  %233 = bitcast <16 x i8> %218 to <8 x i16>
  %234 = shufflevector <8 x i16> %232, <8 x i16> %233, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %235 = getelementptr inbounds i8, i8* %174, i64 %24
  %236 = bitcast i8* %235 to i64*
  %237 = load i64, i64* %236, align 1
  %238 = insertelement <2 x i64> undef, i64 %237, i32 0
  %239 = getelementptr inbounds i8, i8* %174, i64 %30
  %240 = bitcast i8* %239 to i64*
  %241 = load i64, i64* %240, align 1
  %242 = insertelement <2 x i64> undef, i64 %241, i32 0
  %243 = bitcast <2 x i64> %238 to <16 x i8>
  %244 = bitcast <2 x i64> %242 to <16 x i8>
  %245 = shufflevector <16 x i8> %243, <16 x i8> %244, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %246 = getelementptr inbounds i8, i8* %174, i64 %39
  %247 = bitcast i8* %246 to i64*
  %248 = load i64, i64* %247, align 1
  %249 = insertelement <2 x i64> undef, i64 %248, i32 0
  %250 = getelementptr inbounds i8, i8* %174, i64 %45
  %251 = bitcast i8* %250 to i64*
  %252 = load i64, i64* %251, align 1
  %253 = insertelement <2 x i64> undef, i64 %252, i32 0
  %254 = bitcast <2 x i64> %249 to <16 x i8>
  %255 = bitcast <2 x i64> %253 to <16 x i8>
  %256 = shufflevector <16 x i8> %254, <16 x i8> %255, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %257 = bitcast <16 x i8> %231 to <8 x i16>
  %258 = bitcast <16 x i8> %245 to <8 x i16>
  %259 = shufflevector <8 x i16> %257, <8 x i16> %258, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %260 = getelementptr inbounds i8, i8* %174, i64 %54
  %261 = bitcast i8* %260 to i64*
  %262 = load i64, i64* %261, align 1
  %263 = insertelement <2 x i64> undef, i64 %262, i32 0
  %264 = getelementptr inbounds i8, i8* %174, i64 %60
  %265 = bitcast i8* %264 to i64*
  %266 = load i64, i64* %265, align 1
  %267 = insertelement <2 x i64> undef, i64 %266, i32 0
  %268 = bitcast <2 x i64> %263 to <16 x i8>
  %269 = bitcast <2 x i64> %267 to <16 x i8>
  %270 = shufflevector <16 x i8> %268, <16 x i8> %269, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %271 = bitcast <16 x i8> %256 to <8 x i16>
  %272 = bitcast <16 x i8> %270 to <8 x i16>
  %273 = shufflevector <8 x i16> %271, <8 x i16> %272, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %274 = bitcast <8 x i16> %221 to <4 x i32>
  %275 = bitcast <8 x i16> %234 to <4 x i32>
  %276 = shufflevector <4 x i32> %274, <4 x i32> %275, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %277 = bitcast <4 x i32> %276 to <2 x i64>
  %278 = shufflevector <4 x i32> %274, <4 x i32> %275, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %279 = bitcast <4 x i32> %278 to <2 x i64>
  %280 = bitcast <8 x i16> %259 to <4 x i32>
  %281 = bitcast <8 x i16> %273 to <4 x i32>
  %282 = shufflevector <4 x i32> %280, <4 x i32> %281, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %283 = bitcast <4 x i32> %282 to <2 x i64>
  %284 = shufflevector <4 x i32> %280, <4 x i32> %281, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %285 = bitcast <4 x i32> %284 to <2 x i64>
  %286 = bitcast i8* %175 to <2 x i64>*
  %287 = shufflevector <2 x i64> %277, <2 x i64> %283, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %287, <2 x i64>* %286, align 16
  %288 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 144
  %289 = bitcast i8* %288 to <2 x i64>*
  %290 = shufflevector <2 x i64> %277, <2 x i64> %283, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %290, <2 x i64>* %289, align 16
  %291 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 160
  %292 = bitcast i8* %291 to <2 x i64>*
  %293 = shufflevector <2 x i64> %279, <2 x i64> %285, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %293, <2 x i64>* %292, align 16
  %294 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 176
  %295 = bitcast i8* %294 to <2 x i64>*
  %296 = shufflevector <2 x i64> %279, <2 x i64> %285, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %296, <2 x i64>* %295, align 16
  %297 = shufflevector <8 x i16> %219, <8 x i16> %220, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %298 = shufflevector <8 x i16> %232, <8 x i16> %233, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %299 = shufflevector <8 x i16> %257, <8 x i16> %258, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %300 = shufflevector <8 x i16> %271, <8 x i16> %272, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %301 = bitcast <8 x i16> %297 to <4 x i32>
  %302 = bitcast <8 x i16> %298 to <4 x i32>
  %303 = shufflevector <4 x i32> %301, <4 x i32> %302, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %304 = bitcast <4 x i32> %303 to <2 x i64>
  %305 = shufflevector <4 x i32> %301, <4 x i32> %302, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %306 = bitcast <4 x i32> %305 to <2 x i64>
  %307 = bitcast <8 x i16> %299 to <4 x i32>
  %308 = bitcast <8 x i16> %300 to <4 x i32>
  %309 = shufflevector <4 x i32> %307, <4 x i32> %308, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %310 = bitcast <4 x i32> %309 to <2 x i64>
  %311 = shufflevector <4 x i32> %307, <4 x i32> %308, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %312 = bitcast <4 x i32> %311 to <2 x i64>
  %313 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 192
  %314 = bitcast i8* %313 to <2 x i64>*
  %315 = shufflevector <2 x i64> %304, <2 x i64> %310, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %315, <2 x i64>* %314, align 16
  %316 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 208
  %317 = bitcast i8* %316 to <2 x i64>*
  %318 = shufflevector <2 x i64> %304, <2 x i64> %310, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %318, <2 x i64>* %317, align 16
  %319 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 224
  %320 = bitcast i8* %319 to <2 x i64>*
  %321 = shufflevector <2 x i64> %306, <2 x i64> %312, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %321, <2 x i64>* %320, align 16
  %322 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 240
  %323 = bitcast i8* %322 to <2 x i64>*
  %324 = shufflevector <2 x i64> %306, <2 x i64> %312, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %324, <2 x i64>* %323, align 16
  %325 = load void (i8*, i32, i8*, i8*, i8*)*, void (i8*, i32, i8*, i8*, i8*)** @vpx_lpf_horizontal_16_dual, align 8
  call void %325(i8* %175, i32 16, i8* %2, i8* %3, i8* %4) #5
  %326 = bitcast [256 x i8]* %6 to i64*
  %327 = load i64, i64* %326, align 16
  %328 = insertelement <2 x i64> undef, i64 %327, i32 0
  %329 = bitcast i8* %137 to i64*
  %330 = load i64, i64* %329, align 16
  %331 = insertelement <2 x i64> undef, i64 %330, i32 0
  %332 = bitcast <2 x i64> %328 to <16 x i8>
  %333 = bitcast <2 x i64> %331 to <16 x i8>
  %334 = shufflevector <16 x i8> %332, <16 x i8> %333, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %335 = bitcast i8* %140 to i64*
  %336 = load i64, i64* %335, align 16
  %337 = insertelement <2 x i64> undef, i64 %336, i32 0
  %338 = bitcast i8* %143 to i64*
  %339 = load i64, i64* %338, align 16
  %340 = insertelement <2 x i64> undef, i64 %339, i32 0
  %341 = bitcast <2 x i64> %337 to <16 x i8>
  %342 = bitcast <2 x i64> %340 to <16 x i8>
  %343 = shufflevector <16 x i8> %341, <16 x i8> %342, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %344 = bitcast i8* %162 to i64*
  %345 = load i64, i64* %344, align 16
  %346 = insertelement <2 x i64> undef, i64 %345, i32 0
  %347 = bitcast i8* %165 to i64*
  %348 = load i64, i64* %347, align 16
  %349 = insertelement <2 x i64> undef, i64 %348, i32 0
  %350 = bitcast <2 x i64> %346 to <16 x i8>
  %351 = bitcast <2 x i64> %349 to <16 x i8>
  %352 = shufflevector <16 x i8> %350, <16 x i8> %351, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %353 = bitcast i8* %168 to i64*
  %354 = load i64, i64* %353, align 16
  %355 = insertelement <2 x i64> undef, i64 %354, i32 0
  %356 = bitcast i8* %171 to i64*
  %357 = load i64, i64* %356, align 16
  %358 = insertelement <2 x i64> undef, i64 %357, i32 0
  %359 = bitcast <2 x i64> %355 to <16 x i8>
  %360 = bitcast <2 x i64> %358 to <16 x i8>
  %361 = shufflevector <16 x i8> %359, <16 x i8> %360, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %362 = bitcast <16 x i8> %334 to <8 x i16>
  %363 = bitcast <16 x i8> %343 to <8 x i16>
  %364 = shufflevector <8 x i16> %362, <8 x i16> %363, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %365 = bitcast i8* %175 to i64*
  %366 = load i64, i64* %365, align 16
  %367 = insertelement <2 x i64> undef, i64 %366, i32 0
  %368 = bitcast i8* %288 to i64*
  %369 = load i64, i64* %368, align 16
  %370 = insertelement <2 x i64> undef, i64 %369, i32 0
  %371 = bitcast <2 x i64> %367 to <16 x i8>
  %372 = bitcast <2 x i64> %370 to <16 x i8>
  %373 = shufflevector <16 x i8> %371, <16 x i8> %372, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %374 = bitcast <16 x i8> %352 to <8 x i16>
  %375 = bitcast <16 x i8> %361 to <8 x i16>
  %376 = shufflevector <8 x i16> %374, <8 x i16> %375, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %377 = bitcast i8* %291 to i64*
  %378 = load i64, i64* %377, align 16
  %379 = insertelement <2 x i64> undef, i64 %378, i32 0
  %380 = bitcast i8* %294 to i64*
  %381 = load i64, i64* %380, align 16
  %382 = insertelement <2 x i64> undef, i64 %381, i32 0
  %383 = bitcast <2 x i64> %379 to <16 x i8>
  %384 = bitcast <2 x i64> %382 to <16 x i8>
  %385 = shufflevector <16 x i8> %383, <16 x i8> %384, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %386 = bitcast i8* %313 to i64*
  %387 = load i64, i64* %386, align 16
  %388 = insertelement <2 x i64> undef, i64 %387, i32 0
  %389 = bitcast i8* %316 to i64*
  %390 = load i64, i64* %389, align 16
  %391 = insertelement <2 x i64> undef, i64 %390, i32 0
  %392 = bitcast <2 x i64> %388 to <16 x i8>
  %393 = bitcast <2 x i64> %391 to <16 x i8>
  %394 = shufflevector <16 x i8> %392, <16 x i8> %393, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %395 = bitcast <16 x i8> %373 to <8 x i16>
  %396 = bitcast <16 x i8> %385 to <8 x i16>
  %397 = shufflevector <8 x i16> %395, <8 x i16> %396, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %398 = bitcast i8* %319 to i64*
  %399 = load i64, i64* %398, align 16
  %400 = insertelement <2 x i64> undef, i64 %399, i32 0
  %401 = bitcast i8* %322 to i64*
  %402 = load i64, i64* %401, align 16
  %403 = insertelement <2 x i64> undef, i64 %402, i32 0
  %404 = bitcast <2 x i64> %400 to <16 x i8>
  %405 = bitcast <2 x i64> %403 to <16 x i8>
  %406 = shufflevector <16 x i8> %404, <16 x i8> %405, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %407 = bitcast <16 x i8> %394 to <8 x i16>
  %408 = bitcast <16 x i8> %406 to <8 x i16>
  %409 = shufflevector <8 x i16> %407, <8 x i16> %408, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %410 = bitcast <8 x i16> %364 to <4 x i32>
  %411 = bitcast <8 x i16> %376 to <4 x i32>
  %412 = shufflevector <4 x i32> %410, <4 x i32> %411, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %413 = bitcast <4 x i32> %412 to <2 x i64>
  %414 = shufflevector <4 x i32> %410, <4 x i32> %411, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %415 = bitcast <4 x i32> %414 to <2 x i64>
  %416 = bitcast <8 x i16> %397 to <4 x i32>
  %417 = bitcast <8 x i16> %409 to <4 x i32>
  %418 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %419 = bitcast <4 x i32> %418 to <2 x i64>
  %420 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %421 = bitcast <4 x i32> %420 to <2 x i64>
  %422 = bitcast i8* %8 to <2 x i64>*
  %423 = shufflevector <2 x i64> %413, <2 x i64> %419, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %423, <2 x i64>* %422, align 1
  %424 = bitcast i8* %16 to <2 x i64>*
  %425 = shufflevector <2 x i64> %413, <2 x i64> %419, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %425, <2 x i64>* %424, align 1
  %426 = bitcast i8* %25 to <2 x i64>*
  %427 = shufflevector <2 x i64> %415, <2 x i64> %421, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %427, <2 x i64>* %426, align 1
  %428 = bitcast i8* %31 to <2 x i64>*
  %429 = shufflevector <2 x i64> %415, <2 x i64> %421, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %429, <2 x i64>* %428, align 1
  %430 = shufflevector <8 x i16> %362, <8 x i16> %363, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %431 = shufflevector <8 x i16> %374, <8 x i16> %375, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %432 = shufflevector <8 x i16> %395, <8 x i16> %396, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = shufflevector <8 x i16> %407, <8 x i16> %408, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %434 = bitcast <8 x i16> %430 to <4 x i32>
  %435 = bitcast <8 x i16> %431 to <4 x i32>
  %436 = shufflevector <4 x i32> %434, <4 x i32> %435, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %437 = bitcast <4 x i32> %436 to <2 x i64>
  %438 = shufflevector <4 x i32> %434, <4 x i32> %435, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %439 = bitcast <4 x i32> %438 to <2 x i64>
  %440 = bitcast <8 x i16> %432 to <4 x i32>
  %441 = bitcast <8 x i16> %433 to <4 x i32>
  %442 = shufflevector <4 x i32> %440, <4 x i32> %441, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %443 = bitcast <4 x i32> %442 to <2 x i64>
  %444 = shufflevector <4 x i32> %440, <4 x i32> %441, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %445 = bitcast <4 x i32> %444 to <2 x i64>
  %446 = bitcast i8* %40 to <2 x i64>*
  %447 = shufflevector <2 x i64> %437, <2 x i64> %443, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %447, <2 x i64>* %446, align 1
  %448 = bitcast i8* %46 to <2 x i64>*
  %449 = shufflevector <2 x i64> %437, <2 x i64> %443, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %449, <2 x i64>* %448, align 1
  %450 = bitcast i8* %55 to <2 x i64>*
  %451 = shufflevector <2 x i64> %439, <2 x i64> %445, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %451, <2 x i64>* %450, align 1
  %452 = bitcast i8* %61 to <2 x i64>*
  %453 = shufflevector <2 x i64> %439, <2 x i64> %445, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %453, <2 x i64>* %452, align 1
  %454 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 8
  %455 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 136
  %456 = bitcast i8* %454 to i64*
  %457 = load i64, i64* %456, align 8
  %458 = insertelement <2 x i64> undef, i64 %457, i32 0
  %459 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 24
  %460 = bitcast i8* %459 to i64*
  %461 = load i64, i64* %460, align 8
  %462 = insertelement <2 x i64> undef, i64 %461, i32 0
  %463 = bitcast <2 x i64> %458 to <16 x i8>
  %464 = bitcast <2 x i64> %462 to <16 x i8>
  %465 = shufflevector <16 x i8> %463, <16 x i8> %464, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %466 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 40
  %467 = bitcast i8* %466 to i64*
  %468 = load i64, i64* %467, align 8
  %469 = insertelement <2 x i64> undef, i64 %468, i32 0
  %470 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 56
  %471 = bitcast i8* %470 to i64*
  %472 = load i64, i64* %471, align 8
  %473 = insertelement <2 x i64> undef, i64 %472, i32 0
  %474 = bitcast <2 x i64> %469 to <16 x i8>
  %475 = bitcast <2 x i64> %473 to <16 x i8>
  %476 = shufflevector <16 x i8> %474, <16 x i8> %475, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %477 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 72
  %478 = bitcast i8* %477 to i64*
  %479 = load i64, i64* %478, align 8
  %480 = insertelement <2 x i64> undef, i64 %479, i32 0
  %481 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 88
  %482 = bitcast i8* %481 to i64*
  %483 = load i64, i64* %482, align 8
  %484 = insertelement <2 x i64> undef, i64 %483, i32 0
  %485 = bitcast <2 x i64> %480 to <16 x i8>
  %486 = bitcast <2 x i64> %484 to <16 x i8>
  %487 = shufflevector <16 x i8> %485, <16 x i8> %486, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %488 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 104
  %489 = bitcast i8* %488 to i64*
  %490 = load i64, i64* %489, align 8
  %491 = insertelement <2 x i64> undef, i64 %490, i32 0
  %492 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 120
  %493 = bitcast i8* %492 to i64*
  %494 = load i64, i64* %493, align 8
  %495 = insertelement <2 x i64> undef, i64 %494, i32 0
  %496 = bitcast <2 x i64> %491 to <16 x i8>
  %497 = bitcast <2 x i64> %495 to <16 x i8>
  %498 = shufflevector <16 x i8> %496, <16 x i8> %497, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %499 = bitcast <16 x i8> %465 to <8 x i16>
  %500 = bitcast <16 x i8> %476 to <8 x i16>
  %501 = shufflevector <8 x i16> %499, <8 x i16> %500, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %502 = bitcast i8* %455 to i64*
  %503 = load i64, i64* %502, align 8
  %504 = insertelement <2 x i64> undef, i64 %503, i32 0
  %505 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 152
  %506 = bitcast i8* %505 to i64*
  %507 = load i64, i64* %506, align 8
  %508 = insertelement <2 x i64> undef, i64 %507, i32 0
  %509 = bitcast <2 x i64> %504 to <16 x i8>
  %510 = bitcast <2 x i64> %508 to <16 x i8>
  %511 = shufflevector <16 x i8> %509, <16 x i8> %510, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %512 = bitcast <16 x i8> %487 to <8 x i16>
  %513 = bitcast <16 x i8> %498 to <8 x i16>
  %514 = shufflevector <8 x i16> %512, <8 x i16> %513, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %515 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 168
  %516 = bitcast i8* %515 to i64*
  %517 = load i64, i64* %516, align 8
  %518 = insertelement <2 x i64> undef, i64 %517, i32 0
  %519 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 184
  %520 = bitcast i8* %519 to i64*
  %521 = load i64, i64* %520, align 8
  %522 = insertelement <2 x i64> undef, i64 %521, i32 0
  %523 = bitcast <2 x i64> %518 to <16 x i8>
  %524 = bitcast <2 x i64> %522 to <16 x i8>
  %525 = shufflevector <16 x i8> %523, <16 x i8> %524, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %526 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 200
  %527 = bitcast i8* %526 to i64*
  %528 = load i64, i64* %527, align 8
  %529 = insertelement <2 x i64> undef, i64 %528, i32 0
  %530 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 216
  %531 = bitcast i8* %530 to i64*
  %532 = load i64, i64* %531, align 8
  %533 = insertelement <2 x i64> undef, i64 %532, i32 0
  %534 = bitcast <2 x i64> %529 to <16 x i8>
  %535 = bitcast <2 x i64> %533 to <16 x i8>
  %536 = shufflevector <16 x i8> %534, <16 x i8> %535, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %537 = bitcast <16 x i8> %511 to <8 x i16>
  %538 = bitcast <16 x i8> %525 to <8 x i16>
  %539 = shufflevector <8 x i16> %537, <8 x i16> %538, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %540 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 232
  %541 = bitcast i8* %540 to i64*
  %542 = load i64, i64* %541, align 8
  %543 = insertelement <2 x i64> undef, i64 %542, i32 0
  %544 = getelementptr inbounds [256 x i8], [256 x i8]* %6, i64 0, i64 248
  %545 = bitcast i8* %544 to i64*
  %546 = load i64, i64* %545, align 8
  %547 = insertelement <2 x i64> undef, i64 %546, i32 0
  %548 = bitcast <2 x i64> %543 to <16 x i8>
  %549 = bitcast <2 x i64> %547 to <16 x i8>
  %550 = shufflevector <16 x i8> %548, <16 x i8> %549, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %551 = bitcast <16 x i8> %536 to <8 x i16>
  %552 = bitcast <16 x i8> %550 to <8 x i16>
  %553 = shufflevector <8 x i16> %551, <8 x i16> %552, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %554 = bitcast <8 x i16> %501 to <4 x i32>
  %555 = bitcast <8 x i16> %514 to <4 x i32>
  %556 = shufflevector <4 x i32> %554, <4 x i32> %555, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %557 = bitcast <4 x i32> %556 to <2 x i64>
  %558 = shufflevector <4 x i32> %554, <4 x i32> %555, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %559 = bitcast <4 x i32> %558 to <2 x i64>
  %560 = bitcast <8 x i16> %539 to <4 x i32>
  %561 = bitcast <8 x i16> %553 to <4 x i32>
  %562 = shufflevector <4 x i32> %560, <4 x i32> %561, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %563 = bitcast <4 x i32> %562 to <2 x i64>
  %564 = shufflevector <4 x i32> %560, <4 x i32> %561, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %565 = bitcast <4 x i32> %564 to <2 x i64>
  %566 = bitcast i8* %11 to <2 x i64>*
  %567 = shufflevector <2 x i64> %557, <2 x i64> %563, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %567, <2 x i64>* %566, align 1
  %568 = bitcast i8* %74 to <2 x i64>*
  %569 = shufflevector <2 x i64> %557, <2 x i64> %563, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %569, <2 x i64>* %568, align 1
  %570 = bitcast i8* %84 to <2 x i64>*
  %571 = shufflevector <2 x i64> %559, <2 x i64> %565, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %571, <2 x i64>* %570, align 1
  %572 = bitcast i8* %88 to <2 x i64>*
  %573 = shufflevector <2 x i64> %559, <2 x i64> %565, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %573, <2 x i64>* %572, align 1
  %574 = shufflevector <8 x i16> %499, <8 x i16> %500, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %575 = shufflevector <8 x i16> %512, <8 x i16> %513, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %576 = shufflevector <8 x i16> %537, <8 x i16> %538, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %577 = shufflevector <8 x i16> %551, <8 x i16> %552, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %578 = bitcast <8 x i16> %574 to <4 x i32>
  %579 = bitcast <8 x i16> %575 to <4 x i32>
  %580 = shufflevector <4 x i32> %578, <4 x i32> %579, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %581 = bitcast <4 x i32> %580 to <2 x i64>
  %582 = shufflevector <4 x i32> %578, <4 x i32> %579, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %583 = bitcast <4 x i32> %582 to <2 x i64>
  %584 = bitcast <8 x i16> %576 to <4 x i32>
  %585 = bitcast <8 x i16> %577 to <4 x i32>
  %586 = shufflevector <4 x i32> %584, <4 x i32> %585, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %587 = bitcast <4 x i32> %586 to <2 x i64>
  %588 = shufflevector <4 x i32> %584, <4 x i32> %585, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %589 = bitcast <4 x i32> %588 to <2 x i64>
  %590 = bitcast i8* %95 to <2 x i64>*
  %591 = shufflevector <2 x i64> %581, <2 x i64> %587, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %591, <2 x i64>* %590, align 1
  %592 = bitcast i8* %99 to <2 x i64>*
  %593 = shufflevector <2 x i64> %581, <2 x i64> %587, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %593, <2 x i64>* %592, align 1
  %594 = bitcast i8* %109 to <2 x i64>*
  %595 = shufflevector <2 x i64> %583, <2 x i64> %589, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %595, <2 x i64>* %594, align 1
  %596 = bitcast i8* %113 to <2 x i64>*
  %597 = shufflevector <2 x i64> %583, <2 x i64> %589, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %597, <2 x i64>* %596, align 1
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %7) #5
  ret void
}

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.usub.sat.v16i8(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.sadd.sat.v16i8(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #3

attributes #0 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone }
attributes #4 = { nounwind readnone speculatable }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
