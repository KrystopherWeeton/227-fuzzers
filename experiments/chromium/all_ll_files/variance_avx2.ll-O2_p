; ModuleID = '../../third_party/libvpx/source/libvpx/vpx_dsp/x86/variance_avx2.c'
source_filename = "../../third_party/libvpx/source/libvpx/vpx_dsp/x86/variance_avx2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@bilinear_filters_avx2 = internal unnamed_addr constant <{ [256 x i8], [256 x i8] }> <{ [256 x i8] c"\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\10\00\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\08\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\06\0A\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\04\0C\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E\02\0E", [256 x i8] zeroinitializer }>, align 32

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_get16x16var_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture, i32* nocapture) local_unnamed_addr #0 {
  %7 = sext i32 %1 to i64
  %8 = sext i32 %3 to i64
  %9 = shl nsw i32 %1, 1
  %10 = sext i32 %9 to i64
  %11 = shl nsw i32 %3, 1
  %12 = sext i32 %11 to i64
  %13 = bitcast i8* %0 to <2 x i64>*
  %14 = load <2 x i64>, <2 x i64>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 %7
  %16 = bitcast i8* %15 to <2 x i64>*
  %17 = load <2 x i64>, <2 x i64>* %16, align 1
  %18 = bitcast i8* %2 to <2 x i64>*
  %19 = load <2 x i64>, <2 x i64>* %18, align 1
  %20 = getelementptr inbounds i8, i8* %2, i64 %8
  %21 = bitcast i8* %20 to <2 x i64>*
  %22 = load <2 x i64>, <2 x i64>* %21, align 1
  %23 = shufflevector <2 x i64> %14, <2 x i64> %17, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %24 = shufflevector <2 x i64> %19, <2 x i64> %22, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = bitcast <4 x i64> %23 to <32 x i8>
  %26 = bitcast <4 x i64> %24 to <32 x i8>
  %27 = shufflevector <32 x i8> %25, <32 x i8> %26, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %28 = shufflevector <32 x i8> %25, <32 x i8> %26, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %29 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %27, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %30 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %28, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %31 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %29, <16 x i16> %29) #5
  %32 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %30, <16 x i16> %30) #5
  %33 = add <16 x i16> %29, %30
  %34 = add <8 x i32> %31, %32
  %35 = getelementptr inbounds i8, i8* %0, i64 %10
  %36 = getelementptr inbounds i8, i8* %2, i64 %12
  %37 = bitcast i8* %35 to <2 x i64>*
  %38 = load <2 x i64>, <2 x i64>* %37, align 1
  %39 = getelementptr inbounds i8, i8* %35, i64 %7
  %40 = bitcast i8* %39 to <2 x i64>*
  %41 = load <2 x i64>, <2 x i64>* %40, align 1
  %42 = bitcast i8* %36 to <2 x i64>*
  %43 = load <2 x i64>, <2 x i64>* %42, align 1
  %44 = getelementptr inbounds i8, i8* %36, i64 %8
  %45 = bitcast i8* %44 to <2 x i64>*
  %46 = load <2 x i64>, <2 x i64>* %45, align 1
  %47 = shufflevector <2 x i64> %38, <2 x i64> %41, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = shufflevector <2 x i64> %43, <2 x i64> %46, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %49 = bitcast <4 x i64> %47 to <32 x i8>
  %50 = bitcast <4 x i64> %48 to <32 x i8>
  %51 = shufflevector <32 x i8> %49, <32 x i8> %50, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %52 = shufflevector <32 x i8> %49, <32 x i8> %50, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %53 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %51, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %54 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %52, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %55 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %53, <16 x i16> %53) #5
  %56 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %54, <16 x i16> %54) #5
  %57 = add <16 x i16> %53, %33
  %58 = add <16 x i16> %57, %54
  %59 = add <8 x i32> %55, %34
  %60 = add <8 x i32> %59, %56
  %61 = getelementptr inbounds i8, i8* %35, i64 %10
  %62 = getelementptr inbounds i8, i8* %36, i64 %12
  %63 = bitcast i8* %61 to <2 x i64>*
  %64 = load <2 x i64>, <2 x i64>* %63, align 1
  %65 = getelementptr inbounds i8, i8* %61, i64 %7
  %66 = bitcast i8* %65 to <2 x i64>*
  %67 = load <2 x i64>, <2 x i64>* %66, align 1
  %68 = bitcast i8* %62 to <2 x i64>*
  %69 = load <2 x i64>, <2 x i64>* %68, align 1
  %70 = getelementptr inbounds i8, i8* %62, i64 %8
  %71 = bitcast i8* %70 to <2 x i64>*
  %72 = load <2 x i64>, <2 x i64>* %71, align 1
  %73 = shufflevector <2 x i64> %64, <2 x i64> %67, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %74 = shufflevector <2 x i64> %69, <2 x i64> %72, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %75 = bitcast <4 x i64> %73 to <32 x i8>
  %76 = bitcast <4 x i64> %74 to <32 x i8>
  %77 = shufflevector <32 x i8> %75, <32 x i8> %76, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %78 = shufflevector <32 x i8> %75, <32 x i8> %76, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %79 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %77, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %80 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %78, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %81 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %79, <16 x i16> %79) #5
  %82 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %80, <16 x i16> %80) #5
  %83 = add <16 x i16> %79, %58
  %84 = add <16 x i16> %83, %80
  %85 = add <8 x i32> %81, %60
  %86 = add <8 x i32> %85, %82
  %87 = getelementptr inbounds i8, i8* %61, i64 %10
  %88 = getelementptr inbounds i8, i8* %62, i64 %12
  %89 = bitcast i8* %87 to <2 x i64>*
  %90 = load <2 x i64>, <2 x i64>* %89, align 1
  %91 = getelementptr inbounds i8, i8* %87, i64 %7
  %92 = bitcast i8* %91 to <2 x i64>*
  %93 = load <2 x i64>, <2 x i64>* %92, align 1
  %94 = bitcast i8* %88 to <2 x i64>*
  %95 = load <2 x i64>, <2 x i64>* %94, align 1
  %96 = getelementptr inbounds i8, i8* %88, i64 %8
  %97 = bitcast i8* %96 to <2 x i64>*
  %98 = load <2 x i64>, <2 x i64>* %97, align 1
  %99 = shufflevector <2 x i64> %90, <2 x i64> %93, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %100 = shufflevector <2 x i64> %95, <2 x i64> %98, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %101 = bitcast <4 x i64> %99 to <32 x i8>
  %102 = bitcast <4 x i64> %100 to <32 x i8>
  %103 = shufflevector <32 x i8> %101, <32 x i8> %102, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %104 = shufflevector <32 x i8> %101, <32 x i8> %102, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %105 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %103, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %106 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %104, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %107 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %105, <16 x i16> %105) #5
  %108 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %106, <16 x i16> %106) #5
  %109 = add <16 x i16> %105, %84
  %110 = add <16 x i16> %109, %106
  %111 = add <8 x i32> %107, %86
  %112 = add <8 x i32> %111, %108
  %113 = getelementptr inbounds i8, i8* %87, i64 %10
  %114 = getelementptr inbounds i8, i8* %88, i64 %12
  %115 = bitcast i8* %113 to <2 x i64>*
  %116 = load <2 x i64>, <2 x i64>* %115, align 1
  %117 = getelementptr inbounds i8, i8* %113, i64 %7
  %118 = bitcast i8* %117 to <2 x i64>*
  %119 = load <2 x i64>, <2 x i64>* %118, align 1
  %120 = bitcast i8* %114 to <2 x i64>*
  %121 = load <2 x i64>, <2 x i64>* %120, align 1
  %122 = getelementptr inbounds i8, i8* %114, i64 %8
  %123 = bitcast i8* %122 to <2 x i64>*
  %124 = load <2 x i64>, <2 x i64>* %123, align 1
  %125 = shufflevector <2 x i64> %116, <2 x i64> %119, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %126 = shufflevector <2 x i64> %121, <2 x i64> %124, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %127 = bitcast <4 x i64> %125 to <32 x i8>
  %128 = bitcast <4 x i64> %126 to <32 x i8>
  %129 = shufflevector <32 x i8> %127, <32 x i8> %128, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %130 = shufflevector <32 x i8> %127, <32 x i8> %128, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %131 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %129, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %132 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %130, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %133 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %131, <16 x i16> %131) #5
  %134 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %132, <16 x i16> %132) #5
  %135 = add <16 x i16> %131, %110
  %136 = add <16 x i16> %135, %132
  %137 = add <8 x i32> %133, %112
  %138 = add <8 x i32> %137, %134
  %139 = getelementptr inbounds i8, i8* %113, i64 %10
  %140 = getelementptr inbounds i8, i8* %114, i64 %12
  %141 = bitcast i8* %139 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 1
  %143 = getelementptr inbounds i8, i8* %139, i64 %7
  %144 = bitcast i8* %143 to <2 x i64>*
  %145 = load <2 x i64>, <2 x i64>* %144, align 1
  %146 = bitcast i8* %140 to <2 x i64>*
  %147 = load <2 x i64>, <2 x i64>* %146, align 1
  %148 = getelementptr inbounds i8, i8* %140, i64 %8
  %149 = bitcast i8* %148 to <2 x i64>*
  %150 = load <2 x i64>, <2 x i64>* %149, align 1
  %151 = shufflevector <2 x i64> %142, <2 x i64> %145, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %152 = shufflevector <2 x i64> %147, <2 x i64> %150, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %153 = bitcast <4 x i64> %151 to <32 x i8>
  %154 = bitcast <4 x i64> %152 to <32 x i8>
  %155 = shufflevector <32 x i8> %153, <32 x i8> %154, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %156 = shufflevector <32 x i8> %153, <32 x i8> %154, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %157 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %155, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %158 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %156, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %159 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %157, <16 x i16> %157) #5
  %160 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %158, <16 x i16> %158) #5
  %161 = add <16 x i16> %157, %136
  %162 = add <16 x i16> %161, %158
  %163 = add <8 x i32> %159, %138
  %164 = add <8 x i32> %163, %160
  %165 = getelementptr inbounds i8, i8* %139, i64 %10
  %166 = getelementptr inbounds i8, i8* %140, i64 %12
  %167 = bitcast i8* %165 to <2 x i64>*
  %168 = load <2 x i64>, <2 x i64>* %167, align 1
  %169 = getelementptr inbounds i8, i8* %165, i64 %7
  %170 = bitcast i8* %169 to <2 x i64>*
  %171 = load <2 x i64>, <2 x i64>* %170, align 1
  %172 = bitcast i8* %166 to <2 x i64>*
  %173 = load <2 x i64>, <2 x i64>* %172, align 1
  %174 = getelementptr inbounds i8, i8* %166, i64 %8
  %175 = bitcast i8* %174 to <2 x i64>*
  %176 = load <2 x i64>, <2 x i64>* %175, align 1
  %177 = shufflevector <2 x i64> %168, <2 x i64> %171, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %178 = shufflevector <2 x i64> %173, <2 x i64> %176, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %179 = bitcast <4 x i64> %177 to <32 x i8>
  %180 = bitcast <4 x i64> %178 to <32 x i8>
  %181 = shufflevector <32 x i8> %179, <32 x i8> %180, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %182 = shufflevector <32 x i8> %179, <32 x i8> %180, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %183 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %181, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %184 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %182, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %185 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %183, <16 x i16> %183) #5
  %186 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %184, <16 x i16> %184) #5
  %187 = add <16 x i16> %183, %162
  %188 = add <16 x i16> %187, %184
  %189 = add <8 x i32> %185, %164
  %190 = add <8 x i32> %189, %186
  %191 = getelementptr inbounds i8, i8* %165, i64 %10
  %192 = getelementptr inbounds i8, i8* %166, i64 %12
  %193 = bitcast i8* %191 to <2 x i64>*
  %194 = load <2 x i64>, <2 x i64>* %193, align 1
  %195 = getelementptr inbounds i8, i8* %191, i64 %7
  %196 = bitcast i8* %195 to <2 x i64>*
  %197 = load <2 x i64>, <2 x i64>* %196, align 1
  %198 = bitcast i8* %192 to <2 x i64>*
  %199 = load <2 x i64>, <2 x i64>* %198, align 1
  %200 = getelementptr inbounds i8, i8* %192, i64 %8
  %201 = bitcast i8* %200 to <2 x i64>*
  %202 = load <2 x i64>, <2 x i64>* %201, align 1
  %203 = shufflevector <2 x i64> %194, <2 x i64> %197, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %204 = shufflevector <2 x i64> %199, <2 x i64> %202, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = bitcast <4 x i64> %203 to <32 x i8>
  %206 = bitcast <4 x i64> %204 to <32 x i8>
  %207 = shufflevector <32 x i8> %205, <32 x i8> %206, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %208 = shufflevector <32 x i8> %205, <32 x i8> %206, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %209 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %207, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %210 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %208, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %211 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %209, <16 x i16> %209) #5
  %212 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %210, <16 x i16> %210) #5
  %213 = add <16 x i16> %209, %188
  %214 = add <16 x i16> %213, %210
  %215 = add <8 x i32> %211, %190
  %216 = add <8 x i32> %215, %212
  %217 = bitcast <16 x i16> %214 to <4 x i64>
  %218 = bitcast <8 x i32> %216 to <4 x i64>
  %219 = shufflevector <4 x i64> %217, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %220 = bitcast <16 x i16> %214 to <8 x i32>
  %221 = shufflevector <8 x i32> %220, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %222 = bitcast <2 x i64> %219 to <8 x i16>
  %223 = bitcast <4 x i32> %221 to <8 x i16>
  %224 = add <8 x i16> %223, %222
  %225 = bitcast <8 x i16> %224 to <16 x i8>
  %226 = shufflevector <16 x i8> %225, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %227 = bitcast <16 x i8> %226 to <8 x i16>
  %228 = add <8 x i16> %224, %227
  %229 = shufflevector <8 x i16> %228, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %230 = sext <4 x i16> %229 to <4 x i32>
  %231 = shufflevector <4 x i64> %218, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %232 = shufflevector <8 x i32> %216, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %233 = bitcast <2 x i64> %231 to <4 x i32>
  %234 = add <4 x i32> %232, %233
  %235 = shufflevector <4 x i32> %234, <4 x i32> %230, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %236 = shufflevector <4 x i32> %234, <4 x i32> %230, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %237 = add <4 x i32> %236, %235
  %238 = bitcast <4 x i32> %237 to <16 x i8>
  %239 = shufflevector <16 x i8> %238, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %240 = bitcast <16 x i8> %239 to <4 x i32>
  %241 = add <4 x i32> %237, %240
  %242 = extractelement <4 x i32> %241, i32 0
  store i32 %242, i32* %4, align 4
  %243 = extractelement <4 x i32> %241, i64 1
  store i32 %243, i32* %5, align 4
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_variance16x8_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  %8 = shl nsw i32 %1, 1
  %9 = sext i32 %8 to i64
  %10 = shl nsw i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = bitcast i8* %0 to <2 x i64>*
  %13 = load <2 x i64>, <2 x i64>* %12, align 1
  %14 = getelementptr inbounds i8, i8* %0, i64 %6
  %15 = bitcast i8* %14 to <2 x i64>*
  %16 = load <2 x i64>, <2 x i64>* %15, align 1
  %17 = bitcast i8* %2 to <2 x i64>*
  %18 = load <2 x i64>, <2 x i64>* %17, align 1
  %19 = getelementptr inbounds i8, i8* %2, i64 %7
  %20 = bitcast i8* %19 to <2 x i64>*
  %21 = load <2 x i64>, <2 x i64>* %20, align 1
  %22 = shufflevector <2 x i64> %13, <2 x i64> %16, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %23 = shufflevector <2 x i64> %18, <2 x i64> %21, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %24 = bitcast <4 x i64> %22 to <32 x i8>
  %25 = bitcast <4 x i64> %23 to <32 x i8>
  %26 = shufflevector <32 x i8> %24, <32 x i8> %25, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %27 = shufflevector <32 x i8> %24, <32 x i8> %25, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %28 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %26, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %29 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %27, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %30 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %28, <16 x i16> %28) #5
  %31 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %29, <16 x i16> %29) #5
  %32 = add <16 x i16> %28, %29
  %33 = add <8 x i32> %30, %31
  %34 = getelementptr inbounds i8, i8* %0, i64 %9
  %35 = getelementptr inbounds i8, i8* %2, i64 %11
  %36 = bitcast i8* %34 to <2 x i64>*
  %37 = load <2 x i64>, <2 x i64>* %36, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 %6
  %39 = bitcast i8* %38 to <2 x i64>*
  %40 = load <2 x i64>, <2 x i64>* %39, align 1
  %41 = bitcast i8* %35 to <2 x i64>*
  %42 = load <2 x i64>, <2 x i64>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %35, i64 %7
  %44 = bitcast i8* %43 to <2 x i64>*
  %45 = load <2 x i64>, <2 x i64>* %44, align 1
  %46 = shufflevector <2 x i64> %37, <2 x i64> %40, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = shufflevector <2 x i64> %42, <2 x i64> %45, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = bitcast <4 x i64> %46 to <32 x i8>
  %49 = bitcast <4 x i64> %47 to <32 x i8>
  %50 = shufflevector <32 x i8> %48, <32 x i8> %49, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %51 = shufflevector <32 x i8> %48, <32 x i8> %49, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %52 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %50, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %53 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %51, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %54 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %52, <16 x i16> %52) #5
  %55 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %53, <16 x i16> %53) #5
  %56 = add <16 x i16> %52, %32
  %57 = add <16 x i16> %56, %53
  %58 = add <8 x i32> %54, %33
  %59 = add <8 x i32> %58, %55
  %60 = getelementptr inbounds i8, i8* %34, i64 %9
  %61 = getelementptr inbounds i8, i8* %35, i64 %11
  %62 = bitcast i8* %60 to <2 x i64>*
  %63 = load <2 x i64>, <2 x i64>* %62, align 1
  %64 = getelementptr inbounds i8, i8* %60, i64 %6
  %65 = bitcast i8* %64 to <2 x i64>*
  %66 = load <2 x i64>, <2 x i64>* %65, align 1
  %67 = bitcast i8* %61 to <2 x i64>*
  %68 = load <2 x i64>, <2 x i64>* %67, align 1
  %69 = getelementptr inbounds i8, i8* %61, i64 %7
  %70 = bitcast i8* %69 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 1
  %72 = shufflevector <2 x i64> %63, <2 x i64> %66, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %73 = shufflevector <2 x i64> %68, <2 x i64> %71, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %74 = bitcast <4 x i64> %72 to <32 x i8>
  %75 = bitcast <4 x i64> %73 to <32 x i8>
  %76 = shufflevector <32 x i8> %74, <32 x i8> %75, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %77 = shufflevector <32 x i8> %74, <32 x i8> %75, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %78 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %76, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %79 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %77, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %80 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %78, <16 x i16> %78) #5
  %81 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %79, <16 x i16> %79) #5
  %82 = add <16 x i16> %78, %57
  %83 = add <16 x i16> %82, %79
  %84 = add <8 x i32> %80, %59
  %85 = add <8 x i32> %84, %81
  %86 = getelementptr inbounds i8, i8* %60, i64 %9
  %87 = getelementptr inbounds i8, i8* %61, i64 %11
  %88 = bitcast i8* %86 to <2 x i64>*
  %89 = load <2 x i64>, <2 x i64>* %88, align 1
  %90 = getelementptr inbounds i8, i8* %86, i64 %6
  %91 = bitcast i8* %90 to <2 x i64>*
  %92 = load <2 x i64>, <2 x i64>* %91, align 1
  %93 = bitcast i8* %87 to <2 x i64>*
  %94 = load <2 x i64>, <2 x i64>* %93, align 1
  %95 = getelementptr inbounds i8, i8* %87, i64 %7
  %96 = bitcast i8* %95 to <2 x i64>*
  %97 = load <2 x i64>, <2 x i64>* %96, align 1
  %98 = shufflevector <2 x i64> %89, <2 x i64> %92, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %99 = shufflevector <2 x i64> %94, <2 x i64> %97, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %100 = bitcast <4 x i64> %98 to <32 x i8>
  %101 = bitcast <4 x i64> %99 to <32 x i8>
  %102 = shufflevector <32 x i8> %100, <32 x i8> %101, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %103 = shufflevector <32 x i8> %100, <32 x i8> %101, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %104 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %102, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %105 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %103, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %106 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %104, <16 x i16> %104) #5
  %107 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %105, <16 x i16> %105) #5
  %108 = add <16 x i16> %104, %83
  %109 = add <16 x i16> %108, %105
  %110 = add <8 x i32> %106, %85
  %111 = add <8 x i32> %110, %107
  %112 = bitcast <16 x i16> %109 to <4 x i64>
  %113 = bitcast <8 x i32> %111 to <4 x i64>
  %114 = shufflevector <4 x i64> %112, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %115 = bitcast <16 x i16> %109 to <8 x i32>
  %116 = shufflevector <8 x i32> %115, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %117 = bitcast <2 x i64> %114 to <8 x i16>
  %118 = bitcast <4 x i32> %116 to <8 x i16>
  %119 = add <8 x i16> %118, %117
  %120 = bitcast <8 x i16> %119 to <16 x i8>
  %121 = shufflevector <16 x i8> %120, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %122 = bitcast <16 x i8> %121 to <8 x i16>
  %123 = add <8 x i16> %119, %122
  %124 = shufflevector <8 x i16> %123, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %125 = sext <4 x i16> %124 to <4 x i32>
  %126 = shufflevector <4 x i64> %113, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %127 = shufflevector <8 x i32> %111, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %128 = bitcast <2 x i64> %126 to <4 x i32>
  %129 = add <4 x i32> %127, %128
  %130 = shufflevector <4 x i32> %129, <4 x i32> %125, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %131 = shufflevector <4 x i32> %129, <4 x i32> %125, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %132 = add <4 x i32> %131, %130
  %133 = bitcast <4 x i32> %132 to <16 x i8>
  %134 = shufflevector <16 x i8> %133, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %135 = bitcast <16 x i8> %134 to <4 x i32>
  %136 = add <4 x i32> %132, %135
  %137 = extractelement <4 x i32> %136, i32 0
  store i32 %137, i32* %4, align 4
  %138 = extractelement <4 x i32> %136, i64 1
  %139 = sext i32 %138 to i64
  %140 = mul nsw i64 %139, %139
  %141 = lshr i64 %140, 7
  %142 = trunc i64 %141 to i32
  %143 = sub i32 %137, %142
  ret i32 %143
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_variance16x16_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  %8 = shl nsw i32 %1, 1
  %9 = sext i32 %8 to i64
  %10 = shl nsw i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = bitcast i8* %0 to <2 x i64>*
  %13 = load <2 x i64>, <2 x i64>* %12, align 1
  %14 = getelementptr inbounds i8, i8* %0, i64 %6
  %15 = bitcast i8* %14 to <2 x i64>*
  %16 = load <2 x i64>, <2 x i64>* %15, align 1
  %17 = bitcast i8* %2 to <2 x i64>*
  %18 = load <2 x i64>, <2 x i64>* %17, align 1
  %19 = getelementptr inbounds i8, i8* %2, i64 %7
  %20 = bitcast i8* %19 to <2 x i64>*
  %21 = load <2 x i64>, <2 x i64>* %20, align 1
  %22 = shufflevector <2 x i64> %13, <2 x i64> %16, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %23 = shufflevector <2 x i64> %18, <2 x i64> %21, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %24 = bitcast <4 x i64> %22 to <32 x i8>
  %25 = bitcast <4 x i64> %23 to <32 x i8>
  %26 = shufflevector <32 x i8> %24, <32 x i8> %25, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %27 = shufflevector <32 x i8> %24, <32 x i8> %25, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %28 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %26, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %29 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %27, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %30 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %28, <16 x i16> %28) #5
  %31 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %29, <16 x i16> %29) #5
  %32 = add <16 x i16> %28, %29
  %33 = add <8 x i32> %30, %31
  %34 = getelementptr inbounds i8, i8* %0, i64 %9
  %35 = getelementptr inbounds i8, i8* %2, i64 %11
  %36 = bitcast i8* %34 to <2 x i64>*
  %37 = load <2 x i64>, <2 x i64>* %36, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 %6
  %39 = bitcast i8* %38 to <2 x i64>*
  %40 = load <2 x i64>, <2 x i64>* %39, align 1
  %41 = bitcast i8* %35 to <2 x i64>*
  %42 = load <2 x i64>, <2 x i64>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %35, i64 %7
  %44 = bitcast i8* %43 to <2 x i64>*
  %45 = load <2 x i64>, <2 x i64>* %44, align 1
  %46 = shufflevector <2 x i64> %37, <2 x i64> %40, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = shufflevector <2 x i64> %42, <2 x i64> %45, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = bitcast <4 x i64> %46 to <32 x i8>
  %49 = bitcast <4 x i64> %47 to <32 x i8>
  %50 = shufflevector <32 x i8> %48, <32 x i8> %49, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %51 = shufflevector <32 x i8> %48, <32 x i8> %49, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %52 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %50, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %53 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %51, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %54 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %52, <16 x i16> %52) #5
  %55 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %53, <16 x i16> %53) #5
  %56 = add <16 x i16> %52, %32
  %57 = add <16 x i16> %56, %53
  %58 = add <8 x i32> %54, %33
  %59 = add <8 x i32> %58, %55
  %60 = getelementptr inbounds i8, i8* %34, i64 %9
  %61 = getelementptr inbounds i8, i8* %35, i64 %11
  %62 = bitcast i8* %60 to <2 x i64>*
  %63 = load <2 x i64>, <2 x i64>* %62, align 1
  %64 = getelementptr inbounds i8, i8* %60, i64 %6
  %65 = bitcast i8* %64 to <2 x i64>*
  %66 = load <2 x i64>, <2 x i64>* %65, align 1
  %67 = bitcast i8* %61 to <2 x i64>*
  %68 = load <2 x i64>, <2 x i64>* %67, align 1
  %69 = getelementptr inbounds i8, i8* %61, i64 %7
  %70 = bitcast i8* %69 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 1
  %72 = shufflevector <2 x i64> %63, <2 x i64> %66, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %73 = shufflevector <2 x i64> %68, <2 x i64> %71, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %74 = bitcast <4 x i64> %72 to <32 x i8>
  %75 = bitcast <4 x i64> %73 to <32 x i8>
  %76 = shufflevector <32 x i8> %74, <32 x i8> %75, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %77 = shufflevector <32 x i8> %74, <32 x i8> %75, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %78 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %76, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %79 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %77, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %80 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %78, <16 x i16> %78) #5
  %81 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %79, <16 x i16> %79) #5
  %82 = add <16 x i16> %78, %57
  %83 = add <16 x i16> %82, %79
  %84 = add <8 x i32> %80, %59
  %85 = add <8 x i32> %84, %81
  %86 = getelementptr inbounds i8, i8* %60, i64 %9
  %87 = getelementptr inbounds i8, i8* %61, i64 %11
  %88 = bitcast i8* %86 to <2 x i64>*
  %89 = load <2 x i64>, <2 x i64>* %88, align 1
  %90 = getelementptr inbounds i8, i8* %86, i64 %6
  %91 = bitcast i8* %90 to <2 x i64>*
  %92 = load <2 x i64>, <2 x i64>* %91, align 1
  %93 = bitcast i8* %87 to <2 x i64>*
  %94 = load <2 x i64>, <2 x i64>* %93, align 1
  %95 = getelementptr inbounds i8, i8* %87, i64 %7
  %96 = bitcast i8* %95 to <2 x i64>*
  %97 = load <2 x i64>, <2 x i64>* %96, align 1
  %98 = shufflevector <2 x i64> %89, <2 x i64> %92, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %99 = shufflevector <2 x i64> %94, <2 x i64> %97, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %100 = bitcast <4 x i64> %98 to <32 x i8>
  %101 = bitcast <4 x i64> %99 to <32 x i8>
  %102 = shufflevector <32 x i8> %100, <32 x i8> %101, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %103 = shufflevector <32 x i8> %100, <32 x i8> %101, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %104 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %102, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %105 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %103, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %106 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %104, <16 x i16> %104) #5
  %107 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %105, <16 x i16> %105) #5
  %108 = add <16 x i16> %104, %83
  %109 = add <16 x i16> %108, %105
  %110 = add <8 x i32> %106, %85
  %111 = add <8 x i32> %110, %107
  %112 = getelementptr inbounds i8, i8* %86, i64 %9
  %113 = getelementptr inbounds i8, i8* %87, i64 %11
  %114 = bitcast i8* %112 to <2 x i64>*
  %115 = load <2 x i64>, <2 x i64>* %114, align 1
  %116 = getelementptr inbounds i8, i8* %112, i64 %6
  %117 = bitcast i8* %116 to <2 x i64>*
  %118 = load <2 x i64>, <2 x i64>* %117, align 1
  %119 = bitcast i8* %113 to <2 x i64>*
  %120 = load <2 x i64>, <2 x i64>* %119, align 1
  %121 = getelementptr inbounds i8, i8* %113, i64 %7
  %122 = bitcast i8* %121 to <2 x i64>*
  %123 = load <2 x i64>, <2 x i64>* %122, align 1
  %124 = shufflevector <2 x i64> %115, <2 x i64> %118, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %125 = shufflevector <2 x i64> %120, <2 x i64> %123, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %126 = bitcast <4 x i64> %124 to <32 x i8>
  %127 = bitcast <4 x i64> %125 to <32 x i8>
  %128 = shufflevector <32 x i8> %126, <32 x i8> %127, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %129 = shufflevector <32 x i8> %126, <32 x i8> %127, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %130 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %128, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %131 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %129, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %132 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %130, <16 x i16> %130) #5
  %133 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %131, <16 x i16> %131) #5
  %134 = add <16 x i16> %130, %109
  %135 = add <16 x i16> %134, %131
  %136 = add <8 x i32> %132, %111
  %137 = add <8 x i32> %136, %133
  %138 = getelementptr inbounds i8, i8* %112, i64 %9
  %139 = getelementptr inbounds i8, i8* %113, i64 %11
  %140 = bitcast i8* %138 to <2 x i64>*
  %141 = load <2 x i64>, <2 x i64>* %140, align 1
  %142 = getelementptr inbounds i8, i8* %138, i64 %6
  %143 = bitcast i8* %142 to <2 x i64>*
  %144 = load <2 x i64>, <2 x i64>* %143, align 1
  %145 = bitcast i8* %139 to <2 x i64>*
  %146 = load <2 x i64>, <2 x i64>* %145, align 1
  %147 = getelementptr inbounds i8, i8* %139, i64 %7
  %148 = bitcast i8* %147 to <2 x i64>*
  %149 = load <2 x i64>, <2 x i64>* %148, align 1
  %150 = shufflevector <2 x i64> %141, <2 x i64> %144, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %151 = shufflevector <2 x i64> %146, <2 x i64> %149, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %152 = bitcast <4 x i64> %150 to <32 x i8>
  %153 = bitcast <4 x i64> %151 to <32 x i8>
  %154 = shufflevector <32 x i8> %152, <32 x i8> %153, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %155 = shufflevector <32 x i8> %152, <32 x i8> %153, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %156 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %154, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %157 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %155, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %158 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %156, <16 x i16> %156) #5
  %159 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %157, <16 x i16> %157) #5
  %160 = add <16 x i16> %156, %135
  %161 = add <16 x i16> %160, %157
  %162 = add <8 x i32> %158, %137
  %163 = add <8 x i32> %162, %159
  %164 = getelementptr inbounds i8, i8* %138, i64 %9
  %165 = getelementptr inbounds i8, i8* %139, i64 %11
  %166 = bitcast i8* %164 to <2 x i64>*
  %167 = load <2 x i64>, <2 x i64>* %166, align 1
  %168 = getelementptr inbounds i8, i8* %164, i64 %6
  %169 = bitcast i8* %168 to <2 x i64>*
  %170 = load <2 x i64>, <2 x i64>* %169, align 1
  %171 = bitcast i8* %165 to <2 x i64>*
  %172 = load <2 x i64>, <2 x i64>* %171, align 1
  %173 = getelementptr inbounds i8, i8* %165, i64 %7
  %174 = bitcast i8* %173 to <2 x i64>*
  %175 = load <2 x i64>, <2 x i64>* %174, align 1
  %176 = shufflevector <2 x i64> %167, <2 x i64> %170, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %177 = shufflevector <2 x i64> %172, <2 x i64> %175, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %178 = bitcast <4 x i64> %176 to <32 x i8>
  %179 = bitcast <4 x i64> %177 to <32 x i8>
  %180 = shufflevector <32 x i8> %178, <32 x i8> %179, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %181 = shufflevector <32 x i8> %178, <32 x i8> %179, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %182 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %180, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %183 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %181, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %184 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %182, <16 x i16> %182) #5
  %185 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %183, <16 x i16> %183) #5
  %186 = add <16 x i16> %182, %161
  %187 = add <16 x i16> %186, %183
  %188 = add <8 x i32> %184, %163
  %189 = add <8 x i32> %188, %185
  %190 = getelementptr inbounds i8, i8* %164, i64 %9
  %191 = getelementptr inbounds i8, i8* %165, i64 %11
  %192 = bitcast i8* %190 to <2 x i64>*
  %193 = load <2 x i64>, <2 x i64>* %192, align 1
  %194 = getelementptr inbounds i8, i8* %190, i64 %6
  %195 = bitcast i8* %194 to <2 x i64>*
  %196 = load <2 x i64>, <2 x i64>* %195, align 1
  %197 = bitcast i8* %191 to <2 x i64>*
  %198 = load <2 x i64>, <2 x i64>* %197, align 1
  %199 = getelementptr inbounds i8, i8* %191, i64 %7
  %200 = bitcast i8* %199 to <2 x i64>*
  %201 = load <2 x i64>, <2 x i64>* %200, align 1
  %202 = shufflevector <2 x i64> %193, <2 x i64> %196, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = shufflevector <2 x i64> %198, <2 x i64> %201, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %204 = bitcast <4 x i64> %202 to <32 x i8>
  %205 = bitcast <4 x i64> %203 to <32 x i8>
  %206 = shufflevector <32 x i8> %204, <32 x i8> %205, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %207 = shufflevector <32 x i8> %204, <32 x i8> %205, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %208 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %206, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %209 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %207, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %210 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %208, <16 x i16> %208) #5
  %211 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %209, <16 x i16> %209) #5
  %212 = add <16 x i16> %208, %187
  %213 = add <16 x i16> %212, %209
  %214 = add <8 x i32> %210, %189
  %215 = add <8 x i32> %214, %211
  %216 = bitcast <16 x i16> %213 to <4 x i64>
  %217 = bitcast <8 x i32> %215 to <4 x i64>
  %218 = shufflevector <4 x i64> %216, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %219 = bitcast <16 x i16> %213 to <8 x i32>
  %220 = shufflevector <8 x i32> %219, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %221 = bitcast <2 x i64> %218 to <8 x i16>
  %222 = bitcast <4 x i32> %220 to <8 x i16>
  %223 = add <8 x i16> %222, %221
  %224 = bitcast <8 x i16> %223 to <16 x i8>
  %225 = shufflevector <16 x i8> %224, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %226 = bitcast <16 x i8> %225 to <8 x i16>
  %227 = add <8 x i16> %223, %226
  %228 = shufflevector <8 x i16> %227, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %229 = sext <4 x i16> %228 to <4 x i32>
  %230 = shufflevector <4 x i64> %217, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %231 = shufflevector <8 x i32> %215, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %232 = bitcast <2 x i64> %230 to <4 x i32>
  %233 = add <4 x i32> %231, %232
  %234 = shufflevector <4 x i32> %233, <4 x i32> %229, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %235 = shufflevector <4 x i32> %233, <4 x i32> %229, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %236 = add <4 x i32> %235, %234
  %237 = bitcast <4 x i32> %236 to <16 x i8>
  %238 = shufflevector <16 x i8> %237, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %239 = bitcast <16 x i8> %238 to <4 x i32>
  %240 = add <4 x i32> %236, %239
  %241 = extractelement <4 x i32> %240, i32 0
  store i32 %241, i32* %4, align 4
  %242 = extractelement <4 x i32> %240, i64 1
  %243 = sext i32 %242 to i64
  %244 = mul nsw i64 %243, %243
  %245 = lshr i64 %244, 8
  %246 = trunc i64 %245 to i32
  %247 = sub i32 %241, %246
  ret i32 %247
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_variance16x32_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  %8 = shl nsw i32 %1, 1
  %9 = sext i32 %8 to i64
  %10 = shl nsw i32 %3, 1
  %11 = sext i32 %10 to i64
  br label %12

12:                                               ; preds = %12, %5
  %13 = phi <8 x i32> [ zeroinitializer, %5 ], [ %41, %12 ]
  %14 = phi <16 x i16> [ zeroinitializer, %5 ], [ %39, %12 ]
  %15 = phi i32 [ 0, %5 ], [ %44, %12 ]
  %16 = phi i8* [ %0, %5 ], [ %42, %12 ]
  %17 = phi i8* [ %2, %5 ], [ %43, %12 ]
  %18 = bitcast i8* %16 to <2 x i64>*
  %19 = load <2 x i64>, <2 x i64>* %18, align 1
  %20 = getelementptr inbounds i8, i8* %16, i64 %6
  %21 = bitcast i8* %20 to <2 x i64>*
  %22 = load <2 x i64>, <2 x i64>* %21, align 1
  %23 = bitcast i8* %17 to <2 x i64>*
  %24 = load <2 x i64>, <2 x i64>* %23, align 1
  %25 = getelementptr inbounds i8, i8* %17, i64 %7
  %26 = bitcast i8* %25 to <2 x i64>*
  %27 = load <2 x i64>, <2 x i64>* %26, align 1
  %28 = shufflevector <2 x i64> %19, <2 x i64> %22, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %29 = shufflevector <2 x i64> %24, <2 x i64> %27, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %30 = bitcast <4 x i64> %28 to <32 x i8>
  %31 = bitcast <4 x i64> %29 to <32 x i8>
  %32 = shufflevector <32 x i8> %30, <32 x i8> %31, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %33 = shufflevector <32 x i8> %30, <32 x i8> %31, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %34 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %32, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %35 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %33, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %36 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %34, <16 x i16> %34) #5
  %37 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %35, <16 x i16> %35) #5
  %38 = add <16 x i16> %34, %14
  %39 = add <16 x i16> %38, %35
  %40 = add <8 x i32> %36, %13
  %41 = add <8 x i32> %40, %37
  %42 = getelementptr inbounds i8, i8* %16, i64 %9
  %43 = getelementptr inbounds i8, i8* %17, i64 %11
  %44 = add nuw nsw i32 %15, 2
  %45 = icmp ult i32 %44, 32
  br i1 %45, label %12, label %46

46:                                               ; preds = %12
  %47 = bitcast <16 x i16> %39 to <4 x i64>
  %48 = bitcast <8 x i32> %41 to <4 x i64>
  %49 = shufflevector <4 x i64> %47, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %50 = bitcast <16 x i16> %39 to <8 x i32>
  %51 = shufflevector <8 x i32> %50, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %52 = bitcast <2 x i64> %49 to <8 x i16>
  %53 = bitcast <4 x i32> %51 to <8 x i16>
  %54 = add <8 x i16> %53, %52
  %55 = bitcast <8 x i16> %54 to <16 x i8>
  %56 = shufflevector <16 x i8> %55, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %57 = bitcast <16 x i8> %56 to <8 x i16>
  %58 = add <8 x i16> %54, %57
  %59 = shufflevector <8 x i16> %58, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %60 = sext <4 x i16> %59 to <4 x i32>
  %61 = shufflevector <4 x i64> %48, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %62 = shufflevector <8 x i32> %41, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %63 = bitcast <2 x i64> %61 to <4 x i32>
  %64 = add <4 x i32> %62, %63
  %65 = shufflevector <4 x i32> %64, <4 x i32> %60, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %66 = shufflevector <4 x i32> %64, <4 x i32> %60, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %67 = add <4 x i32> %66, %65
  %68 = bitcast <4 x i32> %67 to <16 x i8>
  %69 = shufflevector <16 x i8> %68, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %70 = bitcast <16 x i8> %69 to <4 x i32>
  %71 = add <4 x i32> %67, %70
  %72 = extractelement <4 x i32> %71, i32 0
  store i32 %72, i32* %4, align 4
  %73 = extractelement <4 x i32> %71, i64 1
  %74 = sext i32 %73 to i64
  %75 = mul nsw i64 %74, %74
  %76 = lshr i64 %75, 9
  %77 = trunc i64 %76 to i32
  %78 = sub i32 %72, %77
  ret i32 %78
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_variance32x16_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  br label %8

8:                                                ; preds = %8, %5
  %9 = phi <8 x i32> [ zeroinitializer, %5 ], [ %43, %8 ]
  %10 = phi <16 x i16> [ zeroinitializer, %5 ], [ %41, %8 ]
  %11 = phi i32 [ 0, %5 ], [ %46, %8 ]
  %12 = phi i8* [ %0, %5 ], [ %44, %8 ]
  %13 = phi i8* [ %2, %5 ], [ %45, %8 ]
  %14 = bitcast i8* %12 to <32 x i8>*
  %15 = load <32 x i8>, <32 x i8>* %14, align 1
  %16 = bitcast i8* %13 to <32 x i8>*
  %17 = load <32 x i8>, <32 x i8>* %16, align 1
  %18 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %19 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %20 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %18, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %21 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %19, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %22 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %20, <16 x i16> %20) #5
  %23 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %21, <16 x i16> %21) #5
  %24 = add <16 x i16> %20, %10
  %25 = add <16 x i16> %24, %21
  %26 = add <8 x i32> %22, %9
  %27 = add <8 x i32> %26, %23
  %28 = getelementptr inbounds i8, i8* %12, i64 %6
  %29 = getelementptr inbounds i8, i8* %13, i64 %7
  %30 = bitcast i8* %28 to <32 x i8>*
  %31 = load <32 x i8>, <32 x i8>* %30, align 1
  %32 = bitcast i8* %29 to <32 x i8>*
  %33 = load <32 x i8>, <32 x i8>* %32, align 1
  %34 = shufflevector <32 x i8> %31, <32 x i8> %33, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %35 = shufflevector <32 x i8> %31, <32 x i8> %33, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %36 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %34, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %37 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %35, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %38 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %36, <16 x i16> %36) #5
  %39 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %37, <16 x i16> %37) #5
  %40 = add <16 x i16> %36, %25
  %41 = add <16 x i16> %40, %37
  %42 = add <8 x i32> %38, %27
  %43 = add <8 x i32> %42, %39
  %44 = getelementptr inbounds i8, i8* %28, i64 %6
  %45 = getelementptr inbounds i8, i8* %29, i64 %7
  %46 = add nuw nsw i32 %11, 2
  %47 = icmp eq i32 %46, 16
  br i1 %47, label %48, label %8

48:                                               ; preds = %8
  %49 = bitcast <16 x i16> %41 to <4 x i64>
  %50 = bitcast <8 x i32> %43 to <4 x i64>
  %51 = shufflevector <4 x i64> %49, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %52 = bitcast <16 x i16> %41 to <8 x i32>
  %53 = shufflevector <8 x i32> %52, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %54 = bitcast <2 x i64> %51 to <8 x i16>
  %55 = bitcast <4 x i32> %53 to <8 x i16>
  %56 = add <8 x i16> %55, %54
  %57 = bitcast <8 x i16> %56 to <16 x i8>
  %58 = shufflevector <16 x i8> %57, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %59 = bitcast <16 x i8> %58 to <8 x i16>
  %60 = add <8 x i16> %56, %59
  %61 = shufflevector <8 x i16> %60, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %62 = sext <4 x i16> %61 to <4 x i32>
  %63 = shufflevector <4 x i64> %50, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %64 = shufflevector <8 x i32> %43, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %65 = bitcast <2 x i64> %63 to <4 x i32>
  %66 = add <4 x i32> %64, %65
  %67 = shufflevector <4 x i32> %66, <4 x i32> %62, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %68 = shufflevector <4 x i32> %66, <4 x i32> %62, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %69 = add <4 x i32> %68, %67
  %70 = bitcast <4 x i32> %69 to <16 x i8>
  %71 = shufflevector <16 x i8> %70, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %72 = bitcast <16 x i8> %71 to <4 x i32>
  %73 = add <4 x i32> %69, %72
  %74 = extractelement <4 x i32> %73, i32 0
  store i32 %74, i32* %4, align 4
  %75 = extractelement <4 x i32> %73, i64 1
  %76 = sext i32 %75 to i64
  %77 = mul nsw i64 %76, %76
  %78 = lshr i64 %77, 9
  %79 = trunc i64 %78 to i32
  %80 = sub i32 %74, %79
  ret i32 %80
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_variance32x32_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  br label %8

8:                                                ; preds = %8, %5
  %9 = phi <8 x i32> [ zeroinitializer, %5 ], [ %43, %8 ]
  %10 = phi <16 x i16> [ zeroinitializer, %5 ], [ %41, %8 ]
  %11 = phi i32 [ 0, %5 ], [ %46, %8 ]
  %12 = phi i8* [ %0, %5 ], [ %44, %8 ]
  %13 = phi i8* [ %2, %5 ], [ %45, %8 ]
  %14 = bitcast i8* %12 to <32 x i8>*
  %15 = load <32 x i8>, <32 x i8>* %14, align 1
  %16 = bitcast i8* %13 to <32 x i8>*
  %17 = load <32 x i8>, <32 x i8>* %16, align 1
  %18 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %19 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %20 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %18, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %21 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %19, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %22 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %20, <16 x i16> %20) #5
  %23 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %21, <16 x i16> %21) #5
  %24 = add <16 x i16> %20, %10
  %25 = add <16 x i16> %24, %21
  %26 = add <8 x i32> %22, %9
  %27 = add <8 x i32> %26, %23
  %28 = getelementptr inbounds i8, i8* %12, i64 %6
  %29 = getelementptr inbounds i8, i8* %13, i64 %7
  %30 = bitcast i8* %28 to <32 x i8>*
  %31 = load <32 x i8>, <32 x i8>* %30, align 1
  %32 = bitcast i8* %29 to <32 x i8>*
  %33 = load <32 x i8>, <32 x i8>* %32, align 1
  %34 = shufflevector <32 x i8> %31, <32 x i8> %33, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %35 = shufflevector <32 x i8> %31, <32 x i8> %33, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %36 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %34, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %37 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %35, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %38 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %36, <16 x i16> %36) #5
  %39 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %37, <16 x i16> %37) #5
  %40 = add <16 x i16> %36, %25
  %41 = add <16 x i16> %40, %37
  %42 = add <8 x i32> %38, %27
  %43 = add <8 x i32> %42, %39
  %44 = getelementptr inbounds i8, i8* %28, i64 %6
  %45 = getelementptr inbounds i8, i8* %29, i64 %7
  %46 = add nuw nsw i32 %11, 2
  %47 = icmp eq i32 %46, 32
  br i1 %47, label %48, label %8

48:                                               ; preds = %8
  %49 = bitcast <16 x i16> %41 to <4 x i64>
  %50 = bitcast <8 x i32> %43 to <4 x i64>
  %51 = shufflevector <4 x i64> %49, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %52 = bitcast <16 x i16> %41 to <8 x i32>
  %53 = shufflevector <8 x i32> %52, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %54 = bitcast <2 x i64> %51 to <8 x i16>
  %55 = bitcast <4 x i32> %53 to <8 x i16>
  %56 = add <8 x i16> %55, %54
  %57 = shufflevector <8 x i16> %56, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %58 = sext <4 x i16> %57 to <4 x i32>
  %59 = bitcast <8 x i16> %56 to <16 x i8>
  %60 = shufflevector <16 x i8> %59, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %61 = bitcast <16 x i8> %60 to <8 x i16>
  %62 = shufflevector <8 x i16> %61, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %63 = sext <4 x i16> %62 to <4 x i32>
  %64 = add nsw <4 x i32> %63, %58
  %65 = shufflevector <4 x i64> %50, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %66 = shufflevector <8 x i32> %43, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %67 = bitcast <2 x i64> %65 to <4 x i32>
  %68 = add <4 x i32> %66, %67
  %69 = shufflevector <4 x i32> %68, <4 x i32> %64, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %70 = shufflevector <4 x i32> %68, <4 x i32> %64, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %71 = add <4 x i32> %70, %69
  %72 = bitcast <4 x i32> %71 to <16 x i8>
  %73 = shufflevector <16 x i8> %72, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %74 = bitcast <16 x i8> %73 to <4 x i32>
  %75 = add <4 x i32> %71, %74
  %76 = extractelement <4 x i32> %75, i32 0
  store i32 %76, i32* %4, align 4
  %77 = extractelement <4 x i32> %75, i64 1
  %78 = sext i32 %77 to i64
  %79 = mul nsw i64 %78, %78
  %80 = lshr i64 %79, 10
  %81 = trunc i64 %80 to i32
  %82 = sub i32 %76, %81
  ret i32 %82
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_variance32x64_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  br label %8

8:                                                ; preds = %8, %5
  %9 = phi <8 x i32> [ zeroinitializer, %5 ], [ %43, %8 ]
  %10 = phi <16 x i16> [ zeroinitializer, %5 ], [ %41, %8 ]
  %11 = phi i32 [ 0, %5 ], [ %46, %8 ]
  %12 = phi i8* [ %0, %5 ], [ %44, %8 ]
  %13 = phi i8* [ %2, %5 ], [ %45, %8 ]
  %14 = bitcast i8* %12 to <32 x i8>*
  %15 = load <32 x i8>, <32 x i8>* %14, align 1
  %16 = bitcast i8* %13 to <32 x i8>*
  %17 = load <32 x i8>, <32 x i8>* %16, align 1
  %18 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %19 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %20 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %18, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %21 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %19, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %22 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %20, <16 x i16> %20) #5
  %23 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %21, <16 x i16> %21) #5
  %24 = add <16 x i16> %20, %10
  %25 = add <16 x i16> %24, %21
  %26 = add <8 x i32> %22, %9
  %27 = add <8 x i32> %26, %23
  %28 = getelementptr inbounds i8, i8* %12, i64 %6
  %29 = getelementptr inbounds i8, i8* %13, i64 %7
  %30 = bitcast i8* %28 to <32 x i8>*
  %31 = load <32 x i8>, <32 x i8>* %30, align 1
  %32 = bitcast i8* %29 to <32 x i8>*
  %33 = load <32 x i8>, <32 x i8>* %32, align 1
  %34 = shufflevector <32 x i8> %31, <32 x i8> %33, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %35 = shufflevector <32 x i8> %31, <32 x i8> %33, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %36 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %34, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %37 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %35, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %38 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %36, <16 x i16> %36) #5
  %39 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %37, <16 x i16> %37) #5
  %40 = add <16 x i16> %36, %25
  %41 = add <16 x i16> %40, %37
  %42 = add <8 x i32> %38, %27
  %43 = add <8 x i32> %42, %39
  %44 = getelementptr inbounds i8, i8* %28, i64 %6
  %45 = getelementptr inbounds i8, i8* %29, i64 %7
  %46 = add nuw nsw i32 %11, 2
  %47 = icmp eq i32 %46, 64
  br i1 %47, label %48, label %8

48:                                               ; preds = %8
  %49 = bitcast <16 x i16> %41 to <4 x i64>
  %50 = bitcast <8 x i32> %43 to <4 x i64>
  %51 = shufflevector <4 x i64> %49, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %52 = bitcast <2 x i64> %51 to <8 x i16>
  %53 = sext <8 x i16> %52 to <8 x i32>
  %54 = bitcast <16 x i16> %41 to <8 x i32>
  %55 = shufflevector <8 x i32> %54, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %56 = bitcast <4 x i32> %55 to <8 x i16>
  %57 = sext <8 x i16> %56 to <8 x i32>
  %58 = add nsw <8 x i32> %57, %53
  %59 = bitcast <8 x i32> %58 to <4 x i64>
  %60 = shufflevector <4 x i64> %59, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %61 = shufflevector <8 x i32> %58, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %62 = bitcast <2 x i64> %60 to <4 x i32>
  %63 = add <4 x i32> %61, %62
  %64 = shufflevector <4 x i64> %50, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %65 = shufflevector <8 x i32> %43, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %66 = bitcast <2 x i64> %64 to <4 x i32>
  %67 = add <4 x i32> %65, %66
  %68 = shufflevector <4 x i32> %67, <4 x i32> %63, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %69 = shufflevector <4 x i32> %67, <4 x i32> %63, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %70 = add <4 x i32> %69, %68
  %71 = bitcast <4 x i32> %70 to <16 x i8>
  %72 = shufflevector <16 x i8> %71, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %73 = bitcast <16 x i8> %72 to <4 x i32>
  %74 = add <4 x i32> %70, %73
  %75 = extractelement <4 x i32> %74, i32 0
  store i32 %75, i32* %4, align 4
  %76 = extractelement <4 x i32> %74, i64 1
  %77 = sext i32 %76 to i64
  %78 = mul nsw i64 %77, %77
  %79 = lshr i64 %78, 11
  %80 = trunc i64 %79 to i32
  %81 = sub i32 %75, %80
  ret i32 %81
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_variance64x32_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  br label %8

8:                                                ; preds = %46, %5
  %9 = phi <8 x i32> [ zeroinitializer, %5 ], [ %43, %46 ]
  %10 = phi <16 x i16> [ zeroinitializer, %5 ], [ %39, %46 ]
  %11 = phi i32 [ 0, %5 ], [ %44, %46 ]
  %12 = phi i8* [ %0, %5 ], [ %48, %46 ]
  %13 = phi i8* [ %2, %5 ], [ %47, %46 ]
  %14 = bitcast i8* %12 to <32 x i8>*
  %15 = load <32 x i8>, <32 x i8>* %14, align 1
  %16 = bitcast i8* %13 to <32 x i8>*
  %17 = load <32 x i8>, <32 x i8>* %16, align 1
  %18 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %19 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %20 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %18, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %21 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %19, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %22 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %20, <16 x i16> %20) #5
  %23 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %21, <16 x i16> %21) #5
  %24 = getelementptr inbounds i8, i8* %12, i64 32
  %25 = getelementptr inbounds i8, i8* %13, i64 32
  %26 = bitcast i8* %24 to <32 x i8>*
  %27 = load <32 x i8>, <32 x i8>* %26, align 1
  %28 = bitcast i8* %25 to <32 x i8>*
  %29 = load <32 x i8>, <32 x i8>* %28, align 1
  %30 = shufflevector <32 x i8> %27, <32 x i8> %29, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %31 = shufflevector <32 x i8> %27, <32 x i8> %29, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %32 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %30, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %33 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %31, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %34 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %32, <16 x i16> %32) #5
  %35 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %33, <16 x i16> %33) #5
  %36 = add <16 x i16> %20, %10
  %37 = add <16 x i16> %36, %21
  %38 = add <16 x i16> %37, %32
  %39 = add <16 x i16> %38, %33
  %40 = add <8 x i32> %22, %9
  %41 = add <8 x i32> %40, %23
  %42 = add <8 x i32> %41, %34
  %43 = add <8 x i32> %42, %35
  %44 = add nuw nsw i32 %11, 1
  %45 = icmp eq i32 %44, 32
  br i1 %45, label %49, label %46

46:                                               ; preds = %8
  %47 = getelementptr inbounds i8, i8* %13, i64 %7
  %48 = getelementptr inbounds i8, i8* %12, i64 %6
  br label %8

49:                                               ; preds = %8
  %50 = bitcast <16 x i16> %39 to <4 x i64>
  %51 = bitcast <8 x i32> %43 to <4 x i64>
  %52 = shufflevector <4 x i64> %50, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %53 = bitcast <2 x i64> %52 to <8 x i16>
  %54 = sext <8 x i16> %53 to <8 x i32>
  %55 = bitcast <16 x i16> %39 to <8 x i32>
  %56 = shufflevector <8 x i32> %55, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %57 = bitcast <4 x i32> %56 to <8 x i16>
  %58 = sext <8 x i16> %57 to <8 x i32>
  %59 = add nsw <8 x i32> %58, %54
  %60 = bitcast <8 x i32> %59 to <4 x i64>
  %61 = shufflevector <4 x i64> %60, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %62 = shufflevector <8 x i32> %59, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %63 = bitcast <2 x i64> %61 to <4 x i32>
  %64 = add <4 x i32> %62, %63
  %65 = shufflevector <4 x i64> %51, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %66 = shufflevector <8 x i32> %43, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %67 = bitcast <2 x i64> %65 to <4 x i32>
  %68 = add <4 x i32> %66, %67
  %69 = shufflevector <4 x i32> %68, <4 x i32> %64, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %70 = shufflevector <4 x i32> %68, <4 x i32> %64, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %71 = add <4 x i32> %70, %69
  %72 = bitcast <4 x i32> %71 to <16 x i8>
  %73 = shufflevector <16 x i8> %72, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %74 = bitcast <16 x i8> %73 to <4 x i32>
  %75 = add <4 x i32> %71, %74
  %76 = extractelement <4 x i32> %75, i32 0
  store i32 %76, i32* %4, align 4
  %77 = extractelement <4 x i32> %75, i64 1
  %78 = sext i32 %77 to i64
  %79 = mul nsw i64 %78, %78
  %80 = lshr i64 %79, 11
  %81 = trunc i64 %80 to i32
  %82 = sub i32 %76, %81
  ret i32 %82
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_variance64x64_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  br label %8

8:                                                ; preds = %46, %5
  %9 = phi <8 x i32> [ zeroinitializer, %5 ], [ %43, %46 ]
  %10 = phi <16 x i16> [ zeroinitializer, %5 ], [ %39, %46 ]
  %11 = phi i32 [ 0, %5 ], [ %44, %46 ]
  %12 = phi i8* [ %0, %5 ], [ %48, %46 ]
  %13 = phi i8* [ %2, %5 ], [ %47, %46 ]
  %14 = bitcast i8* %12 to <32 x i8>*
  %15 = load <32 x i8>, <32 x i8>* %14, align 1
  %16 = bitcast i8* %13 to <32 x i8>*
  %17 = load <32 x i8>, <32 x i8>* %16, align 1
  %18 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %19 = shufflevector <32 x i8> %15, <32 x i8> %17, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %20 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %18, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %21 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %19, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %22 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %20, <16 x i16> %20) #5
  %23 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %21, <16 x i16> %21) #5
  %24 = getelementptr inbounds i8, i8* %12, i64 32
  %25 = getelementptr inbounds i8, i8* %13, i64 32
  %26 = bitcast i8* %24 to <32 x i8>*
  %27 = load <32 x i8>, <32 x i8>* %26, align 1
  %28 = bitcast i8* %25 to <32 x i8>*
  %29 = load <32 x i8>, <32 x i8>* %28, align 1
  %30 = shufflevector <32 x i8> %27, <32 x i8> %29, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %31 = shufflevector <32 x i8> %27, <32 x i8> %29, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %32 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %30, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %33 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %31, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %34 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %32, <16 x i16> %32) #5
  %35 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %33, <16 x i16> %33) #5
  %36 = add <16 x i16> %20, %10
  %37 = add <16 x i16> %36, %21
  %38 = add <16 x i16> %37, %32
  %39 = add <16 x i16> %38, %33
  %40 = add <8 x i32> %22, %9
  %41 = add <8 x i32> %40, %23
  %42 = add <8 x i32> %41, %34
  %43 = add <8 x i32> %42, %35
  %44 = add nuw nsw i32 %11, 1
  %45 = icmp eq i32 %44, 32
  br i1 %45, label %49, label %46

46:                                               ; preds = %8
  %47 = getelementptr inbounds i8, i8* %13, i64 %7
  %48 = getelementptr inbounds i8, i8* %12, i64 %6
  br label %8

49:                                               ; preds = %8
  %50 = bitcast <16 x i16> %39 to <4 x i64>
  %51 = shufflevector <4 x i64> %50, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %52 = bitcast <2 x i64> %51 to <8 x i16>
  %53 = sext <8 x i16> %52 to <8 x i32>
  %54 = bitcast <16 x i16> %39 to <8 x i32>
  %55 = shufflevector <8 x i32> %54, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %56 = bitcast <4 x i32> %55 to <8 x i16>
  %57 = sext <8 x i16> %56 to <8 x i32>
  %58 = add nsw <8 x i32> %53, %57
  %59 = shl nsw i64 %6, 5
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = shl nsw i64 %7, 5
  %62 = getelementptr inbounds i8, i8* %2, i64 %61
  br label %63

63:                                               ; preds = %101, %49
  %64 = phi <8 x i32> [ %43, %49 ], [ %98, %101 ]
  %65 = phi <16 x i16> [ zeroinitializer, %49 ], [ %94, %101 ]
  %66 = phi i32 [ 0, %49 ], [ %99, %101 ]
  %67 = phi i8* [ %60, %49 ], [ %103, %101 ]
  %68 = phi i8* [ %62, %49 ], [ %102, %101 ]
  %69 = bitcast i8* %67 to <32 x i8>*
  %70 = load <32 x i8>, <32 x i8>* %69, align 1
  %71 = bitcast i8* %68 to <32 x i8>*
  %72 = load <32 x i8>, <32 x i8>* %71, align 1
  %73 = shufflevector <32 x i8> %70, <32 x i8> %72, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %74 = shufflevector <32 x i8> %70, <32 x i8> %72, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %75 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %73, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %76 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %74, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %77 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %75, <16 x i16> %75) #5
  %78 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %76, <16 x i16> %76) #5
  %79 = getelementptr inbounds i8, i8* %67, i64 32
  %80 = getelementptr inbounds i8, i8* %68, i64 32
  %81 = bitcast i8* %79 to <32 x i8>*
  %82 = load <32 x i8>, <32 x i8>* %81, align 1
  %83 = bitcast i8* %80 to <32 x i8>*
  %84 = load <32 x i8>, <32 x i8>* %83, align 1
  %85 = shufflevector <32 x i8> %82, <32 x i8> %84, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %86 = shufflevector <32 x i8> %82, <32 x i8> %84, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %87 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %85, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %88 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %86, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %89 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %87, <16 x i16> %87) #5
  %90 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %88, <16 x i16> %88) #5
  %91 = add <16 x i16> %75, %65
  %92 = add <16 x i16> %91, %76
  %93 = add <16 x i16> %92, %87
  %94 = add <16 x i16> %93, %88
  %95 = add <8 x i32> %77, %64
  %96 = add <8 x i32> %95, %78
  %97 = add <8 x i32> %96, %89
  %98 = add <8 x i32> %97, %90
  %99 = add nuw nsw i32 %66, 1
  %100 = icmp eq i32 %99, 32
  br i1 %100, label %104, label %101

101:                                              ; preds = %63
  %102 = getelementptr inbounds i8, i8* %68, i64 %7
  %103 = getelementptr inbounds i8, i8* %67, i64 %6
  br label %63

104:                                              ; preds = %63
  %105 = bitcast <16 x i16> %94 to <4 x i64>
  %106 = shufflevector <4 x i64> %105, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %107 = bitcast <2 x i64> %106 to <8 x i16>
  %108 = sext <8 x i16> %107 to <8 x i32>
  %109 = bitcast <16 x i16> %94 to <8 x i32>
  %110 = shufflevector <8 x i32> %109, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %111 = bitcast <4 x i32> %110 to <8 x i16>
  %112 = sext <8 x i16> %111 to <8 x i32>
  %113 = add nsw <8 x i32> %58, %108
  %114 = add nsw <8 x i32> %113, %112
  %115 = bitcast <8 x i32> %98 to <4 x i64>
  %116 = bitcast <8 x i32> %114 to <4 x i64>
  %117 = shufflevector <4 x i64> %116, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %118 = shufflevector <8 x i32> %114, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %119 = bitcast <2 x i64> %117 to <4 x i32>
  %120 = add <4 x i32> %118, %119
  %121 = shufflevector <4 x i64> %115, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %122 = shufflevector <8 x i32> %98, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %123 = bitcast <2 x i64> %121 to <4 x i32>
  %124 = add <4 x i32> %122, %123
  %125 = shufflevector <4 x i32> %124, <4 x i32> %120, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %126 = shufflevector <4 x i32> %124, <4 x i32> %120, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %127 = add <4 x i32> %126, %125
  %128 = bitcast <4 x i32> %127 to <16 x i8>
  %129 = shufflevector <16 x i8> %128, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %130 = bitcast <16 x i8> %129 to <4 x i32>
  %131 = add <4 x i32> %127, %130
  %132 = extractelement <4 x i32> %131, i32 0
  store i32 %132, i32* %4, align 4
  %133 = extractelement <4 x i32> %131, i64 1
  %134 = sext i32 %133 to i64
  %135 = mul nsw i64 %134, %134
  %136 = lshr i64 %135, 12
  %137 = trunc i64 %136 to i32
  %138 = sub i32 %132, %137
  ret i32 %138
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_mse16x8_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  %8 = shl nsw i32 %1, 1
  %9 = sext i32 %8 to i64
  %10 = shl nsw i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = bitcast i8* %0 to <2 x i64>*
  %13 = load <2 x i64>, <2 x i64>* %12, align 1
  %14 = getelementptr inbounds i8, i8* %0, i64 %6
  %15 = bitcast i8* %14 to <2 x i64>*
  %16 = load <2 x i64>, <2 x i64>* %15, align 1
  %17 = bitcast i8* %2 to <2 x i64>*
  %18 = load <2 x i64>, <2 x i64>* %17, align 1
  %19 = getelementptr inbounds i8, i8* %2, i64 %7
  %20 = bitcast i8* %19 to <2 x i64>*
  %21 = load <2 x i64>, <2 x i64>* %20, align 1
  %22 = shufflevector <2 x i64> %13, <2 x i64> %16, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %23 = shufflevector <2 x i64> %18, <2 x i64> %21, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %24 = bitcast <4 x i64> %22 to <32 x i8>
  %25 = bitcast <4 x i64> %23 to <32 x i8>
  %26 = shufflevector <32 x i8> %24, <32 x i8> %25, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %27 = shufflevector <32 x i8> %24, <32 x i8> %25, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %28 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %26, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %29 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %27, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %30 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %28, <16 x i16> %28) #5
  %31 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %29, <16 x i16> %29) #5
  %32 = add <16 x i16> %28, %29
  %33 = add <8 x i32> %30, %31
  %34 = getelementptr inbounds i8, i8* %0, i64 %9
  %35 = getelementptr inbounds i8, i8* %2, i64 %11
  %36 = bitcast i8* %34 to <2 x i64>*
  %37 = load <2 x i64>, <2 x i64>* %36, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 %6
  %39 = bitcast i8* %38 to <2 x i64>*
  %40 = load <2 x i64>, <2 x i64>* %39, align 1
  %41 = bitcast i8* %35 to <2 x i64>*
  %42 = load <2 x i64>, <2 x i64>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %35, i64 %7
  %44 = bitcast i8* %43 to <2 x i64>*
  %45 = load <2 x i64>, <2 x i64>* %44, align 1
  %46 = shufflevector <2 x i64> %37, <2 x i64> %40, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = shufflevector <2 x i64> %42, <2 x i64> %45, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = bitcast <4 x i64> %46 to <32 x i8>
  %49 = bitcast <4 x i64> %47 to <32 x i8>
  %50 = shufflevector <32 x i8> %48, <32 x i8> %49, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %51 = shufflevector <32 x i8> %48, <32 x i8> %49, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %52 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %50, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %53 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %51, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %54 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %52, <16 x i16> %52) #5
  %55 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %53, <16 x i16> %53) #5
  %56 = add <16 x i16> %52, %32
  %57 = add <16 x i16> %56, %53
  %58 = add <8 x i32> %54, %33
  %59 = add <8 x i32> %58, %55
  %60 = getelementptr inbounds i8, i8* %34, i64 %9
  %61 = getelementptr inbounds i8, i8* %35, i64 %11
  %62 = bitcast i8* %60 to <2 x i64>*
  %63 = load <2 x i64>, <2 x i64>* %62, align 1
  %64 = getelementptr inbounds i8, i8* %60, i64 %6
  %65 = bitcast i8* %64 to <2 x i64>*
  %66 = load <2 x i64>, <2 x i64>* %65, align 1
  %67 = bitcast i8* %61 to <2 x i64>*
  %68 = load <2 x i64>, <2 x i64>* %67, align 1
  %69 = getelementptr inbounds i8, i8* %61, i64 %7
  %70 = bitcast i8* %69 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 1
  %72 = shufflevector <2 x i64> %63, <2 x i64> %66, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %73 = shufflevector <2 x i64> %68, <2 x i64> %71, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %74 = bitcast <4 x i64> %72 to <32 x i8>
  %75 = bitcast <4 x i64> %73 to <32 x i8>
  %76 = shufflevector <32 x i8> %74, <32 x i8> %75, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %77 = shufflevector <32 x i8> %74, <32 x i8> %75, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %78 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %76, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %79 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %77, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %80 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %78, <16 x i16> %78) #5
  %81 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %79, <16 x i16> %79) #5
  %82 = add <16 x i16> %78, %57
  %83 = add <16 x i16> %82, %79
  %84 = add <8 x i32> %80, %59
  %85 = add <8 x i32> %84, %81
  %86 = getelementptr inbounds i8, i8* %60, i64 %9
  %87 = getelementptr inbounds i8, i8* %61, i64 %11
  %88 = bitcast i8* %86 to <2 x i64>*
  %89 = load <2 x i64>, <2 x i64>* %88, align 1
  %90 = getelementptr inbounds i8, i8* %86, i64 %6
  %91 = bitcast i8* %90 to <2 x i64>*
  %92 = load <2 x i64>, <2 x i64>* %91, align 1
  %93 = bitcast i8* %87 to <2 x i64>*
  %94 = load <2 x i64>, <2 x i64>* %93, align 1
  %95 = getelementptr inbounds i8, i8* %87, i64 %7
  %96 = bitcast i8* %95 to <2 x i64>*
  %97 = load <2 x i64>, <2 x i64>* %96, align 1
  %98 = shufflevector <2 x i64> %89, <2 x i64> %92, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %99 = shufflevector <2 x i64> %94, <2 x i64> %97, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %100 = bitcast <4 x i64> %98 to <32 x i8>
  %101 = bitcast <4 x i64> %99 to <32 x i8>
  %102 = shufflevector <32 x i8> %100, <32 x i8> %101, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %103 = shufflevector <32 x i8> %100, <32 x i8> %101, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %104 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %102, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %105 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %103, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %106 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %104, <16 x i16> %104) #5
  %107 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %105, <16 x i16> %105) #5
  %108 = add <16 x i16> %104, %83
  %109 = add <16 x i16> %108, %105
  %110 = add <8 x i32> %106, %85
  %111 = add <8 x i32> %110, %107
  %112 = bitcast <16 x i16> %109 to <4 x i64>
  %113 = bitcast <8 x i32> %111 to <4 x i64>
  %114 = shufflevector <4 x i64> %112, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %115 = bitcast <16 x i16> %109 to <8 x i32>
  %116 = shufflevector <8 x i32> %115, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %117 = bitcast <2 x i64> %114 to <8 x i16>
  %118 = bitcast <4 x i32> %116 to <8 x i16>
  %119 = add <8 x i16> %118, %117
  %120 = bitcast <8 x i16> %119 to <16 x i8>
  %121 = shufflevector <16 x i8> %120, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %122 = bitcast <16 x i8> %121 to <8 x i16>
  %123 = add <8 x i16> %119, %122
  %124 = shufflevector <8 x i16> %123, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %125 = sext <4 x i16> %124 to <4 x i32>
  %126 = shufflevector <4 x i64> %113, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %127 = shufflevector <8 x i32> %111, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %128 = bitcast <2 x i64> %126 to <4 x i32>
  %129 = add <4 x i32> %127, %128
  %130 = shufflevector <4 x i32> %129, <4 x i32> %125, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %131 = shufflevector <4 x i32> %129, <4 x i32> %125, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %132 = add <4 x i32> %131, %130
  %133 = bitcast <4 x i32> %132 to <16 x i8>
  %134 = shufflevector <16 x i8> %133, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %135 = bitcast <16 x i8> %134 to <4 x i32>
  %136 = add <4 x i32> %132, %135
  %137 = extractelement <4 x i32> %136, i32 0
  store i32 %137, i32* %4, align 4
  ret i32 %137
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_mse16x16_avx2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  %8 = shl nsw i32 %1, 1
  %9 = sext i32 %8 to i64
  %10 = shl nsw i32 %3, 1
  %11 = sext i32 %10 to i64
  %12 = bitcast i8* %0 to <2 x i64>*
  %13 = load <2 x i64>, <2 x i64>* %12, align 1
  %14 = getelementptr inbounds i8, i8* %0, i64 %6
  %15 = bitcast i8* %14 to <2 x i64>*
  %16 = load <2 x i64>, <2 x i64>* %15, align 1
  %17 = bitcast i8* %2 to <2 x i64>*
  %18 = load <2 x i64>, <2 x i64>* %17, align 1
  %19 = getelementptr inbounds i8, i8* %2, i64 %7
  %20 = bitcast i8* %19 to <2 x i64>*
  %21 = load <2 x i64>, <2 x i64>* %20, align 1
  %22 = shufflevector <2 x i64> %13, <2 x i64> %16, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %23 = shufflevector <2 x i64> %18, <2 x i64> %21, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %24 = bitcast <4 x i64> %22 to <32 x i8>
  %25 = bitcast <4 x i64> %23 to <32 x i8>
  %26 = shufflevector <32 x i8> %24, <32 x i8> %25, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %27 = shufflevector <32 x i8> %24, <32 x i8> %25, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %28 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %26, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %29 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %27, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %30 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %28, <16 x i16> %28) #5
  %31 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %29, <16 x i16> %29) #5
  %32 = add <16 x i16> %28, %29
  %33 = add <8 x i32> %30, %31
  %34 = getelementptr inbounds i8, i8* %0, i64 %9
  %35 = getelementptr inbounds i8, i8* %2, i64 %11
  %36 = bitcast i8* %34 to <2 x i64>*
  %37 = load <2 x i64>, <2 x i64>* %36, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 %6
  %39 = bitcast i8* %38 to <2 x i64>*
  %40 = load <2 x i64>, <2 x i64>* %39, align 1
  %41 = bitcast i8* %35 to <2 x i64>*
  %42 = load <2 x i64>, <2 x i64>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %35, i64 %7
  %44 = bitcast i8* %43 to <2 x i64>*
  %45 = load <2 x i64>, <2 x i64>* %44, align 1
  %46 = shufflevector <2 x i64> %37, <2 x i64> %40, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = shufflevector <2 x i64> %42, <2 x i64> %45, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = bitcast <4 x i64> %46 to <32 x i8>
  %49 = bitcast <4 x i64> %47 to <32 x i8>
  %50 = shufflevector <32 x i8> %48, <32 x i8> %49, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %51 = shufflevector <32 x i8> %48, <32 x i8> %49, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %52 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %50, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %53 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %51, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %54 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %52, <16 x i16> %52) #5
  %55 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %53, <16 x i16> %53) #5
  %56 = add <16 x i16> %52, %32
  %57 = add <16 x i16> %56, %53
  %58 = add <8 x i32> %54, %33
  %59 = add <8 x i32> %58, %55
  %60 = getelementptr inbounds i8, i8* %34, i64 %9
  %61 = getelementptr inbounds i8, i8* %35, i64 %11
  %62 = bitcast i8* %60 to <2 x i64>*
  %63 = load <2 x i64>, <2 x i64>* %62, align 1
  %64 = getelementptr inbounds i8, i8* %60, i64 %6
  %65 = bitcast i8* %64 to <2 x i64>*
  %66 = load <2 x i64>, <2 x i64>* %65, align 1
  %67 = bitcast i8* %61 to <2 x i64>*
  %68 = load <2 x i64>, <2 x i64>* %67, align 1
  %69 = getelementptr inbounds i8, i8* %61, i64 %7
  %70 = bitcast i8* %69 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 1
  %72 = shufflevector <2 x i64> %63, <2 x i64> %66, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %73 = shufflevector <2 x i64> %68, <2 x i64> %71, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %74 = bitcast <4 x i64> %72 to <32 x i8>
  %75 = bitcast <4 x i64> %73 to <32 x i8>
  %76 = shufflevector <32 x i8> %74, <32 x i8> %75, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %77 = shufflevector <32 x i8> %74, <32 x i8> %75, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %78 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %76, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %79 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %77, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %80 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %78, <16 x i16> %78) #5
  %81 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %79, <16 x i16> %79) #5
  %82 = add <16 x i16> %78, %57
  %83 = add <16 x i16> %82, %79
  %84 = add <8 x i32> %80, %59
  %85 = add <8 x i32> %84, %81
  %86 = getelementptr inbounds i8, i8* %60, i64 %9
  %87 = getelementptr inbounds i8, i8* %61, i64 %11
  %88 = bitcast i8* %86 to <2 x i64>*
  %89 = load <2 x i64>, <2 x i64>* %88, align 1
  %90 = getelementptr inbounds i8, i8* %86, i64 %6
  %91 = bitcast i8* %90 to <2 x i64>*
  %92 = load <2 x i64>, <2 x i64>* %91, align 1
  %93 = bitcast i8* %87 to <2 x i64>*
  %94 = load <2 x i64>, <2 x i64>* %93, align 1
  %95 = getelementptr inbounds i8, i8* %87, i64 %7
  %96 = bitcast i8* %95 to <2 x i64>*
  %97 = load <2 x i64>, <2 x i64>* %96, align 1
  %98 = shufflevector <2 x i64> %89, <2 x i64> %92, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %99 = shufflevector <2 x i64> %94, <2 x i64> %97, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %100 = bitcast <4 x i64> %98 to <32 x i8>
  %101 = bitcast <4 x i64> %99 to <32 x i8>
  %102 = shufflevector <32 x i8> %100, <32 x i8> %101, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %103 = shufflevector <32 x i8> %100, <32 x i8> %101, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %104 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %102, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %105 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %103, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %106 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %104, <16 x i16> %104) #5
  %107 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %105, <16 x i16> %105) #5
  %108 = add <16 x i16> %104, %83
  %109 = add <16 x i16> %108, %105
  %110 = add <8 x i32> %106, %85
  %111 = add <8 x i32> %110, %107
  %112 = getelementptr inbounds i8, i8* %86, i64 %9
  %113 = getelementptr inbounds i8, i8* %87, i64 %11
  %114 = bitcast i8* %112 to <2 x i64>*
  %115 = load <2 x i64>, <2 x i64>* %114, align 1
  %116 = getelementptr inbounds i8, i8* %112, i64 %6
  %117 = bitcast i8* %116 to <2 x i64>*
  %118 = load <2 x i64>, <2 x i64>* %117, align 1
  %119 = bitcast i8* %113 to <2 x i64>*
  %120 = load <2 x i64>, <2 x i64>* %119, align 1
  %121 = getelementptr inbounds i8, i8* %113, i64 %7
  %122 = bitcast i8* %121 to <2 x i64>*
  %123 = load <2 x i64>, <2 x i64>* %122, align 1
  %124 = shufflevector <2 x i64> %115, <2 x i64> %118, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %125 = shufflevector <2 x i64> %120, <2 x i64> %123, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %126 = bitcast <4 x i64> %124 to <32 x i8>
  %127 = bitcast <4 x i64> %125 to <32 x i8>
  %128 = shufflevector <32 x i8> %126, <32 x i8> %127, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %129 = shufflevector <32 x i8> %126, <32 x i8> %127, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %130 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %128, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %131 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %129, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %132 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %130, <16 x i16> %130) #5
  %133 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %131, <16 x i16> %131) #5
  %134 = add <16 x i16> %130, %109
  %135 = add <16 x i16> %134, %131
  %136 = add <8 x i32> %132, %111
  %137 = add <8 x i32> %136, %133
  %138 = getelementptr inbounds i8, i8* %112, i64 %9
  %139 = getelementptr inbounds i8, i8* %113, i64 %11
  %140 = bitcast i8* %138 to <2 x i64>*
  %141 = load <2 x i64>, <2 x i64>* %140, align 1
  %142 = getelementptr inbounds i8, i8* %138, i64 %6
  %143 = bitcast i8* %142 to <2 x i64>*
  %144 = load <2 x i64>, <2 x i64>* %143, align 1
  %145 = bitcast i8* %139 to <2 x i64>*
  %146 = load <2 x i64>, <2 x i64>* %145, align 1
  %147 = getelementptr inbounds i8, i8* %139, i64 %7
  %148 = bitcast i8* %147 to <2 x i64>*
  %149 = load <2 x i64>, <2 x i64>* %148, align 1
  %150 = shufflevector <2 x i64> %141, <2 x i64> %144, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %151 = shufflevector <2 x i64> %146, <2 x i64> %149, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %152 = bitcast <4 x i64> %150 to <32 x i8>
  %153 = bitcast <4 x i64> %151 to <32 x i8>
  %154 = shufflevector <32 x i8> %152, <32 x i8> %153, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %155 = shufflevector <32 x i8> %152, <32 x i8> %153, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %156 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %154, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %157 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %155, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %158 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %156, <16 x i16> %156) #5
  %159 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %157, <16 x i16> %157) #5
  %160 = add <16 x i16> %156, %135
  %161 = add <16 x i16> %160, %157
  %162 = add <8 x i32> %158, %137
  %163 = add <8 x i32> %162, %159
  %164 = getelementptr inbounds i8, i8* %138, i64 %9
  %165 = getelementptr inbounds i8, i8* %139, i64 %11
  %166 = bitcast i8* %164 to <2 x i64>*
  %167 = load <2 x i64>, <2 x i64>* %166, align 1
  %168 = getelementptr inbounds i8, i8* %164, i64 %6
  %169 = bitcast i8* %168 to <2 x i64>*
  %170 = load <2 x i64>, <2 x i64>* %169, align 1
  %171 = bitcast i8* %165 to <2 x i64>*
  %172 = load <2 x i64>, <2 x i64>* %171, align 1
  %173 = getelementptr inbounds i8, i8* %165, i64 %7
  %174 = bitcast i8* %173 to <2 x i64>*
  %175 = load <2 x i64>, <2 x i64>* %174, align 1
  %176 = shufflevector <2 x i64> %167, <2 x i64> %170, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %177 = shufflevector <2 x i64> %172, <2 x i64> %175, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %178 = bitcast <4 x i64> %176 to <32 x i8>
  %179 = bitcast <4 x i64> %177 to <32 x i8>
  %180 = shufflevector <32 x i8> %178, <32 x i8> %179, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %181 = shufflevector <32 x i8> %178, <32 x i8> %179, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %182 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %180, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %183 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %181, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %184 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %182, <16 x i16> %182) #5
  %185 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %183, <16 x i16> %183) #5
  %186 = add <16 x i16> %182, %161
  %187 = add <16 x i16> %186, %183
  %188 = add <8 x i32> %184, %163
  %189 = add <8 x i32> %188, %185
  %190 = getelementptr inbounds i8, i8* %164, i64 %9
  %191 = getelementptr inbounds i8, i8* %165, i64 %11
  %192 = bitcast i8* %190 to <2 x i64>*
  %193 = load <2 x i64>, <2 x i64>* %192, align 1
  %194 = getelementptr inbounds i8, i8* %190, i64 %6
  %195 = bitcast i8* %194 to <2 x i64>*
  %196 = load <2 x i64>, <2 x i64>* %195, align 1
  %197 = bitcast i8* %191 to <2 x i64>*
  %198 = load <2 x i64>, <2 x i64>* %197, align 1
  %199 = getelementptr inbounds i8, i8* %191, i64 %7
  %200 = bitcast i8* %199 to <2 x i64>*
  %201 = load <2 x i64>, <2 x i64>* %200, align 1
  %202 = shufflevector <2 x i64> %193, <2 x i64> %196, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = shufflevector <2 x i64> %198, <2 x i64> %201, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %204 = bitcast <4 x i64> %202 to <32 x i8>
  %205 = bitcast <4 x i64> %203 to <32 x i8>
  %206 = shufflevector <32 x i8> %204, <32 x i8> %205, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %207 = shufflevector <32 x i8> %204, <32 x i8> %205, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %208 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %206, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %209 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %207, <32 x i8> <i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1, i8 1, i8 -1>) #5
  %210 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %208, <16 x i16> %208) #5
  %211 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %209, <16 x i16> %209) #5
  %212 = add <16 x i16> %208, %187
  %213 = add <16 x i16> %212, %209
  %214 = add <8 x i32> %210, %189
  %215 = add <8 x i32> %214, %211
  %216 = bitcast <16 x i16> %213 to <4 x i64>
  %217 = bitcast <8 x i32> %215 to <4 x i64>
  %218 = shufflevector <4 x i64> %216, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %219 = bitcast <16 x i16> %213 to <8 x i32>
  %220 = shufflevector <8 x i32> %219, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %221 = bitcast <2 x i64> %218 to <8 x i16>
  %222 = bitcast <4 x i32> %220 to <8 x i16>
  %223 = add <8 x i16> %222, %221
  %224 = bitcast <8 x i16> %223 to <16 x i8>
  %225 = shufflevector <16 x i8> %224, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %226 = bitcast <16 x i8> %225 to <8 x i16>
  %227 = add <8 x i16> %223, %226
  %228 = shufflevector <8 x i16> %227, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %229 = sext <4 x i16> %228 to <4 x i32>
  %230 = shufflevector <4 x i64> %217, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %231 = shufflevector <8 x i32> %215, <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %232 = bitcast <2 x i64> %230 to <4 x i32>
  %233 = add <4 x i32> %231, %232
  %234 = shufflevector <4 x i32> %233, <4 x i32> %229, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %235 = shufflevector <4 x i32> %233, <4 x i32> %229, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %236 = add <4 x i32> %235, %234
  %237 = bitcast <4 x i32> %236 to <16 x i8>
  %238 = shufflevector <16 x i8> %237, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %239 = bitcast <16 x i8> %238 to <4 x i32>
  %240 = add <4 x i32> %236, %239
  %241 = extractelement <4 x i32> %240, i32 0
  store i32 %241, i32* %4, align 4
  ret i32 %241
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_sub_pixel_variance64x64_avx2(i8* nocapture readonly, i32, i32, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #2 {
  %8 = alloca i32, align 4
  %9 = alloca i32, align 4
  %10 = bitcast i32* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %10) #5
  store i32 -1431655766, i32* %8, align 4
  %11 = call fastcc i32 @sub_pix_var32xh(i8* %0, i32 %1, i32 %2, i32 %3, i8* %4, i32 %5, i8* null, i32 0, i32 0, i32 64, i32* nonnull %8) #5
  %12 = bitcast i32* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %12) #5
  store i32 -1431655766, i32* %9, align 4
  %13 = getelementptr inbounds i8, i8* %0, i64 32
  %14 = getelementptr inbounds i8, i8* %4, i64 32
  %15 = call fastcc i32 @sub_pix_var32xh(i8* %13, i32 %1, i32 %2, i32 %3, i8* %14, i32 %5, i8* null, i32 0, i32 0, i32 64, i32* nonnull %9) #5
  %16 = add nsw i32 %15, %11
  %17 = load i32, i32* %8, align 4
  %18 = load i32, i32* %9, align 4
  %19 = add i32 %18, %17
  store i32 %19, i32* %6, align 4
  %20 = sext i32 %16 to i64
  %21 = mul nsw i64 %20, %20
  %22 = lshr i64 %21, 12
  %23 = trunc i64 %22 to i32
  %24 = sub i32 %19, %23
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %12) #5
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %10) #5
  ret i32 %24
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_sub_pixel_variance32x32_avx2(i8* nocapture readonly, i32, i32, i32, i8* nocapture readonly, i32, i32* nocapture) local_unnamed_addr #2 {
  %8 = tail call fastcc i32 @sub_pix_var32xh(i8* %0, i32 %1, i32 %2, i32 %3, i8* %4, i32 %5, i8* null, i32 0, i32 0, i32 32, i32* %6) #5
  %9 = load i32, i32* %6, align 4
  %10 = sext i32 %8 to i64
  %11 = mul nsw i64 %10, %10
  %12 = lshr i64 %11, 10
  %13 = trunc i64 %12 to i32
  %14 = sub i32 %9, %13
  ret i32 %14
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_sub_pixel_avg_variance64x64_avx2(i8* nocapture readonly, i32, i32, i32, i8* nocapture readonly, i32, i32* nocapture, i8* nocapture readonly) local_unnamed_addr #2 {
  %9 = alloca i32, align 4
  %10 = alloca i32, align 4
  %11 = bitcast i32* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %11) #5
  store i32 -1431655766, i32* %9, align 4
  %12 = call fastcc i32 @sub_pix_var32xh(i8* %0, i32 %1, i32 %2, i32 %3, i8* %4, i32 %5, i8* %7, i32 64, i32 1, i32 64, i32* nonnull %9) #5
  %13 = bitcast i32* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %13) #5
  store i32 -1431655766, i32* %10, align 4
  %14 = getelementptr inbounds i8, i8* %0, i64 32
  %15 = getelementptr inbounds i8, i8* %4, i64 32
  %16 = getelementptr inbounds i8, i8* %7, i64 32
  %17 = call fastcc i32 @sub_pix_var32xh(i8* %14, i32 %1, i32 %2, i32 %3, i8* %15, i32 %5, i8* %16, i32 64, i32 1, i32 64, i32* nonnull %10) #5
  %18 = add nsw i32 %17, %12
  %19 = load i32, i32* %9, align 4
  %20 = load i32, i32* %10, align 4
  %21 = add i32 %20, %19
  store i32 %21, i32* %6, align 4
  %22 = sext i32 %18 to i64
  %23 = mul nsw i64 %22, %22
  %24 = lshr i64 %23, 12
  %25 = trunc i64 %24 to i32
  %26 = sub i32 %21, %25
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %13) #5
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %11) #5
  ret i32 %26
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @vpx_sub_pixel_avg_variance32x32_avx2(i8* nocapture readonly, i32, i32, i32, i8* nocapture readonly, i32, i32* nocapture, i8* nocapture readonly) local_unnamed_addr #2 {
  %9 = tail call fastcc i32 @sub_pix_var32xh(i8* %0, i32 %1, i32 %2, i32 %3, i8* %4, i32 %5, i8* %7, i32 32, i32 1, i32 32, i32* %6) #5
  %10 = load i32, i32* %6, align 4
  %11 = sext i32 %9 to i64
  %12 = mul nsw i64 %11, %11
  %13 = lshr i64 %12, 10
  %14 = trunc i64 %13 to i32
  %15 = sub i32 %10, %14
  ret i32 %15
}

; Function Attrs: nounwind readnone
declare <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8>, <32 x i8>) #3

; Function Attrs: nounwind readnone
declare <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16>, <16 x i16>) #3

; Function Attrs: inlinehint nounwind ssp uwtable
define internal fastcc i32 @sub_pix_var32xh(i8* nocapture readonly, i32, i32, i32, i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32, i32, i32* nocapture) unnamed_addr #4 {
  %12 = icmp eq i32 %2, 0
  br i1 %12, label %13, label %188

13:                                               ; preds = %11
  switch i32 %3, label %120 [
    i32 0, label %14
    i32 4, label %66
  ]

14:                                               ; preds = %13
  %15 = icmp sgt i32 %9, 0
  br i1 %15, label %16, label %650

16:                                               ; preds = %14
  %17 = icmp eq i32 %8, 0
  %18 = sext i32 %7 to i64
  %19 = sext i32 %1 to i64
  %20 = sext i32 %5 to i64
  br label %21

21:                                               ; preds = %44, %16
  %22 = phi <16 x i16> [ zeroinitializer, %16 ], [ %58, %44 ]
  %23 = phi <8 x i32> [ zeroinitializer, %16 ], [ %61, %44 ]
  %24 = phi i8* [ %0, %16 ], [ %62, %44 ]
  %25 = phi i8* [ %4, %16 ], [ %63, %44 ]
  %26 = phi i32 [ 0, %16 ], [ %64, %44 ]
  %27 = phi i8* [ %6, %16 ], [ %45, %44 ]
  %28 = bitcast i8* %25 to <32 x i8>*
  %29 = load <32 x i8>, <32 x i8>* %28, align 1
  %30 = bitcast i8* %24 to <4 x i64>*
  %31 = load <4 x i64>, <4 x i64>* %30, align 1
  br i1 %17, label %40, label %32

32:                                               ; preds = %21
  %33 = bitcast i8* %27 to <32 x i8>*
  %34 = load <32 x i8>, <32 x i8>* %33, align 1
  %35 = bitcast <4 x i64> %31 to <32 x i8>
  %36 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %35, <32 x i8> %34) #5
  %37 = shufflevector <32 x i8> %36, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %38 = shufflevector <32 x i8> %36, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %39 = getelementptr inbounds i8, i8* %27, i64 %18
  br label %44

40:                                               ; preds = %21
  %41 = bitcast <4 x i64> %31 to <32 x i8>
  %42 = shufflevector <32 x i8> %41, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %43 = shufflevector <32 x i8> %41, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  br label %44

44:                                               ; preds = %40, %32
  %45 = phi i8* [ %39, %32 ], [ %27, %40 ]
  %46 = phi <32 x i8> [ %37, %32 ], [ %42, %40 ]
  %47 = phi <32 x i8> [ %38, %32 ], [ %43, %40 ]
  %48 = shufflevector <32 x i8> %29, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %49 = shufflevector <32 x i8> %29, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %50 = bitcast <32 x i8> %46 to <16 x i16>
  %51 = bitcast <32 x i8> %48 to <16 x i16>
  %52 = sub <16 x i16> %50, %51
  %53 = bitcast <32 x i8> %47 to <16 x i16>
  %54 = bitcast <32 x i8> %49 to <16 x i16>
  %55 = sub <16 x i16> %53, %54
  %56 = add <16 x i16> %52, %22
  %57 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %52, <16 x i16> %52) #5
  %58 = add <16 x i16> %56, %55
  %59 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %55, <16 x i16> %55) #5
  %60 = add <8 x i32> %57, %23
  %61 = add <8 x i32> %60, %59
  %62 = getelementptr inbounds i8, i8* %24, i64 %19
  %63 = getelementptr inbounds i8, i8* %25, i64 %20
  %64 = add nuw nsw i32 %26, 1
  %65 = icmp eq i32 %64, %9
  br i1 %65, label %634, label %21

66:                                               ; preds = %13
  %67 = icmp sgt i32 %9, 0
  br i1 %67, label %68, label %650

68:                                               ; preds = %66
  %69 = sext i32 %1 to i64
  %70 = icmp eq i32 %8, 0
  %71 = sext i32 %7 to i64
  %72 = sext i32 %5 to i64
  %73 = bitcast i8* %0 to <32 x i8>*
  %74 = load <32 x i8>, <32 x i8>* %73, align 1
  br label %75

75:                                               ; preds = %99, %68
  %76 = phi <32 x i8> [ %74, %68 ], [ %87, %99 ]
  %77 = phi <16 x i16> [ zeroinitializer, %68 ], [ %113, %99 ]
  %78 = phi <8 x i32> [ zeroinitializer, %68 ], [ %116, %99 ]
  %79 = phi i8* [ %0, %68 ], [ %85, %99 ]
  %80 = phi i8* [ %4, %68 ], [ %117, %99 ]
  %81 = phi i8* [ %6, %68 ], [ %102, %99 ]
  %82 = phi i32 [ 0, %68 ], [ %118, %99 ]
  %83 = bitcast i8* %80 to <32 x i8>*
  %84 = load <32 x i8>, <32 x i8>* %83, align 1
  %85 = getelementptr inbounds i8, i8* %79, i64 %69
  %86 = bitcast i8* %85 to <32 x i8>*
  %87 = load <32 x i8>, <32 x i8>* %86, align 1
  %88 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %76, <32 x i8> %87) #5
  br i1 %70, label %96, label %89

89:                                               ; preds = %75
  %90 = bitcast i8* %81 to <32 x i8>*
  %91 = load <32 x i8>, <32 x i8>* %90, align 1
  %92 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %88, <32 x i8> %91) #5
  %93 = shufflevector <32 x i8> %92, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %94 = shufflevector <32 x i8> %92, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %95 = getelementptr inbounds i8, i8* %81, i64 %71
  br label %99

96:                                               ; preds = %75
  %97 = shufflevector <32 x i8> %88, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %98 = shufflevector <32 x i8> %88, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  br label %99

99:                                               ; preds = %96, %89
  %100 = phi <32 x i8> [ %93, %89 ], [ %97, %96 ]
  %101 = phi <32 x i8> [ %94, %89 ], [ %98, %96 ]
  %102 = phi i8* [ %95, %89 ], [ %81, %96 ]
  %103 = shufflevector <32 x i8> %84, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %104 = shufflevector <32 x i8> %84, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %105 = bitcast <32 x i8> %100 to <16 x i16>
  %106 = bitcast <32 x i8> %103 to <16 x i16>
  %107 = sub <16 x i16> %105, %106
  %108 = bitcast <32 x i8> %101 to <16 x i16>
  %109 = bitcast <32 x i8> %104 to <16 x i16>
  %110 = sub <16 x i16> %108, %109
  %111 = add <16 x i16> %107, %77
  %112 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %107, <16 x i16> %107) #5
  %113 = add <16 x i16> %111, %110
  %114 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %110, <16 x i16> %110) #5
  %115 = add <8 x i32> %112, %78
  %116 = add <8 x i32> %115, %114
  %117 = getelementptr inbounds i8, i8* %80, i64 %72
  %118 = add nuw nsw i32 %82, 1
  %119 = icmp eq i32 %118, %9
  br i1 %119, label %636, label %75

120:                                              ; preds = %13
  %121 = shl i32 %3, 5
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds <{ [256 x i8], [256 x i8] }>, <{ [256 x i8], [256 x i8] }>* @bilinear_filters_avx2, i64 0, i32 0, i64 %122
  %124 = bitcast i8* %123 to <32 x i8>*
  %125 = load <32 x i8>, <32 x i8>* %124, align 32
  %126 = icmp sgt i32 %9, 0
  br i1 %126, label %127, label %650

127:                                              ; preds = %120
  %128 = sext i32 %1 to i64
  %129 = icmp eq i32 %8, 0
  %130 = sext i32 %7 to i64
  %131 = sext i32 %5 to i64
  %132 = bitcast i8* %0 to <32 x i8>*
  %133 = load <32 x i8>, <32 x i8>* %132, align 1
  br label %134

134:                                              ; preds = %167, %127
  %135 = phi <32 x i8> [ %133, %127 ], [ %146, %167 ]
  %136 = phi <16 x i16> [ zeroinitializer, %127 ], [ %181, %167 ]
  %137 = phi <8 x i32> [ zeroinitializer, %127 ], [ %184, %167 ]
  %138 = phi i8* [ %0, %127 ], [ %144, %167 ]
  %139 = phi i8* [ %4, %127 ], [ %185, %167 ]
  %140 = phi i8* [ %6, %127 ], [ %170, %167 ]
  %141 = phi i32 [ 0, %127 ], [ %186, %167 ]
  %142 = bitcast i8* %139 to <32 x i8>*
  %143 = load <32 x i8>, <32 x i8>* %142, align 1
  %144 = getelementptr inbounds i8, i8* %138, i64 %128
  %145 = bitcast i8* %144 to <32 x i8>*
  %146 = load <32 x i8>, <32 x i8>* %145, align 1
  %147 = shufflevector <32 x i8> %135, <32 x i8> %146, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %148 = shufflevector <32 x i8> %135, <32 x i8> %146, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %149 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %147, <32 x i8> %125) #5
  %150 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %148, <32 x i8> %125) #5
  %151 = add <16 x i16> %149, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %152 = add <16 x i16> %150, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %153 = ashr <16 x i16> %151, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %154 = bitcast <16 x i16> %153 to <4 x i64>
  %155 = ashr <16 x i16> %152, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %156 = bitcast <16 x i16> %155 to <4 x i64>
  br i1 %129, label %167, label %157

157:                                              ; preds = %134
  %158 = bitcast i8* %140 to <32 x i8>*
  %159 = load <32 x i8>, <32 x i8>* %158, align 1
  %160 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %153, <16 x i16> %155) #5
  %161 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %160, <32 x i8> %159) #5
  %162 = getelementptr inbounds i8, i8* %140, i64 %130
  %163 = shufflevector <32 x i8> %161, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %164 = bitcast <32 x i8> %163 to <4 x i64>
  %165 = shufflevector <32 x i8> %161, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %166 = bitcast <32 x i8> %165 to <4 x i64>
  br label %167

167:                                              ; preds = %157, %134
  %168 = phi <4 x i64> [ %164, %157 ], [ %154, %134 ]
  %169 = phi <4 x i64> [ %166, %157 ], [ %156, %134 ]
  %170 = phi i8* [ %162, %157 ], [ %140, %134 ]
  %171 = shufflevector <32 x i8> %143, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %172 = shufflevector <32 x i8> %143, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %173 = bitcast <4 x i64> %168 to <16 x i16>
  %174 = bitcast <32 x i8> %171 to <16 x i16>
  %175 = sub <16 x i16> %173, %174
  %176 = bitcast <4 x i64> %169 to <16 x i16>
  %177 = bitcast <32 x i8> %172 to <16 x i16>
  %178 = sub <16 x i16> %176, %177
  %179 = add <16 x i16> %175, %136
  %180 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %175, <16 x i16> %175) #5
  %181 = add <16 x i16> %179, %178
  %182 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %178, <16 x i16> %178) #5
  %183 = add <8 x i32> %180, %137
  %184 = add <8 x i32> %183, %182
  %185 = getelementptr inbounds i8, i8* %139, i64 %131
  %186 = add nuw nsw i32 %141, 1
  %187 = icmp eq i32 %186, %9
  br i1 %187, label %632, label %134

188:                                              ; preds = %11
  %189 = icmp eq i32 %2, 4
  %190 = icmp eq i32 %3, 0
  br i1 %189, label %191, label %386

191:                                              ; preds = %188
  br i1 %190, label %192, label %246

192:                                              ; preds = %191
  %193 = icmp sgt i32 %9, 0
  br i1 %193, label %194, label %650

194:                                              ; preds = %192
  %195 = icmp eq i32 %8, 0
  %196 = sext i32 %7 to i64
  %197 = sext i32 %1 to i64
  %198 = sext i32 %5 to i64
  br label %199

199:                                              ; preds = %224, %194
  %200 = phi <16 x i16> [ zeroinitializer, %194 ], [ %238, %224 ]
  %201 = phi <8 x i32> [ zeroinitializer, %194 ], [ %241, %224 ]
  %202 = phi i8* [ %0, %194 ], [ %242, %224 ]
  %203 = phi i8* [ %4, %194 ], [ %243, %224 ]
  %204 = phi i8* [ %6, %194 ], [ %227, %224 ]
  %205 = phi i32 [ 0, %194 ], [ %244, %224 ]
  %206 = bitcast i8* %203 to <32 x i8>*
  %207 = load <32 x i8>, <32 x i8>* %206, align 1
  %208 = bitcast i8* %202 to <32 x i8>*
  %209 = load <32 x i8>, <32 x i8>* %208, align 1
  %210 = getelementptr inbounds i8, i8* %202, i64 1
  %211 = bitcast i8* %210 to <32 x i8>*
  %212 = load <32 x i8>, <32 x i8>* %211, align 1
  %213 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %209, <32 x i8> %212) #5
  br i1 %195, label %221, label %214

214:                                              ; preds = %199
  %215 = bitcast i8* %204 to <32 x i8>*
  %216 = load <32 x i8>, <32 x i8>* %215, align 1
  %217 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %213, <32 x i8> %216) #5
  %218 = shufflevector <32 x i8> %217, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %219 = shufflevector <32 x i8> %217, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %220 = getelementptr inbounds i8, i8* %204, i64 %196
  br label %224

221:                                              ; preds = %199
  %222 = shufflevector <32 x i8> %213, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %223 = shufflevector <32 x i8> %213, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  br label %224

224:                                              ; preds = %221, %214
  %225 = phi <32 x i8> [ %218, %214 ], [ %222, %221 ]
  %226 = phi <32 x i8> [ %219, %214 ], [ %223, %221 ]
  %227 = phi i8* [ %220, %214 ], [ %204, %221 ]
  %228 = shufflevector <32 x i8> %207, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %229 = shufflevector <32 x i8> %207, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %230 = bitcast <32 x i8> %225 to <16 x i16>
  %231 = bitcast <32 x i8> %228 to <16 x i16>
  %232 = sub <16 x i16> %230, %231
  %233 = bitcast <32 x i8> %226 to <16 x i16>
  %234 = bitcast <32 x i8> %229 to <16 x i16>
  %235 = sub <16 x i16> %233, %234
  %236 = add <16 x i16> %232, %200
  %237 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %232, <16 x i16> %232) #5
  %238 = add <16 x i16> %236, %235
  %239 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %235, <16 x i16> %235) #5
  %240 = add <8 x i32> %237, %201
  %241 = add <8 x i32> %240, %239
  %242 = getelementptr inbounds i8, i8* %202, i64 %197
  %243 = getelementptr inbounds i8, i8* %203, i64 %198
  %244 = add nuw nsw i32 %205, 1
  %245 = icmp eq i32 %244, %9
  br i1 %245, label %638, label %199

246:                                              ; preds = %191
  %247 = icmp eq i32 %3, 4
  br i1 %247, label %248, label %310

248:                                              ; preds = %246
  %249 = sext i32 %1 to i64
  %250 = icmp sgt i32 %9, 0
  br i1 %250, label %251, label %650

251:                                              ; preds = %248
  %252 = bitcast i8* %0 to <32 x i8>*
  %253 = load <32 x i8>, <32 x i8>* %252, align 1
  %254 = getelementptr inbounds i8, i8* %0, i64 1
  %255 = bitcast i8* %254 to <32 x i8>*
  %256 = load <32 x i8>, <32 x i8>* %255, align 1
  %257 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %253, <32 x i8> %256) #5
  %258 = icmp eq i32 %8, 0
  %259 = sext i32 %7 to i64
  %260 = sext i32 %5 to i64
  br label %261

261:                                              ; preds = %289, %251
  %262 = phi <16 x i16> [ zeroinitializer, %251 ], [ %303, %289 ]
  %263 = phi <8 x i32> [ zeroinitializer, %251 ], [ %306, %289 ]
  %264 = phi i8* [ %0, %251 ], [ %269, %289 ]
  %265 = phi i8* [ %4, %251 ], [ %307, %289 ]
  %266 = phi i8* [ %6, %251 ], [ %292, %289 ]
  %267 = phi <32 x i8> [ %257, %251 ], [ %277, %289 ]
  %268 = phi i32 [ 0, %251 ], [ %308, %289 ]
  %269 = getelementptr inbounds i8, i8* %264, i64 %249
  %270 = bitcast i8* %265 to <32 x i8>*
  %271 = load <32 x i8>, <32 x i8>* %270, align 1
  %272 = bitcast i8* %269 to <32 x i8>*
  %273 = load <32 x i8>, <32 x i8>* %272, align 1
  %274 = getelementptr inbounds i8, i8* %269, i64 1
  %275 = bitcast i8* %274 to <32 x i8>*
  %276 = load <32 x i8>, <32 x i8>* %275, align 1
  %277 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %273, <32 x i8> %276) #5
  %278 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %267, <32 x i8> %277) #5
  br i1 %258, label %286, label %279

279:                                              ; preds = %261
  %280 = bitcast i8* %266 to <32 x i8>*
  %281 = load <32 x i8>, <32 x i8>* %280, align 1
  %282 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %278, <32 x i8> %281) #5
  %283 = shufflevector <32 x i8> %282, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %284 = shufflevector <32 x i8> %282, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %285 = getelementptr inbounds i8, i8* %266, i64 %259
  br label %289

286:                                              ; preds = %261
  %287 = shufflevector <32 x i8> %278, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %288 = shufflevector <32 x i8> %278, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  br label %289

289:                                              ; preds = %286, %279
  %290 = phi <32 x i8> [ %283, %279 ], [ %287, %286 ]
  %291 = phi <32 x i8> [ %284, %279 ], [ %288, %286 ]
  %292 = phi i8* [ %285, %279 ], [ %266, %286 ]
  %293 = shufflevector <32 x i8> %271, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %294 = shufflevector <32 x i8> %271, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %295 = bitcast <32 x i8> %290 to <16 x i16>
  %296 = bitcast <32 x i8> %293 to <16 x i16>
  %297 = sub <16 x i16> %295, %296
  %298 = bitcast <32 x i8> %291 to <16 x i16>
  %299 = bitcast <32 x i8> %294 to <16 x i16>
  %300 = sub <16 x i16> %298, %299
  %301 = add <16 x i16> %297, %262
  %302 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %297, <16 x i16> %297) #5
  %303 = add <16 x i16> %301, %300
  %304 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %300, <16 x i16> %300) #5
  %305 = add <8 x i32> %302, %263
  %306 = add <8 x i32> %305, %304
  %307 = getelementptr inbounds i8, i8* %265, i64 %260
  %308 = add nuw nsw i32 %268, 1
  %309 = icmp eq i32 %308, %9
  br i1 %309, label %640, label %261

310:                                              ; preds = %246
  %311 = shl i32 %3, 5
  %312 = sext i32 %311 to i64
  %313 = getelementptr inbounds <{ [256 x i8], [256 x i8] }>, <{ [256 x i8], [256 x i8] }>* @bilinear_filters_avx2, i64 0, i32 0, i64 %312
  %314 = bitcast i8* %313 to <32 x i8>*
  %315 = load <32 x i8>, <32 x i8>* %314, align 32
  %316 = sext i32 %1 to i64
  %317 = icmp sgt i32 %9, 0
  br i1 %317, label %318, label %650

318:                                              ; preds = %310
  %319 = bitcast i8* %0 to <32 x i8>*
  %320 = load <32 x i8>, <32 x i8>* %319, align 1
  %321 = getelementptr inbounds i8, i8* %0, i64 1
  %322 = bitcast i8* %321 to <32 x i8>*
  %323 = load <32 x i8>, <32 x i8>* %322, align 1
  %324 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %320, <32 x i8> %323) #5
  %325 = icmp eq i32 %8, 0
  %326 = sext i32 %7 to i64
  %327 = sext i32 %5 to i64
  br label %328

328:                                              ; preds = %365, %318
  %329 = phi <16 x i16> [ zeroinitializer, %318 ], [ %379, %365 ]
  %330 = phi <8 x i32> [ zeroinitializer, %318 ], [ %382, %365 ]
  %331 = phi i8* [ %0, %318 ], [ %336, %365 ]
  %332 = phi i8* [ %4, %318 ], [ %383, %365 ]
  %333 = phi i8* [ %6, %318 ], [ %368, %365 ]
  %334 = phi i32 [ 0, %318 ], [ %384, %365 ]
  %335 = phi <32 x i8> [ %324, %318 ], [ %344, %365 ]
  %336 = getelementptr inbounds i8, i8* %331, i64 %316
  %337 = bitcast i8* %332 to <32 x i8>*
  %338 = load <32 x i8>, <32 x i8>* %337, align 1
  %339 = bitcast i8* %336 to <32 x i8>*
  %340 = load <32 x i8>, <32 x i8>* %339, align 1
  %341 = getelementptr inbounds i8, i8* %336, i64 1
  %342 = bitcast i8* %341 to <32 x i8>*
  %343 = load <32 x i8>, <32 x i8>* %342, align 1
  %344 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %340, <32 x i8> %343) #5
  %345 = shufflevector <32 x i8> %335, <32 x i8> %344, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %346 = shufflevector <32 x i8> %335, <32 x i8> %344, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %347 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %345, <32 x i8> %315) #5
  %348 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %346, <32 x i8> %315) #5
  %349 = add <16 x i16> %347, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %350 = add <16 x i16> %348, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %351 = ashr <16 x i16> %349, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %352 = bitcast <16 x i16> %351 to <4 x i64>
  %353 = ashr <16 x i16> %350, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %354 = bitcast <16 x i16> %353 to <4 x i64>
  br i1 %325, label %365, label %355

355:                                              ; preds = %328
  %356 = bitcast i8* %333 to <32 x i8>*
  %357 = load <32 x i8>, <32 x i8>* %356, align 1
  %358 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %351, <16 x i16> %353) #5
  %359 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %358, <32 x i8> %357) #5
  %360 = shufflevector <32 x i8> %359, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %361 = bitcast <32 x i8> %360 to <4 x i64>
  %362 = shufflevector <32 x i8> %359, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %363 = bitcast <32 x i8> %362 to <4 x i64>
  %364 = getelementptr inbounds i8, i8* %333, i64 %326
  br label %365

365:                                              ; preds = %355, %328
  %366 = phi <4 x i64> [ %361, %355 ], [ %352, %328 ]
  %367 = phi <4 x i64> [ %363, %355 ], [ %354, %328 ]
  %368 = phi i8* [ %364, %355 ], [ %333, %328 ]
  %369 = shufflevector <32 x i8> %338, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %370 = shufflevector <32 x i8> %338, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %371 = bitcast <4 x i64> %366 to <16 x i16>
  %372 = bitcast <32 x i8> %369 to <16 x i16>
  %373 = sub <16 x i16> %371, %372
  %374 = bitcast <4 x i64> %367 to <16 x i16>
  %375 = bitcast <32 x i8> %370 to <16 x i16>
  %376 = sub <16 x i16> %374, %375
  %377 = add <16 x i16> %373, %329
  %378 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %373, <16 x i16> %373) #5
  %379 = add <16 x i16> %377, %376
  %380 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %376, <16 x i16> %376) #5
  %381 = add <8 x i32> %378, %330
  %382 = add <8 x i32> %381, %380
  %383 = getelementptr inbounds i8, i8* %332, i64 %327
  %384 = add nuw nsw i32 %334, 1
  %385 = icmp eq i32 %384, %9
  br i1 %385, label %642, label %328

386:                                              ; preds = %188
  br i1 %190, label %387, label %455

387:                                              ; preds = %386
  %388 = shl i32 %2, 5
  %389 = sext i32 %388 to i64
  %390 = getelementptr inbounds <{ [256 x i8], [256 x i8] }>, <{ [256 x i8], [256 x i8] }>* @bilinear_filters_avx2, i64 0, i32 0, i64 %389
  %391 = bitcast i8* %390 to <32 x i8>*
  %392 = load <32 x i8>, <32 x i8>* %391, align 32
  %393 = icmp sgt i32 %9, 0
  br i1 %393, label %394, label %650

394:                                              ; preds = %387
  %395 = icmp eq i32 %8, 0
  %396 = sext i32 %7 to i64
  %397 = sext i32 %1 to i64
  %398 = sext i32 %5 to i64
  br label %399

399:                                              ; preds = %433, %394
  %400 = phi <16 x i16> [ zeroinitializer, %394 ], [ %447, %433 ]
  %401 = phi <8 x i32> [ zeroinitializer, %394 ], [ %450, %433 ]
  %402 = phi i8* [ %0, %394 ], [ %451, %433 ]
  %403 = phi i8* [ %4, %394 ], [ %452, %433 ]
  %404 = phi i8* [ %6, %394 ], [ %436, %433 ]
  %405 = phi i32 [ 0, %394 ], [ %453, %433 ]
  %406 = bitcast i8* %403 to <32 x i8>*
  %407 = load <32 x i8>, <32 x i8>* %406, align 1
  %408 = bitcast i8* %402 to <32 x i8>*
  %409 = load <32 x i8>, <32 x i8>* %408, align 1
  %410 = getelementptr inbounds i8, i8* %402, i64 1
  %411 = bitcast i8* %410 to <32 x i8>*
  %412 = load <32 x i8>, <32 x i8>* %411, align 1
  %413 = shufflevector <32 x i8> %409, <32 x i8> %412, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %414 = shufflevector <32 x i8> %409, <32 x i8> %412, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %415 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %413, <32 x i8> %392) #5
  %416 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %414, <32 x i8> %392) #5
  %417 = add <16 x i16> %415, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %418 = add <16 x i16> %416, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %419 = ashr <16 x i16> %417, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %420 = bitcast <16 x i16> %419 to <4 x i64>
  %421 = ashr <16 x i16> %418, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %422 = bitcast <16 x i16> %421 to <4 x i64>
  br i1 %395, label %433, label %423

423:                                              ; preds = %399
  %424 = bitcast i8* %404 to <32 x i8>*
  %425 = load <32 x i8>, <32 x i8>* %424, align 1
  %426 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %419, <16 x i16> %421) #5
  %427 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %426, <32 x i8> %425) #5
  %428 = getelementptr inbounds i8, i8* %404, i64 %396
  %429 = shufflevector <32 x i8> %427, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %430 = bitcast <32 x i8> %429 to <4 x i64>
  %431 = shufflevector <32 x i8> %427, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %432 = bitcast <32 x i8> %431 to <4 x i64>
  br label %433

433:                                              ; preds = %423, %399
  %434 = phi <4 x i64> [ %430, %423 ], [ %420, %399 ]
  %435 = phi <4 x i64> [ %432, %423 ], [ %422, %399 ]
  %436 = phi i8* [ %428, %423 ], [ %404, %399 ]
  %437 = shufflevector <32 x i8> %407, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %438 = shufflevector <32 x i8> %407, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %439 = bitcast <4 x i64> %434 to <16 x i16>
  %440 = bitcast <32 x i8> %437 to <16 x i16>
  %441 = sub <16 x i16> %439, %440
  %442 = bitcast <4 x i64> %435 to <16 x i16>
  %443 = bitcast <32 x i8> %438 to <16 x i16>
  %444 = sub <16 x i16> %442, %443
  %445 = add <16 x i16> %441, %400
  %446 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %441, <16 x i16> %441) #5
  %447 = add <16 x i16> %445, %444
  %448 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %444, <16 x i16> %444) #5
  %449 = add <8 x i32> %446, %401
  %450 = add <8 x i32> %449, %448
  %451 = getelementptr inbounds i8, i8* %402, i64 %397
  %452 = getelementptr inbounds i8, i8* %403, i64 %398
  %453 = add nuw nsw i32 %405, 1
  %454 = icmp eq i32 %453, %9
  br i1 %454, label %644, label %399

455:                                              ; preds = %386
  %456 = icmp eq i32 %3, 4
  %457 = shl i32 %2, 5
  %458 = sext i32 %457 to i64
  %459 = getelementptr inbounds <{ [256 x i8], [256 x i8] }>, <{ [256 x i8], [256 x i8] }>* @bilinear_filters_avx2, i64 0, i32 0, i64 %458
  %460 = bitcast i8* %459 to <32 x i8>*
  %461 = load <32 x i8>, <32 x i8>* %460, align 32
  br i1 %456, label %462, label %540

462:                                              ; preds = %455
  %463 = bitcast i8* %0 to <32 x i8>*
  %464 = load <32 x i8>, <32 x i8>* %463, align 1
  %465 = getelementptr inbounds i8, i8* %0, i64 1
  %466 = bitcast i8* %465 to <32 x i8>*
  %467 = load <32 x i8>, <32 x i8>* %466, align 1
  %468 = sext i32 %1 to i64
  %469 = icmp sgt i32 %9, 0
  br i1 %469, label %470, label %650

470:                                              ; preds = %462
  %471 = shufflevector <32 x i8> %464, <32 x i8> %467, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %472 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %471, <32 x i8> %461) #5
  %473 = add <16 x i16> %472, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %474 = ashr <16 x i16> %473, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %475 = shufflevector <32 x i8> %464, <32 x i8> %467, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %476 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %475, <32 x i8> %461) #5
  %477 = add <16 x i16> %476, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %478 = ashr <16 x i16> %477, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %479 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %474, <16 x i16> %478) #5
  %480 = icmp eq i32 %8, 0
  %481 = sext i32 %7 to i64
  %482 = sext i32 %5 to i64
  br label %483

483:                                              ; preds = %519, %470
  %484 = phi <16 x i16> [ zeroinitializer, %470 ], [ %533, %519 ]
  %485 = phi <8 x i32> [ zeroinitializer, %470 ], [ %536, %519 ]
  %486 = phi i8* [ %0, %470 ], [ %491, %519 ]
  %487 = phi i8* [ %4, %470 ], [ %537, %519 ]
  %488 = phi i8* [ %6, %470 ], [ %522, %519 ]
  %489 = phi i32 [ 0, %470 ], [ %538, %519 ]
  %490 = phi <32 x i8> [ %479, %470 ], [ %507, %519 ]
  %491 = getelementptr inbounds i8, i8* %486, i64 %468
  %492 = bitcast i8* %487 to <32 x i8>*
  %493 = load <32 x i8>, <32 x i8>* %492, align 1
  %494 = bitcast i8* %491 to <32 x i8>*
  %495 = load <32 x i8>, <32 x i8>* %494, align 1
  %496 = getelementptr inbounds i8, i8* %491, i64 1
  %497 = bitcast i8* %496 to <32 x i8>*
  %498 = load <32 x i8>, <32 x i8>* %497, align 1
  %499 = shufflevector <32 x i8> %495, <32 x i8> %498, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %500 = shufflevector <32 x i8> %495, <32 x i8> %498, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %501 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %499, <32 x i8> %461) #5
  %502 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %500, <32 x i8> %461) #5
  %503 = add <16 x i16> %501, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %504 = add <16 x i16> %502, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %505 = ashr <16 x i16> %503, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %506 = ashr <16 x i16> %504, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %507 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %505, <16 x i16> %506) #5
  %508 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %490, <32 x i8> %507) #5
  br i1 %480, label %516, label %509

509:                                              ; preds = %483
  %510 = bitcast i8* %488 to <32 x i8>*
  %511 = load <32 x i8>, <32 x i8>* %510, align 1
  %512 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %508, <32 x i8> %511) #5
  %513 = shufflevector <32 x i8> %512, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %514 = shufflevector <32 x i8> %512, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %515 = getelementptr inbounds i8, i8* %488, i64 %481
  br label %519

516:                                              ; preds = %483
  %517 = shufflevector <32 x i8> %508, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %518 = shufflevector <32 x i8> %508, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  br label %519

519:                                              ; preds = %516, %509
  %520 = phi <32 x i8> [ %513, %509 ], [ %517, %516 ]
  %521 = phi <32 x i8> [ %514, %509 ], [ %518, %516 ]
  %522 = phi i8* [ %515, %509 ], [ %488, %516 ]
  %523 = shufflevector <32 x i8> %493, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %524 = shufflevector <32 x i8> %493, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %525 = bitcast <32 x i8> %520 to <16 x i16>
  %526 = bitcast <32 x i8> %523 to <16 x i16>
  %527 = sub <16 x i16> %525, %526
  %528 = bitcast <32 x i8> %521 to <16 x i16>
  %529 = bitcast <32 x i8> %524 to <16 x i16>
  %530 = sub <16 x i16> %528, %529
  %531 = add <16 x i16> %527, %484
  %532 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %527, <16 x i16> %527) #5
  %533 = add <16 x i16> %531, %530
  %534 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %530, <16 x i16> %530) #5
  %535 = add <8 x i32> %532, %485
  %536 = add <8 x i32> %535, %534
  %537 = getelementptr inbounds i8, i8* %487, i64 %482
  %538 = add nuw nsw i32 %489, 1
  %539 = icmp eq i32 %538, %9
  br i1 %539, label %646, label %483

540:                                              ; preds = %455
  %541 = shl i32 %3, 5
  %542 = sext i32 %541 to i64
  %543 = getelementptr inbounds <{ [256 x i8], [256 x i8] }>, <{ [256 x i8], [256 x i8] }>* @bilinear_filters_avx2, i64 0, i32 0, i64 %542
  %544 = bitcast i8* %543 to <32 x i8>*
  %545 = load <32 x i8>, <32 x i8>* %544, align 32
  %546 = bitcast i8* %0 to <32 x i8>*
  %547 = load <32 x i8>, <32 x i8>* %546, align 1
  %548 = getelementptr inbounds i8, i8* %0, i64 1
  %549 = bitcast i8* %548 to <32 x i8>*
  %550 = load <32 x i8>, <32 x i8>* %549, align 1
  %551 = sext i32 %1 to i64
  %552 = icmp sgt i32 %9, 0
  br i1 %552, label %553, label %650

553:                                              ; preds = %540
  %554 = shufflevector <32 x i8> %547, <32 x i8> %550, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %555 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %554, <32 x i8> %461) #5
  %556 = add <16 x i16> %555, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %557 = ashr <16 x i16> %556, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %558 = shufflevector <32 x i8> %547, <32 x i8> %550, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %559 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %558, <32 x i8> %461) #5
  %560 = add <16 x i16> %559, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %561 = ashr <16 x i16> %560, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %562 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %557, <16 x i16> %561) #5
  %563 = icmp eq i32 %8, 0
  %564 = sext i32 %7 to i64
  %565 = sext i32 %5 to i64
  br label %566

566:                                              ; preds = %611, %553
  %567 = phi <16 x i16> [ zeroinitializer, %553 ], [ %625, %611 ]
  %568 = phi <8 x i32> [ zeroinitializer, %553 ], [ %628, %611 ]
  %569 = phi i8* [ %0, %553 ], [ %574, %611 ]
  %570 = phi i8* [ %4, %553 ], [ %629, %611 ]
  %571 = phi i8* [ %6, %553 ], [ %614, %611 ]
  %572 = phi i32 [ 0, %553 ], [ %630, %611 ]
  %573 = phi <32 x i8> [ %562, %553 ], [ %590, %611 ]
  %574 = getelementptr inbounds i8, i8* %569, i64 %551
  %575 = bitcast i8* %570 to <32 x i8>*
  %576 = load <32 x i8>, <32 x i8>* %575, align 1
  %577 = bitcast i8* %574 to <32 x i8>*
  %578 = load <32 x i8>, <32 x i8>* %577, align 1
  %579 = getelementptr inbounds i8, i8* %574, i64 1
  %580 = bitcast i8* %579 to <32 x i8>*
  %581 = load <32 x i8>, <32 x i8>* %580, align 1
  %582 = shufflevector <32 x i8> %578, <32 x i8> %581, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %583 = shufflevector <32 x i8> %578, <32 x i8> %581, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %584 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %582, <32 x i8> %461) #5
  %585 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %583, <32 x i8> %461) #5
  %586 = add <16 x i16> %584, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %587 = add <16 x i16> %585, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %588 = ashr <16 x i16> %586, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %589 = ashr <16 x i16> %587, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %590 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %588, <16 x i16> %589) #5
  %591 = shufflevector <32 x i8> %573, <32 x i8> %590, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %592 = shufflevector <32 x i8> %573, <32 x i8> %590, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %593 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %591, <32 x i8> %545) #5
  %594 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %592, <32 x i8> %545) #5
  %595 = add <16 x i16> %593, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %596 = add <16 x i16> %594, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %597 = ashr <16 x i16> %595, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %598 = bitcast <16 x i16> %597 to <4 x i64>
  %599 = ashr <16 x i16> %596, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %600 = bitcast <16 x i16> %599 to <4 x i64>
  br i1 %563, label %611, label %601

601:                                              ; preds = %566
  %602 = bitcast i8* %571 to <32 x i8>*
  %603 = load <32 x i8>, <32 x i8>* %602, align 1
  %604 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %597, <16 x i16> %599) #5
  %605 = tail call <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8> %604, <32 x i8> %603) #5
  %606 = shufflevector <32 x i8> %605, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %607 = bitcast <32 x i8> %606 to <4 x i64>
  %608 = shufflevector <32 x i8> %605, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %609 = bitcast <32 x i8> %608 to <4 x i64>
  %610 = getelementptr inbounds i8, i8* %571, i64 %564
  br label %611

611:                                              ; preds = %601, %566
  %612 = phi <4 x i64> [ %607, %601 ], [ %598, %566 ]
  %613 = phi <4 x i64> [ %609, %601 ], [ %600, %566 ]
  %614 = phi i8* [ %610, %601 ], [ %571, %566 ]
  %615 = shufflevector <32 x i8> %576, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %616 = shufflevector <32 x i8> %576, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %617 = bitcast <4 x i64> %612 to <16 x i16>
  %618 = bitcast <32 x i8> %615 to <16 x i16>
  %619 = sub <16 x i16> %617, %618
  %620 = bitcast <4 x i64> %613 to <16 x i16>
  %621 = bitcast <32 x i8> %616 to <16 x i16>
  %622 = sub <16 x i16> %620, %621
  %623 = add <16 x i16> %619, %567
  %624 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %619, <16 x i16> %619) #5
  %625 = add <16 x i16> %623, %622
  %626 = tail call <8 x i32> @llvm.x86.avx2.pmadd.wd(<16 x i16> %622, <16 x i16> %622) #5
  %627 = add <8 x i32> %624, %568
  %628 = add <8 x i32> %627, %626
  %629 = getelementptr inbounds i8, i8* %570, i64 %565
  %630 = add nuw nsw i32 %572, 1
  %631 = icmp eq i32 %630, %9
  br i1 %631, label %648, label %566

632:                                              ; preds = %167
  %633 = bitcast <8 x i32> %184 to <4 x i64>
  br label %650

634:                                              ; preds = %44
  %635 = bitcast <8 x i32> %61 to <4 x i64>
  br label %650

636:                                              ; preds = %99
  %637 = bitcast <8 x i32> %116 to <4 x i64>
  br label %650

638:                                              ; preds = %224
  %639 = bitcast <8 x i32> %241 to <4 x i64>
  br label %650

640:                                              ; preds = %289
  %641 = bitcast <8 x i32> %306 to <4 x i64>
  br label %650

642:                                              ; preds = %365
  %643 = bitcast <8 x i32> %382 to <4 x i64>
  br label %650

644:                                              ; preds = %433
  %645 = bitcast <8 x i32> %450 to <4 x i64>
  br label %650

646:                                              ; preds = %519
  %647 = bitcast <8 x i32> %536 to <4 x i64>
  br label %650

648:                                              ; preds = %611
  %649 = bitcast <8 x i32> %628 to <4 x i64>
  br label %650

650:                                              ; preds = %648, %646, %644, %642, %640, %638, %636, %634, %632, %540, %462, %387, %310, %248, %192, %120, %66, %14
  %651 = phi <16 x i16> [ zeroinitializer, %14 ], [ zeroinitializer, %66 ], [ zeroinitializer, %120 ], [ zeroinitializer, %192 ], [ zeroinitializer, %248 ], [ zeroinitializer, %310 ], [ zeroinitializer, %387 ], [ zeroinitializer, %462 ], [ zeroinitializer, %540 ], [ %181, %632 ], [ %58, %634 ], [ %113, %636 ], [ %238, %638 ], [ %303, %640 ], [ %379, %642 ], [ %447, %644 ], [ %533, %646 ], [ %625, %648 ]
  %652 = phi <8 x i32> [ zeroinitializer, %14 ], [ zeroinitializer, %66 ], [ zeroinitializer, %120 ], [ zeroinitializer, %192 ], [ zeroinitializer, %248 ], [ zeroinitializer, %310 ], [ zeroinitializer, %387 ], [ zeroinitializer, %462 ], [ zeroinitializer, %540 ], [ %184, %632 ], [ %61, %634 ], [ %116, %636 ], [ %241, %638 ], [ %306, %640 ], [ %382, %642 ], [ %450, %644 ], [ %536, %646 ], [ %628, %648 ]
  %653 = phi <4 x i64> [ zeroinitializer, %14 ], [ zeroinitializer, %66 ], [ zeroinitializer, %120 ], [ zeroinitializer, %192 ], [ zeroinitializer, %248 ], [ zeroinitializer, %310 ], [ zeroinitializer, %387 ], [ zeroinitializer, %462 ], [ zeroinitializer, %540 ], [ %633, %632 ], [ %635, %634 ], [ %637, %636 ], [ %639, %638 ], [ %641, %640 ], [ %643, %642 ], [ %645, %644 ], [ %647, %646 ], [ %649, %648 ]
  %654 = ashr <16 x i16> %651, <i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15, i16 15>
  %655 = bitcast <4 x i64> %653 to <32 x i8>
  %656 = shufflevector <32 x i8> %655, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %657 = shufflevector <16 x i16> %651, <16 x i16> %654, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %658 = shufflevector <16 x i16> %651, <16 x i16> %654, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %659 = bitcast <32 x i8> %656 to <8 x i32>
  %660 = add <8 x i32> %652, %659
  %661 = bitcast <16 x i16> %657 to <8 x i32>
  %662 = bitcast <16 x i16> %658 to <8 x i32>
  %663 = add <8 x i32> %662, %661
  %664 = bitcast <8 x i32> %660 to <32 x i8>
  %665 = shufflevector <32 x i8> %664, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 32, i32 33, i32 34, i32 35, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 48, i32 49, i32 50, i32 51>
  %666 = bitcast <8 x i32> %663 to <32 x i8>
  %667 = shufflevector <32 x i8> %666, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 32, i32 33, i32 34, i32 35, i32 36, i32 37, i32 38, i32 39, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 48, i32 49, i32 50, i32 51, i32 52, i32 53, i32 54, i32 55>
  %668 = bitcast <32 x i8> %665 to <8 x i32>
  %669 = add <8 x i32> %660, %668
  %670 = bitcast <8 x i32> %669 to <4 x i64>
  %671 = bitcast <32 x i8> %667 to <8 x i32>
  %672 = add <8 x i32> %663, %671
  %673 = shufflevector <4 x i64> %670, <4 x i64> undef, <2 x i32> <i32 0, i32 undef>
  %674 = bitcast <2 x i64> %673 to <4 x i32>
  %675 = extractelement <4 x i32> %674, i32 0
  %676 = extractelement <8 x i32> %669, i32 4
  %677 = add nsw i32 %675, %676
  store i32 %677, i32* %10, align 4
  %678 = bitcast <8 x i32> %672 to <32 x i8>
  %679 = shufflevector <32 x i8> %678, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 32, i32 33, i32 34, i32 35, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 48, i32 49, i32 50, i32 51>
  %680 = bitcast <32 x i8> %679 to <8 x i32>
  %681 = add <8 x i32> %672, %680
  %682 = bitcast <8 x i32> %681 to <4 x i64>
  %683 = shufflevector <4 x i64> %682, <4 x i64> undef, <2 x i32> <i32 0, i32 undef>
  %684 = bitcast <2 x i64> %683 to <4 x i32>
  %685 = extractelement <4 x i32> %684, i32 0
  %686 = extractelement <8 x i32> %681, i32 4
  %687 = add nsw i32 %685, %686
  ret i32 %687
}

; Function Attrs: nounwind readnone
declare <32 x i8> @llvm.x86.avx2.pavg.b(<32 x i8>, <32 x i8>) #3

; Function Attrs: nounwind readnone
declare <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16>, <16 x i16>) #3

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="256" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone }
attributes #4 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="256" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
