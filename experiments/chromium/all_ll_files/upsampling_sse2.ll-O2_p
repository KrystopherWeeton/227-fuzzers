; ModuleID = '../../third_party/libwebp/src/dsp/upsampling_sse2.c'
source_filename = "../../third_party/libwebp/src/dsp/upsampling_sse2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@WebPUpsamplers = external local_unnamed_addr global [0 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*], align 8
@WebPYUV444Converters = external local_unnamed_addr global [0 x void (i8*, i8*, i8*, i8*, i32)*], align 8

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @WebPInitUpsamplersSSE2() local_unnamed_addr #0 {
  store void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)* @UpsampleRgbaLinePair_SSE2, void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)** getelementptr inbounds ([0 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*], [0 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*]* @WebPUpsamplers, i64 0, i64 1), align 8
  store void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)* @UpsampleBgraLinePair_SSE2, void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)** getelementptr inbounds ([0 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*], [0 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*]* @WebPUpsamplers, i64 0, i64 3), align 8
  store <2 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*> <void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)* @UpsampleRgbaLinePair_SSE2, void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)* @UpsampleBgraLinePair_SSE2>, <2 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*>* bitcast (void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)** getelementptr inbounds ([0 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*], [0 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*]* @WebPUpsamplers, i64 0, i64 7) to <2 x void (i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32)*>*), align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @UpsampleRgbaLinePair_SSE2(i8*, i8*, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8*, i8*, i32) #1 {
  %10 = alloca [463 x i8], align 16
  %11 = alloca [17 x i8], align 16
  %12 = alloca [17 x i8], align 16
  %13 = alloca [17 x i8], align 16
  %14 = alloca [17 x i8], align 16
  %15 = getelementptr inbounds [463 x i8], [463 x i8]* %10, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 463, i8* nonnull %15) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 0, i64 463, i1 false)
  %16 = getelementptr inbounds [463 x i8], [463 x i8]* %10, i64 0, i64 15
  %17 = ptrtoint i8* %16 to i64
  %18 = and i64 %17, -16
  %19 = inttoptr i64 %18 to i8*
  %20 = getelementptr inbounds i8, i8* %19, i64 32
  %21 = load i8, i8* %2, align 1
  %22 = zext i8 %21 to i32
  %23 = load i8, i8* %4, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %24, %22
  %26 = lshr i32 %25, 1
  %27 = add nuw nsw i32 %26, 1
  %28 = load i8, i8* %3, align 1
  %29 = zext i8 %28 to i32
  %30 = load i8, i8* %5, align 1
  %31 = zext i8 %30 to i32
  %32 = add nuw nsw i32 %31, %29
  %33 = lshr i32 %32, 1
  %34 = add nuw nsw i32 %33, 1
  %35 = add nuw nsw i32 %27, %22
  %36 = lshr i32 %35, 1
  %37 = add nuw nsw i32 %34, %29
  %38 = lshr i32 %37, 1
  %39 = load i8, i8* %0, align 1
  %40 = zext i8 %39 to i32
  %41 = and i32 %36, 255
  %42 = and i32 %38, 255
  %43 = mul nuw nsw i32 %40, 19077
  %44 = lshr i32 %43, 8
  %45 = mul nuw nsw i32 %42, 26149
  %46 = lshr i32 %45, 8
  %47 = add nsw i32 %44, -14234
  %48 = add nsw i32 %47, %46
  %49 = icmp ult i32 %48, 16384
  %50 = lshr i32 %48, 6
  %51 = icmp slt i32 %48, 0
  %52 = select i1 %51, i32 0, i32 255
  %53 = select i1 %49, i32 %50, i32 %52
  %54 = trunc i32 %53 to i8
  store i8 %54, i8* %6, align 1
  %55 = mul nuw nsw i32 %41, 6419
  %56 = lshr i32 %55, 8
  %57 = mul nuw nsw i32 %42, 13320
  %58 = lshr i32 %57, 8
  %59 = add nuw nsw i32 %44, 8708
  %60 = sub nuw nsw i32 %59, %56
  %61 = sub nsw i32 %60, %58
  %62 = icmp ult i32 %61, 16384
  %63 = lshr i32 %61, 6
  %64 = icmp slt i32 %61, 0
  %65 = select i1 %64, i32 0, i32 255
  %66 = select i1 %62, i32 %63, i32 %65
  %67 = trunc i32 %66 to i8
  %68 = getelementptr inbounds i8, i8* %6, i64 1
  store i8 %67, i8* %68, align 1
  %69 = mul nuw nsw i32 %41, 33050
  %70 = lshr i32 %69, 8
  %71 = add nsw i32 %44, -17685
  %72 = add nsw i32 %71, %70
  %73 = icmp ult i32 %72, 16384
  %74 = lshr i32 %72, 6
  %75 = icmp slt i32 %72, 0
  %76 = select i1 %75, i32 0, i32 255
  %77 = select i1 %73, i32 %74, i32 %76
  %78 = trunc i32 %77 to i8
  %79 = getelementptr inbounds i8, i8* %6, i64 2
  store i8 %78, i8* %79, align 1
  %80 = getelementptr inbounds i8, i8* %6, i64 3
  store i8 -1, i8* %80, align 1
  %81 = icmp ne i8* %1, null
  br i1 %81, label %82, label %133

82:                                               ; preds = %9
  %83 = load i8, i8* %4, align 1
  %84 = zext i8 %83 to i32
  %85 = add nuw nsw i32 %27, %84
  %86 = lshr i32 %85, 1
  %87 = load i8, i8* %5, align 1
  %88 = zext i8 %87 to i32
  %89 = add nuw nsw i32 %34, %88
  %90 = lshr i32 %89, 1
  %91 = load i8, i8* %1, align 1
  %92 = zext i8 %91 to i32
  %93 = and i32 %86, 255
  %94 = and i32 %90, 255
  %95 = mul nuw nsw i32 %92, 19077
  %96 = lshr i32 %95, 8
  %97 = mul nuw nsw i32 %94, 26149
  %98 = lshr i32 %97, 8
  %99 = add nsw i32 %96, -14234
  %100 = add nsw i32 %99, %98
  %101 = icmp ult i32 %100, 16384
  %102 = lshr i32 %100, 6
  %103 = icmp slt i32 %100, 0
  %104 = select i1 %103, i32 0, i32 255
  %105 = select i1 %101, i32 %102, i32 %104
  %106 = trunc i32 %105 to i8
  store i8 %106, i8* %7, align 1
  %107 = mul nuw nsw i32 %93, 6419
  %108 = lshr i32 %107, 8
  %109 = mul nuw nsw i32 %94, 13320
  %110 = lshr i32 %109, 8
  %111 = add nuw nsw i32 %96, 8708
  %112 = sub nuw nsw i32 %111, %108
  %113 = sub nsw i32 %112, %110
  %114 = icmp ult i32 %113, 16384
  %115 = lshr i32 %113, 6
  %116 = icmp slt i32 %113, 0
  %117 = select i1 %116, i32 0, i32 255
  %118 = select i1 %114, i32 %115, i32 %117
  %119 = trunc i32 %118 to i8
  %120 = getelementptr inbounds i8, i8* %7, i64 1
  store i8 %119, i8* %120, align 1
  %121 = mul nuw nsw i32 %93, 33050
  %122 = lshr i32 %121, 8
  %123 = add nsw i32 %96, -17685
  %124 = add nsw i32 %123, %122
  %125 = icmp ult i32 %124, 16384
  %126 = lshr i32 %124, 6
  %127 = icmp slt i32 %124, 0
  %128 = select i1 %127, i32 0, i32 255
  %129 = select i1 %125, i32 %126, i32 %128
  %130 = trunc i32 %129 to i8
  %131 = getelementptr inbounds i8, i8* %7, i64 2
  store i8 %130, i8* %131, align 1
  %132 = getelementptr inbounds i8, i8* %7, i64 3
  store i8 -1, i8* %132, align 1
  br label %133

133:                                              ; preds = %82, %9
  %134 = icmp slt i32 %8, 34
  br i1 %134, label %272, label %135

135:                                              ; preds = %133
  %136 = inttoptr i64 %18 to <2 x i64>*
  %137 = inttoptr i64 %18 to <16 x i8>*
  %138 = getelementptr inbounds <2 x i64>, <2 x i64>* %136, i64 1
  %139 = bitcast <2 x i64>* %138 to <16 x i8>*
  %140 = getelementptr inbounds i8, i8* %19, i64 64
  %141 = bitcast i8* %140 to <16 x i8>*
  %142 = getelementptr inbounds i8, i8* %19, i64 80
  %143 = bitcast i8* %142 to <16 x i8>*
  %144 = bitcast i8* %20 to <16 x i8>*
  %145 = getelementptr inbounds i8, i8* %19, i64 48
  %146 = bitcast i8* %145 to <16 x i8>*
  %147 = getelementptr inbounds i8, i8* %19, i64 96
  %148 = bitcast i8* %147 to <16 x i8>*
  %149 = getelementptr inbounds i8, i8* %19, i64 112
  %150 = bitcast i8* %149 to <16 x i8>*
  br label %151

151:                                              ; preds = %135, %262
  %152 = phi i64 [ 1, %135 ], [ %268, %262 ]
  %153 = phi i64 [ 0, %135 ], [ %263, %262 ]
  %154 = phi i64 [ 33, %135 ], [ %264, %262 ]
  %155 = getelementptr inbounds i8, i8* %2, i64 %153
  %156 = bitcast i8* %155 to <2 x i64>*
  %157 = load <2 x i64>, <2 x i64>* %156, align 1
  %158 = getelementptr inbounds i8, i8* %155, i64 1
  %159 = bitcast i8* %158 to <2 x i64>*
  %160 = load <2 x i64>, <2 x i64>* %159, align 1
  %161 = getelementptr inbounds i8, i8* %4, i64 %153
  %162 = bitcast i8* %161 to <2 x i64>*
  %163 = load <2 x i64>, <2 x i64>* %162, align 1
  %164 = getelementptr inbounds i8, i8* %161, i64 1
  %165 = bitcast i8* %164 to <2 x i64>*
  %166 = load <2 x i64>, <2 x i64>* %165, align 1
  %167 = bitcast <2 x i64> %157 to <16 x i8>
  %168 = bitcast <2 x i64> %166 to <16 x i8>
  %169 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %167, <16 x i8> %168) #6
  %170 = bitcast <2 x i64> %160 to <16 x i8>
  %171 = bitcast <2 x i64> %163 to <16 x i8>
  %172 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %170, <16 x i8> %171) #6
  %173 = xor <16 x i8> %172, %169
  %174 = bitcast <16 x i8> %173 to <2 x i64>
  %175 = xor <2 x i64> %166, %157
  %176 = xor <2 x i64> %163, %160
  %177 = or <2 x i64> %175, %176
  %178 = or <2 x i64> %177, %174
  %179 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %169, <16 x i8> %172) #6
  %180 = bitcast <2 x i64> %178 to <16 x i8>
  %181 = and <16 x i8> %180, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %182 = sub <16 x i8> %179, %181
  %183 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %182, <16 x i8> %172) #6
  %184 = and <2 x i64> %176, %174
  %185 = xor <16 x i8> %182, %172
  %186 = bitcast <2 x i64> %184 to <16 x i8>
  %187 = or <16 x i8> %185, %186
  %188 = and <16 x i8> %187, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %189 = sub <16 x i8> %183, %188
  %190 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %182, <16 x i8> %169) #6
  %191 = and <2 x i64> %175, %174
  %192 = xor <16 x i8> %182, %169
  %193 = bitcast <2 x i64> %191 to <16 x i8>
  %194 = or <16 x i8> %192, %193
  %195 = and <16 x i8> %194, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %196 = sub <16 x i8> %190, %195
  %197 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %167, <16 x i8> %189) #6
  %198 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %170, <16 x i8> %196) #6
  %199 = shufflevector <16 x i8> %197, <16 x i8> %198, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %200 = shufflevector <16 x i8> %197, <16 x i8> %198, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  store <16 x i8> %199, <16 x i8>* %137, align 16
  store <16 x i8> %200, <16 x i8>* %139, align 16
  %201 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %171, <16 x i8> %196) #6
  %202 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %168, <16 x i8> %189) #6
  %203 = shufflevector <16 x i8> %201, <16 x i8> %202, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %204 = shufflevector <16 x i8> %201, <16 x i8> %202, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  store <16 x i8> %203, <16 x i8>* %141, align 16
  store <16 x i8> %204, <16 x i8>* %143, align 16
  %205 = getelementptr inbounds i8, i8* %3, i64 %153
  %206 = bitcast i8* %205 to <2 x i64>*
  %207 = load <2 x i64>, <2 x i64>* %206, align 1
  %208 = getelementptr inbounds i8, i8* %205, i64 1
  %209 = bitcast i8* %208 to <2 x i64>*
  %210 = load <2 x i64>, <2 x i64>* %209, align 1
  %211 = getelementptr inbounds i8, i8* %5, i64 %153
  %212 = bitcast i8* %211 to <2 x i64>*
  %213 = load <2 x i64>, <2 x i64>* %212, align 1
  %214 = getelementptr inbounds i8, i8* %211, i64 1
  %215 = bitcast i8* %214 to <2 x i64>*
  %216 = load <2 x i64>, <2 x i64>* %215, align 1
  %217 = bitcast <2 x i64> %207 to <16 x i8>
  %218 = bitcast <2 x i64> %216 to <16 x i8>
  %219 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %217, <16 x i8> %218) #6
  %220 = bitcast <2 x i64> %210 to <16 x i8>
  %221 = bitcast <2 x i64> %213 to <16 x i8>
  %222 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %220, <16 x i8> %221) #6
  %223 = xor <16 x i8> %222, %219
  %224 = bitcast <16 x i8> %223 to <2 x i64>
  %225 = xor <2 x i64> %216, %207
  %226 = xor <2 x i64> %213, %210
  %227 = or <2 x i64> %225, %226
  %228 = or <2 x i64> %227, %224
  %229 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %219, <16 x i8> %222) #6
  %230 = bitcast <2 x i64> %228 to <16 x i8>
  %231 = and <16 x i8> %230, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %232 = sub <16 x i8> %229, %231
  %233 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %232, <16 x i8> %222) #6
  %234 = and <2 x i64> %226, %224
  %235 = xor <16 x i8> %232, %222
  %236 = bitcast <2 x i64> %234 to <16 x i8>
  %237 = or <16 x i8> %235, %236
  %238 = and <16 x i8> %237, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %239 = sub <16 x i8> %233, %238
  %240 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %232, <16 x i8> %219) #6
  %241 = and <2 x i64> %225, %224
  %242 = xor <16 x i8> %232, %219
  %243 = bitcast <2 x i64> %241 to <16 x i8>
  %244 = or <16 x i8> %242, %243
  %245 = and <16 x i8> %244, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %246 = sub <16 x i8> %240, %245
  %247 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %217, <16 x i8> %239) #6
  %248 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %220, <16 x i8> %246) #6
  %249 = shufflevector <16 x i8> %247, <16 x i8> %248, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %250 = shufflevector <16 x i8> %247, <16 x i8> %248, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  store <16 x i8> %249, <16 x i8>* %144, align 16
  store <16 x i8> %250, <16 x i8>* %146, align 16
  %251 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %221, <16 x i8> %246) #6
  %252 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %218, <16 x i8> %239) #6
  %253 = shufflevector <16 x i8> %251, <16 x i8> %252, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %254 = shufflevector <16 x i8> %251, <16 x i8> %252, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  store <16 x i8> %253, <16 x i8>* %148, align 16
  store <16 x i8> %254, <16 x i8>* %150, align 16
  %255 = getelementptr inbounds i8, i8* %0, i64 %152
  %256 = shl i64 %152, 2
  %257 = and i64 %256, 4294967292
  %258 = getelementptr inbounds i8, i8* %6, i64 %257
  call void @VP8YuvToRgba32_SSE2(i8* %255, i8* %19, i8* %20, i8* %258) #6
  br i1 %81, label %259, label %262

259:                                              ; preds = %151
  %260 = getelementptr inbounds i8, i8* %1, i64 %152
  %261 = getelementptr inbounds i8, i8* %7, i64 %257
  call void @VP8YuvToRgba32_SSE2(i8* %260, i8* %140, i8* %147, i8* %261) #6
  br label %262

262:                                              ; preds = %151, %259
  %263 = add nuw i64 %153, 16
  %264 = add nuw i64 %154, 32
  %265 = trunc i64 %154 to i32
  %266 = add i32 %265, 33
  %267 = icmp sgt i32 %266, %8
  %268 = add nuw nsw i64 %152, 32
  br i1 %267, label %269, label %151

269:                                              ; preds = %262
  %270 = trunc i64 %154 to i32
  %271 = and i64 %263, 4294967280
  br label %272

272:                                              ; preds = %269, %133
  %273 = phi i32 [ 1, %133 ], [ %270, %269 ]
  %274 = phi i64 [ 0, %133 ], [ %271, %269 ]
  %275 = icmp sgt i32 %8, 1
  br i1 %275, label %276, label %455

276:                                              ; preds = %272
  %277 = add nuw nsw i32 %8, 1
  %278 = ashr i32 %277, 1
  %279 = lshr i32 %273, 1
  %280 = sub nsw i32 %278, %279
  %281 = getelementptr inbounds i8, i8* %19, i64 128
  %282 = getelementptr inbounds i8, i8* %19, i64 256
  %283 = getelementptr inbounds i8, i8* %19, i64 384
  %284 = icmp eq i8* %1, null
  %285 = getelementptr inbounds i8, i8* %19, i64 416
  %286 = select i1 %284, i8* null, i8* %285
  %287 = getelementptr inbounds [17 x i8], [17 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 17, i8* nonnull %287) #6
  %288 = getelementptr inbounds [17 x i8], [17 x i8]* %11, i64 0, i64 1
  %289 = getelementptr inbounds [17 x i8], [17 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 17, i8* nonnull %289) #6
  %290 = getelementptr inbounds [17 x i8], [17 x i8]* %12, i64 0, i64 1
  %291 = getelementptr inbounds i8, i8* %2, i64 %274
  %292 = sext i32 %280 to i64
  %293 = icmp ugt i32 %280, 16
  %294 = sub nsw i64 17, %292
  %295 = select i1 %293, i64 0, i64 %294
  %296 = getelementptr [17 x i8], [17 x i8]* %11, i64 0, i64 %292
  call void @llvm.memset.p0i8.i64(i8* align 1 %296, i8 -86, i64 %295, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %287, i8* align 1 %291, i64 %292, i1 false)
  %297 = getelementptr inbounds i8, i8* %4, i64 %274
  %298 = icmp ugt i32 %280, 16
  %299 = sub nsw i64 17, %292
  %300 = select i1 %298, i64 0, i64 %299
  %301 = getelementptr [17 x i8], [17 x i8]* %12, i64 0, i64 %292
  call void @llvm.memset.p0i8.i64(i8* align 1 %301, i8 -86, i64 %300, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %289, i8* align 1 %297, i64 %292, i1 false)
  %302 = getelementptr inbounds [17 x i8], [17 x i8]* %11, i64 0, i64 %292
  %303 = add nsw i32 %280, -1
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds [17 x i8], [17 x i8]* %11, i64 0, i64 %304
  %306 = load i8, i8* %305, align 1
  %307 = sub nsw i32 17, %280
  %308 = sext i32 %307 to i64
  call void @llvm.memset.p0i8.i64(i8* align 1 %302, i8 %306, i64 %308, i1 false)
  %309 = getelementptr inbounds [17 x i8], [17 x i8]* %12, i64 0, i64 %292
  %310 = getelementptr inbounds [17 x i8], [17 x i8]* %12, i64 0, i64 %304
  %311 = load i8, i8* %310, align 1
  call void @llvm.memset.p0i8.i64(i8* align 1 %309, i8 %311, i64 %308, i1 false)
  %312 = bitcast [17 x i8]* %11 to <2 x i64>*
  %313 = load <2 x i64>, <2 x i64>* %312, align 16
  %314 = bitcast i8* %288 to <2 x i64>*
  %315 = load <2 x i64>, <2 x i64>* %314, align 1
  %316 = bitcast [17 x i8]* %12 to <2 x i64>*
  %317 = load <2 x i64>, <2 x i64>* %316, align 16
  %318 = bitcast i8* %290 to <2 x i64>*
  %319 = load <2 x i64>, <2 x i64>* %318, align 1
  %320 = bitcast <2 x i64> %313 to <16 x i8>
  %321 = bitcast <2 x i64> %319 to <16 x i8>
  %322 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %320, <16 x i8> %321) #6
  %323 = bitcast <2 x i64> %315 to <16 x i8>
  %324 = bitcast <2 x i64> %317 to <16 x i8>
  %325 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %323, <16 x i8> %324) #6
  %326 = xor <16 x i8> %325, %322
  %327 = bitcast <16 x i8> %326 to <2 x i64>
  %328 = xor <2 x i64> %319, %313
  %329 = xor <2 x i64> %317, %315
  %330 = or <2 x i64> %328, %329
  %331 = or <2 x i64> %330, %327
  %332 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %322, <16 x i8> %325) #6
  %333 = bitcast <2 x i64> %331 to <16 x i8>
  %334 = and <16 x i8> %333, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %335 = sub <16 x i8> %332, %334
  %336 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %335, <16 x i8> %325) #6
  %337 = and <2 x i64> %329, %327
  %338 = xor <16 x i8> %335, %325
  %339 = bitcast <2 x i64> %337 to <16 x i8>
  %340 = or <16 x i8> %338, %339
  %341 = and <16 x i8> %340, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %342 = sub <16 x i8> %336, %341
  %343 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %335, <16 x i8> %322) #6
  %344 = and <2 x i64> %328, %327
  %345 = xor <16 x i8> %335, %322
  %346 = bitcast <2 x i64> %344 to <16 x i8>
  %347 = or <16 x i8> %345, %346
  %348 = and <16 x i8> %347, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %349 = sub <16 x i8> %343, %348
  %350 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %320, <16 x i8> %342) #6
  %351 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %323, <16 x i8> %349) #6
  %352 = shufflevector <16 x i8> %350, <16 x i8> %351, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %353 = shufflevector <16 x i8> %350, <16 x i8> %351, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %354 = inttoptr i64 %18 to <16 x i8>*
  store <16 x i8> %352, <16 x i8>* %354, align 16
  %355 = getelementptr inbounds i8, i8* %19, i64 16
  %356 = bitcast i8* %355 to <16 x i8>*
  store <16 x i8> %353, <16 x i8>* %356, align 16
  %357 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %324, <16 x i8> %349) #6
  %358 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %321, <16 x i8> %342) #6
  %359 = shufflevector <16 x i8> %357, <16 x i8> %358, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %360 = shufflevector <16 x i8> %357, <16 x i8> %358, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %361 = getelementptr inbounds i8, i8* %19, i64 64
  %362 = bitcast i8* %361 to <16 x i8>*
  store <16 x i8> %359, <16 x i8>* %362, align 16
  %363 = getelementptr inbounds i8, i8* %19, i64 80
  %364 = bitcast i8* %363 to <16 x i8>*
  store <16 x i8> %360, <16 x i8>* %364, align 16
  call void @llvm.lifetime.end.p0i8(i64 17, i8* nonnull %289) #6
  call void @llvm.lifetime.end.p0i8(i64 17, i8* nonnull %287) #6
  %365 = getelementptr inbounds [17 x i8], [17 x i8]* %13, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 17, i8* nonnull %365) #6
  %366 = getelementptr inbounds [17 x i8], [17 x i8]* %13, i64 0, i64 1
  %367 = getelementptr inbounds [17 x i8], [17 x i8]* %14, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 17, i8* nonnull %367) #6
  %368 = getelementptr inbounds [17 x i8], [17 x i8]* %14, i64 0, i64 1
  %369 = getelementptr inbounds i8, i8* %3, i64 %274
  %370 = icmp ugt i32 %280, 16
  %371 = sub nsw i64 17, %292
  %372 = select i1 %370, i64 0, i64 %371
  %373 = getelementptr [17 x i8], [17 x i8]* %13, i64 0, i64 %292
  call void @llvm.memset.p0i8.i64(i8* align 1 %373, i8 -86, i64 %372, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %365, i8* align 1 %369, i64 %292, i1 false)
  %374 = getelementptr inbounds i8, i8* %5, i64 %274
  %375 = icmp ugt i32 %280, 16
  %376 = sub nsw i64 17, %292
  %377 = select i1 %375, i64 0, i64 %376
  %378 = getelementptr [17 x i8], [17 x i8]* %14, i64 0, i64 %292
  call void @llvm.memset.p0i8.i64(i8* align 1 %378, i8 -86, i64 %377, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %367, i8* align 1 %374, i64 %292, i1 false)
  %379 = getelementptr inbounds [17 x i8], [17 x i8]* %13, i64 0, i64 %292
  %380 = getelementptr inbounds [17 x i8], [17 x i8]* %13, i64 0, i64 %304
  %381 = load i8, i8* %380, align 1
  call void @llvm.memset.p0i8.i64(i8* align 1 %379, i8 %381, i64 %308, i1 false)
  %382 = getelementptr inbounds [17 x i8], [17 x i8]* %14, i64 0, i64 %292
  %383 = getelementptr inbounds [17 x i8], [17 x i8]* %14, i64 0, i64 %304
  %384 = load i8, i8* %383, align 1
  call void @llvm.memset.p0i8.i64(i8* align 1 %382, i8 %384, i64 %308, i1 false)
  %385 = bitcast [17 x i8]* %13 to <2 x i64>*
  %386 = load <2 x i64>, <2 x i64>* %385, align 16
  %387 = bitcast i8* %366 to <2 x i64>*
  %388 = load <2 x i64>, <2 x i64>* %387, align 1
  %389 = bitcast [17 x i8]* %14 to <2 x i64>*
  %390 = load <2 x i64>, <2 x i64>* %389, align 16
  %391 = bitcast i8* %368 to <2 x i64>*
  %392 = load <2 x i64>, <2 x i64>* %391, align 1
  %393 = bitcast <2 x i64> %386 to <16 x i8>
  %394 = bitcast <2 x i64> %392 to <16 x i8>
  %395 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %393, <16 x i8> %394) #6
  %396 = bitcast <2 x i64> %388 to <16 x i8>
  %397 = bitcast <2 x i64> %390 to <16 x i8>
  %398 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %396, <16 x i8> %397) #6
  %399 = xor <16 x i8> %398, %395
  %400 = bitcast <16 x i8> %399 to <2 x i64>
  %401 = xor <2 x i64> %392, %386
  %402 = xor <2 x i64> %390, %388
  %403 = or <2 x i64> %401, %402
  %404 = or <2 x i64> %403, %400
  %405 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %395, <16 x i8> %398) #6
  %406 = bitcast <2 x i64> %404 to <16 x i8>
  %407 = and <16 x i8> %406, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %408 = sub <16 x i8> %405, %407
  %409 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %408, <16 x i8> %398) #6
  %410 = and <2 x i64> %402, %400
  %411 = xor <16 x i8> %408, %398
  %412 = bitcast <2 x i64> %410 to <16 x i8>
  %413 = or <16 x i8> %411, %412
  %414 = and <16 x i8> %413, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %415 = sub <16 x i8> %409, %414
  %416 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %408, <16 x i8> %395) #6
  %417 = and <2 x i64> %401, %400
  %418 = xor <16 x i8> %408, %395
  %419 = bitcast <2 x i64> %417 to <16 x i8>
  %420 = or <16 x i8> %418, %419
  %421 = and <16 x i8> %420, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %422 = sub <16 x i8> %416, %421
  %423 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %393, <16 x i8> %415) #6
  %424 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %396, <16 x i8> %422) #6
  %425 = shufflevector <16 x i8> %423, <16 x i8> %424, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %426 = shufflevector <16 x i8> %423, <16 x i8> %424, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %427 = bitcast i8* %20 to <16 x i8>*
  store <16 x i8> %425, <16 x i8>* %427, align 16
  %428 = getelementptr inbounds i8, i8* %19, i64 48
  %429 = bitcast i8* %428 to <16 x i8>*
  store <16 x i8> %426, <16 x i8>* %429, align 16
  %430 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %397, <16 x i8> %422) #6
  %431 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %394, <16 x i8> %415) #6
  %432 = shufflevector <16 x i8> %430, <16 x i8> %431, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %433 = shufflevector <16 x i8> %430, <16 x i8> %431, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %434 = getelementptr inbounds i8, i8* %19, i64 96
  %435 = bitcast i8* %434 to <16 x i8>*
  store <16 x i8> %432, <16 x i8>* %435, align 16
  %436 = getelementptr inbounds i8, i8* %19, i64 112
  %437 = bitcast i8* %436 to <16 x i8>*
  store <16 x i8> %433, <16 x i8>* %437, align 16
  call void @llvm.lifetime.end.p0i8(i64 17, i8* nonnull %367) #6
  call void @llvm.lifetime.end.p0i8(i64 17, i8* nonnull %365) #6
  %438 = zext i32 %273 to i64
  %439 = getelementptr inbounds i8, i8* %0, i64 %438
  %440 = sub nsw i32 %8, %273
  %441 = sext i32 %440 to i64
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %283, i8* align 1 %439, i64 %441, i1 false)
  br i1 %81, label %442, label %444

442:                                              ; preds = %276
  %443 = getelementptr inbounds i8, i8* %1, i64 %438
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %286, i8* align 1 %443, i64 %441, i1 false)
  br label %444

444:                                              ; preds = %276, %442
  call void @VP8YuvToRgba32_SSE2(i8* %283, i8* %19, i8* %20, i8* %281) #6
  %445 = icmp eq i8* %286, null
  br i1 %445, label %447, label %446

446:                                              ; preds = %444
  call void @VP8YuvToRgba32_SSE2(i8* nonnull %286, i8* %361, i8* %434, i8* %282) #6
  br label %447

447:                                              ; preds = %444, %446
  %448 = shl nsw i32 %273, 2
  %449 = zext i32 %448 to i64
  %450 = getelementptr inbounds i8, i8* %6, i64 %449
  %451 = shl nsw i32 %440, 2
  %452 = sext i32 %451 to i64
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %450, i8* align 16 %281, i64 %452, i1 false)
  br i1 %81, label %453, label %455

453:                                              ; preds = %447
  %454 = getelementptr inbounds i8, i8* %7, i64 %449
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %454, i8* align 16 %282, i64 %452, i1 false)
  br label %455

455:                                              ; preds = %447, %453, %272
  call void @llvm.lifetime.end.p0i8(i64 463, i8* nonnull %15) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @UpsampleBgraLinePair_SSE2(i8*, i8*, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8* nocapture readonly, i8*, i8*, i32) #1 {
  %10 = alloca [463 x i8], align 16
  %11 = alloca [17 x i8], align 16
  %12 = alloca [17 x i8], align 16
  %13 = alloca [17 x i8], align 16
  %14 = alloca [17 x i8], align 16
  %15 = getelementptr inbounds [463 x i8], [463 x i8]* %10, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 463, i8* nonnull %15) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 0, i64 463, i1 false)
  %16 = getelementptr inbounds [463 x i8], [463 x i8]* %10, i64 0, i64 15
  %17 = ptrtoint i8* %16 to i64
  %18 = and i64 %17, -16
  %19 = inttoptr i64 %18 to i8*
  %20 = getelementptr inbounds i8, i8* %19, i64 32
  %21 = load i8, i8* %2, align 1
  %22 = zext i8 %21 to i32
  %23 = load i8, i8* %4, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %24, %22
  %26 = lshr i32 %25, 1
  %27 = add nuw nsw i32 %26, 1
  %28 = load i8, i8* %3, align 1
  %29 = zext i8 %28 to i32
  %30 = load i8, i8* %5, align 1
  %31 = zext i8 %30 to i32
  %32 = add nuw nsw i32 %31, %29
  %33 = lshr i32 %32, 1
  %34 = add nuw nsw i32 %33, 1
  %35 = add nuw nsw i32 %27, %22
  %36 = lshr i32 %35, 1
  %37 = add nuw nsw i32 %34, %29
  %38 = lshr i32 %37, 1
  %39 = load i8, i8* %0, align 1
  %40 = zext i8 %39 to i32
  %41 = and i32 %36, 255
  %42 = and i32 %38, 255
  %43 = mul nuw nsw i32 %40, 19077
  %44 = lshr i32 %43, 8
  %45 = mul nuw nsw i32 %41, 33050
  %46 = lshr i32 %45, 8
  %47 = add nsw i32 %44, -17685
  %48 = add nsw i32 %47, %46
  %49 = icmp ult i32 %48, 16384
  %50 = lshr i32 %48, 6
  %51 = icmp slt i32 %48, 0
  %52 = select i1 %51, i32 0, i32 255
  %53 = select i1 %49, i32 %50, i32 %52
  %54 = trunc i32 %53 to i8
  store i8 %54, i8* %6, align 1
  %55 = mul nuw nsw i32 %41, 6419
  %56 = lshr i32 %55, 8
  %57 = mul nuw nsw i32 %42, 13320
  %58 = lshr i32 %57, 8
  %59 = add nuw nsw i32 %44, 8708
  %60 = sub nuw nsw i32 %59, %56
  %61 = sub nsw i32 %60, %58
  %62 = icmp ult i32 %61, 16384
  %63 = lshr i32 %61, 6
  %64 = icmp slt i32 %61, 0
  %65 = select i1 %64, i32 0, i32 255
  %66 = select i1 %62, i32 %63, i32 %65
  %67 = trunc i32 %66 to i8
  %68 = getelementptr inbounds i8, i8* %6, i64 1
  store i8 %67, i8* %68, align 1
  %69 = mul nuw nsw i32 %42, 26149
  %70 = lshr i32 %69, 8
  %71 = add nsw i32 %44, -14234
  %72 = add nsw i32 %71, %70
  %73 = icmp ult i32 %72, 16384
  %74 = lshr i32 %72, 6
  %75 = icmp slt i32 %72, 0
  %76 = select i1 %75, i32 0, i32 255
  %77 = select i1 %73, i32 %74, i32 %76
  %78 = trunc i32 %77 to i8
  %79 = getelementptr inbounds i8, i8* %6, i64 2
  store i8 %78, i8* %79, align 1
  %80 = getelementptr inbounds i8, i8* %6, i64 3
  store i8 -1, i8* %80, align 1
  %81 = icmp ne i8* %1, null
  br i1 %81, label %82, label %133

82:                                               ; preds = %9
  %83 = load i8, i8* %4, align 1
  %84 = zext i8 %83 to i32
  %85 = add nuw nsw i32 %27, %84
  %86 = lshr i32 %85, 1
  %87 = load i8, i8* %5, align 1
  %88 = zext i8 %87 to i32
  %89 = add nuw nsw i32 %34, %88
  %90 = lshr i32 %89, 1
  %91 = load i8, i8* %1, align 1
  %92 = zext i8 %91 to i32
  %93 = and i32 %86, 255
  %94 = and i32 %90, 255
  %95 = mul nuw nsw i32 %92, 19077
  %96 = lshr i32 %95, 8
  %97 = mul nuw nsw i32 %93, 33050
  %98 = lshr i32 %97, 8
  %99 = add nsw i32 %96, -17685
  %100 = add nsw i32 %99, %98
  %101 = icmp ult i32 %100, 16384
  %102 = lshr i32 %100, 6
  %103 = icmp slt i32 %100, 0
  %104 = select i1 %103, i32 0, i32 255
  %105 = select i1 %101, i32 %102, i32 %104
  %106 = trunc i32 %105 to i8
  store i8 %106, i8* %7, align 1
  %107 = mul nuw nsw i32 %93, 6419
  %108 = lshr i32 %107, 8
  %109 = mul nuw nsw i32 %94, 13320
  %110 = lshr i32 %109, 8
  %111 = add nuw nsw i32 %96, 8708
  %112 = sub nuw nsw i32 %111, %108
  %113 = sub nsw i32 %112, %110
  %114 = icmp ult i32 %113, 16384
  %115 = lshr i32 %113, 6
  %116 = icmp slt i32 %113, 0
  %117 = select i1 %116, i32 0, i32 255
  %118 = select i1 %114, i32 %115, i32 %117
  %119 = trunc i32 %118 to i8
  %120 = getelementptr inbounds i8, i8* %7, i64 1
  store i8 %119, i8* %120, align 1
  %121 = mul nuw nsw i32 %94, 26149
  %122 = lshr i32 %121, 8
  %123 = add nsw i32 %96, -14234
  %124 = add nsw i32 %123, %122
  %125 = icmp ult i32 %124, 16384
  %126 = lshr i32 %124, 6
  %127 = icmp slt i32 %124, 0
  %128 = select i1 %127, i32 0, i32 255
  %129 = select i1 %125, i32 %126, i32 %128
  %130 = trunc i32 %129 to i8
  %131 = getelementptr inbounds i8, i8* %7, i64 2
  store i8 %130, i8* %131, align 1
  %132 = getelementptr inbounds i8, i8* %7, i64 3
  store i8 -1, i8* %132, align 1
  br label %133

133:                                              ; preds = %82, %9
  %134 = icmp slt i32 %8, 34
  br i1 %134, label %272, label %135

135:                                              ; preds = %133
  %136 = inttoptr i64 %18 to <2 x i64>*
  %137 = inttoptr i64 %18 to <16 x i8>*
  %138 = getelementptr inbounds <2 x i64>, <2 x i64>* %136, i64 1
  %139 = bitcast <2 x i64>* %138 to <16 x i8>*
  %140 = getelementptr inbounds i8, i8* %19, i64 64
  %141 = bitcast i8* %140 to <16 x i8>*
  %142 = getelementptr inbounds i8, i8* %19, i64 80
  %143 = bitcast i8* %142 to <16 x i8>*
  %144 = bitcast i8* %20 to <16 x i8>*
  %145 = getelementptr inbounds i8, i8* %19, i64 48
  %146 = bitcast i8* %145 to <16 x i8>*
  %147 = getelementptr inbounds i8, i8* %19, i64 96
  %148 = bitcast i8* %147 to <16 x i8>*
  %149 = getelementptr inbounds i8, i8* %19, i64 112
  %150 = bitcast i8* %149 to <16 x i8>*
  br label %151

151:                                              ; preds = %135, %262
  %152 = phi i64 [ 1, %135 ], [ %268, %262 ]
  %153 = phi i64 [ 0, %135 ], [ %263, %262 ]
  %154 = phi i64 [ 33, %135 ], [ %264, %262 ]
  %155 = getelementptr inbounds i8, i8* %2, i64 %153
  %156 = bitcast i8* %155 to <2 x i64>*
  %157 = load <2 x i64>, <2 x i64>* %156, align 1
  %158 = getelementptr inbounds i8, i8* %155, i64 1
  %159 = bitcast i8* %158 to <2 x i64>*
  %160 = load <2 x i64>, <2 x i64>* %159, align 1
  %161 = getelementptr inbounds i8, i8* %4, i64 %153
  %162 = bitcast i8* %161 to <2 x i64>*
  %163 = load <2 x i64>, <2 x i64>* %162, align 1
  %164 = getelementptr inbounds i8, i8* %161, i64 1
  %165 = bitcast i8* %164 to <2 x i64>*
  %166 = load <2 x i64>, <2 x i64>* %165, align 1
  %167 = bitcast <2 x i64> %157 to <16 x i8>
  %168 = bitcast <2 x i64> %166 to <16 x i8>
  %169 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %167, <16 x i8> %168) #6
  %170 = bitcast <2 x i64> %160 to <16 x i8>
  %171 = bitcast <2 x i64> %163 to <16 x i8>
  %172 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %170, <16 x i8> %171) #6
  %173 = xor <16 x i8> %172, %169
  %174 = bitcast <16 x i8> %173 to <2 x i64>
  %175 = xor <2 x i64> %166, %157
  %176 = xor <2 x i64> %163, %160
  %177 = or <2 x i64> %175, %176
  %178 = or <2 x i64> %177, %174
  %179 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %169, <16 x i8> %172) #6
  %180 = bitcast <2 x i64> %178 to <16 x i8>
  %181 = and <16 x i8> %180, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %182 = sub <16 x i8> %179, %181
  %183 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %182, <16 x i8> %172) #6
  %184 = and <2 x i64> %176, %174
  %185 = xor <16 x i8> %182, %172
  %186 = bitcast <2 x i64> %184 to <16 x i8>
  %187 = or <16 x i8> %185, %186
  %188 = and <16 x i8> %187, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %189 = sub <16 x i8> %183, %188
  %190 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %182, <16 x i8> %169) #6
  %191 = and <2 x i64> %175, %174
  %192 = xor <16 x i8> %182, %169
  %193 = bitcast <2 x i64> %191 to <16 x i8>
  %194 = or <16 x i8> %192, %193
  %195 = and <16 x i8> %194, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %196 = sub <16 x i8> %190, %195
  %197 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %167, <16 x i8> %189) #6
  %198 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %170, <16 x i8> %196) #6
  %199 = shufflevector <16 x i8> %197, <16 x i8> %198, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %200 = shufflevector <16 x i8> %197, <16 x i8> %198, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  store <16 x i8> %199, <16 x i8>* %137, align 16
  store <16 x i8> %200, <16 x i8>* %139, align 16
  %201 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %171, <16 x i8> %196) #6
  %202 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %168, <16 x i8> %189) #6
  %203 = shufflevector <16 x i8> %201, <16 x i8> %202, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %204 = shufflevector <16 x i8> %201, <16 x i8> %202, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  store <16 x i8> %203, <16 x i8>* %141, align 16
  store <16 x i8> %204, <16 x i8>* %143, align 16
  %205 = getelementptr inbounds i8, i8* %3, i64 %153
  %206 = bitcast i8* %205 to <2 x i64>*
  %207 = load <2 x i64>, <2 x i64>* %206, align 1
  %208 = getelementptr inbounds i8, i8* %205, i64 1
  %209 = bitcast i8* %208 to <2 x i64>*
  %210 = load <2 x i64>, <2 x i64>* %209, align 1
  %211 = getelementptr inbounds i8, i8* %5, i64 %153
  %212 = bitcast i8* %211 to <2 x i64>*
  %213 = load <2 x i64>, <2 x i64>* %212, align 1
  %214 = getelementptr inbounds i8, i8* %211, i64 1
  %215 = bitcast i8* %214 to <2 x i64>*
  %216 = load <2 x i64>, <2 x i64>* %215, align 1
  %217 = bitcast <2 x i64> %207 to <16 x i8>
  %218 = bitcast <2 x i64> %216 to <16 x i8>
  %219 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %217, <16 x i8> %218) #6
  %220 = bitcast <2 x i64> %210 to <16 x i8>
  %221 = bitcast <2 x i64> %213 to <16 x i8>
  %222 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %220, <16 x i8> %221) #6
  %223 = xor <16 x i8> %222, %219
  %224 = bitcast <16 x i8> %223 to <2 x i64>
  %225 = xor <2 x i64> %216, %207
  %226 = xor <2 x i64> %213, %210
  %227 = or <2 x i64> %225, %226
  %228 = or <2 x i64> %227, %224
  %229 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %219, <16 x i8> %222) #6
  %230 = bitcast <2 x i64> %228 to <16 x i8>
  %231 = and <16 x i8> %230, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %232 = sub <16 x i8> %229, %231
  %233 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %232, <16 x i8> %222) #6
  %234 = and <2 x i64> %226, %224
  %235 = xor <16 x i8> %232, %222
  %236 = bitcast <2 x i64> %234 to <16 x i8>
  %237 = or <16 x i8> %235, %236
  %238 = and <16 x i8> %237, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %239 = sub <16 x i8> %233, %238
  %240 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %232, <16 x i8> %219) #6
  %241 = and <2 x i64> %225, %224
  %242 = xor <16 x i8> %232, %219
  %243 = bitcast <2 x i64> %241 to <16 x i8>
  %244 = or <16 x i8> %242, %243
  %245 = and <16 x i8> %244, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %246 = sub <16 x i8> %240, %245
  %247 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %217, <16 x i8> %239) #6
  %248 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %220, <16 x i8> %246) #6
  %249 = shufflevector <16 x i8> %247, <16 x i8> %248, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %250 = shufflevector <16 x i8> %247, <16 x i8> %248, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  store <16 x i8> %249, <16 x i8>* %144, align 16
  store <16 x i8> %250, <16 x i8>* %146, align 16
  %251 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %221, <16 x i8> %246) #6
  %252 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %218, <16 x i8> %239) #6
  %253 = shufflevector <16 x i8> %251, <16 x i8> %252, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %254 = shufflevector <16 x i8> %251, <16 x i8> %252, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  store <16 x i8> %253, <16 x i8>* %148, align 16
  store <16 x i8> %254, <16 x i8>* %150, align 16
  %255 = getelementptr inbounds i8, i8* %0, i64 %152
  %256 = shl i64 %152, 2
  %257 = and i64 %256, 4294967292
  %258 = getelementptr inbounds i8, i8* %6, i64 %257
  call void @VP8YuvToBgra32_SSE2(i8* %255, i8* %19, i8* %20, i8* %258) #6
  br i1 %81, label %259, label %262

259:                                              ; preds = %151
  %260 = getelementptr inbounds i8, i8* %1, i64 %152
  %261 = getelementptr inbounds i8, i8* %7, i64 %257
  call void @VP8YuvToBgra32_SSE2(i8* %260, i8* %140, i8* %147, i8* %261) #6
  br label %262

262:                                              ; preds = %151, %259
  %263 = add nuw i64 %153, 16
  %264 = add nuw i64 %154, 32
  %265 = trunc i64 %154 to i32
  %266 = add i32 %265, 33
  %267 = icmp sgt i32 %266, %8
  %268 = add nuw nsw i64 %152, 32
  br i1 %267, label %269, label %151

269:                                              ; preds = %262
  %270 = trunc i64 %154 to i32
  %271 = and i64 %263, 4294967280
  br label %272

272:                                              ; preds = %269, %133
  %273 = phi i32 [ 1, %133 ], [ %270, %269 ]
  %274 = phi i64 [ 0, %133 ], [ %271, %269 ]
  %275 = icmp sgt i32 %8, 1
  br i1 %275, label %276, label %455

276:                                              ; preds = %272
  %277 = add nuw nsw i32 %8, 1
  %278 = ashr i32 %277, 1
  %279 = lshr i32 %273, 1
  %280 = sub nsw i32 %278, %279
  %281 = getelementptr inbounds i8, i8* %19, i64 128
  %282 = getelementptr inbounds i8, i8* %19, i64 256
  %283 = getelementptr inbounds i8, i8* %19, i64 384
  %284 = icmp eq i8* %1, null
  %285 = getelementptr inbounds i8, i8* %19, i64 416
  %286 = select i1 %284, i8* null, i8* %285
  %287 = getelementptr inbounds [17 x i8], [17 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 17, i8* nonnull %287) #6
  %288 = getelementptr inbounds [17 x i8], [17 x i8]* %11, i64 0, i64 1
  %289 = getelementptr inbounds [17 x i8], [17 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 17, i8* nonnull %289) #6
  %290 = getelementptr inbounds [17 x i8], [17 x i8]* %12, i64 0, i64 1
  %291 = getelementptr inbounds i8, i8* %2, i64 %274
  %292 = sext i32 %280 to i64
  %293 = icmp ugt i32 %280, 16
  %294 = sub nsw i64 17, %292
  %295 = select i1 %293, i64 0, i64 %294
  %296 = getelementptr [17 x i8], [17 x i8]* %11, i64 0, i64 %292
  call void @llvm.memset.p0i8.i64(i8* align 1 %296, i8 -86, i64 %295, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %287, i8* align 1 %291, i64 %292, i1 false)
  %297 = getelementptr inbounds i8, i8* %4, i64 %274
  %298 = icmp ugt i32 %280, 16
  %299 = sub nsw i64 17, %292
  %300 = select i1 %298, i64 0, i64 %299
  %301 = getelementptr [17 x i8], [17 x i8]* %12, i64 0, i64 %292
  call void @llvm.memset.p0i8.i64(i8* align 1 %301, i8 -86, i64 %300, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %289, i8* align 1 %297, i64 %292, i1 false)
  %302 = getelementptr inbounds [17 x i8], [17 x i8]* %11, i64 0, i64 %292
  %303 = add nsw i32 %280, -1
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds [17 x i8], [17 x i8]* %11, i64 0, i64 %304
  %306 = load i8, i8* %305, align 1
  %307 = sub nsw i32 17, %280
  %308 = sext i32 %307 to i64
  call void @llvm.memset.p0i8.i64(i8* align 1 %302, i8 %306, i64 %308, i1 false)
  %309 = getelementptr inbounds [17 x i8], [17 x i8]* %12, i64 0, i64 %292
  %310 = getelementptr inbounds [17 x i8], [17 x i8]* %12, i64 0, i64 %304
  %311 = load i8, i8* %310, align 1
  call void @llvm.memset.p0i8.i64(i8* align 1 %309, i8 %311, i64 %308, i1 false)
  %312 = bitcast [17 x i8]* %11 to <2 x i64>*
  %313 = load <2 x i64>, <2 x i64>* %312, align 16
  %314 = bitcast i8* %288 to <2 x i64>*
  %315 = load <2 x i64>, <2 x i64>* %314, align 1
  %316 = bitcast [17 x i8]* %12 to <2 x i64>*
  %317 = load <2 x i64>, <2 x i64>* %316, align 16
  %318 = bitcast i8* %290 to <2 x i64>*
  %319 = load <2 x i64>, <2 x i64>* %318, align 1
  %320 = bitcast <2 x i64> %313 to <16 x i8>
  %321 = bitcast <2 x i64> %319 to <16 x i8>
  %322 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %320, <16 x i8> %321) #6
  %323 = bitcast <2 x i64> %315 to <16 x i8>
  %324 = bitcast <2 x i64> %317 to <16 x i8>
  %325 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %323, <16 x i8> %324) #6
  %326 = xor <16 x i8> %325, %322
  %327 = bitcast <16 x i8> %326 to <2 x i64>
  %328 = xor <2 x i64> %319, %313
  %329 = xor <2 x i64> %317, %315
  %330 = or <2 x i64> %328, %329
  %331 = or <2 x i64> %330, %327
  %332 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %322, <16 x i8> %325) #6
  %333 = bitcast <2 x i64> %331 to <16 x i8>
  %334 = and <16 x i8> %333, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %335 = sub <16 x i8> %332, %334
  %336 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %335, <16 x i8> %325) #6
  %337 = and <2 x i64> %329, %327
  %338 = xor <16 x i8> %335, %325
  %339 = bitcast <2 x i64> %337 to <16 x i8>
  %340 = or <16 x i8> %338, %339
  %341 = and <16 x i8> %340, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %342 = sub <16 x i8> %336, %341
  %343 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %335, <16 x i8> %322) #6
  %344 = and <2 x i64> %328, %327
  %345 = xor <16 x i8> %335, %322
  %346 = bitcast <2 x i64> %344 to <16 x i8>
  %347 = or <16 x i8> %345, %346
  %348 = and <16 x i8> %347, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %349 = sub <16 x i8> %343, %348
  %350 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %320, <16 x i8> %342) #6
  %351 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %323, <16 x i8> %349) #6
  %352 = shufflevector <16 x i8> %350, <16 x i8> %351, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %353 = shufflevector <16 x i8> %350, <16 x i8> %351, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %354 = inttoptr i64 %18 to <16 x i8>*
  store <16 x i8> %352, <16 x i8>* %354, align 16
  %355 = getelementptr inbounds i8, i8* %19, i64 16
  %356 = bitcast i8* %355 to <16 x i8>*
  store <16 x i8> %353, <16 x i8>* %356, align 16
  %357 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %324, <16 x i8> %349) #6
  %358 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %321, <16 x i8> %342) #6
  %359 = shufflevector <16 x i8> %357, <16 x i8> %358, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %360 = shufflevector <16 x i8> %357, <16 x i8> %358, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %361 = getelementptr inbounds i8, i8* %19, i64 64
  %362 = bitcast i8* %361 to <16 x i8>*
  store <16 x i8> %359, <16 x i8>* %362, align 16
  %363 = getelementptr inbounds i8, i8* %19, i64 80
  %364 = bitcast i8* %363 to <16 x i8>*
  store <16 x i8> %360, <16 x i8>* %364, align 16
  call void @llvm.lifetime.end.p0i8(i64 17, i8* nonnull %289) #6
  call void @llvm.lifetime.end.p0i8(i64 17, i8* nonnull %287) #6
  %365 = getelementptr inbounds [17 x i8], [17 x i8]* %13, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 17, i8* nonnull %365) #6
  %366 = getelementptr inbounds [17 x i8], [17 x i8]* %13, i64 0, i64 1
  %367 = getelementptr inbounds [17 x i8], [17 x i8]* %14, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 17, i8* nonnull %367) #6
  %368 = getelementptr inbounds [17 x i8], [17 x i8]* %14, i64 0, i64 1
  %369 = getelementptr inbounds i8, i8* %3, i64 %274
  %370 = icmp ugt i32 %280, 16
  %371 = sub nsw i64 17, %292
  %372 = select i1 %370, i64 0, i64 %371
  %373 = getelementptr [17 x i8], [17 x i8]* %13, i64 0, i64 %292
  call void @llvm.memset.p0i8.i64(i8* align 1 %373, i8 -86, i64 %372, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %365, i8* align 1 %369, i64 %292, i1 false)
  %374 = getelementptr inbounds i8, i8* %5, i64 %274
  %375 = icmp ugt i32 %280, 16
  %376 = sub nsw i64 17, %292
  %377 = select i1 %375, i64 0, i64 %376
  %378 = getelementptr [17 x i8], [17 x i8]* %14, i64 0, i64 %292
  call void @llvm.memset.p0i8.i64(i8* align 1 %378, i8 -86, i64 %377, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %367, i8* align 1 %374, i64 %292, i1 false)
  %379 = getelementptr inbounds [17 x i8], [17 x i8]* %13, i64 0, i64 %292
  %380 = getelementptr inbounds [17 x i8], [17 x i8]* %13, i64 0, i64 %304
  %381 = load i8, i8* %380, align 1
  call void @llvm.memset.p0i8.i64(i8* align 1 %379, i8 %381, i64 %308, i1 false)
  %382 = getelementptr inbounds [17 x i8], [17 x i8]* %14, i64 0, i64 %292
  %383 = getelementptr inbounds [17 x i8], [17 x i8]* %14, i64 0, i64 %304
  %384 = load i8, i8* %383, align 1
  call void @llvm.memset.p0i8.i64(i8* align 1 %382, i8 %384, i64 %308, i1 false)
  %385 = bitcast [17 x i8]* %13 to <2 x i64>*
  %386 = load <2 x i64>, <2 x i64>* %385, align 16
  %387 = bitcast i8* %366 to <2 x i64>*
  %388 = load <2 x i64>, <2 x i64>* %387, align 1
  %389 = bitcast [17 x i8]* %14 to <2 x i64>*
  %390 = load <2 x i64>, <2 x i64>* %389, align 16
  %391 = bitcast i8* %368 to <2 x i64>*
  %392 = load <2 x i64>, <2 x i64>* %391, align 1
  %393 = bitcast <2 x i64> %386 to <16 x i8>
  %394 = bitcast <2 x i64> %392 to <16 x i8>
  %395 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %393, <16 x i8> %394) #6
  %396 = bitcast <2 x i64> %388 to <16 x i8>
  %397 = bitcast <2 x i64> %390 to <16 x i8>
  %398 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %396, <16 x i8> %397) #6
  %399 = xor <16 x i8> %398, %395
  %400 = bitcast <16 x i8> %399 to <2 x i64>
  %401 = xor <2 x i64> %392, %386
  %402 = xor <2 x i64> %390, %388
  %403 = or <2 x i64> %401, %402
  %404 = or <2 x i64> %403, %400
  %405 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %395, <16 x i8> %398) #6
  %406 = bitcast <2 x i64> %404 to <16 x i8>
  %407 = and <16 x i8> %406, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %408 = sub <16 x i8> %405, %407
  %409 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %408, <16 x i8> %398) #6
  %410 = and <2 x i64> %402, %400
  %411 = xor <16 x i8> %408, %398
  %412 = bitcast <2 x i64> %410 to <16 x i8>
  %413 = or <16 x i8> %411, %412
  %414 = and <16 x i8> %413, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %415 = sub <16 x i8> %409, %414
  %416 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %408, <16 x i8> %395) #6
  %417 = and <2 x i64> %401, %400
  %418 = xor <16 x i8> %408, %395
  %419 = bitcast <2 x i64> %417 to <16 x i8>
  %420 = or <16 x i8> %418, %419
  %421 = and <16 x i8> %420, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %422 = sub <16 x i8> %416, %421
  %423 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %393, <16 x i8> %415) #6
  %424 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %396, <16 x i8> %422) #6
  %425 = shufflevector <16 x i8> %423, <16 x i8> %424, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %426 = shufflevector <16 x i8> %423, <16 x i8> %424, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %427 = bitcast i8* %20 to <16 x i8>*
  store <16 x i8> %425, <16 x i8>* %427, align 16
  %428 = getelementptr inbounds i8, i8* %19, i64 48
  %429 = bitcast i8* %428 to <16 x i8>*
  store <16 x i8> %426, <16 x i8>* %429, align 16
  %430 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %397, <16 x i8> %422) #6
  %431 = call <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8> %394, <16 x i8> %415) #6
  %432 = shufflevector <16 x i8> %430, <16 x i8> %431, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %433 = shufflevector <16 x i8> %430, <16 x i8> %431, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %434 = getelementptr inbounds i8, i8* %19, i64 96
  %435 = bitcast i8* %434 to <16 x i8>*
  store <16 x i8> %432, <16 x i8>* %435, align 16
  %436 = getelementptr inbounds i8, i8* %19, i64 112
  %437 = bitcast i8* %436 to <16 x i8>*
  store <16 x i8> %433, <16 x i8>* %437, align 16
  call void @llvm.lifetime.end.p0i8(i64 17, i8* nonnull %367) #6
  call void @llvm.lifetime.end.p0i8(i64 17, i8* nonnull %365) #6
  %438 = zext i32 %273 to i64
  %439 = getelementptr inbounds i8, i8* %0, i64 %438
  %440 = sub nsw i32 %8, %273
  %441 = sext i32 %440 to i64
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %283, i8* align 1 %439, i64 %441, i1 false)
  br i1 %81, label %442, label %444

442:                                              ; preds = %276
  %443 = getelementptr inbounds i8, i8* %1, i64 %438
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %286, i8* align 1 %443, i64 %441, i1 false)
  br label %444

444:                                              ; preds = %276, %442
  call void @VP8YuvToBgra32_SSE2(i8* %283, i8* %19, i8* %20, i8* %281) #6
  %445 = icmp eq i8* %286, null
  br i1 %445, label %447, label %446

446:                                              ; preds = %444
  call void @VP8YuvToBgra32_SSE2(i8* nonnull %286, i8* %361, i8* %434, i8* %282) #6
  br label %447

447:                                              ; preds = %444, %446
  %448 = shl nsw i32 %273, 2
  %449 = zext i32 %448 to i64
  %450 = getelementptr inbounds i8, i8* %6, i64 %449
  %451 = shl nsw i32 %440, 2
  %452 = sext i32 %451 to i64
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %450, i8* align 16 %281, i64 %452, i1 false)
  br i1 %81, label %453, label %455

453:                                              ; preds = %447
  %454 = getelementptr inbounds i8, i8* %7, i64 %449
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %454, i8* align 16 %282, i64 %452, i1 false)
  br label %455

455:                                              ; preds = %447, %453, %272
  call void @llvm.lifetime.end.p0i8(i64 463, i8* nonnull %15) #6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @WebPInitYUV444ConvertersSSE2() local_unnamed_addr #0 {
  store void (i8*, i8*, i8*, i8*, i32)* @Yuv444ToRgba_SSE2, void (i8*, i8*, i8*, i8*, i32)** getelementptr inbounds ([0 x void (i8*, i8*, i8*, i8*, i32)*], [0 x void (i8*, i8*, i8*, i8*, i32)*]* @WebPYUV444Converters, i64 0, i64 1), align 8
  store void (i8*, i8*, i8*, i8*, i32)* @Yuv444ToBgra_SSE2, void (i8*, i8*, i8*, i8*, i32)** getelementptr inbounds ([0 x void (i8*, i8*, i8*, i8*, i32)*], [0 x void (i8*, i8*, i8*, i8*, i32)*]* @WebPYUV444Converters, i64 0, i64 3), align 8
  store <2 x void (i8*, i8*, i8*, i8*, i32)*> <void (i8*, i8*, i8*, i8*, i32)* @Yuv444ToRgba_SSE2, void (i8*, i8*, i8*, i8*, i32)* @Yuv444ToBgra_SSE2>, <2 x void (i8*, i8*, i8*, i8*, i32)*>* bitcast (void (i8*, i8*, i8*, i8*, i32)** getelementptr inbounds ([0 x void (i8*, i8*, i8*, i8*, i32)*], [0 x void (i8*, i8*, i8*, i8*, i32)*]* @WebPYUV444Converters, i64 0, i64 7) to <2 x void (i8*, i8*, i8*, i8*, i32)*>*), align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @Yuv444ToRgba_SSE2(i8*, i8*, i8*, i8*, i32) #2 {
  %6 = and i32 %4, -32
  %7 = icmp sgt i32 %6, 0
  br i1 %7, label %8, label %22

8:                                                ; preds = %5
  %9 = sext i32 %6 to i64
  br label %10

10:                                               ; preds = %8, %10
  %11 = phi i64 [ 0, %8 ], [ %18, %10 ]
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = getelementptr inbounds i8, i8* %1, i64 %11
  %14 = getelementptr inbounds i8, i8* %2, i64 %11
  %15 = shl i64 %11, 2
  %16 = and i64 %15, 4294967168
  %17 = getelementptr inbounds i8, i8* %3, i64 %16
  tail call void @VP8YuvToRgba32_SSE2(i8* %12, i8* %13, i8* %14, i8* %17) #6
  %18 = add nuw nsw i64 %11, 32
  %19 = icmp slt i64 %18, %9
  br i1 %19, label %10, label %20

20:                                               ; preds = %10
  %21 = trunc i64 %18 to i32
  br label %22

22:                                               ; preds = %20, %5
  %23 = phi i32 [ 0, %5 ], [ %21, %20 ]
  %24 = icmp slt i32 %23, %4
  br i1 %24, label %25, label %34

25:                                               ; preds = %22
  %26 = zext i32 %23 to i64
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = getelementptr inbounds i8, i8* %1, i64 %26
  %29 = getelementptr inbounds i8, i8* %2, i64 %26
  %30 = shl nsw i32 %23, 2
  %31 = zext i32 %30 to i64
  %32 = getelementptr inbounds i8, i8* %3, i64 %31
  %33 = sub nsw i32 %4, %23
  tail call void @WebPYuv444ToRgba_C(i8* %27, i8* %28, i8* %29, i8* %32, i32 %33) #6
  br label %34

34:                                               ; preds = %25, %22
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @Yuv444ToBgra_SSE2(i8*, i8*, i8*, i8*, i32) #2 {
  %6 = and i32 %4, -32
  %7 = icmp sgt i32 %6, 0
  br i1 %7, label %8, label %22

8:                                                ; preds = %5
  %9 = sext i32 %6 to i64
  br label %10

10:                                               ; preds = %8, %10
  %11 = phi i64 [ 0, %8 ], [ %18, %10 ]
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = getelementptr inbounds i8, i8* %1, i64 %11
  %14 = getelementptr inbounds i8, i8* %2, i64 %11
  %15 = shl i64 %11, 2
  %16 = and i64 %15, 4294967168
  %17 = getelementptr inbounds i8, i8* %3, i64 %16
  tail call void @VP8YuvToBgra32_SSE2(i8* %12, i8* %13, i8* %14, i8* %17) #6
  %18 = add nuw nsw i64 %11, 32
  %19 = icmp slt i64 %18, %9
  br i1 %19, label %10, label %20

20:                                               ; preds = %10
  %21 = trunc i64 %18 to i32
  br label %22

22:                                               ; preds = %20, %5
  %23 = phi i32 [ 0, %5 ], [ %21, %20 ]
  %24 = icmp slt i32 %23, %4
  br i1 %24, label %25, label %34

25:                                               ; preds = %22
  %26 = zext i32 %23 to i64
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = getelementptr inbounds i8, i8* %1, i64 %26
  %29 = getelementptr inbounds i8, i8* %2, i64 %26
  %30 = shl nsw i32 %23, 2
  %31 = zext i32 %30 to i64
  %32 = getelementptr inbounds i8, i8* %3, i64 %31
  %33 = sub nsw i32 %4, %23
  tail call void @WebPYuv444ToBgra_C(i8* %27, i8* %28, i8* %29, i8* %32, i32 %33) #6
  br label %34

34:                                               ; preds = %25, %22
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #3

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #3

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #3

declare void @VP8YuvToRgba32_SSE2(i8*, i8*, i8*, i8*) local_unnamed_addr #4

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #3

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.pavg.b(<16 x i8>, <16 x i8>) #5

declare void @VP8YuvToBgra32_SSE2(i8*, i8*, i8*, i8*) local_unnamed_addr #4

declare void @WebPYuv444ToRgba_C(i8*, i8*, i8*, i8*, i32) local_unnamed_addr #4

declare void @WebPYuv444ToBgra_C(i8*, i8*, i8*, i8*, i32) local_unnamed_addr #4

attributes #0 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { argmemonly nounwind }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind readnone }
attributes #6 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
