; ModuleID = '../../v8/src/base/bounded-page-allocator.cc'
source_filename = "../../v8/src/base/bounded-page-allocator.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.v8::base::BoundedPageAllocator" = type { %"class.v8::PageAllocator", %"class.v8::base::Mutex", i64, i64, %"class.v8::PageAllocator"*, %"class.v8::base::RegionAllocator" }
%"class.v8::PageAllocator" = type { i32 (...)** }
%"class.v8::base::Mutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.v8::base::RegionAllocator" = type { %"class.v8::base::RegionAllocator::Region", i64, i64, i64, i64, %"class.std::__1::set", %"class.std::__1::set.4" }
%"class.v8::base::RegionAllocator::Region" = type <{ %"class.v8::base::AddressRegion", i32, [4 x i8] }>
%"class.v8::base::AddressRegion" = type { i64, i64 }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair", %"class.std::__1::__compressed_pair.1" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type opaque
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.std::__1::__tree_end_node" }
%"class.std::__1::__compressed_pair.1" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"struct.std::__1::__compressed_pair_elem.2" = type { i64 }
%"class.std::__1::set.4" = type { %"class.std::__1::__tree.5" }
%"class.std::__1::__tree.5" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair", %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::PageAllocator::SharedMemory" = type { i32 (...)** }

$_ZN2v84base20BoundedPageAllocatorD2Ev = comdat any

$_ZN2v84base20BoundedPageAllocatorD0Ev = comdat any

$_ZN2v84base20BoundedPageAllocator16AllocatePageSizeEv = comdat any

$_ZN2v84base20BoundedPageAllocator14CommitPageSizeEv = comdat any

$_ZN2v84base20BoundedPageAllocator17SetRandomMmapSeedEl = comdat any

$_ZN2v84base20BoundedPageAllocator17GetRandomMmapAddrEv = comdat any

$_ZN2v813PageAllocator19AllocateSharedPagesEmPKv = comdat any

$_ZN2v813PageAllocator22CanAllocateSharedPagesEv = comdat any

@_ZTVN2v84base20BoundedPageAllocatorE = hidden unnamed_addr constant { [16 x i8*] } { [16 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::base::BoundedPageAllocator"*)* @_ZN2v84base20BoundedPageAllocatorD2Ev to i8*), i8* bitcast (void (%"class.v8::base::BoundedPageAllocator"*)* @_ZN2v84base20BoundedPageAllocatorD0Ev to i8*), i8* bitcast (i64 (%"class.v8::base::BoundedPageAllocator"*)* @_ZN2v84base20BoundedPageAllocator16AllocatePageSizeEv to i8*), i8* bitcast (i64 (%"class.v8::base::BoundedPageAllocator"*)* @_ZN2v84base20BoundedPageAllocator14CommitPageSizeEv to i8*), i8* bitcast (void (%"class.v8::base::BoundedPageAllocator"*, i64)* @_ZN2v84base20BoundedPageAllocator17SetRandomMmapSeedEl to i8*), i8* bitcast (i8* (%"class.v8::base::BoundedPageAllocator"*)* @_ZN2v84base20BoundedPageAllocator17GetRandomMmapAddrEv to i8*), i8* bitcast (i8* (%"class.v8::base::BoundedPageAllocator"*, i8*, i64, i64, i32)* @_ZN2v84base20BoundedPageAllocator13AllocatePagesEPvmmNS_13PageAllocator10PermissionE to i8*), i8* bitcast (i1 (%"class.v8::base::BoundedPageAllocator"*, i8*, i64)* @_ZN2v84base20BoundedPageAllocator9FreePagesEPvm to i8*), i8* bitcast (i1 (%"class.v8::base::BoundedPageAllocator"*, i8*, i64, i64)* @_ZN2v84base20BoundedPageAllocator12ReleasePagesEPvmm to i8*), i8* bitcast (i1 (%"class.v8::base::BoundedPageAllocator"*, i8*, i64, i32)* @_ZN2v84base20BoundedPageAllocator14SetPermissionsEPvmNS_13PageAllocator10PermissionE to i8*), i8* bitcast (i1 (%"class.v8::base::BoundedPageAllocator"*, i8*, i64)* @_ZN2v84base20BoundedPageAllocator18DiscardSystemPagesEPvm to i8*), i8* bitcast (i1 (%"class.v8::base::BoundedPageAllocator"*, i8*, i64)* @_ZN2v84base20BoundedPageAllocator29ReserveForSharedMemoryMappingEPvm to i8*), i8* bitcast (%"class.v8::PageAllocator::SharedMemory"* (%"class.v8::PageAllocator"*, i64, i8*)* @_ZN2v813PageAllocator19AllocateSharedPagesEmPKv to i8*), i8* bitcast (i1 (%"class.v8::PageAllocator"*)* @_ZN2v813PageAllocator22CanAllocateSharedPagesEv to i8*)] }, align 8
@.str = private unnamed_addr constant [18 x i8] c"Check failed: %s.\00", align 1
@.str.1 = private unnamed_addr constant [28 x i8] c"(page_allocator) != nullptr\00", align 1
@.str.2 = private unnamed_addr constant [66 x i8] c"IsAligned(allocate_page_size, page_allocator->AllocatePageSize())\00", align 1
@.str.3 = private unnamed_addr constant [50 x i8] c"IsAligned(allocate_page_size_, commit_page_size_)\00", align 1
@.str.4 = private unnamed_addr constant [52 x i8] c"IsAligned(alignment, region_allocator_.page_size())\00", align 1
@.str.5 = private unnamed_addr constant [33 x i8] c"alignment <= allocate_page_size_\00", align 1
@.str.6 = private unnamed_addr constant [80 x i8] c"page_allocator_->SetPermissions(reinterpret_cast<void*>(address), size, access)\00", align 1
@.str.7 = private unnamed_addr constant [40 x i8] c"IsAligned(address, allocate_page_size_)\00", align 1
@.str.8 = private unnamed_addr constant [37 x i8] c"IsAligned(size, allocate_page_size_)\00", align 1
@.str.9 = private unnamed_addr constant [42 x i8] c"region_allocator_.contains(address, size)\00", align 1
@.str.10 = private unnamed_addr constant [35 x i8] c"IsAligned(size, commit_page_size_)\00", align 1
@.str.11 = private unnamed_addr constant [81 x i8] c"page_allocator_->SetPermissions(ptr, size, PageAllocator::Permission::kNoAccess)\00", align 1
@.str.12 = private unnamed_addr constant [77 x i8] c"page_allocator_->SetPermissions(raw_address, size, PageAllocator::kNoAccess)\00", align 1

@_ZN2v84base20BoundedPageAllocatorC1EPNS_13PageAllocatorEmmm = hidden unnamed_addr alias void (%"class.v8::base::BoundedPageAllocator"*, %"class.v8::PageAllocator"*, i64, i64, i64), void (%"class.v8::base::BoundedPageAllocator"*, %"class.v8::PageAllocator"*, i64, i64, i64)* @_ZN2v84base20BoundedPageAllocatorC2EPNS_13PageAllocatorEmmm

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v84base20BoundedPageAllocatorC2EPNS_13PageAllocatorEmmm(%"class.v8::base::BoundedPageAllocator"*, %"class.v8::PageAllocator"*, i64, i64, i64) unnamed_addr #0 align 2 {
  %6 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [16 x i8*] }, { [16 x i8*] }* @_ZTVN2v84base20BoundedPageAllocatorE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %7 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"* %7) #6
  %8 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 2
  store i64 %4, i64* %8, align 8
  %9 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 3
  %10 = bitcast %"class.v8::PageAllocator"* %1 to i64 (%"class.v8::PageAllocator"*)***
  %11 = load i64 (%"class.v8::PageAllocator"*)**, i64 (%"class.v8::PageAllocator"*)*** %10, align 8
  %12 = getelementptr inbounds i64 (%"class.v8::PageAllocator"*)*, i64 (%"class.v8::PageAllocator"*)** %11, i64 3
  %13 = load i64 (%"class.v8::PageAllocator"*)*, i64 (%"class.v8::PageAllocator"*)** %12, align 8
  %14 = tail call i64 %13(%"class.v8::PageAllocator"* %1) #6
  store i64 %14, i64* %9, align 8
  %15 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  store %"class.v8::PageAllocator"* %1, %"class.v8::PageAllocator"** %15, align 8
  %16 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5
  %17 = load i64, i64* %8, align 8
  tail call void @_ZN2v84base15RegionAllocatorC1Emmm(%"class.v8::base::RegionAllocator"* %16, i64 %2, i64 %3, i64 %17) #6
  %18 = icmp eq %"class.v8::PageAllocator"* %1, null
  br i1 %18, label %19, label %20, !prof !2

19:                                               ; preds = %5
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.1, i64 0, i64 0)) #7
  unreachable

20:                                               ; preds = %5
  %21 = load i64 (%"class.v8::PageAllocator"*)**, i64 (%"class.v8::PageAllocator"*)*** %10, align 8
  %22 = getelementptr inbounds i64 (%"class.v8::PageAllocator"*)*, i64 (%"class.v8::PageAllocator"*)** %21, i64 2
  %23 = load i64 (%"class.v8::PageAllocator"*)*, i64 (%"class.v8::PageAllocator"*)** %22, align 8
  %24 = tail call i64 %23(%"class.v8::PageAllocator"* nonnull %1) #6
  %25 = add i64 %24, -1
  %26 = and i64 %25, %4
  %27 = icmp eq i64 %26, 0
  br i1 %27, label %29, label %28, !prof !3

28:                                               ; preds = %20
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([66 x i8], [66 x i8]* @.str.2, i64 0, i64 0)) #7
  unreachable

29:                                               ; preds = %20
  %30 = load i64, i64* %8, align 8
  %31 = load i64, i64* %9, align 8
  %32 = add i64 %31, -1
  %33 = and i64 %32, %30
  %34 = icmp eq i64 %33, 0
  br i1 %34, label %36, label %35, !prof !3

35:                                               ; preds = %29
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.3, i64 0, i64 0)) #7
  unreachable

36:                                               ; preds = %29
  ret void
}

declare void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"*) unnamed_addr #1

declare void @_ZN2v84base15RegionAllocatorC1Emmm(%"class.v8::base::RegionAllocator"*, i64, i64, i64) unnamed_addr #1

; Function Attrs: noreturn
declare void @_Z8V8_FatalPKcz(i8*, ...) local_unnamed_addr #2

; Function Attrs: norecurse nounwind readonly ssp uwtable
define hidden i64 @_ZNK2v84base20BoundedPageAllocator5beginEv(%"class.v8::base::BoundedPageAllocator"* nocapture readonly) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: norecurse nounwind readonly ssp uwtable
define hidden i64 @_ZNK2v84base20BoundedPageAllocator4sizeEv(%"class.v8::base::BoundedPageAllocator"* nocapture readonly) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5, i32 0, i32 0, i32 1
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define hidden i8* @_ZN2v84base20BoundedPageAllocator13AllocatePagesEPvmmNS_13PageAllocator10PermissionE(%"class.v8::base::BoundedPageAllocator"*, i8* nocapture readnone, i64, i64, i32) unnamed_addr #0 align 2 {
  %6 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %6) #6
  %7 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5
  %8 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5, i32 4
  %9 = load i64, i64* %8, align 8
  %10 = add i64 %9, -1
  %11 = and i64 %10, %3
  %12 = icmp eq i64 %11, 0
  br i1 %12, label %14, label %13, !prof !3

13:                                               ; preds = %5
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([52 x i8], [52 x i8]* @.str.4, i64 0, i64 0)) #7
  unreachable

14:                                               ; preds = %5
  %15 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 2
  %16 = load i64, i64* %15, align 8
  %17 = icmp ult i64 %16, %3
  br i1 %17, label %18, label %19, !prof !2

18:                                               ; preds = %14
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([33 x i8], [33 x i8]* @.str.5, i64 0, i64 0)) #7
  unreachable

19:                                               ; preds = %14
  %20 = tail call i64 @_ZN2v84base15RegionAllocator14AllocateRegionEm(%"class.v8::base::RegionAllocator"* %7, i64 %2) #6
  %21 = icmp eq i64 %20, -1
  br i1 %21, label %32, label %22

22:                                               ; preds = %19
  %23 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %24 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %23, align 8
  %25 = inttoptr i64 %20 to i8*
  %26 = bitcast %"class.v8::PageAllocator"* %24 to i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)***
  %27 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)**, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*** %26, align 8
  %28 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %27, i64 9
  %29 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %28, align 8
  %30 = tail call zeroext i1 %29(%"class.v8::PageAllocator"* %24, i8* %25, i64 %2, i32 %4) #6
  br i1 %30, label %32, label %31, !prof !3

31:                                               ; preds = %22
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([80 x i8], [80 x i8]* @.str.6, i64 0, i64 0)) #7
  unreachable

32:                                               ; preds = %22, %19
  %33 = phi i8* [ null, %19 ], [ %25, %22 ]
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %6) #6
  ret i8* %33
}

declare i64 @_ZN2v84base15RegionAllocator14AllocateRegionEm(%"class.v8::base::RegionAllocator"*, i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v84base20BoundedPageAllocator15AllocatePagesAtEmmNS_13PageAllocator10PermissionE(%"class.v8::base::BoundedPageAllocator"*, i64, i64, i32) local_unnamed_addr #0 align 2 {
  %5 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 2
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, -1
  %8 = and i64 %7, %1
  %9 = icmp eq i64 %8, 0
  br i1 %9, label %11, label %10, !prof !3

10:                                               ; preds = %4
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.7, i64 0, i64 0)) #7
  unreachable

11:                                               ; preds = %4
  %12 = and i64 %7, %2
  %13 = icmp eq i64 %12, 0
  br i1 %13, label %15, label %14, !prof !3

14:                                               ; preds = %11
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.8, i64 0, i64 0)) #7
  unreachable

15:                                               ; preds = %11
  %16 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5
  %17 = getelementptr inbounds %"class.v8::base::RegionAllocator", %"class.v8::base::RegionAllocator"* %16, i64 0, i32 0, i32 0, i32 0
  %18 = load i64, i64* %17, align 8
  %19 = sub i64 %1, %18
  %20 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5, i32 0, i32 0, i32 1
  %21 = load i64, i64* %20, align 8
  %22 = icmp ult i64 %19, %21
  %23 = add i64 %19, %2
  %24 = icmp ule i64 %23, %21
  %25 = and i1 %22, %24
  br i1 %25, label %27, label %26, !prof !3

26:                                               ; preds = %15
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.9, i64 0, i64 0)) #7
  unreachable

27:                                               ; preds = %15
  %28 = tail call zeroext i1 @_ZN2v84base15RegionAllocator16AllocateRegionAtEmmNS1_11RegionStateE(%"class.v8::base::RegionAllocator"* %16, i64 %1, i64 %2, i32 2) #6
  br i1 %28, label %29, label %39

29:                                               ; preds = %27
  %30 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %31 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %30, align 8
  %32 = inttoptr i64 %1 to i8*
  %33 = bitcast %"class.v8::PageAllocator"* %31 to i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)***
  %34 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)**, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*** %33, align 8
  %35 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %34, i64 9
  %36 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %35, align 8
  %37 = tail call zeroext i1 %36(%"class.v8::PageAllocator"* %31, i8* %32, i64 %2, i32 %3) #6
  br i1 %37, label %39, label %38, !prof !3

38:                                               ; preds = %29
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([80 x i8], [80 x i8]* @.str.6, i64 0, i64 0)) #7
  unreachable

39:                                               ; preds = %29, %27
  %40 = phi i1 [ false, %27 ], [ true, %29 ]
  ret i1 %40
}

declare zeroext i1 @_ZN2v84base15RegionAllocator16AllocateRegionAtEmmNS1_11RegionStateE(%"class.v8::base::RegionAllocator"*, i64, i64, i32) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v84base20BoundedPageAllocator29ReserveForSharedMemoryMappingEPvm(%"class.v8::base::BoundedPageAllocator"*, i8*, i64) unnamed_addr #0 align 2 {
  %4 = ptrtoint i8* %1 to i64
  %5 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 2
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, -1
  %8 = and i64 %7, %4
  %9 = icmp eq i64 %8, 0
  br i1 %9, label %11, label %10, !prof !3

10:                                               ; preds = %3
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.7, i64 0, i64 0)) #7
  unreachable

11:                                               ; preds = %3
  %12 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 3
  %13 = load i64, i64* %12, align 8
  %14 = add i64 %13, -1
  %15 = and i64 %14, %2
  %16 = icmp eq i64 %15, 0
  br i1 %16, label %18, label %17, !prof !3

17:                                               ; preds = %11
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.10, i64 0, i64 0)) #7
  unreachable

18:                                               ; preds = %11
  %19 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5
  %20 = getelementptr inbounds %"class.v8::base::RegionAllocator", %"class.v8::base::RegionAllocator"* %19, i64 0, i32 0, i32 0, i32 0
  %21 = load i64, i64* %20, align 8
  %22 = sub i64 %4, %21
  %23 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5, i32 0, i32 0, i32 1
  %24 = load i64, i64* %23, align 8
  %25 = icmp ult i64 %22, %24
  %26 = add i64 %22, %2
  %27 = icmp ule i64 %26, %24
  %28 = and i1 %25, %27
  br i1 %28, label %30, label %29, !prof !3

29:                                               ; preds = %18
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.9, i64 0, i64 0)) #7
  unreachable

30:                                               ; preds = %18
  %31 = add i64 %7, %2
  %32 = sub nsw i64 0, %6
  %33 = and i64 %31, %32
  %34 = tail call zeroext i1 @_ZN2v84base15RegionAllocator16AllocateRegionAtEmmNS1_11RegionStateE(%"class.v8::base::RegionAllocator"* %19, i64 %4, i64 %33, i32 1) #6
  br i1 %34, label %35, label %44

35:                                               ; preds = %30
  %36 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %37 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %36, align 8
  %38 = bitcast %"class.v8::PageAllocator"* %37 to i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)***
  %39 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)**, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*** %38, align 8
  %40 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %39, i64 9
  %41 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %40, align 8
  %42 = tail call zeroext i1 %41(%"class.v8::PageAllocator"* %37, i8* %1, i64 %2, i32 0) #6
  br i1 %42, label %44, label %43, !prof !3

43:                                               ; preds = %35
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.11, i64 0, i64 0)) #7
  unreachable

44:                                               ; preds = %35, %30
  %45 = phi i1 [ false, %30 ], [ true, %35 ]
  ret i1 %45
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v84base20BoundedPageAllocator9FreePagesEPvm(%"class.v8::base::BoundedPageAllocator"*, i8*, i64) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %4) #6
  %5 = ptrtoint i8* %1 to i64
  %6 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5
  %7 = tail call i64 @_ZN2v84base15RegionAllocator10TrimRegionEmm(%"class.v8::base::RegionAllocator"* %6, i64 %5, i64 0) #6
  %8 = icmp eq i64 %7, %2
  br i1 %8, label %9, label %18

9:                                                ; preds = %3
  %10 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %11 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %10, align 8
  %12 = bitcast %"class.v8::PageAllocator"* %11 to i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)***
  %13 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)**, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*** %12, align 8
  %14 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %13, i64 9
  %15 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %14, align 8
  %16 = tail call zeroext i1 %15(%"class.v8::PageAllocator"* %11, i8* %1, i64 %2, i32 0) #6
  br i1 %16, label %18, label %17, !prof !3

17:                                               ; preds = %9
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([77 x i8], [77 x i8]* @.str.12, i64 0, i64 0)) #7
  unreachable

18:                                               ; preds = %9, %3
  %19 = phi i1 [ false, %3 ], [ true, %9 ]
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %4) #6
  ret i1 %19
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v84base20BoundedPageAllocator12ReleasePagesEPvmm(%"class.v8::base::BoundedPageAllocator"*, i8*, i64, i64) unnamed_addr #0 align 2 {
  %5 = ptrtoint i8* %1 to i64
  %6 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 2
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, -1
  %9 = and i64 %8, %5
  %10 = icmp eq i64 %9, 0
  br i1 %10, label %12, label %11, !prof !3

11:                                               ; preds = %4
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.7, i64 0, i64 0)) #7
  unreachable

12:                                               ; preds = %4
  %13 = add i64 %8, %2
  %14 = sub nsw i64 0, %7
  %15 = and i64 %13, %14
  %16 = add i64 %8, %3
  %17 = and i64 %16, %14
  %18 = icmp ult i64 %17, %15
  br i1 %18, label %19, label %23

19:                                               ; preds = %12
  %20 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %20) #6
  %21 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5
  %22 = tail call i64 @_ZN2v84base15RegionAllocator10TrimRegionEmm(%"class.v8::base::RegionAllocator"* %21, i64 %5, i64 %17) #6
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %20) #6
  br label %23

23:                                               ; preds = %19, %12
  %24 = add i64 %5, %3
  %25 = sub i64 %2, %3
  %26 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %27 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %26, align 8
  %28 = inttoptr i64 %24 to i8*
  %29 = bitcast %"class.v8::PageAllocator"* %27 to i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)***
  %30 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)**, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*** %29, align 8
  %31 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %30, i64 9
  %32 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %31, align 8
  %33 = tail call zeroext i1 %32(%"class.v8::PageAllocator"* %27, i8* %28, i64 %25, i32 0) #6
  ret i1 %33
}

declare i64 @_ZN2v84base15RegionAllocator10TrimRegionEmm(%"class.v8::base::RegionAllocator"*, i64, i64) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v84base20BoundedPageAllocator14SetPermissionsEPvmNS_13PageAllocator10PermissionE(%"class.v8::base::BoundedPageAllocator"* nocapture readonly, i8*, i64, i32) unnamed_addr #0 align 2 {
  %5 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %6 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %5, align 8
  %7 = bitcast %"class.v8::PageAllocator"* %6 to i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)***
  %8 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)**, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*** %7, align 8
  %9 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %8, i64 9
  %10 = load i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)*, i1 (%"class.v8::PageAllocator"*, i8*, i64, i32)** %9, align 8
  %11 = tail call zeroext i1 %10(%"class.v8::PageAllocator"* %6, i8* %1, i64 %2, i32 %3) #6
  ret i1 %11
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v84base20BoundedPageAllocator18DiscardSystemPagesEPvm(%"class.v8::base::BoundedPageAllocator"* nocapture readonly, i8*, i64) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %5 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %4, align 8
  %6 = bitcast %"class.v8::PageAllocator"* %5 to i1 (%"class.v8::PageAllocator"*, i8*, i64)***
  %7 = load i1 (%"class.v8::PageAllocator"*, i8*, i64)**, i1 (%"class.v8::PageAllocator"*, i8*, i64)*** %6, align 8
  %8 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64)*, i1 (%"class.v8::PageAllocator"*, i8*, i64)** %7, i64 10
  %9 = load i1 (%"class.v8::PageAllocator"*, i8*, i64)*, i1 (%"class.v8::PageAllocator"*, i8*, i64)** %8, align 8
  %10 = tail call zeroext i1 %9(%"class.v8::PageAllocator"* %5, i8* %1, i64 %2) #6
  ret i1 %10
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v84base20BoundedPageAllocatorD2Ev(%"class.v8::base::BoundedPageAllocator"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [16 x i8*] }, { [16 x i8*] }* @_ZTVN2v84base20BoundedPageAllocatorE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5
  tail call void @_ZN2v84base15RegionAllocatorD1Ev(%"class.v8::base::RegionAllocator"* %3) #6
  %4 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"* %4) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v84base20BoundedPageAllocatorD0Ev(%"class.v8::base::BoundedPageAllocator"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [16 x i8*] }, { [16 x i8*] }* @_ZTVN2v84base20BoundedPageAllocatorE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 5
  tail call void @_ZN2v84base15RegionAllocatorD1Ev(%"class.v8::base::RegionAllocator"* %3) #6
  %4 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"* %4) #6
  %5 = bitcast %"class.v8::base::BoundedPageAllocator"* %0 to i8*
  tail call void @_ZdlPv(i8* %5) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v84base20BoundedPageAllocator16AllocatePageSizeEv(%"class.v8::base::BoundedPageAllocator"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 2
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v84base20BoundedPageAllocator14CommitPageSizeEv(%"class.v8::base::BoundedPageAllocator"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 3
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v84base20BoundedPageAllocator17SetRandomMmapSeedEl(%"class.v8::base::BoundedPageAllocator"*, i64) unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %4 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %3, align 8
  %5 = bitcast %"class.v8::PageAllocator"* %4 to void (%"class.v8::PageAllocator"*, i64)***
  %6 = load void (%"class.v8::PageAllocator"*, i64)**, void (%"class.v8::PageAllocator"*, i64)*** %5, align 8
  %7 = getelementptr inbounds void (%"class.v8::PageAllocator"*, i64)*, void (%"class.v8::PageAllocator"*, i64)** %6, i64 4
  %8 = load void (%"class.v8::PageAllocator"*, i64)*, void (%"class.v8::PageAllocator"*, i64)** %7, align 8
  tail call void %8(%"class.v8::PageAllocator"* %4, i64 %1) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i8* @_ZN2v84base20BoundedPageAllocator17GetRandomMmapAddrEv(%"class.v8::base::BoundedPageAllocator"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::base::BoundedPageAllocator", %"class.v8::base::BoundedPageAllocator"* %0, i64 0, i32 4
  %3 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %2, align 8
  %4 = bitcast %"class.v8::PageAllocator"* %3 to i8* (%"class.v8::PageAllocator"*)***
  %5 = load i8* (%"class.v8::PageAllocator"*)**, i8* (%"class.v8::PageAllocator"*)*** %4, align 8
  %6 = getelementptr inbounds i8* (%"class.v8::PageAllocator"*)*, i8* (%"class.v8::PageAllocator"*)** %5, i64 5
  %7 = load i8* (%"class.v8::PageAllocator"*)*, i8* (%"class.v8::PageAllocator"*)** %6, align 8
  %8 = tail call i8* %7(%"class.v8::PageAllocator"* %3) #6
  ret i8* %8
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden %"class.v8::PageAllocator::SharedMemory"* @_ZN2v813PageAllocator19AllocateSharedPagesEmPKv(%"class.v8::PageAllocator"*, i64, i8*) unnamed_addr #0 comdat align 2 {
  ret %"class.v8::PageAllocator::SharedMemory"* null
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN2v813PageAllocator22CanAllocateSharedPagesEv(%"class.v8::PageAllocator"*) unnamed_addr #0 comdat align 2 {
  ret i1 false
}

; Function Attrs: nounwind
declare void @_ZN2v84base15RegionAllocatorD1Ev(%"class.v8::base::RegionAllocator"*) unnamed_addr #4

; Function Attrs: nounwind
declare void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"*) unnamed_addr #4

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #5

declare void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"*) local_unnamed_addr #1

declare void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"*) local_unnamed_addr #1

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { norecurse nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind }
attributes #7 = { noreturn nounwind }
attributes #8 = { builtin nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!"branch_weights", i32 1, i32 2000}
!3 = !{!"branch_weights", i32 2000, i32 1}
