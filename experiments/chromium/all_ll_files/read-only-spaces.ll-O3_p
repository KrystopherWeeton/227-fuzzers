; ModuleID = '../../v8/src/heap/read-only-spaces.cc'
source_filename = "../../v8/src/heap/read-only-spaces.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.v8::internal::SingleCopyReadOnlyArtifacts" = type { %"class.v8::internal::ReadOnlyArtifacts", %"class.v8::PageAllocator"* }
%"class.v8::internal::ReadOnlyArtifacts" = type { i32 (...)**, %"class.std::__1::vector", %"class.v8::internal::AllocationStats", %"class.std::__1::unique_ptr.610", %"class.std::__1::unique_ptr.629" }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"**, %"class.std::__1::__compressed_pair.605" }
%"class.v8::internal::ReadOnlyPage" = type { %"class.v8::internal::BasicMemoryChunk" }
%"class.v8::internal::BasicMemoryChunk" = type { i64, i64, %"class.v8::internal::Heap"*, i64, i64, i64, i64, %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.601", %"class.v8::internal::VirtualMemory" }
%"class.v8::internal::Heap" = type { %"class.std::__1::unordered_map", %"struct.std::__1::atomic", %"class.v8::internal::Heap::ExternalMemoryAccounting", %"class.v8::internal::Isolate"*, i64, i64, i64, i64, %"struct.std::__1::atomic", i64, i64, i64, i64, i64, i8, i64, i64, %"struct.std::__1::atomic", i64, i64, %"struct.std::__1::atomic", %"struct.std::__1::atomic.20", %"class.std::__1::vector.24", i32, %"class.v8::internal::NewSpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::CodeSpace"*, %"class.v8::internal::MapSpace"*, %"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::MapSpace"*, %"class.std::__1::unique_ptr.101", %"class.std::__1::unique_ptr.101", [8 x %"class.v8::internal::Space"*], %"class.v8::internal::LocalHeap"*, %"class.v8::internal::ArrayBufferExtension"*, %"class.v8::internal::ArrayBufferExtension"*, i8, i64, %"struct.std::__1::atomic.116", i32, i32, i32, i32, %"class.v8::internal::AllocationObserver"*, %"class.v8::internal::StressScavengeObserver"*, double, i32, i32, i32, i64, i32, [128 x i64], %"struct.std::__1::atomic", i64, i8, %"struct.std::__1::atomic", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.std::__1::vector.120", %"class.std::__1::vector.120", i64 ()*, [113 x i32], i64, double, double, i64, i64, double, i32, i32, i32, i32, double, double, double, %"class.std::__1::unique_ptr.127", %"class.std::__1::unique_ptr.133", %"class.v8::internal::MinorMarkCompactCollector"*, %"class.std::__1::unique_ptr.263", %"class.std::__1::unique_ptr.269", %"class.std::__1::unique_ptr.275", %"class.std::__1::unique_ptr.314", %"class.std::__1::unique_ptr.353", %"class.std::__1::unique_ptr.383", %"class.std::__1::unique_ptr.389", %"class.std::__1::unique_ptr.399", %"class.std::__1::unique_ptr.405", %"class.std::__1::unique_ptr.405", %"class.std::__1::unique_ptr.411", %"class.std::__1::unique_ptr.417", %"class.std::__1::unique_ptr.417", %"class.std::__1::unique_ptr.423", %"class.std::__1::unique_ptr.429", %"class.std::__1::shared_ptr.435", %"class.v8::CppHeap"*, %"class.v8::EmbedderRootsHandler"*, %"class.v8::internal::StrongRootsEntry"*, %"class.v8::base::Mutex", i8, i64, i64, i64, i64, %"class.std::__1::unordered_map.457", %"class.std::__1::unique_ptr.483", [512 x i8], i8, i8, i64, i8, i32, i32, %"class.std::__1::unique_ptr.489", i8, %"class.v8::internal::Heap::ExternalStringTable", %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.504", i32, i8, i8, i8, i8, i8, %"class.v8::internal::HeapObject", %"class.v8::base::SharedMutex", %"class.v8::base::Mutex", %"class.std::__1::unordered_set.285", i8, [7 x i8], %"class.std::__1::unordered_map.510", %"class.std::__1::unordered_map.536", %"class.std::__1::unordered_map.510", %"class.std::__1::unordered_map.560", %"class.std::__1::vector.588", i8, %"class.std::__1::unique_ptr.595", i32, i32 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr", %"class.std::__1::__compressed_pair.4", %"class.std::__1::__compressed_pair.9", %"class.std::__1::__compressed_pair.11", [4 x i8] }>
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem", %"struct.std::__1::__compressed_pair_elem.0" }
%"struct.std::__1::__compressed_pair_elem" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.0" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.1" }
%"class.std::__1::__compressed_pair.1" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"struct.std::__1::__compressed_pair_elem.2" = type { i64 }
%"class.std::__1::__compressed_pair.4" = type { %"struct.std::__1::__compressed_pair_elem.5" }
%"struct.std::__1::__compressed_pair_elem.5" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.9" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.11" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::__compressed_pair_elem.12" = type { float }
%"class.v8::internal::Heap::ExternalMemoryAccounting" = type { %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.15" }
%"class.v8::internal::Isolate" = type { %"class.v8::internal::IsolateData", %"class.std::__1::unique_ptr.709", %"class.v8::internal::Heap", %"class.v8::internal::ReadOnlyHeap"*, %"class.std::__1::shared_ptr.715", %"class.std::__1::unique_ptr.716", i32, %"class.v8::internal::Isolate::EntryStackItem"*, i32, %"class.v8::internal::StringStream"*, [13 x i64], %"class.v8::internal::Bootstrapper"*, %"class.v8::internal::RuntimeProfiler"*, %"class.v8::internal::CompilationCache"*, %"class.std::__1::shared_ptr.726", %"class.v8::base::RecursiveMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::internal::Logger"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::Deoptimizer"*, i8, %"class.v8::internal::MaterializedObjectStore"*, i8, i32, i32, %"class.v8::internal::DescriptorLookupCache"*, %"struct.v8::internal::HandleScopeData", %"class.v8::internal::HandleScopeImplementer"*, %"class.v8::internal::UnicodeCache"*, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::InnerPointerToCodeCache"*, %"class.v8::internal::GlobalHandles"*, %"class.v8::internal::EternalHandles"*, %"class.v8::internal::ThreadManager"*, %"class.v8::bigint::Processor"*, %"class.v8::internal::RuntimeState", %"class.v8::internal::Builtins", %"class.v8::internal::SetupIsolateDelegate"*, %"class.v8::internal::RegExpStack"*, %"class.std::__1::vector.847", %"class.v8::internal::DateCache"*, %"class.v8::base::RandomNumberGenerator"*, %"class.v8::base::RandomNumberGenerator"*, %"struct.std::__1::atomic.860", {}*, i8*, void (i32, %"class.v8::Promise"*, %"class.v8::Value"*)*, {}*, {}*, %"struct.std::__1::atomic.870", {}*, %"class.v8::base::Mutex", double, %"class.std::__1::basic_string", %"class.std::__1::unordered_map.882", %"struct.std::__1::atomic.107", i8, i8, i8, i8, i8, i8, double, %"class.v8::internal::Debug"*, %"class.v8::internal::HeapProfiler"*, %"class.std::__1::unique_ptr.957", %"class.v8::internal::AstStringConstants"*, %"class.v8::internal::interpreter::Interpreter"*, %"class.v8::internal::compiler::PerIsolateCompilerCache"*, %"class.v8::internal::Zone"*, %"class.v8::internal::CompilerDispatcher"*, %"class.std::__1::queue", void (i8*, i8*)*, void (i8*, i1)*, void (i8*, i32)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*, i1)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::Context"*)*, void (%"class.v8::FunctionCallbackInfo"*)*, %"class.v8::String"* (%"class.v8::Isolate"*, i8*)*, i1 (%"class.v8::Context"*)*, i1 (%"class.v8::Context"*)*, %"class.v8::internal::Relocatable"*, %"class.std::__1::vector.1000"*, %"class.v8::internal::Object", i64*, %"class.v8::internal::AddressToIndexHashMap"*, %"class.v8::internal::HeapObjectToIndexHashMap"*, %"class.v8::internal::MicrotaskQueue"*, %"class.v8::internal::CompilationStatistics"*, %"class.v8::internal::CodeTracer"*, i32, void (%"class.v8::PromiseRejectMessage"*)*, %"class.v8::StartupData"*, i32, i32, i32, i64, i8, i8, i32, i8, i32, %"class.v8_inspector::V8Inspector"*, i8, i8, i8, i32, i32, %"class.v8::internal::compiler::NodeObserver"*, i8, [128 x i32], [256 x i32], [251 x i32], [251 x i32], %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.std::__1::unique_ptr.1008", i32, i8, i8, i32, i32, %"class.std::__1::vector.1014", %"class.std::__1::vector.1014", void (%"class.v8::Isolate"*, i32)*, %"class.std::__1::shared_ptr.1021", i64, %"class.std::__1::unordered_map.1022", i64, %"struct.v8::metrics::LongTaskStats", %"class.std::__1::vector.497", %"class.v8::internal::BuiltinsConstantsTableBuilder"*, i8*, i32, i8*, i32, %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::shared_ptr.115", %"class.v8::internal::FutexWaitListNode", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::debug::ConsoleDelegate"*, %"class.v8::debug::AsyncEventDelegate"*, i32, i32, %"class.std::__1::unique_ptr.1074", i1 (%"class.v8::Isolate"*)*, i8, %"class.v8::base::Mutex", %"struct.v8::internal::ManagedPtrDestructor"*, i64, i64, %"class.v8::internal::wasm::WasmEngine"*, %"class.std::__1::unique_ptr.1088", %"class.v8::internal::EmbeddedFileWriterInterface"*, %"class.v8::Context::BackupIncumbentScope"*, {}*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate::ThreadDataTable", i8, %"class.v8::internal::Isolate"*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"struct.std::__1::atomic.1122", %"class.std::__1::vector.1126", %"class.std::__1::vector.1126", void (i32, %"class.std::__1::basic_string"*)* }
%"class.v8::internal::IsolateData" = type { [4 x i8*], i64, i64, i64, i64, i64, %"class.v8::internal::StackGuard", %"class.v8::internal::RootsTable", %"class.v8::internal::ExternalReferenceTable", %"class.v8::internal::ThreadLocalTop", [1711 x i64], [1711 x i64], i8, [15 x i8] }
%"class.v8::internal::StackGuard" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::StackGuard::ThreadLocal" }
%"class.v8::internal::StackGuard::ThreadLocal" = type { i64, i64, i64, i64, %"class.v8::internal::InterruptsScope"*, i64 }
%"class.v8::internal::InterruptsScope" = type { i32 (...)**, %"class.v8::internal::StackGuard"*, i64, i64, i32, %"class.v8::internal::InterruptsScope"* }
%"class.v8::internal::RootsTable" = type { [669 x i64] }
%"class.v8::internal::ExternalReferenceTable" = type { [1042 x i64], i32, i32 }
%"class.v8::internal::ThreadLocalTop" = type { %"class.v8::TryCatch"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Context", %"struct.std::__1::atomic.704", %"class.v8::internal::Object", %"class.v8::internal::Context", i64, i64, i64, i64, i64, %"class.v8::internal::Object", i8, i8, %"class.v8::internal::Object", i64, i64, i64, %"class.v8::internal::PromiseOnStack"*, %"class.v8::internal::Simulator"*, i64, %"class.v8::internal::ExternalCallbackScope"*, i32, void (%"class.v8::Object"*, i32, %"class.v8::Value"*)*, i64 }
%"class.v8::TryCatch" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::TryCatch"*, i8*, i8*, i8*, i8, [7 x i8] }>
%"struct.std::__1::atomic.704" = type { %"struct.std::__1::__atomic_base.705" }
%"struct.std::__1::__atomic_base.705" = type { %"struct.std::__1::__cxx_atomic_impl.706" }
%"struct.std::__1::__cxx_atomic_impl.706" = type { %"struct.std::__1::__cxx_atomic_base_impl.707" }
%"struct.std::__1::__cxx_atomic_base_impl.707" = type { %"class.v8::internal::ThreadId" }
%"class.v8::internal::ThreadId" = type { i32 }
%"class.v8::internal::Context" = type { %"class.v8::internal::TorqueGeneratedContext" }
%"class.v8::internal::TorqueGeneratedContext" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::PromiseOnStack" = type { %"class.v8::internal::Handle", %"class.v8::internal::PromiseOnStack"* }
%"class.v8::internal::Handle" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HandleBase" = type { i64* }
%"class.v8::internal::Simulator" = type opaque
%"class.v8::internal::ExternalCallbackScope" = type opaque
%"class.v8::Object" = type { i8 }
%"class.v8::Value" = type { i8 }
%"class.std::__1::unique_ptr.709" = type { %"class.std::__1::__compressed_pair.710" }
%"class.std::__1::__compressed_pair.710" = type { %"struct.std::__1::__compressed_pair_elem.711" }
%"struct.std::__1::__compressed_pair_elem.711" = type { %"class.v8::internal::IsolateAllocator"* }
%"class.v8::internal::IsolateAllocator" = type { i8*, %"class.v8::PageAllocator"* }
%"class.v8::internal::ReadOnlyHeap" = type { i32 (...)**, i8, %"class.v8::internal::ReadOnlySpace"*, %"class.std::__1::vector.497" }
%"class.std::__1::shared_ptr.715" = type { %"class.v8::internal::ReadOnlyArtifacts"*, %"class.std::__1::__shared_weak_count"* }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.std::__1::unique_ptr.716" = type { %"class.std::__1::__compressed_pair.717" }
%"class.std::__1::__compressed_pair.717" = type { %"struct.std::__1::__compressed_pair_elem.718" }
%"struct.std::__1::__compressed_pair_elem.718" = type { %"class.v8::internal::StringTable"* }
%"class.v8::internal::StringTable" = type { %"struct.std::__1::atomic.719", %"class.v8::base::Mutex" }
%"struct.std::__1::atomic.719" = type { %"struct.std::__1::__atomic_base.720" }
%"struct.std::__1::__atomic_base.720" = type { %"struct.std::__1::__cxx_atomic_impl.721" }
%"struct.std::__1::__cxx_atomic_impl.721" = type { %"struct.std::__1::__cxx_atomic_base_impl.722" }
%"struct.std::__1::__cxx_atomic_base_impl.722" = type { %"class.v8::internal::StringTable::Data"* }
%"class.v8::internal::StringTable::Data" = type opaque
%"class.v8::internal::Isolate::EntryStackItem" = type { i32, %"class.v8::internal::Isolate::PerIsolateThreadData"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate::EntryStackItem"* }
%"class.v8::internal::Isolate::PerIsolateThreadData" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::ThreadId", i64, %"class.v8::internal::ThreadState"* }
%"class.v8::internal::ThreadState" = type opaque
%"class.v8::internal::StringStream" = type opaque
%"class.v8::internal::Bootstrapper" = type { %"class.v8::internal::Isolate"*, i32, %"class.v8::internal::SourceCodeCache" }
%"class.v8::internal::SourceCodeCache" = type { i32, %"class.v8::internal::FixedArray" }
%"class.v8::internal::FixedArray" = type { %"class.v8::internal::TorqueGeneratedFixedArray" }
%"class.v8::internal::TorqueGeneratedFixedArray" = type { %"class.v8::internal::FixedArrayBase" }
%"class.v8::internal::FixedArrayBase" = type { %"class.v8::internal::TorqueGeneratedFixedArrayBase" }
%"class.v8::internal::TorqueGeneratedFixedArrayBase" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::RuntimeProfiler" = type opaque
%"class.v8::internal::CompilationCache" = type opaque
%"class.std::__1::shared_ptr.726" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::Counters" = type { %"class.std::__1::enable_shared_from_this", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::AggregatableHistogramTimer", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::RuntimeCallStats", %"class.v8::internal::WorkerThreadRuntimeCallStats", %"class.v8::internal::Isolate"*, %"class.v8::internal::StatsTable" }
%"class.std::__1::enable_shared_from_this" = type { %"class.std::__1::weak_ptr" }
%"class.std::__1::weak_ptr" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::HistogramTimer" = type { %"class.v8::internal::TimedHistogram.base", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::TimedHistogram.base" = type <{ %"class.v8::internal::Histogram", i32 }>
%"class.v8::base::ElapsedTimer" = type { %"class.v8::base::TimeTicks" }
%"class.v8::base::TimeTicks" = type { %"class.v8::base::time_internal::TimeBase" }
%"class.v8::base::time_internal::TimeBase" = type { i64 }
%"class.v8::internal::TimedHistogram" = type <{ %"class.v8::internal::Histogram", i32, [4 x i8] }>
%"class.v8::internal::AggregatableHistogramTimer" = type { %"class.v8::internal::Histogram", %"class.v8::base::TimeDelta" }
%"class.v8::base::TimeDelta" = type { i64 }
%"class.v8::internal::Histogram" = type { i8*, i32, i32, i32, i8*, %"class.v8::internal::Counters"* }
%"class.v8::internal::StatsCounterThreadSafe" = type { %"class.v8::internal::StatsCounterBase", %"class.v8::base::Mutex" }
%"class.v8::internal::StatsCounterBase" = type { %"class.v8::internal::Counters"*, i8*, i32* }
%"class.v8::internal::StatsCounter" = type <{ %"class.v8::internal::StatsCounterBase", i8, [7 x i8] }>
%"class.v8::internal::RuntimeCallStats" = type { %"class.v8::base::AtomicValue", %"class.v8::base::AtomicValue.727", i8, i32, %"class.v8::internal::ThreadId", [1370 x %"class.v8::internal::RuntimeCallCounter"] }
%"class.v8::base::AtomicValue" = type { i64 }
%"class.v8::base::AtomicValue.727" = type { i64 }
%"class.v8::internal::RuntimeCallCounter" = type { i8*, i64, i64 }
%"class.v8::internal::WorkerThreadRuntimeCallStats" = type <{ %"class.v8::base::Mutex", %"class.std::__1::vector.728", %"class.v8::base::Optional", %"class.v8::internal::ThreadId", [4 x i8] }>
%"class.std::__1::vector.728" = type { %"class.std::__1::__vector_base.729" }
%"class.std::__1::__vector_base.729" = type { %"class.std::__1::unique_ptr.730"*, %"class.std::__1::unique_ptr.730"*, %"class.std::__1::__compressed_pair.731" }
%"class.std::__1::unique_ptr.730" = type opaque
%"class.std::__1::__compressed_pair.731" = type { %"struct.std::__1::__compressed_pair_elem.732" }
%"struct.std::__1::__compressed_pair_elem.732" = type { %"class.std::__1::unique_ptr.730"* }
%"class.v8::base::Optional" = type { %"class.v8::base::internal::OptionalBase" }
%"class.v8::base::internal::OptionalBase" = type { %"struct.v8::base::internal::OptionalStorage" }
%"struct.v8::base::internal::OptionalStorage" = type { %"struct.v8::base::internal::OptionalStorageBase" }
%"struct.v8::base::internal::OptionalStorageBase" = type { i8, %union.anon.736 }
%union.anon.736 = type { i32 }
%"class.v8::internal::StatsTable" = type { i32* (i8*)*, i8* (i8*, i32, i32, i64)*, void (i8*, i32)* }
%"class.v8::base::RecursiveMutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.v8::internal::Logger" = type { %"class.v8::internal::CodeEventListener", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.737", %"class.std::__1::unique_ptr.743", %"struct.std::__1::atomic.107", %"class.std::__1::unique_ptr.749", %"class.std::__1::unique_ptr.755", %"class.std::__1::unique_ptr.761", %"class.std::__1::unique_ptr.767", %"class.std::__1::unique_ptr.773", %"class.std::__1::set.779", i32, i8, %"class.v8::internal::ExistingCodeLogger", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::CodeEventListener" = type { i32 (...)** }
%"class.std::__1::unique_ptr.737" = type { %"class.std::__1::__compressed_pair.738" }
%"class.std::__1::__compressed_pair.738" = type { %"struct.std::__1::__compressed_pair_elem.739" }
%"struct.std::__1::__compressed_pair_elem.739" = type { %"class.v8::internal::Ticker"* }
%"class.v8::internal::Ticker" = type opaque
%"class.std::__1::unique_ptr.743" = type { %"class.std::__1::__compressed_pair.744" }
%"class.std::__1::__compressed_pair.744" = type { %"struct.std::__1::__compressed_pair_elem.745" }
%"struct.std::__1::__compressed_pair_elem.745" = type { %"class.v8::internal::Profiler"* }
%"class.v8::internal::Profiler" = type opaque
%"class.std::__1::unique_ptr.749" = type { %"class.std::__1::__compressed_pair.750" }
%"class.std::__1::__compressed_pair.750" = type { %"struct.std::__1::__compressed_pair_elem.751" }
%"struct.std::__1::__compressed_pair_elem.751" = type { %"class.v8::internal::Log"* }
%"class.v8::internal::Log" = type opaque
%"class.std::__1::unique_ptr.755" = type { %"class.std::__1::__compressed_pair.756" }
%"class.std::__1::__compressed_pair.756" = type { %"struct.std::__1::__compressed_pair_elem.757" }
%"struct.std::__1::__compressed_pair_elem.757" = type { %"class.v8::internal::PerfBasicLogger"* }
%"class.v8::internal::PerfBasicLogger" = type opaque
%"class.std::__1::unique_ptr.761" = type { %"class.std::__1::__compressed_pair.762" }
%"class.std::__1::__compressed_pair.762" = type { %"struct.std::__1::__compressed_pair_elem.763" }
%"struct.std::__1::__compressed_pair_elem.763" = type { %"class.v8::internal::PerfJitLogger"* }
%"class.v8::internal::PerfJitLogger" = type opaque
%"class.std::__1::unique_ptr.767" = type { %"class.std::__1::__compressed_pair.768" }
%"class.std::__1::__compressed_pair.768" = type { %"struct.std::__1::__compressed_pair_elem.769" }
%"struct.std::__1::__compressed_pair_elem.769" = type { %"class.v8::internal::LowLevelLogger"* }
%"class.v8::internal::LowLevelLogger" = type opaque
%"class.std::__1::unique_ptr.773" = type { %"class.std::__1::__compressed_pair.774" }
%"class.std::__1::__compressed_pair.774" = type { %"struct.std::__1::__compressed_pair_elem.775" }
%"struct.std::__1::__compressed_pair_elem.775" = type { %"class.v8::internal::JitLogger"* }
%"class.v8::internal::JitLogger" = type opaque
%"class.std::__1::set.779" = type { %"class.std::__1::__tree.780" }
%"class.std::__1::__tree.780" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.781", %"class.std::__1::__compressed_pair.785" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.781" = type { %"struct.std::__1::__compressed_pair_elem.440" }
%"struct.std::__1::__compressed_pair_elem.440" = type { %"class.std::__1::__tree_end_node" }
%"class.std::__1::__compressed_pair.785" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::internal::ExistingCodeLogger" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::CodeEventListener"* }
%"class.v8::internal::StubCache" = type { [2048 x %"struct.v8::internal::StubCache::Entry"], [512 x %"struct.v8::internal::StubCache::Entry"], %"class.v8::internal::Isolate"* }
%"struct.v8::internal::StubCache::Entry" = type { %"class.v8::internal::StrongTaggedValue", %"class.v8::internal::TaggedValue", %"class.v8::internal::StrongTaggedValue" }
%"class.v8::internal::TaggedValue" = type { %"class.v8::internal::TaggedImpl.788" }
%"class.v8::internal::TaggedImpl.788" = type { i32 }
%"class.v8::internal::StrongTaggedValue" = type { %"class.v8::internal::TaggedImpl.787" }
%"class.v8::internal::TaggedImpl.787" = type { i32 }
%"class.v8::internal::Deoptimizer" = type opaque
%"class.v8::internal::MaterializedObjectStore" = type opaque
%"class.v8::internal::DescriptorLookupCache" = type { [64 x %"struct.v8::internal::DescriptorLookupCache::Key"], [64 x i32] }
%"struct.v8::internal::DescriptorLookupCache::Key" = type { %"class.v8::internal::Map", %"class.v8::internal::Name" }
%"class.v8::internal::Map" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Name" = type { %"class.v8::internal::TorqueGeneratedName" }
%"class.v8::internal::TorqueGeneratedName" = type { %"class.v8::internal::PrimitiveHeapObject" }
%"class.v8::internal::PrimitiveHeapObject" = type { %"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" }
%"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" = type { %"class.v8::internal::HeapObject" }
%"struct.v8::internal::HandleScopeData" = type { i64*, i64*, i32, i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::CanonicalHandleScope" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::Zone"*, %"class.v8::internal::RootIndexMap"*, %"class.std::__1::unique_ptr.648", i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::OptimizedCompilationInfo" = type opaque
%"class.v8::internal::RootIndexMap" = type opaque
%"class.std::__1::unique_ptr.648" = type { %"class.std::__1::__compressed_pair.649" }
%"class.std::__1::__compressed_pair.649" = type { %"struct.std::__1::__compressed_pair_elem.650" }
%"struct.std::__1::__compressed_pair_elem.650" = type { %"class.v8::internal::IdentityMap"* }
%"class.v8::internal::IdentityMap" = type opaque
%"class.v8::internal::HandleScopeImplementer" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::DetachableVector", %"class.v8::internal::DetachableVector.789", %"class.v8::internal::DetachableVector.790", %"class.v8::internal::DetachableVector.789", i64*, i64*, %"struct.v8::internal::HandleScopeData" }
%"class.v8::internal::DetachableVector" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVectorBase" = type { i8*, i64, i64 }
%"class.v8::internal::DetachableVector.790" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVector.789" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::UnicodeCache" = type opaque
%"class.v8::internal::AccountingAllocator" = type { i32 (...)**, %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.std::__1::unique_ptr.642", %"class.std::__1::unique_ptr.436" }
%"class.std::__1::unique_ptr.642" = type { %"class.std::__1::__compressed_pair.643" }
%"class.std::__1::__compressed_pair.643" = type { %"struct.std::__1::__compressed_pair_elem.644" }
%"struct.std::__1::__compressed_pair_elem.644" = type { %"class.v8::internal::VirtualMemory"* }
%"class.std::__1::unique_ptr.436" = type { %"class.std::__1::__compressed_pair.437" }
%"class.std::__1::__compressed_pair.437" = type { %"struct.std::__1::__compressed_pair_elem.438" }
%"struct.std::__1::__compressed_pair_elem.438" = type { %"class.v8::base::BoundedPageAllocator"* }
%"class.v8::base::BoundedPageAllocator" = type { %"class.v8::PageAllocator", %"class.v8::base::Mutex", i64, i64, %"class.v8::PageAllocator"*, %"class.v8::base::RegionAllocator" }
%"class.v8::PageAllocator" = type { i32 (...)** }
%"class.v8::base::RegionAllocator" = type { %"class.v8::base::RegionAllocator::Region", i64, i64, i64, i64, %"class.std::__1::set", %"class.std::__1::set.446" }
%"class.v8::base::RegionAllocator::Region" = type <{ %"class.v8::base::AddressRegion", i32, [4 x i8] }>
%"class.v8::base::AddressRegion" = type { i64, i64 }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.439", %"class.std::__1::__compressed_pair.444" }
%"class.std::__1::__compressed_pair.439" = type { %"struct.std::__1::__compressed_pair_elem.440" }
%"class.std::__1::__compressed_pair.444" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::set.446" = type { %"class.std::__1::__tree.447" }
%"class.std::__1::__tree.447" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.439", %"class.std::__1::__compressed_pair.448" }
%"class.std::__1::__compressed_pair.448" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::internal::InnerPointerToCodeCache" = type opaque
%"class.v8::internal::GlobalHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.791", %"class.std::__1::vector.797", %"class.std::__1::unique_ptr.804", %"class.std::__1::vector.811", %"class.std::__1::unique_ptr.818", i64, %"class.std::__1::vector.824", %"class.std::__1::vector.832", %"class.std::__1::vector.840", i8, i8, i32 }
%"class.std::__1::unique_ptr.791" = type { %"class.std::__1::__compressed_pair.792" }
%"class.std::__1::__compressed_pair.792" = type { %"struct.std::__1::__compressed_pair_elem.793" }
%"struct.std::__1::__compressed_pair_elem.793" = type { %"class.v8::internal::GlobalHandles::NodeSpace"* }
%"class.v8::internal::GlobalHandles::NodeSpace" = type opaque
%"class.std::__1::vector.797" = type { %"class.std::__1::__vector_base.798" }
%"class.std::__1::__vector_base.798" = type { %"class.v8::internal::GlobalHandles::Node"**, %"class.v8::internal::GlobalHandles::Node"**, %"class.std::__1::__compressed_pair.799" }
%"class.v8::internal::GlobalHandles::Node" = type opaque
%"class.std::__1::__compressed_pair.799" = type { %"struct.std::__1::__compressed_pair_elem.800" }
%"struct.std::__1::__compressed_pair_elem.800" = type { %"class.v8::internal::GlobalHandles::Node"** }
%"class.std::__1::unique_ptr.804" = type { %"class.std::__1::__compressed_pair.805" }
%"class.std::__1::__compressed_pair.805" = type { %"struct.std::__1::__compressed_pair_elem.806" }
%"struct.std::__1::__compressed_pair_elem.806" = type { %"class.v8::internal::GlobalHandles::NodeSpace.807"* }
%"class.v8::internal::GlobalHandles::NodeSpace.807" = type opaque
%"class.std::__1::vector.811" = type { %"class.std::__1::__vector_base.812" }
%"class.std::__1::__vector_base.812" = type { %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.std::__1::__compressed_pair.813" }
%"class.v8::internal::GlobalHandles::TracedNode" = type opaque
%"class.std::__1::__compressed_pair.813" = type { %"struct.std::__1::__compressed_pair_elem.814" }
%"struct.std::__1::__compressed_pair_elem.814" = type { %"class.v8::internal::GlobalHandles::TracedNode"** }
%"class.std::__1::unique_ptr.818" = type { %"class.std::__1::__compressed_pair.819" }
%"class.std::__1::__compressed_pair.819" = type { %"struct.std::__1::__compressed_pair_elem.820" }
%"struct.std::__1::__compressed_pair_elem.820" = type { %"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace"* }
%"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace" = type opaque
%"class.std::__1::vector.824" = type { %"class.std::__1::__vector_base.825" }
%"class.std::__1::__vector_base.825" = type { %"struct.std::__1::pair.826"*, %"struct.std::__1::pair.826"*, %"class.std::__1::__compressed_pair.827" }
%"struct.std::__1::pair.826" = type opaque
%"class.std::__1::__compressed_pair.827" = type { %"struct.std::__1::__compressed_pair_elem.828" }
%"struct.std::__1::__compressed_pair_elem.828" = type { %"struct.std::__1::pair.826"* }
%"class.std::__1::vector.832" = type { %"class.std::__1::__vector_base.833" }
%"class.std::__1::__vector_base.833" = type { %"struct.std::__1::pair.834"*, %"struct.std::__1::pair.834"*, %"class.std::__1::__compressed_pair.835" }
%"struct.std::__1::pair.834" = type opaque
%"class.std::__1::__compressed_pair.835" = type { %"struct.std::__1::__compressed_pair_elem.836" }
%"struct.std::__1::__compressed_pair_elem.836" = type { %"struct.std::__1::pair.834"* }
%"class.std::__1::vector.840" = type { %"class.std::__1::__vector_base.841" }
%"class.std::__1::__vector_base.841" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.std::__1::__compressed_pair.842" }
%"class.v8::internal::GlobalHandles::PendingPhantomCallback" = type { void (%"class.v8::WeakCallbackInfo"*)*, i8*, [2 x i8*] }
%"class.v8::WeakCallbackInfo" = type { %"class.v8::Isolate"*, i8*, {}**, [2 x i8*] }
%"class.v8::Isolate" = type { i8 }
%"class.std::__1::__compressed_pair.842" = type { %"struct.std::__1::__compressed_pair_elem.843" }
%"struct.std::__1::__compressed_pair_elem.843" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"* }
%"class.v8::internal::EternalHandles" = type { i32, %"class.std::__1::vector.654", %"class.std::__1::vector.847" }
%"class.std::__1::vector.654" = type { %"class.std::__1::__vector_base.655" }
%"class.std::__1::__vector_base.655" = type { i64**, i64**, %"class.std::__1::__compressed_pair.656" }
%"class.std::__1::__compressed_pair.656" = type { %"struct.std::__1::__compressed_pair_elem.657" }
%"struct.std::__1::__compressed_pair_elem.657" = type { i64** }
%"class.v8::internal::ThreadManager" = type opaque
%"class.v8::bigint::Processor" = type opaque
%"class.v8::internal::RuntimeState" = type { %"class.std::__1::unique_ptr.854" }
%"class.std::__1::unique_ptr.854" = type { %"class.std::__1::__compressed_pair.855" }
%"class.std::__1::__compressed_pair.855" = type { %"struct.std::__1::__compressed_pair_elem.856" }
%"struct.std::__1::__compressed_pair_elem.856" = type { %"struct.v8::internal::Runtime::Function"* }
%"struct.v8::internal::Runtime::Function" = type { i32, i32, i8*, i64, i8, i8 }
%"class.v8::internal::Builtins" = type { %"class.v8::internal::Isolate"*, i8, i32 }
%"class.v8::internal::SetupIsolateDelegate" = type opaque
%"class.v8::internal::RegExpStack" = type opaque
%"class.std::__1::vector.847" = type { %"class.std::__1::__vector_base.848" }
%"class.std::__1::__vector_base.848" = type { i32*, i32*, %"class.std::__1::__compressed_pair.849" }
%"class.std::__1::__compressed_pair.849" = type { %"struct.std::__1::__compressed_pair_elem.850" }
%"struct.std::__1::__compressed_pair_elem.850" = type { i32* }
%"class.v8::internal::DateCache" = type opaque
%"class.v8::base::RandomNumberGenerator" = type { i64, i64, i64 }
%"struct.std::__1::atomic.860" = type { %"struct.std::__1::__atomic_base.861" }
%"struct.std::__1::__atomic_base.861" = type { %"struct.std::__1::__cxx_atomic_impl.862" }
%"struct.std::__1::__cxx_atomic_impl.862" = type { %"struct.std::__1::__cxx_atomic_base_impl.863" }
%"struct.std::__1::__cxx_atomic_base_impl.863" = type { i32 }
%"class.v8::Promise" = type { i8 }
%"struct.std::__1::atomic.870" = type { %"struct.std::__1::__atomic_base.871" }
%"struct.std::__1::__atomic_base.871" = type { %"struct.std::__1::__cxx_atomic_impl.872" }
%"struct.std::__1::__cxx_atomic_impl.872" = type { %"struct.std::__1::__cxx_atomic_base_impl.873" }
%"struct.std::__1::__cxx_atomic_base_impl.873" = type { i32 }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair.875" }
%"class.std::__1::__compressed_pair.875" = type { %"struct.std::__1::__compressed_pair_elem.876" }
%"struct.std::__1::__compressed_pair_elem.876" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon.877 }
%union.anon.877 = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%"class.std::__1::unordered_map.882" = type { %"class.std::__1::__hash_table.883" }
%"class.std::__1::__hash_table.883" = type <{ %"class.std::__1::unique_ptr.884", %"class.std::__1::__compressed_pair.894", %"class.std::__1::__compressed_pair.899", %"class.std::__1::__compressed_pair.902", [4 x i8] }>
%"class.std::__1::unique_ptr.884" = type { %"class.std::__1::__compressed_pair.885" }
%"class.std::__1::__compressed_pair.885" = type { %"struct.std::__1::__compressed_pair_elem.886", %"struct.std::__1::__compressed_pair_elem.888" }
%"struct.std::__1::__compressed_pair_elem.886" = type { %"struct.std::__1::__hash_node_base.887"** }
%"struct.std::__1::__hash_node_base.887" = type { %"struct.std::__1::__hash_node_base.887"* }
%"struct.std::__1::__compressed_pair_elem.888" = type { %"class.std::__1::__bucket_list_deallocator.889" }
%"class.std::__1::__bucket_list_deallocator.889" = type { %"class.std::__1::__compressed_pair.890" }
%"class.std::__1::__compressed_pair.890" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.894" = type { %"struct.std::__1::__compressed_pair_elem.895" }
%"struct.std::__1::__compressed_pair_elem.895" = type { %"struct.std::__1::__hash_node_base.887" }
%"class.std::__1::__compressed_pair.899" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.902" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::atomic.107" = type { %"struct.std::__1::__atomic_base.108" }
%"struct.std::__1::__atomic_base.108" = type { %"struct.std::__1::__cxx_atomic_impl.109" }
%"struct.std::__1::__cxx_atomic_impl.109" = type { %"struct.std::__1::__cxx_atomic_base_impl.110" }
%"struct.std::__1::__cxx_atomic_base_impl.110" = type { i8 }
%"class.v8::internal::Debug" = type { %"class.v8::debug::DebugDelegate"*, i8, i8, i8, i8, i8, i8, i8, i8, i8, %"class.v8::internal::DebugInfoListNode"*, %"class.std::__1::unique_ptr.908", %"class.v8::internal::Handle.914", %"class.v8::internal::DebugFeatureTracker", %"class.v8::internal::Debug::ThreadLocal", %"class.v8::internal::Handle.915", %"class.v8::internal::Isolate"* }
%"class.v8::debug::DebugDelegate" = type { i32 (...)** }
%"class.v8::internal::DebugInfoListNode" = type { i64*, %"class.v8::internal::DebugInfoListNode"* }
%"class.std::__1::unique_ptr.908" = type { %"class.std::__1::__compressed_pair.909" }
%"class.std::__1::__compressed_pair.909" = type { %"struct.std::__1::__compressed_pair_elem.910" }
%"struct.std::__1::__compressed_pair_elem.910" = type { %"class.v8::internal::Debug::TemporaryObjectsTracker"* }
%"class.v8::internal::Debug::TemporaryObjectsTracker" = type opaque
%"class.v8::internal::Handle.914" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::DebugFeatureTracker" = type <{ %"class.v8::internal::Isolate"*, i32, [4 x i8] }>
%"class.v8::internal::Debug::ThreadLocal" = type <{ i64, i32, i8, [3 x i8], %"class.v8::internal::Object", i8, [3 x i8], i32, i32, i32, %"class.v8::internal::Object", %"class.v8::internal::Object", i32, i8, [3 x i8] }>
%"class.v8::internal::Handle.915" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HeapProfiler" = type { %"class.v8::internal::HeapObjectAllocationTracker", %"class.std::__1::unique_ptr.916", %"class.std::__1::vector.922", %"class.std::__1::unique_ptr.930", %"class.std::__1::unique_ptr.936", i8, i8, %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.942", %"class.std::__1::vector.948", %"struct.std::__1::pair.956" }
%"class.v8::internal::HeapObjectAllocationTracker" = type { i32 (...)** }
%"class.std::__1::unique_ptr.916" = type { %"class.std::__1::__compressed_pair.917" }
%"class.std::__1::__compressed_pair.917" = type { %"struct.std::__1::__compressed_pair_elem.918" }
%"struct.std::__1::__compressed_pair_elem.918" = type { %"class.v8::internal::HeapObjectsMap"* }
%"class.v8::internal::HeapObjectsMap" = type opaque
%"class.std::__1::vector.922" = type { %"class.std::__1::__vector_base.923" }
%"class.std::__1::__vector_base.923" = type { %"class.std::__1::unique_ptr.924"*, %"class.std::__1::unique_ptr.924"*, %"class.std::__1::__compressed_pair.925" }
%"class.std::__1::unique_ptr.924" = type opaque
%"class.std::__1::__compressed_pair.925" = type { %"struct.std::__1::__compressed_pair_elem.926" }
%"struct.std::__1::__compressed_pair_elem.926" = type { %"class.std::__1::unique_ptr.924"* }
%"class.std::__1::unique_ptr.930" = type { %"class.std::__1::__compressed_pair.931" }
%"class.std::__1::__compressed_pair.931" = type { %"struct.std::__1::__compressed_pair_elem.932" }
%"struct.std::__1::__compressed_pair_elem.932" = type { %"class.v8::internal::StringsStorage"* }
%"class.v8::internal::StringsStorage" = type opaque
%"class.std::__1::unique_ptr.936" = type { %"class.std::__1::__compressed_pair.937" }
%"class.std::__1::__compressed_pair.937" = type { %"struct.std::__1::__compressed_pair_elem.938" }
%"struct.std::__1::__compressed_pair_elem.938" = type { %"class.v8::internal::AllocationTracker"* }
%"class.v8::internal::AllocationTracker" = type opaque
%"class.std::__1::unique_ptr.942" = type { %"class.std::__1::__compressed_pair.943" }
%"class.std::__1::__compressed_pair.943" = type { %"struct.std::__1::__compressed_pair_elem.944" }
%"struct.std::__1::__compressed_pair_elem.944" = type { %"class.v8::internal::SamplingHeapProfiler"* }
%"class.v8::internal::SamplingHeapProfiler" = type opaque
%"class.std::__1::vector.948" = type { %"class.std::__1::__vector_base.949" }
%"class.std::__1::__vector_base.949" = type { %"struct.std::__1::pair.950"*, %"struct.std::__1::pair.950"*, %"class.std::__1::__compressed_pair.951" }
%"struct.std::__1::pair.950" = type opaque
%"class.std::__1::__compressed_pair.951" = type { %"struct.std::__1::__compressed_pair_elem.952" }
%"struct.std::__1::__compressed_pair_elem.952" = type { %"struct.std::__1::pair.950"* }
%"struct.std::__1::pair.956" = type { i8 (%"class.v8::Isolate"*, %"class.v8::Local.708"*, i16, i8*)*, i8* }
%"class.v8::Local.708" = type { %"class.v8::Value"* }
%"class.std::__1::unique_ptr.957" = type { %"class.std::__1::__compressed_pair.958" }
%"class.std::__1::__compressed_pair.958" = type { %"struct.std::__1::__compressed_pair_elem.959" }
%"struct.std::__1::__compressed_pair_elem.959" = type { %"class.v8::internal::CodeEventDispatcher"* }
%"class.v8::internal::CodeEventDispatcher" = type { %"class.v8::internal::CodeEventListener", %"class.std::__1::unordered_set.960", %"class.v8::base::Mutex" }
%"class.std::__1::unordered_set.960" = type { %"class.std::__1::__hash_table.961" }
%"class.std::__1::__hash_table.961" = type <{ %"class.std::__1::unique_ptr.962", %"class.std::__1::__compressed_pair.972", %"class.std::__1::__compressed_pair.977", %"class.std::__1::__compressed_pair.981", [4 x i8] }>
%"class.std::__1::unique_ptr.962" = type { %"class.std::__1::__compressed_pair.963" }
%"class.std::__1::__compressed_pair.963" = type { %"struct.std::__1::__compressed_pair_elem.964", %"struct.std::__1::__compressed_pair_elem.966" }
%"struct.std::__1::__compressed_pair_elem.964" = type { %"struct.std::__1::__hash_node_base.965"** }
%"struct.std::__1::__hash_node_base.965" = type { %"struct.std::__1::__hash_node_base.965"* }
%"struct.std::__1::__compressed_pair_elem.966" = type { %"class.std::__1::__bucket_list_deallocator.967" }
%"class.std::__1::__bucket_list_deallocator.967" = type { %"class.std::__1::__compressed_pair.968" }
%"class.std::__1::__compressed_pair.968" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.972" = type { %"struct.std::__1::__compressed_pair_elem.973" }
%"struct.std::__1::__compressed_pair_elem.973" = type { %"struct.std::__1::__hash_node_base.965" }
%"class.std::__1::__compressed_pair.977" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.981" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::AstStringConstants" = type opaque
%"class.v8::internal::interpreter::Interpreter" = type opaque
%"class.v8::internal::compiler::PerIsolateCompilerCache" = type opaque
%"class.v8::internal::Zone" = type <{ i64, i64, i64, i64, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::Segment"*, i8*, i8, i8, [6 x i8] }>
%"class.v8::internal::Segment" = type { %"class.v8::internal::Zone"*, %"class.v8::internal::Segment"*, i64 }
%"class.v8::internal::CompilerDispatcher" = type opaque
%"class.std::__1::queue" = type { %"class.std::__1::deque" }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.995" }
%"struct.std::__1::__split_buffer" = type { %"struct.std::__1::pair.989"**, %"struct.std::__1::pair.989"**, %"struct.std::__1::pair.989"**, %"class.std::__1::__compressed_pair.990" }
%"struct.std::__1::pair.989" = type opaque
%"class.std::__1::__compressed_pair.990" = type { %"struct.std::__1::__compressed_pair_elem.991" }
%"struct.std::__1::__compressed_pair_elem.991" = type { %"struct.std::__1::pair.989"** }
%"class.std::__1::__compressed_pair.995" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::String" = type { i8 }
%"class.v8::Context" = type { i8 }
%"class.v8::FunctionCallbackInfo" = type <{ i64*, i64*, i32, [4 x i8] }>
%"class.v8::internal::Relocatable" = type { i32 (...)**, %"class.v8::internal::Isolate"*, %"class.v8::internal::Relocatable"* }
%"class.std::__1::vector.1000" = type { %"class.std::__1::__vector_base.1001" }
%"class.std::__1::__vector_base.1001" = type { %"class.v8::internal::Handle.1002"*, %"class.v8::internal::Handle.1002"*, %"class.std::__1::__compressed_pair.1003" }
%"class.v8::internal::Handle.1002" = type { %"class.v8::internal::HandleBase" }
%"class.std::__1::__compressed_pair.1003" = type { %"struct.std::__1::__compressed_pair_elem.1004" }
%"struct.std::__1::__compressed_pair_elem.1004" = type { %"class.v8::internal::Handle.1002"* }
%"class.v8::internal::AddressToIndexHashMap" = type opaque
%"class.v8::internal::HeapObjectToIndexHashMap" = type opaque
%"class.v8::internal::MicrotaskQueue" = type opaque
%"class.v8::internal::CompilationStatistics" = type opaque
%"class.v8::internal::CodeTracer" = type <{ %"class.v8::internal::EmbeddedVector", %struct._IO_FILE*, i32, [4 x i8] }>
%"class.v8::internal::EmbeddedVector" = type { %"class.v8::internal::Vector", [128 x i8] }
%"class.v8::internal::Vector" = type { i8*, i64 }
%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%"class.v8::PromiseRejectMessage" = type { %"class.v8::Local.865", i32, %"class.v8::Local.708" }
%"class.v8::Local.865" = type { %"class.v8::Promise"* }
%"class.v8::StartupData" = type { i8*, i32 }
%"class.v8_inspector::V8Inspector" = type opaque
%"class.v8::internal::compiler::NodeObserver" = type opaque
%"class.v8::internal::OptimizingCompileDispatcher" = type opaque
%"class.std::__1::unique_ptr.1008" = type { %"class.std::__1::__compressed_pair.1009" }
%"class.std::__1::__compressed_pair.1009" = type { %"struct.std::__1::__compressed_pair_elem.1010" }
%"struct.std::__1::__compressed_pair_elem.1010" = type { %"class.v8::internal::PersistentHandlesList"* }
%"class.v8::internal::PersistentHandlesList" = type { %"class.v8::base::Mutex", %"class.v8::internal::PersistentHandles"* }
%"class.v8::internal::PersistentHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::vector.654", i64*, i64*, %"class.v8::internal::PersistentHandles"*, %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.1014" = type { %"class.std::__1::__vector_base.1015" }
%"class.std::__1::__vector_base.1015" = type { void (%"class.v8::Isolate"*)**, void (%"class.v8::Isolate"*)**, %"class.std::__1::__compressed_pair.1016" }
%"class.std::__1::__compressed_pair.1016" = type { %"struct.std::__1::__compressed_pair_elem.1017" }
%"struct.std::__1::__compressed_pair_elem.1017" = type { void (%"class.v8::Isolate"*)** }
%"class.std::__1::shared_ptr.1021" = type { %"class.v8::internal::metrics::Recorder"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::metrics::Recorder" = type opaque
%"class.std::__1::unordered_map.1022" = type { %"class.std::__1::__hash_table.1023" }
%"class.std::__1::__hash_table.1023" = type <{ %"class.std::__1::unique_ptr.1024", %"class.std::__1::__compressed_pair.1034", %"class.std::__1::__compressed_pair.1039", %"class.std::__1::__compressed_pair.1042", [4 x i8] }>
%"class.std::__1::unique_ptr.1024" = type { %"class.std::__1::__compressed_pair.1025" }
%"class.std::__1::__compressed_pair.1025" = type { %"struct.std::__1::__compressed_pair_elem.1026", %"struct.std::__1::__compressed_pair_elem.1028" }
%"struct.std::__1::__compressed_pair_elem.1026" = type { %"struct.std::__1::__hash_node_base.1027"** }
%"struct.std::__1::__hash_node_base.1027" = type { %"struct.std::__1::__hash_node_base.1027"* }
%"struct.std::__1::__compressed_pair_elem.1028" = type { %"class.std::__1::__bucket_list_deallocator.1029" }
%"class.std::__1::__bucket_list_deallocator.1029" = type { %"class.std::__1::__compressed_pair.1030" }
%"class.std::__1::__compressed_pair.1030" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1034" = type { %"struct.std::__1::__compressed_pair_elem.1035" }
%"struct.std::__1::__compressed_pair_elem.1035" = type { %"struct.std::__1::__hash_node_base.1027" }
%"class.std::__1::__compressed_pair.1039" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1042" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.v8::metrics::LongTaskStats" = type { i64, i64, i64 }
%"class.std::__1::vector.497" = type { %"class.std::__1::__vector_base.498" }
%"class.std::__1::__vector_base.498" = type { %"class.v8::internal::Object"*, %"class.v8::internal::Object"*, %"class.std::__1::__compressed_pair.499" }
%"class.std::__1::__compressed_pair.499" = type { %"struct.std::__1::__compressed_pair_elem.500" }
%"struct.std::__1::__compressed_pair_elem.500" = type { %"class.v8::internal::Object"* }
%"class.v8::internal::BuiltinsConstantsTableBuilder" = type opaque
%"class.v8::ArrayBuffer::Allocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.115" = type { %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::FutexWaitListNode" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::shared_ptr.1046", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::base::ConditionVariable", %"class.v8::internal::FutexWaitListNode"*, %"class.v8::internal::FutexWaitListNode"*, %"class.std::__1::weak_ptr.1071", i64, i8*, i8, i8, %"class.v8::Global", %"class.v8::Global.1072", %"class.v8::base::TimeTicks", i64 }
%"class.std::__1::shared_ptr.1046" = type { %"class.v8::TaskRunner"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::TaskRunner" = type { i32 (...)** }
%"class.v8::base::ConditionVariable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon, %union.anon.492, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon = type { i64 }
%union.anon.492 = type { i64 }
%"class.std::__1::weak_ptr.1071" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::BackingStore" = type <{ i8*, %"struct.std::__1::atomic", i64, %"union.v8::internal::BackingStore::TypeSpecificData", i16, [6 x i8] }>
%"union.v8::internal::BackingStore::TypeSpecificData" = type { %"class.std::__1::shared_ptr.115" }
%"class.v8::Global" = type { %"class.v8::PersistentBase" }
%"class.v8::PersistentBase" = type { %"class.v8::Promise"* }
%"class.v8::Global.1072" = type { %"class.v8::PersistentBase.1073" }
%"class.v8::PersistentBase.1073" = type { %"class.v8::Context"* }
%"class.v8::internal::CancelableTaskManager" = type <{ i64, %"class.std::__1::unordered_map.1047", %"class.v8::base::ConditionVariable", %"class.v8::base::Mutex", i8, [7 x i8] }>
%"class.std::__1::unordered_map.1047" = type { %"class.std::__1::__hash_table.1048" }
%"class.std::__1::__hash_table.1048" = type <{ %"class.std::__1::unique_ptr.1049", %"class.std::__1::__compressed_pair.1059", %"class.std::__1::__compressed_pair.1064", %"class.std::__1::__compressed_pair.1067", [4 x i8] }>
%"class.std::__1::unique_ptr.1049" = type { %"class.std::__1::__compressed_pair.1050" }
%"class.std::__1::__compressed_pair.1050" = type { %"struct.std::__1::__compressed_pair_elem.1051", %"struct.std::__1::__compressed_pair_elem.1053" }
%"struct.std::__1::__compressed_pair_elem.1051" = type { %"struct.std::__1::__hash_node_base.1052"** }
%"struct.std::__1::__hash_node_base.1052" = type { %"struct.std::__1::__hash_node_base.1052"* }
%"struct.std::__1::__compressed_pair_elem.1053" = type { %"class.std::__1::__bucket_list_deallocator.1054" }
%"class.std::__1::__bucket_list_deallocator.1054" = type { %"class.std::__1::__compressed_pair.1055" }
%"class.std::__1::__compressed_pair.1055" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1059" = type { %"struct.std::__1::__compressed_pair_elem.1060" }
%"struct.std::__1::__compressed_pair_elem.1060" = type { %"struct.std::__1::__hash_node_base.1052" }
%"class.std::__1::__compressed_pair.1064" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1067" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::debug::ConsoleDelegate" = type { i32 (...)** }
%"class.v8::debug::AsyncEventDelegate" = type { i32 (...)** }
%"class.std::__1::unique_ptr.1074" = type { %"class.std::__1::__compressed_pair.1075" }
%"class.std::__1::__compressed_pair.1075" = type { %"struct.std::__1::__compressed_pair_elem.1076" }
%"struct.std::__1::__compressed_pair_elem.1076" = type { %"class.v8::internal::LocalIsolate"* }
%"class.v8::internal::LocalIsolate" = type { %"class.v8::internal::HiddenLocalFactory", %"class.v8::internal::LocalHeap", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.1079", %"class.v8::internal::ThreadId", i64, %"class.v8::internal::RuntimeCallStats"* }
%"class.v8::internal::HiddenLocalFactory" = type { %"class.v8::internal::LocalFactory" }
%"class.v8::internal::LocalFactory" = type { %"class.v8::internal::ReadOnlyRoots" }
%"class.v8::internal::ReadOnlyRoots" = type { i64* }
%"class.v8::internal::LocalHeap" = type { %"class.v8::internal::Heap"*, i8, %"struct.std::__1::atomic.635", i8, i8, %"class.v8::internal::LocalHeap"*, %"class.v8::internal::LocalHeap"*, %"class.std::__1::unique_ptr.639", %"class.std::__1::unique_ptr.664", %"class.std::__1::unique_ptr.429", %"class.std::__1::vector.670", %"class.v8::internal::ConcurrentAllocator" }
%"struct.std::__1::atomic.635" = type { %"struct.std::__1::__atomic_base.636" }
%"struct.std::__1::__atomic_base.636" = type { %"struct.std::__1::__cxx_atomic_impl.637" }
%"struct.std::__1::__cxx_atomic_impl.637" = type { %"struct.std::__1::__cxx_atomic_base_impl.638" }
%"struct.std::__1::__cxx_atomic_base_impl.638" = type { i32 }
%"class.std::__1::unique_ptr.639" = type { %"class.std::__1::__compressed_pair.640" }
%"class.std::__1::__compressed_pair.640" = type { %"struct.std::__1::__compressed_pair_elem.641" }
%"struct.std::__1::__compressed_pair_elem.641" = type { %"class.v8::internal::LocalHandles"* }
%"class.v8::internal::LocalHandles" = type { %"struct.v8::internal::HandleScopeData", %"class.std::__1::vector.654" }
%"class.std::__1::unique_ptr.664" = type { %"class.std::__1::__compressed_pair.665" }
%"class.std::__1::__compressed_pair.665" = type { %"struct.std::__1::__compressed_pair_elem.666" }
%"struct.std::__1::__compressed_pair_elem.666" = type { %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.670" = type { %"class.std::__1::__vector_base.671" }
%"class.std::__1::__vector_base.671" = type { %"struct.std::__1::pair.672"*, %"struct.std::__1::pair.672"*, %"class.std::__1::__compressed_pair.673" }
%"struct.std::__1::pair.672" = type opaque
%"class.std::__1::__compressed_pair.673" = type { %"struct.std::__1::__compressed_pair_elem.674" }
%"struct.std::__1::__compressed_pair_elem.674" = type { %"struct.std::__1::pair.672"* }
%"class.v8::internal::ConcurrentAllocator" = type { %"class.v8::internal::LocalHeap"*, %"class.v8::internal::PagedSpace"*, %"class.v8::internal::LocalAllocationBuffer" }
%"class.v8::internal::PagedSpace" = type { %"class.v8::internal::SpaceWithLinearArea", i32, i32, i64, %"class.v8::internal::AllocationStats", %"class.v8::base::Mutex", i64, i64 }
%"class.v8::internal::SpaceWithLinearArea" = type { %"class.v8::internal::Space", %"class.v8::internal::LinearAllocationArea", [3 x i64] }
%"class.v8::internal::Space" = type { %"class.v8::internal::BaseSpace", %"class.v8::internal::AllocationCounter", %"class.v8::internal::heap::List", %"struct.std::__1::atomic"*, %"class.std::__1::unique_ptr.61" }
%"class.v8::internal::BaseSpace" = type { i32 (...)**, %"class.v8::internal::Heap"*, i32, %"struct.std::__1::atomic", i64 }
%"class.v8::internal::AllocationCounter" = type <{ %"class.std::__1::vector.31", %"class.std::__1::vector.31", %"class.std::__1::unordered_set", i8, [7 x i8], i64, i64, i8, [7 x i8] }>
%"class.std::__1::vector.31" = type { %"class.std::__1::__vector_base.32" }
%"class.std::__1::__vector_base.32" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"class.std::__1::__compressed_pair.33" }
%"struct.v8::internal::AllocationCounter::AllocationObserverCounter" = type { %"class.v8::internal::AllocationObserver"*, i64, i64 }
%"class.std::__1::__compressed_pair.33" = type { %"struct.std::__1::__compressed_pair_elem.34" }
%"struct.std::__1::__compressed_pair_elem.34" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.38" }
%"class.std::__1::__hash_table.38" = type <{ %"class.std::__1::unique_ptr.39", %"class.std::__1::__compressed_pair.49", %"class.std::__1::__compressed_pair.54", %"class.std::__1::__compressed_pair.56", [4 x i8] }>
%"class.std::__1::unique_ptr.39" = type { %"class.std::__1::__compressed_pair.40" }
%"class.std::__1::__compressed_pair.40" = type { %"struct.std::__1::__compressed_pair_elem.41", %"struct.std::__1::__compressed_pair_elem.43" }
%"struct.std::__1::__compressed_pair_elem.41" = type { %"struct.std::__1::__hash_node_base.42"** }
%"struct.std::__1::__hash_node_base.42" = type { %"struct.std::__1::__hash_node_base.42"* }
%"struct.std::__1::__compressed_pair_elem.43" = type { %"class.std::__1::__bucket_list_deallocator.44" }
%"class.std::__1::__bucket_list_deallocator.44" = type { %"class.std::__1::__compressed_pair.45" }
%"class.std::__1::__compressed_pair.45" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.49" = type { %"struct.std::__1::__compressed_pair_elem.50" }
%"struct.std::__1::__compressed_pair_elem.50" = type { %"struct.std::__1::__hash_node_base.42" }
%"class.std::__1::__compressed_pair.54" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.56" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::heap::List" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::MemoryChunk" = type { %"class.v8::internal::BasicMemoryChunk", [2 x %"class.v8::internal::SlotSet"*], %"struct.std::__1::atomic", %"struct.std::__1::atomic.15", %"class.v8::internal::SlotSet"*, [2 x %"class.v8::internal::TypedSlotSet"*], [2 x %"class.std::__1::set.685"*], %"class.v8::base::Mutex"*, %"struct.std::__1::atomic.693", %"class.v8::base::Mutex"*, i64, [2 x %"struct.std::__1::atomic"], %"class.v8::internal::heap::ListNode", %"class.v8::internal::FreeListCategory"**, %"struct.std::__1::atomic.15", %"class.v8::internal::Bitmap"*, %"class.v8::internal::CodeObjectRegistry"*, %"class.v8::internal::PossiblyEmptyBuckets" }
%"class.v8::internal::SlotSet" = type { i8 }
%"class.v8::internal::TypedSlotSet" = type { %"class.v8::internal::TypedSlots", i64 }
%"class.v8::internal::TypedSlots" = type { i32 (...)**, %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"* }
%"struct.v8::internal::TypedSlots::Chunk" = type { %"struct.v8::internal::TypedSlots::Chunk"*, %"class.std::__1::vector.678" }
%"class.std::__1::vector.678" = type { %"class.std::__1::__vector_base.679" }
%"class.std::__1::__vector_base.679" = type { %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"*, %"class.std::__1::__compressed_pair.680" }
%"struct.v8::internal::TypedSlots::TypedSlot" = type { i32 }
%"class.std::__1::__compressed_pair.680" = type { %"struct.std::__1::__compressed_pair_elem.681" }
%"struct.std::__1::__compressed_pair_elem.681" = type { %"struct.v8::internal::TypedSlots::TypedSlot"* }
%"class.std::__1::set.685" = type { %"class.std::__1::__tree.686" }
%"class.std::__1::__tree.686" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.687", %"class.std::__1::__compressed_pair.691" }
%"class.std::__1::__compressed_pair.687" = type { %"struct.std::__1::__compressed_pair_elem.440" }
%"class.std::__1::__compressed_pair.691" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"struct.std::__1::atomic.693" = type { %"struct.std::__1::__atomic_base.694" }
%"struct.std::__1::__atomic_base.694" = type { %"struct.std::__1::__cxx_atomic_impl.695" }
%"struct.std::__1::__cxx_atomic_impl.695" = type { %"struct.std::__1::__cxx_atomic_base_impl.696" }
%"struct.std::__1::__cxx_atomic_base_impl.696" = type { i64 }
%"class.v8::internal::heap::ListNode" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::FreeListCategory" = type { i32, i32, %"class.v8::internal::FreeSpace", %"class.v8::internal::FreeListCategory"*, %"class.v8::internal::FreeListCategory"* }
%"class.v8::internal::FreeSpace" = type { %"class.v8::internal::TorqueGeneratedFreeSpace" }
%"class.v8::internal::TorqueGeneratedFreeSpace" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Bitmap" = type { i8 }
%"class.v8::internal::CodeObjectRegistry" = type <{ %"class.std::__1::vector.697", i8, [7 x i8] }>
%"class.std::__1::vector.697" = type { %"class.std::__1::__vector_base.698" }
%"class.std::__1::__vector_base.698" = type { i64*, i64*, %"class.std::__1::__compressed_pair.699" }
%"class.std::__1::__compressed_pair.699" = type { %"struct.std::__1::__compressed_pair_elem.700" }
%"struct.std::__1::__compressed_pair_elem.700" = type { i64* }
%"class.v8::internal::PossiblyEmptyBuckets" = type { i64 }
%"class.std::__1::unique_ptr.61" = type { %"class.std::__1::__compressed_pair.62" }
%"class.std::__1::__compressed_pair.62" = type { %"struct.std::__1::__compressed_pair_elem.63" }
%"struct.std::__1::__compressed_pair_elem.63" = type { %"class.v8::internal::FreeList"* }
%"class.v8::internal::FreeList" = type { i32 (...)**, i32, i32, i64, %"struct.std::__1::atomic", %"class.v8::internal::FreeListCategory"**, i64 }
%"class.v8::internal::LinearAllocationArea" = type { i64, i64, i64 }
%"class.v8::internal::LocalAllocationBuffer" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::LinearAllocationArea" }
%"class.std::__1::unique_ptr.1079" = type { %"class.std::__1::__compressed_pair.1080" }
%"class.std::__1::__compressed_pair.1080" = type { %"struct.std::__1::__compressed_pair_elem.1081" }
%"struct.std::__1::__compressed_pair_elem.1081" = type { %"class.v8::internal::LocalLogger"* }
%"class.v8::internal::LocalLogger" = type opaque
%"struct.v8::internal::ManagedPtrDestructor" = type { i64, %"struct.v8::internal::ManagedPtrDestructor"*, %"struct.v8::internal::ManagedPtrDestructor"*, i8*, void (i8*)*, i64* }
%"class.v8::internal::wasm::WasmEngine" = type opaque
%"class.std::__1::unique_ptr.1088" = type { %"class.std::__1::__compressed_pair.1089" }
%"class.std::__1::__compressed_pair.1089" = type { %"struct.std::__1::__compressed_pair_elem.1090" }
%"struct.std::__1::__compressed_pair_elem.1090" = type { %"class.v8::internal::TracingCpuProfilerImpl"* }
%"class.v8::internal::TracingCpuProfilerImpl" = type opaque
%"class.v8::internal::EmbeddedFileWriterInterface" = type opaque
%"class.v8::Context::BackupIncumbentScope" = type { %"class.v8::Local.866", i64, %"class.v8::Context::BackupIncumbentScope"* }
%"class.v8::Local.866" = type { %"class.v8::Context"* }
%"class.v8::internal::Isolate::ThreadDataTable" = type { %"class.std::__1::unordered_map.1096" }
%"class.std::__1::unordered_map.1096" = type { %"class.std::__1::__hash_table.1097" }
%"class.std::__1::__hash_table.1097" = type <{ %"class.std::__1::unique_ptr.1098", %"class.std::__1::__compressed_pair.1108", %"class.std::__1::__compressed_pair.1113", %"class.std::__1::__compressed_pair.1116", [4 x i8] }>
%"class.std::__1::unique_ptr.1098" = type { %"class.std::__1::__compressed_pair.1099" }
%"class.std::__1::__compressed_pair.1099" = type { %"struct.std::__1::__compressed_pair_elem.1100", %"struct.std::__1::__compressed_pair_elem.1102" }
%"struct.std::__1::__compressed_pair_elem.1100" = type { %"struct.std::__1::__hash_node_base.1101"** }
%"struct.std::__1::__hash_node_base.1101" = type { %"struct.std::__1::__hash_node_base.1101"* }
%"struct.std::__1::__compressed_pair_elem.1102" = type { %"class.std::__1::__bucket_list_deallocator.1103" }
%"class.std::__1::__bucket_list_deallocator.1103" = type { %"class.std::__1::__compressed_pair.1104" }
%"class.std::__1::__compressed_pair.1104" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1108" = type { %"struct.std::__1::__compressed_pair_elem.1109" }
%"struct.std::__1::__compressed_pair_elem.1109" = type { %"struct.std::__1::__hash_node_base.1101" }
%"class.std::__1::__compressed_pair.1113" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1116" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::atomic.1122" = type { %"struct.std::__1::__atomic_base.1123" }
%"struct.std::__1::__atomic_base.1123" = type { %"struct.std::__1::__cxx_atomic_impl.1124" }
%"struct.std::__1::__cxx_atomic_impl.1124" = type { %"struct.std::__1::__cxx_atomic_base_impl.1125" }
%"struct.std::__1::__cxx_atomic_base_impl.1125" = type { %"class.std::__1::vector.1126"* }
%"class.std::__1::vector.1126" = type { %"class.std::__1::__vector_base.1127" }
%"class.std::__1::__vector_base.1127" = type { %"struct.v8::MemoryRange"*, %"struct.v8::MemoryRange"*, %"class.std::__1::__compressed_pair.1128" }
%"struct.v8::MemoryRange" = type { i8*, i64 }
%"class.std::__1::__compressed_pair.1128" = type { %"struct.std::__1::__compressed_pair_elem.1129" }
%"struct.std::__1::__compressed_pair_elem.1129" = type { %"struct.v8::MemoryRange"* }
%"struct.std::__1::atomic.20" = type { %"struct.std::__1::__atomic_base.21" }
%"struct.std::__1::__atomic_base.21" = type { %"struct.std::__1::__cxx_atomic_impl.22" }
%"struct.std::__1::__cxx_atomic_impl.22" = type { %"struct.std::__1::__cxx_atomic_base_impl.23" }
%"struct.std::__1::__cxx_atomic_base_impl.23" = type { i32 }
%"class.std::__1::vector.24" = type { %"class.std::__1::__vector_base.25" }
%"class.std::__1::__vector_base.25" = type { %"struct.std::__1::pair"*, %"struct.std::__1::pair"*, %"class.std::__1::__compressed_pair.26" }
%"struct.std::__1::pair" = type opaque
%"class.std::__1::__compressed_pair.26" = type { %"struct.std::__1::__compressed_pair_elem.27" }
%"struct.std::__1::__compressed_pair_elem.27" = type { %"struct.std::__1::pair"* }
%"class.v8::internal::NewSpace" = type { %"class.v8::internal::SpaceWithLinearArea", %"class.v8::base::Mutex", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace", %"class.v8::internal::VirtualMemory", %"class.std::__1::vector.65" }
%"class.v8::internal::SemiSpace" = type { %"class.v8::internal::Space", i64, i64, i64, i64, i64, i32, %"class.v8::internal::Page"* }
%"class.v8::internal::Page" = type { %"class.v8::internal::MemoryChunk" }
%"class.std::__1::vector.65" = type { %"class.std::__1::__vector_base.66" }
%"class.std::__1::__vector_base.66" = type { %"struct.std::__1::pair.67"*, %"struct.std::__1::pair.67"*, %"class.std::__1::__compressed_pair.68" }
%"struct.std::__1::pair.67" = type { i32, i64 }
%"class.std::__1::__compressed_pair.68" = type { %"struct.std::__1::__compressed_pair_elem.69" }
%"struct.std::__1::__compressed_pair_elem.69" = type { %"struct.std::__1::pair.67"* }
%"class.v8::internal::CodeSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::OldLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace" }
%"class.v8::internal::LargeObjectSpace" = type { %"class.v8::internal::Space", %"struct.std::__1::atomic", i32, %"struct.std::__1::atomic", %"class.v8::base::Mutex", %"struct.std::__1::atomic" }
%"class.v8::internal::CodeLargeObjectSpace" = type { %"class.v8::internal::OldLargeObjectSpace", %"class.std::__1::unordered_map.73" }
%"class.std::__1::unordered_map.73" = type { %"class.std::__1::__hash_table.74" }
%"class.std::__1::__hash_table.74" = type <{ %"class.std::__1::unique_ptr.75", %"class.std::__1::__compressed_pair.85", %"class.std::__1::__compressed_pair.90", %"class.std::__1::__compressed_pair.95", [4 x i8] }>
%"class.std::__1::unique_ptr.75" = type { %"class.std::__1::__compressed_pair.76" }
%"class.std::__1::__compressed_pair.76" = type { %"struct.std::__1::__compressed_pair_elem.77", %"struct.std::__1::__compressed_pair_elem.79" }
%"struct.std::__1::__compressed_pair_elem.77" = type { %"struct.std::__1::__hash_node_base.78"** }
%"struct.std::__1::__hash_node_base.78" = type { %"struct.std::__1::__hash_node_base.78"* }
%"struct.std::__1::__compressed_pair_elem.79" = type { %"class.std::__1::__bucket_list_deallocator.80" }
%"class.std::__1::__bucket_list_deallocator.80" = type { %"class.std::__1::__compressed_pair.81" }
%"class.std::__1::__compressed_pair.81" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.85" = type { %"struct.std::__1::__compressed_pair_elem.86" }
%"struct.std::__1::__compressed_pair_elem.86" = type { %"struct.std::__1::__hash_node_base.78" }
%"class.std::__1::__compressed_pair.90" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.95" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::NewLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace", i64 }
%"class.v8::internal::ReadOnlySpace" = type { %"class.v8::internal::BaseSpace", i8, %"class.v8::internal::AllocationStats", %"class.std::__1::vector", i64, i64, i8, i64, i64 }
%"class.v8::internal::OldSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::MapSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.std::__1::unique_ptr.101" = type { %"class.std::__1::__compressed_pair.102" }
%"class.std::__1::__compressed_pair.102" = type { %"struct.std::__1::__compressed_pair_elem.103" }
%"struct.std::__1::__compressed_pair_elem.103" = type { %"class.v8::internal::ConcurrentAllocator"* }
%"class.v8::internal::ArrayBufferExtension" = type { %"struct.std::__1::atomic.107", %"struct.std::__1::atomic.111", %"class.std::__1::shared_ptr", %"class.v8::internal::ArrayBufferExtension"*, %"struct.std::__1::atomic" }
%"struct.std::__1::atomic.111" = type { %"struct.std::__1::__atomic_base.112" }
%"struct.std::__1::__atomic_base.112" = type { %"struct.std::__1::__cxx_atomic_impl.113" }
%"struct.std::__1::__cxx_atomic_impl.113" = type { %"struct.std::__1::__cxx_atomic_base_impl.114" }
%"struct.std::__1::__cxx_atomic_base_impl.114" = type { i8 }
%"class.std::__1::shared_ptr" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"struct.std::__1::atomic.116" = type { %"struct.std::__1::__atomic_base.117" }
%"struct.std::__1::__atomic_base.117" = type { %"struct.std::__1::__cxx_atomic_impl.118" }
%"struct.std::__1::__cxx_atomic_impl.118" = type { %"struct.std::__1::__cxx_atomic_base_impl.119" }
%"struct.std::__1::__cxx_atomic_base_impl.119" = type { i32 }
%"class.v8::internal::AllocationObserver" = type { i32 (...)**, i64 }
%"class.v8::internal::StressScavengeObserver" = type opaque
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.14" }
%"struct.std::__1::__atomic_base.14" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i64 }
%"class.v8::internal::Object" = type { %"class.v8::internal::TaggedImpl" }
%"class.v8::internal::TaggedImpl" = type { i64 }
%"class.std::__1::vector.120" = type { %"class.std::__1::__vector_base.121" }
%"class.std::__1::__vector_base.121" = type { %"struct.v8::internal::Heap::GCCallbackTuple"*, %"struct.v8::internal::Heap::GCCallbackTuple"*, %"class.std::__1::__compressed_pair.122" }
%"struct.v8::internal::Heap::GCCallbackTuple" = type { void (%"class.v8::Isolate"*, i32, i32, i8*)*, i32, i8* }
%"class.std::__1::__compressed_pair.122" = type { %"struct.std::__1::__compressed_pair_elem.123" }
%"struct.std::__1::__compressed_pair_elem.123" = type { %"struct.v8::internal::Heap::GCCallbackTuple"* }
%"class.std::__1::unique_ptr.127" = type { %"class.std::__1::__compressed_pair.128" }
%"class.std::__1::__compressed_pair.128" = type { %"struct.std::__1::__compressed_pair_elem.129" }
%"struct.std::__1::__compressed_pair_elem.129" = type { %"class.v8::internal::GCTracer"* }
%"class.v8::internal::GCTracer" = type opaque
%"class.std::__1::unique_ptr.133" = type { %"class.std::__1::__compressed_pair.134" }
%"class.std::__1::__compressed_pair.134" = type { %"struct.std::__1::__compressed_pair_elem.135" }
%"struct.std::__1::__compressed_pair_elem.135" = type { %"class.v8::internal::MarkCompactCollector"* }
%"class.v8::internal::MarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::base::Mutex", %"class.v8::base::Semaphore", i8, i8, i8, i8, i8, i8, [2 x i8], %"class.v8::internal::MarkingWorklists", %"class.v8::internal::WeakObjects", %"struct.v8::internal::EphemeronMarking", %"class.std::__1::unique_ptr.175", %"class.std::__1::unique_ptr.181", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", %"class.std::__1::vector.235", %"class.std::__1::vector.235", %"class.std::__1::vector.235", %"class.std::__1::vector.242", %"class.v8::internal::Sweeper"*, %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", [2 x i8], i32, i32, [4 x i8] }>
%"class.v8::internal::MarkCompactCollectorBase" = type { i32 (...)**, %"class.v8::internal::Heap"* }
%"class.v8::base::Semaphore" = type { %union.sem_t }
%union.sem_t = type { i64, [24 x i8] }
%"class.v8::internal::MarkingWorklists" = type { %"class.heap::base::Worklist", %"class.heap::base::Worklist", %"class.heap::base::Worklist.136", %"class.std::__1::vector.137", %"class.std::__1::vector.144", %"class.heap::base::Worklist" }
%"class.heap::base::Worklist.136" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment"*, %"struct.std::__1::atomic" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment" = type opaque
%"class.std::__1::vector.137" = type { %"class.std::__1::__vector_base.138" }
%"class.std::__1::__vector_base.138" = type { %"struct.v8::internal::ContextWorklistPair"*, %"struct.v8::internal::ContextWorklistPair"*, %"class.std::__1::__compressed_pair.139" }
%"struct.v8::internal::ContextWorklistPair" = type { i64, %"class.heap::base::Worklist"* }
%"class.std::__1::__compressed_pair.139" = type { %"struct.std::__1::__compressed_pair_elem.140" }
%"struct.std::__1::__compressed_pair_elem.140" = type { %"struct.v8::internal::ContextWorklistPair"* }
%"class.std::__1::vector.144" = type { %"class.std::__1::__vector_base.145" }
%"class.std::__1::__vector_base.145" = type { %"class.std::__1::unique_ptr.146"*, %"class.std::__1::unique_ptr.146"*, %"class.std::__1::__compressed_pair.147" }
%"class.std::__1::unique_ptr.146" = type opaque
%"class.std::__1::__compressed_pair.147" = type { %"struct.std::__1::__compressed_pair_elem.148" }
%"struct.std::__1::__compressed_pair_elem.148" = type { %"class.std::__1::unique_ptr.146"* }
%"class.heap::base::Worklist" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment" = type opaque
%"class.v8::internal::WeakObjects" = type { %"class.v8::internal::Worklist", %"class.v8::internal::Worklist.152", %"class.v8::internal::Worklist.154", %"class.v8::internal::Worklist.154", %"class.v8::internal::Worklist.154", %"class.v8::internal::Worklist.156", %"class.v8::internal::Worklist.158", %"class.v8::internal::Worklist.160", %"class.v8::internal::Worklist.162", %"class.v8::internal::Worklist.164", %"class.v8::internal::Worklist.166" }
%"class.v8::internal::Worklist" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.152" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.154" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.156" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.158" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.160" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.162" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.164" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.166" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"struct.std::__1::atomic" }
%"struct.v8::internal::EphemeronMarking" = type { %"class.std::__1::vector.168", i8, i64 }
%"class.std::__1::vector.168" = type { %"class.std::__1::__vector_base.169" }
%"class.std::__1::__vector_base.169" = type { %"class.v8::internal::HeapObject"*, %"class.v8::internal::HeapObject"*, %"class.std::__1::__compressed_pair.170" }
%"class.std::__1::__compressed_pair.170" = type { %"struct.std::__1::__compressed_pair_elem.171" }
%"struct.std::__1::__compressed_pair_elem.171" = type { %"class.v8::internal::HeapObject"* }
%"class.std::__1::unique_ptr.175" = type { %"class.std::__1::__compressed_pair.176" }
%"class.std::__1::__compressed_pair.176" = type { %"struct.std::__1::__compressed_pair_elem.177" }
%"struct.std::__1::__compressed_pair_elem.177" = type { %"class.v8::internal::MainMarkingVisitor"* }
%"class.v8::internal::MainMarkingVisitor" = type opaque
%"class.std::__1::unique_ptr.181" = type { %"class.std::__1::__compressed_pair.182" }
%"class.std::__1::__compressed_pair.182" = type { %"struct.std::__1::__compressed_pair_elem.183" }
%"struct.std::__1::__compressed_pair_elem.183" = type { %"class.v8::internal::MarkingWorklists::Local"* }
%"class.v8::internal::MarkingWorklists::Local" = type { %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", i64, %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local"*, i8, [7 x i8], %"class.std::__1::unordered_map.184" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local" = type { %"class.heap::base::Worklist.136"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.heap::base::internal::SegmentBase" = type { i16, i16 }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local" = type { %"class.heap::base::Worklist"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.std::__1::unordered_map.184" = type { %"class.std::__1::__hash_table.185" }
%"class.std::__1::__hash_table.185" = type <{ %"class.std::__1::unique_ptr.186", %"class.std::__1::__compressed_pair.196", %"class.std::__1::__compressed_pair.201", %"class.std::__1::__compressed_pair.204", [4 x i8] }>
%"class.std::__1::unique_ptr.186" = type { %"class.std::__1::__compressed_pair.187" }
%"class.std::__1::__compressed_pair.187" = type { %"struct.std::__1::__compressed_pair_elem.188", %"struct.std::__1::__compressed_pair_elem.190" }
%"struct.std::__1::__compressed_pair_elem.188" = type { %"struct.std::__1::__hash_node_base.189"** }
%"struct.std::__1::__hash_node_base.189" = type { %"struct.std::__1::__hash_node_base.189"* }
%"struct.std::__1::__compressed_pair_elem.190" = type { %"class.std::__1::__bucket_list_deallocator.191" }
%"class.std::__1::__bucket_list_deallocator.191" = type { %"class.std::__1::__compressed_pair.192" }
%"class.std::__1::__compressed_pair.192" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.196" = type { %"struct.std::__1::__compressed_pair_elem.197" }
%"struct.std::__1::__compressed_pair_elem.197" = type { %"struct.std::__1::__hash_node_base.189" }
%"class.std::__1::__compressed_pair.201" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.204" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::NativeContextInferrer" = type { i8 }
%"class.v8::internal::NativeContextStats" = type { %"class.std::__1::unordered_map.211" }
%"class.std::__1::unordered_map.211" = type { %"class.std::__1::__hash_table.212" }
%"class.std::__1::__hash_table.212" = type <{ %"class.std::__1::unique_ptr.213", %"class.std::__1::__compressed_pair.223", %"class.std::__1::__compressed_pair.228", %"class.std::__1::__compressed_pair.231", [4 x i8] }>
%"class.std::__1::unique_ptr.213" = type { %"class.std::__1::__compressed_pair.214" }
%"class.std::__1::__compressed_pair.214" = type { %"struct.std::__1::__compressed_pair_elem.215", %"struct.std::__1::__compressed_pair_elem.217" }
%"struct.std::__1::__compressed_pair_elem.215" = type { %"struct.std::__1::__hash_node_base.216"** }
%"struct.std::__1::__hash_node_base.216" = type { %"struct.std::__1::__hash_node_base.216"* }
%"struct.std::__1::__compressed_pair_elem.217" = type { %"class.std::__1::__bucket_list_deallocator.218" }
%"class.std::__1::__bucket_list_deallocator.218" = type { %"class.std::__1::__compressed_pair.219" }
%"class.std::__1::__compressed_pair.219" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.223" = type { %"struct.std::__1::__compressed_pair_elem.224" }
%"struct.std::__1::__compressed_pair_elem.224" = type { %"struct.std::__1::__hash_node_base.216" }
%"class.std::__1::__compressed_pair.228" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.231" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::vector.235" = type { %"class.std::__1::__vector_base.236" }
%"class.std::__1::__vector_base.236" = type { %"class.v8::internal::Page"**, %"class.v8::internal::Page"**, %"class.std::__1::__compressed_pair.237" }
%"class.std::__1::__compressed_pair.237" = type { %"struct.std::__1::__compressed_pair_elem.238" }
%"struct.std::__1::__compressed_pair_elem.238" = type { %"class.v8::internal::Page"** }
%"class.std::__1::vector.242" = type { %"class.std::__1::__vector_base.243" }
%"class.std::__1::__vector_base.243" = type { %"struct.std::__1::pair.244"*, %"struct.std::__1::pair.244"*, %"class.std::__1::__compressed_pair.245" }
%"struct.std::__1::pair.244" = type opaque
%"class.std::__1::__compressed_pair.245" = type { %"struct.std::__1::__compressed_pair_elem.246" }
%"struct.std::__1::__compressed_pair_elem.246" = type { %"struct.std::__1::pair.244"* }
%"class.v8::internal::Sweeper" = type <{ %"class.v8::internal::Heap"*, %"class.v8::internal::MajorNonAtomicMarkingState"*, %"class.std::__1::unique_ptr.250", %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.235"], [3 x %"class.std::__1::vector.235"], i8, %"struct.std::__1::atomic.107", [6 x i8], %"class.std::__1::vector.235", i64, %"class.v8::base::Semaphore", i8, i8, i8, [5 x i8] }>
%"class.std::__1::unique_ptr.250" = type { %"class.std::__1::__compressed_pair.251" }
%"class.std::__1::__compressed_pair.251" = type { %"struct.std::__1::__compressed_pair_elem.252" }
%"struct.std::__1::__compressed_pair_elem.252" = type { %"class.v8::JobHandle"* }
%"class.v8::JobHandle" = type { i32 (...)** }
%"class.v8::internal::MajorMarkingState" = type { i8 }
%"class.v8::internal::MajorNonAtomicMarkingState" = type { i8 }
%"class.v8::internal::MinorMarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::internal::Worklist.260"*, %"class.v8::internal::YoungGenerationMarkingVisitor"*, %"class.v8::base::Semaphore", %"class.std::__1::vector.235", %"class.std::__1::vector.235", %"class.v8::internal::MinorMarkingState", %"class.v8::internal::MinorNonAtomicMarkingState", [6 x i8] }>
%"class.v8::internal::Worklist.260" = type opaque
%"class.v8::internal::YoungGenerationMarkingVisitor" = type opaque
%"class.v8::internal::MinorMarkingState" = type { i8 }
%"class.v8::internal::MinorNonAtomicMarkingState" = type { i8 }
%"class.std::__1::unique_ptr.263" = type { %"class.std::__1::__compressed_pair.264" }
%"class.std::__1::__compressed_pair.264" = type { %"struct.std::__1::__compressed_pair_elem.265" }
%"struct.std::__1::__compressed_pair_elem.265" = type { %"class.v8::internal::ScavengerCollector"* }
%"class.v8::internal::ScavengerCollector" = type opaque
%"class.std::__1::unique_ptr.269" = type { %"class.std::__1::__compressed_pair.270" }
%"class.std::__1::__compressed_pair.270" = type { %"struct.std::__1::__compressed_pair_elem.271" }
%"struct.std::__1::__compressed_pair_elem.271" = type { %"class.v8::internal::ArrayBufferSweeper"* }
%"class.v8::internal::ArrayBufferSweeper" = type opaque
%"class.std::__1::unique_ptr.275" = type { %"class.std::__1::__compressed_pair.276" }
%"class.std::__1::__compressed_pair.276" = type { %"struct.std::__1::__compressed_pair_elem.277" }
%"struct.std::__1::__compressed_pair_elem.277" = type { %"class.v8::internal::MemoryAllocator"* }
%"class.v8::internal::MemoryAllocator" = type { %"class.v8::internal::Isolate"*, %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"*, i64, %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.v8::internal::VirtualMemory", %"class.v8::internal::MemoryAllocator::Unmapper", %"class.std::__1::unordered_set.285", %"class.v8::base::Mutex" }
%"class.v8::internal::MemoryAllocator::Unmapper" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MemoryAllocator"*, %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.278"], %"class.std::__1::unique_ptr.250" }
%"class.std::__1::vector.278" = type { %"class.std::__1::__vector_base.279" }
%"class.std::__1::__vector_base.279" = type { %"class.v8::internal::MemoryChunk"**, %"class.v8::internal::MemoryChunk"**, %"class.std::__1::__compressed_pair.280" }
%"class.std::__1::__compressed_pair.280" = type { %"struct.std::__1::__compressed_pair_elem.281" }
%"struct.std::__1::__compressed_pair_elem.281" = type { %"class.v8::internal::MemoryChunk"** }
%"class.std::__1::unique_ptr.314" = type { %"class.std::__1::__compressed_pair.315" }
%"class.std::__1::__compressed_pair.315" = type { %"struct.std::__1::__compressed_pair_elem.316" }
%"struct.std::__1::__compressed_pair_elem.316" = type { %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::IncrementalMarking" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MarkCompactCollector"*, %"class.v8::internal::WeakObjects"*, double, double, i64, i64, i64, i64, double, i64, %"struct.std::__1::atomic.317", i8, i8, i8, i8, [3 x i8], %"class.v8::internal::IncrementalMarkingJob", %"struct.std::__1::atomic.321", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorAtomicMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", %"class.v8::base::Mutex", %"class.std::__1::unordered_map.326" }
%"struct.std::__1::atomic.317" = type { %"struct.std::__1::__atomic_base.318" }
%"struct.std::__1::__atomic_base.318" = type { %"struct.std::__1::__cxx_atomic_impl.319" }
%"struct.std::__1::__cxx_atomic_impl.319" = type { %"struct.std::__1::__cxx_atomic_base_impl.320" }
%"struct.std::__1::__cxx_atomic_base_impl.320" = type { i8 }
%"class.v8::internal::IncrementalMarkingJob" = type <{ %"class.v8::base::Mutex", double, i8, i8, [6 x i8] }>
%"struct.std::__1::atomic.321" = type { %"struct.std::__1::__atomic_base.322" }
%"struct.std::__1::__atomic_base.322" = type { %"struct.std::__1::__cxx_atomic_impl.323" }
%"struct.std::__1::__cxx_atomic_impl.323" = type { %"struct.std::__1::__cxx_atomic_base_impl.324" }
%"struct.std::__1::__cxx_atomic_base_impl.324" = type { i32 }
%"class.v8::internal::IncrementalMarking::Observer" = type { %"class.v8::internal::AllocationObserver", %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::MajorAtomicMarkingState" = type { i8 }
%"class.std::__1::unordered_map.326" = type { %"class.std::__1::__hash_table.327" }
%"class.std::__1::__hash_table.327" = type <{ %"class.std::__1::unique_ptr.328", %"class.std::__1::__compressed_pair.338", %"class.std::__1::__compressed_pair.343", %"class.std::__1::__compressed_pair.346", [4 x i8] }>
%"class.std::__1::unique_ptr.328" = type { %"class.std::__1::__compressed_pair.329" }
%"class.std::__1::__compressed_pair.329" = type { %"struct.std::__1::__compressed_pair_elem.330", %"struct.std::__1::__compressed_pair_elem.332" }
%"struct.std::__1::__compressed_pair_elem.330" = type { %"struct.std::__1::__hash_node_base.331"** }
%"struct.std::__1::__hash_node_base.331" = type { %"struct.std::__1::__hash_node_base.331"* }
%"struct.std::__1::__compressed_pair_elem.332" = type { %"class.std::__1::__bucket_list_deallocator.333" }
%"class.std::__1::__bucket_list_deallocator.333" = type { %"class.std::__1::__compressed_pair.334" }
%"class.std::__1::__compressed_pair.334" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.338" = type { %"struct.std::__1::__compressed_pair_elem.339" }
%"struct.std::__1::__compressed_pair_elem.339" = type { %"struct.std::__1::__hash_node_base.331" }
%"class.std::__1::__compressed_pair.343" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.346" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.353" = type { %"class.std::__1::__compressed_pair.354" }
%"class.std::__1::__compressed_pair.354" = type { %"struct.std::__1::__compressed_pair_elem.355" }
%"struct.std::__1::__compressed_pair_elem.355" = type { %"class.v8::internal::ConcurrentMarking"* }
%"class.v8::internal::ConcurrentMarking" = type <{ %"class.std::__1::unique_ptr.250", %"class.v8::internal::Heap"*, %"class.v8::internal::MarkingWorklists"*, %"class.v8::internal::WeakObjects"*, [8 x %"struct.v8::internal::ConcurrentMarking::TaskState"], %"struct.std::__1::atomic", %"struct.std::__1::atomic.107", [7 x i8] }>
%"struct.v8::internal::ConcurrentMarking::TaskState" = type { i64, %"class.std::__1::unordered_map.356", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", [64 x i8] }
%"class.std::__1::unordered_map.356" = type { %"class.std::__1::__hash_table.357" }
%"class.std::__1::__hash_table.357" = type <{ %"class.std::__1::unique_ptr.358", %"class.std::__1::__compressed_pair.368", %"class.std::__1::__compressed_pair.373", %"class.std::__1::__compressed_pair.376", [4 x i8] }>
%"class.std::__1::unique_ptr.358" = type { %"class.std::__1::__compressed_pair.359" }
%"class.std::__1::__compressed_pair.359" = type { %"struct.std::__1::__compressed_pair_elem.360", %"struct.std::__1::__compressed_pair_elem.362" }
%"struct.std::__1::__compressed_pair_elem.360" = type { %"struct.std::__1::__hash_node_base.361"** }
%"struct.std::__1::__hash_node_base.361" = type { %"struct.std::__1::__hash_node_base.361"* }
%"struct.std::__1::__compressed_pair_elem.362" = type { %"class.std::__1::__bucket_list_deallocator.363" }
%"class.std::__1::__bucket_list_deallocator.363" = type { %"class.std::__1::__compressed_pair.364" }
%"class.std::__1::__compressed_pair.364" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.368" = type { %"struct.std::__1::__compressed_pair_elem.369" }
%"struct.std::__1::__compressed_pair_elem.369" = type { %"struct.std::__1::__hash_node_base.361" }
%"class.std::__1::__compressed_pair.373" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.376" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.383" = type { %"class.std::__1::__compressed_pair.384" }
%"class.std::__1::__compressed_pair.384" = type { %"struct.std::__1::__compressed_pair_elem.385" }
%"struct.std::__1::__compressed_pair_elem.385" = type { %"class.v8::internal::GCIdleTimeHandler"* }
%"class.v8::internal::GCIdleTimeHandler" = type opaque
%"class.std::__1::unique_ptr.389" = type { %"class.std::__1::__compressed_pair.390" }
%"class.std::__1::__compressed_pair.390" = type { %"struct.std::__1::__compressed_pair_elem.391" }
%"struct.std::__1::__compressed_pair_elem.391" = type { %"class.v8::internal::MemoryMeasurement"* }
%"class.v8::internal::MemoryMeasurement" = type { %"class.std::__1::list", %"class.std::__1::list", %"class.std::__1::list", %"class.v8::internal::Isolate"*, i8, i8, i8, %"class.v8::base::RandomNumberGenerator" }
%"class.std::__1::list" = type { %"class.std::__1::__list_imp" }
%"class.std::__1::__list_imp" = type { %"struct.std::__1::__list_node_base", %"class.std::__1::__compressed_pair.392" }
%"struct.std::__1::__list_node_base" = type { %"struct.std::__1::__list_node_base"*, %"struct.std::__1::__list_node_base"* }
%"class.std::__1::__compressed_pair.392" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::unique_ptr.399" = type { %"class.std::__1::__compressed_pair.400" }
%"class.std::__1::__compressed_pair.400" = type { %"struct.std::__1::__compressed_pair_elem.401" }
%"struct.std::__1::__compressed_pair_elem.401" = type { %"class.v8::internal::MemoryReducer"* }
%"class.v8::internal::MemoryReducer" = type opaque
%"class.std::__1::unique_ptr.405" = type { %"class.std::__1::__compressed_pair.406" }
%"class.std::__1::__compressed_pair.406" = type { %"struct.std::__1::__compressed_pair_elem.407" }
%"struct.std::__1::__compressed_pair_elem.407" = type { %"class.v8::internal::ObjectStats"* }
%"class.v8::internal::ObjectStats" = type opaque
%"class.std::__1::unique_ptr.411" = type { %"class.std::__1::__compressed_pair.412" }
%"class.std::__1::__compressed_pair.412" = type { %"struct.std::__1::__compressed_pair_elem.413" }
%"struct.std::__1::__compressed_pair_elem.413" = type { %"class.v8::internal::ScavengeJob"* }
%"class.v8::internal::ScavengeJob" = type opaque
%"class.std::__1::unique_ptr.417" = type { %"class.std::__1::__compressed_pair.418" }
%"class.std::__1::__compressed_pair.418" = type { %"struct.std::__1::__compressed_pair_elem.419" }
%"struct.std::__1::__compressed_pair_elem.419" = type { %"class.v8::internal::AllocationObserver"* }
%"class.std::__1::unique_ptr.423" = type { %"class.std::__1::__compressed_pair.424" }
%"class.std::__1::__compressed_pair.424" = type { %"struct.std::__1::__compressed_pair_elem.425" }
%"struct.std::__1::__compressed_pair_elem.425" = type { %"class.v8::internal::LocalEmbedderHeapTracer"* }
%"class.v8::internal::LocalEmbedderHeapTracer" = type opaque
%"class.std::__1::unique_ptr.429" = type { %"class.std::__1::__compressed_pair.430" }
%"class.std::__1::__compressed_pair.430" = type { %"struct.std::__1::__compressed_pair_elem.431" }
%"struct.std::__1::__compressed_pair_elem.431" = type { %"class.v8::internal::MarkingBarrier"* }
%"class.v8::internal::MarkingBarrier" = type opaque
%"class.std::__1::shared_ptr.435" = type { %"class.v8::internal::CodeRange"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::CodeRange" = type { %"class.v8::internal::VirtualMemoryCage", %"struct.std::__1::atomic.453", %"class.v8::base::Mutex" }
%"class.v8::internal::VirtualMemoryCage" = type { i32 (...)**, i64, %"class.std::__1::unique_ptr.436", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.453" = type { %"struct.std::__1::__atomic_base.454" }
%"struct.std::__1::__atomic_base.454" = type { %"struct.std::__1::__cxx_atomic_impl.455" }
%"struct.std::__1::__cxx_atomic_impl.455" = type { %"struct.std::__1::__cxx_atomic_base_impl.456" }
%"struct.std::__1::__cxx_atomic_base_impl.456" = type { i8* }
%"class.v8::CppHeap" = type opaque
%"class.v8::EmbedderRootsHandler" = type { i32 (...)** }
%"class.v8::internal::StrongRootsEntry" = type { %"class.v8::internal::FullObjectSlot", %"class.v8::internal::FullObjectSlot", %"class.v8::internal::StrongRootsEntry"*, %"class.v8::internal::StrongRootsEntry"* }
%"class.v8::internal::FullObjectSlot" = type { %"class.v8::internal::SlotBase" }
%"class.v8::internal::SlotBase" = type { i64 }
%"class.std::__1::unordered_map.457" = type { %"class.std::__1::__hash_table.458" }
%"class.std::__1::__hash_table.458" = type <{ %"class.std::__1::unique_ptr.459", %"class.std::__1::__compressed_pair.469", %"class.std::__1::__compressed_pair.474", %"class.std::__1::__compressed_pair.477", [4 x i8] }>
%"class.std::__1::unique_ptr.459" = type { %"class.std::__1::__compressed_pair.460" }
%"class.std::__1::__compressed_pair.460" = type { %"struct.std::__1::__compressed_pair_elem.461", %"struct.std::__1::__compressed_pair_elem.463" }
%"struct.std::__1::__compressed_pair_elem.461" = type { %"struct.std::__1::__hash_node_base.462"** }
%"struct.std::__1::__hash_node_base.462" = type { %"struct.std::__1::__hash_node_base.462"* }
%"struct.std::__1::__compressed_pair_elem.463" = type { %"class.std::__1::__bucket_list_deallocator.464" }
%"class.std::__1::__bucket_list_deallocator.464" = type { %"class.std::__1::__compressed_pair.465" }
%"class.std::__1::__compressed_pair.465" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.469" = type { %"struct.std::__1::__compressed_pair_elem.470" }
%"struct.std::__1::__compressed_pair_elem.470" = type { %"struct.std::__1::__hash_node_base.462" }
%"class.std::__1::__compressed_pair.474" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.477" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.483" = type { %"class.std::__1::__compressed_pair.484" }
%"class.std::__1::__compressed_pair.484" = type { %"struct.std::__1::__compressed_pair_elem.485" }
%"struct.std::__1::__compressed_pair_elem.485" = type { %"class.v8::internal::GlobalHandleVector"* }
%"class.v8::internal::GlobalHandleVector" = type opaque
%"class.std::__1::unique_ptr.489" = type { %"class.std::__1::__compressed_pair.490" }
%"class.std::__1::__compressed_pair.490" = type { %"struct.std::__1::__compressed_pair_elem.491" }
%"struct.std::__1::__compressed_pair_elem.491" = type { %"class.v8::internal::GlobalSafepoint"* }
%"class.v8::internal::GlobalSafepoint" = type <{ %"class.v8::internal::GlobalSafepoint::Barrier", %"class.v8::internal::Heap"*, %"class.v8::base::Mutex", %"class.v8::internal::LocalHeap"*, i32, [4 x i8] }>
%"class.v8::internal::GlobalSafepoint::Barrier" = type { %"class.v8::base::Mutex", %"class.v8::base::ConditionVariable", %"class.v8::base::ConditionVariable", i8, i32 }
%"class.v8::internal::Heap::ExternalStringTable" = type { %"class.v8::internal::Heap"*, %"class.std::__1::vector.497", %"class.std::__1::vector.497" }
%"class.std::__1::unique_ptr.504" = type { %"class.std::__1::__compressed_pair.505" }
%"class.std::__1::__compressed_pair.505" = type { %"struct.std::__1::__compressed_pair_elem.506" }
%"struct.std::__1::__compressed_pair_elem.506" = type { %"class.v8::internal::CollectionBarrier"* }
%"class.v8::internal::CollectionBarrier" = type opaque
%"class.v8::internal::HeapObject" = type { %"class.v8::internal::Object" }
%"class.v8::base::SharedMutex" = type { %union.pthread_rwlock_t }
%union.pthread_rwlock_t = type { %struct.__pthread_rwlock_arch_t }
%struct.__pthread_rwlock_arch_t = type { i32, i32, i32, i32, i32, i32, i32, i32, i8, [7 x i8], i64, i32 }
%"class.v8::base::Mutex" = type { %union.pthread_mutex_t }
%"class.std::__1::unordered_set.285" = type { %"class.std::__1::__hash_table.286" }
%"class.std::__1::__hash_table.286" = type <{ %"class.std::__1::unique_ptr.287", %"class.std::__1::__compressed_pair.297", %"class.std::__1::__compressed_pair.302", %"class.std::__1::__compressed_pair.306", [4 x i8] }>
%"class.std::__1::unique_ptr.287" = type { %"class.std::__1::__compressed_pair.288" }
%"class.std::__1::__compressed_pair.288" = type { %"struct.std::__1::__compressed_pair_elem.289", %"struct.std::__1::__compressed_pair_elem.291" }
%"struct.std::__1::__compressed_pair_elem.289" = type { %"struct.std::__1::__hash_node_base.290"** }
%"struct.std::__1::__hash_node_base.290" = type { %"struct.std::__1::__hash_node_base.290"* }
%"struct.std::__1::__compressed_pair_elem.291" = type { %"class.std::__1::__bucket_list_deallocator.292" }
%"class.std::__1::__bucket_list_deallocator.292" = type { %"class.std::__1::__compressed_pair.293" }
%"class.std::__1::__compressed_pair.293" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.297" = type { %"struct.std::__1::__compressed_pair_elem.298" }
%"struct.std::__1::__compressed_pair_elem.298" = type { %"struct.std::__1::__hash_node_base.290" }
%"class.std::__1::__compressed_pair.302" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.306" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.536" = type { %"class.std::__1::__hash_table.537" }
%"class.std::__1::__hash_table.537" = type <{ %"class.std::__1::unique_ptr.538", %"class.std::__1::__compressed_pair.548", %"class.std::__1::__compressed_pair.553", %"class.std::__1::__compressed_pair.556", [4 x i8] }>
%"class.std::__1::unique_ptr.538" = type { %"class.std::__1::__compressed_pair.539" }
%"class.std::__1::__compressed_pair.539" = type { %"struct.std::__1::__compressed_pair_elem.540", %"struct.std::__1::__compressed_pair_elem.542" }
%"struct.std::__1::__compressed_pair_elem.540" = type { %"struct.std::__1::__hash_node_base.541"** }
%"struct.std::__1::__hash_node_base.541" = type { %"struct.std::__1::__hash_node_base.541"* }
%"struct.std::__1::__compressed_pair_elem.542" = type { %"class.std::__1::__bucket_list_deallocator.543" }
%"class.std::__1::__bucket_list_deallocator.543" = type { %"class.std::__1::__compressed_pair.544" }
%"class.std::__1::__compressed_pair.544" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.548" = type { %"struct.std::__1::__compressed_pair_elem.549" }
%"struct.std::__1::__compressed_pair_elem.549" = type { %"struct.std::__1::__hash_node_base.541" }
%"class.std::__1::__compressed_pair.553" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.556" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.510" = type { %"class.std::__1::__hash_table.511" }
%"class.std::__1::__hash_table.511" = type <{ %"class.std::__1::unique_ptr.512", %"class.std::__1::__compressed_pair.522", %"class.std::__1::__compressed_pair.527", %"class.std::__1::__compressed_pair.530", [4 x i8] }>
%"class.std::__1::unique_ptr.512" = type { %"class.std::__1::__compressed_pair.513" }
%"class.std::__1::__compressed_pair.513" = type { %"struct.std::__1::__compressed_pair_elem.514", %"struct.std::__1::__compressed_pair_elem.516" }
%"struct.std::__1::__compressed_pair_elem.514" = type { %"struct.std::__1::__hash_node_base.515"** }
%"struct.std::__1::__hash_node_base.515" = type { %"struct.std::__1::__hash_node_base.515"* }
%"struct.std::__1::__compressed_pair_elem.516" = type { %"class.std::__1::__bucket_list_deallocator.517" }
%"class.std::__1::__bucket_list_deallocator.517" = type { %"class.std::__1::__compressed_pair.518" }
%"class.std::__1::__compressed_pair.518" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.522" = type { %"struct.std::__1::__compressed_pair_elem.523" }
%"struct.std::__1::__compressed_pair_elem.523" = type { %"struct.std::__1::__hash_node_base.515" }
%"class.std::__1::__compressed_pair.527" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.530" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.560" = type { %"class.std::__1::__hash_table.561" }
%"class.std::__1::__hash_table.561" = type <{ %"class.std::__1::unique_ptr.562", %"class.std::__1::__compressed_pair.572", %"class.std::__1::__compressed_pair.577", %"class.std::__1::__compressed_pair.582", [4 x i8] }>
%"class.std::__1::unique_ptr.562" = type { %"class.std::__1::__compressed_pair.563" }
%"class.std::__1::__compressed_pair.563" = type { %"struct.std::__1::__compressed_pair_elem.564", %"struct.std::__1::__compressed_pair_elem.566" }
%"struct.std::__1::__compressed_pair_elem.564" = type { %"struct.std::__1::__hash_node_base.565"** }
%"struct.std::__1::__hash_node_base.565" = type { %"struct.std::__1::__hash_node_base.565"* }
%"struct.std::__1::__compressed_pair_elem.566" = type { %"class.std::__1::__bucket_list_deallocator.567" }
%"class.std::__1::__bucket_list_deallocator.567" = type { %"class.std::__1::__compressed_pair.568" }
%"class.std::__1::__compressed_pair.568" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.572" = type { %"struct.std::__1::__compressed_pair_elem.573" }
%"struct.std::__1::__compressed_pair_elem.573" = type { %"struct.std::__1::__hash_node_base.565" }
%"class.std::__1::__compressed_pair.577" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.582" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::vector.588" = type { %"class.std::__1::__vector_base.589" }
%"class.std::__1::__vector_base.589" = type { %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.std::__1::__compressed_pair.590" }
%"class.std::__1::__compressed_pair.590" = type { %"struct.std::__1::__compressed_pair_elem.591" }
%"struct.std::__1::__compressed_pair_elem.591" = type { %"class.v8::internal::HeapObjectAllocationTracker"** }
%"class.std::__1::unique_ptr.595" = type { %"class.std::__1::__compressed_pair.596" }
%"class.std::__1::__compressed_pair.596" = type { %"struct.std::__1::__compressed_pair_elem.597" }
%"struct.std::__1::__compressed_pair_elem.597" = type { %"class.v8::internal::third_party_heap::Heap"* }
%"class.v8::internal::third_party_heap::Heap" = type { i8 }
%"struct.std::__1::atomic.15" = type { %"struct.std::__1::__atomic_base.16" }
%"struct.std::__1::__atomic_base.16" = type { %"struct.std::__1::__atomic_base.17" }
%"struct.std::__1::__atomic_base.17" = type { %"struct.std::__1::__cxx_atomic_impl.18" }
%"struct.std::__1::__cxx_atomic_impl.18" = type { %"struct.std::__1::__cxx_atomic_base_impl.19" }
%"struct.std::__1::__cxx_atomic_base_impl.19" = type { i64 }
%"struct.std::__1::atomic.601" = type { %"struct.std::__1::__atomic_base.602" }
%"struct.std::__1::__atomic_base.602" = type { %"struct.std::__1::__cxx_atomic_impl.603" }
%"struct.std::__1::__cxx_atomic_impl.603" = type { %"struct.std::__1::__cxx_atomic_base_impl.604" }
%"struct.std::__1::__cxx_atomic_base_impl.604" = type { %"class.v8::internal::BaseSpace"* }
%"class.v8::internal::VirtualMemory" = type { %"class.v8::PageAllocator"*, %"class.v8::base::AddressRegion" }
%"class.std::__1::__compressed_pair.605" = type { %"struct.std::__1::__compressed_pair_elem.606" }
%"struct.std::__1::__compressed_pair_elem.606" = type { %"class.v8::internal::ReadOnlyPage"** }
%"class.v8::internal::AllocationStats" = type { %"struct.std::__1::atomic", i64, %"struct.std::__1::atomic" }
%"class.std::__1::unique_ptr.610" = type { %"class.std::__1::__compressed_pair.611" }
%"class.std::__1::__compressed_pair.611" = type { %"struct.std::__1::__compressed_pair_elem.612" }
%"struct.std::__1::__compressed_pair_elem.612" = type { %"class.v8::internal::SharedReadOnlySpace"* }
%"class.v8::internal::SharedReadOnlySpace" = type { %"class.v8::internal::ReadOnlySpace", %"class.std::__1::vector.613" }
%"class.std::__1::vector.613" = type { %"class.std::__1::__vector_base.614" }
%"class.std::__1::__vector_base.614" = type { %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"*, %"class.std::__1::__compressed_pair.621" }
%"class.std::__1::unique_ptr.615" = type { %"class.std::__1::__compressed_pair.616" }
%"class.std::__1::__compressed_pair.616" = type { %"struct.std::__1::__compressed_pair_elem.617" }
%"struct.std::__1::__compressed_pair_elem.617" = type { %"class.v8::PageAllocator::SharedMemoryMapping"* }
%"class.v8::PageAllocator::SharedMemoryMapping" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.621" = type { %"struct.std::__1::__compressed_pair_elem.622" }
%"struct.std::__1::__compressed_pair_elem.622" = type { %"class.std::__1::unique_ptr.615"* }
%"class.std::__1::unique_ptr.629" = type { %"class.std::__1::__compressed_pair.630" }
%"class.std::__1::__compressed_pair.630" = type { %"struct.std::__1::__compressed_pair_elem.631" }
%"struct.std::__1::__compressed_pair_elem.631" = type { %"class.v8::internal::ReadOnlyHeap"* }
%"class.v8::internal::PointerCompressedReadOnlyArtifacts" = type { %"class.v8::internal::ReadOnlyArtifacts", [587 x i64], %"class.std::__1::vector.1133", %"class.std::__1::vector.1140" }
%"class.std::__1::vector.1133" = type { %"class.std::__1::__vector_base.1134" }
%"class.std::__1::__vector_base.1134" = type { i32*, i32*, %"class.std::__1::__compressed_pair.1135" }
%"class.std::__1::__compressed_pair.1135" = type { %"struct.std::__1::__compressed_pair_elem.1136" }
%"struct.std::__1::__compressed_pair_elem.1136" = type { i32* }
%"class.std::__1::vector.1140" = type { %"class.std::__1::__vector_base.1141" }
%"class.std::__1::__vector_base.1141" = type { %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::__compressed_pair.1148" }
%"class.std::__1::unique_ptr.1142" = type { %"class.std::__1::__compressed_pair.1143" }
%"class.std::__1::__compressed_pair.1143" = type { %"struct.std::__1::__compressed_pair_elem.1144" }
%"struct.std::__1::__compressed_pair_elem.1144" = type { %"class.v8::PageAllocator::SharedMemory"* }
%"class.v8::PageAllocator::SharedMemory" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.1148" = type { %"struct.std::__1::__compressed_pair_elem.1149" }
%"struct.std::__1::__compressed_pair_elem.1149" = type { %"class.std::__1::unique_ptr.1142"* }
%"class.v8::internal::SnapshotData" = type { %"class.v8::internal::SerializedData.base", [3 x i8] }
%"class.v8::internal::SerializedData.base" = type <{ i32 (...)**, i8*, i32, i8 }>
%"class.std::__1::__vector_base_common" = type { i8 }
%"class.v8::internal::ReadOnlyHeapObjectIterator" = type { %"class.v8::internal::ReadOnlySpace"*, %"class.std::__1::__wrap_iter.1154", i64 }
%"class.std::__1::__wrap_iter.1154" = type { %"class.v8::internal::ReadOnlyPage"** }
%"class.v8::internal::SeqOneByteString" = type { %"class.v8::internal::TorqueGeneratedSeqOneByteString" }
%"class.v8::internal::TorqueGeneratedSeqOneByteString" = type { %"class.v8::internal::SeqString" }
%"class.v8::internal::SeqString" = type { %"class.v8::internal::TorqueGeneratedSeqString" }
%"class.v8::internal::TorqueGeneratedSeqString" = type { %"class.v8::internal::String" }
%"class.v8::internal::String" = type { %"class.v8::internal::TorqueGeneratedString" }
%"class.v8::internal::TorqueGeneratedString" = type { %"class.v8::internal::Name" }
%"class.v8::internal::SeqTwoByteString" = type { %"class.v8::internal::TorqueGeneratedSeqTwoByteString" }
%"class.v8::internal::TorqueGeneratedSeqTwoByteString" = type { %"class.v8::internal::SeqString" }
%"class.v8::internal::ConcurrentBitmap.1155" = type { i8 }

$_ZN2v88internal9BaseSpace15CommittedMemoryEv = comdat any

$_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv = comdat any

$_ZN2v88internal13ReadOnlySpace4SizeEv = comdat any

$_ZN2v88internal19SharedReadOnlySpaceD2Ev = comdat any

$_ZN2v88internal19SharedReadOnlySpaceD0Ev = comdat any

$_ZN2v88internal34PointerCompressedReadOnlyArtifactsD2Ev = comdat any

$_ZN2v88internal34PointerCompressedReadOnlyArtifactsD0Ev = comdat any

$_ZN2v88internal17ReadOnlyArtifactsD2Ev = comdat any

$_ZN2v88internal17ReadOnlyArtifactsD0Ev = comdat any

$_ZNSt3__16vectorINS_10unique_ptrIN2v813PageAllocator19SharedMemoryMappingENS_14default_deleteIS4_EEEENS_9allocatorIS7_EEE21__push_back_slow_pathIS7_EEvOT_ = comdat any

$_ZNSt3__16vectorINS_10unique_ptrIN2v813PageAllocator12SharedMemoryENS_14default_deleteIS4_EEEENS_9allocatorIS7_EEE21__push_back_slow_pathIS7_EEvOT_ = comdat any

$_ZNSt3__16vectorIPN2v88internal12ReadOnlyPageENS_9allocatorIS4_EEE6assignIPS4_EENS_9enable_ifIXaasr27__is_cpp17_forward_iteratorIT_EE5valuesr16is_constructibleIS4_NS_15iterator_traitsISB_E9referenceEEE5valueEvE4typeESB_SB_ = comdat any

$_ZTVN2v88internal17ReadOnlyArtifactsE = comdat any

@_ZTVN2v88internal27SingleCopyReadOnlyArtifactsE = hidden unnamed_addr constant { [8 x i8*] } { [8 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::internal::SingleCopyReadOnlyArtifacts"*)* @_ZN2v88internal27SingleCopyReadOnlyArtifactsD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::SingleCopyReadOnlyArtifacts"*)* @_ZN2v88internal27SingleCopyReadOnlyArtifactsD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::SingleCopyReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)* @_ZN2v88internal27SingleCopyReadOnlyArtifacts10InitializeEPNS0_7IsolateEONSt3__16vectorIPNS0_12ReadOnlyPageENS4_9allocatorIS7_EEEERKNS0_15AllocationStatsE to i8*), i8* bitcast (void (%"class.v8::internal::SingleCopyReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*)* @_ZN2v88internal27SingleCopyReadOnlyArtifacts22ReinstallReadOnlySpaceEPNS0_7IsolateE to i8*), i8* bitcast (%"class.v8::internal::ReadOnlyHeap"* (%"class.v8::internal::SingleCopyReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*)* @_ZN2v88internal27SingleCopyReadOnlyArtifacts25GetReadOnlyHeapForIsolateEPNS0_7IsolateE to i8*), i8* bitcast (void (%"class.v8::internal::SingleCopyReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*)* @_ZN2v88internal27SingleCopyReadOnlyArtifacts31VerifyHeapAndSpaceRelationshipsEPNS0_7IsolateE to i8*)] }, align 8
@.str = private unnamed_addr constant [18 x i8] c"Check failed: %s.\00", align 1
@.str.1 = private unnamed_addr constant [48 x i8] c"page_allocator_->FreePages(chunk_address, size)\00", align 1
@.str.2 = private unnamed_addr constant [8 x i8] c"success\00", align 1
@.str.3 = private unnamed_addr constant [14 x i8] c"shared_memory\00", align 1
@.str.4 = private unnamed_addr constant [22 x i8] c"(new_page) != nullptr\00", align 1
@.str.5 = private unnamed_addr constant [17 x i8] c"(ptr) != nullptr\00", align 1
@_ZTVN2v88internal13ReadOnlySpaceE = hidden unnamed_addr constant { [9 x i8*] } { [9 x i8*] [i8* null, i8* null, i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace15CommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::ReadOnlySpace"*)* @_ZN2v88internal13ReadOnlySpace23CommittedPhysicalMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::ReadOnlySpace"*)* @_ZN2v88internal13ReadOnlySpace4SizeEv to i8*), i8* bitcast (void (%"class.v8::internal::ReadOnlySpace"*)* @_ZN2v88internal13ReadOnlySpaceD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::ReadOnlySpace"*)* @_ZN2v88internal13ReadOnlySpaceD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)* @_ZN2v88internal13ReadOnlySpace8TearDownEPNS0_15MemoryAllocatorE to i8*)] }, align 8
@.str.6 = private unnamed_addr constant [72 x i8] c"SetPermissions(page_allocator, chunk->address(), chunk->size(), access)\00", align 1
@.str.7 = private unnamed_addr constant [19 x i8] c"(chunk) != nullptr\00", align 1
@.str.8 = private unnamed_addr constant [18 x i8] c"!object.is_null()\00", align 1
@.str.9 = private unnamed_addr constant [29 x i8] c"filler.IsFreeSpaceOrFiller()\00", align 1
@_ZN2v88internal21FLAG_trace_gc_verboseE = external local_unnamed_addr global i8, align 1
@.str.10 = private unnamed_addr constant [33 x i8] c"Shrinking page %p: end %p -> %p\0A\00", align 1
@.str.11 = private unnamed_addr constant [47 x i8] c"filler.address() + filler.Size() == area_end()\00", align 1
@_ZTVN2v88internal19SharedReadOnlySpaceE = hidden unnamed_addr constant { [9 x i8*] } { [9 x i8*] [i8* null, i8* null, i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace15CommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::ReadOnlySpace"*)* @_ZN2v88internal13ReadOnlySpace23CommittedPhysicalMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::ReadOnlySpace"*)* @_ZN2v88internal13ReadOnlySpace4SizeEv to i8*), i8* bitcast (void (%"class.v8::internal::SharedReadOnlySpace"*)* @_ZN2v88internal19SharedReadOnlySpaceD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::SharedReadOnlySpace"*)* @_ZN2v88internal19SharedReadOnlySpaceD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)* @_ZN2v88internal19SharedReadOnlySpace8TearDownEPNS0_15MemoryAllocatorE to i8*)] }, align 8
@_ZTVN2v88internal34PointerCompressedReadOnlyArtifactsE = hidden unnamed_addr constant { [8 x i8*] } { [8 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*)* @_ZN2v88internal34PointerCompressedReadOnlyArtifactsD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*)* @_ZN2v88internal34PointerCompressedReadOnlyArtifactsD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)* @_ZN2v88internal34PointerCompressedReadOnlyArtifacts10InitializeEPNS0_7IsolateEONSt3__16vectorIPNS0_12ReadOnlyPageENS4_9allocatorIS7_EEEERKNS0_15AllocationStatsE to i8*), i8* bitcast (void (%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*)* @_ZN2v88internal34PointerCompressedReadOnlyArtifacts22ReinstallReadOnlySpaceEPNS0_7IsolateE to i8*), i8* bitcast (%"class.v8::internal::ReadOnlyHeap"* (%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*)* @_ZN2v88internal34PointerCompressedReadOnlyArtifacts25GetReadOnlyHeapForIsolateEPNS0_7IsolateE to i8*), i8* bitcast (void (%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*)* @_ZN2v88internal34PointerCompressedReadOnlyArtifacts31VerifyHeapAndSpaceRelationshipsEPNS0_7IsolateE to i8*)] }, align 8
@.str.12 = private unnamed_addr constant [17 x i8] c"unreachable code\00", align 1
@_ZTVN2v88internal17ReadOnlyArtifactsE = linkonce_odr hidden unnamed_addr constant { [8 x i8*] } { [8 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::internal::ReadOnlyArtifacts"*)* @_ZN2v88internal17ReadOnlyArtifactsD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::ReadOnlyArtifacts"*)* @_ZN2v88internal17ReadOnlyArtifactsD0Ev to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*)] }, comdat, align 8
@.str.13 = private unnamed_addr constant [16 x i8] c"!object.IsSmi()\00", align 1

@_ZN2v88internal27SingleCopyReadOnlyArtifactsD1Ev = hidden unnamed_addr alias void (%"class.v8::internal::SingleCopyReadOnlyArtifacts"*), void (%"class.v8::internal::SingleCopyReadOnlyArtifacts"*)* @_ZN2v88internal27SingleCopyReadOnlyArtifactsD2Ev
@_ZN2v88internal13ReadOnlySpaceC1EPNS0_4HeapE = hidden unnamed_addr alias void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::Heap"*), void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal13ReadOnlySpaceC2EPNS0_4HeapE
@_ZN2v88internal13ReadOnlySpaceD1Ev = hidden unnamed_addr alias void (%"class.v8::internal::ReadOnlySpace"*), void (%"class.v8::internal::ReadOnlySpace"*)* @_ZN2v88internal13ReadOnlySpaceD2Ev
@_ZN2v88internal19SharedReadOnlySpaceC1EPNS0_4HeapEPNS0_34PointerCompressedReadOnlyArtifactsE = hidden unnamed_addr alias void (%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::Heap"*, %"class.v8::internal::PointerCompressedReadOnlyArtifacts"*), void (%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::Heap"*, %"class.v8::internal::PointerCompressedReadOnlyArtifacts"*)* @_ZN2v88internal19SharedReadOnlySpaceC2EPNS0_4HeapEPNS0_34PointerCompressedReadOnlyArtifactsE
@_ZN2v88internal19SharedReadOnlySpaceC1EPNS0_4HeapEONSt3__16vectorIPNS0_12ReadOnlyPageENS4_9allocatorIS7_EEEEONS5_INS4_10unique_ptrINS_13PageAllocator19SharedMemoryMappingENS4_14default_deleteISE_EEEENS8_ISH_EEEEONS0_15AllocationStatsE = hidden unnamed_addr alias void (%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::Heap"*, %"class.std::__1::vector"*, %"class.std::__1::vector.613"*, %"class.v8::internal::AllocationStats"*), void (%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::Heap"*, %"class.std::__1::vector"*, %"class.std::__1::vector.613"*, %"class.v8::internal::AllocationStats"*)* @_ZN2v88internal19SharedReadOnlySpaceC2EPNS0_4HeapEONSt3__16vectorIPNS0_12ReadOnlyPageENS4_9allocatorIS7_EEEEONS5_INS4_10unique_ptrINS_13PageAllocator19SharedMemoryMappingENS4_14default_deleteISE_EEEENS8_ISH_EEEEONS0_15AllocationStatsE
@_ZN2v88internal19SharedReadOnlySpaceC1EPNS0_4HeapEPNS0_27SingleCopyReadOnlyArtifactsE = hidden unnamed_addr alias void (%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::Heap"*, %"class.v8::internal::SingleCopyReadOnlyArtifacts"*), void (%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::Heap"*, %"class.v8::internal::SingleCopyReadOnlyArtifacts"*)* @_ZN2v88internal19SharedReadOnlySpaceC2EPNS0_4HeapEPNS0_27SingleCopyReadOnlyArtifactsE

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal18CopyAndRebaseRootsEPmS1_m(i64* nocapture readonly, i64* nocapture, i64) local_unnamed_addr #0 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.12, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal17ReadOnlyArtifacts18set_read_only_heapENSt3__110unique_ptrINS0_12ReadOnlyHeapENS2_14default_deleteIS4_EEEE(%"class.v8::internal::ReadOnlyArtifacts"* nocapture, %"class.v8::internal::ReadOnlyHeap"*) local_unnamed_addr #0 align 2 {
  %3 = ptrtoint %"class.v8::internal::ReadOnlyHeap"* %1 to i64
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlyArtifacts", %"class.v8::internal::ReadOnlyArtifacts"* %0, i64 0, i32 4
  %5 = getelementptr inbounds %"class.std::__1::unique_ptr.629", %"class.std::__1::unique_ptr.629"* %4, i64 0, i32 0, i32 0, i32 0
  %6 = load %"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlyHeap"** %5, align 8
  %7 = bitcast %"class.std::__1::unique_ptr.629"* %4 to i64*
  store i64 %3, i64* %7, align 8
  %8 = icmp eq %"class.v8::internal::ReadOnlyHeap"* %6, null
  br i1 %8, label %14, label %9

9:                                                ; preds = %2
  %10 = bitcast %"class.v8::internal::ReadOnlyHeap"* %6 to void (%"class.v8::internal::ReadOnlyHeap"*)***
  %11 = load void (%"class.v8::internal::ReadOnlyHeap"*)**, void (%"class.v8::internal::ReadOnlyHeap"*)*** %10, align 8
  %12 = getelementptr inbounds void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %11, i64 1
  %13 = load void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %12, align 8
  tail call void %13(%"class.v8::internal::ReadOnlyHeap"* nonnull %6) #15
  br label %14

14:                                               ; preds = %9, %2
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void @_ZN2v88internal17ReadOnlyArtifacts18InitializeChecksumEPNS0_12SnapshotDataE(%"class.v8::internal::ReadOnlyArtifacts"* nocapture, %"class.v8::internal::SnapshotData"* nocapture) local_unnamed_addr #2 align 2 {
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void @_ZN2v88internal17ReadOnlyArtifacts14VerifyChecksumEPNS0_12SnapshotDataEb(%"class.v8::internal::ReadOnlyArtifacts"* nocapture, %"class.v8::internal::SnapshotData"* nocapture, i1 zeroext) local_unnamed_addr #2 align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27SingleCopyReadOnlyArtifactsD2Ev(%"class.v8::internal::SingleCopyReadOnlyArtifacts"* nocapture) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [8 x i8*] }, { [8 x i8*] }* @_ZTVN2v88internal27SingleCopyReadOnlyArtifactsE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0
  %4 = load %"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::SharedReadOnlySpace"** %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %4, i64 0, i32 0, i32 3
  %6 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %4, i64 0, i32 0, i32 3, i32 0, i32 1
  %7 = bitcast %"class.v8::internal::ReadOnlyPage"*** %6 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = bitcast %"class.std::__1::vector"* %5 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = icmp eq i64 %8, %10
  br i1 %11, label %14, label %12

12:                                               ; preds = %1
  %13 = inttoptr i64 %10 to %"class.v8::internal::ReadOnlyPage"**
  store %"class.v8::internal::ReadOnlyPage"** %13, %"class.v8::internal::ReadOnlyPage"*** %6, align 8
  br label %14

14:                                               ; preds = %1, %12
  %15 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %16 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %15, align 8
  %17 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 1
  %18 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %17, align 8
  %19 = icmp eq %"class.v8::internal::ReadOnlyPage"** %16, %18
  br i1 %19, label %24, label %20

20:                                               ; preds = %14
  %21 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 1
  br label %49

22:                                               ; preds = %49
  %23 = icmp eq %"class.v8::internal::ReadOnlyPage"** %72, %18
  br i1 %23, label %24, label %49

24:                                               ; preds = %22, %14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [8 x i8*] }, { [8 x i8*] }* @_ZTVN2v88internal17ReadOnlyArtifactsE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %25 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 4, i32 0, i32 0, i32 0
  %26 = load %"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlyHeap"** %25, align 8
  store %"class.v8::internal::ReadOnlyHeap"* null, %"class.v8::internal::ReadOnlyHeap"** %25, align 8
  %27 = icmp eq %"class.v8::internal::ReadOnlyHeap"* %26, null
  br i1 %27, label %33, label %28

28:                                               ; preds = %24
  %29 = bitcast %"class.v8::internal::ReadOnlyHeap"* %26 to void (%"class.v8::internal::ReadOnlyHeap"*)***
  %30 = load void (%"class.v8::internal::ReadOnlyHeap"*)**, void (%"class.v8::internal::ReadOnlyHeap"*)*** %29, align 8
  %31 = getelementptr inbounds void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %30, i64 1
  %32 = load void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %31, align 8
  tail call void %32(%"class.v8::internal::ReadOnlyHeap"* nonnull %26) #15
  br label %33

33:                                               ; preds = %28, %24
  %34 = load %"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::SharedReadOnlySpace"** %3, align 8
  store %"class.v8::internal::SharedReadOnlySpace"* null, %"class.v8::internal::SharedReadOnlySpace"** %3, align 8
  %35 = icmp eq %"class.v8::internal::SharedReadOnlySpace"* %34, null
  br i1 %35, label %41, label %36

36:                                               ; preds = %33
  %37 = bitcast %"class.v8::internal::SharedReadOnlySpace"* %34 to void (%"class.v8::internal::SharedReadOnlySpace"*)***
  %38 = load void (%"class.v8::internal::SharedReadOnlySpace"*)**, void (%"class.v8::internal::SharedReadOnlySpace"*)*** %37, align 8
  %39 = getelementptr inbounds void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %38, i64 5
  %40 = load void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %39, align 8
  tail call void %40(%"class.v8::internal::SharedReadOnlySpace"* nonnull %34) #15
  br label %41

41:                                               ; preds = %36, %33
  %42 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %15, align 8
  %43 = icmp eq %"class.v8::internal::ReadOnlyPage"** %42, null
  br i1 %43, label %48, label %44

44:                                               ; preds = %41
  %45 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %42 to i64
  %46 = bitcast %"class.v8::internal::ReadOnlyPage"*** %17 to i64*
  store i64 %45, i64* %46, align 8
  %47 = bitcast %"class.v8::internal::ReadOnlyPage"** %42 to i8*
  tail call void @_ZdlPv(i8* %47) #16
  br label %48

48:                                               ; preds = %41, %44
  ret void

49:                                               ; preds = %20, %22
  %50 = phi %"class.v8::internal::ReadOnlyPage"** [ %16, %20 ], [ %72, %22 ]
  %51 = bitcast %"class.v8::internal::ReadOnlyPage"** %50 to %"class.v8::internal::BasicMemoryChunk"**
  %52 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %51, align 8
  %53 = bitcast %"class.v8::internal::BasicMemoryChunk"* %52 to i8*
  %54 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %52, i64 0, i32 0
  %55 = load i64, i64* %54, align 8
  %56 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %21, align 8
  %57 = bitcast %"class.v8::PageAllocator"* %56 to i64 (%"class.v8::PageAllocator"*)***
  %58 = load i64 (%"class.v8::PageAllocator"*)**, i64 (%"class.v8::PageAllocator"*)*** %57, align 8
  %59 = getelementptr inbounds i64 (%"class.v8::PageAllocator"*)*, i64 (%"class.v8::PageAllocator"*)** %58, i64 2
  %60 = load i64 (%"class.v8::PageAllocator"*)*, i64 (%"class.v8::PageAllocator"*)** %59, align 8
  %61 = tail call i64 %60(%"class.v8::PageAllocator"* %56) #15
  %62 = add i64 %55, -1
  %63 = add i64 %62, %61
  %64 = sub nsw i64 0, %61
  %65 = and i64 %63, %64
  %66 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %21, align 8
  %67 = bitcast %"class.v8::PageAllocator"* %66 to i1 (%"class.v8::PageAllocator"*, i8*, i64)***
  %68 = load i1 (%"class.v8::PageAllocator"*, i8*, i64)**, i1 (%"class.v8::PageAllocator"*, i8*, i64)*** %67, align 8
  %69 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64)*, i1 (%"class.v8::PageAllocator"*, i8*, i64)** %68, i64 7
  %70 = load i1 (%"class.v8::PageAllocator"*, i8*, i64)*, i1 (%"class.v8::PageAllocator"*, i8*, i64)** %69, align 8
  %71 = tail call zeroext i1 %70(%"class.v8::PageAllocator"* %66, i8* %53, i64 %65) #15
  %72 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %50, i64 1
  br i1 %71, label %22, label %73, !prof !2

73:                                               ; preds = %49
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([48 x i8], [48 x i8]* @.str.1, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: noreturn
declare void @_Z8V8_FatalPKcz(i8*, ...) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27SingleCopyReadOnlyArtifactsD0Ev(%"class.v8::internal::SingleCopyReadOnlyArtifacts"*) unnamed_addr #0 align 2 {
  tail call void @_ZN2v88internal27SingleCopyReadOnlyArtifactsD2Ev(%"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0) #15
  %2 = bitcast %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #16
  ret void
}

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #4

; Function Attrs: norecurse nounwind readonly ssp uwtable
define hidden %"class.v8::internal::ReadOnlyHeap"* @_ZN2v88internal27SingleCopyReadOnlyArtifacts25GetReadOnlyHeapForIsolateEPNS0_7IsolateE(%"class.v8::internal::SingleCopyReadOnlyArtifacts"* nocapture readonly, %"class.v8::internal::Isolate"* nocapture readnone) unnamed_addr #5 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 4, i32 0, i32 0, i32 0
  %4 = load %"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlyHeap"** %3, align 8
  ret %"class.v8::internal::ReadOnlyHeap"* %4
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27SingleCopyReadOnlyArtifacts10InitializeEPNS0_7IsolateEONSt3__16vectorIPNS0_12ReadOnlyPageENS4_9allocatorIS7_EEEERKNS0_15AllocationStatsE(%"class.v8::internal::SingleCopyReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"* nocapture dereferenceable(24), %"class.v8::internal::AllocationStats"* nocapture readonly dereferenceable(24)) unnamed_addr #0 align 2 {
  %5 = tail call %"class.v8::PageAllocator"* @_ZNK2v88internal7Isolate14page_allocatorEv(%"class.v8::internal::Isolate"* %1) #15
  %6 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 1
  store %"class.v8::PageAllocator"* %5, %"class.v8::PageAllocator"** %6, align 8
  %7 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1
  %8 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %7, i64 0, i32 0, i32 0
  %9 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %8, align 8
  %10 = icmp eq %"class.v8::internal::ReadOnlyPage"** %9, null
  br i1 %10, label %17, label %11

11:                                               ; preds = %4
  %12 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %9 to i64
  %13 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 1
  %14 = bitcast %"class.v8::internal::ReadOnlyPage"*** %13 to i64*
  store i64 %12, i64* %14, align 8
  %15 = bitcast %"class.v8::internal::ReadOnlyPage"** %9 to i8*
  tail call void @_ZdlPv(i8* %15) #16
  %16 = bitcast %"class.std::__1::vector"* %7 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %16, i8 0, i64 24, i1 false) #15
  br label %17

17:                                               ; preds = %4, %11
  %18 = bitcast %"class.std::__1::vector"* %2 to i64*
  %19 = load i64, i64* %18, align 8
  %20 = bitcast %"class.std::__1::vector"* %7 to i64*
  store i64 %19, i64* %20, align 8
  %21 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %2, i64 0, i32 0, i32 1
  %22 = bitcast %"class.v8::internal::ReadOnlyPage"*** %21 to i64*
  %23 = load i64, i64* %22, align 8
  %24 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 1
  %25 = bitcast %"class.v8::internal::ReadOnlyPage"*** %24 to i64*
  store i64 %23, i64* %25, align 8
  %26 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %2, i64 0, i32 0, i32 2, i32 0, i32 0
  %27 = bitcast %"class.v8::internal::ReadOnlyPage"*** %26 to i64*
  %28 = load i64, i64* %27, align 8
  %29 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 2, i32 0, i32 0
  %30 = bitcast %"class.v8::internal::ReadOnlyPage"*** %29 to i64*
  store i64 %28, i64* %30, align 8
  %31 = bitcast %"class.std::__1::vector"* %2 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %31, i8 0, i64 24, i1 false) #15
  %32 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %33 = load atomic i64, i64* %32 seq_cst, align 8
  %34 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %33, i64* %34 seq_cst, align 8
  %35 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %3, i64 0, i32 1
  %36 = load i64, i64* %35, align 8
  %37 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 2, i32 1
  store i64 %36, i64* %37, align 8
  %38 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %3, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %39 = load atomic i64, i64* %38 seq_cst, align 8
  %40 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %39, i64* %40 seq_cst, align 8
  %41 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 2
  %42 = tail call i8* @_ZN2v88internal8MallocednwEm(i64 160) #15
  %43 = bitcast i8* %42 to i32 (...)***
  %44 = getelementptr inbounds i8, i8* %42, i64 8
  %45 = bitcast i8* %44 to %"class.v8::internal::Heap"**
  store %"class.v8::internal::Heap"* %41, %"class.v8::internal::Heap"** %45, align 8
  %46 = getelementptr inbounds i8, i8* %42, i64 16
  %47 = bitcast i8* %46 to i32*
  store i32 0, i32* %47, align 8
  %48 = getelementptr inbounds i8, i8* %42, i64 24
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %48, i8 0, i64 16, i1 false) #15
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %43, align 8
  %49 = getelementptr inbounds i8, i8* %42, i64 40
  store i8 0, i8* %49, align 8
  %50 = getelementptr inbounds i8, i8* %42, i64 48
  %51 = bitcast i8* %50 to i64*
  store atomic i64 0, i64* %51 seq_cst, align 8
  %52 = getelementptr inbounds i8, i8* %42, i64 56
  %53 = bitcast i8* %52 to i64*
  store i64 0, i64* %53, align 8
  %54 = getelementptr inbounds i8, i8* %42, i64 64
  %55 = bitcast i8* %54 to i64*
  store atomic i64 0, i64* %55 seq_cst, align 8
  %56 = getelementptr inbounds i8, i8* %42, i64 72
  %57 = bitcast i8* %56 to %"class.std::__1::vector"*
  %58 = getelementptr inbounds i8, i8* %42, i64 112
  %59 = ptrtoint %"class.v8::internal::Heap"* %41 to i64
  %60 = add i64 %59, -41416
  %61 = inttoptr i64 %60 to %"class.v8::internal::Isolate"*
  %62 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %61, i64 0, i32 63
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %56, i8 0, i64 40, i1 false) #15
  %63 = load i8, i8* %62, align 1, !range !3
  store i8 %63, i8* %58, align 8
  %64 = getelementptr inbounds i8, i8* %42, i64 120
  %65 = bitcast i8* %64 to i64*
  store i64 0, i64* %65, align 8
  %66 = getelementptr inbounds i8, i8* %42, i64 128
  %67 = bitcast i8* %66 to i64*
  %68 = tail call i64 @_ZN2v88internal17MemoryChunkLayout30AllocatableMemoryInMemoryChunkENS0_15AllocationSpaceE(i32 0) #15
  store i64 %68, i64* %67, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal19SharedReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %43, align 8
  %69 = getelementptr inbounds i8, i8* %42, i64 136
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %69, i8 0, i64 24, i1 false) #15
  store i8 1, i8* %49, align 8
  %70 = load atomic i64, i64* %34 seq_cst, align 8
  store atomic i64 %70, i64* %51 seq_cst, align 8
  %71 = load i64, i64* %37, align 8
  store i64 %71, i64* %53, align 8
  %72 = load atomic i64, i64* %40 seq_cst, align 8
  store atomic i64 %72, i64* %55 seq_cst, align 8
  %73 = icmp eq %"class.std::__1::vector"* %7, %57
  br i1 %73, label %77, label %74

74:                                               ; preds = %17
  %75 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %8, align 8
  %76 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %24, align 8
  tail call void @_ZNSt3__16vectorIPN2v88internal12ReadOnlyPageENS_9allocatorIS4_EEE6assignIPS4_EENS_9enable_ifIXaasr27__is_cpp17_forward_iteratorIT_EE5valuesr16is_constructibleIS4_NS_15iterator_traitsISB_E9referenceEEE5valueEvE4typeESB_SB_(%"class.std::__1::vector"* %57, %"class.v8::internal::ReadOnlyPage"** %75, %"class.v8::internal::ReadOnlyPage"** %76) #15
  br label %77

77:                                               ; preds = %17, %74
  %78 = ptrtoint i8* %42 to i64
  %79 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 3
  %80 = getelementptr inbounds %"class.std::__1::unique_ptr.610", %"class.std::__1::unique_ptr.610"* %79, i64 0, i32 0, i32 0, i32 0
  %81 = load %"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::SharedReadOnlySpace"** %80, align 8
  %82 = bitcast %"class.std::__1::unique_ptr.610"* %79 to i64*
  store i64 %78, i64* %82, align 8
  %83 = icmp eq %"class.v8::internal::SharedReadOnlySpace"* %81, null
  br i1 %83, label %89, label %84

84:                                               ; preds = %77
  %85 = bitcast %"class.v8::internal::SharedReadOnlySpace"* %81 to void (%"class.v8::internal::SharedReadOnlySpace"*)***
  %86 = load void (%"class.v8::internal::SharedReadOnlySpace"*)**, void (%"class.v8::internal::SharedReadOnlySpace"*)*** %85, align 8
  %87 = getelementptr inbounds void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %86, i64 5
  %88 = load void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %87, align 8
  tail call void %88(%"class.v8::internal::SharedReadOnlySpace"* nonnull %81) #15
  br label %89

89:                                               ; preds = %77, %84
  ret void
}

declare %"class.v8::PageAllocator"* @_ZNK2v88internal7Isolate14page_allocatorEv(%"class.v8::internal::Isolate"*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27SingleCopyReadOnlyArtifacts22ReinstallReadOnlySpaceEPNS0_7IsolateE(%"class.v8::internal::SingleCopyReadOnlyArtifacts"* nocapture readonly, %"class.v8::internal::Isolate"*) unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 2
  %4 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0
  %5 = load %"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::SharedReadOnlySpace"** %4, align 8
  tail call void @_ZN2v88internal4Heap20ReplaceReadOnlySpaceEPNS0_19SharedReadOnlySpaceE(%"class.v8::internal::Heap"* %3, %"class.v8::internal::SharedReadOnlySpace"* %5) #15
  ret void
}

declare void @_ZN2v88internal4Heap20ReplaceReadOnlySpaceEPNS0_19SharedReadOnlySpaceE(%"class.v8::internal::Heap"*, %"class.v8::internal::SharedReadOnlySpace"*) local_unnamed_addr #6

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void @_ZN2v88internal27SingleCopyReadOnlyArtifacts31VerifyHeapAndSpaceRelationshipsEPNS0_7IsolateE(%"class.v8::internal::SingleCopyReadOnlyArtifacts"* nocapture, %"class.v8::internal::Isolate"* nocapture) unnamed_addr #2 align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal34PointerCompressedReadOnlyArtifacts19InitializeRootsFromEPNS0_7IsolateE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"* nocapture readnone, %"class.v8::internal::Isolate"*) local_unnamed_addr #0 align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.12, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal34PointerCompressedReadOnlyArtifacts17InitializeRootsInEPNS0_7IsolateE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"* nocapture readnone, %"class.v8::internal::Isolate"*) local_unnamed_addr #0 align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.12, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::SharedReadOnlySpace"* @_ZN2v88internal34PointerCompressedReadOnlyArtifacts19CreateReadOnlySpaceEPNS0_7IsolateE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"* nocapture readonly, %"class.v8::internal::Isolate"*) local_unnamed_addr #0 align 2 {
  %3 = alloca %"class.v8::internal::AllocationStats", align 8
  %4 = alloca %"class.std::__1::vector.613", align 8
  %5 = alloca %"class.std::__1::vector", align 8
  %6 = alloca %"class.std::__1::unique_ptr.615", align 8
  %7 = bitcast %"class.v8::internal::AllocationStats"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %7) #15
  %8 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %8 seq_cst, align 8
  %9 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %3, i64 0, i32 1
  store i64 0, i64* %9, align 8
  %10 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %3, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %10 seq_cst, align 8
  %11 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = load atomic i64, i64* %11 seq_cst, align 8
  %13 = atomicrmw add i64* %8, i64 %12 seq_cst
  %14 = load atomic i64, i64* %8 seq_cst, align 8
  %15 = load i64, i64* %9, align 8
  %16 = icmp ugt i64 %14, %15
  br i1 %16, label %17, label %19

17:                                               ; preds = %2
  %18 = load atomic i64, i64* %8 seq_cst, align 8
  store i64 %18, i64* %9, align 8
  br label %19

19:                                               ; preds = %2, %17
  %20 = bitcast %"class.std::__1::vector.613"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %20) #15
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %20, i8 0, i64 24, i1 false) #15
  %21 = bitcast %"class.std::__1::vector"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %21) #15
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %21, i8 0, i64 24, i1 false) #15
  %22 = ptrtoint %"class.v8::internal::Isolate"* %1 to i64
  %23 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1
  %24 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 1
  %25 = bitcast %"class.v8::internal::ReadOnlyPage"*** %24 to i64*
  %26 = load i64, i64* %25, align 8
  %27 = bitcast %"class.std::__1::vector"* %23 to i64*
  %28 = load i64, i64* %27, align 8
  %29 = icmp eq i64 %26, %28
  br i1 %29, label %45, label %30

30:                                               ; preds = %19
  %31 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 2, i32 0, i32 0
  %32 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 2, i32 85, i32 0, i32 0, i32 0
  %33 = bitcast %"class.std::__1::unique_ptr.615"* %6 to i8*
  %34 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3, i32 0, i32 0
  %35 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %6, i64 0, i32 0, i32 0, i32 0
  %36 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %4, i64 0, i32 0, i32 1
  %37 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %4, i64 0, i32 0, i32 2, i32 0, i32 0
  %38 = bitcast %"class.std::__1::unique_ptr.615"* %6 to i64*
  %39 = bitcast %"class.std::__1::unique_ptr.615"** %36 to i64*
  %40 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %5, i64 0, i32 0, i32 1
  %41 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %5, i64 0, i32 0, i32 2, i32 0, i32 0
  %42 = bitcast %"class.v8::internal::ReadOnlyPage"*** %40 to i64*
  %43 = bitcast %"class.std::__1::vector"* %5 to i64*
  %44 = bitcast %"class.v8::internal::ReadOnlyPage"*** %41 to i64*
  br label %85

45:                                               ; preds = %197, %19
  %46 = call i8* @_ZN2v88internal8MallocednwEm(i64 160) #15
  %47 = bitcast i8* %46 to %"class.v8::internal::SharedReadOnlySpace"*
  %48 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 2
  call void @_ZN2v88internal19SharedReadOnlySpaceC2EPNS0_4HeapEONSt3__16vectorIPNS0_12ReadOnlyPageENS4_9allocatorIS7_EEEEONS5_INS4_10unique_ptrINS_13PageAllocator19SharedMemoryMappingENS4_14default_deleteISE_EEEENS8_ISH_EEEEONS0_15AllocationStatsE(%"class.v8::internal::SharedReadOnlySpace"* %47, %"class.v8::internal::Heap"* %48, %"class.std::__1::vector"* nonnull dereferenceable(24) %5, %"class.std::__1::vector.613"* nonnull dereferenceable(24) %4, %"class.v8::internal::AllocationStats"* nonnull dereferenceable(24) %3)
  %49 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %5, i64 0, i32 0, i32 0
  %50 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %49, align 8
  %51 = icmp eq %"class.v8::internal::ReadOnlyPage"** %50, null
  br i1 %51, label %57, label %52

52:                                               ; preds = %45
  %53 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %50 to i64
  %54 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %5, i64 0, i32 0, i32 1
  %55 = bitcast %"class.v8::internal::ReadOnlyPage"*** %54 to i64*
  store i64 %53, i64* %55, align 8
  %56 = bitcast %"class.v8::internal::ReadOnlyPage"** %50 to i8*
  call void @_ZdlPv(i8* %56) #16
  br label %57

57:                                               ; preds = %45, %52
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %21) #15
  %58 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %4, i64 0, i32 0, i32 0
  %59 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %58, align 8
  %60 = icmp eq %"class.std::__1::unique_ptr.615"* %59, null
  br i1 %60, label %84, label %61

61:                                               ; preds = %57
  %62 = bitcast %"class.std::__1::unique_ptr.615"* %59 to i8*
  %63 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %4, i64 0, i32 0, i32 1
  %64 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %63, align 8
  %65 = icmp eq %"class.std::__1::unique_ptr.615"* %64, %59
  br i1 %65, label %82, label %66

66:                                               ; preds = %61, %77
  %67 = phi %"class.std::__1::unique_ptr.615"* [ %68, %77 ], [ %64, %61 ]
  %68 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %67, i64 -1
  %69 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %68, i64 0, i32 0, i32 0, i32 0
  %70 = load %"class.v8::PageAllocator::SharedMemoryMapping"*, %"class.v8::PageAllocator::SharedMemoryMapping"** %69, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %69, align 8
  %71 = icmp eq %"class.v8::PageAllocator::SharedMemoryMapping"* %70, null
  br i1 %71, label %77, label %72

72:                                               ; preds = %66
  %73 = bitcast %"class.v8::PageAllocator::SharedMemoryMapping"* %70 to void (%"class.v8::PageAllocator::SharedMemoryMapping"*)***
  %74 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)**, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*** %73, align 8
  %75 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %74, i64 1
  %76 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %75, align 8
  call void %76(%"class.v8::PageAllocator::SharedMemoryMapping"* nonnull %70) #15
  br label %77

77:                                               ; preds = %72, %66
  %78 = icmp eq %"class.std::__1::unique_ptr.615"* %68, %59
  br i1 %78, label %79, label %66

79:                                               ; preds = %77
  %80 = bitcast %"class.std::__1::vector.613"* %4 to i8**
  %81 = load i8*, i8** %80, align 8
  br label %82

82:                                               ; preds = %79, %61
  %83 = phi i8* [ %81, %79 ], [ %62, %61 ]
  store %"class.std::__1::unique_ptr.615"* %59, %"class.std::__1::unique_ptr.615"** %63, align 8
  call void @_ZdlPv(i8* %83) #16
  br label %84

84:                                               ; preds = %57, %82
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %20) #15
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %7) #15
  ret %"class.v8::internal::SharedReadOnlySpace"* %47

85:                                               ; preds = %30, %197
  %86 = phi i64 [ %28, %30 ], [ %200, %197 ]
  %87 = phi i64 [ 0, %30 ], [ %198, %197 ]
  %88 = inttoptr i64 %86 to %"class.v8::internal::ReadOnlyPage"**
  %89 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %88, i64 %87
  %90 = bitcast %"class.v8::internal::ReadOnlyPage"** %89 to %"class.v8::internal::BasicMemoryChunk"**
  %91 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %90, align 8
  %92 = load i32*, i32** %31, align 8
  %93 = getelementptr inbounds i32, i32* %92, i64 %87
  %94 = load i32, i32* %93, align 4
  %95 = zext i32 %94 to i64
  %96 = add i64 %95, %22
  %97 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %32, align 8
  %98 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %97, i64 0, i32 1
  %99 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %98, align 8
  %100 = inttoptr i64 %96 to i8*
  %101 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %91, i64 0, i32 0
  %102 = load i64, i64* %101, align 8
  %103 = bitcast %"class.v8::PageAllocator"* %99 to i1 (%"class.v8::PageAllocator"*, i8*, i64)***
  %104 = load i1 (%"class.v8::PageAllocator"*, i8*, i64)**, i1 (%"class.v8::PageAllocator"*, i8*, i64)*** %103, align 8
  %105 = getelementptr inbounds i1 (%"class.v8::PageAllocator"*, i8*, i64)*, i1 (%"class.v8::PageAllocator"*, i8*, i64)** %104, i64 11
  %106 = load i1 (%"class.v8::PageAllocator"*, i8*, i64)*, i1 (%"class.v8::PageAllocator"*, i8*, i64)** %105, align 8
  %107 = call zeroext i1 %106(%"class.v8::PageAllocator"* %99, i8* %100, i64 %102) #15
  br i1 %107, label %109, label %108, !prof !2

108:                                              ; preds = %85
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.2, i64 0, i64 0)) #14
  unreachable

109:                                              ; preds = %85
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %33) #15
  %110 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %34, align 8
  %111 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %110, i64 %87, i32 0, i32 0, i32 0
  %112 = load %"class.v8::PageAllocator::SharedMemory"*, %"class.v8::PageAllocator::SharedMemory"** %111, align 8
  %113 = bitcast %"class.v8::PageAllocator::SharedMemory"* %112 to %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)***
  %114 = load %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)**, %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)*** %113, align 8
  %115 = getelementptr inbounds %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)*, %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)** %114, i64 2
  %116 = load %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)*, %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)** %115, align 8
  %117 = call %"class.v8::PageAllocator::SharedMemoryMapping"* %116(%"class.v8::PageAllocator::SharedMemory"* %112, i8* %100) #15
  %118 = icmp eq %"class.v8::PageAllocator::SharedMemoryMapping"* %117, null
  store %"class.v8::PageAllocator::SharedMemoryMapping"* %117, %"class.v8::PageAllocator::SharedMemoryMapping"** %35, align 8
  br i1 %118, label %119, label %120

119:                                              ; preds = %109
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.3, i64 0, i64 0)) #14
  unreachable

120:                                              ; preds = %109
  %121 = icmp eq i64 %96, 0
  br i1 %121, label %122, label %123, !prof !4

122:                                              ; preds = %120
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.4, i64 0, i64 0)) #14
  unreachable

123:                                              ; preds = %120
  %124 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %91, i64 0, i32 5
  %125 = load i64, i64* %124, align 8
  %126 = atomicrmw add i64* %10, i64 %125 seq_cst
  %127 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %36, align 8
  %128 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %37, align 8
  %129 = icmp ult %"class.std::__1::unique_ptr.615"* %127, %128
  br i1 %129, label %130, label %135

130:                                              ; preds = %123
  %131 = load i64, i64* %38, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %35, align 8
  %132 = bitcast %"class.std::__1::unique_ptr.615"* %127 to i64*
  store i64 %131, i64* %132, align 8
  %133 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %127, i64 1
  %134 = ptrtoint %"class.std::__1::unique_ptr.615"* %133 to i64
  store i64 %134, i64* %39, align 8
  br label %136

135:                                              ; preds = %123
  call void @_ZNSt3__16vectorINS_10unique_ptrIN2v813PageAllocator19SharedMemoryMappingENS_14default_deleteIS4_EEEENS_9allocatorIS7_EEE21__push_back_slow_pathIS7_EEvOT_(%"class.std::__1::vector.613"* nonnull %4, %"class.std::__1::unique_ptr.615"* nonnull dereferenceable(8) %6) #15
  br label %136

136:                                              ; preds = %130, %135
  %137 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %40, align 8
  %138 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %41, align 8
  %139 = icmp eq %"class.v8::internal::ReadOnlyPage"** %137, %138
  %140 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %138 to i64
  br i1 %139, label %145, label %141

141:                                              ; preds = %136
  %142 = bitcast %"class.v8::internal::ReadOnlyPage"** %137 to i64*
  store i64 %96, i64* %142, align 8
  %143 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %137, i64 1
  %144 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %143 to i64
  store i64 %144, i64* %42, align 8
  br label %189

145:                                              ; preds = %136
  %146 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %137 to i64
  %147 = load i64, i64* %43, align 8
  %148 = sub i64 %146, %147
  %149 = ashr exact i64 %148, 3
  %150 = add nsw i64 %149, 1
  %151 = icmp ugt i64 %150, 2305843009213693951
  br i1 %151, label %152, label %154

152:                                              ; preds = %145
  %153 = bitcast %"class.std::__1::vector"* %5 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %153) #14
  unreachable

154:                                              ; preds = %145
  %155 = sub i64 %140, %147
  %156 = ashr exact i64 %155, 3
  %157 = icmp ult i64 %156, 1152921504606846975
  br i1 %157, label %158, label %166

158:                                              ; preds = %154
  %159 = ashr exact i64 %155, 2
  %160 = icmp ult i64 %159, %150
  %161 = select i1 %160, i64 %150, i64 %159
  %162 = icmp eq i64 %161, 0
  br i1 %162, label %171, label %163

163:                                              ; preds = %158
  %164 = icmp ugt i64 %161, 2305843009213693951
  br i1 %164, label %165, label %166

165:                                              ; preds = %163
  call void @abort() #14
  unreachable

166:                                              ; preds = %163, %154
  %167 = phi i64 [ %161, %163 ], [ 2305843009213693951, %154 ]
  %168 = shl i64 %167, 3
  %169 = call i8* @_Znwm(i64 %168) #16
  %170 = bitcast i8* %169 to %"class.v8::internal::ReadOnlyPage"**
  br label %171

171:                                              ; preds = %166, %158
  %172 = phi i64 [ %167, %166 ], [ 0, %158 ]
  %173 = phi i8* [ %169, %166 ], [ null, %158 ]
  %174 = phi %"class.v8::internal::ReadOnlyPage"** [ %170, %166 ], [ null, %158 ]
  %175 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %174, i64 %149
  %176 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %174, i64 %172
  %177 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %176 to i64
  %178 = bitcast %"class.v8::internal::ReadOnlyPage"** %175 to i64*
  store i64 %96, i64* %178, align 8
  %179 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %175, i64 1
  %180 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %179 to i64
  %181 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %174 to i64
  %182 = icmp sgt i64 %148, 0
  br i1 %182, label %183, label %185

183:                                              ; preds = %171
  %184 = inttoptr i64 %147 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %173, i8* align 8 %184, i64 %148, i1 false) #15
  br label %185

185:                                              ; preds = %183, %171
  store i64 %181, i64* %43, align 8
  store i64 %180, i64* %42, align 8
  store i64 %177, i64* %44, align 8
  %186 = icmp eq i64 %147, 0
  br i1 %186, label %189, label %187

187:                                              ; preds = %185
  %188 = inttoptr i64 %147 to i8*
  call void @_ZdlPv(i8* %188) #16
  br label %189

189:                                              ; preds = %141, %185, %187
  %190 = load %"class.v8::PageAllocator::SharedMemoryMapping"*, %"class.v8::PageAllocator::SharedMemoryMapping"** %35, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %35, align 8
  %191 = icmp eq %"class.v8::PageAllocator::SharedMemoryMapping"* %190, null
  br i1 %191, label %197, label %192

192:                                              ; preds = %189
  %193 = bitcast %"class.v8::PageAllocator::SharedMemoryMapping"* %190 to void (%"class.v8::PageAllocator::SharedMemoryMapping"*)***
  %194 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)**, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*** %193, align 8
  %195 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %194, i64 1
  %196 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %195, align 8
  call void %196(%"class.v8::PageAllocator::SharedMemoryMapping"* nonnull %190) #15
  br label %197

197:                                              ; preds = %189, %192
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %33) #15
  %198 = add nuw i64 %87, 1
  %199 = load i64, i64* %25, align 8
  %200 = load i64, i64* %27, align 8
  %201 = sub i64 %199, %200
  %202 = ashr exact i64 %201, 3
  %203 = icmp ult i64 %198, %202
  br i1 %203, label %85, label %45
}

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::PageAllocator::SharedMemoryMapping"* @_ZN2v88internal34PointerCompressedReadOnlyArtifacts11RemapPageToEmmRPNS0_12ReadOnlyPageE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"* nocapture readonly, i64, i64, %"class.v8::internal::ReadOnlyPage"** nocapture dereferenceable(8)) local_unnamed_addr #0 align 2 {
  %5 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3, i32 0, i32 0
  %6 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %5, align 8
  %7 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %6, i64 %1, i32 0, i32 0, i32 0
  %8 = load %"class.v8::PageAllocator::SharedMemory"*, %"class.v8::PageAllocator::SharedMemory"** %7, align 8
  %9 = inttoptr i64 %2 to i8*
  %10 = bitcast %"class.v8::PageAllocator::SharedMemory"* %8 to %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)***
  %11 = load %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)**, %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)*** %10, align 8
  %12 = getelementptr inbounds %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)*, %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)** %11, i64 2
  %13 = load %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)*, %"class.v8::PageAllocator::SharedMemoryMapping"* (%"class.v8::PageAllocator::SharedMemory"*, i8*)** %12, align 8
  %14 = tail call %"class.v8::PageAllocator::SharedMemoryMapping"* %13(%"class.v8::PageAllocator::SharedMemory"* %8, i8* %9) #15
  %15 = icmp eq %"class.v8::PageAllocator::SharedMemoryMapping"* %14, null
  br i1 %15, label %18, label %16

16:                                               ; preds = %4
  %17 = inttoptr i64 %2 to %"class.v8::internal::ReadOnlyPage"*
  store %"class.v8::internal::ReadOnlyPage"* %17, %"class.v8::internal::ReadOnlyPage"** %3, align 8
  br label %18

18:                                               ; preds = %4, %16
  ret %"class.v8::PageAllocator::SharedMemoryMapping"* %14
}

declare i8* @_ZN2v88internal8MallocednwEm(i64) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden nonnull %"class.v8::internal::ReadOnlyHeap"* @_ZN2v88internal34PointerCompressedReadOnlyArtifacts25GetReadOnlyHeapForIsolateEPNS0_7IsolateE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"* nocapture readonly, %"class.v8::internal::Isolate"*) unnamed_addr #0 align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.12, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #7

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal34PointerCompressedReadOnlyArtifacts10InitializeEPNS0_7IsolateEONSt3__16vectorIPNS0_12ReadOnlyPageENS4_9allocatorIS7_EEEERKNS0_15AllocationStatsE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"* nocapture readonly dereferenceable(24), %"class.v8::internal::AllocationStats"* nocapture readonly dereferenceable(24)) unnamed_addr #0 align 2 {
  %5 = alloca %"class.std::__1::unique_ptr.1142", align 8
  %6 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load atomic i64, i64* %6 seq_cst, align 8
  %8 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %9 = atomicrmw add i64* %8, i64 %7 seq_cst
  %10 = load atomic i64, i64* %8 seq_cst, align 8
  %11 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 2, i32 1
  %12 = load i64, i64* %11, align 8
  %13 = icmp ugt i64 %10, %12
  br i1 %13, label %14, label %16

14:                                               ; preds = %4
  %15 = load atomic i64, i64* %8 seq_cst, align 8
  store i64 %15, i64* %11, align 8
  br label %16

16:                                               ; preds = %4, %14
  %17 = tail call %"class.v8::PageAllocator"* @_ZN2v88internal24GetPlatformPageAllocatorEv() #15
  %18 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %2, i64 0, i32 0, i32 0
  %19 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %18, align 8
  %20 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %2, i64 0, i32 0, i32 1
  %21 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %20, align 8
  %22 = icmp eq %"class.v8::internal::ReadOnlyPage"** %19, %21
  br i1 %22, label %48, label %23

23:                                               ; preds = %16
  %24 = bitcast %"class.v8::PageAllocator"* %17 to i64 (%"class.v8::PageAllocator"*)***
  %25 = bitcast %"class.std::__1::unique_ptr.1142"* %5 to i8*
  %26 = bitcast %"class.v8::PageAllocator"* %17 to %"class.v8::PageAllocator::SharedMemory"* (%"class.v8::PageAllocator"*, i64, i8*)***
  %27 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %5, i64 0, i32 0, i32 0, i32 0
  %28 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1
  %29 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 1
  %30 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 2, i32 0, i32 0
  %31 = bitcast %"class.v8::internal::ReadOnlyPage"*** %29 to i64*
  %32 = bitcast %"class.std::__1::vector"* %28 to i64*
  %33 = bitcast %"class.v8::internal::ReadOnlyPage"*** %30 to i64*
  %34 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %28, i64 0, i32 0, i32 0
  %35 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3, i32 0, i32 1
  %36 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0
  %37 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3
  %38 = bitcast %"class.std::__1::unique_ptr.1142"* %5 to i64*
  %39 = bitcast %"class.std::__1::unique_ptr.1142"** %35 to i64*
  %40 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 2
  %41 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 2, i32 0, i32 1
  %42 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 2, i32 0, i32 2, i32 0, i32 0
  %43 = bitcast i32** %41 to i64*
  %44 = bitcast %"class.std::__1::vector.1133"* %40 to i64*
  %45 = bitcast i32** %42 to i64*
  %46 = getelementptr inbounds %"class.std::__1::vector.1133", %"class.std::__1::vector.1133"* %40, i64 0, i32 0, i32 0
  %47 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %49

48:                                               ; preds = %220, %16
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.12, i64 0, i64 0)) #14
  unreachable

49:                                               ; preds = %23, %220
  %50 = phi %"class.v8::internal::ReadOnlyPage"** [ %19, %23 ], [ %221, %220 ]
  %51 = load %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %50, align 8
  %52 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %51, i64 0, i32 0, i32 0
  %53 = load i64, i64* %52, align 8
  %54 = load i64 (%"class.v8::PageAllocator"*)**, i64 (%"class.v8::PageAllocator"*)*** %24, align 8
  %55 = getelementptr inbounds i64 (%"class.v8::PageAllocator"*)*, i64 (%"class.v8::PageAllocator"*)** %54, i64 2
  %56 = load i64 (%"class.v8::PageAllocator"*)*, i64 (%"class.v8::PageAllocator"*)** %55, align 8
  %57 = call i64 %56(%"class.v8::PageAllocator"* %17) #15
  %58 = add i64 %53, -1
  %59 = add i64 %58, %57
  %60 = sub nsw i64 0, %57
  %61 = and i64 %59, %60
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %25) #15
  %62 = bitcast %"class.v8::internal::ReadOnlyPage"* %51 to i8*
  %63 = load %"class.v8::PageAllocator::SharedMemory"* (%"class.v8::PageAllocator"*, i64, i8*)**, %"class.v8::PageAllocator::SharedMemory"* (%"class.v8::PageAllocator"*, i64, i8*)*** %26, align 8
  %64 = getelementptr inbounds %"class.v8::PageAllocator::SharedMemory"* (%"class.v8::PageAllocator"*, i64, i8*)*, %"class.v8::PageAllocator::SharedMemory"* (%"class.v8::PageAllocator"*, i64, i8*)** %63, i64 12
  %65 = load %"class.v8::PageAllocator::SharedMemory"* (%"class.v8::PageAllocator"*, i64, i8*)*, %"class.v8::PageAllocator::SharedMemory"* (%"class.v8::PageAllocator"*, i64, i8*)** %64, align 8
  %66 = call %"class.v8::PageAllocator::SharedMemory"* %65(%"class.v8::PageAllocator"* %17, i64 %61, i8* %62) #15
  store %"class.v8::PageAllocator::SharedMemory"* %66, %"class.v8::PageAllocator::SharedMemory"** %27, align 8
  %67 = bitcast %"class.v8::PageAllocator::SharedMemory"* %66 to i8* (%"class.v8::PageAllocator::SharedMemory"*)***
  %68 = load i8* (%"class.v8::PageAllocator::SharedMemory"*)**, i8* (%"class.v8::PageAllocator::SharedMemory"*)*** %67, align 8
  %69 = getelementptr inbounds i8* (%"class.v8::PageAllocator::SharedMemory"*)*, i8* (%"class.v8::PageAllocator::SharedMemory"*)** %68, i64 3
  %70 = load i8* (%"class.v8::PageAllocator::SharedMemory"*)*, i8* (%"class.v8::PageAllocator::SharedMemory"*)** %69, align 8
  %71 = call i8* %70(%"class.v8::PageAllocator::SharedMemory"* %66) #15
  %72 = icmp eq i8* %71, null
  br i1 %72, label %73, label %74, !prof !4

73:                                               ; preds = %49
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.5, i64 0, i64 0)) #14
  unreachable

74:                                               ; preds = %49
  %75 = ptrtoint i8* %71 to i64
  %76 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %29, align 8
  %77 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %30, align 8
  %78 = icmp eq %"class.v8::internal::ReadOnlyPage"** %76, %77
  %79 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %77 to i64
  br i1 %78, label %84, label %80

80:                                               ; preds = %74
  %81 = bitcast %"class.v8::internal::ReadOnlyPage"** %76 to i64*
  store i64 %75, i64* %81, align 8
  %82 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %76, i64 1
  %83 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %82 to i64
  store i64 %83, i64* %31, align 8
  br label %137

84:                                               ; preds = %74
  %85 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %76 to i64
  %86 = load i64, i64* %32, align 8
  %87 = sub i64 %85, %86
  %88 = ashr exact i64 %87, 3
  %89 = add nsw i64 %88, 1
  %90 = icmp ugt i64 %89, 2305843009213693951
  br i1 %90, label %91, label %93

91:                                               ; preds = %84
  %92 = bitcast %"class.std::__1::vector"* %28 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %92) #14
  unreachable

93:                                               ; preds = %84
  %94 = sub i64 %79, %86
  %95 = ashr exact i64 %94, 3
  %96 = icmp ult i64 %95, 1152921504606846975
  br i1 %96, label %97, label %105

97:                                               ; preds = %93
  %98 = ashr exact i64 %94, 2
  %99 = icmp ult i64 %98, %89
  %100 = select i1 %99, i64 %89, i64 %98
  %101 = icmp eq i64 %100, 0
  br i1 %101, label %110, label %102

102:                                              ; preds = %97
  %103 = icmp ugt i64 %100, 2305843009213693951
  br i1 %103, label %104, label %105

104:                                              ; preds = %102
  call void @abort() #14
  unreachable

105:                                              ; preds = %102, %93
  %106 = phi i64 [ %100, %102 ], [ 2305843009213693951, %93 ]
  %107 = shl i64 %106, 3
  %108 = call i8* @_Znwm(i64 %107) #16
  %109 = bitcast i8* %108 to %"class.v8::internal::ReadOnlyPage"**
  br label %110

110:                                              ; preds = %105, %97
  %111 = phi i64 [ %106, %105 ], [ 0, %97 ]
  %112 = phi %"class.v8::internal::ReadOnlyPage"** [ %109, %105 ], [ null, %97 ]
  %113 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %112, i64 %88
  %114 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %112, i64 %111
  %115 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %114 to i64
  %116 = bitcast %"class.v8::internal::ReadOnlyPage"** %113 to i64*
  store i64 %75, i64* %116, align 8
  %117 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %113, i64 1
  %118 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %117 to i64
  %119 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %34, align 8
  %120 = load i64, i64* %31, align 8
  %121 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %119 to i64
  %122 = sub i64 %120, %121
  %123 = ashr exact i64 %122, 3
  %124 = sub nsw i64 0, %123
  %125 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %113, i64 %124
  %126 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %125 to i64
  %127 = icmp sgt i64 %122, 0
  br i1 %127, label %128, label %132

128:                                              ; preds = %110
  %129 = bitcast %"class.v8::internal::ReadOnlyPage"** %125 to i8*
  %130 = bitcast %"class.v8::internal::ReadOnlyPage"** %119 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %129, i8* align 8 %130, i64 %122, i1 false) #15
  %131 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %34, align 8
  br label %132

132:                                              ; preds = %128, %110
  %133 = phi %"class.v8::internal::ReadOnlyPage"** [ %119, %110 ], [ %131, %128 ]
  store i64 %126, i64* %32, align 8
  store i64 %118, i64* %31, align 8
  store i64 %115, i64* %33, align 8
  %134 = icmp eq %"class.v8::internal::ReadOnlyPage"** %133, null
  br i1 %134, label %137, label %135

135:                                              ; preds = %132
  %136 = bitcast %"class.v8::internal::ReadOnlyPage"** %133 to i8*
  call void @_ZdlPv(i8* %136) #16
  br label %137

137:                                              ; preds = %80, %132, %135
  %138 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %35, align 8
  %139 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %36, align 8
  %140 = icmp ult %"class.std::__1::unique_ptr.1142"* %138, %139
  br i1 %140, label %141, label %146

141:                                              ; preds = %137
  %142 = load i64, i64* %38, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %27, align 8
  %143 = bitcast %"class.std::__1::unique_ptr.1142"* %138 to i64*
  store i64 %142, i64* %143, align 8
  %144 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %138, i64 1
  %145 = ptrtoint %"class.std::__1::unique_ptr.1142"* %144 to i64
  store i64 %145, i64* %39, align 8
  br label %147

146:                                              ; preds = %137
  call void @_ZNSt3__16vectorINS_10unique_ptrIN2v813PageAllocator12SharedMemoryENS_14default_deleteIS4_EEEENS_9allocatorIS7_EEE21__push_back_slow_pathIS7_EEvOT_(%"class.std::__1::vector.1140"* %37, %"class.std::__1::unique_ptr.1142"* nonnull dereferenceable(8) %5) #15
  br label %147

147:                                              ; preds = %141, %146
  %148 = ptrtoint %"class.v8::internal::ReadOnlyPage"* %51 to i64
  %149 = trunc i64 %148 to i32
  %150 = load i32*, i32** %41, align 8
  %151 = load i32*, i32** %42, align 8
  %152 = icmp eq i32* %150, %151
  %153 = ptrtoint i32* %151 to i64
  br i1 %152, label %157, label %154

154:                                              ; preds = %147
  store i32 %149, i32* %150, align 4
  %155 = getelementptr inbounds i32, i32* %150, i64 1
  %156 = ptrtoint i32* %155 to i64
  store i64 %156, i64* %43, align 8
  br label %209

157:                                              ; preds = %147
  %158 = ptrtoint i32* %150 to i64
  %159 = load i64, i64* %44, align 8
  %160 = sub i64 %158, %159
  %161 = ashr exact i64 %160, 2
  %162 = add nsw i64 %161, 1
  %163 = icmp ugt i64 %162, 4611686018427387903
  br i1 %163, label %164, label %166

164:                                              ; preds = %157
  %165 = bitcast %"class.std::__1::vector.1133"* %40 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %165) #14
  unreachable

166:                                              ; preds = %157
  %167 = sub i64 %153, %159
  %168 = ashr exact i64 %167, 2
  %169 = icmp ult i64 %168, 2305843009213693951
  br i1 %169, label %170, label %178

170:                                              ; preds = %166
  %171 = ashr exact i64 %167, 1
  %172 = icmp ult i64 %171, %162
  %173 = select i1 %172, i64 %162, i64 %171
  %174 = icmp eq i64 %173, 0
  br i1 %174, label %183, label %175

175:                                              ; preds = %170
  %176 = icmp ugt i64 %173, 4611686018427387903
  br i1 %176, label %177, label %178

177:                                              ; preds = %175
  call void @abort() #14
  unreachable

178:                                              ; preds = %175, %166
  %179 = phi i64 [ %173, %175 ], [ 4611686018427387903, %166 ]
  %180 = shl i64 %179, 2
  %181 = call i8* @_Znwm(i64 %180) #16
  %182 = bitcast i8* %181 to i32*
  br label %183

183:                                              ; preds = %178, %170
  %184 = phi i64 [ %179, %178 ], [ 0, %170 ]
  %185 = phi i32* [ %182, %178 ], [ null, %170 ]
  %186 = getelementptr inbounds i32, i32* %185, i64 %161
  %187 = getelementptr inbounds i32, i32* %185, i64 %184
  %188 = ptrtoint i32* %187 to i64
  store i32 %149, i32* %186, align 4
  %189 = getelementptr inbounds i32, i32* %186, i64 1
  %190 = ptrtoint i32* %189 to i64
  %191 = load i32*, i32** %46, align 8
  %192 = load i64, i64* %43, align 8
  %193 = ptrtoint i32* %191 to i64
  %194 = sub i64 %192, %193
  %195 = ashr exact i64 %194, 2
  %196 = sub nsw i64 0, %195
  %197 = getelementptr inbounds i32, i32* %186, i64 %196
  %198 = ptrtoint i32* %197 to i64
  %199 = icmp sgt i64 %194, 0
  br i1 %199, label %200, label %204

200:                                              ; preds = %183
  %201 = bitcast i32* %197 to i8*
  %202 = bitcast i32* %191 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %201, i8* align 4 %202, i64 %194, i1 false) #15
  %203 = load i32*, i32** %46, align 8
  br label %204

204:                                              ; preds = %200, %183
  %205 = phi i32* [ %191, %183 ], [ %203, %200 ]
  store i64 %198, i64* %44, align 8
  store i64 %190, i64* %43, align 8
  store i64 %188, i64* %45, align 8
  %206 = icmp eq i32* %205, null
  br i1 %206, label %209, label %207

207:                                              ; preds = %204
  %208 = bitcast i32* %205 to i8*
  call void @_ZdlPv(i8* %208) #16
  br label %209

209:                                              ; preds = %154, %204, %207
  %210 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %51, i64 0, i32 0, i32 5
  %211 = load i64, i64* %210, align 8
  %212 = atomicrmw add i64* %47, i64 %211 seq_cst
  %213 = load %"class.v8::PageAllocator::SharedMemory"*, %"class.v8::PageAllocator::SharedMemory"** %27, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %27, align 8
  %214 = icmp eq %"class.v8::PageAllocator::SharedMemory"* %213, null
  br i1 %214, label %220, label %215

215:                                              ; preds = %209
  %216 = bitcast %"class.v8::PageAllocator::SharedMemory"* %213 to void (%"class.v8::PageAllocator::SharedMemory"*)***
  %217 = load void (%"class.v8::PageAllocator::SharedMemory"*)**, void (%"class.v8::PageAllocator::SharedMemory"*)*** %216, align 8
  %218 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemory"*)*, void (%"class.v8::PageAllocator::SharedMemory"*)** %217, i64 1
  %219 = load void (%"class.v8::PageAllocator::SharedMemory"*)*, void (%"class.v8::PageAllocator::SharedMemory"*)** %218, align 8
  call void %219(%"class.v8::PageAllocator::SharedMemory"* nonnull %213) #15
  br label %220

220:                                              ; preds = %209, %215
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %25) #15
  %221 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %50, i64 1
  %222 = icmp eq %"class.v8::internal::ReadOnlyPage"** %221, %21
  br i1 %222, label %48, label %49
}

declare %"class.v8::PageAllocator"* @_ZN2v88internal24GetPlatformPageAllocatorEv() local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal34PointerCompressedReadOnlyArtifacts22ReinstallReadOnlySpaceEPNS0_7IsolateE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"* nocapture readonly, %"class.v8::internal::Isolate"*) unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 2
  %4 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 2, i32 31
  %5 = load %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::ReadOnlySpace"** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 2, i32 85, i32 0, i32 0, i32 0
  %7 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %6, align 8
  %8 = bitcast %"class.v8::internal::ReadOnlySpace"* %5 to void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)***
  %9 = load void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)**, void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)*** %8, align 8
  %10 = getelementptr inbounds void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)*, void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)** %9, i64 6
  %11 = load void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)*, void (%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::MemoryAllocator"*)** %10, align 8
  tail call void %11(%"class.v8::internal::ReadOnlySpace"* %5, %"class.v8::internal::MemoryAllocator"* %7) #15
  %12 = ptrtoint %"class.v8::internal::Heap"* %3 to i64
  %13 = add i64 %12, -41416
  %14 = inttoptr i64 %13 to %"class.v8::internal::Isolate"*
  %15 = tail call %"class.v8::internal::SharedReadOnlySpace"* @_ZN2v88internal34PointerCompressedReadOnlyArtifacts19CreateReadOnlySpaceEPNS0_7IsolateE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, %"class.v8::internal::Isolate"* %14)
  tail call void @_ZN2v88internal4Heap20ReplaceReadOnlySpaceEPNS0_19SharedReadOnlySpaceE(%"class.v8::internal::Heap"* %3, %"class.v8::internal::SharedReadOnlySpace"* %15) #15
  %16 = tail call i8* @_Znwm(i64 48) #16
  %17 = bitcast i8* %16 to %"class.v8::internal::ReadOnlyHeap"*
  %18 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 3
  %19 = load %"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlyHeap"** %18, align 8
  %20 = load %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::ReadOnlySpace"** %4, align 8
  tail call void @_ZN2v88internal12ReadOnlyHeapC1EPS1_PNS0_13ReadOnlySpaceE(%"class.v8::internal::ReadOnlyHeap"* nonnull %17, %"class.v8::internal::ReadOnlyHeap"* %19, %"class.v8::internal::ReadOnlySpace"* %20) #15
  %21 = bitcast %"class.v8::internal::ReadOnlyHeap"** %18 to i8**
  store i8* %16, i8** %21, align 8
  ret void
}

declare void @_ZN2v88internal12ReadOnlyHeapC1EPS1_PNS0_13ReadOnlySpaceE(%"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlySpace"*) unnamed_addr #6

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void @_ZN2v88internal34PointerCompressedReadOnlyArtifacts31VerifyHeapAndSpaceRelationshipsEPNS0_7IsolateE(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"* nocapture, %"class.v8::internal::Isolate"* nocapture) unnamed_addr #2 align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpaceC2EPNS0_4HeapE(%"class.v8::internal::ReadOnlySpace"* nocapture, %"class.v8::internal::Heap"*) unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 0
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %4, align 8
  %5 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 2
  store i32 0, i32* %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = bitcast i64* %6 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %7, i8 0, i64 16, i1 false) #15
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %3, align 8
  %8 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 1
  store i8 0, i8* %8, align 8
  %9 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %9 seq_cst, align 8
  %10 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 1
  store i64 0, i64* %10, align 8
  %11 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %11 seq_cst, align 8
  %12 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3
  %13 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 6
  %14 = ptrtoint %"class.v8::internal::Heap"* %1 to i64
  %15 = add i64 %14, -41416
  %16 = inttoptr i64 %15 to %"class.v8::internal::Isolate"*
  %17 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %16, i64 0, i32 63
  %18 = bitcast %"class.std::__1::vector"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %18, i8 0, i64 40, i1 false)
  %19 = load i8, i8* %17, align 1, !range !3
  store i8 %19, i8* %13, align 8
  %20 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 7
  store i64 0, i64* %20, align 8
  %21 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 8
  %22 = tail call i64 @_ZN2v88internal17MemoryChunkLayout30AllocatableMemoryInMemoryChunkENS0_15AllocationSpaceE(i32 0) #15
  store i64 %22, i64* %21, align 8
  ret void
}

declare i64 @_ZN2v88internal17MemoryChunkLayout30AllocatableMemoryInMemoryChunkENS0_15AllocationSpaceE(i32) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpaceD2Ev(%"class.v8::internal::ReadOnlySpace"* nocapture) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %4 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %3, align 8
  %5 = icmp eq %"class.v8::internal::ReadOnlyPage"** %4, null
  br i1 %5, label %11, label %6

6:                                                ; preds = %1
  %7 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %4 to i64
  %8 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %9 = bitcast %"class.v8::internal::ReadOnlyPage"*** %8 to i64*
  store i64 %7, i64* %9, align 8
  %10 = bitcast %"class.v8::internal::ReadOnlyPage"** %4 to i8*
  tail call void @_ZdlPv(i8* %10) #16
  br label %11

11:                                               ; preds = %1, %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpaceD0Ev(%"class.v8::internal::ReadOnlySpace"*) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %4 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %3, align 8
  %5 = icmp eq %"class.v8::internal::ReadOnlyPage"** %4, null
  br i1 %5, label %11, label %6

6:                                                ; preds = %1
  %7 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %4 to i64
  %8 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %9 = bitcast %"class.v8::internal::ReadOnlyPage"*** %8 to i64*
  store i64 %7, i64* %9, align 8
  %10 = bitcast %"class.v8::internal::ReadOnlyPage"** %4 to i8*
  tail call void @_ZdlPv(i8* %10) #16
  br label %11

11:                                               ; preds = %1, %6
  %12 = bitcast %"class.v8::internal::ReadOnlySpace"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %12) #15
  ret void
}

; Function Attrs: nounwind
declare void @_ZN2v88internal8MalloceddlEPv(i8*) local_unnamed_addr #8

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal19SharedReadOnlySpace8TearDownEPNS0_15MemoryAllocatorE(%"class.v8::internal::SharedReadOnlySpace"* nocapture, %"class.v8::internal::MemoryAllocator"* nocapture readnone) unnamed_addr #9 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3
  %4 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 1
  %5 = bitcast %"class.v8::internal::ReadOnlyPage"*** %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = bitcast %"class.std::__1::vector"* %3 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = icmp eq i64 %6, %8
  br i1 %9, label %12, label %10

10:                                               ; preds = %2
  %11 = inttoptr i64 %8 to %"class.v8::internal::ReadOnlyPage"**
  store %"class.v8::internal::ReadOnlyPage"** %11, %"class.v8::internal::ReadOnlyPage"*** %4, align 8
  br label %12

12:                                               ; preds = %2, %10
  %13 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %13 seq_cst, align 8
  %14 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 1
  store i64 0, i64* %14, align 8
  %15 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %15 seq_cst, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace8TearDownEPNS0_15MemoryAllocatorE(%"class.v8::internal::ReadOnlySpace"* nocapture, %"class.v8::internal::MemoryAllocator"*) unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3
  %4 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %3, i64 0, i32 0, i32 0
  %5 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %7 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %6, align 8
  %8 = icmp eq %"class.v8::internal::ReadOnlyPage"** %5, %7
  br i1 %8, label %9, label %27

9:                                                ; preds = %2
  %10 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %5 to i64
  %11 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %7 to i64
  br label %17

12:                                               ; preds = %27
  %13 = bitcast %"class.v8::internal::ReadOnlyPage"*** %6 to i64*
  %14 = load i64, i64* %13, align 8
  %15 = bitcast %"class.std::__1::vector"* %3 to i64*
  %16 = load i64, i64* %15, align 8
  br label %17

17:                                               ; preds = %9, %12
  %18 = phi i64 [ %16, %12 ], [ %10, %9 ]
  %19 = phi i64 [ %14, %12 ], [ %11, %9 ]
  %20 = icmp eq i64 %19, %18
  br i1 %20, label %23, label %21

21:                                               ; preds = %17
  %22 = inttoptr i64 %18 to %"class.v8::internal::ReadOnlyPage"**
  store %"class.v8::internal::ReadOnlyPage"** %22, %"class.v8::internal::ReadOnlyPage"*** %6, align 8
  br label %23

23:                                               ; preds = %17, %21
  %24 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %24 seq_cst, align 8
  %25 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 1
  store i64 0, i64* %25, align 8
  %26 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %26 seq_cst, align 8
  ret void

27:                                               ; preds = %2, %27
  %28 = phi %"class.v8::internal::ReadOnlyPage"** [ %30, %27 ], [ %5, %2 ]
  %29 = load %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %28, align 8
  tail call void @_ZN2v88internal15MemoryAllocator16FreeReadOnlyPageEPNS0_12ReadOnlyPageE(%"class.v8::internal::MemoryAllocator"* %1, %"class.v8::internal::ReadOnlyPage"* %29) #15
  %30 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %28, i64 1
  %31 = icmp eq %"class.v8::internal::ReadOnlyPage"** %30, %7
  br i1 %31, label %12, label %27
}

declare void @_ZN2v88internal15MemoryAllocator16FreeReadOnlyPageEPNS0_12ReadOnlyPageE(%"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::ReadOnlyPage"*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace28DetachPagesAndAddToArtifactsENSt3__110shared_ptrINS0_17ReadOnlyArtifactsEEE(%"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::ReadOnlyArtifacts"*, %"class.std::__1::__shared_weak_count"*) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %5 = bitcast %"class.v8::internal::Heap"** %4 to i64*
  %6 = load i64, i64* %5, align 8
  tail call void @_ZN2v88internal13ReadOnlySpace4SealENS1_8SealModeE(%"class.v8::internal::ReadOnlySpace"* %0, i32 1)
  %7 = add i64 %6, -41416
  %8 = inttoptr i64 %7 to %"class.v8::internal::Isolate"*
  %9 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3
  %10 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2
  %11 = bitcast %"class.v8::internal::ReadOnlyArtifacts"* %1 to void (%"class.v8::internal::ReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)***
  %12 = load void (%"class.v8::internal::ReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)**, void (%"class.v8::internal::ReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)*** %11, align 8
  %13 = getelementptr inbounds void (%"class.v8::internal::ReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)*, void (%"class.v8::internal::ReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)** %12, i64 2
  %14 = load void (%"class.v8::internal::ReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)*, void (%"class.v8::internal::ReadOnlyArtifacts"*, %"class.v8::internal::Isolate"*, %"class.std::__1::vector"*, %"class.v8::internal::AllocationStats"*)** %13, align 8
  tail call void %14(%"class.v8::internal::ReadOnlyArtifacts"* %1, %"class.v8::internal::Isolate"* %8, %"class.std::__1::vector"* dereferenceable(24) %9, %"class.v8::internal::AllocationStats"* dereferenceable(24) %10) #15
  %15 = icmp eq %"class.std::__1::__shared_weak_count"* %2, null
  br i1 %15, label %26, label %16

16:                                               ; preds = %3
  %17 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %2, i64 0, i32 0, i32 1
  %18 = atomicrmw add i64* %17, i64 -1 acq_rel
  %19 = icmp eq i64 %18, 0
  br i1 %19, label %20, label %26

20:                                               ; preds = %16
  %21 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %2, i64 0, i32 0
  %22 = bitcast %"class.std::__1::__shared_weak_count"* %2 to void (%"class.std::__1::__shared_count"*)***
  %23 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %22, align 8
  %24 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %23, i64 2
  %25 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %24, align 8
  tail call void %25(%"class.std::__1::__shared_count"* %21) #15
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %2) #15
  br label %26

26:                                               ; preds = %3, %16, %20
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace4SealENS1_8SealModeE(%"class.v8::internal::ReadOnlySpace"* nocapture, i32) local_unnamed_addr #0 align 2 {
  tail call void @_ZN2v88internal13ReadOnlySpace24FreeLinearAllocationAreaEv(%"class.v8::internal::ReadOnlySpace"* %0)
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 1
  store i8 1, i8* %3, align 8
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %5 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %5, i64 0, i32 85, i32 0, i32 0, i32 0
  %7 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %6, align 8
  %8 = icmp eq i32 %1, 2
  br i1 %8, label %36, label %9

9:                                                ; preds = %2
  store %"class.v8::internal::Heap"* null, %"class.v8::internal::Heap"** %4, align 8
  %10 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %11 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %10, align 8
  %12 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %13 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %12, align 8
  %14 = icmp eq %"class.v8::internal::ReadOnlyPage"** %11, %13
  br i1 %14, label %36, label %15

15:                                               ; preds = %9
  %16 = icmp eq i32 %1, 1
  br i1 %16, label %17, label %27

17:                                               ; preds = %15, %17
  %18 = phi %"class.v8::internal::ReadOnlyPage"** [ %25, %17 ], [ %11, %15 ]
  %19 = load %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %18, align 8
  %20 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %19, i64 0, i32 0
  tail call void @_ZN2v88internal15MemoryAllocator16UnregisterMemoryEPNS0_16BasicMemoryChunkENS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"* %7, %"class.v8::internal::BasicMemoryChunk"* %20, i32 0) #15
  %21 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %19, i64 0, i32 0, i32 2
  store %"class.v8::internal::Heap"* null, %"class.v8::internal::Heap"** %21, align 8
  %22 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %19, i64 0, i32 0, i32 8
  %23 = bitcast %"struct.std::__1::atomic.601"* %22 to i64*
  store atomic i64 0, i64* %23 seq_cst, align 8
  %24 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %19, i64 0, i32 0, i32 9
  tail call void @_ZN2v88internal13VirtualMemory5ResetEv(%"class.v8::internal::VirtualMemory"* %24) #15
  %25 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %18, i64 1
  %26 = icmp eq %"class.v8::internal::ReadOnlyPage"** %25, %13
  br i1 %26, label %36, label %17

27:                                               ; preds = %15, %27
  %28 = phi %"class.v8::internal::ReadOnlyPage"** [ %34, %27 ], [ %11, %15 ]
  %29 = load %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %28, align 8
  %30 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %29, i64 0, i32 0, i32 2
  store %"class.v8::internal::Heap"* null, %"class.v8::internal::Heap"** %30, align 8
  %31 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %29, i64 0, i32 0, i32 8
  %32 = bitcast %"struct.std::__1::atomic.601"* %31 to i64*
  store atomic i64 0, i64* %32 seq_cst, align 8
  %33 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %29, i64 0, i32 0, i32 9
  tail call void @_ZN2v88internal13VirtualMemory5ResetEv(%"class.v8::internal::VirtualMemory"* %33) #15
  %34 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %28, i64 1
  %35 = icmp eq %"class.v8::internal::ReadOnlyPage"** %34, %13
  br i1 %35, label %36, label %27

36:                                               ; preds = %27, %17, %9, %2
  %37 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %38 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %37, align 8
  %39 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %40 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %39, align 8
  %41 = icmp eq %"class.v8::internal::ReadOnlyPage"** %38, %40
  br i1 %41, label %57, label %42

42:                                               ; preds = %36
  %43 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %7, i64 0, i32 1
  br label %46

44:                                               ; preds = %46
  %45 = icmp eq %"class.v8::internal::ReadOnlyPage"** %55, %40
  br i1 %45, label %57, label %46

46:                                               ; preds = %44, %42
  %47 = phi %"class.v8::internal::ReadOnlyPage"** [ %38, %42 ], [ %55, %44 ]
  %48 = bitcast %"class.v8::internal::ReadOnlyPage"** %47 to %"class.v8::internal::BasicMemoryChunk"**
  %49 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %48, align 8
  %50 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %43, align 8
  %51 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %49, i64 0, i32 0
  %52 = load i64, i64* %51, align 8
  %53 = bitcast %"class.v8::internal::BasicMemoryChunk"* %49 to i8*
  %54 = tail call zeroext i1 @_ZN2v88internal14SetPermissionsEPNS_13PageAllocatorEPvmNS1_10PermissionE(%"class.v8::PageAllocator"* %50, i8* %53, i64 %52, i32 1) #15
  %55 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 1
  br i1 %54, label %44, label %56, !prof !2

56:                                               ; preds = %46
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.6, i64 0, i64 0)) #14
  unreachable

57:                                               ; preds = %44, %36
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal12ReadOnlyPage21MakeHeaderRelocatableEv(%"class.v8::internal::ReadOnlyPage"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0, i32 2
  store %"class.v8::internal::Heap"* null, %"class.v8::internal::Heap"** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0, i32 8
  %4 = bitcast %"struct.std::__1::atomic.601"* %3 to i64*
  store atomic i64 0, i64* %4 seq_cst, align 8
  %5 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0, i32 9
  tail call void @_ZN2v88internal13VirtualMemory5ResetEv(%"class.v8::internal::VirtualMemory"* %5) #15
  ret void
}

declare void @_ZN2v88internal13VirtualMemory5ResetEv(%"class.v8::internal::VirtualMemory"*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace22SetPermissionsForPagesEPNS0_15MemoryAllocatorENS_13PageAllocator10PermissionE(%"class.v8::internal::ReadOnlySpace"* nocapture readonly, %"class.v8::internal::MemoryAllocator"* nocapture readonly, i32) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %5 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %7 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %6, align 8
  %8 = icmp eq %"class.v8::internal::ReadOnlyPage"** %5, %7
  br i1 %8, label %13, label %9

9:                                                ; preds = %3
  %10 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %1, i64 0, i32 1
  br label %14

11:                                               ; preds = %14
  %12 = icmp eq %"class.v8::internal::ReadOnlyPage"** %23, %7
  br i1 %12, label %13, label %14

13:                                               ; preds = %11, %3
  ret void

14:                                               ; preds = %9, %11
  %15 = phi %"class.v8::internal::ReadOnlyPage"** [ %5, %9 ], [ %23, %11 ]
  %16 = bitcast %"class.v8::internal::ReadOnlyPage"** %15 to %"class.v8::internal::BasicMemoryChunk"**
  %17 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %16, align 8
  %18 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %10, align 8
  %19 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %17, i64 0, i32 0
  %20 = load i64, i64* %19, align 8
  %21 = bitcast %"class.v8::internal::BasicMemoryChunk"* %17 to i8*
  %22 = tail call zeroext i1 @_ZN2v88internal14SetPermissionsEPNS_13PageAllocatorEPvmNS1_10PermissionE(%"class.v8::PageAllocator"* %18, i8* %21, i64 %20, i32 %2) #15
  %23 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %15, i64 1
  br i1 %22, label %11, label %24, !prof !2

24:                                               ; preds = %14
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.6, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace36RepairFreeSpacesAfterDeserializationEv(%"class.v8::internal::ReadOnlySpace"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %3 = load i64, i64* %2, align 8
  %4 = icmp eq i64 %3, 0
  br i1 %4, label %20, label %5

5:                                                ; preds = %1
  %6 = add i64 %3, -1
  %7 = and i64 %6, -262144
  %8 = inttoptr i64 %7 to %"class.v8::internal::BasicMemoryChunk"*
  %9 = sub i64 %3, %7
  %10 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %8, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %11 = load atomic i64, i64* %10 monotonic, align 8
  %12 = icmp sgt i64 %9, %11
  br i1 %12, label %13, label %20

13:                                               ; preds = %5, %17
  %14 = phi i64 [ %18, %17 ], [ %11, %5 ]
  %15 = cmpxchg weak i64* %10, i64 %14, i64 %9 acq_rel monotonic
  %16 = extractvalue { i64, i1 } %15, 1
  br i1 %16, label %20, label %17

17:                                               ; preds = %13
  %18 = extractvalue { i64, i1 } %15, 0
  %19 = icmp sgt i64 %9, %18
  br i1 %19, label %13, label %20

20:                                               ; preds = %13, %17, %1, %5
  %21 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %22 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %21, align 8
  %23 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %24 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %23, align 8
  %25 = icmp eq %"class.v8::internal::ReadOnlyPage"** %22, %24
  br i1 %25, label %28, label %26

26:                                               ; preds = %20
  %27 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  br label %29

28:                                               ; preds = %45, %20
  ret void

29:                                               ; preds = %26, %45
  %30 = phi %"class.v8::internal::ReadOnlyPage"** [ %22, %26 ], [ %46, %45 ]
  %31 = bitcast %"class.v8::internal::ReadOnlyPage"** %30 to %"class.v8::internal::BasicMemoryChunk"**
  %32 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %31, align 8
  %33 = ptrtoint %"class.v8::internal::BasicMemoryChunk"* %32 to i64
  %34 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %32, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %35 = load atomic i64, i64* %34 seq_cst, align 8
  %36 = add i64 %35, %33
  %37 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %32, i64 0, i32 4
  %38 = load i64, i64* %37, align 8
  %39 = icmp ugt i64 %38, %36
  br i1 %39, label %40, label %45

40:                                               ; preds = %29
  %41 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %27, align 8
  %42 = sub i64 %38, %36
  %43 = trunc i64 %42 to i32
  %44 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %41, i64 %36, i32 %43, i32 1) #15
  br label %45

45:                                               ; preds = %40, %29
  %46 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %30, i64 1
  %47 = icmp eq %"class.v8::internal::ReadOnlyPage"** %46, %24
  br i1 %47, label %28, label %29
}

declare i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"*, i64, i32, i32) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace26ClearStringPaddingIfNeededEv(%"class.v8::internal::ReadOnlySpace"*) local_unnamed_addr #0 align 2 {
  %2 = alloca %"class.v8::internal::ReadOnlyHeapObjectIterator", align 8
  %3 = alloca %"class.v8::internal::SeqOneByteString", align 8
  %4 = alloca %"class.v8::internal::SeqTwoByteString", align 8
  %5 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 6
  %6 = load i8, i8* %5, align 8, !range !3
  %7 = icmp eq i8 %6, 0
  br i1 %7, label %8, label %81

8:                                                ; preds = %1
  %9 = bitcast %"class.v8::internal::ReadOnlyHeapObjectIterator"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %9) #15
  call void @_ZN2v88internal26ReadOnlyHeapObjectIteratorC1EPNS0_13ReadOnlySpaceE(%"class.v8::internal::ReadOnlyHeapObjectIterator"* nonnull %2, %"class.v8::internal::ReadOnlySpace"* %0) #15
  %10 = call i64 @_ZN2v88internal26ReadOnlyHeapObjectIterator4NextEv(%"class.v8::internal::ReadOnlyHeapObjectIterator"* nonnull %2) #15
  %11 = trunc i64 %10 to i32
  %12 = icmp eq i32 %11, 0
  br i1 %12, label %18, label %13

13:                                               ; preds = %8
  %14 = bitcast %"class.v8::internal::SeqOneByteString"* %3 to i8*
  %15 = getelementptr inbounds %"class.v8::internal::SeqOneByteString", %"class.v8::internal::SeqOneByteString"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %16 = bitcast %"class.v8::internal::SeqTwoByteString"* %4 to i8*
  %17 = getelementptr inbounds %"class.v8::internal::SeqTwoByteString", %"class.v8::internal::SeqTwoByteString"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %19

18:                                               ; preds = %77, %8
  store i8 1, i8* %5, align 8
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %9) #15
  br label %81

19:                                               ; preds = %13, %77
  %20 = phi i64 [ %10, %13 ], [ %78, %77 ]
  %21 = and i64 %20, -4294967296
  %22 = add i64 %20, -1
  %23 = inttoptr i64 %22 to i32*
  %24 = load atomic i32, i32* %23 monotonic, align 4
  %25 = zext i32 %24 to i64
  %26 = or i64 %21, %25
  %27 = add i64 %26, 7
  %28 = inttoptr i64 %27 to i16*
  %29 = load atomic i16, i16* %28 monotonic, align 2
  %30 = icmp ult i16 %29, 64
  br i1 %30, label %31, label %50

31:                                               ; preds = %19
  %32 = load atomic i32, i32* %23 monotonic, align 4
  %33 = zext i32 %32 to i64
  %34 = or i64 %21, %33
  %35 = add i64 %34, 7
  %36 = inttoptr i64 %35 to i16*
  %37 = load atomic i16, i16* %36 monotonic, align 2
  %38 = and i16 %37, 7
  %39 = icmp eq i16 %38, 0
  br i1 %39, label %40, label %50

40:                                               ; preds = %31
  %41 = load atomic i32, i32* %23 monotonic, align 4
  %42 = zext i32 %41 to i64
  %43 = or i64 %21, %42
  %44 = add i64 %43, 7
  %45 = inttoptr i64 %44 to i16*
  %46 = load atomic i16, i16* %45 monotonic, align 2
  %47 = and i16 %46, 8
  %48 = icmp eq i16 %47, 0
  br i1 %48, label %50, label %49

49:                                               ; preds = %40
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %14) #15
  store i64 %20, i64* %15, align 8
  call void @_ZN2v88internal16SeqOneByteString13clear_paddingEv(%"class.v8::internal::SeqOneByteString"* nonnull %3) #15
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %14) #15
  br label %77

50:                                               ; preds = %40, %31, %19
  %51 = load atomic i32, i32* %23 monotonic, align 4
  %52 = zext i32 %51 to i64
  %53 = or i64 %21, %52
  %54 = add i64 %53, 7
  %55 = inttoptr i64 %54 to i16*
  %56 = load atomic i16, i16* %55 monotonic, align 2
  %57 = icmp ult i16 %56, 64
  br i1 %57, label %58, label %77

58:                                               ; preds = %50
  %59 = load atomic i32, i32* %23 monotonic, align 4
  %60 = zext i32 %59 to i64
  %61 = or i64 %21, %60
  %62 = add i64 %61, 7
  %63 = inttoptr i64 %62 to i16*
  %64 = load atomic i16, i16* %63 monotonic, align 2
  %65 = and i16 %64, 7
  %66 = icmp eq i16 %65, 0
  br i1 %66, label %67, label %77

67:                                               ; preds = %58
  %68 = load atomic i32, i32* %23 monotonic, align 4
  %69 = zext i32 %68 to i64
  %70 = or i64 %21, %69
  %71 = add i64 %70, 7
  %72 = inttoptr i64 %71 to i16*
  %73 = load atomic i16, i16* %72 monotonic, align 2
  %74 = and i16 %73, 8
  %75 = icmp eq i16 %74, 0
  br i1 %75, label %76, label %77

76:                                               ; preds = %67
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %16) #15
  store i64 %20, i64* %17, align 8
  call void @_ZN2v88internal16SeqTwoByteString13clear_paddingEv(%"class.v8::internal::SeqTwoByteString"* nonnull %4) #15
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %16) #15
  br label %77

77:                                               ; preds = %58, %50, %49, %76, %67
  %78 = call i64 @_ZN2v88internal26ReadOnlyHeapObjectIterator4NextEv(%"class.v8::internal::ReadOnlyHeapObjectIterator"* nonnull %2) #15
  %79 = trunc i64 %78 to i32
  %80 = icmp eq i32 %79, 0
  br i1 %80, label %18, label %19

81:                                               ; preds = %1, %18
  ret void
}

declare void @_ZN2v88internal26ReadOnlyHeapObjectIteratorC1EPNS0_13ReadOnlySpaceE(%"class.v8::internal::ReadOnlyHeapObjectIterator"*, %"class.v8::internal::ReadOnlySpace"*) unnamed_addr #6

declare i64 @_ZN2v88internal26ReadOnlyHeapObjectIterator4NextEv(%"class.v8::internal::ReadOnlyHeapObjectIterator"*) local_unnamed_addr #6

declare void @_ZN2v88internal16SeqOneByteString13clear_paddingEv(%"class.v8::internal::SeqOneByteString"*) local_unnamed_addr #6

declare void @_ZN2v88internal16SeqTwoByteString13clear_paddingEv(%"class.v8::internal::SeqTwoByteString"*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace24FreeLinearAllocationAreaEv(%"class.v8::internal::ReadOnlySpace"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %3 = load i64, i64* %2, align 8
  %4 = icmp eq i64 %3, 0
  br i1 %4, label %150, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %7 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %6, align 8
  %8 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %7, i64 -1
  %9 = bitcast %"class.v8::internal::ReadOnlyPage"** %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %12 = add i64 %10, 272
  %13 = sub i64 %3, %10
  %14 = trunc i64 %13 to i32
  %15 = lshr i32 %14, 2
  %16 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 5
  %17 = load i64, i64* %16, align 8
  %18 = sub i64 %17, %10
  %19 = trunc i64 %18 to i32
  %20 = lshr i32 %19, 2
  %21 = icmp ult i32 %15, %20
  br i1 %21, label %22, label %124

22:                                               ; preds = %5
  %23 = add nsw i32 %20, -1
  %24 = lshr i32 %14, 7
  %25 = and i32 %15, 31
  %26 = shl i32 1, %25
  %27 = lshr i32 %23, 5
  %28 = and i32 %23, 31
  %29 = shl i32 1, %28
  %30 = icmp eq i32 %24, %27
  br i1 %30, label %104, label %31

31:                                               ; preds = %22
  %32 = sub i32 0, %26
  %33 = inttoptr i64 %12 to i32*
  %34 = zext i32 %24 to i64
  %35 = getelementptr inbounds i32, i32* %33, i64 %34
  %36 = load atomic i32, i32* %35 monotonic, align 4
  %37 = add i32 %26, -1
  br label %38

38:                                               ; preds = %42, %31
  %39 = phi i32 [ %36, %31 ], [ %45, %42 ]
  %40 = and i32 %39, %32
  %41 = icmp eq i32 %40, 0
  br i1 %41, label %47, label %42

42:                                               ; preds = %38
  %43 = and i32 %39, %37
  %44 = cmpxchg volatile i32* %35, i32 %39, i32 %43 release monotonic
  %45 = extractvalue { i32, i1 } %44, 0
  %46 = extractvalue { i32, i1 } %44, 1
  br i1 %46, label %47, label %38

47:                                               ; preds = %42, %38
  %48 = add nuw nsw i32 %24, 1
  %49 = icmp ult i32 %48, %27
  br i1 %49, label %50, label %88

50:                                               ; preds = %47
  %51 = zext i32 %48 to i64
  %52 = xor i32 %24, 7
  %53 = add nuw nsw i32 %27, %52
  %54 = add nsw i32 %27, -2
  %55 = sub nsw i32 %54, %24
  %56 = and i32 %53, 7
  %57 = icmp eq i32 %56, 0
  br i1 %57, label %65, label %58

58:                                               ; preds = %50, %58
  %59 = phi i64 [ %62, %58 ], [ %51, %50 ]
  %60 = phi i32 [ %63, %58 ], [ %56, %50 ]
  %61 = getelementptr inbounds i32, i32* %33, i64 %59
  store atomic volatile i32 0, i32* %61 monotonic, align 4
  %62 = add nuw nsw i64 %59, 1
  %63 = add i32 %60, -1
  %64 = icmp eq i32 %63, 0
  br i1 %64, label %65, label %58, !llvm.loop !5

65:                                               ; preds = %58, %50
  %66 = phi i64 [ %51, %50 ], [ %62, %58 ]
  %67 = icmp ult i32 %55, 7
  br i1 %67, label %88, label %68

68:                                               ; preds = %65, %68
  %69 = phi i64 [ %85, %68 ], [ %66, %65 ]
  %70 = getelementptr inbounds i32, i32* %33, i64 %69
  store atomic volatile i32 0, i32* %70 monotonic, align 4
  %71 = add nuw nsw i64 %69, 1
  %72 = getelementptr inbounds i32, i32* %33, i64 %71
  store atomic volatile i32 0, i32* %72 monotonic, align 4
  %73 = add nuw nsw i64 %69, 2
  %74 = getelementptr inbounds i32, i32* %33, i64 %73
  store atomic volatile i32 0, i32* %74 monotonic, align 4
  %75 = add nuw nsw i64 %69, 3
  %76 = getelementptr inbounds i32, i32* %33, i64 %75
  store atomic volatile i32 0, i32* %76 monotonic, align 4
  %77 = add nuw nsw i64 %69, 4
  %78 = getelementptr inbounds i32, i32* %33, i64 %77
  store atomic volatile i32 0, i32* %78 monotonic, align 4
  %79 = add nuw nsw i64 %69, 5
  %80 = getelementptr inbounds i32, i32* %33, i64 %79
  store atomic volatile i32 0, i32* %80 monotonic, align 4
  %81 = add nuw nsw i64 %69, 6
  %82 = getelementptr inbounds i32, i32* %33, i64 %81
  store atomic volatile i32 0, i32* %82 monotonic, align 4
  %83 = add nuw nsw i64 %69, 7
  %84 = getelementptr inbounds i32, i32* %33, i64 %83
  store atomic volatile i32 0, i32* %84 monotonic, align 4
  %85 = add nuw nsw i64 %69, 8
  %86 = trunc i64 %85 to i32
  %87 = icmp eq i32 %27, %86
  br i1 %87, label %88, label %68

88:                                               ; preds = %65, %68, %47
  %89 = add i32 %29, -1
  %90 = or i32 %89, %29
  %91 = zext i32 %27 to i64
  %92 = getelementptr inbounds i32, i32* %33, i64 %91
  %93 = load atomic i32, i32* %92 monotonic, align 4
  %94 = xor i32 %90, -1
  br label %95

95:                                               ; preds = %99, %88
  %96 = phi i32 [ %93, %88 ], [ %102, %99 ]
  %97 = and i32 %96, %90
  %98 = icmp eq i32 %97, 0
  br i1 %98, label %121, label %99

99:                                               ; preds = %95
  %100 = and i32 %96, %94
  %101 = cmpxchg volatile i32* %92, i32 %96, i32 %100 release monotonic
  %102 = extractvalue { i32, i1 } %101, 0
  %103 = extractvalue { i32, i1 } %101, 1
  br i1 %103, label %121, label %95

104:                                              ; preds = %22
  %105 = sub i32 %29, %26
  %106 = or i32 %105, %29
  %107 = inttoptr i64 %12 to i32*
  %108 = zext i32 %24 to i64
  %109 = getelementptr inbounds i32, i32* %107, i64 %108
  %110 = load atomic i32, i32* %109 monotonic, align 4
  %111 = xor i32 %106, -1
  br label %112

112:                                              ; preds = %116, %104
  %113 = phi i32 [ %110, %104 ], [ %119, %116 ]
  %114 = and i32 %113, %106
  %115 = icmp eq i32 %114, 0
  br i1 %115, label %121, label %116

116:                                              ; preds = %112
  %117 = and i32 %113, %111
  %118 = cmpxchg volatile i32* %109, i32 %113, i32 %117 release monotonic
  %119 = extractvalue { i32, i1 } %118, 0
  %120 = extractvalue { i32, i1 } %118, 1
  br i1 %120, label %121, label %112

121:                                              ; preds = %99, %95, %116, %112
  fence seq_cst
  %122 = load i64, i64* %2, align 8
  %123 = load i64, i64* %16, align 8
  br label %124

124:                                              ; preds = %5, %121
  %125 = phi i64 [ %17, %5 ], [ %123, %121 ]
  %126 = phi i64 [ %3, %5 ], [ %122, %121 ]
  %127 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %11, align 8
  %128 = sub i64 %125, %126
  %129 = trunc i64 %128 to i32
  %130 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %127, i64 %126, i32 %129, i32 1) #15
  %131 = load i64, i64* %2, align 8
  %132 = icmp eq i64 %131, 0
  br i1 %132, label %148, label %133

133:                                              ; preds = %124
  %134 = add i64 %131, -1
  %135 = and i64 %134, -262144
  %136 = inttoptr i64 %135 to %"class.v8::internal::BasicMemoryChunk"*
  %137 = sub i64 %131, %135
  %138 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %136, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %139 = load atomic i64, i64* %138 monotonic, align 8
  %140 = icmp sgt i64 %137, %139
  br i1 %140, label %141, label %148

141:                                              ; preds = %133, %145
  %142 = phi i64 [ %146, %145 ], [ %139, %133 ]
  %143 = cmpxchg weak i64* %138, i64 %142, i64 %137 acq_rel monotonic
  %144 = extractvalue { i64, i1 } %143, 1
  br i1 %144, label %148, label %145

145:                                              ; preds = %141
  %146 = extractvalue { i64, i1 } %143, 0
  %147 = icmp sgt i64 %137, %146
  br i1 %147, label %141, label %148

148:                                              ; preds = %141, %145, %124, %133
  %149 = bitcast i64* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %149, i8 0, i64 16, i1 false)
  br label %150

150:                                              ; preds = %1, %148
  ret void
}

declare void @_ZN2v88internal15MemoryAllocator16UnregisterMemoryEPNS0_16BasicMemoryChunkENS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::BasicMemoryChunk"*, i32) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace6UnsealEv(%"class.v8::internal::ReadOnlySpace"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %3 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %2, align 8
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %5 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %4, align 8
  %6 = icmp eq %"class.v8::internal::ReadOnlyPage"** %3, %5
  br i1 %6, label %26, label %7

7:                                                ; preds = %1
  %8 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %9 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %9, i64 0, i32 85, i32 0, i32 0, i32 0
  %11 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %10, align 8
  %12 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %11, i64 0, i32 1
  br label %15

13:                                               ; preds = %15
  %14 = icmp eq %"class.v8::internal::ReadOnlyPage"** %24, %5
  br i1 %14, label %26, label %15

15:                                               ; preds = %13, %7
  %16 = phi %"class.v8::internal::ReadOnlyPage"** [ %3, %7 ], [ %24, %13 ]
  %17 = bitcast %"class.v8::internal::ReadOnlyPage"** %16 to %"class.v8::internal::BasicMemoryChunk"**
  %18 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %17, align 8
  %19 = load %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"** %12, align 8
  %20 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %18, i64 0, i32 0
  %21 = load i64, i64* %20, align 8
  %22 = bitcast %"class.v8::internal::BasicMemoryChunk"* %18 to i8*
  %23 = tail call zeroext i1 @_ZN2v88internal14SetPermissionsEPNS_13PageAllocatorEPvmNS1_10PermissionE(%"class.v8::PageAllocator"* %19, i8* %22, i64 %21, i32 2) #15
  %24 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %16, i64 1
  br i1 %23, label %13, label %25, !prof !2

25:                                               ; preds = %15
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.6, i64 0, i64 0)) #14
  unreachable

26:                                               ; preds = %13, %1
  %27 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 1
  store i8 0, i8* %27, align 8
  ret void
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden zeroext i1 @_ZN2v88internal13ReadOnlySpace12ContainsSlowEm(%"class.v8::internal::ReadOnlySpace"* nocapture readonly, i64) local_unnamed_addr #10 align 2 {
  %3 = and i64 %1, -262144
  %4 = inttoptr i64 %3 to %"class.v8::internal::BasicMemoryChunk"*
  %5 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %6 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %8 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %7, align 8
  %9 = icmp eq %"class.v8::internal::ReadOnlyPage"** %6, %8
  br i1 %9, label %18, label %12

10:                                               ; preds = %12
  %11 = icmp eq %"class.v8::internal::ReadOnlyPage"** %17, %8
  br i1 %11, label %18, label %12

12:                                               ; preds = %2, %10
  %13 = phi %"class.v8::internal::ReadOnlyPage"** [ %17, %10 ], [ %6, %2 ]
  %14 = bitcast %"class.v8::internal::ReadOnlyPage"** %13 to %"class.v8::internal::BasicMemoryChunk"**
  %15 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %14, align 8
  %16 = icmp eq %"class.v8::internal::BasicMemoryChunk"* %15, %4
  %17 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %13, i64 1
  br i1 %16, label %18, label %10

18:                                               ; preds = %10, %12, %2
  %19 = phi i1 [ false, %2 ], [ true, %12 ], [ false, %10 ]
  ret i1 %19
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal13ReadOnlySpace23CommittedPhysicalMemoryEv(%"class.v8::internal::ReadOnlySpace"*) unnamed_addr #0 align 2 {
  %2 = tail call zeroext i1 @_ZN2v84base2OS14HasLazyCommitsEv() #15
  br i1 %2, label %9, label %3

3:                                                ; preds = %1
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0
  %5 = bitcast %"class.v8::internal::ReadOnlySpace"* %0 to i64 (%"class.v8::internal::BaseSpace"*)***
  %6 = load i64 (%"class.v8::internal::BaseSpace"*)**, i64 (%"class.v8::internal::BaseSpace"*)*** %5, align 8
  %7 = load i64 (%"class.v8::internal::BaseSpace"*)*, i64 (%"class.v8::internal::BaseSpace"*)** %6, align 8
  %8 = tail call i64 %7(%"class.v8::internal::BaseSpace"* %4) #15
  br label %116

9:                                                ; preds = %1
  %10 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %11 = load i64, i64* %10, align 8
  %12 = icmp eq i64 %11, 0
  br i1 %12, label %28, label %13

13:                                               ; preds = %9
  %14 = add i64 %11, -1
  %15 = and i64 %14, -262144
  %16 = inttoptr i64 %15 to %"class.v8::internal::BasicMemoryChunk"*
  %17 = sub i64 %11, %15
  %18 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %16, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %19 = load atomic i64, i64* %18 monotonic, align 8
  %20 = icmp sgt i64 %17, %19
  br i1 %20, label %21, label %28

21:                                               ; preds = %13, %25
  %22 = phi i64 [ %26, %25 ], [ %19, %13 ]
  %23 = cmpxchg weak i64* %18, i64 %22, i64 %17 acq_rel monotonic
  %24 = extractvalue { i64, i1 } %23, 1
  br i1 %24, label %28, label %25

25:                                               ; preds = %21
  %26 = extractvalue { i64, i1 } %23, 0
  %27 = icmp sgt i64 %17, %26
  br i1 %27, label %21, label %28

28:                                               ; preds = %21, %25, %9, %13
  %29 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %30 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %29, align 8
  %31 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %32 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %31, align 8
  %33 = icmp eq %"class.v8::internal::ReadOnlyPage"** %30, %32
  br i1 %33, label %116, label %34

34:                                               ; preds = %28
  %35 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %30 to i64
  %36 = getelementptr %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %32, i64 -1
  %37 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %36 to i64
  %38 = sub i64 %37, %35
  %39 = lshr i64 %38, 3
  %40 = add nuw nsw i64 %39, 1
  %41 = and i64 %40, 7
  %42 = icmp ult i64 %38, 56
  br i1 %42, label %99, label %43

43:                                               ; preds = %34
  %44 = sub nsw i64 %40, %41
  br label %45

45:                                               ; preds = %45, %43
  %46 = phi i64 [ 0, %43 ], [ %95, %45 ]
  %47 = phi %"class.v8::internal::ReadOnlyPage"** [ %30, %43 ], [ %96, %45 ]
  %48 = phi i64 [ %44, %43 ], [ %97, %45 ]
  %49 = bitcast %"class.v8::internal::ReadOnlyPage"** %47 to %"class.v8::internal::BasicMemoryChunk"**
  %50 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %49, align 8
  %51 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %50, i64 0, i32 0
  %52 = load i64, i64* %51, align 8
  %53 = add i64 %52, %46
  %54 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 1
  %55 = bitcast %"class.v8::internal::ReadOnlyPage"** %54 to %"class.v8::internal::BasicMemoryChunk"**
  %56 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %55, align 8
  %57 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %56, i64 0, i32 0
  %58 = load i64, i64* %57, align 8
  %59 = add i64 %58, %53
  %60 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 2
  %61 = bitcast %"class.v8::internal::ReadOnlyPage"** %60 to %"class.v8::internal::BasicMemoryChunk"**
  %62 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %61, align 8
  %63 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %62, i64 0, i32 0
  %64 = load i64, i64* %63, align 8
  %65 = add i64 %64, %59
  %66 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 3
  %67 = bitcast %"class.v8::internal::ReadOnlyPage"** %66 to %"class.v8::internal::BasicMemoryChunk"**
  %68 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %67, align 8
  %69 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %68, i64 0, i32 0
  %70 = load i64, i64* %69, align 8
  %71 = add i64 %70, %65
  %72 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 4
  %73 = bitcast %"class.v8::internal::ReadOnlyPage"** %72 to %"class.v8::internal::BasicMemoryChunk"**
  %74 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %73, align 8
  %75 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %74, i64 0, i32 0
  %76 = load i64, i64* %75, align 8
  %77 = add i64 %76, %71
  %78 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 5
  %79 = bitcast %"class.v8::internal::ReadOnlyPage"** %78 to %"class.v8::internal::BasicMemoryChunk"**
  %80 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %79, align 8
  %81 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %80, i64 0, i32 0
  %82 = load i64, i64* %81, align 8
  %83 = add i64 %82, %77
  %84 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 6
  %85 = bitcast %"class.v8::internal::ReadOnlyPage"** %84 to %"class.v8::internal::BasicMemoryChunk"**
  %86 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %85, align 8
  %87 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %86, i64 0, i32 0
  %88 = load i64, i64* %87, align 8
  %89 = add i64 %88, %83
  %90 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 7
  %91 = bitcast %"class.v8::internal::ReadOnlyPage"** %90 to %"class.v8::internal::BasicMemoryChunk"**
  %92 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %91, align 8
  %93 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %92, i64 0, i32 0
  %94 = load i64, i64* %93, align 8
  %95 = add i64 %94, %89
  %96 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %47, i64 8
  %97 = add i64 %48, -8
  %98 = icmp eq i64 %97, 0
  br i1 %98, label %99, label %45

99:                                               ; preds = %45, %34
  %100 = phi i64 [ undef, %34 ], [ %95, %45 ]
  %101 = phi i64 [ 0, %34 ], [ %95, %45 ]
  %102 = phi %"class.v8::internal::ReadOnlyPage"** [ %30, %34 ], [ %96, %45 ]
  %103 = icmp eq i64 %41, 0
  br i1 %103, label %116, label %104

104:                                              ; preds = %99, %104
  %105 = phi i64 [ %112, %104 ], [ %101, %99 ]
  %106 = phi %"class.v8::internal::ReadOnlyPage"** [ %113, %104 ], [ %102, %99 ]
  %107 = phi i64 [ %114, %104 ], [ %41, %99 ]
  %108 = bitcast %"class.v8::internal::ReadOnlyPage"** %106 to %"class.v8::internal::BasicMemoryChunk"**
  %109 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %108, align 8
  %110 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %109, i64 0, i32 0
  %111 = load i64, i64* %110, align 8
  %112 = add i64 %111, %105
  %113 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %106, i64 1
  %114 = add i64 %107, -1
  %115 = icmp eq i64 %114, 0
  br i1 %115, label %116, label %104, !llvm.loop !7

116:                                              ; preds = %99, %104, %28, %3
  %117 = phi i64 [ %8, %3 ], [ 0, %28 ], [ %100, %99 ], [ %112, %104 ]
  ret i64 %117
}

declare zeroext i1 @_ZN2v84base2OS14HasLazyCommitsEv() local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace24EnsureSpaceForAllocationEi(%"class.v8::internal::ReadOnlySpace"*, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %4 = load i64, i64* %3, align 8
  %5 = sext i32 %1 to i64
  %6 = add i64 %4, %5
  %7 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 5
  %8 = load i64, i64* %7, align 8
  %9 = icmp ugt i64 %6, %8
  br i1 %9, label %10, label %133

10:                                               ; preds = %2
  tail call void @_ZN2v88internal13ReadOnlySpace24FreeLinearAllocationAreaEv(%"class.v8::internal::ReadOnlySpace"* %0)
  %11 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %12 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %11, align 8
  %13 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %12, i64 0, i32 85, i32 0, i32 0, i32 0
  %14 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %13, align 8
  %15 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 8
  %16 = load i64, i64* %15, align 8
  %17 = shl i64 %16, 32
  %18 = ashr exact i64 %17, 32
  %19 = tail call %"class.v8::internal::ReadOnlyPage"* @_ZN2v88internal15MemoryAllocator20AllocateReadOnlyPageEmPNS0_13ReadOnlySpaceE(%"class.v8::internal::MemoryAllocator"* %14, i64 %18, %"class.v8::internal::ReadOnlySpace"* %0) #15
  %20 = load i64, i64* %15, align 8
  %21 = shl i64 %20, 32
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 7
  %24 = load i64, i64* %23, align 8
  %25 = add i64 %22, %24
  store i64 %25, i64* %23, align 8
  %26 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %19, i64 0, i32 0, i32 4
  %27 = load i64, i64* %26, align 8
  %28 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %19, i64 0, i32 0, i32 3
  %29 = load i64, i64* %28, align 8
  %30 = sub i64 %27, %29
  %31 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %32 = atomicrmw add i64* %31, i64 %30 seq_cst
  %33 = load atomic i64, i64* %31 seq_cst, align 8
  %34 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 1
  %35 = load i64, i64* %34, align 8
  %36 = icmp ugt i64 %33, %35
  br i1 %36, label %37, label %39

37:                                               ; preds = %10
  %38 = load atomic i64, i64* %31 seq_cst, align 8
  store i64 %38, i64* %34, align 8
  br label %39

39:                                               ; preds = %10, %37
  %40 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %19, i64 0, i32 0, i32 0
  %41 = load i64, i64* %40, align 8
  %42 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %43 = atomicrmw add i64* %42, i64 %41 seq_cst
  %44 = load atomic i64, i64* %42 seq_cst, align 8
  %45 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 4
  %46 = load i64, i64* %45, align 8
  %47 = icmp ugt i64 %44, %46
  br i1 %47, label %48, label %50

48:                                               ; preds = %39
  %49 = load atomic i64, i64* %42 seq_cst, align 8
  store i64 %49, i64* %45, align 8
  br label %50

50:                                               ; preds = %39, %48
  %51 = icmp eq %"class.v8::internal::ReadOnlyPage"* %19, null
  br i1 %51, label %52, label %53, !prof !4

52:                                               ; preds = %50
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.7, i64 0, i64 0)) #14
  unreachable

53:                                               ; preds = %50
  %54 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3
  %55 = ptrtoint %"class.v8::internal::ReadOnlyPage"* %19 to i64
  %56 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %57 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %56, align 8
  %58 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0
  %59 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %58, align 8
  %60 = icmp ult %"class.v8::internal::ReadOnlyPage"** %57, %59
  %61 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %59 to i64
  br i1 %60, label %62, label %67

62:                                               ; preds = %53
  %63 = bitcast %"class.v8::internal::ReadOnlyPage"** %57 to i64*
  store i64 %55, i64* %63, align 8
  %64 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %57, i64 1
  %65 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %64 to i64
  %66 = bitcast %"class.v8::internal::ReadOnlyPage"*** %56 to i64*
  store i64 %65, i64* %66, align 8
  br label %124

67:                                               ; preds = %53
  %68 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %57 to i64
  %69 = bitcast %"class.v8::internal::ReadOnlyPage"*** %56 to i64*
  %70 = bitcast %"class.std::__1::vector"* %54 to i64*
  %71 = load i64, i64* %70, align 8
  %72 = sub i64 %68, %71
  %73 = ashr exact i64 %72, 3
  %74 = add nsw i64 %73, 1
  %75 = icmp ugt i64 %74, 2305843009213693951
  br i1 %75, label %76, label %78

76:                                               ; preds = %67
  %77 = bitcast %"class.std::__1::vector"* %54 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %77) #14
  unreachable

78:                                               ; preds = %67
  %79 = bitcast %"class.v8::internal::ReadOnlyPage"*** %58 to i64*
  %80 = sub i64 %61, %71
  %81 = ashr exact i64 %80, 3
  %82 = icmp ult i64 %81, 1152921504606846975
  br i1 %82, label %83, label %91

83:                                               ; preds = %78
  %84 = ashr exact i64 %80, 2
  %85 = icmp ult i64 %84, %74
  %86 = select i1 %85, i64 %74, i64 %84
  %87 = icmp eq i64 %86, 0
  br i1 %87, label %96, label %88

88:                                               ; preds = %83
  %89 = icmp ugt i64 %86, 2305843009213693951
  br i1 %89, label %90, label %91

90:                                               ; preds = %88
  tail call void @abort() #14
  unreachable

91:                                               ; preds = %88, %78
  %92 = phi i64 [ %86, %88 ], [ 2305843009213693951, %78 ]
  %93 = shl i64 %92, 3
  %94 = tail call i8* @_Znwm(i64 %93) #16
  %95 = bitcast i8* %94 to %"class.v8::internal::ReadOnlyPage"**
  br label %96

96:                                               ; preds = %91, %83
  %97 = phi i64 [ %92, %91 ], [ 0, %83 ]
  %98 = phi %"class.v8::internal::ReadOnlyPage"** [ %95, %91 ], [ null, %83 ]
  %99 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %98, i64 %73
  %100 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %98, i64 %97
  %101 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %100 to i64
  %102 = bitcast %"class.v8::internal::ReadOnlyPage"** %99 to i64*
  store i64 %55, i64* %102, align 8
  %103 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %99, i64 1
  %104 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %103 to i64
  %105 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %54, i64 0, i32 0, i32 0
  %106 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %105, align 8
  %107 = load i64, i64* %69, align 8
  %108 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %106 to i64
  %109 = sub i64 %107, %108
  %110 = ashr exact i64 %109, 3
  %111 = sub nsw i64 0, %110
  %112 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %99, i64 %111
  %113 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %112 to i64
  %114 = icmp sgt i64 %109, 0
  br i1 %114, label %115, label %119

115:                                              ; preds = %96
  %116 = bitcast %"class.v8::internal::ReadOnlyPage"** %112 to i8*
  %117 = bitcast %"class.v8::internal::ReadOnlyPage"** %106 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %116, i8* align 8 %117, i64 %109, i1 false) #15
  %118 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %105, align 8
  br label %119

119:                                              ; preds = %115, %96
  %120 = phi %"class.v8::internal::ReadOnlyPage"** [ %106, %96 ], [ %118, %115 ]
  store i64 %113, i64* %70, align 8
  store i64 %104, i64* %69, align 8
  store i64 %101, i64* %79, align 8
  %121 = icmp eq %"class.v8::internal::ReadOnlyPage"** %120, null
  br i1 %121, label %124, label %122

122:                                              ; preds = %119
  %123 = bitcast %"class.v8::internal::ReadOnlyPage"** %120 to i8*
  tail call void @_ZdlPv(i8* %123) #16
  br label %124

124:                                              ; preds = %62, %119, %122
  %125 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %11, align 8
  %126 = load i64, i64* %28, align 8
  %127 = load i64, i64* %26, align 8
  %128 = sub i64 %127, %126
  %129 = trunc i64 %128 to i32
  %130 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %125, i64 %126, i32 %129, i32 1) #15
  %131 = load i64, i64* %28, align 8
  store i64 %131, i64* %3, align 8
  %132 = load i64, i64* %26, align 8
  store i64 %132, i64* %7, align 8
  br label %133

133:                                              ; preds = %2, %124
  ret void
}

declare %"class.v8::internal::ReadOnlyPage"* @_ZN2v88internal15MemoryAllocator20AllocateReadOnlyPageEmPNS0_13ReadOnlySpaceE(%"class.v8::internal::MemoryAllocator"*, i64, %"class.v8::internal::ReadOnlySpace"*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal13ReadOnlySpace26TryAllocateLinearlyAlignedEiNS0_19AllocationAlignmentE(%"class.v8::internal::ReadOnlySpace"* nocapture, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %5 = load i64, i64* %4, align 8
  %6 = tail call i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64 %5, i32 %2) #15
  %7 = sext i32 %6 to i64
  %8 = sext i32 %1 to i64
  %9 = add i64 %5, %8
  %10 = add i64 %9, %7
  %11 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 5
  %12 = load i64, i64* %11, align 8
  %13 = icmp ugt i64 %10, %12
  br i1 %13, label %39, label %14

14:                                               ; preds = %3
  %15 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %16 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %15, align 8
  %17 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %16, i64 -1
  %18 = bitcast %"class.v8::internal::ReadOnlyPage"** %17 to %"class.v8::internal::BasicMemoryChunk"**
  %19 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %18, align 8
  %20 = add nsw i32 %6, %1
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %23 = atomicrmw add i64* %22, i64 %21 seq_cst
  %24 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %19, i64 0, i32 5
  %25 = load i64, i64* %24, align 8
  %26 = add i64 %25, %21
  store i64 %26, i64* %24, align 8
  store i64 %10, i64* %4, align 8
  %27 = icmp sgt i32 %6, 0
  br i1 %27, label %28, label %37

28:                                               ; preds = %14
  %29 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %30 = bitcast %"class.v8::internal::Heap"** %29 to i64*
  %31 = load i64, i64* %30, align 8
  %32 = add i64 %31, -41416
  %33 = inttoptr i64 %32 to %"class.v8::internal::Isolate"*
  %34 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %33, i64 0, i32 0, i32 7, i32 0, i64 0
  %35 = add i64 %5, 1
  %36 = tail call i64 @_ZN2v88internal4Heap17PrecedeWithFillerENS0_13ReadOnlyRootsENS0_10HeapObjectEi(i64* %34, i64 %35, i32 %6) #15
  br label %39

37:                                               ; preds = %14
  %38 = add i64 %5, 1
  br label %39

39:                                               ; preds = %3, %28, %37
  %40 = phi i64 [ %36, %28 ], [ %38, %37 ], [ 0, %3 ]
  ret i64 %40
}

declare i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64, i32) local_unnamed_addr #6

declare i64 @_ZN2v88internal4Heap17PrecedeWithFillerENS0_13ReadOnlyRootsENS0_10HeapObjectEi(i64*, i64, i32) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal13ReadOnlySpace18AllocateRawAlignedEiNS0_19AllocationAlignmentE(%"class.v8::internal::ReadOnlySpace"*, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %5 = load i64, i64* %4, align 8
  %6 = tail call i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64 %5, i32 %2) #15
  %7 = sext i32 %6 to i64
  %8 = sext i32 %1 to i64
  %9 = add i64 %5, %8
  %10 = add i64 %9, %7
  %11 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 5
  %12 = load i64, i64* %11, align 8
  %13 = icmp ugt i64 %10, %12
  br i1 %13, label %43, label %14

14:                                               ; preds = %3
  %15 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %16 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %15, align 8
  %17 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %16, i64 -1
  %18 = bitcast %"class.v8::internal::ReadOnlyPage"** %17 to %"class.v8::internal::BasicMemoryChunk"**
  %19 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %18, align 8
  %20 = add nsw i32 %6, %1
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %23 = atomicrmw add i64* %22, i64 %21 seq_cst
  %24 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %19, i64 0, i32 5
  %25 = load i64, i64* %24, align 8
  %26 = add i64 %25, %21
  store i64 %26, i64* %24, align 8
  store i64 %10, i64* %4, align 8
  %27 = icmp sgt i32 %6, 0
  br i1 %27, label %28, label %37

28:                                               ; preds = %14
  %29 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %30 = bitcast %"class.v8::internal::Heap"** %29 to i64*
  %31 = load i64, i64* %30, align 8
  %32 = add i64 %31, -41416
  %33 = inttoptr i64 %32 to %"class.v8::internal::Isolate"*
  %34 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %33, i64 0, i32 0, i32 7, i32 0, i64 0
  %35 = add i64 %5, 1
  %36 = tail call i64 @_ZN2v88internal4Heap17PrecedeWithFillerENS0_13ReadOnlyRootsENS0_10HeapObjectEi(i64* %34, i64 %35, i32 %6) #15
  br label %39

37:                                               ; preds = %14
  %38 = add i64 %5, 1
  br label %39

39:                                               ; preds = %28, %37
  %40 = phi i64 [ %36, %28 ], [ %38, %37 ]
  %41 = trunc i64 %40 to i32
  %42 = icmp eq i32 %41, 0
  br i1 %42, label %43, label %83

43:                                               ; preds = %3, %39
  %44 = tail call i32 @_ZN2v88internal4Heap21GetMaximumFillToAlignENS0_19AllocationAlignmentE(i32 %2) #15
  %45 = add nsw i32 %44, %1
  tail call void @_ZN2v88internal13ReadOnlySpace24EnsureSpaceForAllocationEi(%"class.v8::internal::ReadOnlySpace"* %0, i32 %45)
  %46 = load i64, i64* %4, align 8
  %47 = tail call i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64 %46, i32 %2) #15
  %48 = sext i32 %47 to i64
  %49 = add i64 %46, %8
  %50 = add i64 %49, %48
  %51 = load i64, i64* %11, align 8
  %52 = icmp ugt i64 %50, %51
  br i1 %52, label %82, label %53

53:                                               ; preds = %43
  %54 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %55 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %54, align 8
  %56 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %55, i64 -1
  %57 = bitcast %"class.v8::internal::ReadOnlyPage"** %56 to %"class.v8::internal::BasicMemoryChunk"**
  %58 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %57, align 8
  %59 = add nsw i32 %47, %1
  %60 = sext i32 %59 to i64
  %61 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %62 = atomicrmw add i64* %61, i64 %60 seq_cst
  %63 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %58, i64 0, i32 5
  %64 = load i64, i64* %63, align 8
  %65 = add i64 %64, %60
  store i64 %65, i64* %63, align 8
  store i64 %50, i64* %4, align 8
  %66 = icmp sgt i32 %47, 0
  br i1 %66, label %67, label %76

67:                                               ; preds = %53
  %68 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %69 = bitcast %"class.v8::internal::Heap"** %68 to i64*
  %70 = load i64, i64* %69, align 8
  %71 = add i64 %70, -41416
  %72 = inttoptr i64 %71 to %"class.v8::internal::Isolate"*
  %73 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %72, i64 0, i32 0, i32 7, i32 0, i64 0
  %74 = add i64 %46, 1
  %75 = tail call i64 @_ZN2v88internal4Heap17PrecedeWithFillerENS0_13ReadOnlyRootsENS0_10HeapObjectEi(i64* %73, i64 %74, i32 %47) #15
  br label %78

76:                                               ; preds = %53
  %77 = add i64 %46, 1
  br label %78

78:                                               ; preds = %67, %76
  %79 = phi i64 [ %75, %67 ], [ %77, %76 ]
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 0
  br i1 %81, label %82, label %83, !prof !4

82:                                               ; preds = %43, %78
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.8, i64 0, i64 0)) #14
  unreachable

83:                                               ; preds = %39, %78
  %84 = phi i64 [ %79, %78 ], [ %40, %39 ]
  %85 = and i64 %84, 1
  %86 = icmp eq i64 %85, 0
  br i1 %86, label %87, label %88, !prof !4

87:                                               ; preds = %83
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.13, i64 0, i64 0)) #14
  unreachable

88:                                               ; preds = %83
  ret i64 %84
}

declare i32 @_ZN2v88internal4Heap21GetMaximumFillToAlignENS0_19AllocationAlignmentE(i32) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal13ReadOnlySpace20AllocateRawUnalignedEi(%"class.v8::internal::ReadOnlySpace"*, i32) local_unnamed_addr #0 align 2 {
  tail call void @_ZN2v88internal13ReadOnlySpace24EnsureSpaceForAllocationEi(%"class.v8::internal::ReadOnlySpace"* %0, i32 %1)
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %4 = load i64, i64* %3, align 8
  %5 = sext i32 %1 to i64
  %6 = add i64 %4, %5
  store i64 %6, i64* %3, align 8
  %7 = add i64 %4, 1
  %8 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %9 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %9, i64 -1
  %11 = bitcast %"class.v8::internal::ReadOnlyPage"** %10 to %"class.v8::internal::BasicMemoryChunk"**
  %12 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %11, align 8
  %13 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %14 = atomicrmw add i64* %13, i64 %5 seq_cst
  %15 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %12, i64 0, i32 5
  %16 = load i64, i64* %15, align 8
  %17 = add i64 %16, %5
  store i64 %17, i64* %15, align 8
  %18 = and i64 %7, 1
  %19 = icmp eq i64 %18, 0
  br i1 %19, label %20, label %21, !prof !4

20:                                               ; preds = %2
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.13, i64 0, i64 0)) #14
  unreachable

21:                                               ; preds = %2
  ret i64 %7
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal13ReadOnlySpace11AllocateRawEiNS0_19AllocationAlignmentE(%"class.v8::internal::ReadOnlySpace"*, i32, i32) local_unnamed_addr #0 align 2 {
  tail call void @_ZN2v88internal13ReadOnlySpace24EnsureSpaceForAllocationEi(%"class.v8::internal::ReadOnlySpace"* %0, i32 %1) #15
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %5 = load i64, i64* %4, align 8
  %6 = sext i32 %1 to i64
  %7 = add i64 %5, %6
  store i64 %7, i64* %4, align 8
  %8 = add i64 %5, 1
  %9 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %10 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %9, align 8
  %11 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %10, i64 -1
  %12 = bitcast %"class.v8::internal::ReadOnlyPage"** %11 to %"class.v8::internal::BasicMemoryChunk"**
  %13 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %12, align 8
  %14 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %15 = atomicrmw add i64* %14, i64 %6 seq_cst
  %16 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %13, i64 0, i32 5
  %17 = load i64, i64* %16, align 8
  %18 = add i64 %17, %6
  store i64 %18, i64* %16, align 8
  %19 = and i64 %8, 1
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %21, label %22, !prof !4

21:                                               ; preds = %3
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.13, i64 0, i64 0)) #14
  unreachable

22:                                               ; preds = %3
  ret i64 %8
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal12ReadOnlyPage21ShrinkToHighWaterMarkEv(%"class.v8::internal::ReadOnlyPage"*) local_unnamed_addr #0 align 2 {
  %2 = alloca %"class.v8::internal::HeapObject", align 8
  %3 = bitcast %"class.v8::internal::HeapObject"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %3) #15
  %4 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0
  %5 = ptrtoint %"class.v8::internal::ReadOnlyPage"* %0 to i64
  %6 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load atomic i64, i64* %6 seq_cst, align 8
  %8 = add i64 %7, %5
  %9 = add i64 %8, 1
  %10 = getelementptr inbounds %"class.v8::internal::HeapObject", %"class.v8::internal::HeapObject"* %2, i64 0, i32 0, i32 0, i32 0
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0, i32 4
  %12 = load i64, i64* %11, align 8
  %13 = icmp eq i64 %12, %8
  br i1 %13, label %85, label %14

14:                                               ; preds = %1
  %15 = and i64 %9, -4294967296
  %16 = inttoptr i64 %8 to i32*
  %17 = load atomic i32, i32* %16 monotonic, align 4
  %18 = zext i32 %17 to i64
  %19 = or i64 %15, %18
  %20 = add i64 %19, 7
  %21 = inttoptr i64 %20 to i16*
  %22 = load atomic i16, i16* %21 monotonic, align 2
  %23 = or i16 %22, 1
  %24 = icmp eq i16 %23, 169
  br i1 %24, label %26, label %25, !prof !2

25:                                               ; preds = %14
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.9, i64 0, i64 0)) #14
  unreachable

26:                                               ; preds = %14
  %27 = sub i64 %12, %8
  %28 = tail call i64 @_ZN2v88internal15MemoryAllocator17GetCommitPageSizeEv() #15
  %29 = sub nsw i64 0, %28
  %30 = and i64 %27, %29
  %31 = icmp eq i64 %30, 0
  br i1 %31, label %85, label %32

32:                                               ; preds = %26
  %33 = load i8, i8* @_ZN2v88internal21FLAG_trace_gc_verboseE, align 1, !range !3
  %34 = icmp eq i8 %33, 0
  br i1 %34, label %45, label %35

35:                                               ; preds = %32
  %36 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0, i32 2
  %37 = bitcast %"class.v8::internal::Heap"** %36 to i64*
  %38 = load i64, i64* %37, align 8
  %39 = add i64 %38, -41416
  %40 = inttoptr i64 %39 to i8*
  %41 = load i64, i64* %11, align 8
  %42 = inttoptr i64 %41 to i8*
  %43 = sub i64 %41, %30
  %44 = inttoptr i64 %43 to i8*
  tail call void (i8*, i8*, ...) @_ZN2v88internal12PrintIsolateEPvPKcz(i8* %40, i8* getelementptr inbounds ([33 x i8], [33 x i8]* @.str.10, i64 0, i64 0), %"class.v8::internal::ReadOnlyPage"* %0, i8* %42, i8* %44) #15
  br label %45

45:                                               ; preds = %32, %35
  %46 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0, i32 2
  %47 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %46, align 8
  %48 = load i64, i64* %11, align 8
  %49 = sub i64 0, %8
  %50 = sub i64 %49, %30
  %51 = add i64 %50, %48
  %52 = trunc i64 %51 to i32
  %53 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %47, i64 %8, i32 %52, i32 1) #15
  %54 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %46, align 8
  %55 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %54, i64 0, i32 85, i32 0, i32 0, i32 0
  %56 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %55, align 8
  %57 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage", %"class.v8::internal::ReadOnlyPage"* %0, i64 0, i32 0, i32 0
  %58 = load i64, i64* %57, align 8
  %59 = sub i64 %5, %30
  %60 = add i64 %59, %58
  %61 = load i64, i64* %11, align 8
  %62 = sub i64 %61, %30
  tail call void @_ZN2v88internal15MemoryAllocator17PartialFreeMemoryEPNS0_16BasicMemoryChunkEmmm(%"class.v8::internal::MemoryAllocator"* %56, %"class.v8::internal::BasicMemoryChunk"* %4, i64 %60, i64 %30, i64 %62) #15
  %63 = load i64, i64* %11, align 8
  %64 = icmp eq i64 %8, %63
  br i1 %64, label %85, label %65

65:                                               ; preds = %45
  %66 = load atomic i32, i32* %16 monotonic, align 4
  %67 = zext i32 %66 to i64
  %68 = or i64 %15, %67
  %69 = add i64 %68, 7
  %70 = inttoptr i64 %69 to i16*
  %71 = load atomic i16, i16* %70 monotonic, align 2
  %72 = or i16 %71, 1
  %73 = icmp eq i16 %72, 169
  br i1 %73, label %75, label %74, !prof !2

74:                                               ; preds = %65
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str.9, i64 0, i64 0)) #14
  unreachable

75:                                               ; preds = %65
  %76 = load atomic i32, i32* %16 monotonic, align 4
  %77 = zext i32 %76 to i64
  %78 = or i64 %15, %77
  %79 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %2, i64 %78) #15
  %80 = sext i32 %79 to i64
  %81 = add i64 %8, %80
  %82 = load i64, i64* %11, align 8
  %83 = icmp eq i64 %81, %82
  br i1 %83, label %85, label %84, !prof !2

84:                                               ; preds = %75
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([47 x i8], [47 x i8]* @.str.11, i64 0, i64 0)) #14
  unreachable

85:                                               ; preds = %26, %45, %75, %1
  %86 = phi i64 [ 0, %1 ], [ %30, %75 ], [ %30, %45 ], [ 0, %26 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %3) #15
  ret i64 %86
}

declare i64 @_ZN2v88internal15MemoryAllocator17GetCommitPageSizeEv() local_unnamed_addr #6

declare void @_ZN2v88internal12PrintIsolateEPvPKcz(i8*, i8*, ...) local_unnamed_addr #6

declare void @_ZN2v88internal15MemoryAllocator17PartialFreeMemoryEPNS0_16BasicMemoryChunkEmmm(%"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::BasicMemoryChunk"*, i64, i64, i64) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal13ReadOnlySpace11ShrinkPagesEv(%"class.v8::internal::ReadOnlySpace"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 4
  %3 = load i64, i64* %2, align 8
  %4 = icmp eq i64 %3, 0
  br i1 %4, label %22, label %5

5:                                                ; preds = %1
  %6 = add i64 %3, -1
  %7 = and i64 %6, -262144
  %8 = inttoptr i64 %7 to %"class.v8::internal::BasicMemoryChunk"*
  %9 = sub i64 %3, %7
  %10 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %8, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %11 = load atomic i64, i64* %10 monotonic, align 8
  %12 = icmp sgt i64 %9, %11
  br i1 %12, label %13, label %22

13:                                               ; preds = %5, %17
  %14 = phi i64 [ %18, %17 ], [ %11, %5 ]
  %15 = cmpxchg weak i64* %10, i64 %14, i64 %9 acq_rel monotonic
  %16 = extractvalue { i64, i1 } %15, 1
  br i1 %16, label %20, label %17

17:                                               ; preds = %13
  %18 = extractvalue { i64, i1 } %15, 0
  %19 = icmp sgt i64 %9, %18
  br i1 %19, label %13, label %20

20:                                               ; preds = %17, %13
  %21 = load i64, i64* %2, align 8
  br label %22

22:                                               ; preds = %20, %1, %5
  %23 = phi i64 [ %21, %20 ], [ 0, %1 ], [ %3, %5 ]
  %24 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 1
  %25 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %24, align 8
  %26 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 5
  %27 = load i64, i64* %26, align 8
  %28 = sub i64 %27, %23
  %29 = trunc i64 %28 to i32
  %30 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %25, i64 %23, i32 %29, i32 1) #15
  %31 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 0
  %32 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %31, align 8
  %33 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 3, i32 0, i32 1
  %34 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %33, align 8
  %35 = icmp eq %"class.v8::internal::ReadOnlyPage"** %32, %34
  br i1 %35, label %42, label %36

36:                                               ; preds = %22
  %37 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 7
  %38 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %39 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %49

40:                                               ; preds = %49
  %41 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %33, align 8
  br label %42

42:                                               ; preds = %40, %22
  %43 = phi %"class.v8::internal::ReadOnlyPage"** [ %41, %40 ], [ %32, %22 ]
  %44 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %43, i64 -1
  %45 = bitcast %"class.v8::internal::ReadOnlyPage"** %44 to %"class.v8::internal::BasicMemoryChunk"**
  %46 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %45, align 8
  %47 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %46, i64 0, i32 4
  %48 = load i64, i64* %47, align 8
  store i64 %48, i64* %26, align 8
  ret void

49:                                               ; preds = %36, %49
  %50 = phi %"class.v8::internal::ReadOnlyPage"** [ %32, %36 ], [ %57, %49 ]
  %51 = load %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %50, align 8
  %52 = tail call i64 @_ZN2v88internal12ReadOnlyPage21ShrinkToHighWaterMarkEv(%"class.v8::internal::ReadOnlyPage"* %51)
  %53 = load i64, i64* %37, align 8
  %54 = sub i64 %53, %52
  store i64 %54, i64* %37, align 8
  %55 = atomicrmw sub i64* %38, i64 %52 seq_cst
  %56 = atomicrmw sub i64* %39, i64 %52 seq_cst
  %57 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %50, i64 1
  %58 = icmp eq %"class.v8::internal::ReadOnlyPage"** %57, %34
  br i1 %58, label %40, label %49
}

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::ReadOnlyPage"* @_ZN2v88internal13ReadOnlySpace14InitializePageEPNS0_16BasicMemoryChunkE(%"class.v8::internal::ReadOnlySpace"* nocapture readonly, %"class.v8::internal::BasicMemoryChunk"*) local_unnamed_addr #0 align 2 {
  %3 = bitcast %"class.v8::internal::BasicMemoryChunk"* %1 to %"class.v8::internal::ReadOnlyPage"*
  %4 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %1, i64 0, i32 5
  store i64 0, i64* %4, align 8
  %5 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %1, i64 0, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = or i64 %6, 128
  store i64 %7, i64* %5, align 8
  %8 = ptrtoint %"class.v8::internal::BasicMemoryChunk"* %1 to i64
  %9 = add i64 %8, 272
  %10 = inttoptr i64 %9 to %"class.v8::internal::ConcurrentBitmap.1155"*
  %11 = getelementptr inbounds %"class.v8::internal::ConcurrentBitmap.1155", %"class.v8::internal::ConcurrentBitmap.1155"* %10, i64 0, i32 0
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %11, i8 -1, i64 8196, i1 false) #15
  %12 = load i64, i64* %5, align 8
  %13 = or i64 %12, 2097152
  store i64 %13, i64* %5, align 8
  ret %"class.v8::internal::ReadOnlyPage"* %3
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19SharedReadOnlySpaceC2EPNS0_4HeapEPNS0_34PointerCompressedReadOnlyArtifactsE(%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::Heap"*, %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* nocapture readonly) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 0
  %5 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 2
  store i32 0, i32* %6, align 8
  %7 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %8 = bitcast i64* %7 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %8, i8 0, i64 16, i1 false) #15
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %9 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 1
  store i8 0, i8* %9, align 8
  %10 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %10 seq_cst, align 8
  %11 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 1
  store i64 0, i64* %11, align 8
  %12 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %12 seq_cst, align 8
  %13 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3
  %14 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 6
  %15 = ptrtoint %"class.v8::internal::Heap"* %1 to i64
  %16 = add i64 %15, -41416
  %17 = inttoptr i64 %16 to %"class.v8::internal::Isolate"*
  %18 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %17, i64 0, i32 63
  %19 = bitcast %"class.std::__1::vector"* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %19, i8 0, i64 40, i1 false) #15
  %20 = load i8, i8* %18, align 1, !range !3
  store i8 %20, i8* %14, align 8
  %21 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 7
  store i64 0, i64* %21, align 8
  %22 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 8
  %23 = tail call i64 @_ZN2v88internal17MemoryChunkLayout30AllocatableMemoryInMemoryChunkENS0_15AllocationSpaceE(i32 0) #15
  store i64 %23, i64* %22, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal19SharedReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %24 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1
  %25 = bitcast %"class.std::__1::vector.613"* %24 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %25, i8 0, i64 24, i1 false) #15
  store i8 1, i8* %9, align 8
  %26 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %2, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %27 = load atomic i64, i64* %26 seq_cst, align 8
  %28 = atomicrmw add i64* %10, i64 %27 seq_cst
  %29 = load atomic i64, i64* %10 seq_cst, align 8
  %30 = load i64, i64* %11, align 8
  %31 = icmp ugt i64 %29, %30
  br i1 %31, label %32, label %34

32:                                               ; preds = %3
  %33 = load atomic i64, i64* %10 seq_cst, align 8
  store i64 %33, i64* %11, align 8
  br label %34

34:                                               ; preds = %3, %32
  %35 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %2, i64 0, i32 0, i32 1, i32 0, i32 0
  %36 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %35, align 8
  %37 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %2, i64 0, i32 0, i32 1, i32 0, i32 1
  %38 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %37, align 8
  %39 = icmp eq %"class.v8::internal::ReadOnlyPage"** %36, %38
  br i1 %39, label %47, label %40

40:                                               ; preds = %34
  %41 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 1
  %42 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 2, i32 0, i32 0
  %43 = bitcast %"class.v8::internal::ReadOnlyPage"*** %41 to i64*
  %44 = bitcast %"class.std::__1::vector"* %13 to i64*
  %45 = bitcast %"class.v8::internal::ReadOnlyPage"*** %42 to i64*
  %46 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %13, i64 0, i32 0, i32 0
  br label %48

47:                                               ; preds = %113, %34
  ret void

48:                                               ; preds = %40, %113
  %49 = phi %"class.v8::internal::ReadOnlyPage"** [ %36, %40 ], [ %118, %113 ]
  %50 = bitcast %"class.v8::internal::ReadOnlyPage"** %49 to i64*
  %51 = load i64, i64* %50, align 8
  %52 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %41, align 8
  %53 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %42, align 8
  %54 = icmp eq %"class.v8::internal::ReadOnlyPage"** %52, %53
  %55 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %53 to i64
  br i1 %54, label %60, label %56

56:                                               ; preds = %48
  %57 = bitcast %"class.v8::internal::ReadOnlyPage"** %52 to i64*
  store i64 %51, i64* %57, align 8
  %58 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %52, i64 1
  %59 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %58 to i64
  store i64 %59, i64* %43, align 8
  br label %113

60:                                               ; preds = %48
  %61 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %52 to i64
  %62 = load i64, i64* %44, align 8
  %63 = sub i64 %61, %62
  %64 = ashr exact i64 %63, 3
  %65 = add nsw i64 %64, 1
  %66 = icmp ugt i64 %65, 2305843009213693951
  br i1 %66, label %67, label %69

67:                                               ; preds = %60
  %68 = bitcast %"class.std::__1::vector"* %13 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %68) #14
  unreachable

69:                                               ; preds = %60
  %70 = sub i64 %55, %62
  %71 = ashr exact i64 %70, 3
  %72 = icmp ult i64 %71, 1152921504606846975
  br i1 %72, label %73, label %81

73:                                               ; preds = %69
  %74 = ashr exact i64 %70, 2
  %75 = icmp ult i64 %74, %65
  %76 = select i1 %75, i64 %65, i64 %74
  %77 = icmp eq i64 %76, 0
  br i1 %77, label %86, label %78

78:                                               ; preds = %73
  %79 = icmp ugt i64 %76, 2305843009213693951
  br i1 %79, label %80, label %81

80:                                               ; preds = %78
  tail call void @abort() #14
  unreachable

81:                                               ; preds = %78, %69
  %82 = phi i64 [ %76, %78 ], [ 2305843009213693951, %69 ]
  %83 = shl i64 %82, 3
  %84 = tail call i8* @_Znwm(i64 %83) #16
  %85 = bitcast i8* %84 to %"class.v8::internal::ReadOnlyPage"**
  br label %86

86:                                               ; preds = %81, %73
  %87 = phi i64 [ %82, %81 ], [ 0, %73 ]
  %88 = phi %"class.v8::internal::ReadOnlyPage"** [ %85, %81 ], [ null, %73 ]
  %89 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %88, i64 %64
  %90 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %88, i64 %87
  %91 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %90 to i64
  %92 = bitcast %"class.v8::internal::ReadOnlyPage"** %89 to i64*
  store i64 %51, i64* %92, align 8
  %93 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %89, i64 1
  %94 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %93 to i64
  %95 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %46, align 8
  %96 = load i64, i64* %43, align 8
  %97 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %95 to i64
  %98 = sub i64 %96, %97
  %99 = ashr exact i64 %98, 3
  %100 = sub nsw i64 0, %99
  %101 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %89, i64 %100
  %102 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %101 to i64
  %103 = icmp sgt i64 %98, 0
  br i1 %103, label %104, label %108

104:                                              ; preds = %86
  %105 = bitcast %"class.v8::internal::ReadOnlyPage"** %101 to i8*
  %106 = bitcast %"class.v8::internal::ReadOnlyPage"** %95 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %105, i8* align 8 %106, i64 %98, i1 false) #15
  %107 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %46, align 8
  br label %108

108:                                              ; preds = %104, %86
  %109 = phi %"class.v8::internal::ReadOnlyPage"** [ %95, %86 ], [ %107, %104 ]
  store i64 %102, i64* %44, align 8
  store i64 %94, i64* %43, align 8
  store i64 %91, i64* %45, align 8
  %110 = icmp eq %"class.v8::internal::ReadOnlyPage"** %109, null
  br i1 %110, label %113, label %111

111:                                              ; preds = %108
  %112 = bitcast %"class.v8::internal::ReadOnlyPage"** %109 to i8*
  tail call void @_ZdlPv(i8* %112) #16
  br label %113

113:                                              ; preds = %56, %108, %111
  %114 = inttoptr i64 %51 to %"class.v8::internal::BasicMemoryChunk"*
  %115 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %114, i64 0, i32 5
  %116 = load i64, i64* %115, align 8
  %117 = atomicrmw add i64* %12, i64 %116 seq_cst
  %118 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %49, i64 1
  %119 = icmp eq %"class.v8::internal::ReadOnlyPage"** %118, %38
  br i1 %119, label %47, label %48
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19SharedReadOnlySpaceC2EPNS0_4HeapEONSt3__16vectorIPNS0_12ReadOnlyPageENS4_9allocatorIS7_EEEEONS5_INS4_10unique_ptrINS_13PageAllocator19SharedMemoryMappingENS4_14default_deleteISE_EEEENS8_ISH_EEEEONS0_15AllocationStatsE(%"class.v8::internal::SharedReadOnlySpace"* nocapture, %"class.v8::internal::Heap"*, %"class.std::__1::vector"* nocapture dereferenceable(24), %"class.std::__1::vector.613"* nocapture dereferenceable(24), %"class.v8::internal::AllocationStats"* nocapture readonly dereferenceable(24)) unnamed_addr #0 align 2 {
  %6 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 0
  %7 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 2
  store i32 0, i32* %8, align 8
  %9 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %10 = bitcast i64* %9 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %10, i8 0, i64 16, i1 false) #15
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %11 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 1
  store i8 0, i8* %11, align 8
  %12 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %12 seq_cst, align 8
  %13 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 1
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %14 seq_cst, align 8
  %15 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3
  %16 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 6
  %17 = ptrtoint %"class.v8::internal::Heap"* %1 to i64
  %18 = add i64 %17, -41416
  %19 = inttoptr i64 %18 to %"class.v8::internal::Isolate"*
  %20 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %19, i64 0, i32 63
  %21 = bitcast %"class.std::__1::vector"* %15 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %21, i8 0, i64 40, i1 false) #15
  %22 = load i8, i8* %20, align 1, !range !3
  store i8 %22, i8* %16, align 8
  %23 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 7
  store i64 0, i64* %23, align 8
  %24 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 8
  %25 = tail call i64 @_ZN2v88internal17MemoryChunkLayout30AllocatableMemoryInMemoryChunkENS0_15AllocationSpaceE(i32 0) #15
  store i64 %25, i64* %24, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal19SharedReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %26 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1
  %27 = bitcast %"class.std::__1::vector.613"* %26 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %27, i8 0, i64 24, i1 false) #15
  store i8 1, i8* %11, align 8
  %28 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %29 = load atomic i64, i64* %28 seq_cst, align 8
  store atomic i64 %29, i64* %12 seq_cst, align 8
  %30 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %4, i64 0, i32 1
  %31 = load i64, i64* %30, align 8
  store i64 %31, i64* %13, align 8
  %32 = getelementptr inbounds %"class.v8::internal::AllocationStats", %"class.v8::internal::AllocationStats"* %4, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %33 = load atomic i64, i64* %32 seq_cst, align 8
  store atomic i64 %33, i64* %14 seq_cst, align 8
  %34 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %15, i64 0, i32 0, i32 0
  %35 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %34, align 8
  %36 = icmp eq %"class.v8::internal::ReadOnlyPage"** %35, null
  br i1 %36, label %42, label %37

37:                                               ; preds = %5
  %38 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %35 to i64
  %39 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 1
  %40 = bitcast %"class.v8::internal::ReadOnlyPage"*** %39 to i64*
  store i64 %38, i64* %40, align 8
  %41 = bitcast %"class.v8::internal::ReadOnlyPage"** %35 to i8*
  tail call void @_ZdlPv(i8* %41) #16
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %21, i8 0, i64 24, i1 false) #15
  br label %42

42:                                               ; preds = %5, %37
  %43 = bitcast %"class.std::__1::vector"* %2 to i64*
  %44 = load i64, i64* %43, align 8
  %45 = bitcast %"class.std::__1::vector"* %15 to i64*
  store i64 %44, i64* %45, align 8
  %46 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %2, i64 0, i32 0, i32 1
  %47 = bitcast %"class.v8::internal::ReadOnlyPage"*** %46 to i64*
  %48 = load i64, i64* %47, align 8
  %49 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 1
  %50 = bitcast %"class.v8::internal::ReadOnlyPage"*** %49 to i64*
  store i64 %48, i64* %50, align 8
  %51 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %2, i64 0, i32 0, i32 2, i32 0, i32 0
  %52 = bitcast %"class.v8::internal::ReadOnlyPage"*** %51 to i64*
  %53 = load i64, i64* %52, align 8
  %54 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 2, i32 0, i32 0
  %55 = bitcast %"class.v8::internal::ReadOnlyPage"*** %54 to i64*
  store i64 %53, i64* %55, align 8
  %56 = bitcast %"class.std::__1::vector"* %2 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %56, i8 0, i64 24, i1 false) #15
  %57 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %26, i64 0, i32 0, i32 0
  %58 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %57, align 8
  %59 = icmp eq %"class.std::__1::unique_ptr.615"* %58, null
  br i1 %59, label %83, label %60

60:                                               ; preds = %42
  %61 = bitcast %"class.std::__1::unique_ptr.615"* %58 to i8*
  %62 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1, i32 0, i32 1
  %63 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %62, align 8
  %64 = icmp eq %"class.std::__1::unique_ptr.615"* %63, %58
  br i1 %64, label %81, label %65

65:                                               ; preds = %60, %76
  %66 = phi %"class.std::__1::unique_ptr.615"* [ %67, %76 ], [ %63, %60 ]
  %67 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %66, i64 -1
  %68 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %67, i64 0, i32 0, i32 0, i32 0
  %69 = load %"class.v8::PageAllocator::SharedMemoryMapping"*, %"class.v8::PageAllocator::SharedMemoryMapping"** %68, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %68, align 8
  %70 = icmp eq %"class.v8::PageAllocator::SharedMemoryMapping"* %69, null
  br i1 %70, label %76, label %71

71:                                               ; preds = %65
  %72 = bitcast %"class.v8::PageAllocator::SharedMemoryMapping"* %69 to void (%"class.v8::PageAllocator::SharedMemoryMapping"*)***
  %73 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)**, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*** %72, align 8
  %74 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %73, i64 1
  %75 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %74, align 8
  tail call void %75(%"class.v8::PageAllocator::SharedMemoryMapping"* nonnull %69) #15
  br label %76

76:                                               ; preds = %71, %65
  %77 = icmp eq %"class.std::__1::unique_ptr.615"* %67, %58
  br i1 %77, label %78, label %65

78:                                               ; preds = %76
  %79 = bitcast %"class.std::__1::vector.613"* %26 to i8**
  %80 = load i8*, i8** %79, align 8
  br label %81

81:                                               ; preds = %78, %60
  %82 = phi i8* [ %80, %78 ], [ %61, %60 ]
  store %"class.std::__1::unique_ptr.615"* %58, %"class.std::__1::unique_ptr.615"** %62, align 8
  tail call void @_ZdlPv(i8* %82) #16
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %27, i8 0, i64 24, i1 false) #15
  br label %83

83:                                               ; preds = %42, %81
  %84 = bitcast %"class.std::__1::vector.613"* %3 to i64*
  %85 = load i64, i64* %84, align 8
  %86 = bitcast %"class.std::__1::vector.613"* %26 to i64*
  store i64 %85, i64* %86, align 8
  %87 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %3, i64 0, i32 0, i32 1
  %88 = bitcast %"class.std::__1::unique_ptr.615"** %87 to i64*
  %89 = load i64, i64* %88, align 8
  %90 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1, i32 0, i32 1
  %91 = bitcast %"class.std::__1::unique_ptr.615"** %90 to i64*
  store i64 %89, i64* %91, align 8
  %92 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %3, i64 0, i32 0, i32 2, i32 0, i32 0
  %93 = bitcast %"class.std::__1::unique_ptr.615"** %92 to i64*
  %94 = load i64, i64* %93, align 8
  %95 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1, i32 0, i32 2, i32 0, i32 0
  %96 = bitcast %"class.std::__1::unique_ptr.615"** %95 to i64*
  store i64 %94, i64* %96, align 8
  %97 = bitcast %"class.std::__1::vector.613"* %3 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %97, i8 0, i64 24, i1 false) #15
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19SharedReadOnlySpaceC2EPNS0_4HeapEPNS0_27SingleCopyReadOnlyArtifactsE(%"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::Heap"*, %"class.v8::internal::SingleCopyReadOnlyArtifacts"* readonly) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 0
  %5 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 2
  store i32 0, i32* %6, align 8
  %7 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %8 = bitcast i64* %7 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %8, i8 0, i64 16, i1 false) #15
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %9 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 1
  store i8 0, i8* %9, align 8
  %10 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %10 seq_cst, align 8
  %11 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 1
  store i64 0, i64* %11, align 8
  %12 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %12 seq_cst, align 8
  %13 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3
  %14 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 6
  %15 = ptrtoint %"class.v8::internal::Heap"* %1 to i64
  %16 = add i64 %15, -41416
  %17 = inttoptr i64 %16 to %"class.v8::internal::Isolate"*
  %18 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %17, i64 0, i32 63
  %19 = bitcast %"class.std::__1::vector"* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %19, i8 0, i64 40, i1 false) #15
  %20 = load i8, i8* %18, align 1, !range !3
  store i8 %20, i8* %14, align 8
  %21 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 7
  store i64 0, i64* %21, align 8
  %22 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 8
  %23 = tail call i64 @_ZN2v88internal17MemoryChunkLayout30AllocatableMemoryInMemoryChunkENS0_15AllocationSpaceE(i32 0) #15
  store i64 %23, i64* %22, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal19SharedReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %24 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1
  %25 = bitcast %"class.std::__1::vector.613"* %24 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %25, i8 0, i64 24, i1 false) #15
  store i8 1, i8* %9, align 8
  %26 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %2, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %27 = load atomic i64, i64* %26 seq_cst, align 8
  store atomic i64 %27, i64* %10 seq_cst, align 8
  %28 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %2, i64 0, i32 0, i32 2, i32 1
  %29 = load i64, i64* %28, align 8
  store i64 %29, i64* %11, align 8
  %30 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %2, i64 0, i32 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %31 = load atomic i64, i64* %30 seq_cst, align 8
  store atomic i64 %31, i64* %12 seq_cst, align 8
  %32 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %2, i64 0, i32 0, i32 1
  %33 = icmp eq %"class.std::__1::vector"* %13, %32
  br i1 %33, label %39, label %34

34:                                               ; preds = %3
  %35 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %32, i64 0, i32 0, i32 0
  %36 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %35, align 8
  %37 = getelementptr inbounds %"class.v8::internal::SingleCopyReadOnlyArtifacts", %"class.v8::internal::SingleCopyReadOnlyArtifacts"* %2, i64 0, i32 0, i32 1, i32 0, i32 1
  %38 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %37, align 8
  tail call void @_ZNSt3__16vectorIPN2v88internal12ReadOnlyPageENS_9allocatorIS4_EEE6assignIPS4_EENS_9enable_ifIXaasr27__is_cpp17_forward_iteratorIT_EE5valuesr16is_constructibleIS4_NS_15iterator_traitsISB_E9referenceEEE5valueEvE4typeESB_SB_(%"class.std::__1::vector"* %13, %"class.v8::internal::ReadOnlyPage"** %36, %"class.v8::internal::ReadOnlyPage"** %38) #15
  br label %39

39:                                               ; preds = %3, %34
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9BaseSpace15CommittedMemoryEv(%"class.v8::internal::BaseSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::BaseSpace", %"class.v8::internal::BaseSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i64, i64* %2 seq_cst, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv(%"class.v8::internal::BaseSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::BaseSpace", %"class.v8::internal::BaseSpace"* %0, i64 0, i32 4
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal13ReadOnlySpace4SizeEv(%"class.v8::internal::ReadOnlySpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlySpace", %"class.v8::internal::ReadOnlySpace"* %0, i64 0, i32 2, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i64, i64* %2 seq_cst, align 8
  ret i64 %3
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal19SharedReadOnlySpaceD2Ev(%"class.v8::internal::SharedReadOnlySpace"*) unnamed_addr #11 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal19SharedReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1
  %4 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %3, i64 0, i32 0, i32 0
  %5 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %4, align 8
  %6 = icmp eq %"class.std::__1::unique_ptr.615"* %5, null
  br i1 %6, label %30, label %7

7:                                                ; preds = %1
  %8 = bitcast %"class.std::__1::unique_ptr.615"* %5 to i8*
  %9 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1, i32 0, i32 1
  %10 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %9, align 8
  %11 = icmp eq %"class.std::__1::unique_ptr.615"* %10, %5
  br i1 %11, label %28, label %12

12:                                               ; preds = %7, %23
  %13 = phi %"class.std::__1::unique_ptr.615"* [ %14, %23 ], [ %10, %7 ]
  %14 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %13, i64 -1
  %15 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %14, i64 0, i32 0, i32 0, i32 0
  %16 = load %"class.v8::PageAllocator::SharedMemoryMapping"*, %"class.v8::PageAllocator::SharedMemoryMapping"** %15, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %15, align 8
  %17 = icmp eq %"class.v8::PageAllocator::SharedMemoryMapping"* %16, null
  br i1 %17, label %23, label %18

18:                                               ; preds = %12
  %19 = bitcast %"class.v8::PageAllocator::SharedMemoryMapping"* %16 to void (%"class.v8::PageAllocator::SharedMemoryMapping"*)***
  %20 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)**, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*** %19, align 8
  %21 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %20, i64 1
  %22 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %21, align 8
  tail call void %22(%"class.v8::PageAllocator::SharedMemoryMapping"* nonnull %16) #15
  br label %23

23:                                               ; preds = %18, %12
  %24 = icmp eq %"class.std::__1::unique_ptr.615"* %14, %5
  br i1 %24, label %25, label %12

25:                                               ; preds = %23
  %26 = bitcast %"class.std::__1::vector.613"* %3 to i8**
  %27 = load i8*, i8** %26, align 8
  br label %28

28:                                               ; preds = %25, %7
  %29 = phi i8* [ %27, %25 ], [ %8, %7 ]
  store %"class.std::__1::unique_ptr.615"* %5, %"class.std::__1::unique_ptr.615"** %9, align 8
  tail call void @_ZdlPv(i8* %29) #16
  br label %30

30:                                               ; preds = %1, %28
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %31 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0
  %32 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %31, align 8
  %33 = icmp eq %"class.v8::internal::ReadOnlyPage"** %32, null
  br i1 %33, label %39, label %34

34:                                               ; preds = %30
  %35 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %32 to i64
  %36 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 1
  %37 = bitcast %"class.v8::internal::ReadOnlyPage"*** %36 to i64*
  store i64 %35, i64* %37, align 8
  %38 = bitcast %"class.v8::internal::ReadOnlyPage"** %32 to i8*
  tail call void @_ZdlPv(i8* %38) #16
  br label %39

39:                                               ; preds = %30, %34
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal19SharedReadOnlySpaceD0Ev(%"class.v8::internal::SharedReadOnlySpace"*) unnamed_addr #11 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal19SharedReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1
  %4 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %3, i64 0, i32 0, i32 0
  %5 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %4, align 8
  %6 = icmp eq %"class.std::__1::unique_ptr.615"* %5, null
  br i1 %6, label %30, label %7

7:                                                ; preds = %1
  %8 = bitcast %"class.std::__1::unique_ptr.615"* %5 to i8*
  %9 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 1, i32 0, i32 1
  %10 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %9, align 8
  %11 = icmp eq %"class.std::__1::unique_ptr.615"* %10, %5
  br i1 %11, label %28, label %12

12:                                               ; preds = %7, %23
  %13 = phi %"class.std::__1::unique_ptr.615"* [ %14, %23 ], [ %10, %7 ]
  %14 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %13, i64 -1
  %15 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %14, i64 0, i32 0, i32 0, i32 0
  %16 = load %"class.v8::PageAllocator::SharedMemoryMapping"*, %"class.v8::PageAllocator::SharedMemoryMapping"** %15, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %15, align 8
  %17 = icmp eq %"class.v8::PageAllocator::SharedMemoryMapping"* %16, null
  br i1 %17, label %23, label %18

18:                                               ; preds = %12
  %19 = bitcast %"class.v8::PageAllocator::SharedMemoryMapping"* %16 to void (%"class.v8::PageAllocator::SharedMemoryMapping"*)***
  %20 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)**, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*** %19, align 8
  %21 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %20, i64 1
  %22 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %21, align 8
  tail call void %22(%"class.v8::PageAllocator::SharedMemoryMapping"* nonnull %16) #15
  br label %23

23:                                               ; preds = %18, %12
  %24 = icmp eq %"class.std::__1::unique_ptr.615"* %14, %5
  br i1 %24, label %25, label %12

25:                                               ; preds = %23
  %26 = bitcast %"class.std::__1::vector.613"* %3 to i8**
  %27 = load i8*, i8** %26, align 8
  br label %28

28:                                               ; preds = %25, %7
  %29 = phi i8* [ %27, %25 ], [ %8, %7 ]
  store %"class.std::__1::unique_ptr.615"* %5, %"class.std::__1::unique_ptr.615"** %9, align 8
  tail call void @_ZdlPv(i8* %29) #16
  br label %30

30:                                               ; preds = %28, %1
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [9 x i8*] }, { [9 x i8*] }* @_ZTVN2v88internal13ReadOnlySpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %31 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0
  %32 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %31, align 8
  %33 = icmp eq %"class.v8::internal::ReadOnlyPage"** %32, null
  br i1 %33, label %39, label %34

34:                                               ; preds = %30
  %35 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %32 to i64
  %36 = getelementptr inbounds %"class.v8::internal::SharedReadOnlySpace", %"class.v8::internal::SharedReadOnlySpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 1
  %37 = bitcast %"class.v8::internal::ReadOnlyPage"*** %36 to i64*
  store i64 %35, i64* %37, align 8
  %38 = bitcast %"class.v8::internal::ReadOnlyPage"** %32 to i8*
  tail call void @_ZdlPv(i8* %38) #16
  br label %39

39:                                               ; preds = %30, %34
  %40 = bitcast %"class.v8::internal::SharedReadOnlySpace"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %40) #15
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal34PointerCompressedReadOnlyArtifactsD2Ev(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*) unnamed_addr #11 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [8 x i8*] }, { [8 x i8*] }* @_ZTVN2v88internal34PointerCompressedReadOnlyArtifactsE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3
  %4 = getelementptr inbounds %"class.std::__1::vector.1140", %"class.std::__1::vector.1140"* %3, i64 0, i32 0, i32 0
  %5 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %4, align 8
  %6 = icmp eq %"class.std::__1::unique_ptr.1142"* %5, null
  br i1 %6, label %30, label %7

7:                                                ; preds = %1
  %8 = bitcast %"class.std::__1::unique_ptr.1142"* %5 to i8*
  %9 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3, i32 0, i32 1
  %10 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %9, align 8
  %11 = icmp eq %"class.std::__1::unique_ptr.1142"* %10, %5
  br i1 %11, label %28, label %12

12:                                               ; preds = %7, %23
  %13 = phi %"class.std::__1::unique_ptr.1142"* [ %14, %23 ], [ %10, %7 ]
  %14 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %13, i64 -1
  %15 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %14, i64 0, i32 0, i32 0, i32 0
  %16 = load %"class.v8::PageAllocator::SharedMemory"*, %"class.v8::PageAllocator::SharedMemory"** %15, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %15, align 8
  %17 = icmp eq %"class.v8::PageAllocator::SharedMemory"* %16, null
  br i1 %17, label %23, label %18

18:                                               ; preds = %12
  %19 = bitcast %"class.v8::PageAllocator::SharedMemory"* %16 to void (%"class.v8::PageAllocator::SharedMemory"*)***
  %20 = load void (%"class.v8::PageAllocator::SharedMemory"*)**, void (%"class.v8::PageAllocator::SharedMemory"*)*** %19, align 8
  %21 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemory"*)*, void (%"class.v8::PageAllocator::SharedMemory"*)** %20, i64 1
  %22 = load void (%"class.v8::PageAllocator::SharedMemory"*)*, void (%"class.v8::PageAllocator::SharedMemory"*)** %21, align 8
  tail call void %22(%"class.v8::PageAllocator::SharedMemory"* nonnull %16) #15
  br label %23

23:                                               ; preds = %18, %12
  %24 = icmp eq %"class.std::__1::unique_ptr.1142"* %14, %5
  br i1 %24, label %25, label %12

25:                                               ; preds = %23
  %26 = bitcast %"class.std::__1::vector.1140"* %3 to i8**
  %27 = load i8*, i8** %26, align 8
  br label %28

28:                                               ; preds = %25, %7
  %29 = phi i8* [ %27, %25 ], [ %8, %7 ]
  store %"class.std::__1::unique_ptr.1142"* %5, %"class.std::__1::unique_ptr.1142"** %9, align 8
  tail call void @_ZdlPv(i8* %29) #16
  br label %30

30:                                               ; preds = %1, %28
  %31 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 2, i32 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = icmp eq i32* %32, null
  br i1 %33, label %39, label %34

34:                                               ; preds = %30
  %35 = ptrtoint i32* %32 to i64
  %36 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 2, i32 0, i32 1
  %37 = bitcast i32** %36 to i64*
  store i64 %35, i64* %37, align 8
  %38 = bitcast i32* %32 to i8*
  tail call void @_ZdlPv(i8* %38) #16
  br label %39

39:                                               ; preds = %30, %34
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [8 x i8*] }, { [8 x i8*] }* @_ZTVN2v88internal17ReadOnlyArtifactsE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %40 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 4, i32 0, i32 0, i32 0
  %41 = load %"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlyHeap"** %40, align 8
  store %"class.v8::internal::ReadOnlyHeap"* null, %"class.v8::internal::ReadOnlyHeap"** %40, align 8
  %42 = icmp eq %"class.v8::internal::ReadOnlyHeap"* %41, null
  br i1 %42, label %48, label %43

43:                                               ; preds = %39
  %44 = bitcast %"class.v8::internal::ReadOnlyHeap"* %41 to void (%"class.v8::internal::ReadOnlyHeap"*)***
  %45 = load void (%"class.v8::internal::ReadOnlyHeap"*)**, void (%"class.v8::internal::ReadOnlyHeap"*)*** %44, align 8
  %46 = getelementptr inbounds void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %45, i64 1
  %47 = load void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %46, align 8
  tail call void %47(%"class.v8::internal::ReadOnlyHeap"* nonnull %41) #15
  br label %48

48:                                               ; preds = %43, %39
  %49 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0
  %50 = load %"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::SharedReadOnlySpace"** %49, align 8
  store %"class.v8::internal::SharedReadOnlySpace"* null, %"class.v8::internal::SharedReadOnlySpace"** %49, align 8
  %51 = icmp eq %"class.v8::internal::SharedReadOnlySpace"* %50, null
  br i1 %51, label %57, label %52

52:                                               ; preds = %48
  %53 = bitcast %"class.v8::internal::SharedReadOnlySpace"* %50 to void (%"class.v8::internal::SharedReadOnlySpace"*)***
  %54 = load void (%"class.v8::internal::SharedReadOnlySpace"*)**, void (%"class.v8::internal::SharedReadOnlySpace"*)*** %53, align 8
  %55 = getelementptr inbounds void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %54, i64 5
  %56 = load void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %55, align 8
  tail call void %56(%"class.v8::internal::SharedReadOnlySpace"* nonnull %50) #15
  br label %57

57:                                               ; preds = %52, %48
  %58 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %59 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %58, align 8
  %60 = icmp eq %"class.v8::internal::ReadOnlyPage"** %59, null
  br i1 %60, label %66, label %61

61:                                               ; preds = %57
  %62 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %59 to i64
  %63 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 1
  %64 = bitcast %"class.v8::internal::ReadOnlyPage"*** %63 to i64*
  store i64 %62, i64* %64, align 8
  %65 = bitcast %"class.v8::internal::ReadOnlyPage"** %59 to i8*
  tail call void @_ZdlPv(i8* %65) #16
  br label %66

66:                                               ; preds = %57, %61
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal34PointerCompressedReadOnlyArtifactsD0Ev(%"class.v8::internal::PointerCompressedReadOnlyArtifacts"*) unnamed_addr #11 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [8 x i8*] }, { [8 x i8*] }* @_ZTVN2v88internal34PointerCompressedReadOnlyArtifactsE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3
  %4 = getelementptr inbounds %"class.std::__1::vector.1140", %"class.std::__1::vector.1140"* %3, i64 0, i32 0, i32 0
  %5 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %4, align 8
  %6 = icmp eq %"class.std::__1::unique_ptr.1142"* %5, null
  br i1 %6, label %30, label %7

7:                                                ; preds = %1
  %8 = bitcast %"class.std::__1::unique_ptr.1142"* %5 to i8*
  %9 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 3, i32 0, i32 1
  %10 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %9, align 8
  %11 = icmp eq %"class.std::__1::unique_ptr.1142"* %10, %5
  br i1 %11, label %28, label %12

12:                                               ; preds = %7, %23
  %13 = phi %"class.std::__1::unique_ptr.1142"* [ %14, %23 ], [ %10, %7 ]
  %14 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %13, i64 -1
  %15 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %14, i64 0, i32 0, i32 0, i32 0
  %16 = load %"class.v8::PageAllocator::SharedMemory"*, %"class.v8::PageAllocator::SharedMemory"** %15, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %15, align 8
  %17 = icmp eq %"class.v8::PageAllocator::SharedMemory"* %16, null
  br i1 %17, label %23, label %18

18:                                               ; preds = %12
  %19 = bitcast %"class.v8::PageAllocator::SharedMemory"* %16 to void (%"class.v8::PageAllocator::SharedMemory"*)***
  %20 = load void (%"class.v8::PageAllocator::SharedMemory"*)**, void (%"class.v8::PageAllocator::SharedMemory"*)*** %19, align 8
  %21 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemory"*)*, void (%"class.v8::PageAllocator::SharedMemory"*)** %20, i64 1
  %22 = load void (%"class.v8::PageAllocator::SharedMemory"*)*, void (%"class.v8::PageAllocator::SharedMemory"*)** %21, align 8
  tail call void %22(%"class.v8::PageAllocator::SharedMemory"* nonnull %16) #15
  br label %23

23:                                               ; preds = %18, %12
  %24 = icmp eq %"class.std::__1::unique_ptr.1142"* %14, %5
  br i1 %24, label %25, label %12

25:                                               ; preds = %23
  %26 = bitcast %"class.std::__1::vector.1140"* %3 to i8**
  %27 = load i8*, i8** %26, align 8
  br label %28

28:                                               ; preds = %25, %7
  %29 = phi i8* [ %27, %25 ], [ %8, %7 ]
  store %"class.std::__1::unique_ptr.1142"* %5, %"class.std::__1::unique_ptr.1142"** %9, align 8
  tail call void @_ZdlPv(i8* %29) #16
  br label %30

30:                                               ; preds = %28, %1
  %31 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 2, i32 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = icmp eq i32* %32, null
  br i1 %33, label %39, label %34

34:                                               ; preds = %30
  %35 = ptrtoint i32* %32 to i64
  %36 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 2, i32 0, i32 1
  %37 = bitcast i32** %36 to i64*
  store i64 %35, i64* %37, align 8
  %38 = bitcast i32* %32 to i8*
  tail call void @_ZdlPv(i8* %38) #16
  br label %39

39:                                               ; preds = %34, %30
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [8 x i8*] }, { [8 x i8*] }* @_ZTVN2v88internal17ReadOnlyArtifactsE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %40 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 4, i32 0, i32 0, i32 0
  %41 = load %"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlyHeap"** %40, align 8
  store %"class.v8::internal::ReadOnlyHeap"* null, %"class.v8::internal::ReadOnlyHeap"** %40, align 8
  %42 = icmp eq %"class.v8::internal::ReadOnlyHeap"* %41, null
  br i1 %42, label %48, label %43

43:                                               ; preds = %39
  %44 = bitcast %"class.v8::internal::ReadOnlyHeap"* %41 to void (%"class.v8::internal::ReadOnlyHeap"*)***
  %45 = load void (%"class.v8::internal::ReadOnlyHeap"*)**, void (%"class.v8::internal::ReadOnlyHeap"*)*** %44, align 8
  %46 = getelementptr inbounds void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %45, i64 1
  %47 = load void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %46, align 8
  tail call void %47(%"class.v8::internal::ReadOnlyHeap"* nonnull %41) #15
  br label %48

48:                                               ; preds = %43, %39
  %49 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0
  %50 = load %"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::SharedReadOnlySpace"** %49, align 8
  store %"class.v8::internal::SharedReadOnlySpace"* null, %"class.v8::internal::SharedReadOnlySpace"** %49, align 8
  %51 = icmp eq %"class.v8::internal::SharedReadOnlySpace"* %50, null
  br i1 %51, label %57, label %52

52:                                               ; preds = %48
  %53 = bitcast %"class.v8::internal::SharedReadOnlySpace"* %50 to void (%"class.v8::internal::SharedReadOnlySpace"*)***
  %54 = load void (%"class.v8::internal::SharedReadOnlySpace"*)**, void (%"class.v8::internal::SharedReadOnlySpace"*)*** %53, align 8
  %55 = getelementptr inbounds void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %54, i64 5
  %56 = load void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %55, align 8
  tail call void %56(%"class.v8::internal::SharedReadOnlySpace"* nonnull %50) #15
  br label %57

57:                                               ; preds = %52, %48
  %58 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %59 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %58, align 8
  %60 = icmp eq %"class.v8::internal::ReadOnlyPage"** %59, null
  br i1 %60, label %66, label %61

61:                                               ; preds = %57
  %62 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %59 to i64
  %63 = getelementptr inbounds %"class.v8::internal::PointerCompressedReadOnlyArtifacts", %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0, i64 0, i32 0, i32 1, i32 0, i32 1
  %64 = bitcast %"class.v8::internal::ReadOnlyPage"*** %63 to i64*
  store i64 %62, i64* %64, align 8
  %65 = bitcast %"class.v8::internal::ReadOnlyPage"** %59 to i8*
  tail call void @_ZdlPv(i8* %65) #16
  br label %66

66:                                               ; preds = %57, %61
  %67 = bitcast %"class.v8::internal::PointerCompressedReadOnlyArtifacts"* %0 to i8*
  tail call void @_ZdlPv(i8* %67) #16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal17ReadOnlyArtifactsD2Ev(%"class.v8::internal::ReadOnlyArtifacts"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::ReadOnlyArtifacts", %"class.v8::internal::ReadOnlyArtifacts"* %0, i64 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [8 x i8*] }, { [8 x i8*] }* @_ZTVN2v88internal17ReadOnlyArtifactsE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::ReadOnlyArtifacts", %"class.v8::internal::ReadOnlyArtifacts"* %0, i64 0, i32 4, i32 0, i32 0, i32 0
  %4 = load %"class.v8::internal::ReadOnlyHeap"*, %"class.v8::internal::ReadOnlyHeap"** %3, align 8
  store %"class.v8::internal::ReadOnlyHeap"* null, %"class.v8::internal::ReadOnlyHeap"** %3, align 8
  %5 = icmp eq %"class.v8::internal::ReadOnlyHeap"* %4, null
  br i1 %5, label %11, label %6

6:                                                ; preds = %1
  %7 = bitcast %"class.v8::internal::ReadOnlyHeap"* %4 to void (%"class.v8::internal::ReadOnlyHeap"*)***
  %8 = load void (%"class.v8::internal::ReadOnlyHeap"*)**, void (%"class.v8::internal::ReadOnlyHeap"*)*** %7, align 8
  %9 = getelementptr inbounds void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %8, i64 1
  %10 = load void (%"class.v8::internal::ReadOnlyHeap"*)*, void (%"class.v8::internal::ReadOnlyHeap"*)** %9, align 8
  tail call void %10(%"class.v8::internal::ReadOnlyHeap"* nonnull %4) #15
  br label %11

11:                                               ; preds = %1, %6
  %12 = getelementptr inbounds %"class.v8::internal::ReadOnlyArtifacts", %"class.v8::internal::ReadOnlyArtifacts"* %0, i64 0, i32 3, i32 0, i32 0, i32 0
  %13 = load %"class.v8::internal::SharedReadOnlySpace"*, %"class.v8::internal::SharedReadOnlySpace"** %12, align 8
  store %"class.v8::internal::SharedReadOnlySpace"* null, %"class.v8::internal::SharedReadOnlySpace"** %12, align 8
  %14 = icmp eq %"class.v8::internal::SharedReadOnlySpace"* %13, null
  br i1 %14, label %20, label %15

15:                                               ; preds = %11
  %16 = bitcast %"class.v8::internal::SharedReadOnlySpace"* %13 to void (%"class.v8::internal::SharedReadOnlySpace"*)***
  %17 = load void (%"class.v8::internal::SharedReadOnlySpace"*)**, void (%"class.v8::internal::SharedReadOnlySpace"*)*** %16, align 8
  %18 = getelementptr inbounds void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %17, i64 5
  %19 = load void (%"class.v8::internal::SharedReadOnlySpace"*)*, void (%"class.v8::internal::SharedReadOnlySpace"*)** %18, align 8
  tail call void %19(%"class.v8::internal::SharedReadOnlySpace"* nonnull %13) #15
  br label %20

20:                                               ; preds = %11, %15
  %21 = getelementptr inbounds %"class.v8::internal::ReadOnlyArtifacts", %"class.v8::internal::ReadOnlyArtifacts"* %0, i64 0, i32 1, i32 0, i32 0
  %22 = load %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"*** %21, align 8
  %23 = icmp eq %"class.v8::internal::ReadOnlyPage"** %22, null
  br i1 %23, label %29, label %24

24:                                               ; preds = %20
  %25 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %22 to i64
  %26 = getelementptr inbounds %"class.v8::internal::ReadOnlyArtifacts", %"class.v8::internal::ReadOnlyArtifacts"* %0, i64 0, i32 1, i32 0, i32 1
  %27 = bitcast %"class.v8::internal::ReadOnlyPage"*** %26 to i64*
  store i64 %25, i64* %27, align 8
  %28 = bitcast %"class.v8::internal::ReadOnlyPage"** %22 to i8*
  tail call void @_ZdlPv(i8* %28) #16
  br label %29

29:                                               ; preds = %20, %24
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal17ReadOnlyArtifactsD0Ev(%"class.v8::internal::ReadOnlyArtifacts"*) unnamed_addr #0 comdat align 2 {
  tail call void @llvm.trap() #14
  unreachable
}

declare void @__cxa_pure_virtual() unnamed_addr

; Function Attrs: cold noreturn nounwind
declare void @llvm.trap() #12

declare zeroext i1 @_ZN2v88internal14SetPermissionsEPNS_13PageAllocatorEPvmNS1_10PermissionE(%"class.v8::PageAllocator"*, i8*, i64, i32) local_unnamed_addr #6

declare i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"*, i64) local_unnamed_addr #6

; Function Attrs: noreturn
declare void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"*) local_unnamed_addr #3

; Function Attrs: noreturn nounwind
declare void @abort() local_unnamed_addr #13

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__16vectorINS_10unique_ptrIN2v813PageAllocator19SharedMemoryMappingENS_14default_deleteIS4_EEEENS_9allocatorIS7_EEE21__push_back_slow_pathIS7_EEvOT_(%"class.std::__1::vector.613"*, %"class.std::__1::unique_ptr.615"* dereferenceable(8)) local_unnamed_addr #11 comdat align 2 {
  %3 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %0, i64 0, i32 0, i32 1
  %4 = bitcast %"class.std::__1::unique_ptr.615"** %3 to i64*
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.std::__1::vector.613"* %0 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = sub i64 %5, %7
  %9 = ashr exact i64 %8, 3
  %10 = add nsw i64 %9, 1
  %11 = icmp ugt i64 %10, 2305843009213693951
  br i1 %11, label %12, label %14

12:                                               ; preds = %2
  %13 = bitcast %"class.std::__1::vector.613"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %13) #14
  unreachable

14:                                               ; preds = %2
  %15 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %0, i64 0, i32 0, i32 2, i32 0, i32 0
  %16 = bitcast %"class.std::__1::unique_ptr.615"** %15 to i64*
  %17 = load i64, i64* %16, align 8
  %18 = sub i64 %17, %7
  %19 = ashr exact i64 %18, 3
  %20 = icmp ult i64 %19, 1152921504606846975
  br i1 %20, label %21, label %29

21:                                               ; preds = %14
  %22 = ashr exact i64 %18, 2
  %23 = icmp ult i64 %22, %10
  %24 = select i1 %23, i64 %10, i64 %22
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %34, label %26

26:                                               ; preds = %21
  %27 = icmp ugt i64 %24, 2305843009213693951
  br i1 %27, label %28, label %29

28:                                               ; preds = %26
  tail call void @abort() #14
  unreachable

29:                                               ; preds = %14, %26
  %30 = phi i64 [ %24, %26 ], [ 2305843009213693951, %14 ]
  %31 = shl i64 %30, 3
  %32 = tail call i8* @_Znwm(i64 %31) #16
  %33 = bitcast i8* %32 to %"class.std::__1::unique_ptr.615"*
  br label %34

34:                                               ; preds = %21, %29
  %35 = phi i64 [ %30, %29 ], [ 0, %21 ]
  %36 = phi %"class.std::__1::unique_ptr.615"* [ %33, %29 ], [ null, %21 ]
  %37 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %36, i64 %9
  %38 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %36, i64 %35
  %39 = ptrtoint %"class.std::__1::unique_ptr.615"* %38 to i64
  %40 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %1, i64 0, i32 0, i32 0, i32 0
  %41 = bitcast %"class.std::__1::unique_ptr.615"* %1 to i64*
  %42 = load i64, i64* %41, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %40, align 8
  %43 = bitcast %"class.std::__1::unique_ptr.615"* %37 to i64*
  store i64 %42, i64* %43, align 8
  %44 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %37, i64 1
  %45 = ptrtoint %"class.std::__1::unique_ptr.615"* %44 to i64
  %46 = getelementptr inbounds %"class.std::__1::vector.613", %"class.std::__1::vector.613"* %0, i64 0, i32 0, i32 0
  %47 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %46, align 8
  %48 = ptrtoint %"class.std::__1::unique_ptr.615"* %47 to i64
  %49 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %3, align 8
  %50 = icmp eq %"class.std::__1::unique_ptr.615"* %49, %47
  br i1 %50, label %132, label %51

51:                                               ; preds = %34
  %52 = getelementptr %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %49, i64 -1, i32 0, i32 0, i32 0
  %53 = ptrtoint %"class.v8::PageAllocator::SharedMemoryMapping"** %52 to i64
  %54 = sub i64 %53, %48
  %55 = lshr i64 %54, 3
  %56 = add nuw nsw i64 %55, 1
  %57 = and i64 %56, 7
  %58 = icmp eq i64 %57, 0
  br i1 %58, label %71, label %59

59:                                               ; preds = %51, %59
  %60 = phi %"class.std::__1::unique_ptr.615"* [ %63, %59 ], [ %37, %51 ]
  %61 = phi %"class.std::__1::unique_ptr.615"* [ %64, %59 ], [ %49, %51 ]
  %62 = phi i64 [ %69, %59 ], [ %57, %51 ]
  %63 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %60, i64 -1
  %64 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %61, i64 -1
  %65 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %64, i64 0, i32 0, i32 0, i32 0
  %66 = bitcast %"class.std::__1::unique_ptr.615"* %64 to i64*
  %67 = load i64, i64* %66, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %65, align 8
  %68 = bitcast %"class.std::__1::unique_ptr.615"* %63 to i64*
  store i64 %67, i64* %68, align 8
  %69 = add i64 %62, -1
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %71, label %59, !llvm.loop !8

71:                                               ; preds = %59, %51
  %72 = phi %"class.std::__1::unique_ptr.615"* [ undef, %51 ], [ %63, %59 ]
  %73 = phi %"class.std::__1::unique_ptr.615"* [ %37, %51 ], [ %63, %59 ]
  %74 = phi %"class.std::__1::unique_ptr.615"* [ %49, %51 ], [ %64, %59 ]
  %75 = icmp ult i64 %54, 56
  br i1 %75, label %128, label %76

76:                                               ; preds = %71, %76
  %77 = phi %"class.std::__1::unique_ptr.615"* [ %121, %76 ], [ %73, %71 ]
  %78 = phi %"class.std::__1::unique_ptr.615"* [ %122, %76 ], [ %74, %71 ]
  %79 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %77, i64 -1
  %80 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %78, i64 -1
  %81 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %80, i64 0, i32 0, i32 0, i32 0
  %82 = bitcast %"class.std::__1::unique_ptr.615"* %80 to i64*
  %83 = load i64, i64* %82, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %81, align 8
  %84 = bitcast %"class.std::__1::unique_ptr.615"* %79 to i64*
  store i64 %83, i64* %84, align 8
  %85 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %77, i64 -2
  %86 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %78, i64 -2
  %87 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %86, i64 0, i32 0, i32 0, i32 0
  %88 = bitcast %"class.std::__1::unique_ptr.615"* %86 to i64*
  %89 = load i64, i64* %88, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %87, align 8
  %90 = bitcast %"class.std::__1::unique_ptr.615"* %85 to i64*
  store i64 %89, i64* %90, align 8
  %91 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %77, i64 -3
  %92 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %78, i64 -3
  %93 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %92, i64 0, i32 0, i32 0, i32 0
  %94 = bitcast %"class.std::__1::unique_ptr.615"* %92 to i64*
  %95 = load i64, i64* %94, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %93, align 8
  %96 = bitcast %"class.std::__1::unique_ptr.615"* %91 to i64*
  store i64 %95, i64* %96, align 8
  %97 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %77, i64 -4
  %98 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %78, i64 -4
  %99 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %98, i64 0, i32 0, i32 0, i32 0
  %100 = bitcast %"class.std::__1::unique_ptr.615"* %98 to i64*
  %101 = load i64, i64* %100, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %99, align 8
  %102 = bitcast %"class.std::__1::unique_ptr.615"* %97 to i64*
  store i64 %101, i64* %102, align 8
  %103 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %77, i64 -5
  %104 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %78, i64 -5
  %105 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %104, i64 0, i32 0, i32 0, i32 0
  %106 = bitcast %"class.std::__1::unique_ptr.615"* %104 to i64*
  %107 = load i64, i64* %106, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %105, align 8
  %108 = bitcast %"class.std::__1::unique_ptr.615"* %103 to i64*
  store i64 %107, i64* %108, align 8
  %109 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %77, i64 -6
  %110 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %78, i64 -6
  %111 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %110, i64 0, i32 0, i32 0, i32 0
  %112 = bitcast %"class.std::__1::unique_ptr.615"* %110 to i64*
  %113 = load i64, i64* %112, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %111, align 8
  %114 = bitcast %"class.std::__1::unique_ptr.615"* %109 to i64*
  store i64 %113, i64* %114, align 8
  %115 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %77, i64 -7
  %116 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %78, i64 -7
  %117 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %116, i64 0, i32 0, i32 0, i32 0
  %118 = bitcast %"class.std::__1::unique_ptr.615"* %116 to i64*
  %119 = load i64, i64* %118, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %117, align 8
  %120 = bitcast %"class.std::__1::unique_ptr.615"* %115 to i64*
  store i64 %119, i64* %120, align 8
  %121 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %77, i64 -8
  %122 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %78, i64 -8
  %123 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %122, i64 0, i32 0, i32 0, i32 0
  %124 = bitcast %"class.std::__1::unique_ptr.615"* %122 to i64*
  %125 = load i64, i64* %124, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %123, align 8
  %126 = bitcast %"class.std::__1::unique_ptr.615"* %121 to i64*
  store i64 %125, i64* %126, align 8
  %127 = icmp eq %"class.std::__1::unique_ptr.615"* %122, %47
  br i1 %127, label %128, label %76

128:                                              ; preds = %76, %71
  %129 = phi %"class.std::__1::unique_ptr.615"* [ %72, %71 ], [ %121, %76 ]
  %130 = load i64, i64* %6, align 8
  %131 = load %"class.std::__1::unique_ptr.615"*, %"class.std::__1::unique_ptr.615"** %3, align 8
  br label %132

132:                                              ; preds = %34, %128
  %133 = phi %"class.std::__1::unique_ptr.615"* [ %131, %128 ], [ %47, %34 ]
  %134 = phi %"class.std::__1::unique_ptr.615"* [ %129, %128 ], [ %37, %34 ]
  %135 = phi i64 [ %130, %128 ], [ %48, %34 ]
  %136 = ptrtoint %"class.std::__1::unique_ptr.615"* %134 to i64
  store i64 %136, i64* %6, align 8
  store i64 %45, i64* %4, align 8
  store i64 %39, i64* %16, align 8
  %137 = inttoptr i64 %135 to %"class.std::__1::unique_ptr.615"*
  %138 = icmp eq %"class.std::__1::unique_ptr.615"* %133, %137
  br i1 %138, label %152, label %139

139:                                              ; preds = %132, %150
  %140 = phi %"class.std::__1::unique_ptr.615"* [ %141, %150 ], [ %133, %132 ]
  %141 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %140, i64 -1
  %142 = getelementptr inbounds %"class.std::__1::unique_ptr.615", %"class.std::__1::unique_ptr.615"* %141, i64 0, i32 0, i32 0, i32 0
  %143 = load %"class.v8::PageAllocator::SharedMemoryMapping"*, %"class.v8::PageAllocator::SharedMemoryMapping"** %142, align 8
  store %"class.v8::PageAllocator::SharedMemoryMapping"* null, %"class.v8::PageAllocator::SharedMemoryMapping"** %142, align 8
  %144 = icmp eq %"class.v8::PageAllocator::SharedMemoryMapping"* %143, null
  br i1 %144, label %150, label %145

145:                                              ; preds = %139
  %146 = bitcast %"class.v8::PageAllocator::SharedMemoryMapping"* %143 to void (%"class.v8::PageAllocator::SharedMemoryMapping"*)***
  %147 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)**, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*** %146, align 8
  %148 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %147, i64 1
  %149 = load void (%"class.v8::PageAllocator::SharedMemoryMapping"*)*, void (%"class.v8::PageAllocator::SharedMemoryMapping"*)** %148, align 8
  tail call void %149(%"class.v8::PageAllocator::SharedMemoryMapping"* nonnull %143) #15
  br label %150

150:                                              ; preds = %145, %139
  %151 = icmp eq %"class.std::__1::unique_ptr.615"* %141, %137
  br i1 %151, label %152, label %139

152:                                              ; preds = %150, %132
  %153 = icmp eq i64 %135, 0
  br i1 %153, label %156, label %154

154:                                              ; preds = %152
  %155 = inttoptr i64 %135 to i8*
  tail call void @_ZdlPv(i8* %155) #16
  br label %156

156:                                              ; preds = %152, %154
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__16vectorINS_10unique_ptrIN2v813PageAllocator12SharedMemoryENS_14default_deleteIS4_EEEENS_9allocatorIS7_EEE21__push_back_slow_pathIS7_EEvOT_(%"class.std::__1::vector.1140"*, %"class.std::__1::unique_ptr.1142"* dereferenceable(8)) local_unnamed_addr #11 comdat align 2 {
  %3 = getelementptr inbounds %"class.std::__1::vector.1140", %"class.std::__1::vector.1140"* %0, i64 0, i32 0, i32 1
  %4 = bitcast %"class.std::__1::unique_ptr.1142"** %3 to i64*
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.std::__1::vector.1140"* %0 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = sub i64 %5, %7
  %9 = ashr exact i64 %8, 3
  %10 = add nsw i64 %9, 1
  %11 = icmp ugt i64 %10, 2305843009213693951
  br i1 %11, label %12, label %14

12:                                               ; preds = %2
  %13 = bitcast %"class.std::__1::vector.1140"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %13) #14
  unreachable

14:                                               ; preds = %2
  %15 = getelementptr inbounds %"class.std::__1::vector.1140", %"class.std::__1::vector.1140"* %0, i64 0, i32 0, i32 2, i32 0, i32 0
  %16 = bitcast %"class.std::__1::unique_ptr.1142"** %15 to i64*
  %17 = load i64, i64* %16, align 8
  %18 = sub i64 %17, %7
  %19 = ashr exact i64 %18, 3
  %20 = icmp ult i64 %19, 1152921504606846975
  br i1 %20, label %21, label %29

21:                                               ; preds = %14
  %22 = ashr exact i64 %18, 2
  %23 = icmp ult i64 %22, %10
  %24 = select i1 %23, i64 %10, i64 %22
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %34, label %26

26:                                               ; preds = %21
  %27 = icmp ugt i64 %24, 2305843009213693951
  br i1 %27, label %28, label %29

28:                                               ; preds = %26
  tail call void @abort() #14
  unreachable

29:                                               ; preds = %14, %26
  %30 = phi i64 [ %24, %26 ], [ 2305843009213693951, %14 ]
  %31 = shl i64 %30, 3
  %32 = tail call i8* @_Znwm(i64 %31) #16
  %33 = bitcast i8* %32 to %"class.std::__1::unique_ptr.1142"*
  br label %34

34:                                               ; preds = %21, %29
  %35 = phi i64 [ %30, %29 ], [ 0, %21 ]
  %36 = phi %"class.std::__1::unique_ptr.1142"* [ %33, %29 ], [ null, %21 ]
  %37 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %36, i64 %9
  %38 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %36, i64 %35
  %39 = ptrtoint %"class.std::__1::unique_ptr.1142"* %38 to i64
  %40 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %1, i64 0, i32 0, i32 0, i32 0
  %41 = bitcast %"class.std::__1::unique_ptr.1142"* %1 to i64*
  %42 = load i64, i64* %41, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %40, align 8
  %43 = bitcast %"class.std::__1::unique_ptr.1142"* %37 to i64*
  store i64 %42, i64* %43, align 8
  %44 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %37, i64 1
  %45 = ptrtoint %"class.std::__1::unique_ptr.1142"* %44 to i64
  %46 = getelementptr inbounds %"class.std::__1::vector.1140", %"class.std::__1::vector.1140"* %0, i64 0, i32 0, i32 0
  %47 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %46, align 8
  %48 = ptrtoint %"class.std::__1::unique_ptr.1142"* %47 to i64
  %49 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %3, align 8
  %50 = icmp eq %"class.std::__1::unique_ptr.1142"* %49, %47
  br i1 %50, label %132, label %51

51:                                               ; preds = %34
  %52 = getelementptr %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %49, i64 -1, i32 0, i32 0, i32 0
  %53 = ptrtoint %"class.v8::PageAllocator::SharedMemory"** %52 to i64
  %54 = sub i64 %53, %48
  %55 = lshr i64 %54, 3
  %56 = add nuw nsw i64 %55, 1
  %57 = and i64 %56, 7
  %58 = icmp eq i64 %57, 0
  br i1 %58, label %71, label %59

59:                                               ; preds = %51, %59
  %60 = phi %"class.std::__1::unique_ptr.1142"* [ %63, %59 ], [ %37, %51 ]
  %61 = phi %"class.std::__1::unique_ptr.1142"* [ %64, %59 ], [ %49, %51 ]
  %62 = phi i64 [ %69, %59 ], [ %57, %51 ]
  %63 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %60, i64 -1
  %64 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %61, i64 -1
  %65 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %64, i64 0, i32 0, i32 0, i32 0
  %66 = bitcast %"class.std::__1::unique_ptr.1142"* %64 to i64*
  %67 = load i64, i64* %66, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %65, align 8
  %68 = bitcast %"class.std::__1::unique_ptr.1142"* %63 to i64*
  store i64 %67, i64* %68, align 8
  %69 = add i64 %62, -1
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %71, label %59, !llvm.loop !9

71:                                               ; preds = %59, %51
  %72 = phi %"class.std::__1::unique_ptr.1142"* [ undef, %51 ], [ %63, %59 ]
  %73 = phi %"class.std::__1::unique_ptr.1142"* [ %37, %51 ], [ %63, %59 ]
  %74 = phi %"class.std::__1::unique_ptr.1142"* [ %49, %51 ], [ %64, %59 ]
  %75 = icmp ult i64 %54, 56
  br i1 %75, label %128, label %76

76:                                               ; preds = %71, %76
  %77 = phi %"class.std::__1::unique_ptr.1142"* [ %121, %76 ], [ %73, %71 ]
  %78 = phi %"class.std::__1::unique_ptr.1142"* [ %122, %76 ], [ %74, %71 ]
  %79 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %77, i64 -1
  %80 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %78, i64 -1
  %81 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %80, i64 0, i32 0, i32 0, i32 0
  %82 = bitcast %"class.std::__1::unique_ptr.1142"* %80 to i64*
  %83 = load i64, i64* %82, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %81, align 8
  %84 = bitcast %"class.std::__1::unique_ptr.1142"* %79 to i64*
  store i64 %83, i64* %84, align 8
  %85 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %77, i64 -2
  %86 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %78, i64 -2
  %87 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %86, i64 0, i32 0, i32 0, i32 0
  %88 = bitcast %"class.std::__1::unique_ptr.1142"* %86 to i64*
  %89 = load i64, i64* %88, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %87, align 8
  %90 = bitcast %"class.std::__1::unique_ptr.1142"* %85 to i64*
  store i64 %89, i64* %90, align 8
  %91 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %77, i64 -3
  %92 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %78, i64 -3
  %93 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %92, i64 0, i32 0, i32 0, i32 0
  %94 = bitcast %"class.std::__1::unique_ptr.1142"* %92 to i64*
  %95 = load i64, i64* %94, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %93, align 8
  %96 = bitcast %"class.std::__1::unique_ptr.1142"* %91 to i64*
  store i64 %95, i64* %96, align 8
  %97 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %77, i64 -4
  %98 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %78, i64 -4
  %99 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %98, i64 0, i32 0, i32 0, i32 0
  %100 = bitcast %"class.std::__1::unique_ptr.1142"* %98 to i64*
  %101 = load i64, i64* %100, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %99, align 8
  %102 = bitcast %"class.std::__1::unique_ptr.1142"* %97 to i64*
  store i64 %101, i64* %102, align 8
  %103 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %77, i64 -5
  %104 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %78, i64 -5
  %105 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %104, i64 0, i32 0, i32 0, i32 0
  %106 = bitcast %"class.std::__1::unique_ptr.1142"* %104 to i64*
  %107 = load i64, i64* %106, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %105, align 8
  %108 = bitcast %"class.std::__1::unique_ptr.1142"* %103 to i64*
  store i64 %107, i64* %108, align 8
  %109 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %77, i64 -6
  %110 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %78, i64 -6
  %111 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %110, i64 0, i32 0, i32 0, i32 0
  %112 = bitcast %"class.std::__1::unique_ptr.1142"* %110 to i64*
  %113 = load i64, i64* %112, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %111, align 8
  %114 = bitcast %"class.std::__1::unique_ptr.1142"* %109 to i64*
  store i64 %113, i64* %114, align 8
  %115 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %77, i64 -7
  %116 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %78, i64 -7
  %117 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %116, i64 0, i32 0, i32 0, i32 0
  %118 = bitcast %"class.std::__1::unique_ptr.1142"* %116 to i64*
  %119 = load i64, i64* %118, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %117, align 8
  %120 = bitcast %"class.std::__1::unique_ptr.1142"* %115 to i64*
  store i64 %119, i64* %120, align 8
  %121 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %77, i64 -8
  %122 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %78, i64 -8
  %123 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %122, i64 0, i32 0, i32 0, i32 0
  %124 = bitcast %"class.std::__1::unique_ptr.1142"* %122 to i64*
  %125 = load i64, i64* %124, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %123, align 8
  %126 = bitcast %"class.std::__1::unique_ptr.1142"* %121 to i64*
  store i64 %125, i64* %126, align 8
  %127 = icmp eq %"class.std::__1::unique_ptr.1142"* %122, %47
  br i1 %127, label %128, label %76

128:                                              ; preds = %76, %71
  %129 = phi %"class.std::__1::unique_ptr.1142"* [ %72, %71 ], [ %121, %76 ]
  %130 = load i64, i64* %6, align 8
  %131 = load %"class.std::__1::unique_ptr.1142"*, %"class.std::__1::unique_ptr.1142"** %3, align 8
  br label %132

132:                                              ; preds = %34, %128
  %133 = phi %"class.std::__1::unique_ptr.1142"* [ %131, %128 ], [ %47, %34 ]
  %134 = phi %"class.std::__1::unique_ptr.1142"* [ %129, %128 ], [ %37, %34 ]
  %135 = phi i64 [ %130, %128 ], [ %48, %34 ]
  %136 = ptrtoint %"class.std::__1::unique_ptr.1142"* %134 to i64
  store i64 %136, i64* %6, align 8
  store i64 %45, i64* %4, align 8
  store i64 %39, i64* %16, align 8
  %137 = inttoptr i64 %135 to %"class.std::__1::unique_ptr.1142"*
  %138 = icmp eq %"class.std::__1::unique_ptr.1142"* %133, %137
  br i1 %138, label %152, label %139

139:                                              ; preds = %132, %150
  %140 = phi %"class.std::__1::unique_ptr.1142"* [ %141, %150 ], [ %133, %132 ]
  %141 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %140, i64 -1
  %142 = getelementptr inbounds %"class.std::__1::unique_ptr.1142", %"class.std::__1::unique_ptr.1142"* %141, i64 0, i32 0, i32 0, i32 0
  %143 = load %"class.v8::PageAllocator::SharedMemory"*, %"class.v8::PageAllocator::SharedMemory"** %142, align 8
  store %"class.v8::PageAllocator::SharedMemory"* null, %"class.v8::PageAllocator::SharedMemory"** %142, align 8
  %144 = icmp eq %"class.v8::PageAllocator::SharedMemory"* %143, null
  br i1 %144, label %150, label %145

145:                                              ; preds = %139
  %146 = bitcast %"class.v8::PageAllocator::SharedMemory"* %143 to void (%"class.v8::PageAllocator::SharedMemory"*)***
  %147 = load void (%"class.v8::PageAllocator::SharedMemory"*)**, void (%"class.v8::PageAllocator::SharedMemory"*)*** %146, align 8
  %148 = getelementptr inbounds void (%"class.v8::PageAllocator::SharedMemory"*)*, void (%"class.v8::PageAllocator::SharedMemory"*)** %147, i64 1
  %149 = load void (%"class.v8::PageAllocator::SharedMemory"*)*, void (%"class.v8::PageAllocator::SharedMemory"*)** %148, align 8
  tail call void %149(%"class.v8::PageAllocator::SharedMemory"* nonnull %143) #15
  br label %150

150:                                              ; preds = %145, %139
  %151 = icmp eq %"class.std::__1::unique_ptr.1142"* %141, %137
  br i1 %151, label %152, label %139

152:                                              ; preds = %150, %132
  %153 = icmp eq i64 %135, 0
  br i1 %153, label %156, label %154

154:                                              ; preds = %152
  %155 = inttoptr i64 %135 to i8*
  tail call void @_ZdlPv(i8* %155) #16
  br label %156

156:                                              ; preds = %152, %154
  ret void
}

; Function Attrs: nounwind
declare void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"*) local_unnamed_addr #8

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__16vectorIPN2v88internal12ReadOnlyPageENS_9allocatorIS4_EEE6assignIPS4_EENS_9enable_ifIXaasr27__is_cpp17_forward_iteratorIT_EE5valuesr16is_constructibleIS4_NS_15iterator_traitsISB_E9referenceEEE5valueEvE4typeESB_SB_(%"class.std::__1::vector"*, %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"**) local_unnamed_addr #0 comdat align 2 {
  %4 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %2 to i64
  %5 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %1 to i64
  %6 = sub i64 %4, %5
  %7 = ashr exact i64 %6, 3
  %8 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %0, i64 0, i32 0, i32 2, i32 0, i32 0
  %9 = bitcast %"class.v8::internal::ReadOnlyPage"*** %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = bitcast %"class.std::__1::vector"* %0 to i64*
  %12 = load i64, i64* %11, align 8
  %13 = sub i64 %10, %12
  %14 = ashr exact i64 %13, 3
  %15 = icmp ugt i64 %7, %14
  %16 = inttoptr i64 %12 to %"class.v8::internal::ReadOnlyPage"**
  br i1 %15, label %49, label %17

17:                                               ; preds = %3
  %18 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %0, i64 0, i32 0, i32 1
  %19 = bitcast %"class.v8::internal::ReadOnlyPage"*** %18 to i64*
  %20 = load i64, i64* %19, align 8
  %21 = sub i64 %20, %12
  %22 = ashr exact i64 %21, 3
  %23 = icmp ugt i64 %7, %22
  %24 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %1, i64 %22
  %25 = select i1 %23, %"class.v8::internal::ReadOnlyPage"** %24, %"class.v8::internal::ReadOnlyPage"** %2
  %26 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %25 to i64
  %27 = sub i64 %26, %5
  %28 = ashr exact i64 %27, 3
  %29 = icmp eq i64 %27, 0
  br i1 %29, label %33, label %30

30:                                               ; preds = %17
  %31 = inttoptr i64 %12 to i8*
  %32 = bitcast %"class.v8::internal::ReadOnlyPage"** %1 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 8 %31, i8* align 8 %32, i64 %27, i1 false) #15
  br label %33

33:                                               ; preds = %17, %30
  br i1 %23, label %34, label %47

34:                                               ; preds = %33
  %35 = load i64, i64* %19, align 8
  %36 = sub i64 %4, %26
  %37 = icmp sgt i64 %36, 0
  br i1 %37, label %38, label %45

38:                                               ; preds = %34
  %39 = lshr exact i64 %36, 3
  %40 = inttoptr i64 %35 to i8*
  %41 = bitcast %"class.v8::internal::ReadOnlyPage"** %25 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %40, i8* align 8 %41, i64 %36, i1 false) #15
  %42 = inttoptr i64 %35 to %"class.v8::internal::ReadOnlyPage"**
  %43 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %42, i64 %39
  %44 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %43 to i64
  br label %45

45:                                               ; preds = %34, %38
  %46 = phi i64 [ %44, %38 ], [ %35, %34 ]
  store i64 %46, i64* %19, align 8
  br label %90

47:                                               ; preds = %33
  %48 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %16, i64 %28
  store %"class.v8::internal::ReadOnlyPage"** %48, %"class.v8::internal::ReadOnlyPage"*** %18, align 8
  br label %90

49:                                               ; preds = %3
  %50 = icmp eq i64 %12, 0
  br i1 %50, label %56, label %51

51:                                               ; preds = %49
  %52 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %0, i64 0, i32 0, i32 1
  %53 = bitcast %"class.v8::internal::ReadOnlyPage"*** %52 to i64*
  store i64 %12, i64* %53, align 8
  %54 = inttoptr i64 %12 to i8*
  tail call void @_ZdlPv(i8* %54) #16
  %55 = bitcast %"class.std::__1::vector"* %0 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %55, i8 0, i64 24, i1 false) #15
  br label %56

56:                                               ; preds = %49, %51
  %57 = phi i64 [ %10, %49 ], [ 0, %51 ]
  %58 = icmp ugt i64 %7, 2305843009213693951
  br i1 %58, label %59, label %61

59:                                               ; preds = %56
  %60 = bitcast %"class.std::__1::vector"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %60) #14
  unreachable

61:                                               ; preds = %56
  %62 = ashr exact i64 %57, 3
  %63 = icmp ult i64 %62, 1152921504606846975
  br i1 %63, label %64, label %71

64:                                               ; preds = %61
  %65 = ashr exact i64 %57, 2
  %66 = icmp ult i64 %65, %7
  br i1 %66, label %71, label %67

67:                                               ; preds = %64
  %68 = icmp ugt i64 %65, 2305843009213693951
  br i1 %68, label %69, label %71

69:                                               ; preds = %67
  %70 = bitcast %"class.std::__1::vector"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %70) #14
  unreachable

71:                                               ; preds = %64, %61, %67
  %72 = phi i64 [ %65, %67 ], [ 2305843009213693951, %61 ], [ %7, %64 ]
  %73 = shl i64 %72, 3
  %74 = tail call i8* @_Znwm(i64 %73) #16
  %75 = bitcast i8* %74 to %"class.v8::internal::ReadOnlyPage"**
  %76 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %0, i64 0, i32 0, i32 1
  %77 = bitcast %"class.v8::internal::ReadOnlyPage"*** %76 to i8**
  store i8* %74, i8** %77, align 8
  %78 = bitcast %"class.std::__1::vector"* %0 to i8**
  store i8* %74, i8** %78, align 8
  %79 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %75, i64 %72
  store %"class.v8::internal::ReadOnlyPage"** %79, %"class.v8::internal::ReadOnlyPage"*** %8, align 8
  %80 = bitcast %"class.v8::internal::ReadOnlyPage"*** %76 to i64*
  %81 = ptrtoint i8* %74 to i64
  %82 = icmp sgt i64 %6, 0
  br i1 %82, label %83, label %88

83:                                               ; preds = %71
  %84 = lshr exact i64 %6, 3
  %85 = bitcast %"class.v8::internal::ReadOnlyPage"** %1 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %74, i8* align 8 %85, i64 %6, i1 false) #15
  %86 = getelementptr inbounds %"class.v8::internal::ReadOnlyPage"*, %"class.v8::internal::ReadOnlyPage"** %75, i64 %84
  %87 = ptrtoint %"class.v8::internal::ReadOnlyPage"** %86 to i64
  br label %88

88:                                               ; preds = %71, %83
  %89 = phi i64 [ %87, %83 ], [ %81, %71 ]
  store i64 %89, i64* %80, align 8
  br label %90

90:                                               ; preds = %45, %47, %88
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memmove.p0i8.p0i8.i64(i8* nocapture, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { norecurse nounwind readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { norecurse nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nobuiltin nofree "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { cold noreturn nounwind }
attributes #13 = { noreturn nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #14 = { noreturn nounwind }
attributes #15 = { nounwind }
attributes #16 = { builtin nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!"branch_weights", i32 2000, i32 1}
!3 = !{i8 0, i8 2}
!4 = !{!"branch_weights", i32 1, i32 2000}
!5 = distinct !{!5, !6}
!6 = !{!"llvm.loop.unroll.disable"}
!7 = distinct !{!7, !6}
!8 = distinct !{!8, !6}
!9 = distinct !{!9, !6}
