; ModuleID = '../../v8/src/heap/new-spaces.cc'
source_filename = "../../v8/src/heap/new-spaces.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.v8::internal::SemiSpaceObjectIterator" = type { %"class.v8::internal::ObjectIterator", i64, i64 }
%"class.v8::internal::ObjectIterator" = type { i32 (...)** }
%"class.v8::internal::NewSpace" = type { %"class.v8::internal::SpaceWithLinearArea", %"class.v8::base::Mutex", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace", %"class.v8::internal::VirtualMemory", %"class.std::__1::vector.63" }
%"class.v8::internal::SpaceWithLinearArea" = type { %"class.v8::internal::Space", %"class.v8::internal::LinearAllocationArea", [3 x i64] }
%"class.v8::internal::Space" = type { %"class.v8::internal::BaseSpace", %"class.v8::internal::AllocationCounter", %"class.v8::internal::heap::List", %"struct.std::__1::atomic"*, %"class.std::__1::unique_ptr.59" }
%"class.v8::internal::BaseSpace" = type { i32 (...)**, %"class.v8::internal::Heap"*, i32, %"struct.std::__1::atomic", i64 }
%"class.v8::internal::Heap" = type { %"class.std::__1::unordered_map", %"struct.std::__1::atomic", %"class.v8::internal::Heap::ExternalMemoryAccounting", %"class.v8::internal::Isolate"*, i64, i64, i64, i64, %"struct.std::__1::atomic", i64, i64, i64, i64, i64, i8, i64, i64, %"struct.std::__1::atomic", i64, i64, %"struct.std::__1::atomic", %"struct.std::__1::atomic.20", %"class.std::__1::vector", i32, %"class.v8::internal::NewSpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::CodeSpace"*, %"class.v8::internal::MapSpace"*, %"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::MapSpace"*, %"class.std::__1::unique_ptr.106", %"class.std::__1::unique_ptr.106", [8 x %"class.v8::internal::Space"*], %"class.v8::internal::LocalHeap"*, %"class.v8::internal::ArrayBufferExtension"*, %"class.v8::internal::ArrayBufferExtension"*, i8, i64, %"struct.std::__1::atomic.121", i32, i32, i32, i32, %"class.v8::internal::AllocationObserver"*, %"class.v8::internal::StressScavengeObserver"*, double, i32, i32, i32, i64, i32, [128 x i64], %"struct.std::__1::atomic", i64, i8, %"struct.std::__1::atomic", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.std::__1::vector.125", %"class.std::__1::vector.125", i64 ()*, [113 x i32], i64, double, double, i64, i64, double, i32, i32, i32, i32, double, double, double, %"class.std::__1::unique_ptr.132", %"class.std::__1::unique_ptr.138", %"class.v8::internal::MinorMarkCompactCollector"*, %"class.std::__1::unique_ptr.268", %"class.std::__1::unique_ptr.274", %"class.std::__1::unique_ptr.287", %"class.std::__1::unique_ptr.326", %"class.std::__1::unique_ptr.365", %"class.std::__1::unique_ptr.395", %"class.std::__1::unique_ptr.401", %"class.std::__1::unique_ptr.411", %"class.std::__1::unique_ptr.417", %"class.std::__1::unique_ptr.417", %"class.std::__1::unique_ptr.423", %"class.std::__1::unique_ptr.429", %"class.std::__1::unique_ptr.429", %"class.std::__1::unique_ptr.435", %"class.std::__1::unique_ptr.441", %"class.std::__1::shared_ptr.447", %"class.v8::CppHeap"*, %"class.v8::EmbedderRootsHandler"*, %"class.v8::internal::StrongRootsEntry"*, %"class.v8::base::Mutex", i8, i64, i64, i64, i64, %"class.std::__1::unordered_map.469", %"class.std::__1::unique_ptr.495", [512 x i8], i8, i8, i64, i8, i32, i32, %"class.std::__1::unique_ptr.501", i8, %"class.v8::internal::Heap::ExternalStringTable", %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.514", i32, i8, i8, i8, i8, i8, %"class.v8::internal::HeapObject", %"class.v8::base::SharedMutex", %"class.v8::base::Mutex", %"class.std::__1::unordered_set.297", i8, [7 x i8], %"class.std::__1::unordered_map.520", %"class.std::__1::unordered_map.546", %"class.std::__1::unordered_map.520", %"class.std::__1::unordered_map.570", %"class.std::__1::vector.598", i8, %"class.std::__1::unique_ptr.605", i32, i32 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr", %"class.std::__1::__compressed_pair.4", %"class.std::__1::__compressed_pair.9", %"class.std::__1::__compressed_pair.11", [4 x i8] }>
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem", %"struct.std::__1::__compressed_pair_elem.0" }
%"struct.std::__1::__compressed_pair_elem" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.0" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.1" }
%"class.std::__1::__compressed_pair.1" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"struct.std::__1::__compressed_pair_elem.2" = type { i64 }
%"class.std::__1::__compressed_pair.4" = type { %"struct.std::__1::__compressed_pair_elem.5" }
%"struct.std::__1::__compressed_pair_elem.5" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.9" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.11" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::__compressed_pair_elem.12" = type { float }
%"class.v8::internal::Heap::ExternalMemoryAccounting" = type { %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.15" }
%"struct.std::__1::atomic.15" = type { %"struct.std::__1::__atomic_base.16" }
%"struct.std::__1::__atomic_base.16" = type { %"struct.std::__1::__atomic_base.17" }
%"struct.std::__1::__atomic_base.17" = type { %"struct.std::__1::__cxx_atomic_impl.18" }
%"struct.std::__1::__cxx_atomic_impl.18" = type { %"struct.std::__1::__cxx_atomic_base_impl.19" }
%"struct.std::__1::__cxx_atomic_base_impl.19" = type { i64 }
%"class.v8::internal::Isolate" = type { %"class.v8::internal::IsolateData", %"class.std::__1::unique_ptr.689", %"class.v8::internal::Heap", %"class.v8::internal::ReadOnlyHeap"*, %"class.std::__1::shared_ptr.695", %"class.std::__1::unique_ptr.716", i32, %"class.v8::internal::Isolate::EntryStackItem"*, i32, %"class.v8::internal::StringStream"*, [13 x i64], %"class.v8::internal::Bootstrapper"*, %"class.v8::internal::RuntimeProfiler"*, %"class.v8::internal::CompilationCache"*, %"class.std::__1::shared_ptr.726", %"class.v8::base::RecursiveMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::internal::Logger"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::Deoptimizer"*, i8, %"class.v8::internal::MaterializedObjectStore"*, i8, i32, i32, %"class.v8::internal::DescriptorLookupCache"*, %"struct.v8::internal::HandleScopeData", %"class.v8::internal::HandleScopeImplementer"*, %"class.v8::internal::UnicodeCache"*, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::InnerPointerToCodeCache"*, %"class.v8::internal::GlobalHandles"*, %"class.v8::internal::EternalHandles"*, %"class.v8::internal::ThreadManager"*, %"class.v8::bigint::Processor"*, %"class.v8::internal::RuntimeState", %"class.v8::internal::Builtins", %"class.v8::internal::SetupIsolateDelegate"*, %"class.v8::internal::RegExpStack"*, %"class.std::__1::vector.855", %"class.v8::internal::DateCache"*, %"class.v8::base::RandomNumberGenerator"*, %"class.v8::base::RandomNumberGenerator"*, %"struct.std::__1::atomic.868", {}*, i8*, void (i32, %"class.v8::Promise"*, %"class.v8::Value"*)*, {}*, {}*, %"struct.std::__1::atomic.878", {}*, %"class.v8::base::Mutex", double, %"class.std::__1::basic_string", %"class.std::__1::unordered_map.890", %"struct.std::__1::atomic.112", i8, i8, i8, i8, i8, i8, double, %"class.v8::internal::Debug"*, %"class.v8::internal::HeapProfiler"*, %"class.std::__1::unique_ptr.965", %"class.v8::internal::AstStringConstants"*, %"class.v8::internal::interpreter::Interpreter"*, %"class.v8::internal::compiler::PerIsolateCompilerCache"*, %"class.v8::internal::Zone"*, %"class.v8::internal::CompilerDispatcher"*, %"class.std::__1::queue", void (i8*, i8*)*, void (i8*, i1)*, void (i8*, i32)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*, i1)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::Context"*)*, void (%"class.v8::FunctionCallbackInfo"*)*, %"class.v8::String"* (%"class.v8::Isolate"*, i8*)*, i1 (%"class.v8::Context"*)*, i1 (%"class.v8::Context"*)*, %"class.v8::internal::Relocatable"*, %"class.std::__1::vector.1008"*, %"class.v8::internal::Object", i64*, %"class.v8::internal::AddressToIndexHashMap"*, %"class.v8::internal::HeapObjectToIndexHashMap"*, %"class.v8::internal::MicrotaskQueue"*, %"class.v8::internal::CompilationStatistics"*, %"class.v8::internal::CodeTracer"*, i32, void (%"class.v8::PromiseRejectMessage"*)*, %"class.v8::StartupData"*, i32, i32, i32, i64, i8, i8, i32, i8, i32, %"class.v8_inspector::V8Inspector"*, i8, i8, i8, i32, i32, %"class.v8::internal::compiler::NodeObserver"*, i8, [128 x i32], [256 x i32], [251 x i32], [251 x i32], %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.std::__1::unique_ptr.1016", i32, i8, i8, i32, i32, %"class.std::__1::vector.1022", %"class.std::__1::vector.1022", void (%"class.v8::Isolate"*, i32)*, %"class.std::__1::shared_ptr.1029", i64, %"class.std::__1::unordered_map.1030", i64, %"struct.v8::metrics::LongTaskStats", %"class.std::__1::vector.507", %"class.v8::internal::BuiltinsConstantsTableBuilder"*, i8*, i32, i8*, i32, %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::shared_ptr.120", %"class.v8::internal::FutexWaitListNode", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::debug::ConsoleDelegate"*, %"class.v8::debug::AsyncEventDelegate"*, i32, i32, %"class.std::__1::unique_ptr.1082", i1 (%"class.v8::Isolate"*)*, i8, %"class.v8::base::Mutex", %"struct.v8::internal::ManagedPtrDestructor"*, i64, i64, %"class.v8::internal::wasm::WasmEngine"*, %"class.std::__1::unique_ptr.1096", %"class.v8::internal::EmbeddedFileWriterInterface"*, %"class.v8::Context::BackupIncumbentScope"*, {}*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate::ThreadDataTable", i8, %"class.v8::internal::Isolate"*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"struct.std::__1::atomic.1130", %"class.std::__1::vector.1134", %"class.std::__1::vector.1134", void (i32, %"class.std::__1::basic_string"*)* }
%"class.v8::internal::IsolateData" = type { [4 x i8*], i64, i64, i64, i64, i64, %"class.v8::internal::StackGuard", %"class.v8::internal::RootsTable", %"class.v8::internal::ExternalReferenceTable", %"class.v8::internal::ThreadLocalTop", [1711 x i64], [1711 x i64], i8, [15 x i8] }
%"class.v8::internal::StackGuard" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::StackGuard::ThreadLocal" }
%"class.v8::internal::StackGuard::ThreadLocal" = type { i64, i64, i64, i64, %"class.v8::internal::InterruptsScope"*, i64 }
%"class.v8::internal::InterruptsScope" = type { i32 (...)**, %"class.v8::internal::StackGuard"*, i64, i64, i32, %"class.v8::internal::InterruptsScope"* }
%"class.v8::internal::RootsTable" = type { [669 x i64] }
%"class.v8::internal::ExternalReferenceTable" = type { [1042 x i64], i32, i32 }
%"class.v8::internal::ThreadLocalTop" = type { %"class.v8::TryCatch"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Context", %"struct.std::__1::atomic.684", %"class.v8::internal::Object", %"class.v8::internal::Context", i64, i64, i64, i64, i64, %"class.v8::internal::Object", i8, i8, %"class.v8::internal::Object", i64, i64, i64, %"class.v8::internal::PromiseOnStack"*, %"class.v8::internal::Simulator"*, i64, %"class.v8::internal::ExternalCallbackScope"*, i32, void (%"class.v8::Object"*, i32, %"class.v8::Value"*)*, i64 }
%"class.v8::TryCatch" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::TryCatch"*, i8*, i8*, i8*, i8, [7 x i8] }>
%"struct.std::__1::atomic.684" = type { %"struct.std::__1::__atomic_base.685" }
%"struct.std::__1::__atomic_base.685" = type { %"struct.std::__1::__cxx_atomic_impl.686" }
%"struct.std::__1::__cxx_atomic_impl.686" = type { %"struct.std::__1::__cxx_atomic_base_impl.687" }
%"struct.std::__1::__cxx_atomic_base_impl.687" = type { %"class.v8::internal::ThreadId" }
%"class.v8::internal::ThreadId" = type { i32 }
%"class.v8::internal::Context" = type { %"class.v8::internal::TorqueGeneratedContext" }
%"class.v8::internal::TorqueGeneratedContext" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::PromiseOnStack" = type { %"class.v8::internal::Handle", %"class.v8::internal::PromiseOnStack"* }
%"class.v8::internal::Handle" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HandleBase" = type { i64* }
%"class.v8::internal::Simulator" = type opaque
%"class.v8::internal::ExternalCallbackScope" = type opaque
%"class.v8::Object" = type { i8 }
%"class.v8::Value" = type { i8 }
%"class.std::__1::unique_ptr.689" = type { %"class.std::__1::__compressed_pair.690" }
%"class.std::__1::__compressed_pair.690" = type { %"struct.std::__1::__compressed_pair_elem.691" }
%"struct.std::__1::__compressed_pair_elem.691" = type { %"class.v8::internal::IsolateAllocator"* }
%"class.v8::internal::IsolateAllocator" = type { i8*, %"class.v8::PageAllocator"* }
%"class.v8::PageAllocator" = type { i32 (...)** }
%"class.v8::internal::ReadOnlyHeap" = type { i32 (...)**, i8, %"class.v8::internal::ReadOnlySpace"*, %"class.std::__1::vector.507" }
%"class.std::__1::shared_ptr.695" = type { %"class.v8::internal::ReadOnlyArtifacts"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::ReadOnlyArtifacts" = type { i32 (...)**, %"class.std::__1::vector.99", %"class.v8::internal::AllocationStats", %"class.std::__1::unique_ptr.696", %"class.std::__1::unique_ptr.710" }
%"class.std::__1::vector.99" = type { %"class.std::__1::__vector_base.100" }
%"class.std::__1::__vector_base.100" = type { %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"**, %"class.std::__1::__compressed_pair.101" }
%"class.v8::internal::ReadOnlyPage" = type { %"class.v8::internal::BasicMemoryChunk" }
%"class.v8::internal::BasicMemoryChunk" = type { i64, i64, %"class.v8::internal::Heap"*, i64, i64, i64, i64, %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.611", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.611" = type { %"struct.std::__1::__atomic_base.612" }
%"struct.std::__1::__atomic_base.612" = type { %"struct.std::__1::__cxx_atomic_impl.613" }
%"struct.std::__1::__cxx_atomic_impl.613" = type { %"struct.std::__1::__cxx_atomic_base_impl.614" }
%"struct.std::__1::__cxx_atomic_base_impl.614" = type { %"class.v8::internal::BaseSpace"* }
%"class.std::__1::__compressed_pair.101" = type { %"struct.std::__1::__compressed_pair_elem.102" }
%"struct.std::__1::__compressed_pair_elem.102" = type { %"class.v8::internal::ReadOnlyPage"** }
%"class.v8::internal::AllocationStats" = type { %"struct.std::__1::atomic", i64, %"struct.std::__1::atomic" }
%"class.std::__1::unique_ptr.696" = type { %"class.std::__1::__compressed_pair.697" }
%"class.std::__1::__compressed_pair.697" = type { %"struct.std::__1::__compressed_pair_elem.698" }
%"struct.std::__1::__compressed_pair_elem.698" = type { %"class.v8::internal::SharedReadOnlySpace"* }
%"class.v8::internal::SharedReadOnlySpace" = type { %"class.v8::internal::ReadOnlySpace", %"class.std::__1::vector.699" }
%"class.v8::internal::ReadOnlySpace" = type { %"class.v8::internal::BaseSpace", i8, %"class.v8::internal::AllocationStats", %"class.std::__1::vector.99", i64, i64, i8, i64, i64 }
%"class.std::__1::vector.699" = type { %"class.std::__1::__vector_base.700" }
%"class.std::__1::__vector_base.700" = type { %"class.std::__1::unique_ptr.701"*, %"class.std::__1::unique_ptr.701"*, %"class.std::__1::__compressed_pair.702" }
%"class.std::__1::unique_ptr.701" = type { %"class.std::__1::__compressed_pair.1148" }
%"class.std::__1::__compressed_pair.1148" = type { %"struct.std::__1::__compressed_pair_elem.1149" }
%"struct.std::__1::__compressed_pair_elem.1149" = type { %"class.v8::PageAllocator::SharedMemoryMapping"* }
%"class.v8::PageAllocator::SharedMemoryMapping" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.702" = type { %"struct.std::__1::__compressed_pair_elem.703" }
%"struct.std::__1::__compressed_pair_elem.703" = type { %"class.std::__1::unique_ptr.701"* }
%"class.std::__1::unique_ptr.710" = type { %"class.std::__1::__compressed_pair.711" }
%"class.std::__1::__compressed_pair.711" = type { %"struct.std::__1::__compressed_pair_elem.712" }
%"struct.std::__1::__compressed_pair_elem.712" = type { %"class.v8::internal::ReadOnlyHeap"* }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.std::__1::unique_ptr.716" = type { %"class.std::__1::__compressed_pair.717" }
%"class.std::__1::__compressed_pair.717" = type { %"struct.std::__1::__compressed_pair_elem.718" }
%"struct.std::__1::__compressed_pair_elem.718" = type { %"class.v8::internal::StringTable"* }
%"class.v8::internal::StringTable" = type { %"struct.std::__1::atomic.719", %"class.v8::base::Mutex" }
%"struct.std::__1::atomic.719" = type { %"struct.std::__1::__atomic_base.720" }
%"struct.std::__1::__atomic_base.720" = type { %"struct.std::__1::__cxx_atomic_impl.721" }
%"struct.std::__1::__cxx_atomic_impl.721" = type { %"struct.std::__1::__cxx_atomic_base_impl.722" }
%"struct.std::__1::__cxx_atomic_base_impl.722" = type { %"class.v8::internal::StringTable::Data"* }
%"class.v8::internal::StringTable::Data" = type opaque
%"class.v8::internal::Isolate::EntryStackItem" = type { i32, %"class.v8::internal::Isolate::PerIsolateThreadData"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate::EntryStackItem"* }
%"class.v8::internal::Isolate::PerIsolateThreadData" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::ThreadId", i64, %"class.v8::internal::ThreadState"* }
%"class.v8::internal::ThreadState" = type opaque
%"class.v8::internal::StringStream" = type opaque
%"class.v8::internal::Bootstrapper" = type { %"class.v8::internal::Isolate"*, i32, %"class.v8::internal::SourceCodeCache" }
%"class.v8::internal::SourceCodeCache" = type { i32, %"class.v8::internal::FixedArray" }
%"class.v8::internal::FixedArray" = type { %"class.v8::internal::TorqueGeneratedFixedArray" }
%"class.v8::internal::TorqueGeneratedFixedArray" = type { %"class.v8::internal::FixedArrayBase" }
%"class.v8::internal::FixedArrayBase" = type { %"class.v8::internal::TorqueGeneratedFixedArrayBase" }
%"class.v8::internal::TorqueGeneratedFixedArrayBase" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::RuntimeProfiler" = type opaque
%"class.v8::internal::CompilationCache" = type opaque
%"class.std::__1::shared_ptr.726" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::Counters" = type { %"class.std::__1::enable_shared_from_this", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::AggregatableHistogramTimer", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::RuntimeCallStats", %"class.v8::internal::WorkerThreadRuntimeCallStats", %"class.v8::internal::Isolate"*, %"class.v8::internal::StatsTable" }
%"class.std::__1::enable_shared_from_this" = type { %"class.std::__1::weak_ptr" }
%"class.std::__1::weak_ptr" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::HistogramTimer" = type { %"class.v8::internal::TimedHistogram.base", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::TimedHistogram.base" = type <{ %"class.v8::internal::Histogram", i32 }>
%"class.v8::base::ElapsedTimer" = type { %"class.v8::base::TimeTicks" }
%"class.v8::base::TimeTicks" = type { %"class.v8::base::time_internal::TimeBase" }
%"class.v8::base::time_internal::TimeBase" = type { i64 }
%"class.v8::internal::TimedHistogram" = type <{ %"class.v8::internal::Histogram", i32, [4 x i8] }>
%"class.v8::internal::AggregatableHistogramTimer" = type { %"class.v8::internal::Histogram", %"class.v8::base::TimeDelta" }
%"class.v8::base::TimeDelta" = type { i64 }
%"class.v8::internal::Histogram" = type { i8*, i32, i32, i32, i8*, %"class.v8::internal::Counters"* }
%"class.v8::internal::StatsCounterThreadSafe" = type { %"class.v8::internal::StatsCounterBase", %"class.v8::base::Mutex" }
%"class.v8::internal::StatsCounterBase" = type { %"class.v8::internal::Counters"*, i8*, i32* }
%"class.v8::internal::StatsCounter" = type <{ %"class.v8::internal::StatsCounterBase", i8, [7 x i8] }>
%"class.v8::internal::RuntimeCallStats" = type { %"class.v8::base::AtomicValue", %"class.v8::base::AtomicValue.727", i8, i32, %"class.v8::internal::ThreadId", [1370 x %"class.v8::internal::RuntimeCallCounter"] }
%"class.v8::base::AtomicValue" = type { i64 }
%"class.v8::base::AtomicValue.727" = type { i64 }
%"class.v8::internal::RuntimeCallCounter" = type { i8*, i64, i64 }
%"class.v8::internal::WorkerThreadRuntimeCallStats" = type <{ %"class.v8::base::Mutex", %"class.std::__1::vector.728", %"class.v8::base::Optional.736", %"class.v8::internal::ThreadId", [4 x i8] }>
%"class.std::__1::vector.728" = type { %"class.std::__1::__vector_base.729" }
%"class.std::__1::__vector_base.729" = type { %"class.std::__1::unique_ptr.730"*, %"class.std::__1::unique_ptr.730"*, %"class.std::__1::__compressed_pair.731" }
%"class.std::__1::unique_ptr.730" = type opaque
%"class.std::__1::__compressed_pair.731" = type { %"struct.std::__1::__compressed_pair_elem.732" }
%"struct.std::__1::__compressed_pair_elem.732" = type { %"class.std::__1::unique_ptr.730"* }
%"class.v8::base::Optional.736" = type { %"class.v8::base::internal::OptionalBase.737" }
%"class.v8::base::internal::OptionalBase.737" = type { %"struct.v8::base::internal::OptionalStorage.738" }
%"struct.v8::base::internal::OptionalStorage.738" = type { %"struct.v8::base::internal::OptionalStorageBase.739" }
%"struct.v8::base::internal::OptionalStorageBase.739" = type { i8, %union.anon.740 }
%union.anon.740 = type { i32 }
%"class.v8::internal::StatsTable" = type { i32* (i8*)*, i8* (i8*, i32, i32, i64)*, void (i8*, i32)* }
%"class.v8::base::RecursiveMutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.v8::internal::Logger" = type { %"class.v8::internal::CodeEventListener", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.745", %"class.std::__1::unique_ptr.751", %"struct.std::__1::atomic.112", %"class.std::__1::unique_ptr.757", %"class.std::__1::unique_ptr.763", %"class.std::__1::unique_ptr.769", %"class.std::__1::unique_ptr.775", %"class.std::__1::unique_ptr.781", %"class.std::__1::set.787", i32, i8, %"class.v8::internal::ExistingCodeLogger", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::CodeEventListener" = type { i32 (...)** }
%"class.std::__1::unique_ptr.745" = type { %"class.std::__1::__compressed_pair.746" }
%"class.std::__1::__compressed_pair.746" = type { %"struct.std::__1::__compressed_pair_elem.747" }
%"struct.std::__1::__compressed_pair_elem.747" = type { %"class.v8::internal::Ticker"* }
%"class.v8::internal::Ticker" = type opaque
%"class.std::__1::unique_ptr.751" = type { %"class.std::__1::__compressed_pair.752" }
%"class.std::__1::__compressed_pair.752" = type { %"struct.std::__1::__compressed_pair_elem.753" }
%"struct.std::__1::__compressed_pair_elem.753" = type { %"class.v8::internal::Profiler"* }
%"class.v8::internal::Profiler" = type opaque
%"class.std::__1::unique_ptr.757" = type { %"class.std::__1::__compressed_pair.758" }
%"class.std::__1::__compressed_pair.758" = type { %"struct.std::__1::__compressed_pair_elem.759" }
%"struct.std::__1::__compressed_pair_elem.759" = type { %"class.v8::internal::Log"* }
%"class.v8::internal::Log" = type opaque
%"class.std::__1::unique_ptr.763" = type { %"class.std::__1::__compressed_pair.764" }
%"class.std::__1::__compressed_pair.764" = type { %"struct.std::__1::__compressed_pair_elem.765" }
%"struct.std::__1::__compressed_pair_elem.765" = type { %"class.v8::internal::PerfBasicLogger"* }
%"class.v8::internal::PerfBasicLogger" = type opaque
%"class.std::__1::unique_ptr.769" = type { %"class.std::__1::__compressed_pair.770" }
%"class.std::__1::__compressed_pair.770" = type { %"struct.std::__1::__compressed_pair_elem.771" }
%"struct.std::__1::__compressed_pair_elem.771" = type { %"class.v8::internal::PerfJitLogger"* }
%"class.v8::internal::PerfJitLogger" = type opaque
%"class.std::__1::unique_ptr.775" = type { %"class.std::__1::__compressed_pair.776" }
%"class.std::__1::__compressed_pair.776" = type { %"struct.std::__1::__compressed_pair_elem.777" }
%"struct.std::__1::__compressed_pair_elem.777" = type { %"class.v8::internal::LowLevelLogger"* }
%"class.v8::internal::LowLevelLogger" = type opaque
%"class.std::__1::unique_ptr.781" = type { %"class.std::__1::__compressed_pair.782" }
%"class.std::__1::__compressed_pair.782" = type { %"struct.std::__1::__compressed_pair_elem.783" }
%"struct.std::__1::__compressed_pair_elem.783" = type { %"class.v8::internal::JitLogger"* }
%"class.v8::internal::JitLogger" = type opaque
%"class.std::__1::set.787" = type { %"class.std::__1::__tree.788" }
%"class.std::__1::__tree.788" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.789", %"class.std::__1::__compressed_pair.793" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.789" = type { %"struct.std::__1::__compressed_pair_elem.452" }
%"struct.std::__1::__compressed_pair_elem.452" = type { %"class.std::__1::__tree_end_node" }
%"class.std::__1::__compressed_pair.793" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::internal::ExistingCodeLogger" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::CodeEventListener"* }
%"class.v8::internal::StubCache" = type { [2048 x %"struct.v8::internal::StubCache::Entry"], [512 x %"struct.v8::internal::StubCache::Entry"], %"class.v8::internal::Isolate"* }
%"struct.v8::internal::StubCache::Entry" = type { %"class.v8::internal::StrongTaggedValue", %"class.v8::internal::TaggedValue", %"class.v8::internal::StrongTaggedValue" }
%"class.v8::internal::TaggedValue" = type { %"class.v8::internal::TaggedImpl.796" }
%"class.v8::internal::TaggedImpl.796" = type { i32 }
%"class.v8::internal::StrongTaggedValue" = type { %"class.v8::internal::TaggedImpl.795" }
%"class.v8::internal::TaggedImpl.795" = type { i32 }
%"class.v8::internal::Deoptimizer" = type opaque
%"class.v8::internal::MaterializedObjectStore" = type opaque
%"class.v8::internal::DescriptorLookupCache" = type { [64 x %"struct.v8::internal::DescriptorLookupCache::Key"], [64 x i32] }
%"struct.v8::internal::DescriptorLookupCache::Key" = type { %"class.v8::internal::Map", %"class.v8::internal::Name" }
%"class.v8::internal::Map" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Name" = type { %"class.v8::internal::TorqueGeneratedName" }
%"class.v8::internal::TorqueGeneratedName" = type { %"class.v8::internal::PrimitiveHeapObject" }
%"class.v8::internal::PrimitiveHeapObject" = type { %"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" }
%"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" = type { %"class.v8::internal::HeapObject" }
%"struct.v8::internal::HandleScopeData" = type { i64*, i64*, i32, i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::CanonicalHandleScope" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::Zone"*, %"class.v8::internal::RootIndexMap"*, %"class.std::__1::unique_ptr.654", i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::OptimizedCompilationInfo" = type opaque
%"class.v8::internal::RootIndexMap" = type opaque
%"class.std::__1::unique_ptr.654" = type { %"class.std::__1::__compressed_pair.655" }
%"class.std::__1::__compressed_pair.655" = type { %"struct.std::__1::__compressed_pair_elem.656" }
%"struct.std::__1::__compressed_pair_elem.656" = type { %"class.v8::internal::IdentityMap"* }
%"class.v8::internal::IdentityMap" = type opaque
%"class.v8::internal::HandleScopeImplementer" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::DetachableVector", %"class.v8::internal::DetachableVector.797", %"class.v8::internal::DetachableVector.798", %"class.v8::internal::DetachableVector.797", i64*, i64*, %"struct.v8::internal::HandleScopeData" }
%"class.v8::internal::DetachableVector" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVectorBase" = type { i8*, i64, i64 }
%"class.v8::internal::DetachableVector.798" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVector.797" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::UnicodeCache" = type opaque
%"class.v8::internal::AccountingAllocator" = type { i32 (...)**, %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.std::__1::unique_ptr.648", %"class.std::__1::unique_ptr.448" }
%"class.std::__1::unique_ptr.648" = type { %"class.std::__1::__compressed_pair.649" }
%"class.std::__1::__compressed_pair.649" = type { %"struct.std::__1::__compressed_pair_elem.650" }
%"struct.std::__1::__compressed_pair_elem.650" = type { %"class.v8::internal::VirtualMemory"* }
%"class.std::__1::unique_ptr.448" = type { %"class.std::__1::__compressed_pair.449" }
%"class.std::__1::__compressed_pair.449" = type { %"struct.std::__1::__compressed_pair_elem.450" }
%"struct.std::__1::__compressed_pair_elem.450" = type { %"class.v8::base::BoundedPageAllocator"* }
%"class.v8::base::BoundedPageAllocator" = type { %"class.v8::PageAllocator", %"class.v8::base::Mutex", i64, i64, %"class.v8::PageAllocator"*, %"class.v8::base::RegionAllocator" }
%"class.v8::base::RegionAllocator" = type { %"class.v8::base::RegionAllocator::Region", i64, i64, i64, i64, %"class.std::__1::set", %"class.std::__1::set.458" }
%"class.v8::base::RegionAllocator::Region" = type <{ %"class.v8::base::AddressRegion", i32, [4 x i8] }>
%"class.v8::base::AddressRegion" = type { i64, i64 }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.451", %"class.std::__1::__compressed_pair.456" }
%"class.std::__1::__compressed_pair.451" = type { %"struct.std::__1::__compressed_pair_elem.452" }
%"class.std::__1::__compressed_pair.456" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::set.458" = type { %"class.std::__1::__tree.459" }
%"class.std::__1::__tree.459" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.451", %"class.std::__1::__compressed_pair.460" }
%"class.std::__1::__compressed_pair.460" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::internal::InnerPointerToCodeCache" = type opaque
%"class.v8::internal::GlobalHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.799", %"class.std::__1::vector.805", %"class.std::__1::unique_ptr.812", %"class.std::__1::vector.819", %"class.std::__1::unique_ptr.826", i64, %"class.std::__1::vector.832", %"class.std::__1::vector.840", %"class.std::__1::vector.848", i8, i8, i32 }
%"class.std::__1::unique_ptr.799" = type { %"class.std::__1::__compressed_pair.800" }
%"class.std::__1::__compressed_pair.800" = type { %"struct.std::__1::__compressed_pair_elem.801" }
%"struct.std::__1::__compressed_pair_elem.801" = type { %"class.v8::internal::GlobalHandles::NodeSpace"* }
%"class.v8::internal::GlobalHandles::NodeSpace" = type opaque
%"class.std::__1::vector.805" = type { %"class.std::__1::__vector_base.806" }
%"class.std::__1::__vector_base.806" = type { %"class.v8::internal::GlobalHandles::Node"**, %"class.v8::internal::GlobalHandles::Node"**, %"class.std::__1::__compressed_pair.807" }
%"class.v8::internal::GlobalHandles::Node" = type opaque
%"class.std::__1::__compressed_pair.807" = type { %"struct.std::__1::__compressed_pair_elem.808" }
%"struct.std::__1::__compressed_pair_elem.808" = type { %"class.v8::internal::GlobalHandles::Node"** }
%"class.std::__1::unique_ptr.812" = type { %"class.std::__1::__compressed_pair.813" }
%"class.std::__1::__compressed_pair.813" = type { %"struct.std::__1::__compressed_pair_elem.814" }
%"struct.std::__1::__compressed_pair_elem.814" = type { %"class.v8::internal::GlobalHandles::NodeSpace.815"* }
%"class.v8::internal::GlobalHandles::NodeSpace.815" = type opaque
%"class.std::__1::vector.819" = type { %"class.std::__1::__vector_base.820" }
%"class.std::__1::__vector_base.820" = type { %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.std::__1::__compressed_pair.821" }
%"class.v8::internal::GlobalHandles::TracedNode" = type opaque
%"class.std::__1::__compressed_pair.821" = type { %"struct.std::__1::__compressed_pair_elem.822" }
%"struct.std::__1::__compressed_pair_elem.822" = type { %"class.v8::internal::GlobalHandles::TracedNode"** }
%"class.std::__1::unique_ptr.826" = type { %"class.std::__1::__compressed_pair.827" }
%"class.std::__1::__compressed_pair.827" = type { %"struct.std::__1::__compressed_pair_elem.828" }
%"struct.std::__1::__compressed_pair_elem.828" = type { %"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace"* }
%"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace" = type opaque
%"class.std::__1::vector.832" = type { %"class.std::__1::__vector_base.833" }
%"class.std::__1::__vector_base.833" = type { %"struct.std::__1::pair.834"*, %"struct.std::__1::pair.834"*, %"class.std::__1::__compressed_pair.835" }
%"struct.std::__1::pair.834" = type opaque
%"class.std::__1::__compressed_pair.835" = type { %"struct.std::__1::__compressed_pair_elem.836" }
%"struct.std::__1::__compressed_pair_elem.836" = type { %"struct.std::__1::pair.834"* }
%"class.std::__1::vector.840" = type { %"class.std::__1::__vector_base.841" }
%"class.std::__1::__vector_base.841" = type { %"struct.std::__1::pair.842"*, %"struct.std::__1::pair.842"*, %"class.std::__1::__compressed_pair.843" }
%"struct.std::__1::pair.842" = type opaque
%"class.std::__1::__compressed_pair.843" = type { %"struct.std::__1::__compressed_pair_elem.844" }
%"struct.std::__1::__compressed_pair_elem.844" = type { %"struct.std::__1::pair.842"* }
%"class.std::__1::vector.848" = type { %"class.std::__1::__vector_base.849" }
%"class.std::__1::__vector_base.849" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.std::__1::__compressed_pair.850" }
%"class.v8::internal::GlobalHandles::PendingPhantomCallback" = type { void (%"class.v8::WeakCallbackInfo"*)*, i8*, [2 x i8*] }
%"class.v8::WeakCallbackInfo" = type { %"class.v8::Isolate"*, i8*, {}**, [2 x i8*] }
%"class.v8::Isolate" = type { i8 }
%"class.std::__1::__compressed_pair.850" = type { %"struct.std::__1::__compressed_pair_elem.851" }
%"struct.std::__1::__compressed_pair_elem.851" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"* }
%"class.v8::internal::EternalHandles" = type { i32, %"class.std::__1::vector.660", %"class.std::__1::vector.855" }
%"class.std::__1::vector.660" = type { %"class.std::__1::__vector_base.661" }
%"class.std::__1::__vector_base.661" = type { i64**, i64**, %"class.std::__1::__compressed_pair.662" }
%"class.std::__1::__compressed_pair.662" = type { %"struct.std::__1::__compressed_pair_elem.663" }
%"struct.std::__1::__compressed_pair_elem.663" = type { i64** }
%"class.v8::internal::ThreadManager" = type opaque
%"class.v8::bigint::Processor" = type opaque
%"class.v8::internal::RuntimeState" = type { %"class.std::__1::unique_ptr.862" }
%"class.std::__1::unique_ptr.862" = type { %"class.std::__1::__compressed_pair.863" }
%"class.std::__1::__compressed_pair.863" = type { %"struct.std::__1::__compressed_pair_elem.864" }
%"struct.std::__1::__compressed_pair_elem.864" = type { %"struct.v8::internal::Runtime::Function"* }
%"struct.v8::internal::Runtime::Function" = type { i32, i32, i8*, i64, i8, i8 }
%"class.v8::internal::Builtins" = type { %"class.v8::internal::Isolate"*, i8, i32 }
%"class.v8::internal::SetupIsolateDelegate" = type opaque
%"class.v8::internal::RegExpStack" = type opaque
%"class.std::__1::vector.855" = type { %"class.std::__1::__vector_base.856" }
%"class.std::__1::__vector_base.856" = type { i32*, i32*, %"class.std::__1::__compressed_pair.857" }
%"class.std::__1::__compressed_pair.857" = type { %"struct.std::__1::__compressed_pair_elem.858" }
%"struct.std::__1::__compressed_pair_elem.858" = type { i32* }
%"class.v8::internal::DateCache" = type opaque
%"class.v8::base::RandomNumberGenerator" = type { i64, i64, i64 }
%"struct.std::__1::atomic.868" = type { %"struct.std::__1::__atomic_base.869" }
%"struct.std::__1::__atomic_base.869" = type { %"struct.std::__1::__cxx_atomic_impl.870" }
%"struct.std::__1::__cxx_atomic_impl.870" = type { %"struct.std::__1::__cxx_atomic_base_impl.871" }
%"struct.std::__1::__cxx_atomic_base_impl.871" = type { i32 }
%"class.v8::Promise" = type { i8 }
%"struct.std::__1::atomic.878" = type { %"struct.std::__1::__atomic_base.879" }
%"struct.std::__1::__atomic_base.879" = type { %"struct.std::__1::__cxx_atomic_impl.880" }
%"struct.std::__1::__cxx_atomic_impl.880" = type { %"struct.std::__1::__cxx_atomic_base_impl.881" }
%"struct.std::__1::__cxx_atomic_base_impl.881" = type { i32 }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair.883" }
%"class.std::__1::__compressed_pair.883" = type { %"struct.std::__1::__compressed_pair_elem.884" }
%"struct.std::__1::__compressed_pair_elem.884" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon.885 }
%union.anon.885 = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%"class.std::__1::unordered_map.890" = type { %"class.std::__1::__hash_table.891" }
%"class.std::__1::__hash_table.891" = type <{ %"class.std::__1::unique_ptr.892", %"class.std::__1::__compressed_pair.902", %"class.std::__1::__compressed_pair.907", %"class.std::__1::__compressed_pair.910", [4 x i8] }>
%"class.std::__1::unique_ptr.892" = type { %"class.std::__1::__compressed_pair.893" }
%"class.std::__1::__compressed_pair.893" = type { %"struct.std::__1::__compressed_pair_elem.894", %"struct.std::__1::__compressed_pair_elem.896" }
%"struct.std::__1::__compressed_pair_elem.894" = type { %"struct.std::__1::__hash_node_base.895"** }
%"struct.std::__1::__hash_node_base.895" = type { %"struct.std::__1::__hash_node_base.895"* }
%"struct.std::__1::__compressed_pair_elem.896" = type { %"class.std::__1::__bucket_list_deallocator.897" }
%"class.std::__1::__bucket_list_deallocator.897" = type { %"class.std::__1::__compressed_pair.898" }
%"class.std::__1::__compressed_pair.898" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.902" = type { %"struct.std::__1::__compressed_pair_elem.903" }
%"struct.std::__1::__compressed_pair_elem.903" = type { %"struct.std::__1::__hash_node_base.895" }
%"class.std::__1::__compressed_pair.907" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.910" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::atomic.112" = type { %"struct.std::__1::__atomic_base.113" }
%"struct.std::__1::__atomic_base.113" = type { %"struct.std::__1::__cxx_atomic_impl.114" }
%"struct.std::__1::__cxx_atomic_impl.114" = type { %"struct.std::__1::__cxx_atomic_base_impl.115" }
%"struct.std::__1::__cxx_atomic_base_impl.115" = type { i8 }
%"class.v8::internal::Debug" = type { %"class.v8::debug::DebugDelegate"*, i8, i8, i8, i8, i8, i8, i8, i8, i8, %"class.v8::internal::DebugInfoListNode"*, %"class.std::__1::unique_ptr.916", %"class.v8::internal::Handle.922", %"class.v8::internal::DebugFeatureTracker", %"class.v8::internal::Debug::ThreadLocal", %"class.v8::internal::Handle.923", %"class.v8::internal::Isolate"* }
%"class.v8::debug::DebugDelegate" = type { i32 (...)** }
%"class.v8::internal::DebugInfoListNode" = type { i64*, %"class.v8::internal::DebugInfoListNode"* }
%"class.std::__1::unique_ptr.916" = type { %"class.std::__1::__compressed_pair.917" }
%"class.std::__1::__compressed_pair.917" = type { %"struct.std::__1::__compressed_pair_elem.918" }
%"struct.std::__1::__compressed_pair_elem.918" = type { %"class.v8::internal::Debug::TemporaryObjectsTracker"* }
%"class.v8::internal::Debug::TemporaryObjectsTracker" = type opaque
%"class.v8::internal::Handle.922" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::DebugFeatureTracker" = type <{ %"class.v8::internal::Isolate"*, i32, [4 x i8] }>
%"class.v8::internal::Debug::ThreadLocal" = type <{ i64, i32, i8, [3 x i8], %"class.v8::internal::Object", i8, [3 x i8], i32, i32, i32, %"class.v8::internal::Object", %"class.v8::internal::Object", i32, i8, [3 x i8] }>
%"class.v8::internal::Handle.923" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HeapProfiler" = type { %"class.v8::internal::HeapObjectAllocationTracker", %"class.std::__1::unique_ptr.924", %"class.std::__1::vector.930", %"class.std::__1::unique_ptr.938", %"class.std::__1::unique_ptr.944", i8, i8, %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.950", %"class.std::__1::vector.956", %"struct.std::__1::pair.964" }
%"class.v8::internal::HeapObjectAllocationTracker" = type { i32 (...)** }
%"class.std::__1::unique_ptr.924" = type { %"class.std::__1::__compressed_pair.925" }
%"class.std::__1::__compressed_pair.925" = type { %"struct.std::__1::__compressed_pair_elem.926" }
%"struct.std::__1::__compressed_pair_elem.926" = type { %"class.v8::internal::HeapObjectsMap"* }
%"class.v8::internal::HeapObjectsMap" = type opaque
%"class.std::__1::vector.930" = type { %"class.std::__1::__vector_base.931" }
%"class.std::__1::__vector_base.931" = type { %"class.std::__1::unique_ptr.932"*, %"class.std::__1::unique_ptr.932"*, %"class.std::__1::__compressed_pair.933" }
%"class.std::__1::unique_ptr.932" = type opaque
%"class.std::__1::__compressed_pair.933" = type { %"struct.std::__1::__compressed_pair_elem.934" }
%"struct.std::__1::__compressed_pair_elem.934" = type { %"class.std::__1::unique_ptr.932"* }
%"class.std::__1::unique_ptr.938" = type { %"class.std::__1::__compressed_pair.939" }
%"class.std::__1::__compressed_pair.939" = type { %"struct.std::__1::__compressed_pair_elem.940" }
%"struct.std::__1::__compressed_pair_elem.940" = type { %"class.v8::internal::StringsStorage"* }
%"class.v8::internal::StringsStorage" = type opaque
%"class.std::__1::unique_ptr.944" = type { %"class.std::__1::__compressed_pair.945" }
%"class.std::__1::__compressed_pair.945" = type { %"struct.std::__1::__compressed_pair_elem.946" }
%"struct.std::__1::__compressed_pair_elem.946" = type { %"class.v8::internal::AllocationTracker"* }
%"class.v8::internal::AllocationTracker" = type opaque
%"class.std::__1::unique_ptr.950" = type { %"class.std::__1::__compressed_pair.951" }
%"class.std::__1::__compressed_pair.951" = type { %"struct.std::__1::__compressed_pair_elem.952" }
%"struct.std::__1::__compressed_pair_elem.952" = type { %"class.v8::internal::SamplingHeapProfiler"* }
%"class.v8::internal::SamplingHeapProfiler" = type opaque
%"class.std::__1::vector.956" = type { %"class.std::__1::__vector_base.957" }
%"class.std::__1::__vector_base.957" = type { %"struct.std::__1::pair.958"*, %"struct.std::__1::pair.958"*, %"class.std::__1::__compressed_pair.959" }
%"struct.std::__1::pair.958" = type opaque
%"class.std::__1::__compressed_pair.959" = type { %"struct.std::__1::__compressed_pair_elem.960" }
%"struct.std::__1::__compressed_pair_elem.960" = type { %"struct.std::__1::pair.958"* }
%"struct.std::__1::pair.964" = type { i8 (%"class.v8::Isolate"*, %"class.v8::Local.688"*, i16, i8*)*, i8* }
%"class.v8::Local.688" = type { %"class.v8::Value"* }
%"class.std::__1::unique_ptr.965" = type { %"class.std::__1::__compressed_pair.966" }
%"class.std::__1::__compressed_pair.966" = type { %"struct.std::__1::__compressed_pair_elem.967" }
%"struct.std::__1::__compressed_pair_elem.967" = type { %"class.v8::internal::CodeEventDispatcher"* }
%"class.v8::internal::CodeEventDispatcher" = type { %"class.v8::internal::CodeEventListener", %"class.std::__1::unordered_set.968", %"class.v8::base::Mutex" }
%"class.std::__1::unordered_set.968" = type { %"class.std::__1::__hash_table.969" }
%"class.std::__1::__hash_table.969" = type <{ %"class.std::__1::unique_ptr.970", %"class.std::__1::__compressed_pair.980", %"class.std::__1::__compressed_pair.985", %"class.std::__1::__compressed_pair.989", [4 x i8] }>
%"class.std::__1::unique_ptr.970" = type { %"class.std::__1::__compressed_pair.971" }
%"class.std::__1::__compressed_pair.971" = type { %"struct.std::__1::__compressed_pair_elem.972", %"struct.std::__1::__compressed_pair_elem.974" }
%"struct.std::__1::__compressed_pair_elem.972" = type { %"struct.std::__1::__hash_node_base.973"** }
%"struct.std::__1::__hash_node_base.973" = type { %"struct.std::__1::__hash_node_base.973"* }
%"struct.std::__1::__compressed_pair_elem.974" = type { %"class.std::__1::__bucket_list_deallocator.975" }
%"class.std::__1::__bucket_list_deallocator.975" = type { %"class.std::__1::__compressed_pair.976" }
%"class.std::__1::__compressed_pair.976" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.980" = type { %"struct.std::__1::__compressed_pair_elem.981" }
%"struct.std::__1::__compressed_pair_elem.981" = type { %"struct.std::__1::__hash_node_base.973" }
%"class.std::__1::__compressed_pair.985" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.989" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::AstStringConstants" = type opaque
%"class.v8::internal::interpreter::Interpreter" = type opaque
%"class.v8::internal::compiler::PerIsolateCompilerCache" = type opaque
%"class.v8::internal::Zone" = type <{ i64, i64, i64, i64, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::Segment"*, i8*, i8, i8, [6 x i8] }>
%"class.v8::internal::Segment" = type { %"class.v8::internal::Zone"*, %"class.v8::internal::Segment"*, i64 }
%"class.v8::internal::CompilerDispatcher" = type opaque
%"class.std::__1::queue" = type { %"class.std::__1::deque" }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.1003" }
%"struct.std::__1::__split_buffer" = type { %"struct.std::__1::pair.997"**, %"struct.std::__1::pair.997"**, %"struct.std::__1::pair.997"**, %"class.std::__1::__compressed_pair.998" }
%"struct.std::__1::pair.997" = type opaque
%"class.std::__1::__compressed_pair.998" = type { %"struct.std::__1::__compressed_pair_elem.999" }
%"struct.std::__1::__compressed_pair_elem.999" = type { %"struct.std::__1::pair.997"** }
%"class.std::__1::__compressed_pair.1003" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::String" = type { i8 }
%"class.v8::Context" = type { i8 }
%"class.v8::FunctionCallbackInfo" = type <{ i64*, i64*, i32, [4 x i8] }>
%"class.v8::internal::Relocatable" = type { i32 (...)**, %"class.v8::internal::Isolate"*, %"class.v8::internal::Relocatable"* }
%"class.std::__1::vector.1008" = type { %"class.std::__1::__vector_base.1009" }
%"class.std::__1::__vector_base.1009" = type { %"class.v8::internal::Handle.1010"*, %"class.v8::internal::Handle.1010"*, %"class.std::__1::__compressed_pair.1011" }
%"class.v8::internal::Handle.1010" = type { %"class.v8::internal::HandleBase" }
%"class.std::__1::__compressed_pair.1011" = type { %"struct.std::__1::__compressed_pair_elem.1012" }
%"struct.std::__1::__compressed_pair_elem.1012" = type { %"class.v8::internal::Handle.1010"* }
%"class.v8::internal::AddressToIndexHashMap" = type opaque
%"class.v8::internal::HeapObjectToIndexHashMap" = type opaque
%"class.v8::internal::MicrotaskQueue" = type opaque
%"class.v8::internal::CompilationStatistics" = type opaque
%"class.v8::internal::CodeTracer" = type <{ %"class.v8::internal::EmbeddedVector", %struct._IO_FILE*, i32, [4 x i8] }>
%"class.v8::internal::EmbeddedVector" = type { %"class.v8::internal::Vector", [128 x i8] }
%"class.v8::internal::Vector" = type { i8*, i64 }
%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%"class.v8::PromiseRejectMessage" = type { %"class.v8::Local.873", i32, %"class.v8::Local.688" }
%"class.v8::Local.873" = type { %"class.v8::Promise"* }
%"class.v8::StartupData" = type { i8*, i32 }
%"class.v8_inspector::V8Inspector" = type opaque
%"class.v8::internal::compiler::NodeObserver" = type opaque
%"class.v8::internal::OptimizingCompileDispatcher" = type opaque
%"class.std::__1::unique_ptr.1016" = type { %"class.std::__1::__compressed_pair.1017" }
%"class.std::__1::__compressed_pair.1017" = type { %"struct.std::__1::__compressed_pair_elem.1018" }
%"struct.std::__1::__compressed_pair_elem.1018" = type { %"class.v8::internal::PersistentHandlesList"* }
%"class.v8::internal::PersistentHandlesList" = type { %"class.v8::base::Mutex", %"class.v8::internal::PersistentHandles"* }
%"class.v8::internal::PersistentHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::vector.660", i64*, i64*, %"class.v8::internal::PersistentHandles"*, %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.1022" = type { %"class.std::__1::__vector_base.1023" }
%"class.std::__1::__vector_base.1023" = type { void (%"class.v8::Isolate"*)**, void (%"class.v8::Isolate"*)**, %"class.std::__1::__compressed_pair.1024" }
%"class.std::__1::__compressed_pair.1024" = type { %"struct.std::__1::__compressed_pair_elem.1025" }
%"struct.std::__1::__compressed_pair_elem.1025" = type { void (%"class.v8::Isolate"*)** }
%"class.std::__1::shared_ptr.1029" = type { %"class.v8::internal::metrics::Recorder"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::metrics::Recorder" = type opaque
%"class.std::__1::unordered_map.1030" = type { %"class.std::__1::__hash_table.1031" }
%"class.std::__1::__hash_table.1031" = type <{ %"class.std::__1::unique_ptr.1032", %"class.std::__1::__compressed_pair.1042", %"class.std::__1::__compressed_pair.1047", %"class.std::__1::__compressed_pair.1050", [4 x i8] }>
%"class.std::__1::unique_ptr.1032" = type { %"class.std::__1::__compressed_pair.1033" }
%"class.std::__1::__compressed_pair.1033" = type { %"struct.std::__1::__compressed_pair_elem.1034", %"struct.std::__1::__compressed_pair_elem.1036" }
%"struct.std::__1::__compressed_pair_elem.1034" = type { %"struct.std::__1::__hash_node_base.1035"** }
%"struct.std::__1::__hash_node_base.1035" = type { %"struct.std::__1::__hash_node_base.1035"* }
%"struct.std::__1::__compressed_pair_elem.1036" = type { %"class.std::__1::__bucket_list_deallocator.1037" }
%"class.std::__1::__bucket_list_deallocator.1037" = type { %"class.std::__1::__compressed_pair.1038" }
%"class.std::__1::__compressed_pair.1038" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1042" = type { %"struct.std::__1::__compressed_pair_elem.1043" }
%"struct.std::__1::__compressed_pair_elem.1043" = type { %"struct.std::__1::__hash_node_base.1035" }
%"class.std::__1::__compressed_pair.1047" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1050" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.v8::metrics::LongTaskStats" = type { i64, i64, i64 }
%"class.std::__1::vector.507" = type { %"class.std::__1::__vector_base.508" }
%"class.std::__1::__vector_base.508" = type { %"class.v8::internal::Object"*, %"class.v8::internal::Object"*, %"class.std::__1::__compressed_pair.509" }
%"class.std::__1::__compressed_pair.509" = type { %"struct.std::__1::__compressed_pair_elem.510" }
%"struct.std::__1::__compressed_pair_elem.510" = type { %"class.v8::internal::Object"* }
%"class.v8::internal::BuiltinsConstantsTableBuilder" = type opaque
%"class.v8::ArrayBuffer::Allocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.120" = type { %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::FutexWaitListNode" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::shared_ptr.1054", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::base::ConditionVariable", %"class.v8::internal::FutexWaitListNode"*, %"class.v8::internal::FutexWaitListNode"*, %"class.std::__1::weak_ptr.1079", i64, i8*, i8, i8, %"class.v8::Global", %"class.v8::Global.1080", %"class.v8::base::TimeTicks", i64 }
%"class.std::__1::shared_ptr.1054" = type { %"class.v8::TaskRunner"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::TaskRunner" = type { i32 (...)** }
%"class.v8::base::ConditionVariable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon.281, %union.anon.282, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon.281 = type { i64 }
%union.anon.282 = type { i64 }
%"class.std::__1::weak_ptr.1079" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::BackingStore" = type <{ i8*, %"struct.std::__1::atomic", i64, %"union.v8::internal::BackingStore::TypeSpecificData", i16, [6 x i8] }>
%"union.v8::internal::BackingStore::TypeSpecificData" = type { %"class.std::__1::shared_ptr.120" }
%"class.v8::Global" = type { %"class.v8::PersistentBase" }
%"class.v8::PersistentBase" = type { %"class.v8::Promise"* }
%"class.v8::Global.1080" = type { %"class.v8::PersistentBase.1081" }
%"class.v8::PersistentBase.1081" = type { %"class.v8::Context"* }
%"class.v8::internal::CancelableTaskManager" = type <{ i64, %"class.std::__1::unordered_map.1055", %"class.v8::base::ConditionVariable", %"class.v8::base::Mutex", i8, [7 x i8] }>
%"class.std::__1::unordered_map.1055" = type { %"class.std::__1::__hash_table.1056" }
%"class.std::__1::__hash_table.1056" = type <{ %"class.std::__1::unique_ptr.1057", %"class.std::__1::__compressed_pair.1067", %"class.std::__1::__compressed_pair.1072", %"class.std::__1::__compressed_pair.1075", [4 x i8] }>
%"class.std::__1::unique_ptr.1057" = type { %"class.std::__1::__compressed_pair.1058" }
%"class.std::__1::__compressed_pair.1058" = type { %"struct.std::__1::__compressed_pair_elem.1059", %"struct.std::__1::__compressed_pair_elem.1061" }
%"struct.std::__1::__compressed_pair_elem.1059" = type { %"struct.std::__1::__hash_node_base.1060"** }
%"struct.std::__1::__hash_node_base.1060" = type { %"struct.std::__1::__hash_node_base.1060"* }
%"struct.std::__1::__compressed_pair_elem.1061" = type { %"class.std::__1::__bucket_list_deallocator.1062" }
%"class.std::__1::__bucket_list_deallocator.1062" = type { %"class.std::__1::__compressed_pair.1063" }
%"class.std::__1::__compressed_pair.1063" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1067" = type { %"struct.std::__1::__compressed_pair_elem.1068" }
%"struct.std::__1::__compressed_pair_elem.1068" = type { %"struct.std::__1::__hash_node_base.1060" }
%"class.std::__1::__compressed_pair.1072" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1075" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::debug::ConsoleDelegate" = type { i32 (...)** }
%"class.v8::debug::AsyncEventDelegate" = type { i32 (...)** }
%"class.std::__1::unique_ptr.1082" = type { %"class.std::__1::__compressed_pair.1083" }
%"class.std::__1::__compressed_pair.1083" = type { %"struct.std::__1::__compressed_pair_elem.1084" }
%"struct.std::__1::__compressed_pair_elem.1084" = type { %"class.v8::internal::LocalIsolate"* }
%"class.v8::internal::LocalIsolate" = type { %"class.v8::internal::HiddenLocalFactory", %"class.v8::internal::LocalHeap", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.1087", %"class.v8::internal::ThreadId", i64, %"class.v8::internal::RuntimeCallStats"* }
%"class.v8::internal::HiddenLocalFactory" = type { %"class.v8::internal::LocalFactory" }
%"class.v8::internal::LocalFactory" = type { %"class.v8::internal::ReadOnlyRoots" }
%"class.v8::internal::ReadOnlyRoots" = type { i64* }
%"class.v8::internal::LocalHeap" = type { %"class.v8::internal::Heap"*, i8, %"struct.std::__1::atomic.641", i8, i8, %"class.v8::internal::LocalHeap"*, %"class.v8::internal::LocalHeap"*, %"class.std::__1::unique_ptr.645", %"class.std::__1::unique_ptr.670", %"class.std::__1::unique_ptr.441", %"class.std::__1::vector.676", %"class.v8::internal::ConcurrentAllocator" }
%"struct.std::__1::atomic.641" = type { %"struct.std::__1::__atomic_base.642" }
%"struct.std::__1::__atomic_base.642" = type { %"struct.std::__1::__cxx_atomic_impl.643" }
%"struct.std::__1::__cxx_atomic_impl.643" = type { %"struct.std::__1::__cxx_atomic_base_impl.644" }
%"struct.std::__1::__cxx_atomic_base_impl.644" = type { i32 }
%"class.std::__1::unique_ptr.645" = type { %"class.std::__1::__compressed_pair.646" }
%"class.std::__1::__compressed_pair.646" = type { %"struct.std::__1::__compressed_pair_elem.647" }
%"struct.std::__1::__compressed_pair_elem.647" = type { %"class.v8::internal::LocalHandles"* }
%"class.v8::internal::LocalHandles" = type { %"struct.v8::internal::HandleScopeData", %"class.std::__1::vector.660" }
%"class.std::__1::unique_ptr.670" = type { %"class.std::__1::__compressed_pair.671" }
%"class.std::__1::__compressed_pair.671" = type { %"struct.std::__1::__compressed_pair_elem.672" }
%"struct.std::__1::__compressed_pair_elem.672" = type { %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.676" = type { %"class.std::__1::__vector_base.677" }
%"class.std::__1::__vector_base.677" = type { %"struct.std::__1::pair.678"*, %"struct.std::__1::pair.678"*, %"class.std::__1::__compressed_pair.679" }
%"struct.std::__1::pair.678" = type opaque
%"class.std::__1::__compressed_pair.679" = type { %"struct.std::__1::__compressed_pair_elem.680" }
%"struct.std::__1::__compressed_pair_elem.680" = type { %"struct.std::__1::pair.678"* }
%"class.v8::internal::ConcurrentAllocator" = type { %"class.v8::internal::LocalHeap"*, %"class.v8::internal::PagedSpace"*, %"class.v8::internal::LocalAllocationBuffer" }
%"class.v8::internal::PagedSpace" = type { %"class.v8::internal::SpaceWithLinearArea", i32, i32, i64, %"class.v8::internal::AllocationStats", %"class.v8::base::Mutex", i64, i64 }
%"class.v8::internal::LocalAllocationBuffer" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::LinearAllocationArea" }
%"class.std::__1::unique_ptr.1087" = type { %"class.std::__1::__compressed_pair.1088" }
%"class.std::__1::__compressed_pair.1088" = type { %"struct.std::__1::__compressed_pair_elem.1089" }
%"struct.std::__1::__compressed_pair_elem.1089" = type { %"class.v8::internal::LocalLogger"* }
%"class.v8::internal::LocalLogger" = type opaque
%"struct.v8::internal::ManagedPtrDestructor" = type { i64, %"struct.v8::internal::ManagedPtrDestructor"*, %"struct.v8::internal::ManagedPtrDestructor"*, i8*, void (i8*)*, i64* }
%"class.v8::internal::wasm::WasmEngine" = type opaque
%"class.std::__1::unique_ptr.1096" = type { %"class.std::__1::__compressed_pair.1097" }
%"class.std::__1::__compressed_pair.1097" = type { %"struct.std::__1::__compressed_pair_elem.1098" }
%"struct.std::__1::__compressed_pair_elem.1098" = type { %"class.v8::internal::TracingCpuProfilerImpl"* }
%"class.v8::internal::TracingCpuProfilerImpl" = type opaque
%"class.v8::internal::EmbeddedFileWriterInterface" = type opaque
%"class.v8::Context::BackupIncumbentScope" = type { %"class.v8::Local.874", i64, %"class.v8::Context::BackupIncumbentScope"* }
%"class.v8::Local.874" = type { %"class.v8::Context"* }
%"class.v8::internal::Isolate::ThreadDataTable" = type { %"class.std::__1::unordered_map.1104" }
%"class.std::__1::unordered_map.1104" = type { %"class.std::__1::__hash_table.1105" }
%"class.std::__1::__hash_table.1105" = type <{ %"class.std::__1::unique_ptr.1106", %"class.std::__1::__compressed_pair.1116", %"class.std::__1::__compressed_pair.1121", %"class.std::__1::__compressed_pair.1124", [4 x i8] }>
%"class.std::__1::unique_ptr.1106" = type { %"class.std::__1::__compressed_pair.1107" }
%"class.std::__1::__compressed_pair.1107" = type { %"struct.std::__1::__compressed_pair_elem.1108", %"struct.std::__1::__compressed_pair_elem.1110" }
%"struct.std::__1::__compressed_pair_elem.1108" = type { %"struct.std::__1::__hash_node_base.1109"** }
%"struct.std::__1::__hash_node_base.1109" = type { %"struct.std::__1::__hash_node_base.1109"* }
%"struct.std::__1::__compressed_pair_elem.1110" = type { %"class.std::__1::__bucket_list_deallocator.1111" }
%"class.std::__1::__bucket_list_deallocator.1111" = type { %"class.std::__1::__compressed_pair.1112" }
%"class.std::__1::__compressed_pair.1112" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1116" = type { %"struct.std::__1::__compressed_pair_elem.1117" }
%"struct.std::__1::__compressed_pair_elem.1117" = type { %"struct.std::__1::__hash_node_base.1109" }
%"class.std::__1::__compressed_pair.1121" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1124" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::atomic.1130" = type { %"struct.std::__1::__atomic_base.1131" }
%"struct.std::__1::__atomic_base.1131" = type { %"struct.std::__1::__cxx_atomic_impl.1132" }
%"struct.std::__1::__cxx_atomic_impl.1132" = type { %"struct.std::__1::__cxx_atomic_base_impl.1133" }
%"struct.std::__1::__cxx_atomic_base_impl.1133" = type { %"class.std::__1::vector.1134"* }
%"class.std::__1::vector.1134" = type { %"class.std::__1::__vector_base.1135" }
%"class.std::__1::__vector_base.1135" = type { %"struct.v8::MemoryRange"*, %"struct.v8::MemoryRange"*, %"class.std::__1::__compressed_pair.1136" }
%"struct.v8::MemoryRange" = type { i8*, i64 }
%"class.std::__1::__compressed_pair.1136" = type { %"struct.std::__1::__compressed_pair_elem.1137" }
%"struct.std::__1::__compressed_pair_elem.1137" = type { %"struct.v8::MemoryRange"* }
%"struct.std::__1::atomic.20" = type { %"struct.std::__1::__atomic_base.21" }
%"struct.std::__1::__atomic_base.21" = type { %"struct.std::__1::__cxx_atomic_impl.22" }
%"struct.std::__1::__cxx_atomic_impl.22" = type { %"struct.std::__1::__cxx_atomic_base_impl.23" }
%"struct.std::__1::__cxx_atomic_base_impl.23" = type { i32 }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"struct.std::__1::pair"*, %"struct.std::__1::pair"*, %"class.std::__1::__compressed_pair.24" }
%"struct.std::__1::pair" = type opaque
%"class.std::__1::__compressed_pair.24" = type { %"struct.std::__1::__compressed_pair_elem.25" }
%"struct.std::__1::__compressed_pair_elem.25" = type { %"struct.std::__1::pair"* }
%"class.v8::internal::CodeSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::OldLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace" }
%"class.v8::internal::LargeObjectSpace" = type { %"class.v8::internal::Space", %"struct.std::__1::atomic", i32, %"struct.std::__1::atomic", %"class.v8::base::Mutex", %"struct.std::__1::atomic" }
%"class.v8::internal::CodeLargeObjectSpace" = type { %"class.v8::internal::OldLargeObjectSpace", %"class.std::__1::unordered_map.71" }
%"class.std::__1::unordered_map.71" = type { %"class.std::__1::__hash_table.72" }
%"class.std::__1::__hash_table.72" = type <{ %"class.std::__1::unique_ptr.73", %"class.std::__1::__compressed_pair.83", %"class.std::__1::__compressed_pair.88", %"class.std::__1::__compressed_pair.93", [4 x i8] }>
%"class.std::__1::unique_ptr.73" = type { %"class.std::__1::__compressed_pair.74" }
%"class.std::__1::__compressed_pair.74" = type { %"struct.std::__1::__compressed_pair_elem.75", %"struct.std::__1::__compressed_pair_elem.77" }
%"struct.std::__1::__compressed_pair_elem.75" = type { %"struct.std::__1::__hash_node_base.76"** }
%"struct.std::__1::__hash_node_base.76" = type { %"struct.std::__1::__hash_node_base.76"* }
%"struct.std::__1::__compressed_pair_elem.77" = type { %"class.std::__1::__bucket_list_deallocator.78" }
%"class.std::__1::__bucket_list_deallocator.78" = type { %"class.std::__1::__compressed_pair.79" }
%"class.std::__1::__compressed_pair.79" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.83" = type { %"struct.std::__1::__compressed_pair_elem.84" }
%"struct.std::__1::__compressed_pair_elem.84" = type { %"struct.std::__1::__hash_node_base.76" }
%"class.std::__1::__compressed_pair.88" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.93" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::NewLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace", i64 }
%"class.v8::internal::OldSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::MapSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.std::__1::unique_ptr.106" = type { %"class.std::__1::__compressed_pair.107" }
%"class.std::__1::__compressed_pair.107" = type { %"struct.std::__1::__compressed_pair_elem.108" }
%"struct.std::__1::__compressed_pair_elem.108" = type { %"class.v8::internal::ConcurrentAllocator"* }
%"class.v8::internal::ArrayBufferExtension" = type { %"struct.std::__1::atomic.112", %"struct.std::__1::atomic.116", %"class.std::__1::shared_ptr", %"class.v8::internal::ArrayBufferExtension"*, %"struct.std::__1::atomic" }
%"struct.std::__1::atomic.116" = type { %"struct.std::__1::__atomic_base.117" }
%"struct.std::__1::__atomic_base.117" = type { %"struct.std::__1::__cxx_atomic_impl.118" }
%"struct.std::__1::__cxx_atomic_impl.118" = type { %"struct.std::__1::__cxx_atomic_base_impl.119" }
%"struct.std::__1::__cxx_atomic_base_impl.119" = type { i8 }
%"class.std::__1::shared_ptr" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"struct.std::__1::atomic.121" = type { %"struct.std::__1::__atomic_base.122" }
%"struct.std::__1::__atomic_base.122" = type { %"struct.std::__1::__cxx_atomic_impl.123" }
%"struct.std::__1::__cxx_atomic_impl.123" = type { %"struct.std::__1::__cxx_atomic_base_impl.124" }
%"struct.std::__1::__cxx_atomic_base_impl.124" = type { i32 }
%"class.v8::internal::AllocationObserver" = type { i32 (...)**, i64 }
%"class.v8::internal::StressScavengeObserver" = type opaque
%"class.v8::internal::Object" = type { %"class.v8::internal::TaggedImpl" }
%"class.v8::internal::TaggedImpl" = type { i64 }
%"class.std::__1::vector.125" = type { %"class.std::__1::__vector_base.126" }
%"class.std::__1::__vector_base.126" = type { %"struct.v8::internal::Heap::GCCallbackTuple"*, %"struct.v8::internal::Heap::GCCallbackTuple"*, %"class.std::__1::__compressed_pair.127" }
%"struct.v8::internal::Heap::GCCallbackTuple" = type { void (%"class.v8::Isolate"*, i32, i32, i8*)*, i32, i8* }
%"class.std::__1::__compressed_pair.127" = type { %"struct.std::__1::__compressed_pair_elem.128" }
%"struct.std::__1::__compressed_pair_elem.128" = type { %"struct.v8::internal::Heap::GCCallbackTuple"* }
%"class.std::__1::unique_ptr.132" = type { %"class.std::__1::__compressed_pair.133" }
%"class.std::__1::__compressed_pair.133" = type { %"struct.std::__1::__compressed_pair_elem.134" }
%"struct.std::__1::__compressed_pair_elem.134" = type { %"class.v8::internal::GCTracer"* }
%"class.v8::internal::GCTracer" = type opaque
%"class.std::__1::unique_ptr.138" = type { %"class.std::__1::__compressed_pair.139" }
%"class.std::__1::__compressed_pair.139" = type { %"struct.std::__1::__compressed_pair_elem.140" }
%"struct.std::__1::__compressed_pair_elem.140" = type { %"class.v8::internal::MarkCompactCollector"* }
%"class.v8::internal::MarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::base::Mutex", %"class.v8::base::Semaphore", i8, i8, i8, i8, i8, i8, [2 x i8], %"class.v8::internal::MarkingWorklists", %"class.v8::internal::WeakObjects", %"struct.v8::internal::EphemeronMarking", %"class.std::__1::unique_ptr.180", %"class.std::__1::unique_ptr.186", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", %"class.std::__1::vector.240", %"class.std::__1::vector.240", %"class.std::__1::vector.240", %"class.std::__1::vector.247", %"class.v8::internal::Sweeper"*, %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", [2 x i8], i32, i32, [4 x i8] }>
%"class.v8::internal::MarkCompactCollectorBase" = type { i32 (...)**, %"class.v8::internal::Heap"* }
%"class.v8::base::Semaphore" = type { %union.sem_t }
%union.sem_t = type { i64, [24 x i8] }
%"class.v8::internal::MarkingWorklists" = type { %"class.heap::base::Worklist", %"class.heap::base::Worklist", %"class.heap::base::Worklist.141", %"class.std::__1::vector.142", %"class.std::__1::vector.149", %"class.heap::base::Worklist" }
%"class.heap::base::Worklist.141" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment"*, %"struct.std::__1::atomic" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment" = type opaque
%"class.std::__1::vector.142" = type { %"class.std::__1::__vector_base.143" }
%"class.std::__1::__vector_base.143" = type { %"struct.v8::internal::ContextWorklistPair"*, %"struct.v8::internal::ContextWorklistPair"*, %"class.std::__1::__compressed_pair.144" }
%"struct.v8::internal::ContextWorklistPair" = type { i64, %"class.heap::base::Worklist"* }
%"class.std::__1::__compressed_pair.144" = type { %"struct.std::__1::__compressed_pair_elem.145" }
%"struct.std::__1::__compressed_pair_elem.145" = type { %"struct.v8::internal::ContextWorklistPair"* }
%"class.std::__1::vector.149" = type { %"class.std::__1::__vector_base.150" }
%"class.std::__1::__vector_base.150" = type { %"class.std::__1::unique_ptr.151"*, %"class.std::__1::unique_ptr.151"*, %"class.std::__1::__compressed_pair.152" }
%"class.std::__1::unique_ptr.151" = type opaque
%"class.std::__1::__compressed_pair.152" = type { %"struct.std::__1::__compressed_pair_elem.153" }
%"struct.std::__1::__compressed_pair_elem.153" = type { %"class.std::__1::unique_ptr.151"* }
%"class.heap::base::Worklist" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment" = type opaque
%"class.v8::internal::WeakObjects" = type { %"class.v8::internal::Worklist", %"class.v8::internal::Worklist.157", %"class.v8::internal::Worklist.159", %"class.v8::internal::Worklist.159", %"class.v8::internal::Worklist.159", %"class.v8::internal::Worklist.161", %"class.v8::internal::Worklist.163", %"class.v8::internal::Worklist.165", %"class.v8::internal::Worklist.167", %"class.v8::internal::Worklist.169", %"class.v8::internal::Worklist.171" }
%"class.v8::internal::Worklist" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.157" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.159" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.161" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.163" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.165" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.167" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.169" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.171" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"struct.std::__1::atomic" }
%"struct.v8::internal::EphemeronMarking" = type { %"class.std::__1::vector.173", i8, i64 }
%"class.std::__1::vector.173" = type { %"class.std::__1::__vector_base.174" }
%"class.std::__1::__vector_base.174" = type { %"class.v8::internal::HeapObject"*, %"class.v8::internal::HeapObject"*, %"class.std::__1::__compressed_pair.175" }
%"class.std::__1::__compressed_pair.175" = type { %"struct.std::__1::__compressed_pair_elem.176" }
%"struct.std::__1::__compressed_pair_elem.176" = type { %"class.v8::internal::HeapObject"* }
%"class.std::__1::unique_ptr.180" = type { %"class.std::__1::__compressed_pair.181" }
%"class.std::__1::__compressed_pair.181" = type { %"struct.std::__1::__compressed_pair_elem.182" }
%"struct.std::__1::__compressed_pair_elem.182" = type { %"class.v8::internal::MainMarkingVisitor"* }
%"class.v8::internal::MainMarkingVisitor" = type opaque
%"class.std::__1::unique_ptr.186" = type { %"class.std::__1::__compressed_pair.187" }
%"class.std::__1::__compressed_pair.187" = type { %"struct.std::__1::__compressed_pair_elem.188" }
%"struct.std::__1::__compressed_pair_elem.188" = type { %"class.v8::internal::MarkingWorklists::Local"* }
%"class.v8::internal::MarkingWorklists::Local" = type { %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", i64, %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local"*, i8, [7 x i8], %"class.std::__1::unordered_map.189" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local" = type { %"class.heap::base::Worklist.141"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.heap::base::internal::SegmentBase" = type { i16, i16 }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local" = type { %"class.heap::base::Worklist"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.std::__1::unordered_map.189" = type { %"class.std::__1::__hash_table.190" }
%"class.std::__1::__hash_table.190" = type <{ %"class.std::__1::unique_ptr.191", %"class.std::__1::__compressed_pair.201", %"class.std::__1::__compressed_pair.206", %"class.std::__1::__compressed_pair.209", [4 x i8] }>
%"class.std::__1::unique_ptr.191" = type { %"class.std::__1::__compressed_pair.192" }
%"class.std::__1::__compressed_pair.192" = type { %"struct.std::__1::__compressed_pair_elem.193", %"struct.std::__1::__compressed_pair_elem.195" }
%"struct.std::__1::__compressed_pair_elem.193" = type { %"struct.std::__1::__hash_node_base.194"** }
%"struct.std::__1::__hash_node_base.194" = type { %"struct.std::__1::__hash_node_base.194"* }
%"struct.std::__1::__compressed_pair_elem.195" = type { %"class.std::__1::__bucket_list_deallocator.196" }
%"class.std::__1::__bucket_list_deallocator.196" = type { %"class.std::__1::__compressed_pair.197" }
%"class.std::__1::__compressed_pair.197" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.201" = type { %"struct.std::__1::__compressed_pair_elem.202" }
%"struct.std::__1::__compressed_pair_elem.202" = type { %"struct.std::__1::__hash_node_base.194" }
%"class.std::__1::__compressed_pair.206" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.209" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::NativeContextInferrer" = type { i8 }
%"class.v8::internal::NativeContextStats" = type { %"class.std::__1::unordered_map.216" }
%"class.std::__1::unordered_map.216" = type { %"class.std::__1::__hash_table.217" }
%"class.std::__1::__hash_table.217" = type <{ %"class.std::__1::unique_ptr.218", %"class.std::__1::__compressed_pair.228", %"class.std::__1::__compressed_pair.233", %"class.std::__1::__compressed_pair.236", [4 x i8] }>
%"class.std::__1::unique_ptr.218" = type { %"class.std::__1::__compressed_pair.219" }
%"class.std::__1::__compressed_pair.219" = type { %"struct.std::__1::__compressed_pair_elem.220", %"struct.std::__1::__compressed_pair_elem.222" }
%"struct.std::__1::__compressed_pair_elem.220" = type { %"struct.std::__1::__hash_node_base.221"** }
%"struct.std::__1::__hash_node_base.221" = type { %"struct.std::__1::__hash_node_base.221"* }
%"struct.std::__1::__compressed_pair_elem.222" = type { %"class.std::__1::__bucket_list_deallocator.223" }
%"class.std::__1::__bucket_list_deallocator.223" = type { %"class.std::__1::__compressed_pair.224" }
%"class.std::__1::__compressed_pair.224" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.228" = type { %"struct.std::__1::__compressed_pair_elem.229" }
%"struct.std::__1::__compressed_pair_elem.229" = type { %"struct.std::__1::__hash_node_base.221" }
%"class.std::__1::__compressed_pair.233" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.236" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::vector.240" = type { %"class.std::__1::__vector_base.241" }
%"class.std::__1::__vector_base.241" = type { %"class.v8::internal::Page"**, %"class.v8::internal::Page"**, %"class.std::__1::__compressed_pair.242" }
%"class.v8::internal::Page" = type { %"class.v8::internal::MemoryChunk" }
%"class.v8::internal::MemoryChunk" = type { %"class.v8::internal::BasicMemoryChunk", [2 x %"class.v8::internal::SlotSet"*], %"struct.std::__1::atomic", %"struct.std::__1::atomic.15", %"class.v8::internal::SlotSet"*, [2 x %"class.v8::internal::TypedSlotSet"*], [2 x %"class.std::__1::set.622"*], %"class.v8::base::Mutex"*, %"struct.std::__1::atomic.630", %"class.v8::base::Mutex"*, i64, [2 x %"struct.std::__1::atomic"], %"class.v8::internal::heap::ListNode", %"class.v8::internal::FreeListCategory"**, %"struct.std::__1::atomic.15", %"class.v8::internal::Bitmap"*, %"class.v8::internal::CodeObjectRegistry"*, %"class.v8::internal::PossiblyEmptyBuckets" }
%"class.v8::internal::SlotSet" = type { i8 }
%"class.v8::internal::TypedSlotSet" = type { %"class.v8::internal::TypedSlots", i64 }
%"class.v8::internal::TypedSlots" = type { i32 (...)**, %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"* }
%"struct.v8::internal::TypedSlots::Chunk" = type { %"struct.v8::internal::TypedSlots::Chunk"*, %"class.std::__1::vector.615" }
%"class.std::__1::vector.615" = type { %"class.std::__1::__vector_base.616" }
%"class.std::__1::__vector_base.616" = type { %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"*, %"class.std::__1::__compressed_pair.617" }
%"struct.v8::internal::TypedSlots::TypedSlot" = type { i32 }
%"class.std::__1::__compressed_pair.617" = type { %"struct.std::__1::__compressed_pair_elem.618" }
%"struct.std::__1::__compressed_pair_elem.618" = type { %"struct.v8::internal::TypedSlots::TypedSlot"* }
%"class.std::__1::set.622" = type { %"class.std::__1::__tree.623" }
%"class.std::__1::__tree.623" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.624", %"class.std::__1::__compressed_pair.628" }
%"class.std::__1::__compressed_pair.624" = type { %"struct.std::__1::__compressed_pair_elem.452" }
%"class.std::__1::__compressed_pair.628" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"struct.std::__1::atomic.630" = type { %"struct.std::__1::__atomic_base.631" }
%"struct.std::__1::__atomic_base.631" = type { %"struct.std::__1::__cxx_atomic_impl.632" }
%"struct.std::__1::__cxx_atomic_impl.632" = type { %"struct.std::__1::__cxx_atomic_base_impl.633" }
%"struct.std::__1::__cxx_atomic_base_impl.633" = type { i64 }
%"class.v8::internal::heap::ListNode" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::FreeListCategory" = type { i32, i32, %"class.v8::internal::FreeSpace", %"class.v8::internal::FreeListCategory"*, %"class.v8::internal::FreeListCategory"* }
%"class.v8::internal::FreeSpace" = type { %"class.v8::internal::TorqueGeneratedFreeSpace" }
%"class.v8::internal::TorqueGeneratedFreeSpace" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Bitmap" = type { i8 }
%"class.v8::internal::CodeObjectRegistry" = type <{ %"class.std::__1::vector.634", i8, [7 x i8] }>
%"class.std::__1::vector.634" = type { %"class.std::__1::__vector_base.635" }
%"class.std::__1::__vector_base.635" = type { i64*, i64*, %"class.std::__1::__compressed_pair.636" }
%"class.std::__1::__compressed_pair.636" = type { %"struct.std::__1::__compressed_pair_elem.637" }
%"struct.std::__1::__compressed_pair_elem.637" = type { i64* }
%"class.v8::internal::PossiblyEmptyBuckets" = type { i64 }
%"class.std::__1::__compressed_pair.242" = type { %"struct.std::__1::__compressed_pair_elem.243" }
%"struct.std::__1::__compressed_pair_elem.243" = type { %"class.v8::internal::Page"** }
%"class.std::__1::vector.247" = type { %"class.std::__1::__vector_base.248" }
%"class.std::__1::__vector_base.248" = type { %"struct.std::__1::pair.249"*, %"struct.std::__1::pair.249"*, %"class.std::__1::__compressed_pair.250" }
%"struct.std::__1::pair.249" = type opaque
%"class.std::__1::__compressed_pair.250" = type { %"struct.std::__1::__compressed_pair_elem.251" }
%"struct.std::__1::__compressed_pair_elem.251" = type { %"struct.std::__1::pair.249"* }
%"class.v8::internal::Sweeper" = type <{ %"class.v8::internal::Heap"*, %"class.v8::internal::MajorNonAtomicMarkingState"*, %"class.std::__1::unique_ptr.255", %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.240"], [3 x %"class.std::__1::vector.240"], i8, %"struct.std::__1::atomic.112", [6 x i8], %"class.std::__1::vector.240", i64, %"class.v8::base::Semaphore", i8, i8, i8, [5 x i8] }>
%"class.std::__1::unique_ptr.255" = type { %"class.std::__1::__compressed_pair.256" }
%"class.std::__1::__compressed_pair.256" = type { %"struct.std::__1::__compressed_pair_elem.257" }
%"struct.std::__1::__compressed_pair_elem.257" = type { %"class.v8::JobHandle"* }
%"class.v8::JobHandle" = type { i32 (...)** }
%"class.v8::internal::MajorMarkingState" = type { i8 }
%"class.v8::internal::MajorNonAtomicMarkingState" = type { i8 }
%"class.v8::internal::MinorMarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::internal::Worklist.265"*, %"class.v8::internal::YoungGenerationMarkingVisitor"*, %"class.v8::base::Semaphore", %"class.std::__1::vector.240", %"class.std::__1::vector.240", %"class.v8::internal::MinorMarkingState", %"class.v8::internal::MinorNonAtomicMarkingState", [6 x i8] }>
%"class.v8::internal::Worklist.265" = type opaque
%"class.v8::internal::YoungGenerationMarkingVisitor" = type opaque
%"class.v8::internal::MinorMarkingState" = type { i8 }
%"class.v8::internal::MinorNonAtomicMarkingState" = type { i8 }
%"class.std::__1::unique_ptr.268" = type { %"class.std::__1::__compressed_pair.269" }
%"class.std::__1::__compressed_pair.269" = type { %"struct.std::__1::__compressed_pair_elem.270" }
%"struct.std::__1::__compressed_pair_elem.270" = type { %"class.v8::internal::ScavengerCollector"* }
%"class.v8::internal::ScavengerCollector" = type opaque
%"class.std::__1::unique_ptr.274" = type { %"class.std::__1::__compressed_pair.275" }
%"class.std::__1::__compressed_pair.275" = type { %"struct.std::__1::__compressed_pair_elem.276" }
%"struct.std::__1::__compressed_pair_elem.276" = type { %"class.v8::internal::ArrayBufferSweeper"* }
%"class.v8::internal::ArrayBufferSweeper" = type { %"class.v8::base::Optional", %"class.v8::internal::Heap"*, i8, %"class.v8::base::Mutex", %"class.v8::base::ConditionVariable", %"struct.std::__1::atomic", %"struct.v8::internal::ArrayBufferList", %"struct.v8::internal::ArrayBufferList", i64, i64 }
%"class.v8::base::Optional" = type { %"class.v8::base::internal::OptionalBase" }
%"class.v8::base::internal::OptionalBase" = type { %"struct.v8::base::internal::OptionalStorage" }
%"struct.v8::base::internal::OptionalStorage" = type { %"struct.v8::base::internal::OptionalStorageBase" }
%"struct.v8::base::internal::OptionalStorageBase" = type { i8, [7 x i8], %union.anon }
%union.anon = type { %"struct.v8::internal::ArrayBufferSweeper::SweepingJob" }
%"struct.v8::internal::ArrayBufferSweeper::SweepingJob" = type <{ %"class.v8::internal::ArrayBufferSweeper"*, i64, %"struct.std::__1::atomic.277", [4 x i8], %"struct.v8::internal::ArrayBufferList", %"struct.v8::internal::ArrayBufferList", i32, [4 x i8] }>
%"struct.std::__1::atomic.277" = type { %"struct.std::__1::__atomic_base.278" }
%"struct.std::__1::__atomic_base.278" = type { %"struct.std::__1::__cxx_atomic_impl.279" }
%"struct.std::__1::__cxx_atomic_impl.279" = type { %"struct.std::__1::__cxx_atomic_base_impl.280" }
%"struct.std::__1::__cxx_atomic_base_impl.280" = type { i32 }
%"struct.v8::internal::ArrayBufferList" = type { %"class.v8::internal::ArrayBufferExtension"*, %"class.v8::internal::ArrayBufferExtension"*, i64 }
%"class.std::__1::unique_ptr.287" = type { %"class.std::__1::__compressed_pair.288" }
%"class.std::__1::__compressed_pair.288" = type { %"struct.std::__1::__compressed_pair_elem.289" }
%"struct.std::__1::__compressed_pair_elem.289" = type { %"class.v8::internal::MemoryAllocator"* }
%"class.v8::internal::MemoryAllocator" = type { %"class.v8::internal::Isolate"*, %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"*, i64, %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.v8::internal::VirtualMemory", %"class.v8::internal::MemoryAllocator::Unmapper", %"class.std::__1::unordered_set.297", %"class.v8::base::Mutex" }
%"class.v8::internal::MemoryAllocator::Unmapper" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MemoryAllocator"*, %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.290"], %"class.std::__1::unique_ptr.255" }
%"class.std::__1::vector.290" = type { %"class.std::__1::__vector_base.291" }
%"class.std::__1::__vector_base.291" = type { %"class.v8::internal::MemoryChunk"**, %"class.v8::internal::MemoryChunk"**, %"class.std::__1::__compressed_pair.292" }
%"class.std::__1::__compressed_pair.292" = type { %"struct.std::__1::__compressed_pair_elem.293" }
%"struct.std::__1::__compressed_pair_elem.293" = type { %"class.v8::internal::MemoryChunk"** }
%"class.std::__1::unique_ptr.326" = type { %"class.std::__1::__compressed_pair.327" }
%"class.std::__1::__compressed_pair.327" = type { %"struct.std::__1::__compressed_pair_elem.328" }
%"struct.std::__1::__compressed_pair_elem.328" = type { %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::IncrementalMarking" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MarkCompactCollector"*, %"class.v8::internal::WeakObjects"*, double, double, i64, i64, i64, i64, double, i64, %"struct.std::__1::atomic.329", i8, i8, i8, i8, [3 x i8], %"class.v8::internal::IncrementalMarkingJob", %"struct.std::__1::atomic.333", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorAtomicMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", %"class.v8::base::Mutex", %"class.std::__1::unordered_map.338" }
%"struct.std::__1::atomic.329" = type { %"struct.std::__1::__atomic_base.330" }
%"struct.std::__1::__atomic_base.330" = type { %"struct.std::__1::__cxx_atomic_impl.331" }
%"struct.std::__1::__cxx_atomic_impl.331" = type { %"struct.std::__1::__cxx_atomic_base_impl.332" }
%"struct.std::__1::__cxx_atomic_base_impl.332" = type { i8 }
%"class.v8::internal::IncrementalMarkingJob" = type <{ %"class.v8::base::Mutex", double, i8, i8, [6 x i8] }>
%"struct.std::__1::atomic.333" = type { %"struct.std::__1::__atomic_base.334" }
%"struct.std::__1::__atomic_base.334" = type { %"struct.std::__1::__cxx_atomic_impl.335" }
%"struct.std::__1::__cxx_atomic_impl.335" = type { %"struct.std::__1::__cxx_atomic_base_impl.336" }
%"struct.std::__1::__cxx_atomic_base_impl.336" = type { i32 }
%"class.v8::internal::IncrementalMarking::Observer" = type { %"class.v8::internal::AllocationObserver", %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::MajorAtomicMarkingState" = type { i8 }
%"class.std::__1::unordered_map.338" = type { %"class.std::__1::__hash_table.339" }
%"class.std::__1::__hash_table.339" = type <{ %"class.std::__1::unique_ptr.340", %"class.std::__1::__compressed_pair.350", %"class.std::__1::__compressed_pair.355", %"class.std::__1::__compressed_pair.358", [4 x i8] }>
%"class.std::__1::unique_ptr.340" = type { %"class.std::__1::__compressed_pair.341" }
%"class.std::__1::__compressed_pair.341" = type { %"struct.std::__1::__compressed_pair_elem.342", %"struct.std::__1::__compressed_pair_elem.344" }
%"struct.std::__1::__compressed_pair_elem.342" = type { %"struct.std::__1::__hash_node_base.343"** }
%"struct.std::__1::__hash_node_base.343" = type { %"struct.std::__1::__hash_node_base.343"* }
%"struct.std::__1::__compressed_pair_elem.344" = type { %"class.std::__1::__bucket_list_deallocator.345" }
%"class.std::__1::__bucket_list_deallocator.345" = type { %"class.std::__1::__compressed_pair.346" }
%"class.std::__1::__compressed_pair.346" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.350" = type { %"struct.std::__1::__compressed_pair_elem.351" }
%"struct.std::__1::__compressed_pair_elem.351" = type { %"struct.std::__1::__hash_node_base.343" }
%"class.std::__1::__compressed_pair.355" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.358" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.365" = type { %"class.std::__1::__compressed_pair.366" }
%"class.std::__1::__compressed_pair.366" = type { %"struct.std::__1::__compressed_pair_elem.367" }
%"struct.std::__1::__compressed_pair_elem.367" = type { %"class.v8::internal::ConcurrentMarking"* }
%"class.v8::internal::ConcurrentMarking" = type <{ %"class.std::__1::unique_ptr.255", %"class.v8::internal::Heap"*, %"class.v8::internal::MarkingWorklists"*, %"class.v8::internal::WeakObjects"*, [8 x %"struct.v8::internal::ConcurrentMarking::TaskState"], %"struct.std::__1::atomic", %"struct.std::__1::atomic.112", [7 x i8] }>
%"struct.v8::internal::ConcurrentMarking::TaskState" = type { i64, %"class.std::__1::unordered_map.368", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", [64 x i8] }
%"class.std::__1::unordered_map.368" = type { %"class.std::__1::__hash_table.369" }
%"class.std::__1::__hash_table.369" = type <{ %"class.std::__1::unique_ptr.370", %"class.std::__1::__compressed_pair.380", %"class.std::__1::__compressed_pair.385", %"class.std::__1::__compressed_pair.388", [4 x i8] }>
%"class.std::__1::unique_ptr.370" = type { %"class.std::__1::__compressed_pair.371" }
%"class.std::__1::__compressed_pair.371" = type { %"struct.std::__1::__compressed_pair_elem.372", %"struct.std::__1::__compressed_pair_elem.374" }
%"struct.std::__1::__compressed_pair_elem.372" = type { %"struct.std::__1::__hash_node_base.373"** }
%"struct.std::__1::__hash_node_base.373" = type { %"struct.std::__1::__hash_node_base.373"* }
%"struct.std::__1::__compressed_pair_elem.374" = type { %"class.std::__1::__bucket_list_deallocator.375" }
%"class.std::__1::__bucket_list_deallocator.375" = type { %"class.std::__1::__compressed_pair.376" }
%"class.std::__1::__compressed_pair.376" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.380" = type { %"struct.std::__1::__compressed_pair_elem.381" }
%"struct.std::__1::__compressed_pair_elem.381" = type { %"struct.std::__1::__hash_node_base.373" }
%"class.std::__1::__compressed_pair.385" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.388" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.395" = type { %"class.std::__1::__compressed_pair.396" }
%"class.std::__1::__compressed_pair.396" = type { %"struct.std::__1::__compressed_pair_elem.397" }
%"struct.std::__1::__compressed_pair_elem.397" = type { %"class.v8::internal::GCIdleTimeHandler"* }
%"class.v8::internal::GCIdleTimeHandler" = type opaque
%"class.std::__1::unique_ptr.401" = type { %"class.std::__1::__compressed_pair.402" }
%"class.std::__1::__compressed_pair.402" = type { %"struct.std::__1::__compressed_pair_elem.403" }
%"struct.std::__1::__compressed_pair_elem.403" = type { %"class.v8::internal::MemoryMeasurement"* }
%"class.v8::internal::MemoryMeasurement" = type { %"class.std::__1::list", %"class.std::__1::list", %"class.std::__1::list", %"class.v8::internal::Isolate"*, i8, i8, i8, %"class.v8::base::RandomNumberGenerator" }
%"class.std::__1::list" = type { %"class.std::__1::__list_imp" }
%"class.std::__1::__list_imp" = type { %"struct.std::__1::__list_node_base", %"class.std::__1::__compressed_pair.404" }
%"struct.std::__1::__list_node_base" = type { %"struct.std::__1::__list_node_base"*, %"struct.std::__1::__list_node_base"* }
%"class.std::__1::__compressed_pair.404" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::unique_ptr.411" = type { %"class.std::__1::__compressed_pair.412" }
%"class.std::__1::__compressed_pair.412" = type { %"struct.std::__1::__compressed_pair_elem.413" }
%"struct.std::__1::__compressed_pair_elem.413" = type { %"class.v8::internal::MemoryReducer"* }
%"class.v8::internal::MemoryReducer" = type opaque
%"class.std::__1::unique_ptr.417" = type { %"class.std::__1::__compressed_pair.418" }
%"class.std::__1::__compressed_pair.418" = type { %"struct.std::__1::__compressed_pair_elem.419" }
%"struct.std::__1::__compressed_pair_elem.419" = type { %"class.v8::internal::ObjectStats"* }
%"class.v8::internal::ObjectStats" = type opaque
%"class.std::__1::unique_ptr.423" = type { %"class.std::__1::__compressed_pair.424" }
%"class.std::__1::__compressed_pair.424" = type { %"struct.std::__1::__compressed_pair_elem.425" }
%"struct.std::__1::__compressed_pair_elem.425" = type { %"class.v8::internal::ScavengeJob"* }
%"class.v8::internal::ScavengeJob" = type opaque
%"class.std::__1::unique_ptr.429" = type { %"class.std::__1::__compressed_pair.430" }
%"class.std::__1::__compressed_pair.430" = type { %"struct.std::__1::__compressed_pair_elem.431" }
%"struct.std::__1::__compressed_pair_elem.431" = type { %"class.v8::internal::AllocationObserver"* }
%"class.std::__1::unique_ptr.435" = type { %"class.std::__1::__compressed_pair.436" }
%"class.std::__1::__compressed_pair.436" = type { %"struct.std::__1::__compressed_pair_elem.437" }
%"struct.std::__1::__compressed_pair_elem.437" = type { %"class.v8::internal::LocalEmbedderHeapTracer"* }
%"class.v8::internal::LocalEmbedderHeapTracer" = type opaque
%"class.std::__1::unique_ptr.441" = type { %"class.std::__1::__compressed_pair.442" }
%"class.std::__1::__compressed_pair.442" = type { %"struct.std::__1::__compressed_pair_elem.443" }
%"struct.std::__1::__compressed_pair_elem.443" = type { %"class.v8::internal::MarkingBarrier"* }
%"class.v8::internal::MarkingBarrier" = type opaque
%"class.std::__1::shared_ptr.447" = type { %"class.v8::internal::CodeRange"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::CodeRange" = type { %"class.v8::internal::VirtualMemoryCage", %"struct.std::__1::atomic.465", %"class.v8::base::Mutex" }
%"class.v8::internal::VirtualMemoryCage" = type { i32 (...)**, i64, %"class.std::__1::unique_ptr.448", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.465" = type { %"struct.std::__1::__atomic_base.466" }
%"struct.std::__1::__atomic_base.466" = type { %"struct.std::__1::__cxx_atomic_impl.467" }
%"struct.std::__1::__cxx_atomic_impl.467" = type { %"struct.std::__1::__cxx_atomic_base_impl.468" }
%"struct.std::__1::__cxx_atomic_base_impl.468" = type { i8* }
%"class.v8::CppHeap" = type opaque
%"class.v8::EmbedderRootsHandler" = type { i32 (...)** }
%"class.v8::internal::StrongRootsEntry" = type { %"class.v8::internal::FullObjectSlot", %"class.v8::internal::FullObjectSlot", %"class.v8::internal::StrongRootsEntry"*, %"class.v8::internal::StrongRootsEntry"* }
%"class.v8::internal::FullObjectSlot" = type { %"class.v8::internal::SlotBase" }
%"class.v8::internal::SlotBase" = type { i64 }
%"class.std::__1::unordered_map.469" = type { %"class.std::__1::__hash_table.470" }
%"class.std::__1::__hash_table.470" = type <{ %"class.std::__1::unique_ptr.471", %"class.std::__1::__compressed_pair.481", %"class.std::__1::__compressed_pair.486", %"class.std::__1::__compressed_pair.489", [4 x i8] }>
%"class.std::__1::unique_ptr.471" = type { %"class.std::__1::__compressed_pair.472" }
%"class.std::__1::__compressed_pair.472" = type { %"struct.std::__1::__compressed_pair_elem.473", %"struct.std::__1::__compressed_pair_elem.475" }
%"struct.std::__1::__compressed_pair_elem.473" = type { %"struct.std::__1::__hash_node_base.474"** }
%"struct.std::__1::__hash_node_base.474" = type { %"struct.std::__1::__hash_node_base.474"* }
%"struct.std::__1::__compressed_pair_elem.475" = type { %"class.std::__1::__bucket_list_deallocator.476" }
%"class.std::__1::__bucket_list_deallocator.476" = type { %"class.std::__1::__compressed_pair.477" }
%"class.std::__1::__compressed_pair.477" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.481" = type { %"struct.std::__1::__compressed_pair_elem.482" }
%"struct.std::__1::__compressed_pair_elem.482" = type { %"struct.std::__1::__hash_node_base.474" }
%"class.std::__1::__compressed_pair.486" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.489" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.495" = type { %"class.std::__1::__compressed_pair.496" }
%"class.std::__1::__compressed_pair.496" = type { %"struct.std::__1::__compressed_pair_elem.497" }
%"struct.std::__1::__compressed_pair_elem.497" = type { %"class.v8::internal::GlobalHandleVector"* }
%"class.v8::internal::GlobalHandleVector" = type opaque
%"class.std::__1::unique_ptr.501" = type { %"class.std::__1::__compressed_pair.502" }
%"class.std::__1::__compressed_pair.502" = type { %"struct.std::__1::__compressed_pair_elem.503" }
%"struct.std::__1::__compressed_pair_elem.503" = type { %"class.v8::internal::GlobalSafepoint"* }
%"class.v8::internal::GlobalSafepoint" = type <{ %"class.v8::internal::GlobalSafepoint::Barrier", %"class.v8::internal::Heap"*, %"class.v8::base::Mutex", %"class.v8::internal::LocalHeap"*, i32, [4 x i8] }>
%"class.v8::internal::GlobalSafepoint::Barrier" = type { %"class.v8::base::Mutex", %"class.v8::base::ConditionVariable", %"class.v8::base::ConditionVariable", i8, i32 }
%"class.v8::internal::Heap::ExternalStringTable" = type { %"class.v8::internal::Heap"*, %"class.std::__1::vector.507", %"class.std::__1::vector.507" }
%"class.std::__1::unique_ptr.514" = type { %"class.std::__1::__compressed_pair.515" }
%"class.std::__1::__compressed_pair.515" = type { %"struct.std::__1::__compressed_pair_elem.516" }
%"struct.std::__1::__compressed_pair_elem.516" = type { %"class.v8::internal::CollectionBarrier"* }
%"class.v8::internal::CollectionBarrier" = type opaque
%"class.v8::internal::HeapObject" = type { %"class.v8::internal::Object" }
%"class.v8::base::SharedMutex" = type { %union.pthread_rwlock_t }
%union.pthread_rwlock_t = type { %struct.__pthread_rwlock_arch_t }
%struct.__pthread_rwlock_arch_t = type { i32, i32, i32, i32, i32, i32, i32, i32, i8, [7 x i8], i64, i32 }
%"class.std::__1::unordered_set.297" = type { %"class.std::__1::__hash_table.298" }
%"class.std::__1::__hash_table.298" = type <{ %"class.std::__1::unique_ptr.299", %"class.std::__1::__compressed_pair.309", %"class.std::__1::__compressed_pair.314", %"class.std::__1::__compressed_pair.318", [4 x i8] }>
%"class.std::__1::unique_ptr.299" = type { %"class.std::__1::__compressed_pair.300" }
%"class.std::__1::__compressed_pair.300" = type { %"struct.std::__1::__compressed_pair_elem.301", %"struct.std::__1::__compressed_pair_elem.303" }
%"struct.std::__1::__compressed_pair_elem.301" = type { %"struct.std::__1::__hash_node_base.302"** }
%"struct.std::__1::__hash_node_base.302" = type { %"struct.std::__1::__hash_node_base.302"* }
%"struct.std::__1::__compressed_pair_elem.303" = type { %"class.std::__1::__bucket_list_deallocator.304" }
%"class.std::__1::__bucket_list_deallocator.304" = type { %"class.std::__1::__compressed_pair.305" }
%"class.std::__1::__compressed_pair.305" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.309" = type { %"struct.std::__1::__compressed_pair_elem.310" }
%"struct.std::__1::__compressed_pair_elem.310" = type { %"struct.std::__1::__hash_node_base.302" }
%"class.std::__1::__compressed_pair.314" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.318" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.546" = type { %"class.std::__1::__hash_table.547" }
%"class.std::__1::__hash_table.547" = type <{ %"class.std::__1::unique_ptr.548", %"class.std::__1::__compressed_pair.558", %"class.std::__1::__compressed_pair.563", %"class.std::__1::__compressed_pair.566", [4 x i8] }>
%"class.std::__1::unique_ptr.548" = type { %"class.std::__1::__compressed_pair.549" }
%"class.std::__1::__compressed_pair.549" = type { %"struct.std::__1::__compressed_pair_elem.550", %"struct.std::__1::__compressed_pair_elem.552" }
%"struct.std::__1::__compressed_pair_elem.550" = type { %"struct.std::__1::__hash_node_base.551"** }
%"struct.std::__1::__hash_node_base.551" = type { %"struct.std::__1::__hash_node_base.551"* }
%"struct.std::__1::__compressed_pair_elem.552" = type { %"class.std::__1::__bucket_list_deallocator.553" }
%"class.std::__1::__bucket_list_deallocator.553" = type { %"class.std::__1::__compressed_pair.554" }
%"class.std::__1::__compressed_pair.554" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.558" = type { %"struct.std::__1::__compressed_pair_elem.559" }
%"struct.std::__1::__compressed_pair_elem.559" = type { %"struct.std::__1::__hash_node_base.551" }
%"class.std::__1::__compressed_pair.563" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.566" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.520" = type { %"class.std::__1::__hash_table.521" }
%"class.std::__1::__hash_table.521" = type <{ %"class.std::__1::unique_ptr.522", %"class.std::__1::__compressed_pair.532", %"class.std::__1::__compressed_pair.537", %"class.std::__1::__compressed_pair.540", [4 x i8] }>
%"class.std::__1::unique_ptr.522" = type { %"class.std::__1::__compressed_pair.523" }
%"class.std::__1::__compressed_pair.523" = type { %"struct.std::__1::__compressed_pair_elem.524", %"struct.std::__1::__compressed_pair_elem.526" }
%"struct.std::__1::__compressed_pair_elem.524" = type { %"struct.std::__1::__hash_node_base.525"** }
%"struct.std::__1::__hash_node_base.525" = type { %"struct.std::__1::__hash_node_base.525"* }
%"struct.std::__1::__compressed_pair_elem.526" = type { %"class.std::__1::__bucket_list_deallocator.527" }
%"class.std::__1::__bucket_list_deallocator.527" = type { %"class.std::__1::__compressed_pair.528" }
%"class.std::__1::__compressed_pair.528" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.532" = type { %"struct.std::__1::__compressed_pair_elem.533" }
%"struct.std::__1::__compressed_pair_elem.533" = type { %"struct.std::__1::__hash_node_base.525" }
%"class.std::__1::__compressed_pair.537" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.540" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.570" = type { %"class.std::__1::__hash_table.571" }
%"class.std::__1::__hash_table.571" = type <{ %"class.std::__1::unique_ptr.572", %"class.std::__1::__compressed_pair.582", %"class.std::__1::__compressed_pair.587", %"class.std::__1::__compressed_pair.592", [4 x i8] }>
%"class.std::__1::unique_ptr.572" = type { %"class.std::__1::__compressed_pair.573" }
%"class.std::__1::__compressed_pair.573" = type { %"struct.std::__1::__compressed_pair_elem.574", %"struct.std::__1::__compressed_pair_elem.576" }
%"struct.std::__1::__compressed_pair_elem.574" = type { %"struct.std::__1::__hash_node_base.575"** }
%"struct.std::__1::__hash_node_base.575" = type { %"struct.std::__1::__hash_node_base.575"* }
%"struct.std::__1::__compressed_pair_elem.576" = type { %"class.std::__1::__bucket_list_deallocator.577" }
%"class.std::__1::__bucket_list_deallocator.577" = type { %"class.std::__1::__compressed_pair.578" }
%"class.std::__1::__compressed_pair.578" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.582" = type { %"struct.std::__1::__compressed_pair_elem.583" }
%"struct.std::__1::__compressed_pair_elem.583" = type { %"struct.std::__1::__hash_node_base.575" }
%"class.std::__1::__compressed_pair.587" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.592" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::vector.598" = type { %"class.std::__1::__vector_base.599" }
%"class.std::__1::__vector_base.599" = type { %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.std::__1::__compressed_pair.600" }
%"class.std::__1::__compressed_pair.600" = type { %"struct.std::__1::__compressed_pair_elem.601" }
%"struct.std::__1::__compressed_pair_elem.601" = type { %"class.v8::internal::HeapObjectAllocationTracker"** }
%"class.std::__1::unique_ptr.605" = type { %"class.std::__1::__compressed_pair.606" }
%"class.std::__1::__compressed_pair.606" = type { %"struct.std::__1::__compressed_pair_elem.607" }
%"struct.std::__1::__compressed_pair_elem.607" = type { %"class.v8::internal::third_party_heap::Heap"* }
%"class.v8::internal::third_party_heap::Heap" = type { i8 }
%"class.v8::internal::AllocationCounter" = type <{ %"class.std::__1::vector.29", %"class.std::__1::vector.29", %"class.std::__1::unordered_set", i8, [7 x i8], i64, i64, i8, [7 x i8] }>
%"class.std::__1::vector.29" = type { %"class.std::__1::__vector_base.30" }
%"class.std::__1::__vector_base.30" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"class.std::__1::__compressed_pair.31" }
%"struct.v8::internal::AllocationCounter::AllocationObserverCounter" = type { %"class.v8::internal::AllocationObserver"*, i64, i64 }
%"class.std::__1::__compressed_pair.31" = type { %"struct.std::__1::__compressed_pair_elem.32" }
%"struct.std::__1::__compressed_pair_elem.32" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.36" }
%"class.std::__1::__hash_table.36" = type <{ %"class.std::__1::unique_ptr.37", %"class.std::__1::__compressed_pair.47", %"class.std::__1::__compressed_pair.52", %"class.std::__1::__compressed_pair.54", [4 x i8] }>
%"class.std::__1::unique_ptr.37" = type { %"class.std::__1::__compressed_pair.38" }
%"class.std::__1::__compressed_pair.38" = type { %"struct.std::__1::__compressed_pair_elem.39", %"struct.std::__1::__compressed_pair_elem.41" }
%"struct.std::__1::__compressed_pair_elem.39" = type { %"struct.std::__1::__hash_node_base.40"** }
%"struct.std::__1::__hash_node_base.40" = type { %"struct.std::__1::__hash_node_base.40"* }
%"struct.std::__1::__compressed_pair_elem.41" = type { %"class.std::__1::__bucket_list_deallocator.42" }
%"class.std::__1::__bucket_list_deallocator.42" = type { %"class.std::__1::__compressed_pair.43" }
%"class.std::__1::__compressed_pair.43" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.47" = type { %"struct.std::__1::__compressed_pair_elem.48" }
%"struct.std::__1::__compressed_pair_elem.48" = type { %"struct.std::__1::__hash_node_base.40" }
%"class.std::__1::__compressed_pair.52" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.54" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::heap::List" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.std::__1::unique_ptr.59" = type { %"class.std::__1::__compressed_pair.60" }
%"class.std::__1::__compressed_pair.60" = type { %"struct.std::__1::__compressed_pair_elem.61" }
%"struct.std::__1::__compressed_pair_elem.61" = type { %"class.v8::internal::FreeList"* }
%"class.v8::internal::FreeList" = type { i32 (...)**, i32, i32, i64, %"struct.std::__1::atomic", %"class.v8::internal::FreeListCategory"**, i64 }
%"class.v8::internal::LinearAllocationArea" = type { i64, i64, i64 }
%"class.v8::base::Mutex" = type { %union.pthread_mutex_t }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.14" }
%"struct.std::__1::__atomic_base.14" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i64 }
%"class.v8::internal::SemiSpace" = type { %"class.v8::internal::Space", i64, i64, i64, i64, i64, i32, %"class.v8::internal::Page"* }
%"class.v8::internal::VirtualMemory" = type { %"class.v8::PageAllocator"*, %"class.v8::base::AddressRegion" }
%"class.std::__1::vector.63" = type { %"class.std::__1::__vector_base.64" }
%"class.std::__1::__vector_base.64" = type { %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"*, %"class.std::__1::__compressed_pair.66" }
%"struct.std::__1::pair.65" = type { i32, i64 }
%"class.std::__1::__compressed_pair.66" = type { %"struct.std::__1::__compressed_pair_elem.67" }
%"struct.std::__1::__compressed_pair_elem.67" = type { %"struct.std::__1::pair.65"* }
%"class.v8::internal::ConcurrentBitmap" = type { i8 }
%"class.std::__1::__vector_base_common" = type { i8 }
%"class.v8::internal::NoFreeList" = type { %"class.v8::internal::FreeList" }

$_ZN2v88internal8NewSpace15CommittedMemoryEv = comdat any

$_ZN2v88internal8NewSpace4SizeEv = comdat any

$_ZN2v88internal9BaseSpace15CommittedMemoryEv = comdat any

$_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv = comdat any

$_ZN2v88internal9SemiSpace4SizeEv = comdat any

$_ZN2v88internal5SpaceD2Ev = comdat any

$_ZN2v88internal9SemiSpaceD0Ev = comdat any

$_ZN2v88internal5Space29StartNextInlineAllocationStepEv = comdat any

$_ZN2v88internal9SemiSpace13SizeOfObjectsEv = comdat any

$_ZN2v88internal9SemiSpace9AvailableEv = comdat any

$_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi = comdat any

$_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE = comdat any

$_ZN2v88internal8NewSpace22MaximumCommittedMemoryEv = comdat any

$_ZN2v88internal8NewSpaceD2Ev = comdat any

$_ZN2v88internal8NewSpaceD0Ev = comdat any

$_ZN2v88internal8NewSpace13SizeOfObjectsEv = comdat any

$_ZN2v88internal8NewSpace9AvailableEv = comdat any

$_ZNK2v88internal8NewSpace25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE = comdat any

$_ZN2v88internal8NewSpace26SupportsAllocationObserverEv = comdat any

$_ZN2v88internal23SemiSpaceObjectIteratorD0Ev = comdat any

$_ZN2v88internal23SemiSpaceObjectIterator4NextEv = comdat any

$_ZN2v88internal14ObjectIteratorD2Ev = comdat any

$_ZN2v88internal8FreeListD2Ev = comdat any

$_ZN2v88internal10NoFreeListD0Ev = comdat any

$_ZN2v88internal10NoFreeList21GuaranteedAllocatableEm = comdat any

$_ZN2v88internal10NoFreeList4FreeEmmNS0_8FreeModeE = comdat any

$_ZN2v88internal10NoFreeList8AllocateEmPmNS0_16AllocationOriginE = comdat any

$_ZN2v88internal10NoFreeList14GetPageForSizeEm = comdat any

$_ZN2v88internal10NoFreeList26SelectFreeListCategoryTypeEm = comdat any

$_ZTVN2v88internal23SemiSpaceObjectIteratorE = comdat any

$_ZTVN2v88internal10NoFreeListE = comdat any

@_ZN2v88internal13FLAG_minor_mcE = external local_unnamed_addr global i8, align 1
@.str = private unnamed_addr constant [17 x i8] c"unreachable code\00", align 1
@_ZTVN2v88internal23SemiSpaceObjectIteratorE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::internal::ObjectIterator"*)* @_ZN2v88internal14ObjectIteratorD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::SemiSpaceObjectIterator"*)* @_ZN2v88internal23SemiSpaceObjectIteratorD0Ev to i8*), i8* bitcast (i64 (%"class.v8::internal::SemiSpaceObjectIterator"*)* @_ZN2v88internal23SemiSpaceObjectIterator4NextEv to i8*)] }, comdat, align 8
@_ZTVN2v88internal8NewSpaceE = hidden unnamed_addr constant { [20 x i8*] } { [20 x i8*] [i8* null, i8* null, i8* bitcast (i64 (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpace15CommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpace22MaximumCommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpace23CommittedPhysicalMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpace4SizeEv to i8*), i8* bitcast (void (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpaceD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpaceD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::SpaceWithLinearArea"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal19SpaceWithLinearArea21AddAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::SpaceWithLinearArea"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal19SpaceWithLinearArea24RemoveAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::SpaceWithLinearArea"*)* @_ZN2v88internal19SpaceWithLinearArea24PauseAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::SpaceWithLinearArea"*)* @_ZN2v88internal19SpaceWithLinearArea25ResumeAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space29StartNextInlineAllocationStepEv to i8*), i8* bitcast (i64 (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpace13SizeOfObjectsEv to i8*), i8* bitcast (i64 (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpace9AvailableEv to i8*), i8* bitcast (i32 (%"class.v8::internal::Space"*, i32)* @_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi to i8*), i8* bitcast (%"class.v8::internal::ObjectIterator"* (%"class.v8::internal::NewSpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal8NewSpace17GetObjectIteratorEPNS0_4HeapE to i8*), i8* bitcast (i64 (%"class.v8::internal::NewSpace"*, i32)* @_ZNK2v88internal8NewSpace25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE to i8*), i8* bitcast (i1 (%"class.v8::internal::NewSpace"*)* @_ZN2v88internal8NewSpace26SupportsAllocationObserverEv to i8*), i8* bitcast (void (%"class.v8::internal::NewSpace"*, i64)* @_ZN2v88internal8NewSpace27UpdateInlineAllocationLimitEm to i8*)] }, align 8
@.str.1 = private unnamed_addr constant [16 x i8] c"New space setup\00", align 1
@_ZN2v88internal29FLAG_semi_space_growth_factorE = external local_unnamed_addr global i32, align 4
@_ZN2v88internal30FLAG_allocation_buffer_parkingE = external local_unnamed_addr global i8, align 1
@_ZTVN2v88internal9SemiSpaceE = hidden unnamed_addr constant { [18 x i8*] } { [18 x i8*] [i8* null, i8* null, i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace15CommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::SemiSpace"*)* @_ZN2v88internal9SemiSpace23CommittedPhysicalMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::SemiSpace"*)* @_ZN2v88internal9SemiSpace4SizeEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5SpaceD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::SemiSpace"*)* @_ZN2v88internal9SemiSpaceD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space21AddAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space24RemoveAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space24PauseAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space25ResumeAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space29StartNextInlineAllocationStepEv to i8*), i8* bitcast (i64 (%"class.v8::internal::SemiSpace"*)* @_ZN2v88internal9SemiSpace13SizeOfObjectsEv to i8*), i8* bitcast (i64 (%"class.v8::internal::SemiSpace"*)* @_ZN2v88internal9SemiSpace9AvailableEv to i8*), i8* bitcast (i32 (%"class.v8::internal::Space"*, i32)* @_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi to i8*), i8* bitcast (%"class.v8::internal::ObjectIterator"* (%"class.v8::internal::SemiSpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal9SemiSpace17GetObjectIteratorEPNS0_4HeapE to i8*), i8* bitcast (i64 (%"class.v8::internal::Space"*, i32)* @_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE to i8*)] }, align 8
@_ZTVN2v88internal10NoFreeListE = linkonce_odr hidden unnamed_addr constant { [12 x i8*] } { [12 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::internal::FreeList"*)* @_ZN2v88internal8FreeListD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::NoFreeList"*)* @_ZN2v88internal10NoFreeListD0Ev to i8*), i8* bitcast (i64 (%"class.v8::internal::NoFreeList"*, i64)* @_ZN2v88internal10NoFreeList21GuaranteedAllocatableEm to i8*), i8* bitcast (i64 (%"class.v8::internal::NoFreeList"*, i64, i64, i32)* @_ZN2v88internal10NoFreeList4FreeEmmNS0_8FreeModeE to i8*), i8* bitcast (i64 (%"class.v8::internal::NoFreeList"*, i64, i64*, i32)* @_ZN2v88internal10NoFreeList8AllocateEmPmNS0_16AllocationOriginE to i8*), i8* bitcast (%"class.v8::internal::Page"* (%"class.v8::internal::NoFreeList"*, i64)* @_ZN2v88internal10NoFreeList14GetPageForSizeEm to i8*), i8* bitcast (void (%"class.v8::internal::FreeList"*)* @_ZN2v88internal8FreeList5ResetEv to i8*), i8* bitcast (i1 (%"class.v8::internal::FreeList"*, %"class.v8::internal::FreeListCategory"*)* @_ZN2v88internal8FreeList11AddCategoryEPNS0_16FreeListCategoryE to i8*), i8* bitcast (void (%"class.v8::internal::FreeList"*, %"class.v8::internal::FreeListCategory"*)* @_ZN2v88internal8FreeList14RemoveCategoryEPNS0_16FreeListCategoryE to i8*), i8* bitcast (i32 (%"class.v8::internal::NoFreeList"*, i64)* @_ZN2v88internal10NoFreeList26SelectFreeListCategoryTypeEm to i8*)] }, comdat, align 8
@.str.2 = private unnamed_addr constant [50 x i8] c"NoFreeList can't be used as a standard FreeList. \00", align 1
@.str.3 = private unnamed_addr constant [49 x i8] c"NoFreeList can't be used as a standard FreeList.\00", align 1
@_ZTVN2v88internal5SpaceE = external unnamed_addr constant { [18 x i8*] }, align 8
@_ZN2v88internal30FLAG_trace_allocations_originsE = external local_unnamed_addr global i8, align 1
@.str.4 = private unnamed_addr constant [18 x i8] c"Check failed: %s.\00", align 1
@.str.5 = private unnamed_addr constant [16 x i8] c"!object.IsSmi()\00", align 1

@_ZN2v88internal23SemiSpaceObjectIteratorC1EPNS0_8NewSpaceE = hidden unnamed_addr alias void (%"class.v8::internal::SemiSpaceObjectIterator"*, %"class.v8::internal::NewSpace"*), void (%"class.v8::internal::SemiSpaceObjectIterator"*, %"class.v8::internal::NewSpace"*)* @_ZN2v88internal23SemiSpaceObjectIteratorC2EPNS0_8NewSpaceE
@_ZN2v88internal8NewSpaceC1EPNS0_4HeapEPNS_13PageAllocatorEmm = hidden unnamed_addr alias void (%"class.v8::internal::NewSpace"*, %"class.v8::internal::Heap"*, %"class.v8::PageAllocator"*, i64, i64), void (%"class.v8::internal::NewSpace"*, %"class.v8::internal::Heap"*, %"class.v8::PageAllocator"*, i64, i64)* @_ZN2v88internal8NewSpaceC2EPNS0_4HeapEPNS_13PageAllocatorEmm

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::Page"* @_ZN2v88internal9SemiSpace14InitializePageEPNS0_11MemoryChunkE(%"class.v8::internal::SemiSpace"* nocapture readonly, %"class.v8::internal::MemoryChunk"*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 6
  %4 = load i32, i32* %3, align 8
  %5 = icmp eq i32 %4, 0
  %6 = select i1 %5, i64 8, i64 16
  %7 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %1, i64 0, i32 0, i32 1
  %8 = load i64, i64* %7, align 8
  %9 = or i64 %6, %8
  store i64 %9, i64* %7, align 8
  %10 = bitcast %"class.v8::internal::MemoryChunk"* %1 to %"class.v8::internal::Page"*
  %11 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %12 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %11, align 8
  %13 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %12, i64 0, i32 86, i32 0, i32 0, i32 0
  %14 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %13, align 8
  %15 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %14, i64 0, i32 11, i32 0, i32 0, i32 0, i32 0
  %16 = load atomic i8, i8* %15 seq_cst, align 1
  %17 = icmp ne i8 %16, 0
  tail call void @_ZN2v88internal11MemoryChunk27SetYoungGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"* %1, i1 zeroext %17) #13
  %18 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %1, i64 0, i32 12
  %19 = bitcast %"class.v8::internal::heap::ListNode"* %18 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %19, i8 0, i64 16, i1 false) #13
  %20 = load i8, i8* @_ZN2v88internal13FLAG_minor_mcE, align 1, !range !2
  %21 = icmp eq i8 %20, 0
  br i1 %21, label %29, label %22

22:                                               ; preds = %2
  %23 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %1, i64 0, i32 0
  tail call void @_ZN2v88internal11MemoryChunk29AllocateYoungGenerationBitmapEv(%"class.v8::internal::MemoryChunk"* %1) #13
  %24 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %23, i64 2, i32 7
  %25 = bitcast %"struct.std::__1::atomic.15"* %24 to %"class.v8::internal::ConcurrentBitmap"**
  %26 = load %"class.v8::internal::ConcurrentBitmap"*, %"class.v8::internal::ConcurrentBitmap"** %25, align 8
  %27 = getelementptr inbounds %"class.v8::internal::ConcurrentBitmap", %"class.v8::internal::ConcurrentBitmap"* %26, i64 0, i32 0
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %27, i8 0, i64 8196, i1 false) #13
  %28 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %1, i64 0, i32 14, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %28 monotonic, align 8
  br label %29

29:                                               ; preds = %2, %22
  tail call void @_ZN2v88internal11MemoryChunk25InitializationMemoryFenceEv(%"class.v8::internal::MemoryChunk"* %1) #13
  ret %"class.v8::internal::Page"* %10
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

declare void @_ZN2v88internal11MemoryChunk27SetYoungGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"*, i1 zeroext) local_unnamed_addr #2

declare void @_ZN2v88internal11MemoryChunk29AllocateYoungGenerationBitmapEv(%"class.v8::internal::MemoryChunk"*) local_unnamed_addr #2

declare void @_ZN2v88internal11MemoryChunk25InitializationMemoryFenceEv(%"class.v8::internal::MemoryChunk"*) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal9SemiSpace21EnsureCurrentCapacityEv(%"class.v8::internal::SemiSpace"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %3 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %2, align 8
  %4 = icmp eq %"class.v8::internal::MemoryChunk"* %3, null
  br i1 %4, label %5, label %9

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %7 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %6, align 8
  %8 = icmp eq %"class.v8::internal::MemoryChunk"* %7, null
  br i1 %8, label %123, label %9

9:                                                ; preds = %5, %1
  %10 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  %11 = load i64, i64* %10, align 8
  %12 = lshr i64 %11, 18
  %13 = trunc i64 %12 to i32
  %14 = bitcast %"class.v8::internal::MemoryChunk"** %2 to %"class.v8::internal::Page"**
  %15 = icmp ne %"class.v8::internal::MemoryChunk"* %3, null
  %16 = icmp sgt i32 %13, 0
  %17 = and i1 %16, %15
  br i1 %17, label %29, label %18

18:                                               ; preds = %29, %9
  %19 = phi i32 [ 0, %9 ], [ %32, %29 ]
  %20 = phi %"class.v8::internal::MemoryChunk"* [ %3, %9 ], [ %34, %29 ]
  %21 = icmp eq %"class.v8::internal::MemoryChunk"* %20, null
  br i1 %21, label %74, label %22

22:                                               ; preds = %18
  %23 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %24 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %25 = bitcast %"class.v8::internal::MemoryChunk"** %24 to i64*
  %26 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %23, i64 0, i32 0
  %27 = bitcast %"class.v8::internal::heap::List"* %23 to i64*
  %28 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  br label %38

29:                                               ; preds = %9, %29
  %30 = phi %"class.v8::internal::MemoryChunk"* [ %34, %29 ], [ %3, %9 ]
  %31 = phi i32 [ %32, %29 ], [ 0, %9 ]
  %32 = add nuw nsw i32 %31, 1
  %33 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %30, i64 0, i32 12, i32 0
  %34 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %33, align 8
  %35 = icmp ne %"class.v8::internal::MemoryChunk"* %34, null
  %36 = icmp slt i32 %32, %13
  %37 = and i1 %36, %35
  br i1 %37, label %29, label %18

38:                                               ; preds = %22, %65
  %39 = phi %"class.v8::internal::MemoryChunk"* [ %20, %22 ], [ %41, %65 ]
  %40 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %39, i64 0, i32 12, i32 0
  %41 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %40, align 8
  %42 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %24, align 8
  %43 = icmp eq %"class.v8::internal::MemoryChunk"* %42, %39
  br i1 %43, label %44, label %48

44:                                               ; preds = %38
  %45 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %39, i64 0, i32 12, i32 1
  %46 = bitcast %"class.v8::internal::MemoryChunk"** %45 to i64*
  %47 = load i64, i64* %46, align 8
  store i64 %47, i64* %25, align 8
  br label %48

48:                                               ; preds = %44, %38
  %49 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %26, align 8
  %50 = icmp eq %"class.v8::internal::MemoryChunk"* %49, %39
  br i1 %50, label %51, label %54

51:                                               ; preds = %48
  %52 = bitcast %"class.v8::internal::MemoryChunk"** %40 to i64*
  %53 = load i64, i64* %52, align 8
  store i64 %53, i64* %27, align 8
  br label %54

54:                                               ; preds = %51, %48
  %55 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %40, align 8
  %56 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %39, i64 0, i32 12, i32 1
  %57 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %56, align 8
  %58 = icmp eq %"class.v8::internal::MemoryChunk"* %55, null
  br i1 %58, label %61, label %59

59:                                               ; preds = %54
  %60 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %55, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %57, %"class.v8::internal::MemoryChunk"** %60, align 8
  br label %61

61:                                               ; preds = %59, %54
  %62 = icmp eq %"class.v8::internal::MemoryChunk"* %57, null
  br i1 %62, label %65, label %63

63:                                               ; preds = %61
  %64 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %57, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %55, %"class.v8::internal::MemoryChunk"** %64, align 8
  br label %65

65:                                               ; preds = %61, %63
  %66 = bitcast %"class.v8::internal::MemoryChunk"** %40 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %66, i8 0, i64 16, i1 false) #13
  %67 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %39, i64 0, i32 0, i32 1
  %68 = load i64, i64* %67, align 8
  %69 = and i64 %68, -25
  store i64 %69, i64* %67, align 8
  %70 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %28, align 8
  %71 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %70, i64 0, i32 85, i32 0, i32 0, i32 0
  %72 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %71, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %72, %"class.v8::internal::MemoryChunk"* nonnull %39) #13
  %73 = icmp eq %"class.v8::internal::MemoryChunk"* %41, null
  br i1 %73, label %74, label %38

74:                                               ; preds = %65, %18
  %75 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %76 = icmp slt i32 %19, %13
  br i1 %76, label %77, label %123

77:                                               ; preds = %74
  %78 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  br label %79

79:                                               ; preds = %103, %77
  %80 = phi i32 [ %19, %77 ], [ %89, %103 ]
  %81 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %75, align 8
  %82 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %81, i64 0, i32 85, i32 0, i32 0, i32 0
  %83 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %82, align 8
  %84 = tail call i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() #13
  %85 = tail call %"class.v8::internal::Page"* @_ZN2v88internal15MemoryAllocator12AllocatePageILNS1_14AllocationModeE1ENS0_9SemiSpaceEEEPNS0_4PageEmPT0_NS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"* %83, i64 %84, %"class.v8::internal::SemiSpace"* %0, i32 0) #13
  %86 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %85, i64 0, i32 0
  %87 = icmp eq %"class.v8::internal::Page"* %85, null
  br i1 %87, label %123, label %88

88:                                               ; preds = %79
  %89 = add nuw i32 %80, 1
  %90 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %78, align 8
  %91 = icmp eq %"class.v8::internal::MemoryChunk"* %90, null
  br i1 %91, label %100, label %92

92:                                               ; preds = %88
  %93 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %90, i64 0, i32 12, i32 0
  %94 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %93, align 8
  %95 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %85, i64 0, i32 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %94, %"class.v8::internal::MemoryChunk"** %95, align 8
  %96 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %85, i64 0, i32 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %90, %"class.v8::internal::MemoryChunk"** %96, align 8
  store %"class.v8::internal::MemoryChunk"* %86, %"class.v8::internal::MemoryChunk"** %93, align 8
  %97 = icmp eq %"class.v8::internal::MemoryChunk"* %94, null
  %98 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %94, i64 0, i32 12, i32 1
  %99 = select i1 %97, %"class.v8::internal::MemoryChunk"** %78, %"class.v8::internal::MemoryChunk"** %98
  br label %103

100:                                              ; preds = %88
  %101 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %85, i64 0, i32 0, i32 12, i32 0
  %102 = bitcast %"class.v8::internal::MemoryChunk"** %101 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %102, i8 0, i64 16, i1 false) #13
  store %"class.v8::internal::MemoryChunk"* %86, %"class.v8::internal::MemoryChunk"** %2, align 8
  br label %103

103:                                              ; preds = %92, %100
  %104 = phi %"class.v8::internal::MemoryChunk"** [ %78, %100 ], [ %99, %92 ]
  store %"class.v8::internal::MemoryChunk"* %86, %"class.v8::internal::MemoryChunk"** %104, align 8
  %105 = ptrtoint %"class.v8::internal::Page"* %85 to i64
  %106 = add i64 %105, 272
  %107 = inttoptr i64 %106 to %"class.v8::internal::ConcurrentBitmap"*
  %108 = getelementptr inbounds %"class.v8::internal::ConcurrentBitmap", %"class.v8::internal::ConcurrentBitmap"* %107, i64 0, i32 0
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %108, i8 0, i64 8196, i1 false) #13
  %109 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %85, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %109 monotonic, align 8
  %110 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %14, align 8
  %111 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %110, i64 0, i32 0, i32 0, i32 1
  %112 = load i64, i64* %111, align 8
  %113 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %85, i64 0, i32 0, i32 0, i32 1
  store i64 %112, i64* %113, align 8
  %114 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %75, align 8
  %115 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %85, i64 0, i32 0, i32 0, i32 3
  %116 = load i64, i64* %115, align 8
  %117 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %85, i64 0, i32 0, i32 0, i32 4
  %118 = load i64, i64* %117, align 8
  %119 = sub i64 %118, %116
  %120 = trunc i64 %119 to i32
  %121 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %114, i64 %116, i32 %120, i32 1) #13
  %122 = icmp eq i32 %89, %13
  br i1 %122, label %123, label %79

123:                                              ; preds = %79, %103, %74, %5
  %124 = phi i1 [ true, %5 ], [ true, %74 ], [ true, %103 ], [ false, %79 ]
  ret i1 %124
}

declare void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryChunk"*) local_unnamed_addr #2

declare %"class.v8::internal::Page"* @_ZN2v88internal15MemoryAllocator12AllocatePageILNS1_14AllocationModeE1ENS0_9SemiSpaceEEEPNS0_4PageEmPT0_NS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"*, i64, %"class.v8::internal::SemiSpace"*, i32) local_unnamed_addr #2

declare i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() local_unnamed_addr #2

declare i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"*, i64, i32, i32) local_unnamed_addr #2

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @_ZN2v88internal9SemiSpace5SetUpEmm(%"class.v8::internal::SemiSpace"* nocapture, i64, i64) local_unnamed_addr #3 align 2 {
  %4 = and i64 %1, -262144
  %5 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 4
  store i64 %4, i64* %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  store i64 %4, i64* %6, align 8
  %7 = and i64 %2, -262144
  %8 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 3
  store i64 %7, i64* %8, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace8TearDownEv(%"class.v8::internal::SemiSpace"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %3 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %2, align 8
  %4 = icmp eq %"class.v8::internal::MemoryChunk"* %3, null
  %5 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %6 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %5, align 8
  %7 = icmp eq %"class.v8::internal::MemoryChunk"* %6, null
  %8 = and i1 %4, %7
  br i1 %8, label %59, label %9

9:                                                ; preds = %1
  %10 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %11 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %12 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %11, i64 0, i32 0
  %13 = bitcast %"class.v8::internal::MemoryChunk"** %10 to i64*
  %14 = bitcast %"class.v8::internal::heap::List"* %11 to i64*
  %15 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  br label %16

16:                                               ; preds = %9, %38
  %17 = phi %"class.v8::internal::MemoryChunk"* [ %45, %38 ], [ %6, %9 ]
  %18 = phi %"class.v8::internal::MemoryChunk"* [ %43, %38 ], [ %3, %9 ]
  %19 = icmp eq %"class.v8::internal::MemoryChunk"* %17, %18
  br i1 %19, label %20, label %24

20:                                               ; preds = %16
  %21 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %17, i64 0, i32 12, i32 1
  %22 = bitcast %"class.v8::internal::MemoryChunk"** %21 to i64*
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %13, align 8
  br label %24

24:                                               ; preds = %20, %16
  %25 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %18, i64 0, i32 12, i32 0
  %26 = bitcast %"class.v8::internal::MemoryChunk"** %25 to i64*
  %27 = load i64, i64* %26, align 8
  store i64 %27, i64* %14, align 8
  %28 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %25, align 8
  %29 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %18, i64 0, i32 12, i32 1
  %30 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %29, align 8
  %31 = icmp eq %"class.v8::internal::MemoryChunk"* %28, null
  br i1 %31, label %34, label %32

32:                                               ; preds = %24
  %33 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %28, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %30, %"class.v8::internal::MemoryChunk"** %33, align 8
  br label %34

34:                                               ; preds = %32, %24
  %35 = icmp eq %"class.v8::internal::MemoryChunk"* %30, null
  br i1 %35, label %38, label %36

36:                                               ; preds = %34
  %37 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %30, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %28, %"class.v8::internal::MemoryChunk"** %37, align 8
  br label %38

38:                                               ; preds = %36, %34
  %39 = bitcast %"class.v8::internal::MemoryChunk"** %25 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %39, i8 0, i64 16, i1 false) #13
  %40 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %15, align 8
  %41 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %40, i64 0, i32 85, i32 0, i32 0, i32 0
  %42 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %41, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %42, %"class.v8::internal::MemoryChunk"* %18) #13
  %43 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %12, align 8
  %44 = icmp eq %"class.v8::internal::MemoryChunk"* %43, null
  %45 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %10, align 8
  %46 = icmp eq %"class.v8::internal::MemoryChunk"* %45, null
  %47 = and i1 %44, %46
  br i1 %47, label %48, label %16

48:                                               ; preds = %38
  %49 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 7
  store %"class.v8::internal::Page"* null, %"class.v8::internal::Page"** %49, align 8
  %50 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 1
  store i64 0, i64* %50, align 8
  %51 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  %52 = load i64, i64* %51, align 8
  %53 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %54 = atomicrmw sub i64* %53, i64 %52 seq_cst
  %55 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %15, align 8
  %56 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %55, i64 0, i32 85, i32 0, i32 0, i32 0
  %57 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %56, align 8
  %58 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %57, i64 0, i32 9
  tail call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %58) #13
  br label %59

59:                                               ; preds = %1, %48
  %60 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  %61 = bitcast i64* %60 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %61, i8 0, i64 16, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal9SemiSpace8UncommitEv(%"class.v8::internal::SemiSpace"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %4 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %3, i64 0, i32 0
  %5 = bitcast %"class.v8::internal::MemoryChunk"** %2 to i64*
  %6 = bitcast %"class.v8::internal::heap::List"* %3 to i64*
  %7 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %8 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %4, align 8
  %9 = icmp eq %"class.v8::internal::MemoryChunk"* %8, null
  %10 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %2, align 8
  %11 = icmp eq %"class.v8::internal::MemoryChunk"* %10, null
  %12 = and i1 %9, %11
  br i1 %12, label %45, label %13

13:                                               ; preds = %1, %35
  %14 = phi %"class.v8::internal::MemoryChunk"* [ %42, %35 ], [ %10, %1 ]
  %15 = phi %"class.v8::internal::MemoryChunk"* [ %40, %35 ], [ %8, %1 ]
  %16 = icmp eq %"class.v8::internal::MemoryChunk"* %14, %15
  br i1 %16, label %17, label %21

17:                                               ; preds = %13
  %18 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %15, i64 0, i32 12, i32 1
  %19 = bitcast %"class.v8::internal::MemoryChunk"** %18 to i64*
  %20 = load i64, i64* %19, align 8
  store i64 %20, i64* %5, align 8
  br label %21

21:                                               ; preds = %17, %13
  %22 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %15, i64 0, i32 12, i32 0
  %23 = bitcast %"class.v8::internal::MemoryChunk"** %22 to i64*
  %24 = load i64, i64* %23, align 8
  store i64 %24, i64* %6, align 8
  %25 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %22, align 8
  %26 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %15, i64 0, i32 12, i32 1
  %27 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %26, align 8
  %28 = icmp eq %"class.v8::internal::MemoryChunk"* %25, null
  br i1 %28, label %31, label %29

29:                                               ; preds = %21
  %30 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %25, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %27, %"class.v8::internal::MemoryChunk"** %30, align 8
  br label %31

31:                                               ; preds = %29, %21
  %32 = icmp eq %"class.v8::internal::MemoryChunk"* %27, null
  br i1 %32, label %35, label %33

33:                                               ; preds = %31
  %34 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %27, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %25, %"class.v8::internal::MemoryChunk"** %34, align 8
  br label %35

35:                                               ; preds = %31, %33
  %36 = bitcast %"class.v8::internal::MemoryChunk"** %22 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %36, i8 0, i64 16, i1 false) #13
  %37 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %7, align 8
  %38 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %37, i64 0, i32 85, i32 0, i32 0, i32 0
  %39 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %38, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %39, %"class.v8::internal::MemoryChunk"* %15) #13
  %40 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %4, align 8
  %41 = icmp eq %"class.v8::internal::MemoryChunk"* %40, null
  %42 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %2, align 8
  %43 = icmp eq %"class.v8::internal::MemoryChunk"* %42, null
  %44 = and i1 %41, %43
  br i1 %44, label %45, label %13

45:                                               ; preds = %35, %1
  %46 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 7
  store %"class.v8::internal::Page"* null, %"class.v8::internal::Page"** %46, align 8
  %47 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 1
  store i64 0, i64* %47, align 8
  %48 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  %49 = load i64, i64* %48, align 8
  %50 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %51 = atomicrmw sub i64* %50, i64 %49 seq_cst
  %52 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %7, align 8
  %53 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %52, i64 0, i32 85, i32 0, i32 0, i32 0
  %54 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %53, align 8
  %55 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %54, i64 0, i32 9
  tail call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %55) #13
  ret i1 true
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal9SemiSpace6CommitEv(%"class.v8::internal::SemiSpace"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  %3 = load i64, i64* %2, align 8
  %4 = lshr i64 %3, 18
  %5 = trunc i64 %4 to i32
  %6 = icmp sgt i32 %5, 0
  br i1 %6, label %7, label %79

7:                                                ; preds = %1
  %8 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %9 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %10 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  br label %11

11:                                               ; preds = %73, %7
  %12 = phi i32 [ 0, %7 ], [ %75, %73 ]
  %13 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %8, align 8
  %14 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %13, i64 0, i32 85, i32 0, i32 0, i32 0
  %15 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %14, align 8
  %16 = tail call i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() #13
  %17 = tail call %"class.v8::internal::Page"* @_ZN2v88internal15MemoryAllocator12AllocatePageILNS1_14AllocationModeE1ENS0_9SemiSpaceEEEPNS0_4PageEmPT0_NS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"* %15, i64 %16, %"class.v8::internal::SemiSpace"* %0, i32 0) #13
  %18 = icmp eq %"class.v8::internal::Page"* %17, null
  br i1 %18, label %19, label %58

19:                                               ; preds = %11
  %20 = icmp eq i32 %12, 0
  br i1 %20, label %104, label %21

21:                                               ; preds = %19
  %22 = bitcast %"class.v8::internal::MemoryChunk"** %9 to %"class.v8::internal::Page"**
  %23 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %24 = bitcast %"class.v8::internal::MemoryChunk"** %9 to i64*
  %25 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %23, i64 0, i32 0
  %26 = bitcast %"class.v8::internal::heap::List"* %23 to i64*
  br label %27

27:                                               ; preds = %51, %21
  %28 = phi i32 [ %12, %21 ], [ %56, %51 ]
  %29 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %22, align 8
  %30 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0
  %31 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0, i32 12, i32 1
  %32 = bitcast %"class.v8::internal::MemoryChunk"** %31 to i64*
  %33 = load i64, i64* %32, align 8
  store i64 %33, i64* %24, align 8
  %34 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %25, align 8
  %35 = icmp eq %"class.v8::internal::MemoryChunk"* %34, %30
  br i1 %35, label %36, label %40

36:                                               ; preds = %27
  %37 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0, i32 12, i32 0
  %38 = bitcast %"class.v8::internal::MemoryChunk"** %37 to i64*
  %39 = load i64, i64* %38, align 8
  store i64 %39, i64* %26, align 8
  br label %40

40:                                               ; preds = %36, %27
  %41 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0, i32 12, i32 0
  %42 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %41, align 8
  %43 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %31, align 8
  %44 = icmp eq %"class.v8::internal::MemoryChunk"* %42, null
  br i1 %44, label %47, label %45

45:                                               ; preds = %40
  %46 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %42, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %43, %"class.v8::internal::MemoryChunk"** %46, align 8
  br label %47

47:                                               ; preds = %45, %40
  %48 = icmp eq %"class.v8::internal::MemoryChunk"* %43, null
  br i1 %48, label %51, label %49

49:                                               ; preds = %47
  %50 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %43, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %42, %"class.v8::internal::MemoryChunk"** %50, align 8
  br label %51

51:                                               ; preds = %49, %47
  %52 = bitcast %"class.v8::internal::MemoryChunk"** %41 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %52, i8 0, i64 16, i1 false) #13
  %53 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %8, align 8
  %54 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %53, i64 0, i32 85, i32 0, i32 0, i32 0
  %55 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %54, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %55, %"class.v8::internal::MemoryChunk"* %30) #13
  %56 = add nsw i32 %28, -1
  %57 = icmp sgt i32 %56, 0
  br i1 %57, label %27, label %104

58:                                               ; preds = %11
  %59 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %17, i64 0, i32 0
  %60 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %9, align 8
  %61 = icmp eq %"class.v8::internal::MemoryChunk"* %60, null
  br i1 %61, label %70, label %62

62:                                               ; preds = %58
  %63 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %60, i64 0, i32 12, i32 0
  %64 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %63, align 8
  %65 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %17, i64 0, i32 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %64, %"class.v8::internal::MemoryChunk"** %65, align 8
  %66 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %17, i64 0, i32 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %60, %"class.v8::internal::MemoryChunk"** %66, align 8
  store %"class.v8::internal::MemoryChunk"* %59, %"class.v8::internal::MemoryChunk"** %63, align 8
  %67 = icmp eq %"class.v8::internal::MemoryChunk"* %64, null
  %68 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %64, i64 0, i32 12, i32 1
  %69 = select i1 %67, %"class.v8::internal::MemoryChunk"** %9, %"class.v8::internal::MemoryChunk"** %68
  br label %73

70:                                               ; preds = %58
  %71 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %17, i64 0, i32 0, i32 12, i32 0
  %72 = bitcast %"class.v8::internal::MemoryChunk"** %71 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %72, i8 0, i64 16, i1 false) #13
  store %"class.v8::internal::MemoryChunk"* %59, %"class.v8::internal::MemoryChunk"** %10, align 8
  br label %73

73:                                               ; preds = %62, %70
  %74 = phi %"class.v8::internal::MemoryChunk"** [ %9, %70 ], [ %69, %62 ]
  store %"class.v8::internal::MemoryChunk"* %59, %"class.v8::internal::MemoryChunk"** %74, align 8
  %75 = add nuw nsw i32 %12, 1
  %76 = icmp eq i32 %75, %5
  br i1 %76, label %77, label %11

77:                                               ; preds = %73
  %78 = load i64, i64* %2, align 8
  br label %79

79:                                               ; preds = %77, %1
  %80 = phi i64 [ %78, %77 ], [ %3, %1 ]
  %81 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %82 = bitcast %"class.v8::internal::MemoryChunk"** %81 to i64*
  %83 = load i64, i64* %82, align 8
  %84 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 7
  %85 = bitcast %"class.v8::internal::Page"** %84 to i64*
  store i64 %83, i64* %85, align 8
  %86 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 1
  store i64 262144, i64* %86, align 8
  %87 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %88 = atomicrmw add i64* %87, i64 %80 seq_cst
  %89 = load atomic i64, i64* %87 seq_cst, align 8
  %90 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 4
  %91 = load i64, i64* %90, align 8
  %92 = icmp ugt i64 %89, %91
  br i1 %92, label %93, label %95

93:                                               ; preds = %79
  %94 = load atomic i64, i64* %87 seq_cst, align 8
  store i64 %94, i64* %90, align 8
  br label %95

95:                                               ; preds = %79, %93
  %96 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 5
  %97 = load i64, i64* %96, align 8
  %98 = icmp eq i64 %97, 0
  br i1 %98, label %99, label %104

99:                                               ; preds = %95
  %100 = bitcast %"class.v8::internal::MemoryChunk"** %81 to %"class.v8::internal::Page"**
  %101 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %100, align 8
  %102 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %101, i64 0, i32 0, i32 0, i32 3
  %103 = load i64, i64* %102, align 8
  store i64 %103, i64* %96, align 8
  br label %104

104:                                              ; preds = %51, %19, %95, %99
  %105 = phi i1 [ true, %99 ], [ true, %95 ], [ false, %19 ], [ false, %51 ]
  ret i1 %105
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace11RewindPagesEi(%"class.v8::internal::SemiSpace"* nocapture, i32) local_unnamed_addr #0 align 2 {
  %3 = icmp sgt i32 %1, 0
  br i1 %3, label %4, label %43

4:                                                ; preds = %2
  %5 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %6 = bitcast %"class.v8::internal::MemoryChunk"** %5 to %"class.v8::internal::Page"**
  %7 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %8 = bitcast %"class.v8::internal::MemoryChunk"** %5 to i64*
  %9 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %7, i64 0, i32 0
  %10 = bitcast %"class.v8::internal::heap::List"* %7 to i64*
  %11 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  br label %12

12:                                               ; preds = %4, %36
  %13 = phi i32 [ %1, %4 ], [ %41, %36 ]
  %14 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %6, align 8
  %15 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %14, i64 0, i32 0
  %16 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %14, i64 0, i32 0, i32 12, i32 1
  %17 = bitcast %"class.v8::internal::MemoryChunk"** %16 to i64*
  %18 = load i64, i64* %17, align 8
  store i64 %18, i64* %8, align 8
  %19 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %9, align 8
  %20 = icmp eq %"class.v8::internal::MemoryChunk"* %19, %15
  br i1 %20, label %21, label %25

21:                                               ; preds = %12
  %22 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %14, i64 0, i32 0, i32 12, i32 0
  %23 = bitcast %"class.v8::internal::MemoryChunk"** %22 to i64*
  %24 = load i64, i64* %23, align 8
  store i64 %24, i64* %10, align 8
  br label %25

25:                                               ; preds = %21, %12
  %26 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %14, i64 0, i32 0, i32 12, i32 0
  %27 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %26, align 8
  %28 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %16, align 8
  %29 = icmp eq %"class.v8::internal::MemoryChunk"* %27, null
  br i1 %29, label %32, label %30

30:                                               ; preds = %25
  %31 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %27, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %28, %"class.v8::internal::MemoryChunk"** %31, align 8
  br label %32

32:                                               ; preds = %30, %25
  %33 = icmp eq %"class.v8::internal::MemoryChunk"* %28, null
  br i1 %33, label %36, label %34

34:                                               ; preds = %32
  %35 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %28, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %27, %"class.v8::internal::MemoryChunk"** %35, align 8
  br label %36

36:                                               ; preds = %32, %34
  %37 = bitcast %"class.v8::internal::MemoryChunk"** %26 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %37, i8 0, i64 16, i1 false) #13
  %38 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %11, align 8
  %39 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %38, i64 0, i32 85, i32 0, i32 0, i32 0
  %40 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %39, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %40, %"class.v8::internal::MemoryChunk"* %15) #13
  %41 = add nsw i32 %13, -1
  %42 = icmp sgt i32 %41, 0
  br i1 %42, label %12, label %43

43:                                               ; preds = %36, %2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace5ResetEv(%"class.v8::internal::SemiSpace"* nocapture) local_unnamed_addr #4 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %3 = bitcast %"class.v8::internal::MemoryChunk"** %2 to i64*
  %4 = load i64, i64* %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 7
  %6 = bitcast %"class.v8::internal::Page"** %5 to i64*
  store i64 %4, i64* %6, align 8
  %7 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 1
  store i64 262144, i64* %7, align 8
  ret void
}

declare void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal9SemiSpace23CommittedPhysicalMemoryEv(%"class.v8::internal::SemiSpace"* nocapture readonly) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %3 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %2, align 8
  %4 = icmp eq %"class.v8::internal::MemoryChunk"* %3, null
  br i1 %4, label %17, label %5

5:                                                ; preds = %1
  %6 = bitcast %"class.v8::internal::MemoryChunk"* %3 to %"class.v8::internal::Page"*
  br label %7

7:                                                ; preds = %5, %7
  %8 = phi %"class.v8::internal::Page"* [ %15, %7 ], [ %6, %5 ]
  %9 = phi i64 [ %12, %7 ], [ 0, %5 ]
  %10 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %8, i64 0, i32 0
  %11 = tail call i64 @_ZN2v88internal11MemoryChunk23CommittedPhysicalMemoryEv(%"class.v8::internal::MemoryChunk"* %10) #13
  %12 = add i64 %11, %9
  %13 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %8, i64 0, i32 0, i32 12, i32 0
  %14 = bitcast %"class.v8::internal::MemoryChunk"** %13 to %"class.v8::internal::Page"**
  %15 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %14, align 8
  %16 = icmp eq %"class.v8::internal::Page"* %15, null
  br i1 %16, label %17, label %7

17:                                               ; preds = %7, %1
  %18 = phi i64 [ 0, %1 ], [ %12, %7 ]
  ret i64 %18
}

declare i64 @_ZN2v88internal11MemoryChunk23CommittedPhysicalMemoryEv(%"class.v8::internal::MemoryChunk"*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal9SemiSpace6GrowToEm(%"class.v8::internal::SemiSpace"*, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %4 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %3, align 8
  %5 = icmp eq %"class.v8::internal::MemoryChunk"* %4, null
  br i1 %5, label %6, label %12

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %8 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %7, align 8
  %9 = icmp eq %"class.v8::internal::MemoryChunk"* %8, null
  br i1 %9, label %10, label %12

10:                                               ; preds = %6
  %11 = tail call zeroext i1 @_ZN2v88internal9SemiSpace6CommitEv(%"class.v8::internal::SemiSpace"* %0)
  br i1 %11, label %12, label %111

12:                                               ; preds = %6, %2, %10
  %13 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  %14 = load i64, i64* %13, align 8
  %15 = sub i64 %1, %14
  %16 = lshr i64 %15, 18
  %17 = trunc i64 %16 to i32
  %18 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %19 = icmp sgt i32 %17, 0
  br i1 %19, label %20, label %101

20:                                               ; preds = %12
  %21 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %22 = bitcast %"class.v8::internal::MemoryChunk"** %21 to %"class.v8::internal::Page"**
  br label %23

23:                                               ; preds = %84, %20
  %24 = phi i32 [ 0, %20 ], [ %99, %84 ]
  %25 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %18, align 8
  %26 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %25, i64 0, i32 85, i32 0, i32 0, i32 0
  %27 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %26, align 8
  %28 = tail call i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() #13
  %29 = tail call %"class.v8::internal::Page"* @_ZN2v88internal15MemoryAllocator12AllocatePageILNS1_14AllocationModeE1ENS0_9SemiSpaceEEEPNS0_4PageEmPT0_NS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"* %27, i64 %28, %"class.v8::internal::SemiSpace"* %0, i32 0) #13
  %30 = icmp eq %"class.v8::internal::Page"* %29, null
  br i1 %30, label %31, label %69

31:                                               ; preds = %23
  %32 = icmp eq i32 %24, 0
  br i1 %32, label %111, label %33

33:                                               ; preds = %31
  %34 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %35 = bitcast %"class.v8::internal::MemoryChunk"** %21 to i64*
  %36 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %34, i64 0, i32 0
  %37 = bitcast %"class.v8::internal::heap::List"* %34 to i64*
  br label %38

38:                                               ; preds = %62, %33
  %39 = phi i32 [ %24, %33 ], [ %67, %62 ]
  %40 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %22, align 8
  %41 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %40, i64 0, i32 0
  %42 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %40, i64 0, i32 0, i32 12, i32 1
  %43 = bitcast %"class.v8::internal::MemoryChunk"** %42 to i64*
  %44 = load i64, i64* %43, align 8
  store i64 %44, i64* %35, align 8
  %45 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %36, align 8
  %46 = icmp eq %"class.v8::internal::MemoryChunk"* %45, %41
  br i1 %46, label %47, label %51

47:                                               ; preds = %38
  %48 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %40, i64 0, i32 0, i32 12, i32 0
  %49 = bitcast %"class.v8::internal::MemoryChunk"** %48 to i64*
  %50 = load i64, i64* %49, align 8
  store i64 %50, i64* %37, align 8
  br label %51

51:                                               ; preds = %47, %38
  %52 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %40, i64 0, i32 0, i32 12, i32 0
  %53 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %52, align 8
  %54 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %42, align 8
  %55 = icmp eq %"class.v8::internal::MemoryChunk"* %53, null
  br i1 %55, label %58, label %56

56:                                               ; preds = %51
  %57 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %53, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %54, %"class.v8::internal::MemoryChunk"** %57, align 8
  br label %58

58:                                               ; preds = %56, %51
  %59 = icmp eq %"class.v8::internal::MemoryChunk"* %54, null
  br i1 %59, label %62, label %60

60:                                               ; preds = %58
  %61 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %54, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %53, %"class.v8::internal::MemoryChunk"** %61, align 8
  br label %62

62:                                               ; preds = %60, %58
  %63 = bitcast %"class.v8::internal::MemoryChunk"** %52 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %63, i8 0, i64 16, i1 false) #13
  %64 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %18, align 8
  %65 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %64, i64 0, i32 85, i32 0, i32 0, i32 0
  %66 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %65, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %66, %"class.v8::internal::MemoryChunk"* %41) #13
  %67 = add nsw i32 %39, -1
  %68 = icmp sgt i32 %67, 0
  br i1 %68, label %38, label %111

69:                                               ; preds = %23
  %70 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0
  %71 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %21, align 8
  %72 = icmp eq %"class.v8::internal::MemoryChunk"* %71, null
  br i1 %72, label %81, label %73

73:                                               ; preds = %69
  %74 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %71, i64 0, i32 12, i32 0
  %75 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %74, align 8
  %76 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %75, %"class.v8::internal::MemoryChunk"** %76, align 8
  %77 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %71, %"class.v8::internal::MemoryChunk"** %77, align 8
  store %"class.v8::internal::MemoryChunk"* %70, %"class.v8::internal::MemoryChunk"** %74, align 8
  %78 = icmp eq %"class.v8::internal::MemoryChunk"* %75, null
  %79 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %75, i64 0, i32 12, i32 1
  %80 = select i1 %78, %"class.v8::internal::MemoryChunk"** %21, %"class.v8::internal::MemoryChunk"** %79
  br label %84

81:                                               ; preds = %69
  %82 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0, i32 12, i32 0
  %83 = bitcast %"class.v8::internal::MemoryChunk"** %82 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %83, i8 0, i64 16, i1 false) #13
  store %"class.v8::internal::MemoryChunk"* %70, %"class.v8::internal::MemoryChunk"** %3, align 8
  br label %84

84:                                               ; preds = %73, %81
  %85 = phi %"class.v8::internal::MemoryChunk"** [ %21, %81 ], [ %80, %73 ]
  store %"class.v8::internal::MemoryChunk"* %70, %"class.v8::internal::MemoryChunk"** %85, align 8
  %86 = ptrtoint %"class.v8::internal::Page"* %29 to i64
  %87 = add i64 %86, 272
  %88 = inttoptr i64 %87 to %"class.v8::internal::ConcurrentBitmap"*
  %89 = getelementptr inbounds %"class.v8::internal::ConcurrentBitmap", %"class.v8::internal::ConcurrentBitmap"* %88, i64 0, i32 0
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %89, i8 0, i64 8196, i1 false) #13
  %90 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %90 monotonic, align 8
  %91 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %22, align 8
  %92 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %91, i64 0, i32 0, i32 0, i32 1
  %93 = load i64, i64* %92, align 8
  %94 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %29, i64 0, i32 0, i32 0, i32 1
  %95 = load i64, i64* %94, align 8
  %96 = and i64 %95, -262151
  %97 = and i64 %93, 262150
  %98 = or i64 %96, %97
  store i64 %98, i64* %94, align 8
  %99 = add nuw nsw i32 %24, 1
  %100 = icmp eq i32 %99, %17
  br i1 %100, label %101, label %23

101:                                              ; preds = %84, %12
  %102 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %103 = atomicrmw add i64* %102, i64 %15 seq_cst
  %104 = load atomic i64, i64* %102 seq_cst, align 8
  %105 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 4
  %106 = load i64, i64* %105, align 8
  %107 = icmp ugt i64 %104, %106
  br i1 %107, label %108, label %110

108:                                              ; preds = %101
  %109 = load atomic i64, i64* %102 seq_cst, align 8
  store i64 %109, i64* %105, align 8
  br label %110

110:                                              ; preds = %101, %108
  store i64 %1, i64* %13, align 8
  br label %111

111:                                              ; preds = %62, %31, %110, %10
  %112 = phi i1 [ false, %10 ], [ true, %110 ], [ false, %31 ], [ false, %62 ]
  ret i1 %112
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace8ShrinkToEm(%"class.v8::internal::SemiSpace"* nocapture, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %4 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %3, align 8
  %5 = icmp eq %"class.v8::internal::MemoryChunk"* %4, null
  br i1 %5, label %6, label %10

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %8 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %7, align 8
  %9 = icmp eq %"class.v8::internal::MemoryChunk"* %8, null
  br i1 %9, label %66, label %10

10:                                               ; preds = %6, %2
  %11 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  %12 = load i64, i64* %11, align 8
  %13 = sub i64 %12, %1
  %14 = lshr i64 %13, 18
  %15 = trunc i64 %14 to i32
  %16 = icmp sgt i32 %15, 0
  br i1 %16, label %17, label %58

17:                                               ; preds = %10
  %18 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %19 = bitcast %"class.v8::internal::MemoryChunk"** %18 to %"class.v8::internal::Page"**
  %20 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %21 = bitcast %"class.v8::internal::MemoryChunk"** %18 to i64*
  %22 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %20, i64 0, i32 0
  %23 = bitcast %"class.v8::internal::heap::List"* %20 to i64*
  %24 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  br label %25

25:                                               ; preds = %56, %17
  %26 = phi %"class.v8::internal::MemoryChunk"* [ %4, %17 ], [ %57, %56 ]
  %27 = phi i32 [ %15, %17 ], [ %54, %56 ]
  %28 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %19, align 8
  %29 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %28, i64 0, i32 0
  %30 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %28, i64 0, i32 0, i32 12, i32 1
  %31 = bitcast %"class.v8::internal::MemoryChunk"** %30 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %21, align 8
  %33 = icmp eq %"class.v8::internal::MemoryChunk"* %26, %29
  br i1 %33, label %34, label %38

34:                                               ; preds = %25
  %35 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %28, i64 0, i32 0, i32 12, i32 0
  %36 = bitcast %"class.v8::internal::MemoryChunk"** %35 to i64*
  %37 = load i64, i64* %36, align 8
  store i64 %37, i64* %23, align 8
  br label %38

38:                                               ; preds = %34, %25
  %39 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %28, i64 0, i32 0, i32 12, i32 0
  %40 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %39, align 8
  %41 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %30, align 8
  %42 = icmp eq %"class.v8::internal::MemoryChunk"* %40, null
  br i1 %42, label %45, label %43

43:                                               ; preds = %38
  %44 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %40, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %41, %"class.v8::internal::MemoryChunk"** %44, align 8
  br label %45

45:                                               ; preds = %43, %38
  %46 = icmp eq %"class.v8::internal::MemoryChunk"* %41, null
  br i1 %46, label %49, label %47

47:                                               ; preds = %45
  %48 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %41, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %40, %"class.v8::internal::MemoryChunk"** %48, align 8
  br label %49

49:                                               ; preds = %47, %45
  %50 = bitcast %"class.v8::internal::MemoryChunk"** %39 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %50, i8 0, i64 16, i1 false) #13
  %51 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %24, align 8
  %52 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %51, i64 0, i32 85, i32 0, i32 0, i32 0
  %53 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %52, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %53, %"class.v8::internal::MemoryChunk"* %29) #13
  %54 = add nsw i32 %27, -1
  %55 = icmp sgt i32 %54, 0
  br i1 %55, label %56, label %58

56:                                               ; preds = %49
  %57 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %22, align 8
  br label %25

58:                                               ; preds = %49, %10
  %59 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %60 = atomicrmw sub i64* %59, i64 %13 seq_cst
  %61 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %62 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %61, align 8
  %63 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %62, i64 0, i32 85, i32 0, i32 0, i32 0
  %64 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %63, align 8
  %65 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %64, i64 0, i32 9
  tail call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %65) #13
  br label %66

66:                                               ; preds = %6, %58
  %67 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  store i64 %1, i64* %67, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace13FixPagesFlagsEll(%"class.v8::internal::SemiSpace"*, i64, i64) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %5 = bitcast %"class.v8::internal::MemoryChunk"** %4 to %"class.v8::internal::Page"**
  %6 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %5, align 8
  %7 = icmp eq %"class.v8::internal::Page"* %6, null
  br i1 %7, label %13, label %8

8:                                                ; preds = %3
  %9 = ptrtoint %"class.v8::internal::SemiSpace"* %0 to i64
  %10 = xor i64 %2, -1
  %11 = and i64 %2, %1
  %12 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 6
  br label %14

13:                                               ; preds = %31, %3
  ret void

14:                                               ; preds = %8, %31
  %15 = phi %"class.v8::internal::Page"* [ %6, %8 ], [ %34, %31 ]
  %16 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %15, i64 0, i32 0, i32 0, i32 8
  %17 = bitcast %"struct.std::__1::atomic.611"* %16 to i64*
  store atomic i64 %9, i64* %17 seq_cst, align 8
  %18 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %15, i64 0, i32 0, i32 0, i32 1
  %19 = load i64, i64* %18, align 8
  %20 = and i64 %19, %10
  %21 = or i64 %20, %11
  store i64 %21, i64* %18, align 8
  %22 = load i32, i32* %12, align 8
  %23 = icmp eq i32 %22, 1
  br i1 %23, label %24, label %28

24:                                               ; preds = %14
  %25 = and i64 %21, -524313
  %26 = or i64 %25, 16
  store i64 %26, i64* %18, align 8
  %27 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %15, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %27 monotonic, align 8
  br label %31

28:                                               ; preds = %14
  %29 = and i64 %21, -25
  %30 = or i64 %29, 8
  store i64 %30, i64* %18, align 8
  br label %31

31:                                               ; preds = %28, %24
  %32 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %15, i64 0, i32 0, i32 12, i32 0
  %33 = bitcast %"class.v8::internal::MemoryChunk"** %32 to %"class.v8::internal::Page"**
  %34 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %33, align 8
  %35 = icmp eq %"class.v8::internal::Page"* %34, null
  br i1 %35, label %13, label %14
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace10RemovePageEPNS0_4PageE(%"class.v8::internal::SemiSpace"* nocapture, %"class.v8::internal::Page"*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 7
  %4 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %3, align 8
  %5 = icmp eq %"class.v8::internal::Page"* %4, %1
  br i1 %5, label %6, label %12

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 1
  %8 = bitcast %"class.v8::internal::MemoryChunk"** %7 to %"class.v8::internal::Page"**
  %9 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %8, align 8
  %10 = icmp eq %"class.v8::internal::Page"* %9, null
  br i1 %10, label %12, label %11

11:                                               ; preds = %6
  store %"class.v8::internal::Page"* %9, %"class.v8::internal::Page"** %3, align 8
  br label %12

12:                                               ; preds = %6, %11, %2
  %13 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %14 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0
  %15 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %16 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %15, align 8
  %17 = icmp eq %"class.v8::internal::MemoryChunk"* %16, %14
  br i1 %17, label %18, label %23

18:                                               ; preds = %12
  %19 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 1
  %20 = bitcast %"class.v8::internal::MemoryChunk"** %19 to i64*
  %21 = load i64, i64* %20, align 8
  %22 = bitcast %"class.v8::internal::MemoryChunk"** %15 to i64*
  store i64 %21, i64* %22, align 8
  br label %23

23:                                               ; preds = %18, %12
  %24 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %13, i64 0, i32 0
  %25 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %24, align 8
  %26 = icmp eq %"class.v8::internal::MemoryChunk"* %25, %14
  br i1 %26, label %27, label %32

27:                                               ; preds = %23
  %28 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 0
  %29 = bitcast %"class.v8::internal::MemoryChunk"** %28 to i64*
  %30 = load i64, i64* %29, align 8
  %31 = bitcast %"class.v8::internal::heap::List"* %13 to i64*
  store i64 %30, i64* %31, align 8
  br label %32

32:                                               ; preds = %27, %23
  %33 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 0
  %34 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %33, align 8
  %35 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 1
  %36 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %35, align 8
  %37 = icmp eq %"class.v8::internal::MemoryChunk"* %34, null
  br i1 %37, label %40, label %38

38:                                               ; preds = %32
  %39 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %34, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %36, %"class.v8::internal::MemoryChunk"** %39, align 8
  br label %40

40:                                               ; preds = %38, %32
  %41 = icmp eq %"class.v8::internal::MemoryChunk"* %36, null
  br i1 %41, label %44, label %42

42:                                               ; preds = %40
  %43 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %36, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %34, %"class.v8::internal::MemoryChunk"** %43, align 8
  br label %44

44:                                               ; preds = %40, %42
  %45 = bitcast %"class.v8::internal::MemoryChunk"** %33 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %45, i8 0, i64 16, i1 false) #13
  %46 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 3
  %47 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %48 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 11, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %49 = load atomic i64, i64* %48 seq_cst, align 8
  %50 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %46, align 8
  %51 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %50, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %52 = atomicrmw sub i64* %51, i64 %49 seq_cst
  %53 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %47, align 8
  %54 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %53, i64 0, i32 17, i32 0, i32 0, i32 0, i32 0, i32 0
  %55 = atomicrmw sub i64* %54, i64 %49 seq_cst
  %56 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 11, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %57 = load atomic i64, i64* %56 seq_cst, align 8
  %58 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %46, align 8
  %59 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %58, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %60 = atomicrmw sub i64* %59, i64 %57 seq_cst
  %61 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %47, align 8
  %62 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %61, i64 0, i32 17, i32 0, i32 0, i32 0, i32 0, i32 0
  %63 = atomicrmw sub i64* %62, i64 %57 seq_cst
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace11PrependPageEPNS0_4PageE(%"class.v8::internal::SemiSpace"*, %"class.v8::internal::Page"*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 7
  %4 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %4, i64 0, i32 0, i32 0, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 0, i32 1
  store i64 %6, i64* %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 0, i32 8
  %9 = ptrtoint %"class.v8::internal::SemiSpace"* %0 to i64
  %10 = bitcast %"struct.std::__1::atomic.611"* %8 to i64*
  store atomic i64 %9, i64* %10 seq_cst, align 8
  %11 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0
  %12 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %13 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %12, align 8
  %14 = icmp eq %"class.v8::internal::MemoryChunk"* %13, null
  br i1 %14, label %23, label %15

15:                                               ; preds = %2
  %16 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %13, i64 0, i32 12, i32 1
  %17 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %16, align 8
  %18 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %13, %"class.v8::internal::MemoryChunk"** %18, align 8
  %19 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %17, %"class.v8::internal::MemoryChunk"** %19, align 8
  store %"class.v8::internal::MemoryChunk"* %11, %"class.v8::internal::MemoryChunk"** %16, align 8
  %20 = icmp eq %"class.v8::internal::MemoryChunk"* %17, null
  %21 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %17, i64 0, i32 12, i32 0
  %22 = select i1 %20, %"class.v8::internal::MemoryChunk"** %12, %"class.v8::internal::MemoryChunk"** %21
  br label %27

23:                                               ; preds = %2
  %24 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 0
  %25 = bitcast %"class.v8::internal::MemoryChunk"** %24 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %25, i8 0, i64 16, i1 false) #13
  store %"class.v8::internal::MemoryChunk"* %11, %"class.v8::internal::MemoryChunk"** %12, align 8
  %26 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  br label %27

27:                                               ; preds = %15, %23
  %28 = phi %"class.v8::internal::MemoryChunk"** [ %26, %23 ], [ %22, %15 ]
  store %"class.v8::internal::MemoryChunk"* %11, %"class.v8::internal::MemoryChunk"** %28, align 8
  %29 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 1
  %30 = load i64, i64* %29, align 8
  %31 = add i64 %30, 262144
  store i64 %31, i64* %29, align 8
  %32 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 3
  %33 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %34 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 11, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %35 = load atomic i64, i64* %34 seq_cst, align 8
  %36 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %32, align 8
  %37 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %36, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %38 = atomicrmw add i64* %37, i64 %35 seq_cst
  %39 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %33, align 8
  %40 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %39, i64 0, i32 17, i32 0, i32 0, i32 0, i32 0, i32 0
  %41 = atomicrmw add i64* %40, i64 %35 seq_cst
  %42 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 11, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %43 = load atomic i64, i64* %42 seq_cst, align 8
  %44 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %32, align 8
  %45 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %44, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %46 = atomicrmw add i64* %45, i64 %43 seq_cst
  %47 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %33, align 8
  %48 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %47, i64 0, i32 17, i32 0, i32 0, i32 0, i32 0, i32 0
  %49 = atomicrmw add i64* %48, i64 %43 seq_cst
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace16MovePageToTheEndEPNS0_4PageE(%"class.v8::internal::SemiSpace"* nocapture, %"class.v8::internal::Page"*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %4 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0
  %5 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %6 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %5, align 8
  %7 = icmp eq %"class.v8::internal::MemoryChunk"* %6, %4
  br i1 %7, label %8, label %13

8:                                                ; preds = %2
  %9 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 1
  %10 = bitcast %"class.v8::internal::MemoryChunk"** %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = bitcast %"class.v8::internal::MemoryChunk"** %5 to i64*
  store i64 %11, i64* %12, align 8
  br label %13

13:                                               ; preds = %8, %2
  %14 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %3, i64 0, i32 0
  %15 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %14, align 8
  %16 = icmp eq %"class.v8::internal::MemoryChunk"* %15, %4
  br i1 %16, label %17, label %22

17:                                               ; preds = %13
  %18 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 0
  %19 = bitcast %"class.v8::internal::MemoryChunk"** %18 to i64*
  %20 = load i64, i64* %19, align 8
  %21 = bitcast %"class.v8::internal::heap::List"* %3 to i64*
  store i64 %20, i64* %21, align 8
  br label %22

22:                                               ; preds = %17, %13
  %23 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 0
  %24 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %23, align 8
  %25 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %1, i64 0, i32 0, i32 12, i32 1
  %26 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %25, align 8
  %27 = icmp eq %"class.v8::internal::MemoryChunk"* %24, null
  br i1 %27, label %30, label %28

28:                                               ; preds = %22
  %29 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %24, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %26, %"class.v8::internal::MemoryChunk"** %29, align 8
  br label %30

30:                                               ; preds = %28, %22
  %31 = icmp eq %"class.v8::internal::MemoryChunk"* %26, null
  br i1 %31, label %34, label %32

32:                                               ; preds = %30
  %33 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %26, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %24, %"class.v8::internal::MemoryChunk"** %33, align 8
  br label %34

34:                                               ; preds = %30, %32
  %35 = bitcast %"class.v8::internal::MemoryChunk"** %23 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %35, i8 0, i64 16, i1 false) #13
  %36 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %5, align 8
  %37 = icmp eq %"class.v8::internal::MemoryChunk"* %36, null
  br i1 %37, label %44, label %38

38:                                               ; preds = %34
  %39 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %36, i64 0, i32 12, i32 0
  %40 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %39, align 8
  store %"class.v8::internal::MemoryChunk"* %40, %"class.v8::internal::MemoryChunk"** %23, align 8
  store %"class.v8::internal::MemoryChunk"* %36, %"class.v8::internal::MemoryChunk"** %25, align 8
  store %"class.v8::internal::MemoryChunk"* %4, %"class.v8::internal::MemoryChunk"** %39, align 8
  %41 = icmp eq %"class.v8::internal::MemoryChunk"* %40, null
  %42 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %40, i64 0, i32 12, i32 1
  %43 = select i1 %41, %"class.v8::internal::MemoryChunk"** %5, %"class.v8::internal::MemoryChunk"** %42
  br label %45

44:                                               ; preds = %34
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %35, i8 0, i64 16, i1 false) #13
  store %"class.v8::internal::MemoryChunk"* %4, %"class.v8::internal::MemoryChunk"** %14, align 8
  br label %45

45:                                               ; preds = %38, %44
  %46 = phi %"class.v8::internal::MemoryChunk"** [ %5, %44 ], [ %43, %38 ]
  store %"class.v8::internal::MemoryChunk"* %4, %"class.v8::internal::MemoryChunk"** %46, align 8
  %47 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 7
  store %"class.v8::internal::Page"* %1, %"class.v8::internal::Page"** %47, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace4SwapEPS1_S2_(%"class.v8::internal::SemiSpace"*, %"class.v8::internal::SemiSpace"*) local_unnamed_addr #4 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 7
  %4 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %4, i64 0, i32 0, i32 0, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 2
  %8 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 2
  %9 = load i64, i64* %7, align 8
  %10 = load i64, i64* %8, align 8
  store i64 %10, i64* %7, align 8
  store i64 %9, i64* %8, align 8
  %11 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 3
  %12 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 3
  %13 = load i64, i64* %11, align 8
  %14 = load i64, i64* %12, align 8
  store i64 %14, i64* %11, align 8
  store i64 %13, i64* %12, align 8
  %15 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 4
  %16 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 4
  %17 = load i64, i64* %15, align 8
  %18 = load i64, i64* %16, align 8
  store i64 %18, i64* %15, align 8
  store i64 %17, i64* %16, align 8
  %19 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 5
  %20 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 5
  %21 = load i64, i64* %19, align 8
  %22 = load i64, i64* %20, align 8
  store i64 %22, i64* %19, align 8
  store i64 %21, i64* %20, align 8
  %23 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2
  %24 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 0, i32 2
  %25 = bitcast %"class.v8::internal::heap::List"* %23 to i64*
  %26 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %27 = bitcast %"class.v8::internal::MemoryChunk"** %26 to i64*
  %28 = bitcast %"class.v8::internal::heap::List"* %23 to <2 x i64>*
  %29 = load <2 x i64>, <2 x i64>* %28, align 8
  %30 = bitcast %"class.v8::internal::heap::List"* %23 to <2 x %"class.v8::internal::MemoryChunk"*>*
  store <2 x %"class.v8::internal::MemoryChunk"*> zeroinitializer, <2 x %"class.v8::internal::MemoryChunk"*>* %30, align 8
  %31 = bitcast %"class.v8::internal::heap::List"* %24 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %25, align 8
  %33 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 0, i32 2, i32 1
  %34 = bitcast %"class.v8::internal::MemoryChunk"** %33 to i64*
  %35 = load i64, i64* %34, align 8
  store i64 %35, i64* %27, align 8
  %36 = bitcast %"class.v8::internal::heap::List"* %24 to <2 x i64>*
  store <2 x i64> %29, <2 x i64>* %36, align 8
  %37 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 7
  %38 = bitcast %"class.v8::internal::Page"** %37 to i64*
  %39 = load i64, i64* %38, align 8
  %40 = bitcast %"class.v8::internal::Page"** %3 to i64*
  %41 = load i64, i64* %40, align 8
  store i64 %41, i64* %38, align 8
  store i64 %39, i64* %40, align 8
  %42 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 3
  %43 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 0, i32 3
  %44 = bitcast %"struct.std::__1::atomic"** %42 to i64*
  %45 = load i64, i64* %44, align 8
  %46 = bitcast %"struct.std::__1::atomic"** %43 to i64*
  %47 = load i64, i64* %46, align 8
  store i64 %47, i64* %44, align 8
  store i64 %45, i64* %46, align 8
  %48 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 0, i32 2, i32 0
  %49 = bitcast %"class.v8::internal::MemoryChunk"** %48 to %"class.v8::internal::Page"**
  %50 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %49, align 8
  %51 = icmp eq %"class.v8::internal::Page"* %50, null
  br i1 %51, label %78, label %52

52:                                               ; preds = %2
  %53 = ptrtoint %"class.v8::internal::SemiSpace"* %1 to i64
  %54 = and i64 %6, 262150
  %55 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %1, i64 0, i32 6
  br label %56

56:                                               ; preds = %73, %52
  %57 = phi %"class.v8::internal::Page"* [ %50, %52 ], [ %76, %73 ]
  %58 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %57, i64 0, i32 0, i32 0, i32 8
  %59 = bitcast %"struct.std::__1::atomic.611"* %58 to i64*
  store atomic i64 %53, i64* %59 seq_cst, align 8
  %60 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %57, i64 0, i32 0, i32 0, i32 1
  %61 = load i64, i64* %60, align 8
  %62 = and i64 %61, -262151
  %63 = or i64 %62, %54
  store i64 %63, i64* %60, align 8
  %64 = load i32, i32* %55, align 8
  %65 = icmp eq i32 %64, 1
  br i1 %65, label %66, label %70

66:                                               ; preds = %56
  %67 = and i64 %63, -524313
  %68 = or i64 %67, 16
  store i64 %68, i64* %60, align 8
  %69 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %57, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %69 monotonic, align 8
  br label %73

70:                                               ; preds = %56
  %71 = and i64 %63, -25
  %72 = or i64 %71, 8
  store i64 %72, i64* %60, align 8
  br label %73

73:                                               ; preds = %70, %66
  %74 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %57, i64 0, i32 0, i32 12, i32 0
  %75 = bitcast %"class.v8::internal::MemoryChunk"** %74 to %"class.v8::internal::Page"**
  %76 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %75, align 8
  %77 = icmp eq %"class.v8::internal::Page"* %76, null
  br i1 %77, label %78, label %56

78:                                               ; preds = %73, %2
  %79 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %80 = bitcast %"class.v8::internal::MemoryChunk"** %79 to %"class.v8::internal::Page"**
  %81 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %80, align 8
  %82 = icmp eq %"class.v8::internal::Page"* %81, null
  br i1 %82, label %106, label %83

83:                                               ; preds = %78
  %84 = ptrtoint %"class.v8::internal::SemiSpace"* %0 to i64
  %85 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 6
  br label %86

86:                                               ; preds = %101, %83
  %87 = phi %"class.v8::internal::Page"* [ %81, %83 ], [ %104, %101 ]
  %88 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %87, i64 0, i32 0, i32 0, i32 8
  %89 = bitcast %"struct.std::__1::atomic.611"* %88 to i64*
  store atomic i64 %84, i64* %89 seq_cst, align 8
  %90 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %87, i64 0, i32 0, i32 0, i32 1
  %91 = load i64, i64* %90, align 8
  %92 = load i32, i32* %85, align 8
  %93 = icmp eq i32 %92, 1
  br i1 %93, label %94, label %98

94:                                               ; preds = %86
  %95 = and i64 %91, -524313
  %96 = or i64 %95, 16
  store i64 %96, i64* %90, align 8
  %97 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %87, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %97 monotonic, align 8
  br label %101

98:                                               ; preds = %86
  %99 = and i64 %91, -25
  %100 = or i64 %99, 8
  store i64 %100, i64* %90, align 8
  br label %101

101:                                              ; preds = %98, %94
  %102 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %87, i64 0, i32 0, i32 12, i32 0
  %103 = bitcast %"class.v8::internal::MemoryChunk"** %102 to %"class.v8::internal::Page"**
  %104 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %103, align 8
  %105 = icmp eq %"class.v8::internal::Page"* %104, null
  br i1 %105, label %106, label %86

106:                                              ; preds = %101, %78
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9SemiSpace12set_age_markEm(%"class.v8::internal::SemiSpace"* nocapture, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 5
  store i64 %1, i64* %3, align 8
  %4 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %5 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %5, i64 0, i32 0, i32 3
  %7 = load i64, i64* %6, align 8
  %8 = and i64 %7, -262144
  %9 = add i64 %1, -4
  %10 = and i64 %9, -262144
  %11 = inttoptr i64 %10 to %"class.v8::internal::Page"*
  %12 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %11, i64 0, i32 0, i32 12, i32 0
  %13 = bitcast %"class.v8::internal::MemoryChunk"** %12 to %"class.v8::internal::Page"**
  %14 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %13, align 8
  %15 = inttoptr i64 %8 to %"class.v8::internal::Page"*
  %16 = icmp eq %"class.v8::internal::Page"* %14, %15
  br i1 %16, label %17, label %18

17:                                               ; preds = %18, %2
  ret void

18:                                               ; preds = %2, %18
  %19 = phi %"class.v8::internal::Page"* [ %25, %18 ], [ %15, %2 ]
  %20 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %19, i64 0, i32 0, i32 0, i32 1
  %21 = load i64, i64* %20, align 8
  %22 = or i64 %21, 524288
  store i64 %22, i64* %20, align 8
  %23 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %19, i64 0, i32 0, i32 12, i32 0
  %24 = bitcast %"class.v8::internal::MemoryChunk"** %23 to %"class.v8::internal::Page"**
  %25 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %24, align 8
  %26 = icmp eq %"class.v8::internal::Page"* %14, %25
  br i1 %26, label %17, label %18
}

; Function Attrs: noreturn nounwind ssp uwtable
define hidden noalias nonnull %"class.v8::internal::ObjectIterator"* @_ZN2v88internal9SemiSpace17GetObjectIteratorEPNS0_4HeapE(%"class.v8::internal::SemiSpace"* nocapture readnone, %"class.v8::internal::Heap"* nocapture readnone) unnamed_addr #5 align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: noreturn
declare void @_Z8V8_FatalPKcz(i8*, ...) local_unnamed_addr #6

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal23SemiSpaceObjectIteratorC2EPNS0_8NewSpaceE(%"class.v8::internal::SemiSpaceObjectIterator"* nocapture, %"class.v8::internal::NewSpace"* nocapture readonly) unnamed_addr #4 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpaceObjectIterator", %"class.v8::internal::SemiSpaceObjectIterator"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2v88internal23SemiSpaceObjectIteratorE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %3, align 8
  %4 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %1, i64 0, i32 4, i32 0, i32 2, i32 0
  %5 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %5, i64 0, i32 0, i32 3
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %1, i64 0, i32 0, i32 1, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::SemiSpaceObjectIterator", %"class.v8::internal::SemiSpaceObjectIterator"* %0, i64 0, i32 1
  store i64 %7, i64* %10, align 8
  %11 = getelementptr inbounds %"class.v8::internal::SemiSpaceObjectIterator", %"class.v8::internal::SemiSpaceObjectIterator"* %0, i64 0, i32 2
  store i64 %9, i64* %11, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @_ZN2v88internal23SemiSpaceObjectIterator10InitializeEmm(%"class.v8::internal::SemiSpaceObjectIterator"* nocapture, i64, i64) local_unnamed_addr #3 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::SemiSpaceObjectIterator", %"class.v8::internal::SemiSpaceObjectIterator"* %0, i64 0, i32 1
  store i64 %1, i64* %4, align 8
  %5 = getelementptr inbounds %"class.v8::internal::SemiSpaceObjectIterator", %"class.v8::internal::SemiSpaceObjectIterator"* %0, i64 0, i32 2
  store i64 %2, i64* %5, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal8NewSpace23CommittedPhysicalMemoryEv(%"class.v8::internal::NewSpace"* nocapture readonly) unnamed_addr #0 align 2 {
  %2 = tail call zeroext i1 @_ZN2v84base2OS14HasLazyCommitsEv() #13
  br i1 %2, label %9, label %3

3:                                                ; preds = %1
  %4 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %5 = load atomic i64, i64* %4 seq_cst, align 8
  %6 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load atomic i64, i64* %6 seq_cst, align 8
  %8 = add i64 %7, %5
  br label %68

9:                                                ; preds = %1
  %10 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %11 = load i64, i64* %10, align 8
  %12 = icmp eq i64 %11, 0
  br i1 %12, label %28, label %13

13:                                               ; preds = %9
  %14 = add i64 %11, -1
  %15 = and i64 %14, -262144
  %16 = inttoptr i64 %15 to %"class.v8::internal::BasicMemoryChunk"*
  %17 = sub i64 %11, %15
  %18 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %16, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %19 = load atomic i64, i64* %18 monotonic, align 8
  %20 = icmp sgt i64 %17, %19
  br i1 %20, label %21, label %28

21:                                               ; preds = %13, %25
  %22 = phi i64 [ %26, %25 ], [ %19, %13 ]
  %23 = cmpxchg weak i64* %18, i64 %22, i64 %17 acq_rel monotonic
  %24 = extractvalue { i64, i1 } %23, 1
  br i1 %24, label %28, label %25

25:                                               ; preds = %21
  %26 = extractvalue { i64, i1 } %23, 0
  %27 = icmp sgt i64 %17, %26
  br i1 %27, label %21, label %28

28:                                               ; preds = %21, %25, %9, %13
  %29 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 0
  %30 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %29, align 8
  %31 = icmp eq %"class.v8::internal::MemoryChunk"* %30, null
  br i1 %31, label %44, label %32

32:                                               ; preds = %28
  %33 = bitcast %"class.v8::internal::MemoryChunk"* %30 to %"class.v8::internal::Page"*
  br label %34

34:                                               ; preds = %32, %34
  %35 = phi %"class.v8::internal::Page"* [ %42, %34 ], [ %33, %32 ]
  %36 = phi i64 [ %39, %34 ], [ 0, %32 ]
  %37 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %35, i64 0, i32 0
  %38 = tail call i64 @_ZN2v88internal11MemoryChunk23CommittedPhysicalMemoryEv(%"class.v8::internal::MemoryChunk"* %37) #13
  %39 = add i64 %38, %36
  %40 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %35, i64 0, i32 0, i32 12, i32 0
  %41 = bitcast %"class.v8::internal::MemoryChunk"** %40 to %"class.v8::internal::Page"**
  %42 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %41, align 8
  %43 = icmp eq %"class.v8::internal::Page"* %42, null
  br i1 %43, label %44, label %34

44:                                               ; preds = %34, %28
  %45 = phi i64 [ 0, %28 ], [ %39, %34 ]
  %46 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2, i32 0
  %47 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %46, align 8
  %48 = icmp eq %"class.v8::internal::MemoryChunk"* %47, null
  br i1 %48, label %49, label %53

49:                                               ; preds = %44
  %50 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2, i32 1
  %51 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %50, align 8
  %52 = icmp eq %"class.v8::internal::MemoryChunk"* %51, null
  br i1 %52, label %68, label %65

53:                                               ; preds = %44
  %54 = bitcast %"class.v8::internal::MemoryChunk"* %47 to %"class.v8::internal::Page"*
  br label %55

55:                                               ; preds = %53, %55
  %56 = phi %"class.v8::internal::Page"* [ %63, %55 ], [ %54, %53 ]
  %57 = phi i64 [ %60, %55 ], [ 0, %53 ]
  %58 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %56, i64 0, i32 0
  %59 = tail call i64 @_ZN2v88internal11MemoryChunk23CommittedPhysicalMemoryEv(%"class.v8::internal::MemoryChunk"* %58) #13
  %60 = add i64 %59, %57
  %61 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %56, i64 0, i32 0, i32 12, i32 0
  %62 = bitcast %"class.v8::internal::MemoryChunk"** %61 to %"class.v8::internal::Page"**
  %63 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %62, align 8
  %64 = icmp eq %"class.v8::internal::Page"* %63, null
  br i1 %64, label %65, label %55

65:                                               ; preds = %55, %49
  %66 = phi i64 [ 0, %49 ], [ %60, %55 ]
  %67 = add i64 %66, %45
  br label %68

68:                                               ; preds = %49, %65, %3
  %69 = phi i64 [ %8, %3 ], [ %67, %65 ], [ %45, %49 ]
  ret i64 %69
}

declare zeroext i1 @_ZN2v84base2OS14HasLazyCommitsEv() local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal8NewSpace15CommittedMemoryEv(%"class.v8::internal::NewSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i64, i64* %2 seq_cst, align 8
  %4 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %5 = load atomic i64, i64* %4 seq_cst, align 8
  %6 = add i64 %5, %3
  ret i64 %6
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpaceC2EPNS0_4HeapEPNS_13PageAllocatorEmm(%"class.v8::internal::NewSpace"*, %"class.v8::internal::Heap"*, %"class.v8::PageAllocator"* nocapture readnone, i64, i64) unnamed_addr #0 align 2 {
  %6 = tail call i8* @_Znwm(i64 48) #15
  %7 = bitcast i8* %6 to i32 (...)***
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %6, i8 0, i64 48, i1 false)
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [12 x i8*] }, { [12 x i8*] }* @_ZTVN2v88internal10NoFreeListE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %9 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %9, align 8
  %10 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 7, i32* %10, align 8
  %11 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = bitcast i64* %11 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %12, i8 0, i64 16, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %8, align 8
  %13 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %14 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 2, i32 0, i32 3
  %15 = bitcast %"class.std::__1::__compressed_pair.54"* %14 to i32*
  %16 = bitcast %"class.v8::internal::AllocationCounter"* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %16, i8 0, i64 80, i1 false) #13
  store i32 1065353216, i32* %15, align 4
  %17 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 3
  store i8 0, i8* %17, align 8
  %18 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 5
  %19 = bitcast i64* %18 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %19, i8 0, i64 17, i1 false) #13
  %20 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 2
  %21 = bitcast %"class.v8::internal::heap::List"* %20 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %21, i8 0, i64 16, i1 false) #13
  %22 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 4
  %23 = ptrtoint i8* %6 to i64
  %24 = bitcast %"class.std::__1::unique_ptr.59"* %22 to i64*
  store i64 %23, i64* %24, align 8
  %25 = tail call i8* @_Znam(i64 16) #15
  %26 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 3
  %27 = bitcast %"struct.std::__1::atomic"** %26 to i8**
  store i8* %25, i8** %27, align 8
  %28 = bitcast i8* %25 to i64*
  store atomic i64 0, i64* %28 seq_cst, align 8
  %29 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %26, align 8
  %30 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %29, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %30 seq_cst, align 8
  %31 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 0
  %32 = bitcast i64* %31 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %32, i8 0, i64 48, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [20 x i8*] }, { [20 x i8*] }* @_ZTVN2v88internal8NewSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %8, align 8
  %33 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"* %33) #13
  %34 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4
  %35 = tail call i8* @_Znwm(i64 48) #15
  %36 = bitcast i8* %35 to i32 (...)***
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %35, i8 0, i64 48, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [12 x i8*] }, { [12 x i8*] }* @_ZTVN2v88internal10NoFreeListE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %36, align 8
  %37 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %34, i64 0, i32 0, i32 0, i32 0
  %38 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %38, align 8
  %39 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 2
  store i32 7, i32* %39, align 8
  %40 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %41 = bitcast i64* %40 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %41, i8 0, i64 16, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %37, align 8
  %42 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 1
  %43 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 1, i32 2, i32 0, i32 3
  %44 = bitcast %"class.std::__1::__compressed_pair.54"* %43 to i32*
  %45 = bitcast %"class.v8::internal::AllocationCounter"* %42 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %45, i8 0, i64 80, i1 false) #13
  store i32 1065353216, i32* %44, align 4
  %46 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 1, i32 3
  store i8 0, i8* %46, align 8
  %47 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 1, i32 5
  %48 = bitcast i64* %47 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %48, i8 0, i64 17, i1 false) #13
  %49 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2
  %50 = bitcast %"class.v8::internal::heap::List"* %49 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %50, i8 0, i64 16, i1 false) #13
  %51 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 4
  %52 = ptrtoint i8* %35 to i64
  %53 = bitcast %"class.std::__1::unique_ptr.59"* %51 to i64*
  store i64 %52, i64* %53, align 8
  %54 = tail call i8* @_Znam(i64 16) #15
  %55 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 3
  %56 = bitcast %"struct.std::__1::atomic"** %55 to i8**
  store i8* %54, i8** %56, align 8
  %57 = bitcast i8* %54 to i64*
  store atomic i64 0, i64* %57 seq_cst, align 8
  %58 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %55, align 8
  %59 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %58, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %59 seq_cst, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal9SemiSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %37, align 8
  %60 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 1
  %61 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 6
  %62 = bitcast i64* %60 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %62, i8 0, i64 40, i1 false) #13
  store i32 1, i32* %61, align 8
  %63 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  store %"class.v8::internal::Page"* null, %"class.v8::internal::Page"** %63, align 8
  %64 = tail call i8* @_Znwm(i64 48) #15
  %65 = bitcast i8* %64 to i32 (...)***
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %64, i8 0, i64 48, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [12 x i8*] }, { [12 x i8*] }* @_ZTVN2v88internal10NoFreeListE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %65, align 8
  %66 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 0
  %67 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %67, align 8
  %68 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 2
  store i32 7, i32* %68, align 8
  %69 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %70 = bitcast i64* %69 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %70, i8 0, i64 16, i1 false) #13
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %66, align 8
  %71 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 1
  %72 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 1, i32 2, i32 0, i32 3
  %73 = bitcast %"class.std::__1::__compressed_pair.54"* %72 to i32*
  %74 = bitcast %"class.v8::internal::AllocationCounter"* %71 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %74, i8 0, i64 80, i1 false) #13
  store i32 1065353216, i32* %73, align 4
  %75 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 1, i32 3
  store i8 0, i8* %75, align 8
  %76 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 1, i32 5
  %77 = bitcast i64* %76 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %77, i8 0, i64 17, i1 false) #13
  %78 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2
  %79 = bitcast %"class.v8::internal::heap::List"* %78 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %79, i8 0, i64 16, i1 false) #13
  %80 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 4
  %81 = ptrtoint i8* %64 to i64
  %82 = bitcast %"class.std::__1::unique_ptr.59"* %80 to i64*
  store i64 %81, i64* %82, align 8
  %83 = tail call i8* @_Znam(i64 16) #15
  %84 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 3
  %85 = bitcast %"struct.std::__1::atomic"** %84 to i8**
  store i8* %83, i8** %85, align 8
  %86 = bitcast i8* %83 to i64*
  store atomic i64 0, i64* %86 seq_cst, align 8
  %87 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %84, align 8
  %88 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %87, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %88 seq_cst, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal9SemiSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %66, align 8
  %89 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 1
  %90 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 7
  store %"class.v8::internal::Page"* null, %"class.v8::internal::Page"** %90, align 8
  %91 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 6
  %92 = bitcast i64* %89 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %92, i8 0, i64 44, i1 false)
  tail call void @_ZN2v88internal13VirtualMemoryC1Ev(%"class.v8::internal::VirtualMemory"* %91) #13
  %93 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7
  %94 = bitcast %"class.std::__1::vector.63"* %93 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %94, i8 0, i64 24, i1 false) #13
  %95 = and i64 %3, -262144
  %96 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 4
  store i64 %95, i64* %96, align 8
  %97 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 2
  store i64 %95, i64* %97, align 8
  %98 = and i64 %4, -262144
  %99 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 3
  store i64 %98, i64* %99, align 8
  %100 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 4
  store i64 %95, i64* %100, align 8
  %101 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 2
  store i64 %95, i64* %101, align 8
  %102 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 3
  store i64 %98, i64* %102, align 8
  %103 = tail call zeroext i1 @_ZN2v88internal9SemiSpace6CommitEv(%"class.v8::internal::SemiSpace"* %34)
  br i1 %103, label %108, label %104

104:                                              ; preds = %5
  %105 = ptrtoint %"class.v8::internal::Heap"* %1 to i64
  %106 = add i64 %105, -41416
  %107 = inttoptr i64 %106 to %"class.v8::internal::Isolate"*
  tail call void @_ZN2v88internal2V823FatalProcessOutOfMemoryEPNS0_7IsolateEPKcb(%"class.v8::internal::Isolate"* %107, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.1, i64 0, i64 0), i1 zeroext false) #14
  unreachable

108:                                              ; preds = %5
  tail call void @_ZN2v88internal8NewSpace25ResetLinearAllocationAreaEv(%"class.v8::internal::NewSpace"* %0)
  ret void
}

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #7

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

declare void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"*) unnamed_addr #2

declare void @_ZN2v88internal13VirtualMemoryC1Ev(%"class.v8::internal::VirtualMemory"*) unnamed_addr #2

; Function Attrs: noreturn
declare void @_ZN2v88internal2V823FatalProcessOutOfMemoryEPNS0_7IsolateEPKcb(%"class.v8::internal::Isolate"*, i8*, i1 zeroext) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace25ResetLinearAllocationAreaEv(%"class.v8::internal::NewSpace"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 0
  %3 = bitcast %"class.v8::internal::MemoryChunk"** %2 to i64*
  %4 = load i64, i64* %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %6 = bitcast %"class.v8::internal::Page"** %5 to i64*
  store i64 %4, i64* %6, align 8
  %7 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 1
  store i64 262144, i64* %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal19SpaceWithLinearArea26AdvanceAllocationObserversEv(%"class.v8::internal::SpaceWithLinearArea"* %8) #13
  %9 = bitcast %"class.v8::internal::Page"** %5 to %"class.v8::internal::BasicMemoryChunk"**
  %10 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %9, align 8
  %11 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %10, i64 0, i32 3
  %12 = load i64, i64* %11, align 8
  %13 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %14 = load i64, i64* %13, align 8
  %15 = icmp eq i64 %14, 0
  br i1 %15, label %33, label %16

16:                                               ; preds = %1
  %17 = add i64 %14, -1
  %18 = and i64 %17, -262144
  %19 = inttoptr i64 %18 to %"class.v8::internal::BasicMemoryChunk"*
  %20 = sub i64 %14, %18
  %21 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %19, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %22 = load atomic i64, i64* %21 monotonic, align 8
  %23 = icmp sgt i64 %20, %22
  br i1 %23, label %24, label %33

24:                                               ; preds = %16, %28
  %25 = phi i64 [ %29, %28 ], [ %22, %16 ]
  %26 = cmpxchg weak i64* %21, i64 %25, i64 %20 acq_rel monotonic
  %27 = extractvalue { i64, i1 } %26, 1
  br i1 %27, label %31, label %28

28:                                               ; preds = %24
  %29 = extractvalue { i64, i1 } %26, 0
  %30 = icmp sgt i64 %20, %29
  br i1 %30, label %24, label %31

31:                                               ; preds = %28, %24
  %32 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %9, align 8
  br label %33

33:                                               ; preds = %31, %1, %16
  %34 = phi %"class.v8::internal::BasicMemoryChunk"* [ %32, %31 ], [ %10, %1 ], [ %10, %16 ]
  %35 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %34, i64 0, i32 4
  %36 = load i64, i64* %35, align 8
  %37 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 0
  store i64 %12, i64* %37, align 8
  store i64 %12, i64* %13, align 8
  %38 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 2
  store i64 %36, i64* %38, align 8
  %39 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %40 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %39, align 8
  %41 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %40, i64 0, i32 129
  tail call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %41) #13
  %42 = load i64, i64* %38, align 8
  %43 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %42, i64* %43 monotonic, align 8
  %44 = load i64, i64* %13, align 8
  %45 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %44, i64* %45 release, align 8
  tail call void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"* %41) #13
  %46 = bitcast %"class.v8::internal::NewSpace"* %0 to void (%"class.v8::internal::NewSpace"*, i64)***
  %47 = load void (%"class.v8::internal::NewSpace"*, i64)**, void (%"class.v8::internal::NewSpace"*, i64)*** %46, align 8
  %48 = getelementptr inbounds void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %47, i64 17
  %49 = load void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %48, align 8
  tail call void %49(%"class.v8::internal::NewSpace"* %0, i64 0) #13
  %50 = bitcast %"class.v8::internal::MemoryChunk"** %2 to %"class.v8::internal::Page"**
  %51 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %50, align 8
  %52 = icmp eq %"class.v8::internal::Page"* %51, null
  br i1 %52, label %53, label %54

53:                                               ; preds = %54, %33
  ret void

54:                                               ; preds = %33, %54
  %55 = phi %"class.v8::internal::Page"* [ %67, %54 ], [ %51, %33 ]
  %56 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %55, i64 0, i32 0
  %57 = ptrtoint %"class.v8::internal::Page"* %55 to i64
  %58 = add i64 %57, 272
  %59 = inttoptr i64 %58 to %"class.v8::internal::ConcurrentBitmap"*
  %60 = getelementptr inbounds %"class.v8::internal::ConcurrentBitmap", %"class.v8::internal::ConcurrentBitmap"* %59, i64 0, i32 0
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %60, i8 0, i64 8196, i1 false) #13
  %61 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %55, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %61 monotonic, align 8
  %62 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %39, align 8
  %63 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %62, i64 0, i32 87, i32 0, i32 0, i32 0
  %64 = load %"class.v8::internal::ConcurrentMarking"*, %"class.v8::internal::ConcurrentMarking"** %63, align 8
  tail call void @_ZN2v88internal17ConcurrentMarking20ClearMemoryChunkDataEPNS0_11MemoryChunkE(%"class.v8::internal::ConcurrentMarking"* %64, %"class.v8::internal::MemoryChunk"* %56) #13
  %65 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %55, i64 0, i32 0, i32 12, i32 0
  %66 = bitcast %"class.v8::internal::MemoryChunk"** %65 to %"class.v8::internal::Page"**
  %67 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %66, align 8
  %68 = icmp eq %"class.v8::internal::Page"* %67, null
  br i1 %68, label %53, label %54
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace8TearDownEv(%"class.v8::internal::NewSpace"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 0
  %3 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 0
  %4 = bitcast i64* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %4, i8 0, i64 24, i1 false)
  %5 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %3, align 8
  %6 = icmp eq %"class.v8::internal::MemoryChunk"* %5, null
  %7 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 1
  %8 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %7, align 8
  %9 = icmp eq %"class.v8::internal::MemoryChunk"* %8, null
  %10 = and i1 %6, %9
  br i1 %10, label %60, label %11

11:                                               ; preds = %1
  %12 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2
  %13 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %12, i64 0, i32 0
  %14 = bitcast %"class.v8::internal::MemoryChunk"** %7 to i64*
  %15 = bitcast %"class.v8::internal::heap::List"* %12 to i64*
  %16 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 1
  br label %17

17:                                               ; preds = %39, %11
  %18 = phi %"class.v8::internal::MemoryChunk"* [ %46, %39 ], [ %8, %11 ]
  %19 = phi %"class.v8::internal::MemoryChunk"* [ %44, %39 ], [ %5, %11 ]
  %20 = icmp eq %"class.v8::internal::MemoryChunk"* %18, %19
  br i1 %20, label %21, label %25

21:                                               ; preds = %17
  %22 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %18, i64 0, i32 12, i32 1
  %23 = bitcast %"class.v8::internal::MemoryChunk"** %22 to i64*
  %24 = load i64, i64* %23, align 8
  store i64 %24, i64* %14, align 8
  br label %25

25:                                               ; preds = %21, %17
  %26 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %19, i64 0, i32 12, i32 0
  %27 = bitcast %"class.v8::internal::MemoryChunk"** %26 to i64*
  %28 = load i64, i64* %27, align 8
  store i64 %28, i64* %15, align 8
  %29 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %26, align 8
  %30 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %19, i64 0, i32 12, i32 1
  %31 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %30, align 8
  %32 = icmp eq %"class.v8::internal::MemoryChunk"* %29, null
  br i1 %32, label %35, label %33

33:                                               ; preds = %25
  %34 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %29, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %31, %"class.v8::internal::MemoryChunk"** %34, align 8
  br label %35

35:                                               ; preds = %33, %25
  %36 = icmp eq %"class.v8::internal::MemoryChunk"* %31, null
  br i1 %36, label %39, label %37

37:                                               ; preds = %35
  %38 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %31, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %29, %"class.v8::internal::MemoryChunk"** %38, align 8
  br label %39

39:                                               ; preds = %37, %35
  %40 = bitcast %"class.v8::internal::MemoryChunk"** %26 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %40, i8 0, i64 16, i1 false) #13
  %41 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %16, align 8
  %42 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %41, i64 0, i32 85, i32 0, i32 0, i32 0
  %43 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %42, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %43, %"class.v8::internal::MemoryChunk"* %19) #13
  %44 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %13, align 8
  %45 = icmp eq %"class.v8::internal::MemoryChunk"* %44, null
  %46 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %7, align 8
  %47 = icmp eq %"class.v8::internal::MemoryChunk"* %46, null
  %48 = and i1 %45, %47
  br i1 %48, label %49, label %17

49:                                               ; preds = %39
  %50 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  store %"class.v8::internal::Page"* null, %"class.v8::internal::Page"** %50, align 8
  %51 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 1
  store i64 0, i64* %51, align 8
  %52 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 2
  %53 = load i64, i64* %52, align 8
  %54 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %55 = atomicrmw sub i64* %54, i64 %53 seq_cst
  %56 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %16, align 8
  %57 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %56, i64 0, i32 85, i32 0, i32 0, i32 0
  %58 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %57, align 8
  %59 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %58, i64 0, i32 9
  tail call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %59) #13
  br label %60

60:                                               ; preds = %1, %49
  %61 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 2
  %62 = bitcast i64* %61 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %62, i8 0, i64 16, i1 false) #13
  %63 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2, i32 0
  %64 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %63, align 8
  %65 = icmp eq %"class.v8::internal::MemoryChunk"* %64, null
  %66 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2, i32 1
  %67 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %66, align 8
  %68 = icmp eq %"class.v8::internal::MemoryChunk"* %67, null
  %69 = and i1 %65, %68
  br i1 %69, label %119, label %70

70:                                               ; preds = %60
  %71 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2
  %72 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %71, i64 0, i32 0
  %73 = bitcast %"class.v8::internal::MemoryChunk"** %66 to i64*
  %74 = bitcast %"class.v8::internal::heap::List"* %71 to i64*
  %75 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 1
  br label %76

76:                                               ; preds = %98, %70
  %77 = phi %"class.v8::internal::MemoryChunk"* [ %105, %98 ], [ %67, %70 ]
  %78 = phi %"class.v8::internal::MemoryChunk"* [ %103, %98 ], [ %64, %70 ]
  %79 = icmp eq %"class.v8::internal::MemoryChunk"* %77, %78
  br i1 %79, label %80, label %84

80:                                               ; preds = %76
  %81 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %77, i64 0, i32 12, i32 1
  %82 = bitcast %"class.v8::internal::MemoryChunk"** %81 to i64*
  %83 = load i64, i64* %82, align 8
  store i64 %83, i64* %73, align 8
  br label %84

84:                                               ; preds = %80, %76
  %85 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %78, i64 0, i32 12, i32 0
  %86 = bitcast %"class.v8::internal::MemoryChunk"** %85 to i64*
  %87 = load i64, i64* %86, align 8
  store i64 %87, i64* %74, align 8
  %88 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %85, align 8
  %89 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %78, i64 0, i32 12, i32 1
  %90 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %89, align 8
  %91 = icmp eq %"class.v8::internal::MemoryChunk"* %88, null
  br i1 %91, label %94, label %92

92:                                               ; preds = %84
  %93 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %88, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %90, %"class.v8::internal::MemoryChunk"** %93, align 8
  br label %94

94:                                               ; preds = %92, %84
  %95 = icmp eq %"class.v8::internal::MemoryChunk"* %90, null
  br i1 %95, label %98, label %96

96:                                               ; preds = %94
  %97 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %90, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %88, %"class.v8::internal::MemoryChunk"** %97, align 8
  br label %98

98:                                               ; preds = %96, %94
  %99 = bitcast %"class.v8::internal::MemoryChunk"** %85 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %99, i8 0, i64 16, i1 false) #13
  %100 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %75, align 8
  %101 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %100, i64 0, i32 85, i32 0, i32 0, i32 0
  %102 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %101, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %102, %"class.v8::internal::MemoryChunk"* %78) #13
  %103 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %72, align 8
  %104 = icmp eq %"class.v8::internal::MemoryChunk"* %103, null
  %105 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %66, align 8
  %106 = icmp eq %"class.v8::internal::MemoryChunk"* %105, null
  %107 = and i1 %104, %106
  br i1 %107, label %108, label %76

108:                                              ; preds = %98
  %109 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 7
  store %"class.v8::internal::Page"* null, %"class.v8::internal::Page"** %109, align 8
  %110 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 1
  store i64 0, i64* %110, align 8
  %111 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 2
  %112 = load i64, i64* %111, align 8
  %113 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %114 = atomicrmw sub i64* %113, i64 %112 seq_cst
  %115 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %75, align 8
  %116 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %115, i64 0, i32 85, i32 0, i32 0, i32 0
  %117 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %116, align 8
  %118 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %117, i64 0, i32 9
  tail call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %118) #13
  br label %119

119:                                              ; preds = %60, %108
  %120 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 2
  %121 = bitcast i64* %120 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %121, i8 0, i64 16, i1 false) #13
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace28ResetParkedAllocationBuffersEv(%"class.v8::internal::NewSpace"* nocapture) local_unnamed_addr #4 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7
  %3 = bitcast %"class.std::__1::vector.63"* %2 to i64*
  %4 = load i64, i64* %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 1
  %6 = bitcast %"struct.std::__1::pair.65"** %5 to i64*
  store i64 %4, i64* %6, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace4FlipEv(%"class.v8::internal::NewSpace"*) local_unnamed_addr #4 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5
  %3 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4
  tail call void @_ZN2v88internal9SemiSpace4SwapEPS1_S2_(%"class.v8::internal::SemiSpace"* %2, %"class.v8::internal::SemiSpace"* %3)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace4GrowEv(%"class.v8::internal::NewSpace"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 3
  %3 = load i64, i64* %2, align 8
  %4 = load i32, i32* @_ZN2v88internal29FLAG_semi_space_growth_factorE, align 4
  %5 = sext i32 %4 to i64
  %6 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 2
  %7 = load i64, i64* %6, align 8
  %8 = mul i64 %7, %5
  %9 = icmp ult i64 %8, %3
  %10 = select i1 %9, i64 %8, i64 %3
  %11 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4
  %12 = tail call zeroext i1 @_ZN2v88internal9SemiSpace6GrowToEm(%"class.v8::internal::SemiSpace"* %11, i64 %10)
  br i1 %12, label %13, label %82

13:                                               ; preds = %1
  %14 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5
  %15 = tail call zeroext i1 @_ZN2v88internal9SemiSpace6GrowToEm(%"class.v8::internal::SemiSpace"* %14, i64 %10)
  br i1 %15, label %82, label %16

16:                                               ; preds = %13
  %17 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 2
  %18 = load i64, i64* %17, align 8
  %19 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 0
  %20 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %19, align 8
  %21 = icmp eq %"class.v8::internal::MemoryChunk"* %20, null
  br i1 %21, label %22, label %26

22:                                               ; preds = %16
  %23 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 1
  %24 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %23, align 8
  %25 = icmp eq %"class.v8::internal::MemoryChunk"* %24, null
  br i1 %25, label %81, label %26

26:                                               ; preds = %22, %16
  %27 = load i64, i64* %6, align 8
  %28 = sub i64 %27, %18
  %29 = lshr i64 %28, 18
  %30 = trunc i64 %29 to i32
  %31 = icmp sgt i32 %30, 0
  br i1 %31, label %32, label %73

32:                                               ; preds = %26
  %33 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 1
  %34 = bitcast %"class.v8::internal::MemoryChunk"** %33 to %"class.v8::internal::Page"**
  %35 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2
  %36 = bitcast %"class.v8::internal::MemoryChunk"** %33 to i64*
  %37 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %35, i64 0, i32 0
  %38 = bitcast %"class.v8::internal::heap::List"* %35 to i64*
  %39 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 1
  br label %40

40:                                               ; preds = %71, %32
  %41 = phi %"class.v8::internal::MemoryChunk"* [ %20, %32 ], [ %72, %71 ]
  %42 = phi i32 [ %30, %32 ], [ %69, %71 ]
  %43 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %34, align 8
  %44 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %43, i64 0, i32 0
  %45 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %43, i64 0, i32 0, i32 12, i32 1
  %46 = bitcast %"class.v8::internal::MemoryChunk"** %45 to i64*
  %47 = load i64, i64* %46, align 8
  store i64 %47, i64* %36, align 8
  %48 = icmp eq %"class.v8::internal::MemoryChunk"* %41, %44
  br i1 %48, label %49, label %53

49:                                               ; preds = %40
  %50 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %43, i64 0, i32 0, i32 12, i32 0
  %51 = bitcast %"class.v8::internal::MemoryChunk"** %50 to i64*
  %52 = load i64, i64* %51, align 8
  store i64 %52, i64* %38, align 8
  br label %53

53:                                               ; preds = %49, %40
  %54 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %43, i64 0, i32 0, i32 12, i32 0
  %55 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %54, align 8
  %56 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %45, align 8
  %57 = icmp eq %"class.v8::internal::MemoryChunk"* %55, null
  br i1 %57, label %60, label %58

58:                                               ; preds = %53
  %59 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %55, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %56, %"class.v8::internal::MemoryChunk"** %59, align 8
  br label %60

60:                                               ; preds = %58, %53
  %61 = icmp eq %"class.v8::internal::MemoryChunk"* %56, null
  br i1 %61, label %64, label %62

62:                                               ; preds = %60
  %63 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %56, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %55, %"class.v8::internal::MemoryChunk"** %63, align 8
  br label %64

64:                                               ; preds = %62, %60
  %65 = bitcast %"class.v8::internal::MemoryChunk"** %54 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %65, i8 0, i64 16, i1 false) #13
  %66 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %39, align 8
  %67 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %66, i64 0, i32 85, i32 0, i32 0, i32 0
  %68 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %67, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %68, %"class.v8::internal::MemoryChunk"* %44) #13
  %69 = add nsw i32 %42, -1
  %70 = icmp sgt i32 %69, 0
  br i1 %70, label %71, label %73

71:                                               ; preds = %64
  %72 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %37, align 8
  br label %40

73:                                               ; preds = %64, %26
  %74 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %75 = atomicrmw sub i64* %74, i64 %28 seq_cst
  %76 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 1
  %77 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %76, align 8
  %78 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %77, i64 0, i32 85, i32 0, i32 0, i32 0
  %79 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %78, align 8
  %80 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %79, i64 0, i32 9
  tail call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %80) #13
  br label %81

81:                                               ; preds = %22, %73
  store i64 %18, i64* %6, align 8
  br label %82

82:                                               ; preds = %13, %81, %1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace6ShrinkEv(%"class.v8::internal::NewSpace"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 4
  %3 = load i64, i64* %2, align 8
  %4 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 1
  %5 = load i64, i64* %4, align 8
  %6 = add i64 %5, -262144
  %7 = lshr i64 %6, 18
  %8 = tail call i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() #13
  %9 = mul i64 %7, %8
  %10 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %11 = load i64, i64* %10, align 8
  %12 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %13 = bitcast %"class.v8::internal::Page"** %12 to %"class.v8::internal::BasicMemoryChunk"**
  %14 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %13, align 8
  %15 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %14, i64 0, i32 3
  %16 = load i64, i64* %15, align 8
  %17 = add i64 %9, %11
  %18 = sub i64 %17, %16
  %19 = shl i64 %18, 1
  %20 = icmp ult i64 %3, %19
  %21 = select i1 %20, i64 %19, i64 %3
  %22 = add i64 %21, 262143
  %23 = and i64 %22, -262144
  %24 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 2
  %25 = load i64, i64* %24, align 8
  %26 = icmp ugt i64 %25, %23
  br i1 %26, label %27, label %159

27:                                               ; preds = %1
  %28 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 0
  %29 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %28, align 8
  %30 = icmp eq %"class.v8::internal::MemoryChunk"* %29, null
  br i1 %30, label %31, label %35

31:                                               ; preds = %27
  %32 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 1
  %33 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %32, align 8
  %34 = icmp eq %"class.v8::internal::MemoryChunk"* %33, null
  br i1 %34, label %89, label %35

35:                                               ; preds = %31, %27
  %36 = sub i64 %25, %23
  %37 = lshr i64 %36, 18
  %38 = trunc i64 %37 to i32
  %39 = icmp sgt i32 %38, 0
  br i1 %39, label %40, label %81

40:                                               ; preds = %35
  %41 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 1
  %42 = bitcast %"class.v8::internal::MemoryChunk"** %41 to %"class.v8::internal::Page"**
  %43 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2
  %44 = bitcast %"class.v8::internal::MemoryChunk"** %41 to i64*
  %45 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %43, i64 0, i32 0
  %46 = bitcast %"class.v8::internal::heap::List"* %43 to i64*
  %47 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 1
  br label %48

48:                                               ; preds = %79, %40
  %49 = phi %"class.v8::internal::MemoryChunk"* [ %29, %40 ], [ %80, %79 ]
  %50 = phi i32 [ %38, %40 ], [ %77, %79 ]
  %51 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %42, align 8
  %52 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %51, i64 0, i32 0
  %53 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %51, i64 0, i32 0, i32 12, i32 1
  %54 = bitcast %"class.v8::internal::MemoryChunk"** %53 to i64*
  %55 = load i64, i64* %54, align 8
  store i64 %55, i64* %44, align 8
  %56 = icmp eq %"class.v8::internal::MemoryChunk"* %49, %52
  br i1 %56, label %57, label %61

57:                                               ; preds = %48
  %58 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %51, i64 0, i32 0, i32 12, i32 0
  %59 = bitcast %"class.v8::internal::MemoryChunk"** %58 to i64*
  %60 = load i64, i64* %59, align 8
  store i64 %60, i64* %46, align 8
  br label %61

61:                                               ; preds = %57, %48
  %62 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %51, i64 0, i32 0, i32 12, i32 0
  %63 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %62, align 8
  %64 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %53, align 8
  %65 = icmp eq %"class.v8::internal::MemoryChunk"* %63, null
  br i1 %65, label %68, label %66

66:                                               ; preds = %61
  %67 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %63, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %64, %"class.v8::internal::MemoryChunk"** %67, align 8
  br label %68

68:                                               ; preds = %66, %61
  %69 = icmp eq %"class.v8::internal::MemoryChunk"* %64, null
  br i1 %69, label %72, label %70

70:                                               ; preds = %68
  %71 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %64, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %63, %"class.v8::internal::MemoryChunk"** %71, align 8
  br label %72

72:                                               ; preds = %70, %68
  %73 = bitcast %"class.v8::internal::MemoryChunk"** %62 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %73, i8 0, i64 16, i1 false) #13
  %74 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %47, align 8
  %75 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %74, i64 0, i32 85, i32 0, i32 0, i32 0
  %76 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %75, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %76, %"class.v8::internal::MemoryChunk"* %52) #13
  %77 = add nsw i32 %50, -1
  %78 = icmp sgt i32 %77, 0
  br i1 %78, label %79, label %81

79:                                               ; preds = %72
  %80 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %45, align 8
  br label %48

81:                                               ; preds = %72, %35
  %82 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %83 = atomicrmw sub i64* %82, i64 %36 seq_cst
  %84 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 1
  %85 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %84, align 8
  %86 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %85, i64 0, i32 85, i32 0, i32 0, i32 0
  %87 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %86, align 8
  %88 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %87, i64 0, i32 9
  tail call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %88) #13
  br label %89

89:                                               ; preds = %31, %81
  store i64 %23, i64* %24, align 8
  %90 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2, i32 0
  %91 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %90, align 8
  %92 = icmp eq %"class.v8::internal::MemoryChunk"* %91, null
  %93 = ptrtoint %"class.v8::internal::MemoryChunk"* %91 to i64
  br i1 %92, label %94, label %98

94:                                               ; preds = %89
  %95 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2, i32 1
  %96 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %95, align 8
  %97 = icmp eq %"class.v8::internal::MemoryChunk"* %96, null
  br i1 %97, label %157, label %98

98:                                               ; preds = %94, %89
  %99 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 7
  %100 = bitcast %"class.v8::internal::Page"** %99 to i64*
  store i64 %93, i64* %100, align 8
  %101 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 1
  store i64 262144, i64* %101, align 8
  %102 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 2
  %103 = load i64, i64* %102, align 8
  %104 = sub i64 %103, %23
  %105 = lshr i64 %104, 18
  %106 = trunc i64 %105 to i32
  %107 = icmp sgt i32 %106, 0
  br i1 %107, label %108, label %149

108:                                              ; preds = %98
  %109 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2, i32 1
  %110 = bitcast %"class.v8::internal::MemoryChunk"** %109 to %"class.v8::internal::Page"**
  %111 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 2
  %112 = bitcast %"class.v8::internal::MemoryChunk"** %109 to i64*
  %113 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %111, i64 0, i32 0
  %114 = bitcast %"class.v8::internal::heap::List"* %111 to i64*
  %115 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 1
  br label %116

116:                                              ; preds = %147, %108
  %117 = phi %"class.v8::internal::MemoryChunk"* [ %91, %108 ], [ %148, %147 ]
  %118 = phi i32 [ %106, %108 ], [ %145, %147 ]
  %119 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %110, align 8
  %120 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %119, i64 0, i32 0
  %121 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %119, i64 0, i32 0, i32 12, i32 1
  %122 = bitcast %"class.v8::internal::MemoryChunk"** %121 to i64*
  %123 = load i64, i64* %122, align 8
  store i64 %123, i64* %112, align 8
  %124 = icmp eq %"class.v8::internal::MemoryChunk"* %117, %120
  br i1 %124, label %125, label %129

125:                                              ; preds = %116
  %126 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %119, i64 0, i32 0, i32 12, i32 0
  %127 = bitcast %"class.v8::internal::MemoryChunk"** %126 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %114, align 8
  br label %129

129:                                              ; preds = %125, %116
  %130 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %119, i64 0, i32 0, i32 12, i32 0
  %131 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %130, align 8
  %132 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %121, align 8
  %133 = icmp eq %"class.v8::internal::MemoryChunk"* %131, null
  br i1 %133, label %136, label %134

134:                                              ; preds = %129
  %135 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %131, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %132, %"class.v8::internal::MemoryChunk"** %135, align 8
  br label %136

136:                                              ; preds = %134, %129
  %137 = icmp eq %"class.v8::internal::MemoryChunk"* %132, null
  br i1 %137, label %140, label %138

138:                                              ; preds = %136
  %139 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %132, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %131, %"class.v8::internal::MemoryChunk"** %139, align 8
  br label %140

140:                                              ; preds = %138, %136
  %141 = bitcast %"class.v8::internal::MemoryChunk"** %130 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %141, i8 0, i64 16, i1 false) #13
  %142 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %115, align 8
  %143 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %142, i64 0, i32 85, i32 0, i32 0, i32 0
  %144 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %143, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE3EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %144, %"class.v8::internal::MemoryChunk"* %120) #13
  %145 = add nsw i32 %118, -1
  %146 = icmp sgt i32 %145, 0
  br i1 %146, label %147, label %149

147:                                              ; preds = %140
  %148 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %113, align 8
  br label %116

149:                                              ; preds = %140, %98
  %150 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %151 = atomicrmw sub i64* %150, i64 %104 seq_cst
  %152 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 1
  %153 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %152, align 8
  %154 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %153, i64 0, i32 85, i32 0, i32 0, i32 0
  %155 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %154, align 8
  %156 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %155, i64 0, i32 9
  tail call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %156) #13
  br label %157

157:                                              ; preds = %94, %149
  %158 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 2
  store i64 %23, i64* %158, align 8
  br label %159

159:                                              ; preds = %157, %1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal8NewSpace4SizeEv(%"class.v8::internal::NewSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 1
  %3 = load i64, i64* %2, align 8
  %4 = add i64 %3, -262144
  %5 = lshr i64 %4, 18
  %6 = tail call i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() #13
  %7 = mul i64 %5, %6
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %11 = bitcast %"class.v8::internal::Page"** %10 to %"class.v8::internal::BasicMemoryChunk"**
  %12 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %11, align 8
  %13 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %12, i64 0, i32 3
  %14 = load i64, i64* %13, align 8
  %15 = add i64 %7, %9
  %16 = sub i64 %15, %14
  ret i64 %16
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal8NewSpace9RebalanceEv(%"class.v8::internal::NewSpace"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4
  %3 = tail call zeroext i1 @_ZN2v88internal9SemiSpace21EnsureCurrentCapacityEv(%"class.v8::internal::SemiSpace"* %2)
  br i1 %3, label %4, label %7

4:                                                ; preds = %1
  %5 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5
  %6 = tail call zeroext i1 @_ZN2v88internal9SemiSpace21EnsureCurrentCapacityEv(%"class.v8::internal::SemiSpace"* %5)
  br label %7

7:                                                ; preds = %4, %1
  %8 = phi i1 [ false, %1 ], [ %6, %4 ]
  ret i1 %8
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace26UpdateLinearAllocationAreaEm(%"class.v8::internal::NewSpace"*, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal19SpaceWithLinearArea26AdvanceAllocationObserversEv(%"class.v8::internal::SpaceWithLinearArea"* %3) #13
  %4 = icmp eq i64 %1, 0
  br i1 %4, label %5, label %11

5:                                                ; preds = %2
  %6 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %7 = bitcast %"class.v8::internal::Page"** %6 to %"class.v8::internal::BasicMemoryChunk"**
  %8 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %7, align 8
  %9 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %8, i64 0, i32 3
  %10 = load i64, i64* %9, align 8
  br label %11

11:                                               ; preds = %2, %5
  %12 = phi i64 [ %10, %5 ], [ %1, %2 ]
  %13 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %14 = load i64, i64* %13, align 8
  %15 = icmp eq i64 %14, 0
  br i1 %15, label %31, label %16

16:                                               ; preds = %11
  %17 = add i64 %14, -1
  %18 = and i64 %17, -262144
  %19 = inttoptr i64 %18 to %"class.v8::internal::BasicMemoryChunk"*
  %20 = sub i64 %14, %18
  %21 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %19, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %22 = load atomic i64, i64* %21 monotonic, align 8
  %23 = icmp sgt i64 %20, %22
  br i1 %23, label %24, label %31

24:                                               ; preds = %16, %28
  %25 = phi i64 [ %29, %28 ], [ %22, %16 ]
  %26 = cmpxchg weak i64* %21, i64 %25, i64 %20 acq_rel monotonic
  %27 = extractvalue { i64, i1 } %26, 1
  br i1 %27, label %31, label %28

28:                                               ; preds = %24
  %29 = extractvalue { i64, i1 } %26, 0
  %30 = icmp sgt i64 %20, %29
  br i1 %30, label %24, label %31

31:                                               ; preds = %24, %28, %11, %16
  %32 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %33 = bitcast %"class.v8::internal::Page"** %32 to %"class.v8::internal::BasicMemoryChunk"**
  %34 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %33, align 8
  %35 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %34, i64 0, i32 4
  %36 = load i64, i64* %35, align 8
  %37 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 0
  store i64 %12, i64* %37, align 8
  store i64 %12, i64* %13, align 8
  %38 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 2
  store i64 %36, i64* %38, align 8
  %39 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %40 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %39, align 8
  %41 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %40, i64 0, i32 129
  tail call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %41) #13
  %42 = load i64, i64* %38, align 8
  %43 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %42, i64* %43 monotonic, align 8
  %44 = load i64, i64* %13, align 8
  %45 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %44, i64* %45 release, align 8
  tail call void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"* %41) #13
  %46 = bitcast %"class.v8::internal::NewSpace"* %0 to void (%"class.v8::internal::NewSpace"*, i64)***
  %47 = load void (%"class.v8::internal::NewSpace"*, i64)**, void (%"class.v8::internal::NewSpace"*, i64)*** %46, align 8
  %48 = getelementptr inbounds void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %47, i64 17
  %49 = load void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %48, align 8
  tail call void %49(%"class.v8::internal::NewSpace"* %0, i64 0) #13
  ret void
}

declare void @_ZN2v88internal19SpaceWithLinearArea26AdvanceAllocationObserversEv(%"class.v8::internal::SpaceWithLinearArea"*) local_unnamed_addr #2

declare void @_ZN2v88internal17ConcurrentMarking20ClearMemoryChunkDataEPNS0_11MemoryChunkE(%"class.v8::internal::ConcurrentMarking"*, %"class.v8::internal::MemoryChunk"*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace27UpdateInlineAllocationLimitEm(%"class.v8::internal::NewSpace"*, i64) unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  %4 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %5 = load i64, i64* %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %7 = bitcast %"class.v8::internal::Page"** %6 to %"class.v8::internal::BasicMemoryChunk"**
  %8 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %7, align 8
  %9 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %8, i64 0, i32 4
  %10 = load i64, i64* %9, align 8
  %11 = tail call i64 @_ZN2v88internal19SpaceWithLinearArea12ComputeLimitEmmm(%"class.v8::internal::SpaceWithLinearArea"* %3, i64 %5, i64 %10, i64 %1) #13
  %12 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 2
  store i64 %11, i64* %12, align 8
  ret void
}

declare i64 @_ZN2v88internal19SpaceWithLinearArea12ComputeLimitEmmm(%"class.v8::internal::SpaceWithLinearArea"*, i64, i64, i64) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal8NewSpace12AddFreshPageEv(%"class.v8::internal::NewSpace"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %3 = load i64, i64* %2, align 8
  %4 = add i64 %3, -4
  %5 = and i64 %4, -262144
  %6 = inttoptr i64 %5 to %"class.v8::internal::Page"*
  %7 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %6, i64 0, i32 0, i32 0, i32 4
  %8 = load i64, i64* %7, align 32
  %9 = sub i64 %8, %3
  %10 = trunc i64 %9 to i32
  %11 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %12 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %11, align 8
  %13 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %12, i64 %3, i32 %10, i32 1) #13
  %14 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %15 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %14, align 8
  %16 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %15, i64 0, i32 0, i32 12, i32 0
  %17 = bitcast %"class.v8::internal::MemoryChunk"** %16 to %"class.v8::internal::Page"**
  %18 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %17, align 8
  %19 = icmp eq %"class.v8::internal::Page"* %18, null
  br i1 %19, label %150, label %20

20:                                               ; preds = %1
  %21 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 1
  %22 = load i64, i64* %21, align 8
  %23 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 2
  %24 = load i64, i64* %23, align 8
  %25 = icmp eq i64 %22, %24
  br i1 %25, label %150, label %26

26:                                               ; preds = %20
  store %"class.v8::internal::Page"* %18, %"class.v8::internal::Page"** %14, align 8
  %27 = add i64 %22, 262144
  store i64 %27, i64* %21, align 8
  %28 = load i8, i8* @_ZN2v88internal30FLAG_allocation_buffer_parkingE, align 1, !range !2
  %29 = icmp eq i8 %28, 0
  br i1 %29, label %109, label %30

30:                                               ; preds = %26
  %31 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %11, align 8
  %32 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %31, i64 0, i32 42, i32 0, i32 0, i32 0, i32 0
  %33 = load atomic i32, i32* %32 monotonic, align 4
  %34 = icmp eq i32 %33, 0
  %35 = icmp sgt i32 %10, 4095
  %36 = and i1 %35, %34
  br i1 %36, label %37, label %109

37:                                               ; preds = %30
  %38 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7
  %39 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 1
  %40 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %39, align 8
  %41 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 2, i32 0, i32 0
  %42 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %41, align 8
  %43 = icmp ult %"struct.std::__1::pair.65"* %40, %42
  %44 = ptrtoint %"struct.std::__1::pair.65"* %42 to i64
  br i1 %43, label %45, label %51

45:                                               ; preds = %37
  %46 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %40, i64 0, i32 0
  store i32 %10, i32* %46, align 8
  %47 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %40, i64 0, i32 1
  store i64 %3, i64* %47, align 8
  %48 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %40, i64 1
  %49 = ptrtoint %"struct.std::__1::pair.65"* %48 to i64
  %50 = bitcast %"struct.std::__1::pair.65"** %39 to i64*
  store i64 %49, i64* %50, align 8
  br label %109

51:                                               ; preds = %37
  %52 = ptrtoint %"struct.std::__1::pair.65"* %40 to i64
  %53 = bitcast %"struct.std::__1::pair.65"** %39 to i64*
  %54 = bitcast %"class.std::__1::vector.63"* %38 to i64*
  %55 = load i64, i64* %54, align 8
  %56 = sub i64 %52, %55
  %57 = ashr exact i64 %56, 4
  %58 = add nsw i64 %57, 1
  %59 = icmp ugt i64 %58, 1152921504606846975
  br i1 %59, label %60, label %62

60:                                               ; preds = %51
  %61 = bitcast %"class.std::__1::vector.63"* %38 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %61) #14
  unreachable

62:                                               ; preds = %51
  %63 = bitcast %"struct.std::__1::pair.65"** %41 to i64*
  %64 = sub i64 %44, %55
  %65 = ashr exact i64 %64, 4
  %66 = icmp ult i64 %65, 576460752303423487
  br i1 %66, label %67, label %75

67:                                               ; preds = %62
  %68 = ashr exact i64 %64, 3
  %69 = icmp ult i64 %68, %58
  %70 = select i1 %69, i64 %58, i64 %68
  %71 = icmp eq i64 %70, 0
  br i1 %71, label %80, label %72

72:                                               ; preds = %67
  %73 = icmp ugt i64 %70, 1152921504606846975
  br i1 %73, label %74, label %75

74:                                               ; preds = %72
  tail call void @abort() #14
  unreachable

75:                                               ; preds = %72, %62
  %76 = phi i64 [ %70, %72 ], [ 1152921504606846975, %62 ]
  %77 = shl i64 %76, 4
  %78 = tail call i8* @_Znwm(i64 %77) #15
  %79 = bitcast i8* %78 to %"struct.std::__1::pair.65"*
  br label %80

80:                                               ; preds = %75, %67
  %81 = phi i64 [ %76, %75 ], [ 0, %67 ]
  %82 = phi %"struct.std::__1::pair.65"* [ %79, %75 ], [ null, %67 ]
  %83 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %82, i64 %57
  %84 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %82, i64 %81
  %85 = ptrtoint %"struct.std::__1::pair.65"* %84 to i64
  %86 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %83, i64 0, i32 0
  store i32 %10, i32* %86, align 8
  %87 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %82, i64 %57, i32 1
  store i64 %3, i64* %87, align 8
  %88 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %83, i64 1
  %89 = ptrtoint %"struct.std::__1::pair.65"* %88 to i64
  %90 = getelementptr inbounds %"class.std::__1::vector.63", %"class.std::__1::vector.63"* %38, i64 0, i32 0, i32 0
  %91 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %90, align 8
  %92 = load i64, i64* %53, align 8
  %93 = ptrtoint %"struct.std::__1::pair.65"* %91 to i64
  %94 = sub i64 %92, %93
  %95 = ashr exact i64 %94, 4
  %96 = sub nsw i64 0, %95
  %97 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %83, i64 %96
  %98 = ptrtoint %"struct.std::__1::pair.65"* %97 to i64
  %99 = icmp sgt i64 %94, 0
  br i1 %99, label %100, label %104

100:                                              ; preds = %80
  %101 = bitcast %"struct.std::__1::pair.65"* %97 to i8*
  %102 = bitcast %"struct.std::__1::pair.65"* %91 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %101, i8* align 8 %102, i64 %94, i1 false) #13
  %103 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %90, align 8
  br label %104

104:                                              ; preds = %100, %80
  %105 = phi %"struct.std::__1::pair.65"* [ %91, %80 ], [ %103, %100 ]
  store i64 %98, i64* %54, align 8
  store i64 %89, i64* %53, align 8
  store i64 %85, i64* %63, align 8
  %106 = icmp eq %"struct.std::__1::pair.65"* %105, null
  br i1 %106, label %109, label %107

107:                                              ; preds = %104
  %108 = bitcast %"struct.std::__1::pair.65"* %105 to i8*
  tail call void @_ZdlPv(i8* %108) #15
  br label %109

109:                                              ; preds = %107, %104, %45, %26, %30
  %110 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal19SpaceWithLinearArea26AdvanceAllocationObserversEv(%"class.v8::internal::SpaceWithLinearArea"* %110) #13
  %111 = bitcast %"class.v8::internal::Page"** %14 to %"class.v8::internal::BasicMemoryChunk"**
  %112 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %111, align 8
  %113 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %112, i64 0, i32 3
  %114 = load i64, i64* %113, align 8
  %115 = load i64, i64* %2, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %134, label %117

117:                                              ; preds = %109
  %118 = add i64 %115, -1
  %119 = and i64 %118, -262144
  %120 = inttoptr i64 %119 to %"class.v8::internal::BasicMemoryChunk"*
  %121 = sub i64 %115, %119
  %122 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %120, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %123 = load atomic i64, i64* %122 monotonic, align 8
  %124 = icmp sgt i64 %121, %123
  br i1 %124, label %125, label %134

125:                                              ; preds = %117, %129
  %126 = phi i64 [ %130, %129 ], [ %123, %117 ]
  %127 = cmpxchg weak i64* %122, i64 %126, i64 %121 acq_rel monotonic
  %128 = extractvalue { i64, i1 } %127, 1
  br i1 %128, label %132, label %129

129:                                              ; preds = %125
  %130 = extractvalue { i64, i1 } %127, 0
  %131 = icmp sgt i64 %121, %130
  br i1 %131, label %125, label %132

132:                                              ; preds = %129, %125
  %133 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %111, align 8
  br label %134

134:                                              ; preds = %132, %109, %117
  %135 = phi %"class.v8::internal::BasicMemoryChunk"* [ %133, %132 ], [ %112, %109 ], [ %112, %117 ]
  %136 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %135, i64 0, i32 4
  %137 = load i64, i64* %136, align 8
  %138 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 0
  store i64 %114, i64* %138, align 8
  store i64 %114, i64* %2, align 8
  %139 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 2
  store i64 %137, i64* %139, align 8
  %140 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %11, align 8
  %141 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %140, i64 0, i32 129
  tail call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %141) #13
  %142 = load i64, i64* %139, align 8
  %143 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %142, i64* %143 monotonic, align 8
  %144 = load i64, i64* %2, align 8
  %145 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %144, i64* %145 release, align 8
  tail call void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"* %141) #13
  %146 = bitcast %"class.v8::internal::NewSpace"* %0 to void (%"class.v8::internal::NewSpace"*, i64)***
  %147 = load void (%"class.v8::internal::NewSpace"*, i64)**, void (%"class.v8::internal::NewSpace"*, i64)*** %146, align 8
  %148 = getelementptr inbounds void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %147, i64 17
  %149 = load void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %148, align 8
  tail call void %149(%"class.v8::internal::NewSpace"* %0, i64 0) #13
  br label %150

150:                                              ; preds = %1, %20, %134
  %151 = phi i1 [ true, %134 ], [ false, %20 ], [ false, %1 ]
  ret i1 %151
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal8NewSpace24AddFreshPageSynchronizedEv(%"class.v8::internal::NewSpace"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %2) #13
  %3 = tail call zeroext i1 @_ZN2v88internal8NewSpace12AddFreshPageEv(%"class.v8::internal::NewSpace"* %0)
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %2) #13
  ret i1 %3
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal8NewSpace25AddParkedAllocationBufferEiNS0_19AllocationAlignmentE(%"class.v8::internal::NewSpace"*, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 0
  %5 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 1
  br label %7

7:                                                ; preds = %11, %3
  %8 = phi %"struct.std::__1::pair.65"* [ %5, %3 ], [ %19, %11 ]
  %9 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %6, align 8
  %10 = icmp eq %"struct.std::__1::pair.65"* %8, %9
  br i1 %10, label %175, label %11

11:                                               ; preds = %7
  %12 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %8, i64 0, i32 0
  %13 = load i32, i32* %12, align 8
  %14 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %8, i64 0, i32 1
  %15 = load i64, i64* %14, align 8
  %16 = tail call i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64 %15, i32 %2) #13
  %17 = add nsw i32 %16, %1
  %18 = icmp sgt i32 %17, %13
  %19 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %8, i64 1
  br i1 %18, label %7, label %20

20:                                               ; preds = %11
  %21 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %6, align 8
  %22 = icmp eq %"struct.std::__1::pair.65"* %19, %21
  br i1 %22, label %81, label %23

23:                                               ; preds = %20
  %24 = ptrtoint %"struct.std::__1::pair.65"* %19 to i64
  %25 = getelementptr %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %21, i64 -1, i32 0
  %26 = ptrtoint i32* %25 to i64
  %27 = sub i64 %26, %24
  %28 = lshr i64 %27, 4
  %29 = add nuw nsw i64 %28, 1
  %30 = and i64 %29, 3
  %31 = icmp eq i64 %30, 0
  br i1 %31, label %46, label %32

32:                                               ; preds = %23, %32
  %33 = phi %"struct.std::__1::pair.65"* [ %43, %32 ], [ %8, %23 ]
  %34 = phi %"struct.std::__1::pair.65"* [ %42, %32 ], [ %19, %23 ]
  %35 = phi i64 [ %44, %32 ], [ %30, %23 ]
  %36 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %34, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %33, i64 0, i32 0
  store i32 %37, i32* %38, align 8
  %39 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %34, i64 0, i32 1
  %40 = load i64, i64* %39, align 8
  %41 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %33, i64 0, i32 1
  store i64 %40, i64* %41, align 8
  %42 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %34, i64 1
  %43 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %33, i64 1
  %44 = add i64 %35, -1
  %45 = icmp eq i64 %44, 0
  br i1 %45, label %46, label %32, !llvm.loop !3

46:                                               ; preds = %32, %23
  %47 = phi %"struct.std::__1::pair.65"* [ undef, %23 ], [ %43, %32 ]
  %48 = phi %"struct.std::__1::pair.65"* [ %8, %23 ], [ %43, %32 ]
  %49 = phi %"struct.std::__1::pair.65"* [ %19, %23 ], [ %42, %32 ]
  %50 = icmp ult i64 %27, 48
  br i1 %50, label %81, label %51

51:                                               ; preds = %46, %51
  %52 = phi %"struct.std::__1::pair.65"* [ %79, %51 ], [ %48, %46 ]
  %53 = phi %"struct.std::__1::pair.65"* [ %78, %51 ], [ %49, %46 ]
  %54 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 0, i32 0
  %55 = load i32, i32* %54, align 4
  %56 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 0, i32 0
  store i32 %55, i32* %56, align 8
  %57 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 0, i32 1
  %58 = load i64, i64* %57, align 8
  %59 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 0, i32 1
  store i64 %58, i64* %59, align 8
  %60 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 1, i32 0
  %61 = load i32, i32* %60, align 4
  %62 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 1, i32 0
  store i32 %61, i32* %62, align 8
  %63 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 1, i32 1
  %64 = load i64, i64* %63, align 8
  %65 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 1, i32 1
  store i64 %64, i64* %65, align 8
  %66 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 2, i32 0
  %67 = load i32, i32* %66, align 4
  %68 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 2, i32 0
  store i32 %67, i32* %68, align 8
  %69 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 2, i32 1
  %70 = load i64, i64* %69, align 8
  %71 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 2, i32 1
  store i64 %70, i64* %71, align 8
  %72 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 3, i32 0
  %73 = load i32, i32* %72, align 4
  %74 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 3, i32 0
  store i32 %73, i32* %74, align 8
  %75 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 3, i32 1
  %76 = load i64, i64* %75, align 8
  %77 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 3, i32 1
  store i64 %76, i64* %77, align 8
  %78 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %53, i64 4
  %79 = getelementptr inbounds %"struct.std::__1::pair.65", %"struct.std::__1::pair.65"* %52, i64 4
  %80 = icmp eq %"struct.std::__1::pair.65"* %78, %21
  br i1 %80, label %81, label %51

81:                                               ; preds = %46, %51, %20
  %82 = phi %"struct.std::__1::pair.65"* [ %8, %20 ], [ %47, %46 ], [ %79, %51 ]
  store %"struct.std::__1::pair.65"* %82, %"struct.std::__1::pair.65"** %6, align 8
  %83 = and i64 %15, -262144
  %84 = inttoptr i64 %83 to %"class.v8::internal::Page"*
  %85 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2
  %86 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %84, i64 0, i32 0
  %87 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 1
  %88 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %87, align 8
  %89 = icmp eq %"class.v8::internal::MemoryChunk"* %88, %86
  br i1 %89, label %90, label %95

90:                                               ; preds = %81
  %91 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %84, i64 0, i32 0, i32 12, i32 1
  %92 = bitcast %"class.v8::internal::MemoryChunk"** %91 to i64*
  %93 = load i64, i64* %92, align 8
  %94 = bitcast %"class.v8::internal::MemoryChunk"** %87 to i64*
  store i64 %93, i64* %94, align 8
  br label %95

95:                                               ; preds = %90, %81
  %96 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %85, i64 0, i32 0
  %97 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %96, align 8
  %98 = icmp eq %"class.v8::internal::MemoryChunk"* %97, %86
  br i1 %98, label %99, label %104

99:                                               ; preds = %95
  %100 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %84, i64 0, i32 0, i32 12, i32 0
  %101 = bitcast %"class.v8::internal::MemoryChunk"** %100 to i64*
  %102 = load i64, i64* %101, align 8
  %103 = bitcast %"class.v8::internal::heap::List"* %85 to i64*
  store i64 %102, i64* %103, align 8
  br label %104

104:                                              ; preds = %99, %95
  %105 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %84, i64 0, i32 0, i32 12, i32 0
  %106 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %105, align 8
  %107 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %84, i64 0, i32 0, i32 12, i32 1
  %108 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %107, align 8
  %109 = icmp eq %"class.v8::internal::MemoryChunk"* %106, null
  br i1 %109, label %112, label %110

110:                                              ; preds = %104
  %111 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %106, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %108, %"class.v8::internal::MemoryChunk"** %111, align 8
  br label %112

112:                                              ; preds = %110, %104
  %113 = icmp eq %"class.v8::internal::MemoryChunk"* %108, null
  br i1 %113, label %116, label %114

114:                                              ; preds = %112
  %115 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %108, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %106, %"class.v8::internal::MemoryChunk"** %115, align 8
  br label %116

116:                                              ; preds = %114, %112
  %117 = bitcast %"class.v8::internal::MemoryChunk"** %105 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %117, i8 0, i64 16, i1 false) #13
  %118 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %87, align 8
  %119 = icmp eq %"class.v8::internal::MemoryChunk"* %118, null
  br i1 %119, label %126, label %120

120:                                              ; preds = %116
  %121 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %118, i64 0, i32 12, i32 0
  %122 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %121, align 8
  store %"class.v8::internal::MemoryChunk"* %122, %"class.v8::internal::MemoryChunk"** %105, align 8
  store %"class.v8::internal::MemoryChunk"* %118, %"class.v8::internal::MemoryChunk"** %107, align 8
  store %"class.v8::internal::MemoryChunk"* %86, %"class.v8::internal::MemoryChunk"** %121, align 8
  %123 = icmp eq %"class.v8::internal::MemoryChunk"* %122, null
  %124 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %122, i64 0, i32 12, i32 1
  %125 = select i1 %123, %"class.v8::internal::MemoryChunk"** %87, %"class.v8::internal::MemoryChunk"** %124
  br label %127

126:                                              ; preds = %116
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %117, i8 0, i64 16, i1 false) #13
  store %"class.v8::internal::MemoryChunk"* %86, %"class.v8::internal::MemoryChunk"** %96, align 8
  br label %127

127:                                              ; preds = %120, %126
  %128 = phi %"class.v8::internal::MemoryChunk"** [ %87, %126 ], [ %125, %120 ]
  store %"class.v8::internal::MemoryChunk"* %86, %"class.v8::internal::MemoryChunk"** %128, align 8
  %129 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  store %"class.v8::internal::Page"* %84, %"class.v8::internal::Page"** %129, align 8
  %130 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal19SpaceWithLinearArea26AdvanceAllocationObserversEv(%"class.v8::internal::SpaceWithLinearArea"* %130) #13
  %131 = icmp eq i64 %15, 0
  br i1 %131, label %132, label %137

132:                                              ; preds = %127
  %133 = bitcast %"class.v8::internal::Page"** %129 to %"class.v8::internal::BasicMemoryChunk"**
  %134 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %133, align 8
  %135 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %134, i64 0, i32 3
  %136 = load i64, i64* %135, align 8
  br label %137

137:                                              ; preds = %132, %127
  %138 = phi i64 [ %136, %132 ], [ %15, %127 ]
  %139 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %140 = load i64, i64* %139, align 8
  %141 = icmp eq i64 %140, 0
  br i1 %141, label %157, label %142

142:                                              ; preds = %137
  %143 = add i64 %140, -1
  %144 = and i64 %143, -262144
  %145 = inttoptr i64 %144 to %"class.v8::internal::BasicMemoryChunk"*
  %146 = sub i64 %140, %144
  %147 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %145, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
  %148 = load atomic i64, i64* %147 monotonic, align 8
  %149 = icmp sgt i64 %146, %148
  br i1 %149, label %150, label %157

150:                                              ; preds = %142, %154
  %151 = phi i64 [ %155, %154 ], [ %148, %142 ]
  %152 = cmpxchg weak i64* %147, i64 %151, i64 %146 acq_rel monotonic
  %153 = extractvalue { i64, i1 } %152, 1
  br i1 %153, label %157, label %154

154:                                              ; preds = %150
  %155 = extractvalue { i64, i1 } %152, 0
  %156 = icmp sgt i64 %146, %155
  br i1 %156, label %150, label %157

157:                                              ; preds = %154, %150, %142, %137
  %158 = bitcast %"class.v8::internal::Page"** %129 to %"class.v8::internal::BasicMemoryChunk"**
  %159 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %158, align 8
  %160 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %159, i64 0, i32 4
  %161 = load i64, i64* %160, align 8
  %162 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 0
  store i64 %138, i64* %162, align 8
  store i64 %138, i64* %139, align 8
  %163 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 2
  store i64 %161, i64* %163, align 8
  %164 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %165 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %164, align 8
  %166 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %165, i64 0, i32 129
  tail call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %166) #13
  %167 = load i64, i64* %163, align 8
  %168 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %167, i64* %168 monotonic, align 8
  %169 = load i64, i64* %139, align 8
  %170 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %169, i64* %170 release, align 8
  tail call void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"* %166) #13
  %171 = bitcast %"class.v8::internal::NewSpace"* %0 to void (%"class.v8::internal::NewSpace"*, i64)***
  %172 = load void (%"class.v8::internal::NewSpace"*, i64)**, void (%"class.v8::internal::NewSpace"*, i64)*** %171, align 8
  %173 = getelementptr inbounds void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %172, i64 17
  %174 = load void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %173, align 8
  tail call void %174(%"class.v8::internal::NewSpace"* %0, i64 0) #13
  br label %175

175:                                              ; preds = %7, %157
  %176 = phi i1 [ true, %157 ], [ false, %7 ]
  ret i1 %176
}

declare i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64, i32) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal8NewSpace16EnsureAllocationEiNS0_19AllocationAlignmentE(%"class.v8::internal::NewSpace"*, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal19SpaceWithLinearArea26AdvanceAllocationObserversEv(%"class.v8::internal::SpaceWithLinearArea"* %4) #13
  %5 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %8 = bitcast %"class.v8::internal::Page"** %7 to %"class.v8::internal::BasicMemoryChunk"**
  %9 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %9, i64 0, i32 4
  %11 = load i64, i64* %10, align 8
  %12 = tail call i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64 %6, i32 %2) #13
  %13 = add nsw i32 %12, %1
  %14 = sext i32 %13 to i64
  %15 = add i64 %6, %14
  %16 = icmp ugt i64 %15, %11
  br i1 %16, label %22, label %17

17:                                               ; preds = %3
  %18 = bitcast %"class.v8::internal::NewSpace"* %0 to void (%"class.v8::internal::NewSpace"*, i64)***
  %19 = load void (%"class.v8::internal::NewSpace"*, i64)**, void (%"class.v8::internal::NewSpace"*, i64)*** %18, align 8
  %20 = getelementptr inbounds void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %19, i64 17
  %21 = load void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %20, align 8
  tail call void %21(%"class.v8::internal::NewSpace"* %0, i64 %14) #13
  br label %38

22:                                               ; preds = %3
  %23 = tail call zeroext i1 @_ZN2v88internal8NewSpace12AddFreshPageEv(%"class.v8::internal::NewSpace"* %0)
  br i1 %23, label %29, label %24

24:                                               ; preds = %22
  %25 = load i8, i8* @_ZN2v88internal30FLAG_allocation_buffer_parkingE, align 1, !range !2
  %26 = icmp eq i8 %25, 0
  br i1 %26, label %38, label %27

27:                                               ; preds = %24
  %28 = tail call zeroext i1 @_ZN2v88internal8NewSpace25AddParkedAllocationBufferEiNS0_19AllocationAlignmentE(%"class.v8::internal::NewSpace"* %0, i32 %1, i32 %2)
  br i1 %28, label %29, label %38

29:                                               ; preds = %27, %22
  %30 = load i64, i64* %5, align 8
  %31 = tail call i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64 %30, i32 %2) #13
  %32 = add nsw i32 %31, %1
  %33 = sext i32 %32 to i64
  %34 = bitcast %"class.v8::internal::NewSpace"* %0 to void (%"class.v8::internal::NewSpace"*, i64)***
  %35 = load void (%"class.v8::internal::NewSpace"*, i64)**, void (%"class.v8::internal::NewSpace"*, i64)*** %34, align 8
  %36 = getelementptr inbounds void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %35, i64 17
  %37 = load void (%"class.v8::internal::NewSpace"*, i64)*, void (%"class.v8::internal::NewSpace"*, i64)** %36, align 8
  tail call void %37(%"class.v8::internal::NewSpace"* %0, i64 %33) #13
  br label %38

38:                                               ; preds = %27, %24, %29, %17
  %39 = phi i1 [ true, %17 ], [ true, %29 ], [ false, %24 ], [ false, %27 ]
  ret i1 %39
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal8NewSpace18MaybeFreeUnusedLabENS0_20LinearAllocationAreaE(%"class.v8::internal::NewSpace"* nocapture, %"class.v8::internal::LinearAllocationArea"* nocapture readonly byval(%"class.v8::internal::LinearAllocationArea") align 8) local_unnamed_addr #4 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::LinearAllocationArea", %"class.v8::internal::LinearAllocationArea"* %1, i64 0, i32 2
  %4 = load i64, i64* %3, align 8
  %5 = icmp eq i64 %4, 0
  br i1 %5, label %15, label %6

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %8 = load i64, i64* %7, align 8
  %9 = icmp eq i64 %4, %8
  br i1 %9, label %10, label %15

10:                                               ; preds = %6
  %11 = getelementptr inbounds %"class.v8::internal::LinearAllocationArea", %"class.v8::internal::LinearAllocationArea"* %1, i64 0, i32 1
  %12 = load i64, i64* %11, align 8
  store i64 %12, i64* %7, align 8
  %13 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 0
  store i64 %12, i64* %13, align 8
  %14 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %12, i64* %14 release, align 8
  br label %15

15:                                               ; preds = %2, %10, %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::ObjectIterator"* @_ZN2v88internal8NewSpace17GetObjectIteratorEPNS0_4HeapE(%"class.v8::internal::NewSpace"* nocapture readonly, %"class.v8::internal::Heap"* nocapture readnone) unnamed_addr #0 align 2 {
  %3 = tail call i8* @_ZN2v88internal8MallocednwEm(i64 24) #13
  %4 = bitcast i8* %3 to i32 (...)***
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2v88internal23SemiSpaceObjectIteratorE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %5 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 2, i32 0
  %6 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %6, i64 0, i32 0, i32 3
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i8, i8* %3, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %8, i64* %12, align 8
  %13 = getelementptr inbounds i8, i8* %3, i64 16
  %14 = bitcast i8* %13 to i64*
  store i64 %10, i64* %14, align 8
  %15 = bitcast i8* %3 to %"class.v8::internal::ObjectIterator"*
  ret %"class.v8::internal::ObjectIterator"* %15
}

declare i8* @_ZN2v88internal8MallocednwEm(i64) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal8NewSpace15AllocateRawSlowEiNS0_19AllocationAlignmentENS0_16AllocationOriginE(%"class.v8::internal::NewSpace"*, i32, i32, i32) local_unnamed_addr #0 align 2 {
  %5 = tail call zeroext i1 @_ZN2v88internal8NewSpace16EnsureAllocationEiNS0_19AllocationAlignmentE(%"class.v8::internal::NewSpace"* %0, i32 %1, i32 0) #13
  br i1 %5, label %6, label %27

6:                                                ; preds = %4
  %7 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 2
  %11 = load i64, i64* %10, align 8
  %12 = sext i32 %1 to i64
  %13 = add i64 %9, %12
  %14 = icmp ult i64 %11, %13
  br i1 %14, label %24, label %15

15:                                               ; preds = %6
  %16 = add i64 %9, 1
  store i64 %13, i64* %8, align 8
  %17 = load i8, i8* @_ZN2v88internal30FLAG_trace_allocations_originsE, align 1, !range !2
  %18 = icmp eq i8 %17, 0
  br i1 %18, label %20, label %19

19:                                               ; preds = %15
  tail call void @_ZN2v88internal19SpaceWithLinearArea23UpdateAllocationOriginsENS0_16AllocationOriginE(%"class.v8::internal::SpaceWithLinearArea"* %7, i32 %3) #13
  br label %20

20:                                               ; preds = %19, %15
  %21 = and i64 %16, 1
  %22 = icmp eq i64 %21, 0
  br i1 %22, label %23, label %24, !prof !5

23:                                               ; preds = %20
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.4, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.5, i64 0, i64 0)) #14
  unreachable

24:                                               ; preds = %20, %6
  %25 = phi i64 [ 14, %6 ], [ %16, %20 ]
  %26 = add i64 %25, -1
  tail call void @_ZN2v88internal19SpaceWithLinearArea25InvokeAllocationObserversEmmmm(%"class.v8::internal::SpaceWithLinearArea"* %7, i64 %26, i64 %12, i64 %12, i64 %12) #13
  br label %27

27:                                               ; preds = %4, %24
  %28 = phi i64 [ %25, %24 ], [ 14, %4 ]
  ret i64 %28
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal8NewSpace20AllocateRawUnalignedEiNS0_16AllocationOriginE(%"class.v8::internal::NewSpace"*, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = tail call zeroext i1 @_ZN2v88internal8NewSpace16EnsureAllocationEiNS0_19AllocationAlignmentE(%"class.v8::internal::NewSpace"* %0, i32 %1, i32 0)
  br i1 %4, label %5, label %26

5:                                                ; preds = %3
  %6 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  %7 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 2
  %10 = load i64, i64* %9, align 8
  %11 = sext i32 %1 to i64
  %12 = add i64 %8, %11
  %13 = icmp ult i64 %10, %12
  br i1 %13, label %23, label %14

14:                                               ; preds = %5
  %15 = add i64 %8, 1
  store i64 %12, i64* %7, align 8
  %16 = load i8, i8* @_ZN2v88internal30FLAG_trace_allocations_originsE, align 1, !range !2
  %17 = icmp eq i8 %16, 0
  br i1 %17, label %19, label %18

18:                                               ; preds = %14
  tail call void @_ZN2v88internal19SpaceWithLinearArea23UpdateAllocationOriginsENS0_16AllocationOriginE(%"class.v8::internal::SpaceWithLinearArea"* %6, i32 %2) #13
  br label %19

19:                                               ; preds = %18, %14
  %20 = and i64 %15, 1
  %21 = icmp eq i64 %20, 0
  br i1 %21, label %22, label %23, !prof !5

22:                                               ; preds = %19
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.4, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.5, i64 0, i64 0)) #14
  unreachable

23:                                               ; preds = %5, %19
  %24 = phi i64 [ 14, %5 ], [ %15, %19 ]
  %25 = add i64 %24, -1
  tail call void @_ZN2v88internal19SpaceWithLinearArea25InvokeAllocationObserversEmmmm(%"class.v8::internal::SpaceWithLinearArea"* %6, i64 %25, i64 %11, i64 %11, i64 %11) #13
  br label %26

26:                                               ; preds = %3, %23
  %27 = phi i64 [ %24, %23 ], [ 14, %3 ]
  ret i64 %27
}

declare void @_ZN2v88internal19SpaceWithLinearArea25InvokeAllocationObserversEmmmm(%"class.v8::internal::SpaceWithLinearArea"*, i64, i64, i64, i64) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal8NewSpace18AllocateRawAlignedEiNS0_19AllocationAlignmentENS0_16AllocationOriginE(%"class.v8::internal::NewSpace"*, i32, i32, i32) local_unnamed_addr #0 align 2 {
  %5 = tail call zeroext i1 @_ZN2v88internal8NewSpace16EnsureAllocationEiNS0_19AllocationAlignmentE(%"class.v8::internal::NewSpace"* %0, i32 %1, i32 %2)
  br i1 %5, label %6, label %42

6:                                                ; preds = %4
  %7 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = tail call i32 @_ZN2v88internal4Heap14GetFillToAlignEmNS0_19AllocationAlignmentE(i64 %9, i32 %2) #13
  %11 = add nsw i32 %10, %1
  %12 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 2
  %13 = load i64, i64* %12, align 8
  %14 = sub i64 %13, %9
  %15 = sext i32 %11 to i64
  %16 = icmp ult i64 %14, %15
  br i1 %16, label %38, label %17

17:                                               ; preds = %6
  %18 = add i64 %9, 1
  %19 = add i64 %9, %15
  store i64 %19, i64* %8, align 8
  %20 = icmp sgt i32 %10, 0
  br i1 %20, label %21, label %29

21:                                               ; preds = %17
  %22 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %23 = bitcast %"class.v8::internal::Heap"** %22 to i64*
  %24 = load i64, i64* %23, align 8
  %25 = add i64 %24, -41416
  %26 = inttoptr i64 %25 to %"class.v8::internal::Isolate"*
  %27 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %26, i64 0, i32 0, i32 7, i32 0, i64 0
  %28 = tail call i64 @_ZN2v88internal4Heap17PrecedeWithFillerENS0_13ReadOnlyRootsENS0_10HeapObjectEi(i64* %27, i64 %18, i32 %10) #13
  br label %29

29:                                               ; preds = %21, %17
  %30 = phi i64 [ %28, %21 ], [ %18, %17 ]
  %31 = load i8, i8* @_ZN2v88internal30FLAG_trace_allocations_originsE, align 1, !range !2
  %32 = icmp eq i8 %31, 0
  br i1 %32, label %34, label %33

33:                                               ; preds = %29
  tail call void @_ZN2v88internal19SpaceWithLinearArea23UpdateAllocationOriginsENS0_16AllocationOriginE(%"class.v8::internal::SpaceWithLinearArea"* %7, i32 %3) #13
  br label %34

34:                                               ; preds = %33, %29
  %35 = and i64 %30, 1
  %36 = icmp eq i64 %35, 0
  br i1 %36, label %37, label %38, !prof !5

37:                                               ; preds = %34
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.4, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.5, i64 0, i64 0)) #14
  unreachable

38:                                               ; preds = %6, %34
  %39 = phi i64 [ 14, %6 ], [ %30, %34 ]
  %40 = add i64 %39, -1
  %41 = sext i32 %1 to i64
  tail call void @_ZN2v88internal19SpaceWithLinearArea25InvokeAllocationObserversEmmmm(%"class.v8::internal::SpaceWithLinearArea"* %7, i64 %40, i64 %41, i64 %15, i64 %15) #13
  br label %42

42:                                               ; preds = %4, %38
  %43 = phi i64 [ %39, %38 ], [ 14, %4 ]
  ret i64 %43
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void @_ZN2v88internal8NewSpace9VerifyTopEv(%"class.v8::internal::NewSpace"* nocapture) local_unnamed_addr #8 align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9BaseSpace15CommittedMemoryEv(%"class.v8::internal::BaseSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::BaseSpace", %"class.v8::internal::BaseSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i64, i64* %2 seq_cst, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv(%"class.v8::internal::BaseSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::BaseSpace", %"class.v8::internal::BaseSpace"* %0, i64 0, i32 4
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9SemiSpace4SizeEv(%"class.v8::internal::SemiSpace"*) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal5SpaceD2Ev(%"class.v8::internal::Space"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 3
  %4 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %3, align 8
  %5 = icmp eq %"struct.std::__1::atomic"* %4, null
  br i1 %5, label %8, label %6

6:                                                ; preds = %1
  %7 = bitcast %"struct.std::__1::atomic"* %4 to i8*
  tail call void @_ZdaPv(i8* %7) #15
  br label %8

8:                                                ; preds = %6, %1
  store %"struct.std::__1::atomic"* null, %"struct.std::__1::atomic"** %3, align 8
  %9 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 4, i32 0, i32 0, i32 0
  %10 = load %"class.v8::internal::FreeList"*, %"class.v8::internal::FreeList"** %9, align 8
  store %"class.v8::internal::FreeList"* null, %"class.v8::internal::FreeList"** %9, align 8
  %11 = icmp eq %"class.v8::internal::FreeList"* %10, null
  br i1 %11, label %17, label %12

12:                                               ; preds = %8
  %13 = bitcast %"class.v8::internal::FreeList"* %10 to void (%"class.v8::internal::FreeList"*)***
  %14 = load void (%"class.v8::internal::FreeList"*)**, void (%"class.v8::internal::FreeList"*)*** %13, align 8
  %15 = getelementptr inbounds void (%"class.v8::internal::FreeList"*)*, void (%"class.v8::internal::FreeList"*)** %14, i64 1
  %16 = load void (%"class.v8::internal::FreeList"*)*, void (%"class.v8::internal::FreeList"*)** %15, align 8
  tail call void %16(%"class.v8::internal::FreeList"* nonnull %10) #13
  br label %17

17:                                               ; preds = %8, %12
  %18 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 1, i32 2, i32 0, i32 1, i32 0, i32 0, i32 0
  %19 = load %"struct.std::__1::__hash_node_base.40"*, %"struct.std::__1::__hash_node_base.40"** %18, align 8
  %20 = icmp eq %"struct.std::__1::__hash_node_base.40"* %19, null
  br i1 %20, label %27, label %21

21:                                               ; preds = %17, %21
  %22 = phi %"struct.std::__1::__hash_node_base.40"* [ %24, %21 ], [ %19, %17 ]
  %23 = getelementptr inbounds %"struct.std::__1::__hash_node_base.40", %"struct.std::__1::__hash_node_base.40"* %22, i64 0, i32 0
  %24 = load %"struct.std::__1::__hash_node_base.40"*, %"struct.std::__1::__hash_node_base.40"** %23, align 8
  %25 = bitcast %"struct.std::__1::__hash_node_base.40"* %22 to i8*
  tail call void @_ZdlPv(i8* %25) #15
  %26 = icmp eq %"struct.std::__1::__hash_node_base.40"* %24, null
  br i1 %26, label %27, label %21

27:                                               ; preds = %21, %17
  %28 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 1, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %29 = load %"struct.std::__1::__hash_node_base.40"**, %"struct.std::__1::__hash_node_base.40"*** %28, align 8
  store %"struct.std::__1::__hash_node_base.40"** null, %"struct.std::__1::__hash_node_base.40"*** %28, align 8
  %30 = icmp eq %"struct.std::__1::__hash_node_base.40"** %29, null
  br i1 %30, label %33, label %31

31:                                               ; preds = %27
  %32 = bitcast %"struct.std::__1::__hash_node_base.40"** %29 to i8*
  tail call void @_ZdlPv(i8* %32) #15
  br label %33

33:                                               ; preds = %31, %27
  %34 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 1, i32 1, i32 0, i32 0
  %35 = load %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %34, align 8
  %36 = icmp eq %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %35, null
  br i1 %36, label %42, label %37

37:                                               ; preds = %33
  %38 = ptrtoint %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %35 to i64
  %39 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 1, i32 1, i32 0, i32 1
  %40 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %39 to i64*
  store i64 %38, i64* %40, align 8
  %41 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %35 to i8*
  tail call void @_ZdlPv(i8* %41) #15
  br label %42

42:                                               ; preds = %37, %33
  %43 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %44 = load %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %43, align 8
  %45 = icmp eq %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %44, null
  br i1 %45, label %51, label %46

46:                                               ; preds = %42
  %47 = ptrtoint %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %44 to i64
  %48 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 1, i32 0, i32 0, i32 1
  %49 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %44 to i8*
  tail call void @_ZdlPv(i8* %50) #15
  br label %51

51:                                               ; preds = %42, %46
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal9SemiSpaceD0Ev(%"class.v8::internal::SemiSpace"*) unnamed_addr #9 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal5SpaceD2Ev(%"class.v8::internal::Space"* %2) #13
  %3 = bitcast %"class.v8::internal::SemiSpace"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %3) #13
  ret void
}

declare void @_ZN2v88internal5Space21AddAllocationObserverEPNS0_18AllocationObserverE(%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*) unnamed_addr #2

declare void @_ZN2v88internal5Space24RemoveAllocationObserverEPNS0_18AllocationObserverE(%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*) unnamed_addr #2

declare void @_ZN2v88internal5Space24PauseAllocationObserversEv(%"class.v8::internal::Space"*) unnamed_addr #2

declare void @_ZN2v88internal5Space25ResumeAllocationObserversEv(%"class.v8::internal::Space"*) unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal5Space29StartNextInlineAllocationStepEv(%"class.v8::internal::Space"*) unnamed_addr #0 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9SemiSpace13SizeOfObjectsEv(%"class.v8::internal::SemiSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = bitcast %"class.v8::internal::SemiSpace"* %0 to i64 (%"class.v8::internal::SemiSpace"*)***
  %3 = load i64 (%"class.v8::internal::SemiSpace"*)**, i64 (%"class.v8::internal::SemiSpace"*)*** %2, align 8
  %4 = getelementptr inbounds i64 (%"class.v8::internal::SemiSpace"*)*, i64 (%"class.v8::internal::SemiSpace"*)** %3, i64 3
  %5 = load i64 (%"class.v8::internal::SemiSpace"*)*, i64 (%"class.v8::internal::SemiSpace"*)** %4, align 8
  %6 = tail call i64 %5(%"class.v8::internal::SemiSpace"* %0) #13
  ret i64 %6
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9SemiSpace9AvailableEv(%"class.v8::internal::SemiSpace"*) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi(%"class.v8::internal::Space"*, i32) unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 0, i32 2
  %4 = load i32, i32* %3, align 8
  %5 = icmp eq i32 %4, 2
  %6 = select i1 %5, i32 -32, i32 -4
  %7 = and i32 %6, %1
  ret i32 %7
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE(%"class.v8::internal::Space"*, i32) unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 3
  %4 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %3, align 8
  %5 = zext i32 %1 to i64
  %6 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %4, i64 %5, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load atomic i64, i64* %6 seq_cst, align 8
  ret i64 %7
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal8NewSpace22MaximumCommittedMemoryEv(%"class.v8::internal::NewSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 4
  %3 = load i64, i64* %2, align 8
  %4 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 0, i32 4
  %5 = load i64, i64* %4, align 8
  %6 = add i64 %5, %3
  ret i64 %6
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal8NewSpaceD2Ev(%"class.v8::internal::NewSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [20 x i8*] }, { [20 x i8*] }* @_ZTVN2v88internal8NewSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  tail call void @_ZN2v88internal8NewSpace8TearDownEv(%"class.v8::internal::NewSpace"* %0)
  %3 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 0
  %4 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %3, align 8
  %5 = icmp eq %"struct.std::__1::pair.65"* %4, null
  br i1 %5, label %11, label %6

6:                                                ; preds = %1
  %7 = ptrtoint %"struct.std::__1::pair.65"* %4 to i64
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 1
  %9 = bitcast %"struct.std::__1::pair.65"** %8 to i64*
  store i64 %7, i64* %9, align 8
  %10 = bitcast %"struct.std::__1::pair.65"* %4 to i8*
  tail call void @_ZdlPv(i8* %10) #15
  br label %11

11:                                               ; preds = %1, %6
  %12 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 6
  tail call void @_ZN2v88internal13VirtualMemoryD1Ev(%"class.v8::internal::VirtualMemory"* %12) #13
  %13 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0
  tail call void @_ZN2v88internal5SpaceD2Ev(%"class.v8::internal::Space"* %13) #13
  %14 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0
  tail call void @_ZN2v88internal5SpaceD2Ev(%"class.v8::internal::Space"* %14) #13
  %15 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"* %15) #13
  %16 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0
  tail call void @_ZN2v88internal5SpaceD2Ev(%"class.v8::internal::Space"* %16) #13
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal8NewSpaceD0Ev(%"class.v8::internal::NewSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [20 x i8*] }, { [20 x i8*] }* @_ZTVN2v88internal8NewSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  tail call void @_ZN2v88internal8NewSpace8TearDownEv(%"class.v8::internal::NewSpace"* %0) #13
  %3 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 0
  %4 = load %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"** %3, align 8
  %5 = icmp eq %"struct.std::__1::pair.65"* %4, null
  br i1 %5, label %11, label %6

6:                                                ; preds = %1
  %7 = ptrtoint %"struct.std::__1::pair.65"* %4 to i64
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 7, i32 0, i32 1
  %9 = bitcast %"struct.std::__1::pair.65"** %8 to i64*
  store i64 %7, i64* %9, align 8
  %10 = bitcast %"struct.std::__1::pair.65"* %4 to i8*
  tail call void @_ZdlPv(i8* %10) #15
  br label %11

11:                                               ; preds = %1, %6
  %12 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 6
  tail call void @_ZN2v88internal13VirtualMemoryD1Ev(%"class.v8::internal::VirtualMemory"* %12) #13
  %13 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 5, i32 0
  tail call void @_ZN2v88internal5SpaceD2Ev(%"class.v8::internal::Space"* %13) #13
  %14 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0
  tail call void @_ZN2v88internal5SpaceD2Ev(%"class.v8::internal::Space"* %14) #13
  %15 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 1
  tail call void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"* %15) #13
  %16 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0
  tail call void @_ZN2v88internal5SpaceD2Ev(%"class.v8::internal::Space"* %16) #13
  %17 = bitcast %"class.v8::internal::NewSpace"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %17) #13
  ret void
}

declare void @_ZN2v88internal19SpaceWithLinearArea21AddAllocationObserverEPNS0_18AllocationObserverE(%"class.v8::internal::SpaceWithLinearArea"*, %"class.v8::internal::AllocationObserver"*) unnamed_addr #2

declare void @_ZN2v88internal19SpaceWithLinearArea24RemoveAllocationObserverEPNS0_18AllocationObserverE(%"class.v8::internal::SpaceWithLinearArea"*, %"class.v8::internal::AllocationObserver"*) unnamed_addr #2

declare void @_ZN2v88internal19SpaceWithLinearArea24PauseAllocationObserversEv(%"class.v8::internal::SpaceWithLinearArea"*) unnamed_addr #2

declare void @_ZN2v88internal19SpaceWithLinearArea25ResumeAllocationObserversEv(%"class.v8::internal::SpaceWithLinearArea"*) unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal8NewSpace13SizeOfObjectsEv(%"class.v8::internal::NewSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 1
  %3 = load i64, i64* %2, align 8
  %4 = add i64 %3, -262144
  %5 = lshr i64 %4, 18
  %6 = tail call i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() #13
  %7 = mul i64 %5, %6
  %8 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %11 = bitcast %"class.v8::internal::Page"** %10 to %"class.v8::internal::BasicMemoryChunk"**
  %12 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %11, align 8
  %13 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %12, i64 0, i32 3
  %14 = load i64, i64* %13, align 8
  %15 = add i64 %7, %9
  %16 = sub i64 %15, %14
  ret i64 %16
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal8NewSpace9AvailableEv(%"class.v8::internal::NewSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 2
  %3 = load i64, i64* %2, align 8
  %4 = lshr i64 %3, 18
  %5 = tail call i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() #13
  %6 = mul i64 %4, %5
  %7 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 1
  %8 = load i64, i64* %7, align 8
  %9 = add i64 %8, -262144
  %10 = lshr i64 %9, 18
  %11 = tail call i64 @_ZN2v88internal17MemoryChunkLayout27AllocatableMemoryInDataPageEv() #13
  %12 = mul i64 %10, %11
  %13 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 1, i32 1
  %14 = load i64, i64* %13, align 8
  %15 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 7
  %16 = bitcast %"class.v8::internal::Page"** %15 to %"class.v8::internal::BasicMemoryChunk"**
  %17 = load %"class.v8::internal::BasicMemoryChunk"*, %"class.v8::internal::BasicMemoryChunk"** %16, align 8
  %18 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %17, i64 0, i32 3
  %19 = load i64, i64* %18, align 8
  %20 = sub i64 %6, %14
  %21 = sub i64 %20, %12
  %22 = add i64 %21, %19
  ret i64 %22
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZNK2v88internal8NewSpace25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE(%"class.v8::internal::NewSpace"*, i32) unnamed_addr #0 comdat align 2 {
  %3 = icmp eq i32 %1, 0
  br i1 %3, label %4, label %8

4:                                                ; preds = %2
  %5 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %6 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %7 = tail call i64 @_ZN2v88internal4Heap21YoungArrayBufferBytesEv(%"class.v8::internal::Heap"* %6) #13
  br label %14

8:                                                ; preds = %2
  %9 = getelementptr inbounds %"class.v8::internal::NewSpace", %"class.v8::internal::NewSpace"* %0, i64 0, i32 4, i32 0, i32 3
  %10 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %9, align 8
  %11 = zext i32 %1 to i64
  %12 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %10, i64 %11, i32 0, i32 0, i32 0, i32 0, i32 0
  %13 = load atomic i64, i64* %12 seq_cst, align 8
  br label %14

14:                                               ; preds = %8, %4
  %15 = phi i64 [ %7, %4 ], [ %13, %8 ]
  ret i64 %15
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN2v88internal8NewSpace26SupportsAllocationObserverEv(%"class.v8::internal::NewSpace"*) unnamed_addr #0 comdat align 2 {
  ret i1 true
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal23SemiSpaceObjectIteratorD0Ev(%"class.v8::internal::SemiSpaceObjectIterator"*) unnamed_addr #9 comdat align 2 {
  %2 = bitcast %"class.v8::internal::SemiSpaceObjectIterator"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %2) #13
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal23SemiSpaceObjectIterator4NextEv(%"class.v8::internal::SemiSpaceObjectIterator"*) unnamed_addr #9 comdat align 2 {
  %2 = alloca %"class.v8::internal::HeapObject", align 8
  %3 = getelementptr inbounds %"class.v8::internal::SemiSpaceObjectIterator", %"class.v8::internal::SemiSpaceObjectIterator"* %0, i64 0, i32 1
  %4 = getelementptr inbounds %"class.v8::internal::SemiSpaceObjectIterator", %"class.v8::internal::SemiSpaceObjectIterator"* %0, i64 0, i32 2
  %5 = bitcast %"class.v8::internal::HeapObject"* %2 to i8*
  %6 = getelementptr inbounds %"class.v8::internal::HeapObject", %"class.v8::internal::HeapObject"* %2, i64 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %3, align 8
  br label %8

8:                                                ; preds = %25, %1
  %9 = phi i64 [ %36, %25 ], [ %7, %1 ]
  %10 = load i64, i64* %4, align 8
  %11 = icmp eq i64 %9, %10
  br i1 %11, label %49, label %12

12:                                               ; preds = %8
  %13 = and i64 %9, 262143
  %14 = icmp eq i64 %13, 0
  br i1 %14, label %15, label %25

15:                                               ; preds = %12
  %16 = add i64 %9, -4
  %17 = and i64 %16, -262144
  %18 = inttoptr i64 %17 to %"class.v8::internal::Page"*
  %19 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %18, i64 0, i32 0, i32 12, i32 0
  %20 = bitcast %"class.v8::internal::MemoryChunk"** %19 to %"class.v8::internal::Page"**
  %21 = load %"class.v8::internal::Page"*, %"class.v8::internal::Page"** %20, align 8
  %22 = getelementptr inbounds %"class.v8::internal::Page", %"class.v8::internal::Page"* %21, i64 0, i32 0, i32 0, i32 3
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %3, align 8
  %24 = icmp eq i64 %23, %10
  br i1 %24, label %49, label %25

25:                                               ; preds = %15, %12
  %26 = phi i64 [ %23, %15 ], [ %9, %12 ]
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %5) #13
  %27 = add i64 %26, 1
  store i64 %27, i64* %6, align 8
  %28 = and i64 %27, -4294967296
  %29 = inttoptr i64 %26 to i32*
  %30 = load atomic i32, i32* %29 monotonic, align 4
  %31 = zext i32 %30 to i64
  %32 = or i64 %28, %31
  %33 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %2, i64 %32) #13
  %34 = sext i32 %33 to i64
  %35 = load i64, i64* %3, align 8
  %36 = add i64 %35, %34
  store i64 %36, i64* %3, align 8
  %37 = load i64, i64* %6, align 8
  %38 = and i64 %37, -4294967296
  %39 = add i64 %37, -1
  %40 = inttoptr i64 %39 to i32*
  %41 = load atomic i32, i32* %40 monotonic, align 4
  %42 = zext i32 %41 to i64
  %43 = or i64 %38, %42
  %44 = add i64 %43, 7
  %45 = inttoptr i64 %44 to i16*
  %46 = load atomic i16, i16* %45 monotonic, align 2
  %47 = or i16 %46, 1
  %48 = icmp eq i16 %47, 169
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %5) #13
  br i1 %48, label %8, label %49

49:                                               ; preds = %25, %8, %15
  %50 = phi i64 [ 0, %15 ], [ 0, %8 ], [ %37, %25 ]
  ret i64 %50
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal14ObjectIteratorD2Ev(%"class.v8::internal::ObjectIterator"*) unnamed_addr #0 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal8FreeListD2Ev(%"class.v8::internal::FreeList"*) unnamed_addr #0 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal10NoFreeListD0Ev(%"class.v8::internal::NoFreeList"*) unnamed_addr #9 comdat align 2 {
  %2 = bitcast %"class.v8::internal::NoFreeList"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #15
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal10NoFreeList21GuaranteedAllocatableEm(%"class.v8::internal::NoFreeList"*, i64) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.2, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal10NoFreeList4FreeEmmNS0_8FreeModeE(%"class.v8::internal::NoFreeList"*, i64, i64, i32) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.3, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal10NoFreeList8AllocateEmPmNS0_16AllocationOriginE(%"class.v8::internal::NoFreeList"*, i64, i64*, i32) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.3, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden %"class.v8::internal::Page"* @_ZN2v88internal10NoFreeList14GetPageForSizeEm(%"class.v8::internal::NoFreeList"*, i64) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.3, i64 0, i64 0)) #14
  unreachable
}

declare void @_ZN2v88internal8FreeList5ResetEv(%"class.v8::internal::FreeList"*) unnamed_addr #2

declare zeroext i1 @_ZN2v88internal8FreeList11AddCategoryEPNS0_16FreeListCategoryE(%"class.v8::internal::FreeList"*, %"class.v8::internal::FreeListCategory"*) unnamed_addr #2

declare void @_ZN2v88internal8FreeList14RemoveCategoryEPNS0_16FreeListCategoryE(%"class.v8::internal::FreeList"*, %"class.v8::internal::FreeListCategory"*) unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN2v88internal10NoFreeList26SelectFreeListCategoryTypeEm(%"class.v8::internal::NoFreeList"*, i64) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.3, i64 0, i64 0)) #14
  unreachable
}

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #10

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znam(i64) local_unnamed_addr #7

declare void @_ZN2v88internal19SpaceWithLinearArea23UpdateAllocationOriginsENS0_16AllocationOriginE(%"class.v8::internal::SpaceWithLinearArea"*, i32) local_unnamed_addr #2

declare i64 @_ZN2v88internal4Heap17PrecedeWithFillerENS0_13ReadOnlyRootsENS0_10HeapObjectEi(i64*, i64, i32) local_unnamed_addr #2

; Function Attrs: nobuiltin nounwind
declare void @_ZdaPv(i8*) local_unnamed_addr #10

; Function Attrs: nounwind
declare void @_ZN2v88internal8MalloceddlEPv(i8*) local_unnamed_addr #11

; Function Attrs: nounwind
declare void @_ZN2v88internal13VirtualMemoryD1Ev(%"class.v8::internal::VirtualMemory"*) unnamed_addr #11

; Function Attrs: nounwind
declare void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"*) unnamed_addr #11

declare i64 @_ZN2v88internal4Heap21YoungArrayBufferBytesEv(%"class.v8::internal::Heap"*) local_unnamed_addr #2

declare void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"*) local_unnamed_addr #2

declare void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"*) local_unnamed_addr #2

declare void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"*) local_unnamed_addr #2

declare void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"*) local_unnamed_addr #2

; Function Attrs: noreturn
declare void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"*) local_unnamed_addr #6

; Function Attrs: noreturn nounwind
declare void @abort() local_unnamed_addr #12

declare i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"*, i64) local_unnamed_addr #2

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noreturn nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nobuiltin nofree "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { norecurse nounwind readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { noreturn nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #13 = { nounwind }
attributes #14 = { noreturn nounwind }
attributes #15 = { builtin nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i8 0, i8 2}
!3 = distinct !{!3, !4}
!4 = !{!"llvm.loop.unroll.disable"}
!5 = !{!"branch_weights", i32 1, i32 2000}
