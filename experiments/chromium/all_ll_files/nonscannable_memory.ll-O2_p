; ModuleID = '../../base/memory/nonscannable_memory.cc'
source_filename = "../../base/memory/nonscannable_memory.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.base::NoDestructor" = type { [24 x i8] }
%"class.base::internal::PCScan" = type <{ %"class.base::internal::PCScanScheduler", %"struct.std::__1::atomic.16", i8, [6 x i8] }>
%"class.base::internal::PCScanScheduler" = type { %"struct.base::internal::QuarantineData", %"class.base::internal::LimitBackend", %"class.base::internal::PCScanSchedulingBackend"* }
%"struct.base::internal::QuarantineData" = type { %"struct.std::__1::atomic.1", %"struct.std::__1::atomic.1", %"struct.std::__1::atomic.1", i64 }
%"struct.std::__1::atomic.1" = type { %"struct.std::__1::__atomic_base.2" }
%"struct.std::__1::__atomic_base.2" = type { %"struct.std::__1::__atomic_base.3" }
%"struct.std::__1::__atomic_base.3" = type { %"struct.std::__1::__cxx_atomic_impl.4" }
%"struct.std::__1::__cxx_atomic_impl.4" = type { %"struct.std::__1::__cxx_atomic_base_impl.5" }
%"struct.std::__1::__cxx_atomic_base_impl.5" = type { i64 }
%"class.base::internal::LimitBackend" = type { %"class.base::internal::PCScanSchedulingBackend" }
%"class.base::internal::PCScanSchedulingBackend" = type { i32 (...)**, %"class.base::internal::PCScanScheduler"* }
%"struct.std::__1::atomic.16" = type { %"struct.std::__1::__atomic_base.17" }
%"struct.std::__1::__atomic_base.17" = type { %"struct.std::__1::__cxx_atomic_impl.18" }
%"struct.std::__1::__cxx_atomic_impl.18" = type { %"struct.std::__1::__cxx_atomic_base_impl.19" }
%"struct.std::__1::__cxx_atomic_base_impl.19" = type { i8 }
%"class.base::internal::NonScannableAllocator" = type { %"class.std::__1::unique_ptr", %"struct.std::__1::atomic.7", [7 x i8] }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type <{ %"struct.std::__1::__compressed_pair_elem", %"struct.std::__1::__compressed_pair_elem.6", [7 x i8] }>
%"struct.std::__1::__compressed_pair_elem" = type { %"struct.base::internal::PartitionAllocator"* }
%"struct.base::internal::PartitionAllocator" = type { %"struct.base::PartitionRoot" }
%"struct.base::PartitionRoot" = type <{ i8, i8, i8, i8, i8, i8, i8, i8, %"class.base::internal::MaybeSpinLock", [4 x i8], [128 x %"struct.base::internal::PartitionBucket"], %"struct.base::internal::PartitionBucket", i8, [7 x i8], %"struct.std::__1::atomic.1", %"struct.std::__1::atomic.1", %"struct.std::__1::atomic.1", i8*, i8*, i8*, %"struct.base::internal::PartitionSuperPageExtentEntry"*, %"struct.base::internal::PartitionSuperPageExtentEntry"*, %"struct.base::internal::PartitionDirectMapExtent"*, [16 x %"struct.base::internal::SlotSpanMetadata"*], i16, [6 x i8], i64, %"struct.std::__1::atomic", [4 x i8] }>
%"class.base::internal::MaybeSpinLock" = type { %"class.base::internal::SpinningMutex" }
%"class.base::internal::SpinningMutex" = type { %"struct.std::__1::atomic" }
%"struct.base::internal::PartitionBucket" = type { %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::SlotSpanMetadata"*, i32, i32, i64 }
%"struct.base::internal::SlotSpanMetadata" = type <{ %"class.base::internal::PartitionFreelistEntry"*, %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::PartitionBucket"*, i16, i16, i8, i8 }>
%"class.base::internal::PartitionFreelistEntry" = type { %"struct.base::internal::EncodedPartitionFreelistEntry"*, i64 }
%"struct.base::internal::EncodedPartitionFreelistEntry" = type { [8 x i8], [8 x i8] }
%"struct.base::internal::PartitionSuperPageExtentEntry" = type { %"struct.base::PartitionRoot"*, i8*, i8*, %"struct.base::internal::PartitionSuperPageExtentEntry"* }
%"struct.base::internal::PartitionDirectMapExtent" = type opaque
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.0" }
%"struct.std::__1::__atomic_base.0" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"struct.std::__1::__compressed_pair_elem.6" = type { %"struct.base::internal::PCScanMetadataDeleter" }
%"struct.base::internal::PCScanMetadataDeleter" = type { i8 }
%"struct.std::__1::atomic.7" = type { %"struct.std::__1::__atomic_base.8" }
%"struct.std::__1::__atomic_base.8" = type { %"struct.std::__1::__cxx_atomic_impl.9" }
%"struct.std::__1::__cxx_atomic_impl.9" = type { %"struct.std::__1::__cxx_atomic_base_impl.10" }
%"struct.std::__1::__cxx_atomic_base_impl.10" = type { i8 }
%"class.base::internal::ThreadCache" = type { [89 x %"struct.base::internal::ThreadCache::Bucket"], i64, %"struct.std::__1::atomic.7", %"struct.base::ThreadCacheStats", %"struct.base::PartitionRoot"*, %"class.base::internal::ThreadCache"*, %"class.base::internal::ThreadCache"* }
%"struct.base::internal::ThreadCache::Bucket" = type <{ %"class.base::internal::PartitionFreelistEntry"*, i8, %"struct.std::__1::atomic.11", i16, [4 x i8] }>
%"struct.std::__1::atomic.11" = type { %"struct.std::__1::__atomic_base.12" }
%"struct.std::__1::__atomic_base.12" = type { %"struct.std::__1::__atomic_base.13" }
%"struct.std::__1::__atomic_base.13" = type { %"struct.std::__1::__cxx_atomic_impl.14" }
%"struct.std::__1::__cxx_atomic_impl.14" = type { %"struct.std::__1::__cxx_atomic_base_impl.15" }
%"struct.std::__1::__cxx_atomic_base_impl.15" = type { i8 }
%"struct.base::ThreadCacheStats" = type { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, [129 x i64], [129 x i64] }
%"struct.base::internal::DeferredUnmap" = type { i8*, i64 }
%"struct.base::internal::PartitionPage" = type { %union.anon, i8, i8 }
%union.anon = type <{ %"struct.base::internal::SubsequentPageMetadata", [22 x i8] }>
%"struct.base::internal::SubsequentPageMetadata" = type { i64 }
%"class.base::internal::ObjectBitmap" = type { %"struct.std::__1::array" }
%"struct.std::__1::array" = type { [2048 x i64] }

$_ZN4base8internal18MakePCScanMetadataINS0_18PartitionAllocatorILb1EEEJEEEPT_DpOT0_ = comdat any

$_ZNK4base8internal21PCScanMetadataDeleterclEPv = comdat any

@_ZZN4base8internal21NonScannableAllocator8InstanceEvE8instance = internal global %"class.base::NoDestructor" zeroinitializer, align 8
@_ZGVZN4base8internal21NonScannableAllocator8InstanceEvE8instance = internal global i64 0, align 8
@_ZZN4base8internal17BucketIndexLookup8GetIndexEmE6lookup = internal unnamed_addr constant { [128 x i64], [521 x i16] } { [128 x i64] [i64 16, i64 18, i64 20, i64 22, i64 24, i64 26, i64 28, i64 30, i64 32, i64 36, i64 40, i64 44, i64 48, i64 52, i64 56, i64 60, i64 64, i64 72, i64 80, i64 88, i64 96, i64 104, i64 112, i64 120, i64 128, i64 144, i64 160, i64 176, i64 192, i64 208, i64 224, i64 240, i64 256, i64 288, i64 320, i64 352, i64 384, i64 416, i64 448, i64 480, i64 512, i64 576, i64 640, i64 704, i64 768, i64 832, i64 896, i64 960, i64 1024, i64 1152, i64 1280, i64 1408, i64 1536, i64 1664, i64 1792, i64 1920, i64 2048, i64 2304, i64 2560, i64 2816, i64 3072, i64 3328, i64 3584, i64 3840, i64 4096, i64 4608, i64 5120, i64 5632, i64 6144, i64 6656, i64 7168, i64 7680, i64 8192, i64 9216, i64 10240, i64 11264, i64 12288, i64 13312, i64 14336, i64 15360, i64 16384, i64 18432, i64 20480, i64 22528, i64 24576, i64 26624, i64 28672, i64 30720, i64 32768, i64 36864, i64 40960, i64 45056, i64 49152, i64 53248, i64 57344, i64 61440, i64 65536, i64 73728, i64 81920, i64 90112, i64 98304, i64 106496, i64 114688, i64 122880, i64 131072, i64 147456, i64 163840, i64 180224, i64 196608, i64 212992, i64 229376, i64 245760, i64 262144, i64 294912, i64 327680, i64 360448, i64 393216, i64 425984, i64 458752, i64 491520, i64 524288, i64 589824, i64 655360, i64 720896, i64 786432, i64 851968, i64 917504, i64 983040], [521 x i16] [i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 12, i16 12, i16 12, i16 12, i16 16, i16 16, i16 16, i16 16, i16 18, i16 18, i16 20, i16 20, i16 22, i16 22, i16 24, i16 24, i16 25, i16 26, i16 27, i16 28, i16 29, i16 30, i16 31, i16 32, i16 33, i16 34, i16 35, i16 36, i16 37, i16 38, i16 39, i16 40, i16 41, i16 42, i16 43, i16 44, i16 45, i16 46, i16 47, i16 48, i16 49, i16 50, i16 51, i16 52, i16 53, i16 54, i16 55, i16 56, i16 57, i16 58, i16 59, i16 60, i16 61, i16 62, i16 63, i16 64, i16 65, i16 66, i16 67, i16 68, i16 69, i16 70, i16 71, i16 72, i16 73, i16 74, i16 75, i16 76, i16 77, i16 78, i16 79, i16 80, i16 81, i16 82, i16 83, i16 84, i16 85, i16 86, i16 87, i16 88, i16 89, i16 90, i16 91, i16 92, i16 93, i16 94, i16 95, i16 96, i16 97, i16 98, i16 99, i16 100, i16 101, i16 102, i16 103, i16 104, i16 105, i16 106, i16 107, i16 108, i16 109, i16 110, i16 111, i16 112, i16 113, i16 114, i16 115, i16 116, i16 117, i16 118, i16 119, i16 120, i16 121, i16 122, i16 123, i16 124, i16 125, i16 126, i16 127, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128, i16 128] }, align 8
@_ZN4base12_GLOBAL__N_116kOrderIndexShiftE = internal unnamed_addr constant [65 x i8] c"\00\00\00\00\00\01\02\03\04\05\06\07\08\09\0A\0B\0C\0D\0E\0F\10\11\12\13\14\15\16\17\18\19\1A\1B\1C\1D\1E\1F !\22#$%&'()*+,-./0123456789:;<", align 16
@_ZN4base12_GLOBAL__N_118kOrderSubIndexMaskE = internal unnamed_addr constant [65 x i64] [i64 0, i64 0, i64 0, i64 0, i64 0, i64 1, i64 3, i64 7, i64 15, i64 31, i64 63, i64 127, i64 255, i64 511, i64 1023, i64 2047, i64 4095, i64 8191, i64 16383, i64 32767, i64 65535, i64 131071, i64 262143, i64 524287, i64 1048575, i64 2097151, i64 4194303, i64 8388607, i64 16777215, i64 33554431, i64 67108863, i64 134217727, i64 268435455, i64 536870911, i64 1073741823, i64 2147483647, i64 4294967295, i64 8589934591, i64 17179869183, i64 34359738367, i64 68719476735, i64 137438953471, i64 274877906943, i64 549755813887, i64 1099511627775, i64 2199023255551, i64 4398046511103, i64 8796093022207, i64 17592186044415, i64 35184372088831, i64 70368744177663, i64 140737488355327, i64 281474976710655, i64 562949953421311, i64 1125899906842623, i64 2251799813685247, i64 4503599627370495, i64 9007199254740991, i64 18014398509481983, i64 36028797018963967, i64 72057594037927935, i64 144115188075855871, i64 288230376151711743, i64 576460752303423487, i64 1152921504606846975], align 16
@_ZN4base8internal6PCScan9instance_E = external global %"class.base::internal::PCScan", align 8
@_ZN4base8internal18g_thread_cache_keyE = external local_unnamed_addr global i32, align 4
@_ZN4base8internal11ThreadCache28largest_active_bucket_index_E = external local_unnamed_addr global i16, align 2
@.str.1 = private unnamed_addr constant [105 x i8] c"../../base/allocator/partition_allocator/partition_page.h(549) Check failed: slot_start != freelist_head\00", align 1

@_ZN4base8internal21NonScannableAllocatorC1Ev = hidden unnamed_addr alias void (%"class.base::internal::NonScannableAllocator"*), void (%"class.base::internal::NonScannableAllocator"*)* @_ZN4base8internal21NonScannableAllocatorC2Ev
@_ZN4base8internal21NonScannableAllocatorD1Ev = hidden unnamed_addr alias void (%"class.base::internal::NonScannableAllocator"*), void (%"class.base::internal::NonScannableAllocator"*)* @_ZN4base8internal21NonScannableAllocatorD2Ev

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @_ZN4base8internal21NonScannableAllocatorC2Ev(%"class.base::internal::NonScannableAllocator"* nocapture) unnamed_addr #0 align 2 {
  %2 = bitcast %"class.base::internal::NonScannableAllocator"* %0 to i64*
  store i64 0, i64* %2, align 8
  %3 = getelementptr inbounds %"class.base::internal::NonScannableAllocator", %"class.base::internal::NonScannableAllocator"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
  store i8 0, i8* %3, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN4base8internal21NonScannableAllocatorD2Ev(%"class.base::internal::NonScannableAllocator"*) unnamed_addr #1 align 2 {
  %2 = getelementptr inbounds %"class.base::internal::NonScannableAllocator", %"class.base::internal::NonScannableAllocator"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %3 = load %"struct.base::internal::PartitionAllocator"*, %"struct.base::internal::PartitionAllocator"** %2, align 8
  store %"struct.base::internal::PartitionAllocator"* null, %"struct.base::internal::PartitionAllocator"** %2, align 8
  %4 = icmp eq %"struct.base::internal::PartitionAllocator"* %3, null
  br i1 %4, label %9, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.base::internal::NonScannableAllocator", %"class.base::internal::NonScannableAllocator"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0
  %7 = bitcast i8* %6 to %"struct.base::internal::PCScanMetadataDeleter"*
  %8 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %3, i64 0, i32 0, i32 0
  tail call void @_ZNK4base8internal21PCScanMetadataDeleterclEPv(%"struct.base::internal::PCScanMetadataDeleter"* %7, i8* %8) #12
  br label %9

9:                                                ; preds = %1, %5
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden dereferenceable(24) %"class.base::internal::NonScannableAllocator"* @_ZN4base8internal21NonScannableAllocator8InstanceEv() local_unnamed_addr #2 align 2 {
  %1 = load atomic i8, i8* bitcast (i64* @_ZGVZN4base8internal21NonScannableAllocator8InstanceEvE8instance to i8*) acquire, align 8
  %2 = icmp eq i8 %1, 0
  br i1 %2, label %3, label %7, !prof !2

3:                                                ; preds = %0
  %4 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN4base8internal21NonScannableAllocator8InstanceEvE8instance) #12
  %5 = icmp eq i32 %4, 0
  br i1 %5, label %7, label %6

6:                                                ; preds = %3
  store i64 0, i64* bitcast (%"class.base::NoDestructor"* @_ZZN4base8internal21NonScannableAllocator8InstanceEvE8instance to i64*), align 8
  store i8 0, i8* getelementptr inbounds (%"class.base::NoDestructor", %"class.base::NoDestructor"* @_ZZN4base8internal21NonScannableAllocator8InstanceEvE8instance, i64 0, i32 0, i64 16), align 8
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN4base8internal21NonScannableAllocator8InstanceEvE8instance) #12
  br label %7

7:                                                ; preds = %3, %6, %0
  ret %"class.base::internal::NonScannableAllocator"* bitcast (%"class.base::NoDestructor"* @_ZZN4base8internal21NonScannableAllocator8InstanceEvE8instance to %"class.base::internal::NonScannableAllocator"*)
}

; Function Attrs: nofree nounwind
declare i32 @__cxa_guard_acquire(i64*) local_unnamed_addr #3

; Function Attrs: nofree nounwind
declare void @__cxa_guard_release(i64*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden i8* @_ZN4base8internal21NonScannableAllocator5AllocEm(%"class.base::internal::NonScannableAllocator"* nocapture readonly, i64) local_unnamed_addr #1 align 2 {
  %3 = alloca i8, align 1
  %4 = alloca i64, align 8
  %5 = alloca i8, align 1
  %6 = alloca i64, align 8
  %7 = getelementptr inbounds %"class.base::internal::NonScannableAllocator", %"class.base::internal::NonScannableAllocator"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %8 = load atomic i8, i8* %7 acquire, align 1
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  br i1 %10, label %264, label %11, !prof !3

11:                                               ; preds = %2
  %12 = getelementptr inbounds %"class.base::internal::NonScannableAllocator", %"class.base::internal::NonScannableAllocator"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %13 = load %"struct.base::internal::PartitionAllocator"*, %"struct.base::internal::PartitionAllocator"** %12, align 8
  %14 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %13, i64 0, i32 0
  %15 = tail call i64 @llvm.ctlz.i64(i64 %1, i1 false) #12, !range !4
  %16 = sub nuw nsw i64 64, %15
  %17 = and i64 %16, 255
  %18 = getelementptr inbounds [65 x i8], [65 x i8]* @_ZN4base12_GLOBAL__N_116kOrderIndexShiftE, i64 0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i64
  %21 = lshr i64 %1, %20
  %22 = and i64 %21, 7
  %23 = getelementptr inbounds [65 x i64], [65 x i64]* @_ZN4base12_GLOBAL__N_118kOrderSubIndexMaskE, i64 0, i64 %17
  %24 = load i64, i64* %23, align 8
  %25 = and i64 %24, %1
  %26 = shl nuw nsw i64 %17, 3
  %27 = or i64 %22, %26
  %28 = icmp ne i64 %25, 0
  %29 = zext i1 %28 to i64
  %30 = add nuw nsw i64 %27, %29
  %31 = getelementptr inbounds { [128 x i64], [521 x i16] }, { [128 x i64], [521 x i16] }* @_ZZN4base8internal17BucketIndexLookup8GetIndexEmE6lookup, i64 0, i32 1, i64 %30
  %32 = load i16, i16* %31, align 2
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %3) #12
  store i8 0, i8* %3, align 1
  %33 = bitcast i64* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %33) #12
  store i64 -6148914691236517206, i64* %4, align 8
  %34 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %13, i64 0, i32 0, i32 0
  %35 = load i8, i8* %34, align 8
  %36 = icmp eq i8 %35, 2
  br i1 %36, label %37, label %41

37:                                               ; preds = %11
  %38 = load atomic i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0) acquire, align 8
  %39 = icmp eq i8 %38, 2
  br i1 %39, label %40, label %41, !prof !5

40:                                               ; preds = %37
  tail call void @_ZN4base8internal6PCScan8JoinScanEv() #12
  br label %41

41:                                               ; preds = %40, %37, %11
  %42 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %13, i64 0, i32 0, i32 2
  %43 = load i8, i8* %42, align 2, !range !6
  %44 = icmp eq i8 %43, 0
  br i1 %44, label %193, label %45, !prof !7

45:                                               ; preds = %41
  %46 = load i32, i32* @_ZN4base8internal18g_thread_cache_keyE, align 4
  %47 = tail call i8* @pthread_getspecific(i32 %46) #12
  %48 = bitcast i8* %47 to %"class.base::internal::ThreadCache"*
  %49 = icmp ugt i8* %47, inttoptr (i64 1 to i8*)
  br i1 %49, label %50, label %120, !prof !3

50:                                               ; preds = %45
  %51 = zext i16 %32 to i64
  %52 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %48, i64 0, i32 3, i32 12, i64 %51
  %53 = load i64, i64* %52, align 8
  %54 = add i64 %53, 1
  store i64 %54, i64* %52, align 8
  %55 = getelementptr inbounds i8, i8* %47, i64 1440
  %56 = bitcast i8* %55 to i64*
  %57 = load i64, i64* %56, align 8
  %58 = add i64 %57, 1
  store i64 %58, i64* %56, align 8
  %59 = load i16, i16* @_ZN4base8internal11ThreadCache28largest_active_bucket_index_E, align 2
  %60 = icmp ult i16 %59, %32
  br i1 %60, label %61, label %70, !prof !5

61:                                               ; preds = %50
  %62 = getelementptr inbounds i8, i8* %47, i64 1472
  %63 = bitcast i8* %62 to i64*
  %64 = load i64, i64* %63, align 8
  %65 = add i64 %64, 1
  store i64 %65, i64* %63, align 8
  %66 = getelementptr inbounds i8, i8* %47, i64 1456
  %67 = bitcast i8* %66 to i64*
  %68 = load i64, i64* %67, align 8
  %69 = add i64 %68, 1
  store i64 %69, i64* %67, align 8
  br label %127

70:                                               ; preds = %50
  %71 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %48, i64 0, i32 0, i64 %51, i32 0
  %72 = load %"class.base::internal::PartitionFreelistEntry"*, %"class.base::internal::PartitionFreelistEntry"** %71, align 8
  %73 = icmp eq %"class.base::internal::PartitionFreelistEntry"* %72, null
  br i1 %73, label %79, label %74, !prof !5

74:                                               ; preds = %70
  %75 = getelementptr inbounds i8, i8* %47, i64 1448
  %76 = bitcast i8* %75 to i64*
  %77 = load i64, i64* %76, align 8
  %78 = add i64 %77, 1
  store i64 %78, i64* %76, align 8
  br label %87

79:                                               ; preds = %70
  %80 = getelementptr inbounds i8, i8* %47, i64 1456
  %81 = bitcast i8* %80 to <2 x i64>*
  %82 = load <2 x i64>, <2 x i64>* %81, align 8
  %83 = add <2 x i64> %82, <i64 1, i64 1>
  %84 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %84, align 8
  tail call void @_ZN4base8internal11ThreadCache10FillBucketEm(%"class.base::internal::ThreadCache"* %48, i64 %51) #12
  %85 = load %"class.base::internal::PartitionFreelistEntry"*, %"class.base::internal::PartitionFreelistEntry"** %71, align 8
  %86 = icmp eq %"class.base::internal::PartitionFreelistEntry"* %85, null
  br i1 %86, label %127, label %87, !prof !5

87:                                               ; preds = %79, %74
  %88 = phi %"class.base::internal::PartitionFreelistEntry"* [ %85, %79 ], [ %72, %74 ]
  %89 = getelementptr inbounds %"class.base::internal::PartitionFreelistEntry", %"class.base::internal::PartitionFreelistEntry"* %88, i64 0, i32 0
  %90 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %89, align 8
  %91 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %90, null
  %92 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %90 to i64
  br i1 %91, label %93, label %95

93:                                               ; preds = %87
  %94 = tail call i64 @llvm.bswap.i64(i64 %92) #12
  br label %104

95:                                               ; preds = %87
  %96 = xor i64 %92, -1
  %97 = getelementptr inbounds %"class.base::internal::PartitionFreelistEntry", %"class.base::internal::PartitionFreelistEntry"* %88, i64 0, i32 1
  %98 = load i64, i64* %97, align 8
  %99 = icmp eq i64 %98, %96
  br i1 %99, label %101, label %100, !prof !3

100:                                              ; preds = %95
  tail call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

101:                                              ; preds = %95
  %102 = tail call i64 @llvm.bswap.i64(i64 %92) #12
  %103 = inttoptr i64 %102 to i8*
  tail call void @llvm.prefetch(i8* nonnull %103, i32 0, i32 3, i32 1) #12
  br label %104

104:                                              ; preds = %101, %93
  %105 = phi i64 [ %94, %93 ], [ %102, %101 ]
  %106 = inttoptr i64 %105 to %"class.base::internal::PartitionFreelistEntry"*
  %107 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %48, i64 0, i32 0, i64 %51, i32 1
  %108 = load i8, i8* %107, align 8
  %109 = add i8 %108, -1
  store i8 %109, i8* %107, align 8
  store %"class.base::internal::PartitionFreelistEntry"* %106, %"class.base::internal::PartitionFreelistEntry"** %71, align 8
  %110 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %48, i64 0, i32 0, i64 %51, i32 3
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i64
  store i64 %112, i64* %4, align 8
  %113 = load i16, i16* %110, align 2
  %114 = zext i16 %113 to i64
  %115 = getelementptr inbounds i8, i8* %47, i64 1424
  %116 = bitcast i8* %115 to i64*
  %117 = load i64, i64* %116, align 8
  %118 = sub i64 %117, %114
  store i64 %118, i64* %116, align 8
  %119 = bitcast %"class.base::internal::PartitionFreelistEntry"* %88 to i8*
  br label %122

120:                                              ; preds = %45
  %121 = call i8* @_ZN4base13PartitionRootILb1EE28MaybeInitThreadCacheAndAllocEtPm(%"struct.base::PartitionRoot"* %14, i16 zeroext %32, i64* nonnull %4) #12
  br label %122

122:                                              ; preds = %120, %104
  %123 = phi i8* [ %121, %120 ], [ %119, %104 ]
  %124 = icmp eq i8* %123, null
  br i1 %124, label %125, label %262, !prof !5

125:                                              ; preds = %122
  %126 = zext i16 %32 to i64
  br label %127

127:                                              ; preds = %125, %79, %61
  %128 = phi i64 [ %126, %125 ], [ %51, %79 ], [ %51, %61 ]
  %129 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %13, i64 0, i32 0, i32 10, i64 %128
  %130 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %13, i64 0, i32 0, i32 8
  %131 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %130, i64 0, i32 0
  %132 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %130, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %133

133:                                              ; preds = %145, %127
  %134 = phi i32 [ 0, %127 ], [ %146, %145 ]
  %135 = phi i32 [ 1, %127 ], [ %149, %145 ]
  %136 = load atomic i32, i32* %132 monotonic, align 4
  %137 = icmp eq i32 %136, 0
  br i1 %137, label %138, label %141, !prof !8

138:                                              ; preds = %133
  %139 = cmpxchg weak i32* %132, i32 0, i32 1 acquire monotonic
  %140 = extractvalue { i32, i1 } %139, 1
  br i1 %140, label %156, label %141, !prof !3

141:                                              ; preds = %138, %133
  %142 = icmp sgt i32 %135, 0
  br i1 %142, label %151, label %145

143:                                              ; preds = %151
  %144 = add i32 %135, %134
  br label %145

145:                                              ; preds = %143, %141
  %146 = phi i32 [ %134, %141 ], [ %144, %143 ]
  %147 = shl i32 %135, 1
  %148 = icmp slt i32 %147, 64
  %149 = select i1 %148, i32 %147, i32 64
  %150 = icmp slt i32 %146, 1000
  br i1 %150, label %133, label %155

151:                                              ; preds = %141, %151
  %152 = phi i32 [ %153, %151 ], [ 0, %141 ]
  call void asm sideeffect "pause", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !9
  %153 = add nuw nsw i32 %152, 1
  %154 = icmp eq i32 %153, %135
  br i1 %154, label %143, label %151

155:                                              ; preds = %145
  call void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"* %131) #12
  br label %156

156:                                              ; preds = %138, %155
  %157 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %129, i64 0, i32 0
  %158 = load %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::SlotSpanMetadata"** %157, align 8
  %159 = bitcast %"struct.base::internal::SlotSpanMetadata"* %158 to i8**
  %160 = load i8*, i8** %159, align 1
  %161 = icmp eq i8* %160, null
  br i1 %161, label %186, label %162, !prof !5

162:                                              ; preds = %156
  %163 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %158, i64 0, i32 0
  store i8 0, i8* %3, align 1
  %164 = bitcast i8* %160 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  %165 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %164, align 8
  %166 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %165, null
  %167 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %165 to i64
  br i1 %166, label %168, label %170

168:                                              ; preds = %162
  %169 = call i64 @llvm.bswap.i64(i64 %167) #12
  br label %180

170:                                              ; preds = %162
  %171 = xor i64 %167, -1
  %172 = getelementptr inbounds i8, i8* %160, i64 8
  %173 = bitcast i8* %172 to i64*
  %174 = load i64, i64* %173, align 8
  %175 = icmp eq i64 %174, %171
  br i1 %175, label %177, label %176, !prof !3

176:                                              ; preds = %170
  call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

177:                                              ; preds = %170
  %178 = call i64 @llvm.bswap.i64(i64 %167) #12
  %179 = inttoptr i64 %178 to i8*
  call void @llvm.prefetch(i8* nonnull %179, i32 0, i32 3, i32 1) #12
  br label %180

180:                                              ; preds = %177, %168
  %181 = phi i64 [ %169, %168 ], [ %178, %177 ]
  %182 = inttoptr i64 %181 to %"class.base::internal::PartitionFreelistEntry"*
  store %"class.base::internal::PartitionFreelistEntry"* %182, %"class.base::internal::PartitionFreelistEntry"** %163, align 1
  %183 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %158, i64 0, i32 3
  %184 = load i16, i16* %183, align 1
  %185 = add i16 %184, 1
  store i16 %185, i16* %183, align 1
  br label %188

186:                                              ; preds = %156
  %187 = call i8* @_ZN4base8internal15PartitionBucketILb1EE13SlowPathAllocEPNS_13PartitionRootILb1EEEimmPb(%"struct.base::internal::PartitionBucket"* %129, %"struct.base::PartitionRoot"* %14, i32 0, i64 %1, i64 16384, i8* nonnull %3) #12
  br label %188

188:                                              ; preds = %186, %180
  %189 = phi i8* [ %160, %180 ], [ %187, %186 ]
  %190 = atomicrmw xchg i32* %132, i32 0 release
  %191 = icmp eq i32 %190, 2
  br i1 %191, label %192, label %259, !prof !5

192:                                              ; preds = %188
  call void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"* %131) #12
  br label %259

193:                                              ; preds = %41
  %194 = zext i16 %32 to i64
  %195 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %13, i64 0, i32 0, i32 10, i64 %194
  %196 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %13, i64 0, i32 0, i32 8
  %197 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %196, i64 0, i32 0
  %198 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %196, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %199

199:                                              ; preds = %211, %193
  %200 = phi i32 [ 0, %193 ], [ %212, %211 ]
  %201 = phi i32 [ 1, %193 ], [ %215, %211 ]
  %202 = load atomic i32, i32* %198 monotonic, align 4
  %203 = icmp eq i32 %202, 0
  br i1 %203, label %204, label %207, !prof !8

204:                                              ; preds = %199
  %205 = cmpxchg weak i32* %198, i32 0, i32 1 acquire monotonic
  %206 = extractvalue { i32, i1 } %205, 1
  br i1 %206, label %222, label %207, !prof !3

207:                                              ; preds = %204, %199
  %208 = icmp sgt i32 %201, 0
  br i1 %208, label %217, label %211

209:                                              ; preds = %217
  %210 = add i32 %201, %200
  br label %211

211:                                              ; preds = %209, %207
  %212 = phi i32 [ %200, %207 ], [ %210, %209 ]
  %213 = shl i32 %201, 1
  %214 = icmp slt i32 %213, 64
  %215 = select i1 %214, i32 %213, i32 64
  %216 = icmp slt i32 %212, 1000
  br i1 %216, label %199, label %221

217:                                              ; preds = %207, %217
  %218 = phi i32 [ %219, %217 ], [ 0, %207 ]
  tail call void asm sideeffect "pause", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !9
  %219 = add nuw nsw i32 %218, 1
  %220 = icmp eq i32 %219, %201
  br i1 %220, label %209, label %217

221:                                              ; preds = %211
  tail call void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"* %197) #12
  br label %222

222:                                              ; preds = %204, %221
  %223 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %195, i64 0, i32 0
  %224 = load %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::SlotSpanMetadata"** %223, align 8
  %225 = bitcast %"struct.base::internal::SlotSpanMetadata"* %224 to i8**
  %226 = load i8*, i8** %225, align 1
  %227 = icmp eq i8* %226, null
  br i1 %227, label %252, label %228, !prof !5

228:                                              ; preds = %222
  %229 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %224, i64 0, i32 0
  store i8 0, i8* %3, align 1
  %230 = bitcast i8* %226 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  %231 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %230, align 8
  %232 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %231, null
  %233 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %231 to i64
  br i1 %232, label %234, label %236

234:                                              ; preds = %228
  %235 = tail call i64 @llvm.bswap.i64(i64 %233) #12
  br label %246

236:                                              ; preds = %228
  %237 = xor i64 %233, -1
  %238 = getelementptr inbounds i8, i8* %226, i64 8
  %239 = bitcast i8* %238 to i64*
  %240 = load i64, i64* %239, align 8
  %241 = icmp eq i64 %240, %237
  br i1 %241, label %243, label %242, !prof !3

242:                                              ; preds = %236
  tail call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

243:                                              ; preds = %236
  %244 = tail call i64 @llvm.bswap.i64(i64 %233) #12
  %245 = inttoptr i64 %244 to i8*
  tail call void @llvm.prefetch(i8* nonnull %245, i32 0, i32 3, i32 1) #12
  br label %246

246:                                              ; preds = %243, %234
  %247 = phi i64 [ %235, %234 ], [ %244, %243 ]
  %248 = inttoptr i64 %247 to %"class.base::internal::PartitionFreelistEntry"*
  store %"class.base::internal::PartitionFreelistEntry"* %248, %"class.base::internal::PartitionFreelistEntry"** %229, align 1
  %249 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %224, i64 0, i32 3
  %250 = load i16, i16* %249, align 1
  %251 = add i16 %250, 1
  store i16 %251, i16* %249, align 1
  br label %254

252:                                              ; preds = %222
  %253 = call i8* @_ZN4base8internal15PartitionBucketILb1EE13SlowPathAllocEPNS_13PartitionRootILb1EEEimmPb(%"struct.base::internal::PartitionBucket"* %195, %"struct.base::PartitionRoot"* %14, i32 0, i64 %1, i64 16384, i8* nonnull %3) #12
  br label %254

254:                                              ; preds = %252, %246
  %255 = phi i8* [ %226, %246 ], [ %253, %252 ]
  %256 = atomicrmw xchg i32* %198, i32 0 release
  %257 = icmp eq i32 %256, 2
  br i1 %257, label %258, label %259, !prof !5

258:                                              ; preds = %254
  call void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"* %197) #12
  br label %259

259:                                              ; preds = %258, %254, %192, %188
  %260 = phi i8* [ %189, %188 ], [ %189, %192 ], [ %255, %254 ], [ %255, %258 ]
  %261 = icmp eq i8* %260, null
  br i1 %261, label %515, label %262, !prof !5

262:                                              ; preds = %122, %259
  %263 = phi i8* [ %260, %259 ], [ %123, %122 ]
  br label %515

264:                                              ; preds = %2
  %265 = tail call %"struct.base::PartitionRoot"* @_ZN4base8internal20PartitionAllocMalloc9AllocatorEv() #12
  %266 = tail call i64 @llvm.ctlz.i64(i64 %1, i1 false) #12, !range !4
  %267 = sub nuw nsw i64 64, %266
  %268 = and i64 %267, 255
  %269 = getelementptr inbounds [65 x i8], [65 x i8]* @_ZN4base12_GLOBAL__N_116kOrderIndexShiftE, i64 0, i64 %268
  %270 = load i8, i8* %269, align 1
  %271 = zext i8 %270 to i64
  %272 = lshr i64 %1, %271
  %273 = and i64 %272, 7
  %274 = getelementptr inbounds [65 x i64], [65 x i64]* @_ZN4base12_GLOBAL__N_118kOrderSubIndexMaskE, i64 0, i64 %268
  %275 = load i64, i64* %274, align 8
  %276 = and i64 %275, %1
  %277 = shl nuw nsw i64 %268, 3
  %278 = or i64 %273, %277
  %279 = icmp ne i64 %276, 0
  %280 = zext i1 %279 to i64
  %281 = add nuw nsw i64 %278, %280
  %282 = getelementptr inbounds { [128 x i64], [521 x i16] }, { [128 x i64], [521 x i16] }* @_ZZN4base8internal17BucketIndexLookup8GetIndexEmE6lookup, i64 0, i32 1, i64 %281
  %283 = load i16, i16* %282, align 2
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %5) #12
  store i8 0, i8* %5, align 1
  %284 = bitcast i64* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %284) #12
  store i64 -6148914691236517206, i64* %6, align 8
  %285 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %265, i64 0, i32 0
  %286 = load i8, i8* %285, align 8
  %287 = icmp eq i8 %286, 2
  br i1 %287, label %288, label %292

288:                                              ; preds = %264
  %289 = load atomic i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0) acquire, align 8
  %290 = icmp eq i8 %289, 2
  br i1 %290, label %291, label %292, !prof !5

291:                                              ; preds = %288
  tail call void @_ZN4base8internal6PCScan8JoinScanEv() #12
  br label %292

292:                                              ; preds = %291, %288, %264
  %293 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %265, i64 0, i32 2
  %294 = load i8, i8* %293, align 2, !range !6
  %295 = icmp eq i8 %294, 0
  br i1 %295, label %444, label %296, !prof !7

296:                                              ; preds = %292
  %297 = load i32, i32* @_ZN4base8internal18g_thread_cache_keyE, align 4
  %298 = tail call i8* @pthread_getspecific(i32 %297) #12
  %299 = bitcast i8* %298 to %"class.base::internal::ThreadCache"*
  %300 = icmp ugt i8* %298, inttoptr (i64 1 to i8*)
  br i1 %300, label %301, label %371, !prof !3

301:                                              ; preds = %296
  %302 = zext i16 %283 to i64
  %303 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %299, i64 0, i32 3, i32 12, i64 %302
  %304 = load i64, i64* %303, align 8
  %305 = add i64 %304, 1
  store i64 %305, i64* %303, align 8
  %306 = getelementptr inbounds i8, i8* %298, i64 1440
  %307 = bitcast i8* %306 to i64*
  %308 = load i64, i64* %307, align 8
  %309 = add i64 %308, 1
  store i64 %309, i64* %307, align 8
  %310 = load i16, i16* @_ZN4base8internal11ThreadCache28largest_active_bucket_index_E, align 2
  %311 = icmp ult i16 %310, %283
  br i1 %311, label %312, label %321, !prof !5

312:                                              ; preds = %301
  %313 = getelementptr inbounds i8, i8* %298, i64 1472
  %314 = bitcast i8* %313 to i64*
  %315 = load i64, i64* %314, align 8
  %316 = add i64 %315, 1
  store i64 %316, i64* %314, align 8
  %317 = getelementptr inbounds i8, i8* %298, i64 1456
  %318 = bitcast i8* %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, 1
  store i64 %320, i64* %318, align 8
  br label %378

321:                                              ; preds = %301
  %322 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %299, i64 0, i32 0, i64 %302, i32 0
  %323 = load %"class.base::internal::PartitionFreelistEntry"*, %"class.base::internal::PartitionFreelistEntry"** %322, align 8
  %324 = icmp eq %"class.base::internal::PartitionFreelistEntry"* %323, null
  br i1 %324, label %330, label %325, !prof !5

325:                                              ; preds = %321
  %326 = getelementptr inbounds i8, i8* %298, i64 1448
  %327 = bitcast i8* %326 to i64*
  %328 = load i64, i64* %327, align 8
  %329 = add i64 %328, 1
  store i64 %329, i64* %327, align 8
  br label %338

330:                                              ; preds = %321
  %331 = getelementptr inbounds i8, i8* %298, i64 1456
  %332 = bitcast i8* %331 to <2 x i64>*
  %333 = load <2 x i64>, <2 x i64>* %332, align 8
  %334 = add <2 x i64> %333, <i64 1, i64 1>
  %335 = bitcast i8* %331 to <2 x i64>*
  store <2 x i64> %334, <2 x i64>* %335, align 8
  tail call void @_ZN4base8internal11ThreadCache10FillBucketEm(%"class.base::internal::ThreadCache"* %299, i64 %302) #12
  %336 = load %"class.base::internal::PartitionFreelistEntry"*, %"class.base::internal::PartitionFreelistEntry"** %322, align 8
  %337 = icmp eq %"class.base::internal::PartitionFreelistEntry"* %336, null
  br i1 %337, label %378, label %338, !prof !5

338:                                              ; preds = %330, %325
  %339 = phi %"class.base::internal::PartitionFreelistEntry"* [ %336, %330 ], [ %323, %325 ]
  %340 = getelementptr inbounds %"class.base::internal::PartitionFreelistEntry", %"class.base::internal::PartitionFreelistEntry"* %339, i64 0, i32 0
  %341 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %340, align 8
  %342 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %341, null
  %343 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %341 to i64
  br i1 %342, label %344, label %346

344:                                              ; preds = %338
  %345 = tail call i64 @llvm.bswap.i64(i64 %343) #12
  br label %355

346:                                              ; preds = %338
  %347 = xor i64 %343, -1
  %348 = getelementptr inbounds %"class.base::internal::PartitionFreelistEntry", %"class.base::internal::PartitionFreelistEntry"* %339, i64 0, i32 1
  %349 = load i64, i64* %348, align 8
  %350 = icmp eq i64 %349, %347
  br i1 %350, label %352, label %351, !prof !3

351:                                              ; preds = %346
  tail call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

352:                                              ; preds = %346
  %353 = tail call i64 @llvm.bswap.i64(i64 %343) #12
  %354 = inttoptr i64 %353 to i8*
  tail call void @llvm.prefetch(i8* nonnull %354, i32 0, i32 3, i32 1) #12
  br label %355

355:                                              ; preds = %352, %344
  %356 = phi i64 [ %345, %344 ], [ %353, %352 ]
  %357 = inttoptr i64 %356 to %"class.base::internal::PartitionFreelistEntry"*
  %358 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %299, i64 0, i32 0, i64 %302, i32 1
  %359 = load i8, i8* %358, align 8
  %360 = add i8 %359, -1
  store i8 %360, i8* %358, align 8
  store %"class.base::internal::PartitionFreelistEntry"* %357, %"class.base::internal::PartitionFreelistEntry"** %322, align 8
  %361 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %299, i64 0, i32 0, i64 %302, i32 3
  %362 = load i16, i16* %361, align 2
  %363 = zext i16 %362 to i64
  store i64 %363, i64* %6, align 8
  %364 = load i16, i16* %361, align 2
  %365 = zext i16 %364 to i64
  %366 = getelementptr inbounds i8, i8* %298, i64 1424
  %367 = bitcast i8* %366 to i64*
  %368 = load i64, i64* %367, align 8
  %369 = sub i64 %368, %365
  store i64 %369, i64* %367, align 8
  %370 = bitcast %"class.base::internal::PartitionFreelistEntry"* %339 to i8*
  br label %373

371:                                              ; preds = %296
  %372 = call i8* @_ZN4base13PartitionRootILb1EE28MaybeInitThreadCacheAndAllocEtPm(%"struct.base::PartitionRoot"* %265, i16 zeroext %283, i64* nonnull %6) #12
  br label %373

373:                                              ; preds = %371, %355
  %374 = phi i8* [ %372, %371 ], [ %370, %355 ]
  %375 = icmp eq i8* %374, null
  br i1 %375, label %376, label %513, !prof !5

376:                                              ; preds = %373
  %377 = zext i16 %283 to i64
  br label %378

378:                                              ; preds = %376, %330, %312
  %379 = phi i64 [ %377, %376 ], [ %302, %330 ], [ %302, %312 ]
  %380 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %265, i64 0, i32 10, i64 %379
  %381 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %265, i64 0, i32 8
  %382 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %381, i64 0, i32 0
  %383 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %381, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %384

384:                                              ; preds = %396, %378
  %385 = phi i32 [ 0, %378 ], [ %397, %396 ]
  %386 = phi i32 [ 1, %378 ], [ %400, %396 ]
  %387 = load atomic i32, i32* %383 monotonic, align 4
  %388 = icmp eq i32 %387, 0
  br i1 %388, label %389, label %392, !prof !8

389:                                              ; preds = %384
  %390 = cmpxchg weak i32* %383, i32 0, i32 1 acquire monotonic
  %391 = extractvalue { i32, i1 } %390, 1
  br i1 %391, label %407, label %392, !prof !3

392:                                              ; preds = %389, %384
  %393 = icmp sgt i32 %386, 0
  br i1 %393, label %402, label %396

394:                                              ; preds = %402
  %395 = add i32 %386, %385
  br label %396

396:                                              ; preds = %394, %392
  %397 = phi i32 [ %385, %392 ], [ %395, %394 ]
  %398 = shl i32 %386, 1
  %399 = icmp slt i32 %398, 64
  %400 = select i1 %399, i32 %398, i32 64
  %401 = icmp slt i32 %397, 1000
  br i1 %401, label %384, label %406

402:                                              ; preds = %392, %402
  %403 = phi i32 [ %404, %402 ], [ 0, %392 ]
  call void asm sideeffect "pause", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !9
  %404 = add nuw nsw i32 %403, 1
  %405 = icmp eq i32 %404, %386
  br i1 %405, label %394, label %402

406:                                              ; preds = %396
  call void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"* %382) #12
  br label %407

407:                                              ; preds = %389, %406
  %408 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %380, i64 0, i32 0
  %409 = load %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::SlotSpanMetadata"** %408, align 8
  %410 = bitcast %"struct.base::internal::SlotSpanMetadata"* %409 to i8**
  %411 = load i8*, i8** %410, align 1
  %412 = icmp eq i8* %411, null
  br i1 %412, label %437, label %413, !prof !5

413:                                              ; preds = %407
  %414 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %409, i64 0, i32 0
  store i8 0, i8* %5, align 1
  %415 = bitcast i8* %411 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  %416 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %415, align 8
  %417 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %416, null
  %418 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %416 to i64
  br i1 %417, label %419, label %421

419:                                              ; preds = %413
  %420 = call i64 @llvm.bswap.i64(i64 %418) #12
  br label %431

421:                                              ; preds = %413
  %422 = xor i64 %418, -1
  %423 = getelementptr inbounds i8, i8* %411, i64 8
  %424 = bitcast i8* %423 to i64*
  %425 = load i64, i64* %424, align 8
  %426 = icmp eq i64 %425, %422
  br i1 %426, label %428, label %427, !prof !3

427:                                              ; preds = %421
  call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

428:                                              ; preds = %421
  %429 = call i64 @llvm.bswap.i64(i64 %418) #12
  %430 = inttoptr i64 %429 to i8*
  call void @llvm.prefetch(i8* nonnull %430, i32 0, i32 3, i32 1) #12
  br label %431

431:                                              ; preds = %428, %419
  %432 = phi i64 [ %420, %419 ], [ %429, %428 ]
  %433 = inttoptr i64 %432 to %"class.base::internal::PartitionFreelistEntry"*
  store %"class.base::internal::PartitionFreelistEntry"* %433, %"class.base::internal::PartitionFreelistEntry"** %414, align 1
  %434 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %409, i64 0, i32 3
  %435 = load i16, i16* %434, align 1
  %436 = add i16 %435, 1
  store i16 %436, i16* %434, align 1
  br label %439

437:                                              ; preds = %407
  %438 = call i8* @_ZN4base8internal15PartitionBucketILb1EE13SlowPathAllocEPNS_13PartitionRootILb1EEEimmPb(%"struct.base::internal::PartitionBucket"* %380, %"struct.base::PartitionRoot"* %265, i32 0, i64 %1, i64 16384, i8* nonnull %5) #12
  br label %439

439:                                              ; preds = %437, %431
  %440 = phi i8* [ %411, %431 ], [ %438, %437 ]
  %441 = atomicrmw xchg i32* %383, i32 0 release
  %442 = icmp eq i32 %441, 2
  br i1 %442, label %443, label %510, !prof !5

443:                                              ; preds = %439
  call void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"* %382) #12
  br label %510

444:                                              ; preds = %292
  %445 = zext i16 %283 to i64
  %446 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %265, i64 0, i32 10, i64 %445
  %447 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %265, i64 0, i32 8
  %448 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %447, i64 0, i32 0
  %449 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %447, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %450

450:                                              ; preds = %462, %444
  %451 = phi i32 [ 0, %444 ], [ %463, %462 ]
  %452 = phi i32 [ 1, %444 ], [ %466, %462 ]
  %453 = load atomic i32, i32* %449 monotonic, align 4
  %454 = icmp eq i32 %453, 0
  br i1 %454, label %455, label %458, !prof !8

455:                                              ; preds = %450
  %456 = cmpxchg weak i32* %449, i32 0, i32 1 acquire monotonic
  %457 = extractvalue { i32, i1 } %456, 1
  br i1 %457, label %473, label %458, !prof !3

458:                                              ; preds = %455, %450
  %459 = icmp sgt i32 %452, 0
  br i1 %459, label %468, label %462

460:                                              ; preds = %468
  %461 = add i32 %452, %451
  br label %462

462:                                              ; preds = %460, %458
  %463 = phi i32 [ %451, %458 ], [ %461, %460 ]
  %464 = shl i32 %452, 1
  %465 = icmp slt i32 %464, 64
  %466 = select i1 %465, i32 %464, i32 64
  %467 = icmp slt i32 %463, 1000
  br i1 %467, label %450, label %472

468:                                              ; preds = %458, %468
  %469 = phi i32 [ %470, %468 ], [ 0, %458 ]
  tail call void asm sideeffect "pause", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !9
  %470 = add nuw nsw i32 %469, 1
  %471 = icmp eq i32 %470, %452
  br i1 %471, label %460, label %468

472:                                              ; preds = %462
  tail call void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"* %448) #12
  br label %473

473:                                              ; preds = %455, %472
  %474 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %446, i64 0, i32 0
  %475 = load %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::SlotSpanMetadata"** %474, align 8
  %476 = bitcast %"struct.base::internal::SlotSpanMetadata"* %475 to i8**
  %477 = load i8*, i8** %476, align 1
  %478 = icmp eq i8* %477, null
  br i1 %478, label %503, label %479, !prof !5

479:                                              ; preds = %473
  %480 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %475, i64 0, i32 0
  store i8 0, i8* %5, align 1
  %481 = bitcast i8* %477 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  %482 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %481, align 8
  %483 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %482, null
  %484 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %482 to i64
  br i1 %483, label %485, label %487

485:                                              ; preds = %479
  %486 = tail call i64 @llvm.bswap.i64(i64 %484) #12
  br label %497

487:                                              ; preds = %479
  %488 = xor i64 %484, -1
  %489 = getelementptr inbounds i8, i8* %477, i64 8
  %490 = bitcast i8* %489 to i64*
  %491 = load i64, i64* %490, align 8
  %492 = icmp eq i64 %491, %488
  br i1 %492, label %494, label %493, !prof !3

493:                                              ; preds = %487
  tail call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

494:                                              ; preds = %487
  %495 = tail call i64 @llvm.bswap.i64(i64 %484) #12
  %496 = inttoptr i64 %495 to i8*
  tail call void @llvm.prefetch(i8* nonnull %496, i32 0, i32 3, i32 1) #12
  br label %497

497:                                              ; preds = %494, %485
  %498 = phi i64 [ %486, %485 ], [ %495, %494 ]
  %499 = inttoptr i64 %498 to %"class.base::internal::PartitionFreelistEntry"*
  store %"class.base::internal::PartitionFreelistEntry"* %499, %"class.base::internal::PartitionFreelistEntry"** %480, align 1
  %500 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %475, i64 0, i32 3
  %501 = load i16, i16* %500, align 1
  %502 = add i16 %501, 1
  store i16 %502, i16* %500, align 1
  br label %505

503:                                              ; preds = %473
  %504 = call i8* @_ZN4base8internal15PartitionBucketILb1EE13SlowPathAllocEPNS_13PartitionRootILb1EEEimmPb(%"struct.base::internal::PartitionBucket"* %446, %"struct.base::PartitionRoot"* %265, i32 0, i64 %1, i64 16384, i8* nonnull %5) #12
  br label %505

505:                                              ; preds = %503, %497
  %506 = phi i8* [ %477, %497 ], [ %504, %503 ]
  %507 = atomicrmw xchg i32* %449, i32 0 release
  %508 = icmp eq i32 %507, 2
  br i1 %508, label %509, label %510, !prof !5

509:                                              ; preds = %505
  call void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"* %448) #12
  br label %510

510:                                              ; preds = %509, %505, %443, %439
  %511 = phi i8* [ %440, %439 ], [ %440, %443 ], [ %506, %505 ], [ %506, %509 ]
  %512 = icmp eq i8* %511, null
  br i1 %512, label %515, label %513, !prof !5

513:                                              ; preds = %373, %510
  %514 = phi i8* [ %511, %510 ], [ %374, %373 ]
  br label %515

515:                                              ; preds = %513, %510, %262, %259
  %516 = phi i8* [ %33, %259 ], [ %33, %262 ], [ %284, %510 ], [ %284, %513 ]
  %517 = phi i8* [ %3, %259 ], [ %3, %262 ], [ %5, %510 ], [ %5, %513 ]
  %518 = phi i8* [ null, %259 ], [ %263, %262 ], [ null, %510 ], [ %514, %513 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %516) #12
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %517) #12
  ret i8* %518
}

declare %"struct.base::PartitionRoot"* @_ZN4base8internal20PartitionAllocMalloc9AllocatorEv() local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN4base8internal21NonScannableAllocator4FreeEPv(i8*) local_unnamed_addr #1 align 2 {
  %2 = alloca %"struct.base::internal::DeferredUnmap", align 8
  %3 = icmp eq i8* %0, null
  br i1 %3, label %236, label %4, !prof !5

4:                                                ; preds = %1
  tail call void @llvm.prefetch(i8* nonnull %0, i32 0, i32 3, i32 1) #12
  %5 = ptrtoint i8* %0 to i64
  %6 = and i64 %5, -2097152
  %7 = or i64 %6, 4096
  %8 = inttoptr i64 %7 to i8*
  %9 = lshr i64 %5, 9
  %10 = and i64 %9, 4064
  %11 = getelementptr inbounds i8, i8* %8, i64 %10
  %12 = bitcast i8* %11 to %"struct.base::internal::PartitionPage"*
  %13 = getelementptr inbounds i8, i8* %11, i64 30
  %14 = load i8, i8* %13, align 2
  %15 = zext i8 %14 to i64
  %16 = sub nsw i64 0, %15
  %17 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %12, i64 %16, i32 0
  %18 = bitcast %union.anon* %17 to %"struct.base::internal::SlotSpanMetadata"*
  %19 = bitcast %union.anon* %17 to i8*
  tail call void @llvm.prefetch(i8* %19, i32 0, i32 3, i32 1) #12
  %20 = ptrtoint %union.anon* %17 to i64
  %21 = and i64 %20, -4096
  %22 = inttoptr i64 %21 to %"struct.base::internal::PartitionSuperPageExtentEntry"*
  %23 = getelementptr inbounds %"struct.base::internal::PartitionSuperPageExtentEntry", %"struct.base::internal::PartitionSuperPageExtentEntry"* %22, i64 0, i32 0
  %24 = load %"struct.base::PartitionRoot"*, %"struct.base::PartitionRoot"** %23, align 4096
  %25 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %24, i64 0, i32 0
  %26 = load i8, i8* %25, align 8
  %27 = icmp eq i8 %26, 2
  br i1 %27, label %28, label %97, !prof !5

28:                                               ; preds = %4
  %29 = load atomic i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0) acquire, align 8
  %30 = icmp eq i8 %29, 2
  br i1 %30, label %31, label %32, !prof !5

31:                                               ; preds = %28
  tail call void @_ZN4base8internal6PCScan8JoinScanEv() #12
  br label %32

32:                                               ; preds = %31, %28
  %33 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %12, i64 %16, i32 0, i32 1, i64 8
  %34 = bitcast i8* %33 to %"struct.base::internal::PartitionBucket"**
  %35 = load %"struct.base::internal::PartitionBucket"*, %"struct.base::internal::PartitionBucket"** %34, align 1
  %36 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %24, i64 0, i32 10, i64 0
  %37 = icmp ugt %"struct.base::internal::PartitionBucket"* %36, %35
  %38 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %24, i64 0, i32 11
  %39 = icmp ult %"struct.base::internal::PartitionBucket"* %38, %35
  %40 = or i1 %37, %39
  br i1 %40, label %97, label %41, !prof !5

41:                                               ; preds = %32
  %42 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %12, i64 %16, i32 0, i32 1, i64 21
  %43 = load i8, i8* %42, align 1, !range !6
  %44 = icmp eq i8 %43, 0
  br i1 %44, label %45, label %49, !prof !3

45:                                               ; preds = %41
  %46 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %35, i64 0, i32 3
  %47 = load i32, i32* %46, align 8
  %48 = zext i32 %47 to i64
  br label %56

49:                                               ; preds = %41
  %50 = bitcast %union.anon* %17 to %"struct.base::internal::PartitionPage"*
  %51 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %50, i64 1, i32 0, i32 0, i32 0
  %52 = load i64, i64* %51, align 1
  %53 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %35, i64 0, i32 3
  %54 = load i32, i32* %53, align 8
  %55 = zext i32 %54 to i64
  br label %56

56:                                               ; preds = %49, %45
  %57 = phi i64 [ %48, %45 ], [ %55, %49 ]
  %58 = phi i64 [ %48, %45 ], [ %52, %49 ]
  %59 = load atomic i64, i64* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0) monotonic, align 8
  %60 = inttoptr i64 %6 to i8*
  %61 = and i64 %59, 1
  %62 = icmp eq i64 %61, 0
  %63 = select i1 %62, i64 16384, i64 32768
  %64 = getelementptr inbounds i8, i8* %60, i64 %63
  %65 = bitcast i8* %64 to %"class.base::internal::ObjectBitmap"*
  %66 = lshr i64 %5, 4
  %67 = lshr i64 %5, 10
  %68 = and i64 %67, 2047
  %69 = and i64 %66, 63
  %70 = shl i64 1, %69
  %71 = getelementptr inbounds %"class.base::internal::ObjectBitmap", %"class.base::internal::ObjectBitmap"* %65, i64 0, i32 0, i32 0, i64 %68
  %72 = atomicrmw or i64* %71, i64 %70 monotonic
  %73 = and i64 %72, %70
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %76, label %75, !prof !3

75:                                               ; preds = %56
  notail call void @_ZN4base8internal17DoubleFreeAttemptEv() #13
  unreachable

76:                                               ; preds = %56
  %77 = atomicrmw add i64* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), i64 %57 monotonic
  %78 = add i64 %77, %57
  %79 = load atomic i64, i64* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) monotonic, align 8
  %80 = icmp ugt i64 %78, %79
  br i1 %80, label %81, label %87

81:                                               ; preds = %76
  %82 = load %"class.base::internal::PCScanSchedulingBackend"*, %"class.base::internal::PCScanSchedulingBackend"** getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 0, i32 2), align 8
  %83 = bitcast %"class.base::internal::PCScanSchedulingBackend"* %82 to i1 (%"class.base::internal::PCScanSchedulingBackend"*)***
  %84 = load i1 (%"class.base::internal::PCScanSchedulingBackend"*)**, i1 (%"class.base::internal::PCScanSchedulingBackend"*)*** %83, align 8
  %85 = load i1 (%"class.base::internal::PCScanSchedulingBackend"*)*, i1 (%"class.base::internal::PCScanSchedulingBackend"*)** %84, align 8
  %86 = tail call zeroext i1 %85(%"class.base::internal::PCScanSchedulingBackend"* %82) #12
  br label %87

87:                                               ; preds = %81, %76
  %88 = phi i1 [ false, %76 ], [ %86, %81 ]
  %89 = load i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 2), align 1
  %90 = icmp eq i8 %89, 1
  br i1 %90, label %91, label %92

91:                                               ; preds = %87
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %0, i8 0, i64 %58, i1 false) #12
  br label %92

92:                                               ; preds = %91, %87
  br i1 %88, label %93, label %236, !prof !5

93:                                               ; preds = %92
  %94 = load atomic i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0) monotonic, align 8
  %95 = icmp eq i8 %94, 0
  br i1 %95, label %96, label %236

96:                                               ; preds = %93
  tail call void @_ZN4base8internal6PCScan11PerformScanENS1_14InvocationModeE(%"class.base::internal::PCScan"* nonnull @_ZN4base8internal6PCScan9instance_E, i32 1) #12
  br label %236

97:                                               ; preds = %32, %4
  %98 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %24, i64 0, i32 2
  %99 = load i8, i8* %98, align 2, !range !6
  %100 = icmp eq i8 %99, 0
  br i1 %100, label %169, label %101, !prof !5

101:                                              ; preds = %97
  %102 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %12, i64 %16, i32 0, i32 1, i64 8
  %103 = bitcast i8* %102 to %"struct.base::internal::PartitionBucket"**
  %104 = load %"struct.base::internal::PartitionBucket"*, %"struct.base::internal::PartitionBucket"** %103, align 1
  %105 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %24, i64 0, i32 10, i64 0
  %106 = icmp ule %"struct.base::internal::PartitionBucket"* %105, %104
  %107 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %24, i64 0, i32 11
  %108 = icmp uge %"struct.base::internal::PartitionBucket"* %107, %104
  %109 = and i1 %108, %106
  %110 = ptrtoint %"struct.base::internal::PartitionBucket"* %104 to i64
  br i1 %109, label %111, label %169, !prof !3

111:                                              ; preds = %101
  %112 = load i32, i32* @_ZN4base8internal18g_thread_cache_keyE, align 4
  %113 = tail call i8* @pthread_getspecific(i32 %112) #12
  %114 = bitcast i8* %113 to %"class.base::internal::ThreadCache"*
  %115 = icmp ugt i8* %113, inttoptr (i64 1 to i8*)
  br i1 %115, label %116, label %169, !prof !3

116:                                              ; preds = %111
  %117 = ptrtoint %"struct.base::internal::PartitionBucket"* %105 to i64
  %118 = sub i64 %110, %117
  %119 = sdiv exact i64 %118, 40
  %120 = getelementptr inbounds i8, i8* %113, i64 1480
  %121 = bitcast i8* %120 to i64*
  %122 = load i64, i64* %121, align 8
  %123 = add i64 %122, 1
  store i64 %123, i64* %121, align 8
  %124 = load i16, i16* @_ZN4base8internal11ThreadCache28largest_active_bucket_index_E, align 2
  %125 = zext i16 %124 to i64
  %126 = icmp ugt i64 %119, %125
  br i1 %126, label %127, label %132, !prof !5

127:                                              ; preds = %116
  %128 = getelementptr inbounds i8, i8* %113, i64 1496
  %129 = bitcast i8* %128 to i64*
  %130 = load i64, i64* %129, align 8
  %131 = add i64 %130, 1
  store i64 %131, i64* %129, align 8
  br label %169

132:                                              ; preds = %116
  %133 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %114, i64 0, i32 0, i64 %119
  %134 = bitcast %"struct.base::internal::ThreadCache::Bucket"* %133 to i64*
  %135 = load i64, i64* %134, align 8
  %136 = tail call i64 @llvm.bswap.i64(i64 %135) #12
  %137 = inttoptr i64 %136 to %"struct.base::internal::EncodedPartitionFreelistEntry"*
  %138 = bitcast i8* %0 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  store %"struct.base::internal::EncodedPartitionFreelistEntry"* %137, %"struct.base::internal::EncodedPartitionFreelistEntry"** %138, align 8
  %139 = xor i64 %136, -1
  %140 = getelementptr inbounds i8, i8* %0, i64 8
  %141 = bitcast i8* %140 to i64*
  store i64 %139, i64* %141, align 8
  %142 = bitcast %"struct.base::internal::ThreadCache::Bucket"* %133 to i8**
  store i8* %0, i8** %142, align 8
  %143 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %114, i64 0, i32 0, i64 %119, i32 1
  %144 = load i8, i8* %143, align 8
  %145 = add i8 %144, 1
  store i8 %145, i8* %143, align 8
  %146 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %114, i64 0, i32 0, i64 %119, i32 3
  %147 = load i16, i16* %146, align 2
  %148 = zext i16 %147 to i64
  %149 = getelementptr inbounds i8, i8* %113, i64 1424
  %150 = bitcast i8* %149 to i64*
  %151 = load i64, i64* %150, align 8
  %152 = add i64 %151, %148
  store i64 %152, i64* %150, align 8
  %153 = getelementptr inbounds i8, i8* %113, i64 1488
  %154 = bitcast i8* %153 to i64*
  %155 = load i64, i64* %154, align 8
  %156 = add i64 %155, 1
  store i64 %156, i64* %154, align 8
  %157 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %114, i64 0, i32 0, i64 %119, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %158 = load atomic i8, i8* %157 monotonic, align 1
  %159 = icmp ugt i8 %145, %158
  br i1 %159, label %160, label %163, !prof !5

160:                                              ; preds = %132
  %161 = lshr i8 %158, 1
  %162 = zext i8 %161 to i64
  tail call void @_ZN4base8internal11ThreadCache11ClearBucketERNS1_6BucketEm(%"class.base::internal::ThreadCache"* %114, %"struct.base::internal::ThreadCache::Bucket"* dereferenceable(16) %133, i64 %162) #12
  br label %163

163:                                              ; preds = %160, %132
  %164 = getelementptr inbounds i8, i8* %113, i64 1432
  %165 = load atomic i8, i8* %164 monotonic, align 1
  %166 = and i8 %165, 1
  %167 = icmp eq i8 %166, 0
  br i1 %167, label %236, label %168, !prof !3

168:                                              ; preds = %163
  tail call void @_ZN4base8internal11ThreadCache13PurgeInternalEv(%"class.base::internal::ThreadCache"* %114) #12
  br label %236

169:                                              ; preds = %127, %111, %101, %97
  %170 = bitcast %"struct.base::internal::DeferredUnmap"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %170) #12
  %171 = getelementptr inbounds %"struct.base::internal::DeferredUnmap", %"struct.base::internal::DeferredUnmap"* %2, i64 0, i32 0
  %172 = getelementptr inbounds %"struct.base::internal::DeferredUnmap", %"struct.base::internal::DeferredUnmap"* %2, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %170, i8 0, i64 16, i1 false) #12
  %173 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %24, i64 0, i32 8
  %174 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %173, i64 0, i32 0
  %175 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %173, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %176

176:                                              ; preds = %188, %169
  %177 = phi i32 [ 0, %169 ], [ %189, %188 ]
  %178 = phi i32 [ 1, %169 ], [ %192, %188 ]
  %179 = load atomic i32, i32* %175 monotonic, align 4
  %180 = icmp eq i32 %179, 0
  br i1 %180, label %181, label %184, !prof !8

181:                                              ; preds = %176
  %182 = cmpxchg weak i32* %175, i32 0, i32 1 acquire monotonic
  %183 = extractvalue { i32, i1 } %182, 1
  br i1 %183, label %199, label %184, !prof !3

184:                                              ; preds = %181, %176
  %185 = icmp sgt i32 %178, 0
  br i1 %185, label %194, label %188

186:                                              ; preds = %194
  %187 = add i32 %178, %177
  br label %188

188:                                              ; preds = %186, %184
  %189 = phi i32 [ %177, %184 ], [ %187, %186 ]
  %190 = shl i32 %178, 1
  %191 = icmp slt i32 %190, 64
  %192 = select i1 %191, i32 %190, i32 64
  %193 = icmp slt i32 %189, 1000
  br i1 %193, label %176, label %198

194:                                              ; preds = %184, %194
  %195 = phi i32 [ %196, %194 ], [ 0, %184 ]
  tail call void asm sideeffect "pause", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !9
  %196 = add nuw nsw i32 %195, 1
  %197 = icmp eq i32 %196, %178
  br i1 %197, label %186, label %194

198:                                              ; preds = %188
  tail call void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"* %174) #12
  br label %199

199:                                              ; preds = %181, %198
  %200 = bitcast %union.anon* %17 to i8**
  %201 = load i8*, i8** %200, align 1
  %202 = icmp eq i8* %201, %0
  br i1 %202, label %205, label %203, !prof !5

203:                                              ; preds = %199
  %204 = ptrtoint i8* %201 to i64
  br label %208

205:                                              ; preds = %199
  tail call void @_ZN7logging8RawCheckEPKc(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.1, i64 0, i64 0)) #12
  %206 = getelementptr inbounds %union.anon, %union.anon* %17, i64 0, i32 0, i32 0
  %207 = load i64, i64* %206, align 1
  br label %208

208:                                              ; preds = %205, %203
  %209 = phi i64 [ %204, %203 ], [ %207, %205 ]
  %210 = tail call i64 @llvm.bswap.i64(i64 %209) #12
  %211 = inttoptr i64 %210 to %"struct.base::internal::EncodedPartitionFreelistEntry"*
  %212 = bitcast i8* %0 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  store %"struct.base::internal::EncodedPartitionFreelistEntry"* %211, %"struct.base::internal::EncodedPartitionFreelistEntry"** %212, align 8
  %213 = xor i64 %210, -1
  %214 = getelementptr inbounds i8, i8* %0, i64 8
  %215 = bitcast i8* %214 to i64*
  store i64 %213, i64* %215, align 8
  store i8* %0, i8** %200, align 1
  %216 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %12, i64 %16, i32 0, i32 1, i64 16
  %217 = bitcast i8* %216 to i16*
  %218 = load i16, i16* %217, align 1
  %219 = add i16 %218, -1
  store i16 %219, i16* %217, align 1
  %220 = icmp slt i16 %219, 1
  br i1 %220, label %221, label %225, !prof !5

221:                                              ; preds = %208
  %222 = tail call { i8*, i64 } @_ZN4base8internal16SlotSpanMetadataILb1EE12FreeSlowPathEv(%"struct.base::internal::SlotSpanMetadata"* %18) #12
  %223 = extractvalue { i8*, i64 } %222, 0
  %224 = extractvalue { i8*, i64 } %222, 1
  br label %225

225:                                              ; preds = %221, %208
  %226 = phi i8* [ %223, %221 ], [ null, %208 ]
  %227 = phi i64 [ %224, %221 ], [ 0, %208 ]
  store i8* %226, i8** %171, align 8
  store i64 %227, i64* %172, align 8
  %228 = atomicrmw xchg i32* %175, i32 0 release
  %229 = icmp eq i32 %228, 2
  br i1 %229, label %230, label %231, !prof !5

230:                                              ; preds = %225
  tail call void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"* %174) #12
  br label %231

231:                                              ; preds = %230, %225
  %232 = load i8*, i8** %171, align 8
  %233 = icmp eq i8* %232, null
  br i1 %233, label %235, label %234, !prof !3

234:                                              ; preds = %231
  call void @_ZN4base8internal13DeferredUnmap5UnmapEv(%"struct.base::internal::DeferredUnmap"* nonnull %2) #12
  br label %235

235:                                              ; preds = %234, %231
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %170) #12
  br label %236

236:                                              ; preds = %1, %92, %93, %96, %163, %168, %235
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN4base8internal21NonScannableAllocator12EnablePCScanEv(%"class.base::internal::NonScannableAllocator"*) local_unnamed_addr #1 align 2 {
  %2 = tail call %"struct.base::internal::PartitionAllocator"* @_ZN4base8internal18MakePCScanMetadataINS0_18PartitionAllocatorILb1EEEJEEEPT_DpOT0_()
  %3 = getelementptr inbounds %"class.base::internal::NonScannableAllocator", %"class.base::internal::NonScannableAllocator"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %4 = load %"struct.base::internal::PartitionAllocator"*, %"struct.base::internal::PartitionAllocator"** %3, align 8
  store %"struct.base::internal::PartitionAllocator"* %2, %"struct.base::internal::PartitionAllocator"** %3, align 8
  %5 = icmp eq %"struct.base::internal::PartitionAllocator"* %4, null
  br i1 %5, label %11, label %6

6:                                                ; preds = %1
  %7 = getelementptr inbounds %"class.base::internal::NonScannableAllocator", %"class.base::internal::NonScannableAllocator"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0
  %8 = bitcast i8* %7 to %"struct.base::internal::PCScanMetadataDeleter"*
  %9 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %4, i64 0, i32 0, i32 0
  tail call void @_ZNK4base8internal21PCScanMetadataDeleterclEPv(%"struct.base::internal::PCScanMetadataDeleter"* %8, i8* %9) #12
  %10 = load %"struct.base::internal::PartitionAllocator"*, %"struct.base::internal::PartitionAllocator"** %3, align 8
  br label %11

11:                                               ; preds = %1, %6
  %12 = phi %"struct.base::internal::PartitionAllocator"* [ %2, %1 ], [ %10, %6 ]
  tail call void @_ZN4base8internal18PartitionAllocatorILb1EE4initENS_16PartitionOptionsE(%"struct.base::internal::PartitionAllocator"* %12, i40 16842752) #12
  %13 = load %"struct.base::internal::PartitionAllocator"*, %"struct.base::internal::PartitionAllocator"** %3, align 8
  %14 = getelementptr inbounds %"struct.base::internal::PartitionAllocator", %"struct.base::internal::PartitionAllocator"* %13, i64 0, i32 0
  tail call void @_ZN4base8internal6PCScan24RegisterNonScannableRootEPNS_13PartitionRootILb1EEE(%"struct.base::PartitionRoot"* %14) #12
  %15 = getelementptr inbounds %"class.base::internal::NonScannableAllocator", %"class.base::internal::NonScannableAllocator"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
  store atomic i8 1, i8* %15 release, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden %"struct.base::internal::PartitionAllocator"* @_ZN4base8internal18MakePCScanMetadataINS0_18PartitionAllocatorILb1EEEJEEEPT_DpOT0_() local_unnamed_addr #1 comdat {
  %1 = alloca i8, align 1
  %2 = alloca i64, align 8
  %3 = tail call dereferenceable(5408) %"struct.base::PartitionRoot"* @_ZN4base8internal23PCScanMetadataAllocatorEv() #12
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %1) #12
  store i8 0, i8* %1, align 1
  %4 = bitcast i64* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %4) #12
  store i64 -6148914691236517206, i64* %2, align 8
  %5 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %3, i64 0, i32 0
  %6 = load i8, i8* %5, align 8
  %7 = icmp eq i8 %6, 2
  br i1 %7, label %8, label %12

8:                                                ; preds = %0
  %9 = load atomic i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0) acquire, align 8
  %10 = icmp eq i8 %9, 2
  br i1 %10, label %11, label %12, !prof !5

11:                                               ; preds = %8
  tail call void @_ZN4base8internal6PCScan8JoinScanEv() #12
  br label %12

12:                                               ; preds = %11, %8, %0
  %13 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %3, i64 0, i32 2
  %14 = load i8, i8* %13, align 2, !range !6
  %15 = icmp eq i8 %14, 0
  br i1 %15, label %161, label %16, !prof !7

16:                                               ; preds = %12
  %17 = load i32, i32* @_ZN4base8internal18g_thread_cache_keyE, align 4
  %18 = tail call i8* @pthread_getspecific(i32 %17) #12
  %19 = bitcast i8* %18 to %"class.base::internal::ThreadCache"*
  %20 = icmp ugt i8* %18, inttoptr (i64 1 to i8*)
  br i1 %20, label %21, label %91, !prof !3

21:                                               ; preds = %16
  %22 = getelementptr inbounds i8, i8* %18, i64 3096
  %23 = bitcast i8* %22 to i64*
  %24 = load i64, i64* %23, align 8
  %25 = add i64 %24, 1
  store i64 %25, i64* %23, align 8
  %26 = getelementptr inbounds i8, i8* %18, i64 1440
  %27 = bitcast i8* %26 to i64*
  %28 = load i64, i64* %27, align 8
  %29 = add i64 %28, 1
  store i64 %29, i64* %27, align 8
  %30 = load i16, i16* @_ZN4base8internal11ThreadCache28largest_active_bucket_index_E, align 2
  %31 = icmp ult i16 %30, 67
  br i1 %31, label %32, label %41, !prof !5

32:                                               ; preds = %21
  %33 = getelementptr inbounds i8, i8* %18, i64 1472
  %34 = bitcast i8* %33 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = add i64 %35, 1
  store i64 %36, i64* %34, align 8
  %37 = getelementptr inbounds i8, i8* %18, i64 1456
  %38 = bitcast i8* %37 to i64*
  %39 = load i64, i64* %38, align 8
  %40 = add i64 %39, 1
  store i64 %40, i64* %38, align 8
  br label %96

41:                                               ; preds = %21
  %42 = getelementptr inbounds i8, i8* %18, i64 1072
  %43 = bitcast i8* %42 to %"class.base::internal::PartitionFreelistEntry"**
  %44 = load %"class.base::internal::PartitionFreelistEntry"*, %"class.base::internal::PartitionFreelistEntry"** %43, align 8
  %45 = icmp eq %"class.base::internal::PartitionFreelistEntry"* %44, null
  br i1 %45, label %51, label %46, !prof !5

46:                                               ; preds = %41
  %47 = getelementptr inbounds i8, i8* %18, i64 1448
  %48 = bitcast i8* %47 to i64*
  %49 = load i64, i64* %48, align 8
  %50 = add i64 %49, 1
  store i64 %50, i64* %48, align 8
  br label %59

51:                                               ; preds = %41
  %52 = getelementptr inbounds i8, i8* %18, i64 1456
  %53 = bitcast i8* %52 to <2 x i64>*
  %54 = load <2 x i64>, <2 x i64>* %53, align 8
  %55 = add <2 x i64> %54, <i64 1, i64 1>
  %56 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %55, <2 x i64>* %56, align 8
  tail call void @_ZN4base8internal11ThreadCache10FillBucketEm(%"class.base::internal::ThreadCache"* %19, i64 67) #12
  %57 = load %"class.base::internal::PartitionFreelistEntry"*, %"class.base::internal::PartitionFreelistEntry"** %43, align 8
  %58 = icmp eq %"class.base::internal::PartitionFreelistEntry"* %57, null
  br i1 %58, label %96, label %59, !prof !5

59:                                               ; preds = %51, %46
  %60 = phi %"class.base::internal::PartitionFreelistEntry"* [ %57, %51 ], [ %44, %46 ]
  %61 = getelementptr inbounds %"class.base::internal::PartitionFreelistEntry", %"class.base::internal::PartitionFreelistEntry"* %60, i64 0, i32 0
  %62 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %61, align 8
  %63 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %62, null
  %64 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %62 to i64
  br i1 %63, label %65, label %67

65:                                               ; preds = %59
  %66 = tail call i64 @llvm.bswap.i64(i64 %64) #12
  br label %76

67:                                               ; preds = %59
  %68 = xor i64 %64, -1
  %69 = getelementptr inbounds %"class.base::internal::PartitionFreelistEntry", %"class.base::internal::PartitionFreelistEntry"* %60, i64 0, i32 1
  %70 = load i64, i64* %69, align 8
  %71 = icmp eq i64 %70, %68
  br i1 %71, label %73, label %72, !prof !3

72:                                               ; preds = %67
  tail call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

73:                                               ; preds = %67
  %74 = tail call i64 @llvm.bswap.i64(i64 %64) #12
  %75 = inttoptr i64 %74 to i8*
  tail call void @llvm.prefetch(i8* nonnull %75, i32 0, i32 3, i32 1) #12
  br label %76

76:                                               ; preds = %73, %65
  %77 = phi i64 [ %66, %65 ], [ %74, %73 ]
  %78 = inttoptr i64 %77 to %"class.base::internal::PartitionFreelistEntry"*
  %79 = getelementptr inbounds i8, i8* %18, i64 1080
  %80 = load i8, i8* %79, align 8
  %81 = add i8 %80, -1
  store i8 %81, i8* %79, align 8
  store %"class.base::internal::PartitionFreelistEntry"* %78, %"class.base::internal::PartitionFreelistEntry"** %43, align 8
  %82 = getelementptr inbounds i8, i8* %18, i64 1082
  %83 = bitcast i8* %82 to i16*
  %84 = load i16, i16* %83, align 2
  %85 = zext i16 %84 to i64
  store i64 %85, i64* %2, align 8
  %86 = getelementptr inbounds i8, i8* %18, i64 1424
  %87 = bitcast i8* %86 to i64*
  %88 = load i64, i64* %87, align 8
  %89 = sub i64 %88, %85
  store i64 %89, i64* %87, align 8
  %90 = bitcast %"class.base::internal::PartitionFreelistEntry"* %60 to i8*
  br label %93

91:                                               ; preds = %16
  %92 = call i8* @_ZN4base13PartitionRootILb1EE28MaybeInitThreadCacheAndAllocEtPm(%"struct.base::PartitionRoot"* %3, i16 zeroext 67, i64* nonnull %2) #12
  br label %93

93:                                               ; preds = %91, %76
  %94 = phi i8* [ %92, %91 ], [ %90, %76 ]
  %95 = icmp eq i8* %94, null
  br i1 %95, label %96, label %229, !prof !5

96:                                               ; preds = %93, %51, %32
  %97 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %3, i64 0, i32 10, i64 67
  %98 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %3, i64 0, i32 8
  %99 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %98, i64 0, i32 0
  %100 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %98, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %101

101:                                              ; preds = %113, %96
  %102 = phi i32 [ 0, %96 ], [ %114, %113 ]
  %103 = phi i32 [ 1, %96 ], [ %117, %113 ]
  %104 = load atomic i32, i32* %100 monotonic, align 4
  %105 = icmp eq i32 %104, 0
  br i1 %105, label %106, label %109, !prof !8

106:                                              ; preds = %101
  %107 = cmpxchg weak i32* %100, i32 0, i32 1 acquire monotonic
  %108 = extractvalue { i32, i1 } %107, 1
  br i1 %108, label %124, label %109, !prof !3

109:                                              ; preds = %106, %101
  %110 = icmp sgt i32 %103, 0
  br i1 %110, label %119, label %113

111:                                              ; preds = %119
  %112 = add i32 %103, %102
  br label %113

113:                                              ; preds = %111, %109
  %114 = phi i32 [ %102, %109 ], [ %112, %111 ]
  %115 = shl i32 %103, 1
  %116 = icmp slt i32 %115, 64
  %117 = select i1 %116, i32 %115, i32 64
  %118 = icmp slt i32 %114, 1000
  br i1 %118, label %101, label %123

119:                                              ; preds = %109, %119
  %120 = phi i32 [ %121, %119 ], [ 0, %109 ]
  call void asm sideeffect "pause", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !9
  %121 = add nuw nsw i32 %120, 1
  %122 = icmp eq i32 %121, %103
  br i1 %122, label %111, label %119

123:                                              ; preds = %113
  call void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"* %99) #12
  br label %124

124:                                              ; preds = %106, %123
  %125 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %97, i64 0, i32 0
  %126 = load %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::SlotSpanMetadata"** %125, align 8
  %127 = bitcast %"struct.base::internal::SlotSpanMetadata"* %126 to i8**
  %128 = load i8*, i8** %127, align 1
  %129 = icmp eq i8* %128, null
  br i1 %129, label %154, label %130, !prof !5

130:                                              ; preds = %124
  %131 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %126, i64 0, i32 0
  store i8 0, i8* %1, align 1
  %132 = bitcast i8* %128 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  %133 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %132, align 8
  %134 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %133, null
  %135 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %133 to i64
  br i1 %134, label %136, label %138

136:                                              ; preds = %130
  %137 = call i64 @llvm.bswap.i64(i64 %135) #12
  br label %148

138:                                              ; preds = %130
  %139 = xor i64 %135, -1
  %140 = getelementptr inbounds i8, i8* %128, i64 8
  %141 = bitcast i8* %140 to i64*
  %142 = load i64, i64* %141, align 8
  %143 = icmp eq i64 %142, %139
  br i1 %143, label %145, label %144, !prof !3

144:                                              ; preds = %138
  call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

145:                                              ; preds = %138
  %146 = call i64 @llvm.bswap.i64(i64 %135) #12
  %147 = inttoptr i64 %146 to i8*
  call void @llvm.prefetch(i8* nonnull %147, i32 0, i32 3, i32 1) #12
  br label %148

148:                                              ; preds = %145, %136
  %149 = phi i64 [ %137, %136 ], [ %146, %145 ]
  %150 = inttoptr i64 %149 to %"class.base::internal::PartitionFreelistEntry"*
  store %"class.base::internal::PartitionFreelistEntry"* %150, %"class.base::internal::PartitionFreelistEntry"** %131, align 1
  %151 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %126, i64 0, i32 3
  %152 = load i16, i16* %151, align 1
  %153 = add i16 %152, 1
  store i16 %153, i16* %151, align 1
  br label %156

154:                                              ; preds = %124
  %155 = call i8* @_ZN4base8internal15PartitionBucketILb1EE13SlowPathAllocEPNS_13PartitionRootILb1EEEimmPb(%"struct.base::internal::PartitionBucket"* %97, %"struct.base::PartitionRoot"* %3, i32 0, i64 5408, i64 16384, i8* nonnull %1) #12
  br label %156

156:                                              ; preds = %154, %148
  %157 = phi i8* [ %128, %148 ], [ %155, %154 ]
  %158 = atomicrmw xchg i32* %100, i32 0 release
  %159 = icmp eq i32 %158, 2
  br i1 %159, label %160, label %226, !prof !5

160:                                              ; preds = %156
  call void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"* %99) #12
  br label %226

161:                                              ; preds = %12
  %162 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %3, i64 0, i32 10, i64 67
  %163 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %3, i64 0, i32 8
  %164 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %163, i64 0, i32 0
  %165 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %163, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %166

166:                                              ; preds = %178, %161
  %167 = phi i32 [ 0, %161 ], [ %179, %178 ]
  %168 = phi i32 [ 1, %161 ], [ %182, %178 ]
  %169 = load atomic i32, i32* %165 monotonic, align 4
  %170 = icmp eq i32 %169, 0
  br i1 %170, label %171, label %174, !prof !8

171:                                              ; preds = %166
  %172 = cmpxchg weak i32* %165, i32 0, i32 1 acquire monotonic
  %173 = extractvalue { i32, i1 } %172, 1
  br i1 %173, label %189, label %174, !prof !3

174:                                              ; preds = %171, %166
  %175 = icmp sgt i32 %168, 0
  br i1 %175, label %184, label %178

176:                                              ; preds = %184
  %177 = add i32 %168, %167
  br label %178

178:                                              ; preds = %176, %174
  %179 = phi i32 [ %167, %174 ], [ %177, %176 ]
  %180 = shl i32 %168, 1
  %181 = icmp slt i32 %180, 64
  %182 = select i1 %181, i32 %180, i32 64
  %183 = icmp slt i32 %179, 1000
  br i1 %183, label %166, label %188

184:                                              ; preds = %174, %184
  %185 = phi i32 [ %186, %184 ], [ 0, %174 ]
  tail call void asm sideeffect "pause", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !9
  %186 = add nuw nsw i32 %185, 1
  %187 = icmp eq i32 %186, %168
  br i1 %187, label %176, label %184

188:                                              ; preds = %178
  tail call void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"* %164) #12
  br label %189

189:                                              ; preds = %171, %188
  %190 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %162, i64 0, i32 0
  %191 = load %"struct.base::internal::SlotSpanMetadata"*, %"struct.base::internal::SlotSpanMetadata"** %190, align 8
  %192 = bitcast %"struct.base::internal::SlotSpanMetadata"* %191 to i8**
  %193 = load i8*, i8** %192, align 1
  %194 = icmp eq i8* %193, null
  br i1 %194, label %219, label %195, !prof !5

195:                                              ; preds = %189
  %196 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %191, i64 0, i32 0
  store i8 0, i8* %1, align 1
  %197 = bitcast i8* %193 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  %198 = load %"struct.base::internal::EncodedPartitionFreelistEntry"*, %"struct.base::internal::EncodedPartitionFreelistEntry"** %197, align 8
  %199 = icmp eq %"struct.base::internal::EncodedPartitionFreelistEntry"* %198, null
  %200 = ptrtoint %"struct.base::internal::EncodedPartitionFreelistEntry"* %198 to i64
  br i1 %199, label %201, label %203

201:                                              ; preds = %195
  %202 = tail call i64 @llvm.bswap.i64(i64 %200) #12
  br label %213

203:                                              ; preds = %195
  %204 = xor i64 %200, -1
  %205 = getelementptr inbounds i8, i8* %193, i64 8
  %206 = bitcast i8* %205 to i64*
  %207 = load i64, i64* %206, align 8
  %208 = icmp eq i64 %207, %204
  br i1 %208, label %210, label %209, !prof !3

209:                                              ; preds = %203
  tail call fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() #13
  unreachable

210:                                              ; preds = %203
  %211 = tail call i64 @llvm.bswap.i64(i64 %200) #12
  %212 = inttoptr i64 %211 to i8*
  tail call void @llvm.prefetch(i8* nonnull %212, i32 0, i32 3, i32 1) #12
  br label %213

213:                                              ; preds = %210, %201
  %214 = phi i64 [ %202, %201 ], [ %211, %210 ]
  %215 = inttoptr i64 %214 to %"class.base::internal::PartitionFreelistEntry"*
  store %"class.base::internal::PartitionFreelistEntry"* %215, %"class.base::internal::PartitionFreelistEntry"** %196, align 1
  %216 = getelementptr inbounds %"struct.base::internal::SlotSpanMetadata", %"struct.base::internal::SlotSpanMetadata"* %191, i64 0, i32 3
  %217 = load i16, i16* %216, align 1
  %218 = add i16 %217, 1
  store i16 %218, i16* %216, align 1
  br label %221

219:                                              ; preds = %189
  %220 = call i8* @_ZN4base8internal15PartitionBucketILb1EE13SlowPathAllocEPNS_13PartitionRootILb1EEEimmPb(%"struct.base::internal::PartitionBucket"* %162, %"struct.base::PartitionRoot"* %3, i32 0, i64 5408, i64 16384, i8* nonnull %1) #12
  br label %221

221:                                              ; preds = %219, %213
  %222 = phi i8* [ %193, %213 ], [ %220, %219 ]
  %223 = atomicrmw xchg i32* %165, i32 0 release
  %224 = icmp eq i32 %223, 2
  br i1 %224, label %225, label %226, !prof !5

225:                                              ; preds = %221
  call void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"* %164) #12
  br label %226

226:                                              ; preds = %225, %221, %160, %156
  %227 = phi i8* [ %157, %156 ], [ %157, %160 ], [ %222, %221 ], [ %222, %225 ]
  %228 = icmp eq i8* %227, null
  br i1 %228, label %231, label %229, !prof !5

229:                                              ; preds = %93, %226
  %230 = phi i8* [ %227, %226 ], [ %94, %93 ]
  br label %231

231:                                              ; preds = %226, %229
  %232 = phi i8* [ null, %226 ], [ %230, %229 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %4) #12
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %1) #12
  %233 = bitcast i8* %232 to %"struct.base::internal::PartitionAllocator"*
  %234 = getelementptr inbounds i8, i8* %232, i64 3
  call void @llvm.memset.p0i8.i64(i8* align 8 %232, i8 0, i64 5408, i1 false)
  store i8 1, i8* %234, align 1
  %235 = getelementptr inbounds i8, i8* %232, i64 8
  %236 = bitcast i8* %235 to i32*
  store i32 0, i32* %236, align 4
  %237 = getelementptr i8, i8* %232, i64 16
  call void @llvm.memset.p0i8.i64(i8* align 8 %237, i8 0, i64 5120, i1 false) #12
  %238 = getelementptr inbounds i8, i8* %232, i64 5176
  store i8 0, i8* %238, align 8
  %239 = getelementptr inbounds i8, i8* %232, i64 5184
  %240 = getelementptr inbounds i8, i8* %232, i64 5392
  %241 = bitcast i8* %240 to i64*
  store i64 0, i64* %241, align 8
  %242 = getelementptr inbounds i8, i8* %232, i64 5400
  %243 = bitcast i8* %242 to i32*
  store i32 0, i32* %243, align 4
  call void @llvm.memset.p0i8.i64(i8* align 8 %239, i8 0, i64 202, i1 false) #12
  ret %"struct.base::internal::PartitionAllocator"* %233
}

declare void @_ZN4base8internal18PartitionAllocatorILb1EE4initENS_16PartitionOptionsE(%"struct.base::internal::PartitionAllocator"*, i40) local_unnamed_addr #4

declare void @_ZN4base8internal6PCScan24RegisterNonScannableRootEPNS_13PartitionRootILb1EEE(%"struct.base::PartitionRoot"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden i8* @_ZN4base17AllocNonScannableEm(i64) local_unnamed_addr #1 {
  %2 = load atomic i8, i8* bitcast (i64* @_ZGVZN4base8internal21NonScannableAllocator8InstanceEvE8instance to i8*) acquire, align 8
  %3 = icmp eq i8 %2, 0
  br i1 %3, label %4, label %8, !prof !2

4:                                                ; preds = %1
  %5 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN4base8internal21NonScannableAllocator8InstanceEvE8instance) #12
  %6 = icmp eq i32 %5, 0
  br i1 %6, label %8, label %7

7:                                                ; preds = %4
  store i64 0, i64* bitcast (%"class.base::NoDestructor"* @_ZZN4base8internal21NonScannableAllocator8InstanceEvE8instance to i64*), align 8
  store i8 0, i8* getelementptr inbounds (%"class.base::NoDestructor", %"class.base::NoDestructor"* @_ZZN4base8internal21NonScannableAllocator8InstanceEvE8instance, i64 0, i32 0, i64 16), align 8
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN4base8internal21NonScannableAllocator8InstanceEvE8instance) #12
  br label %8

8:                                                ; preds = %1, %4, %7
  %9 = tail call i8* @_ZN4base8internal21NonScannableAllocator5AllocEm(%"class.base::internal::NonScannableAllocator"* bitcast (%"class.base::NoDestructor"* @_ZZN4base8internal21NonScannableAllocator8InstanceEvE8instance to %"class.base::internal::NonScannableAllocator"*), i64 %0)
  ret i8* %9
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN4base16FreeNonScannableEPv(i8*) local_unnamed_addr #1 {
  tail call void @_ZN4base8internal21NonScannableAllocator4FreeEPv(i8* %0)
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #5

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #5

declare void @_ZN7logging8RawCheckEPKc(i8*) local_unnamed_addr #4

declare i8* @_ZN4base13PartitionRootILb1EE28MaybeInitThreadCacheAndAllocEtPm(%"struct.base::PartitionRoot"*, i16 zeroext, i64*) local_unnamed_addr #4

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #5

; Function Attrs: nounwind readnone speculatable
declare i64 @llvm.ctlz.i64(i64, i1 immarg) #6

declare void @_ZN4base8internal6PCScan8JoinScanEv() local_unnamed_addr #4

; Function Attrs: nounwind
declare i8* @pthread_getspecific(i32) local_unnamed_addr #7

declare void @_ZN4base8internal11ThreadCache10FillBucketEm(%"class.base::internal::ThreadCache"*, i64) local_unnamed_addr #4

; Function Attrs: noinline noreturn nounwind ssp uwtable
define internal fastcc void @_ZN4base8internal12_GLOBAL__N_126FreelistCorruptionDetectedEv() unnamed_addr #8 {
  tail call void asm sideeffect "int3", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !10
  tail call void asm sideeffect "ud2", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !11
  unreachable
}

; Function Attrs: inaccessiblemem_or_argmemonly nounwind
declare void @llvm.prefetch(i8* nocapture readonly, i32 immarg, i32 immarg, i32) #9

; Function Attrs: nounwind readnone speculatable
declare i64 @llvm.bswap.i64(i64) #6

declare void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"*) local_unnamed_addr #4

declare i8* @_ZN4base8internal15PartitionBucketILb1EE13SlowPathAllocEPNS_13PartitionRootILb1EEEimmPb(%"struct.base::internal::PartitionBucket"*, %"struct.base::PartitionRoot"*, i32, i64, i64, i8*) local_unnamed_addr #4

declare void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"*) local_unnamed_addr #4

; Function Attrs: noreturn
declare void @_ZN4base8internal17DoubleFreeAttemptEv() local_unnamed_addr #10

declare void @_ZN4base8internal6PCScan11PerformScanENS1_14InvocationModeE(%"class.base::internal::PCScan"*, i32) local_unnamed_addr #4

declare void @_ZN4base8internal11ThreadCache11ClearBucketERNS1_6BucketEm(%"class.base::internal::ThreadCache"*, %"struct.base::internal::ThreadCache::Bucket"* dereferenceable(16), i64) local_unnamed_addr #4

declare void @_ZN4base8internal11ThreadCache13PurgeInternalEv(%"class.base::internal::ThreadCache"*) local_unnamed_addr #4

declare { i8*, i64 } @_ZN4base8internal16SlotSpanMetadataILb1EE12FreeSlowPathEv(%"struct.base::internal::SlotSpanMetadata"*) local_unnamed_addr #4

declare void @_ZN4base8internal13DeferredUnmap5UnmapEv(%"struct.base::internal::DeferredUnmap"*) local_unnamed_addr #4

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK4base8internal21PCScanMetadataDeleterclEPv(%"struct.base::internal::PCScanMetadataDeleter"*, i8*) local_unnamed_addr #11 comdat align 2 {
  %3 = alloca %"struct.base::internal::DeferredUnmap", align 8
  %4 = tail call dereferenceable(5408) %"struct.base::PartitionRoot"* @_ZN4base8internal23PCScanMetadataAllocatorEv() #12
  %5 = icmp eq i8* %1, null
  br i1 %5, label %238, label %6, !prof !5

6:                                                ; preds = %2
  tail call void @llvm.prefetch(i8* nonnull %1, i32 0, i32 3, i32 1) #12
  %7 = ptrtoint i8* %1 to i64
  %8 = and i64 %7, -2097152
  %9 = or i64 %8, 4096
  %10 = inttoptr i64 %9 to i8*
  %11 = lshr i64 %7, 9
  %12 = and i64 %11, 4064
  %13 = getelementptr inbounds i8, i8* %10, i64 %12
  %14 = bitcast i8* %13 to %"struct.base::internal::PartitionPage"*
  %15 = getelementptr inbounds i8, i8* %13, i64 30
  %16 = load i8, i8* %15, align 2
  %17 = zext i8 %16 to i64
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %14, i64 %18, i32 0
  %20 = bitcast %union.anon* %19 to %"struct.base::internal::SlotSpanMetadata"*
  %21 = bitcast %union.anon* %19 to i8*
  tail call void @llvm.prefetch(i8* %21, i32 0, i32 3, i32 1) #12
  %22 = ptrtoint %union.anon* %19 to i64
  %23 = and i64 %22, -4096
  %24 = inttoptr i64 %23 to %"struct.base::internal::PartitionSuperPageExtentEntry"*
  %25 = getelementptr inbounds %"struct.base::internal::PartitionSuperPageExtentEntry", %"struct.base::internal::PartitionSuperPageExtentEntry"* %24, i64 0, i32 0
  %26 = load %"struct.base::PartitionRoot"*, %"struct.base::PartitionRoot"** %25, align 4096
  %27 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %26, i64 0, i32 0
  %28 = load i8, i8* %27, align 8
  %29 = icmp eq i8 %28, 2
  br i1 %29, label %30, label %99, !prof !5

30:                                               ; preds = %6
  %31 = load atomic i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0) acquire, align 8
  %32 = icmp eq i8 %31, 2
  br i1 %32, label %33, label %34, !prof !5

33:                                               ; preds = %30
  tail call void @_ZN4base8internal6PCScan8JoinScanEv() #12
  br label %34

34:                                               ; preds = %33, %30
  %35 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %14, i64 %18, i32 0, i32 1, i64 8
  %36 = bitcast i8* %35 to %"struct.base::internal::PartitionBucket"**
  %37 = load %"struct.base::internal::PartitionBucket"*, %"struct.base::internal::PartitionBucket"** %36, align 1
  %38 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %26, i64 0, i32 10, i64 0
  %39 = icmp ugt %"struct.base::internal::PartitionBucket"* %38, %37
  %40 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %26, i64 0, i32 11
  %41 = icmp ult %"struct.base::internal::PartitionBucket"* %40, %37
  %42 = or i1 %39, %41
  br i1 %42, label %99, label %43, !prof !5

43:                                               ; preds = %34
  %44 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %14, i64 %18, i32 0, i32 1, i64 21
  %45 = load i8, i8* %44, align 1, !range !6
  %46 = icmp eq i8 %45, 0
  br i1 %46, label %47, label %51, !prof !3

47:                                               ; preds = %43
  %48 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %37, i64 0, i32 3
  %49 = load i32, i32* %48, align 8
  %50 = zext i32 %49 to i64
  br label %58

51:                                               ; preds = %43
  %52 = bitcast %union.anon* %19 to %"struct.base::internal::PartitionPage"*
  %53 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %52, i64 1, i32 0, i32 0, i32 0
  %54 = load i64, i64* %53, align 1
  %55 = getelementptr inbounds %"struct.base::internal::PartitionBucket", %"struct.base::internal::PartitionBucket"* %37, i64 0, i32 3
  %56 = load i32, i32* %55, align 8
  %57 = zext i32 %56 to i64
  br label %58

58:                                               ; preds = %51, %47
  %59 = phi i64 [ %50, %47 ], [ %57, %51 ]
  %60 = phi i64 [ %50, %47 ], [ %54, %51 ]
  %61 = load atomic i64, i64* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0) monotonic, align 8
  %62 = inttoptr i64 %8 to i8*
  %63 = and i64 %61, 1
  %64 = icmp eq i64 %63, 0
  %65 = select i1 %64, i64 16384, i64 32768
  %66 = getelementptr inbounds i8, i8* %62, i64 %65
  %67 = bitcast i8* %66 to %"class.base::internal::ObjectBitmap"*
  %68 = lshr i64 %7, 4
  %69 = lshr i64 %7, 10
  %70 = and i64 %69, 2047
  %71 = and i64 %68, 63
  %72 = shl i64 1, %71
  %73 = getelementptr inbounds %"class.base::internal::ObjectBitmap", %"class.base::internal::ObjectBitmap"* %67, i64 0, i32 0, i32 0, i64 %70
  %74 = atomicrmw or i64* %73, i64 %72 monotonic
  %75 = and i64 %74, %72
  %76 = icmp eq i64 %75, 0
  br i1 %76, label %78, label %77, !prof !3

77:                                               ; preds = %58
  notail call void @_ZN4base8internal17DoubleFreeAttemptEv() #13
  unreachable

78:                                               ; preds = %58
  %79 = atomicrmw add i64* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), i64 %59 monotonic
  %80 = add i64 %79, %59
  %81 = load atomic i64, i64* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) monotonic, align 8
  %82 = icmp ugt i64 %80, %81
  br i1 %82, label %83, label %89

83:                                               ; preds = %78
  %84 = load %"class.base::internal::PCScanSchedulingBackend"*, %"class.base::internal::PCScanSchedulingBackend"** getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 0, i32 2), align 8
  %85 = bitcast %"class.base::internal::PCScanSchedulingBackend"* %84 to i1 (%"class.base::internal::PCScanSchedulingBackend"*)***
  %86 = load i1 (%"class.base::internal::PCScanSchedulingBackend"*)**, i1 (%"class.base::internal::PCScanSchedulingBackend"*)*** %85, align 8
  %87 = load i1 (%"class.base::internal::PCScanSchedulingBackend"*)*, i1 (%"class.base::internal::PCScanSchedulingBackend"*)** %86, align 8
  %88 = tail call zeroext i1 %87(%"class.base::internal::PCScanSchedulingBackend"* %84) #12
  br label %89

89:                                               ; preds = %83, %78
  %90 = phi i1 [ false, %78 ], [ %88, %83 ]
  %91 = load i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 2), align 1
  %92 = icmp eq i8 %91, 1
  br i1 %92, label %93, label %94

93:                                               ; preds = %89
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %1, i8 0, i64 %60, i1 false) #12
  br label %94

94:                                               ; preds = %93, %89
  br i1 %90, label %95, label %238, !prof !5

95:                                               ; preds = %94
  %96 = load atomic i8, i8* getelementptr inbounds (%"class.base::internal::PCScan", %"class.base::internal::PCScan"* @_ZN4base8internal6PCScan9instance_E, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0) monotonic, align 8
  %97 = icmp eq i8 %96, 0
  br i1 %97, label %98, label %238

98:                                               ; preds = %95
  tail call void @_ZN4base8internal6PCScan11PerformScanENS1_14InvocationModeE(%"class.base::internal::PCScan"* nonnull @_ZN4base8internal6PCScan9instance_E, i32 1) #12
  br label %238

99:                                               ; preds = %34, %6
  %100 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %26, i64 0, i32 2
  %101 = load i8, i8* %100, align 2, !range !6
  %102 = icmp eq i8 %101, 0
  br i1 %102, label %171, label %103, !prof !5

103:                                              ; preds = %99
  %104 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %14, i64 %18, i32 0, i32 1, i64 8
  %105 = bitcast i8* %104 to %"struct.base::internal::PartitionBucket"**
  %106 = load %"struct.base::internal::PartitionBucket"*, %"struct.base::internal::PartitionBucket"** %105, align 1
  %107 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %26, i64 0, i32 10, i64 0
  %108 = icmp ule %"struct.base::internal::PartitionBucket"* %107, %106
  %109 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %26, i64 0, i32 11
  %110 = icmp uge %"struct.base::internal::PartitionBucket"* %109, %106
  %111 = and i1 %110, %108
  %112 = ptrtoint %"struct.base::internal::PartitionBucket"* %106 to i64
  br i1 %111, label %113, label %171, !prof !3

113:                                              ; preds = %103
  %114 = load i32, i32* @_ZN4base8internal18g_thread_cache_keyE, align 4
  %115 = tail call i8* @pthread_getspecific(i32 %114) #12
  %116 = bitcast i8* %115 to %"class.base::internal::ThreadCache"*
  %117 = icmp ugt i8* %115, inttoptr (i64 1 to i8*)
  br i1 %117, label %118, label %171, !prof !3

118:                                              ; preds = %113
  %119 = ptrtoint %"struct.base::internal::PartitionBucket"* %107 to i64
  %120 = sub i64 %112, %119
  %121 = sdiv exact i64 %120, 40
  %122 = getelementptr inbounds i8, i8* %115, i64 1480
  %123 = bitcast i8* %122 to i64*
  %124 = load i64, i64* %123, align 8
  %125 = add i64 %124, 1
  store i64 %125, i64* %123, align 8
  %126 = load i16, i16* @_ZN4base8internal11ThreadCache28largest_active_bucket_index_E, align 2
  %127 = zext i16 %126 to i64
  %128 = icmp ugt i64 %121, %127
  br i1 %128, label %129, label %134, !prof !5

129:                                              ; preds = %118
  %130 = getelementptr inbounds i8, i8* %115, i64 1496
  %131 = bitcast i8* %130 to i64*
  %132 = load i64, i64* %131, align 8
  %133 = add i64 %132, 1
  store i64 %133, i64* %131, align 8
  br label %171

134:                                              ; preds = %118
  %135 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %116, i64 0, i32 0, i64 %121
  %136 = bitcast %"struct.base::internal::ThreadCache::Bucket"* %135 to i64*
  %137 = load i64, i64* %136, align 8
  %138 = tail call i64 @llvm.bswap.i64(i64 %137) #12
  %139 = inttoptr i64 %138 to %"struct.base::internal::EncodedPartitionFreelistEntry"*
  %140 = bitcast i8* %1 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  store %"struct.base::internal::EncodedPartitionFreelistEntry"* %139, %"struct.base::internal::EncodedPartitionFreelistEntry"** %140, align 8
  %141 = xor i64 %138, -1
  %142 = getelementptr inbounds i8, i8* %1, i64 8
  %143 = bitcast i8* %142 to i64*
  store i64 %141, i64* %143, align 8
  %144 = bitcast %"struct.base::internal::ThreadCache::Bucket"* %135 to i8**
  store i8* %1, i8** %144, align 8
  %145 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %116, i64 0, i32 0, i64 %121, i32 1
  %146 = load i8, i8* %145, align 8
  %147 = add i8 %146, 1
  store i8 %147, i8* %145, align 8
  %148 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %116, i64 0, i32 0, i64 %121, i32 3
  %149 = load i16, i16* %148, align 2
  %150 = zext i16 %149 to i64
  %151 = getelementptr inbounds i8, i8* %115, i64 1424
  %152 = bitcast i8* %151 to i64*
  %153 = load i64, i64* %152, align 8
  %154 = add i64 %153, %150
  store i64 %154, i64* %152, align 8
  %155 = getelementptr inbounds i8, i8* %115, i64 1488
  %156 = bitcast i8* %155 to i64*
  %157 = load i64, i64* %156, align 8
  %158 = add i64 %157, 1
  store i64 %158, i64* %156, align 8
  %159 = getelementptr inbounds %"class.base::internal::ThreadCache", %"class.base::internal::ThreadCache"* %116, i64 0, i32 0, i64 %121, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %160 = load atomic i8, i8* %159 monotonic, align 1
  %161 = icmp ugt i8 %147, %160
  br i1 %161, label %162, label %165, !prof !5

162:                                              ; preds = %134
  %163 = lshr i8 %160, 1
  %164 = zext i8 %163 to i64
  tail call void @_ZN4base8internal11ThreadCache11ClearBucketERNS1_6BucketEm(%"class.base::internal::ThreadCache"* %116, %"struct.base::internal::ThreadCache::Bucket"* dereferenceable(16) %135, i64 %164) #12
  br label %165

165:                                              ; preds = %162, %134
  %166 = getelementptr inbounds i8, i8* %115, i64 1432
  %167 = load atomic i8, i8* %166 monotonic, align 1
  %168 = and i8 %167, 1
  %169 = icmp eq i8 %168, 0
  br i1 %169, label %238, label %170, !prof !3

170:                                              ; preds = %165
  tail call void @_ZN4base8internal11ThreadCache13PurgeInternalEv(%"class.base::internal::ThreadCache"* %116) #12
  br label %238

171:                                              ; preds = %129, %113, %103, %99
  %172 = bitcast %"struct.base::internal::DeferredUnmap"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %172) #12
  %173 = getelementptr inbounds %"struct.base::internal::DeferredUnmap", %"struct.base::internal::DeferredUnmap"* %3, i64 0, i32 0
  %174 = getelementptr inbounds %"struct.base::internal::DeferredUnmap", %"struct.base::internal::DeferredUnmap"* %3, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %172, i8 0, i64 16, i1 false) #12
  %175 = getelementptr inbounds %"struct.base::PartitionRoot", %"struct.base::PartitionRoot"* %26, i64 0, i32 8
  %176 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %175, i64 0, i32 0
  %177 = getelementptr inbounds %"class.base::internal::MaybeSpinLock", %"class.base::internal::MaybeSpinLock"* %175, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %178

178:                                              ; preds = %190, %171
  %179 = phi i32 [ 0, %171 ], [ %191, %190 ]
  %180 = phi i32 [ 1, %171 ], [ %194, %190 ]
  %181 = load atomic i32, i32* %177 monotonic, align 4
  %182 = icmp eq i32 %181, 0
  br i1 %182, label %183, label %186, !prof !8

183:                                              ; preds = %178
  %184 = cmpxchg weak i32* %177, i32 0, i32 1 acquire monotonic
  %185 = extractvalue { i32, i1 } %184, 1
  br i1 %185, label %201, label %186, !prof !3

186:                                              ; preds = %183, %178
  %187 = icmp sgt i32 %180, 0
  br i1 %187, label %196, label %190

188:                                              ; preds = %196
  %189 = add i32 %180, %179
  br label %190

190:                                              ; preds = %188, %186
  %191 = phi i32 [ %179, %186 ], [ %189, %188 ]
  %192 = shl i32 %180, 1
  %193 = icmp slt i32 %192, 64
  %194 = select i1 %193, i32 %192, i32 64
  %195 = icmp slt i32 %191, 1000
  br i1 %195, label %178, label %200

196:                                              ; preds = %186, %196
  %197 = phi i32 [ %198, %196 ], [ 0, %186 ]
  tail call void asm sideeffect "pause", "~{dirflag},~{fpsr},~{flags}"() #12, !srcloc !9
  %198 = add nuw nsw i32 %197, 1
  %199 = icmp eq i32 %198, %180
  br i1 %199, label %188, label %196

200:                                              ; preds = %190
  tail call void @_ZN4base8internal13SpinningMutex8LockSlowEv(%"class.base::internal::SpinningMutex"* %176) #12
  br label %201

201:                                              ; preds = %183, %200
  %202 = bitcast %union.anon* %19 to i8**
  %203 = load i8*, i8** %202, align 1
  %204 = icmp eq i8* %203, %1
  br i1 %204, label %207, label %205, !prof !5

205:                                              ; preds = %201
  %206 = ptrtoint i8* %203 to i64
  br label %210

207:                                              ; preds = %201
  tail call void @_ZN7logging8RawCheckEPKc(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.1, i64 0, i64 0)) #12
  %208 = getelementptr inbounds %union.anon, %union.anon* %19, i64 0, i32 0, i32 0
  %209 = load i64, i64* %208, align 1
  br label %210

210:                                              ; preds = %207, %205
  %211 = phi i64 [ %206, %205 ], [ %209, %207 ]
  %212 = tail call i64 @llvm.bswap.i64(i64 %211) #12
  %213 = inttoptr i64 %212 to %"struct.base::internal::EncodedPartitionFreelistEntry"*
  %214 = bitcast i8* %1 to %"struct.base::internal::EncodedPartitionFreelistEntry"**
  store %"struct.base::internal::EncodedPartitionFreelistEntry"* %213, %"struct.base::internal::EncodedPartitionFreelistEntry"** %214, align 8
  %215 = xor i64 %212, -1
  %216 = getelementptr inbounds i8, i8* %1, i64 8
  %217 = bitcast i8* %216 to i64*
  store i64 %215, i64* %217, align 8
  store i8* %1, i8** %202, align 1
  %218 = getelementptr inbounds %"struct.base::internal::PartitionPage", %"struct.base::internal::PartitionPage"* %14, i64 %18, i32 0, i32 1, i64 16
  %219 = bitcast i8* %218 to i16*
  %220 = load i16, i16* %219, align 1
  %221 = add i16 %220, -1
  store i16 %221, i16* %219, align 1
  %222 = icmp slt i16 %221, 1
  br i1 %222, label %223, label %227, !prof !5

223:                                              ; preds = %210
  %224 = tail call { i8*, i64 } @_ZN4base8internal16SlotSpanMetadataILb1EE12FreeSlowPathEv(%"struct.base::internal::SlotSpanMetadata"* %20) #12
  %225 = extractvalue { i8*, i64 } %224, 0
  %226 = extractvalue { i8*, i64 } %224, 1
  br label %227

227:                                              ; preds = %223, %210
  %228 = phi i8* [ %225, %223 ], [ null, %210 ]
  %229 = phi i64 [ %226, %223 ], [ 0, %210 ]
  store i8* %228, i8** %173, align 8
  store i64 %229, i64* %174, align 8
  %230 = atomicrmw xchg i32* %177, i32 0 release
  %231 = icmp eq i32 %230, 2
  br i1 %231, label %232, label %233, !prof !5

232:                                              ; preds = %227
  tail call void @_ZN4base8internal13SpinningMutex9FutexWakeEv(%"class.base::internal::SpinningMutex"* %176) #12
  br label %233

233:                                              ; preds = %232, %227
  %234 = load i8*, i8** %173, align 8
  %235 = icmp eq i8* %234, null
  br i1 %235, label %237, label %236, !prof !3

236:                                              ; preds = %233
  call void @_ZN4base8internal13DeferredUnmap5UnmapEv(%"struct.base::internal::DeferredUnmap"* nonnull %3) #12
  br label %237

237:                                              ; preds = %236, %233
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %172) #12
  br label %238

238:                                              ; preds = %2, %94, %95, %98, %165, %170, %237
  ret void
}

declare dereferenceable(5408) %"struct.base::PartitionRoot"* @_ZN4base8internal23PCScanMetadataAllocatorEv() local_unnamed_addr #4

attributes #0 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree nounwind }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { argmemonly nounwind }
attributes #6 = { nounwind readnone speculatable }
attributes #7 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { noinline noreturn nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { inaccessiblemem_or_argmemonly nounwind }
attributes #10 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { nounwind }
attributes #13 = { noreturn nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!"branch_weights", i32 1, i32 1048575}
!3 = !{!"branch_weights", i32 2000, i32 1}
!4 = !{i64 0, i64 65}
!5 = !{!"branch_weights", i32 1, i32 2000}
!6 = !{i8 0, i8 2}
!7 = !{!"branch_weights", i32 4001, i32 4000000}
!8 = !{!"branch_weights", i32 2146410443, i32 1073205}
!9 = !{i32 -2142404432}
!10 = !{i32 -2142443005}
!11 = !{i32 -2142442984}
