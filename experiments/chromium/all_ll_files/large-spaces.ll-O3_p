; ModuleID = '../../v8/src/heap/large-spaces.cc'
source_filename = "../../v8/src/heap/large-spaces.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"struct.std::__1::piecewise_construct_t" = type { i8 }
%"class.v8::internal::LargeObjectSpaceObjectIterator" = type { %"class.v8::internal::ObjectIterator", %"class.v8::internal::LargePage"* }
%"class.v8::internal::ObjectIterator" = type { i32 (...)** }
%"class.v8::internal::LargePage" = type { %"class.v8::internal::MemoryChunk" }
%"class.v8::internal::MemoryChunk" = type { %"class.v8::internal::BasicMemoryChunk", [2 x %"class.v8::internal::SlotSet"*], %"struct.std::__1::atomic", %"struct.std::__1::atomic.15", %"class.v8::internal::SlotSet"*, [2 x %"class.v8::internal::TypedSlotSet"*], [2 x %"class.std::__1::set.617"*], %"class.v8::base::Mutex"*, %"struct.std::__1::atomic.625", %"class.v8::base::Mutex"*, i64, [2 x %"struct.std::__1::atomic"], %"class.v8::internal::heap::ListNode", %"class.v8::internal::FreeListCategory"**, %"struct.std::__1::atomic.15", %"class.v8::internal::Bitmap"*, %"class.v8::internal::CodeObjectRegistry"*, %"class.v8::internal::PossiblyEmptyBuckets" }
%"class.v8::internal::BasicMemoryChunk" = type { i64, i64, %"class.v8::internal::Heap"*, i64, i64, i64, i64, %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.606", %"class.v8::internal::VirtualMemory" }
%"class.v8::internal::Heap" = type { %"class.std::__1::unordered_map", %"struct.std::__1::atomic", %"class.v8::internal::Heap::ExternalMemoryAccounting", %"class.v8::internal::Isolate"*, i64, i64, i64, i64, %"struct.std::__1::atomic", i64, i64, i64, i64, i64, i8, i64, i64, %"struct.std::__1::atomic", i64, i64, %"struct.std::__1::atomic", %"struct.std::__1::atomic.20", %"class.std::__1::vector", i32, %"class.v8::internal::NewSpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::CodeSpace"*, %"class.v8::internal::MapSpace"*, %"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::MapSpace"*, %"class.std::__1::unique_ptr.106", %"class.std::__1::unique_ptr.106", [8 x %"class.v8::internal::Space"*], %"class.v8::internal::LocalHeap"*, %"class.v8::internal::ArrayBufferExtension"*, %"class.v8::internal::ArrayBufferExtension"*, i8, i64, %"struct.std::__1::atomic.121", i32, i32, i32, i32, %"class.v8::internal::AllocationObserver"*, %"class.v8::internal::StressScavengeObserver"*, double, i32, i32, i32, i64, i32, [128 x i64], %"struct.std::__1::atomic", i64, i8, %"struct.std::__1::atomic", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.std::__1::vector.125", %"class.std::__1::vector.125", i64 ()*, [113 x i32], i64, double, double, i64, i64, double, i32, i32, i32, i32, double, double, double, %"class.std::__1::unique_ptr.132", %"class.std::__1::unique_ptr.138", %"class.v8::internal::MinorMarkCompactCollector"*, %"class.std::__1::unique_ptr.268", %"class.std::__1::unique_ptr.274", %"class.std::__1::unique_ptr.280", %"class.std::__1::unique_ptr.319", %"class.std::__1::unique_ptr.358", %"class.std::__1::unique_ptr.388", %"class.std::__1::unique_ptr.394", %"class.std::__1::unique_ptr.404", %"class.std::__1::unique_ptr.410", %"class.std::__1::unique_ptr.410", %"class.std::__1::unique_ptr.416", %"class.std::__1::unique_ptr.422", %"class.std::__1::unique_ptr.422", %"class.std::__1::unique_ptr.428", %"class.std::__1::unique_ptr.434", %"class.std::__1::shared_ptr.440", %"class.v8::CppHeap"*, %"class.v8::EmbedderRootsHandler"*, %"class.v8::internal::StrongRootsEntry"*, %"class.v8::base::Mutex", i8, i64, i64, i64, i64, %"class.std::__1::unordered_map.462", %"class.std::__1::unique_ptr.488", [512 x i8], i8, i8, i64, i8, i32, i32, %"class.std::__1::unique_ptr.494", i8, %"class.v8::internal::Heap::ExternalStringTable", %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.509", i32, i8, i8, i8, i8, i8, %"class.v8::internal::HeapObject", %"class.v8::base::SharedMutex", %"class.v8::base::Mutex", %"class.std::__1::unordered_set.290", i8, [7 x i8], %"class.std::__1::unordered_map.515", %"class.std::__1::unordered_map.541", %"class.std::__1::unordered_map.515", %"class.std::__1::unordered_map.565", %"class.std::__1::vector.593", i8, %"class.std::__1::unique_ptr.600", i32, i32 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr", %"class.std::__1::__compressed_pair.4", %"class.std::__1::__compressed_pair.9", %"class.std::__1::__compressed_pair.11", [4 x i8] }>
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem", %"struct.std::__1::__compressed_pair_elem.0" }
%"struct.std::__1::__compressed_pair_elem" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.0" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.1" }
%"class.std::__1::__compressed_pair.1" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"struct.std::__1::__compressed_pair_elem.2" = type { i64 }
%"class.std::__1::__compressed_pair.4" = type { %"struct.std::__1::__compressed_pair_elem.5" }
%"struct.std::__1::__compressed_pair_elem.5" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.9" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.11" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::__compressed_pair_elem.12" = type { float }
%"class.v8::internal::Heap::ExternalMemoryAccounting" = type { %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.15", %"struct.std::__1::atomic.15" }
%"class.v8::internal::Isolate" = type { %"class.v8::internal::IsolateData", %"class.std::__1::unique_ptr.684", %"class.v8::internal::Heap", %"class.v8::internal::ReadOnlyHeap"*, %"class.std::__1::shared_ptr.690", %"class.std::__1::unique_ptr.711", i32, %"class.v8::internal::Isolate::EntryStackItem"*, i32, %"class.v8::internal::StringStream"*, [13 x i64], %"class.v8::internal::Bootstrapper"*, %"class.v8::internal::RuntimeProfiler"*, %"class.v8::internal::CompilationCache"*, %"class.std::__1::shared_ptr.721", %"class.v8::base::RecursiveMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::internal::Logger"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::Deoptimizer"*, i8, %"class.v8::internal::MaterializedObjectStore"*, i8, i32, i32, %"class.v8::internal::DescriptorLookupCache"*, %"struct.v8::internal::HandleScopeData", %"class.v8::internal::HandleScopeImplementer"*, %"class.v8::internal::UnicodeCache"*, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::InnerPointerToCodeCache"*, %"class.v8::internal::GlobalHandles"*, %"class.v8::internal::EternalHandles"*, %"class.v8::internal::ThreadManager"*, %"class.v8::bigint::Processor"*, %"class.v8::internal::RuntimeState", %"class.v8::internal::Builtins", %"class.v8::internal::SetupIsolateDelegate"*, %"class.v8::internal::RegExpStack"*, %"class.std::__1::vector.842", %"class.v8::internal::DateCache"*, %"class.v8::base::RandomNumberGenerator"*, %"class.v8::base::RandomNumberGenerator"*, %"struct.std::__1::atomic.855", {}*, i8*, void (i32, %"class.v8::Promise"*, %"class.v8::Value"*)*, {}*, {}*, %"struct.std::__1::atomic.865", {}*, %"class.v8::base::Mutex", double, %"class.std::__1::basic_string", %"class.std::__1::unordered_map.877", %"struct.std::__1::atomic.112", i8, i8, i8, i8, i8, i8, double, %"class.v8::internal::Debug"*, %"class.v8::internal::HeapProfiler"*, %"class.std::__1::unique_ptr.952", %"class.v8::internal::AstStringConstants"*, %"class.v8::internal::interpreter::Interpreter"*, %"class.v8::internal::compiler::PerIsolateCompilerCache"*, %"class.v8::internal::Zone"*, %"class.v8::internal::CompilerDispatcher"*, %"class.std::__1::queue", void (i8*, i8*)*, void (i8*, i1)*, void (i8*, i32)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*, i1)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::Context"*)*, void (%"class.v8::FunctionCallbackInfo"*)*, %"class.v8::String"* (%"class.v8::Isolate"*, i8*)*, i1 (%"class.v8::Context"*)*, i1 (%"class.v8::Context"*)*, %"class.v8::internal::Relocatable"*, %"class.std::__1::vector.995"*, %"class.v8::internal::Object", i64*, %"class.v8::internal::AddressToIndexHashMap"*, %"class.v8::internal::HeapObjectToIndexHashMap"*, %"class.v8::internal::MicrotaskQueue"*, %"class.v8::internal::CompilationStatistics"*, %"class.v8::internal::CodeTracer"*, i32, void (%"class.v8::PromiseRejectMessage"*)*, %"class.v8::StartupData"*, i32, i32, i32, i64, i8, i8, i32, i8, i32, %"class.v8_inspector::V8Inspector"*, i8, i8, i8, i32, i32, %"class.v8::internal::compiler::NodeObserver"*, i8, [128 x i32], [256 x i32], [251 x i32], [251 x i32], %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.std::__1::unique_ptr.1003", i32, i8, i8, i32, i32, %"class.std::__1::vector.1009", %"class.std::__1::vector.1009", void (%"class.v8::Isolate"*, i32)*, %"class.std::__1::shared_ptr.1016", i64, %"class.std::__1::unordered_map.1017", i64, %"struct.v8::metrics::LongTaskStats", %"class.std::__1::vector.502", %"class.v8::internal::BuiltinsConstantsTableBuilder"*, i8*, i32, i8*, i32, %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::shared_ptr.120", %"class.v8::internal::FutexWaitListNode", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::debug::ConsoleDelegate"*, %"class.v8::debug::AsyncEventDelegate"*, i32, i32, %"class.std::__1::unique_ptr.1069", i1 (%"class.v8::Isolate"*)*, i8, %"class.v8::base::Mutex", %"struct.v8::internal::ManagedPtrDestructor"*, i64, i64, %"class.v8::internal::wasm::WasmEngine"*, %"class.std::__1::unique_ptr.1083", %"class.v8::internal::EmbeddedFileWriterInterface"*, %"class.v8::Context::BackupIncumbentScope"*, {}*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate::ThreadDataTable", i8, %"class.v8::internal::Isolate"*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"struct.std::__1::atomic.1117", %"class.std::__1::vector.1121", %"class.std::__1::vector.1121", void (i32, %"class.std::__1::basic_string"*)* }
%"class.v8::internal::IsolateData" = type { [4 x i8*], i64, i64, i64, i64, i64, %"class.v8::internal::StackGuard", %"class.v8::internal::RootsTable", %"class.v8::internal::ExternalReferenceTable", %"class.v8::internal::ThreadLocalTop", [1711 x i64], [1711 x i64], i8, [15 x i8] }
%"class.v8::internal::StackGuard" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::StackGuard::ThreadLocal" }
%"class.v8::internal::StackGuard::ThreadLocal" = type { i64, i64, i64, i64, %"class.v8::internal::InterruptsScope"*, i64 }
%"class.v8::internal::InterruptsScope" = type { i32 (...)**, %"class.v8::internal::StackGuard"*, i64, i64, i32, %"class.v8::internal::InterruptsScope"* }
%"class.v8::internal::RootsTable" = type { [669 x i64] }
%"class.v8::internal::ExternalReferenceTable" = type { [1042 x i64], i32, i32 }
%"class.v8::internal::ThreadLocalTop" = type { %"class.v8::TryCatch"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Context", %"struct.std::__1::atomic.679", %"class.v8::internal::Object", %"class.v8::internal::Context", i64, i64, i64, i64, i64, %"class.v8::internal::Object", i8, i8, %"class.v8::internal::Object", i64, i64, i64, %"class.v8::internal::PromiseOnStack"*, %"class.v8::internal::Simulator"*, i64, %"class.v8::internal::ExternalCallbackScope"*, i32, void (%"class.v8::Object"*, i32, %"class.v8::Value"*)*, i64 }
%"class.v8::TryCatch" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::TryCatch"*, i8*, i8*, i8*, i8, [7 x i8] }>
%"struct.std::__1::atomic.679" = type { %"struct.std::__1::__atomic_base.680" }
%"struct.std::__1::__atomic_base.680" = type { %"struct.std::__1::__cxx_atomic_impl.681" }
%"struct.std::__1::__cxx_atomic_impl.681" = type { %"struct.std::__1::__cxx_atomic_base_impl.682" }
%"struct.std::__1::__cxx_atomic_base_impl.682" = type { %"class.v8::internal::ThreadId" }
%"class.v8::internal::ThreadId" = type { i32 }
%"class.v8::internal::Context" = type { %"class.v8::internal::TorqueGeneratedContext" }
%"class.v8::internal::TorqueGeneratedContext" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::PromiseOnStack" = type { %"class.v8::internal::Handle", %"class.v8::internal::PromiseOnStack"* }
%"class.v8::internal::Handle" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HandleBase" = type { i64* }
%"class.v8::internal::Simulator" = type opaque
%"class.v8::internal::ExternalCallbackScope" = type opaque
%"class.v8::Object" = type { i8 }
%"class.v8::Value" = type { i8 }
%"class.std::__1::unique_ptr.684" = type { %"class.std::__1::__compressed_pair.685" }
%"class.std::__1::__compressed_pair.685" = type { %"struct.std::__1::__compressed_pair_elem.686" }
%"struct.std::__1::__compressed_pair_elem.686" = type { %"class.v8::internal::IsolateAllocator"* }
%"class.v8::internal::IsolateAllocator" = type { i8*, %"class.v8::PageAllocator"* }
%"class.v8::PageAllocator" = type { i32 (...)** }
%"class.v8::internal::ReadOnlyHeap" = type { i32 (...)**, i8, %"class.v8::internal::ReadOnlySpace"*, %"class.std::__1::vector.502" }
%"class.std::__1::shared_ptr.690" = type { %"class.v8::internal::ReadOnlyArtifacts"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::ReadOnlyArtifacts" = type { i32 (...)**, %"class.std::__1::vector.99", %"class.v8::internal::AllocationStats", %"class.std::__1::unique_ptr.691", %"class.std::__1::unique_ptr.705" }
%"class.std::__1::vector.99" = type { %"class.std::__1::__vector_base.100" }
%"class.std::__1::__vector_base.100" = type { %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"**, %"class.std::__1::__compressed_pair.101" }
%"class.v8::internal::ReadOnlyPage" = type { %"class.v8::internal::BasicMemoryChunk" }
%"class.std::__1::__compressed_pair.101" = type { %"struct.std::__1::__compressed_pair_elem.102" }
%"struct.std::__1::__compressed_pair_elem.102" = type { %"class.v8::internal::ReadOnlyPage"** }
%"class.v8::internal::AllocationStats" = type { %"struct.std::__1::atomic", i64, %"struct.std::__1::atomic" }
%"class.std::__1::unique_ptr.691" = type { %"class.std::__1::__compressed_pair.692" }
%"class.std::__1::__compressed_pair.692" = type { %"struct.std::__1::__compressed_pair_elem.693" }
%"struct.std::__1::__compressed_pair_elem.693" = type { %"class.v8::internal::SharedReadOnlySpace"* }
%"class.v8::internal::SharedReadOnlySpace" = type { %"class.v8::internal::ReadOnlySpace", %"class.std::__1::vector.694" }
%"class.v8::internal::ReadOnlySpace" = type { %"class.v8::internal::BaseSpace", i8, %"class.v8::internal::AllocationStats", %"class.std::__1::vector.99", i64, i64, i8, i64, i64 }
%"class.v8::internal::BaseSpace" = type { i32 (...)**, %"class.v8::internal::Heap"*, i32, %"struct.std::__1::atomic", i64 }
%"class.std::__1::vector.694" = type { %"class.std::__1::__vector_base.695" }
%"class.std::__1::__vector_base.695" = type { %"class.std::__1::unique_ptr.696"*, %"class.std::__1::unique_ptr.696"*, %"class.std::__1::__compressed_pair.697" }
%"class.std::__1::unique_ptr.696" = type { %"class.std::__1::__compressed_pair.1136" }
%"class.std::__1::__compressed_pair.1136" = type { %"struct.std::__1::__compressed_pair_elem.1137" }
%"struct.std::__1::__compressed_pair_elem.1137" = type { %"class.v8::PageAllocator::SharedMemoryMapping"* }
%"class.v8::PageAllocator::SharedMemoryMapping" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.697" = type { %"struct.std::__1::__compressed_pair_elem.698" }
%"struct.std::__1::__compressed_pair_elem.698" = type { %"class.std::__1::unique_ptr.696"* }
%"class.std::__1::unique_ptr.705" = type { %"class.std::__1::__compressed_pair.706" }
%"class.std::__1::__compressed_pair.706" = type { %"struct.std::__1::__compressed_pair_elem.707" }
%"struct.std::__1::__compressed_pair_elem.707" = type { %"class.v8::internal::ReadOnlyHeap"* }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.std::__1::unique_ptr.711" = type { %"class.std::__1::__compressed_pair.712" }
%"class.std::__1::__compressed_pair.712" = type { %"struct.std::__1::__compressed_pair_elem.713" }
%"struct.std::__1::__compressed_pair_elem.713" = type { %"class.v8::internal::StringTable"* }
%"class.v8::internal::StringTable" = type { %"struct.std::__1::atomic.714", %"class.v8::base::Mutex" }
%"struct.std::__1::atomic.714" = type { %"struct.std::__1::__atomic_base.715" }
%"struct.std::__1::__atomic_base.715" = type { %"struct.std::__1::__cxx_atomic_impl.716" }
%"struct.std::__1::__cxx_atomic_impl.716" = type { %"struct.std::__1::__cxx_atomic_base_impl.717" }
%"struct.std::__1::__cxx_atomic_base_impl.717" = type { %"class.v8::internal::StringTable::Data"* }
%"class.v8::internal::StringTable::Data" = type opaque
%"class.v8::internal::Isolate::EntryStackItem" = type { i32, %"class.v8::internal::Isolate::PerIsolateThreadData"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate::EntryStackItem"* }
%"class.v8::internal::Isolate::PerIsolateThreadData" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::ThreadId", i64, %"class.v8::internal::ThreadState"* }
%"class.v8::internal::ThreadState" = type opaque
%"class.v8::internal::StringStream" = type opaque
%"class.v8::internal::Bootstrapper" = type { %"class.v8::internal::Isolate"*, i32, %"class.v8::internal::SourceCodeCache" }
%"class.v8::internal::SourceCodeCache" = type { i32, %"class.v8::internal::FixedArray" }
%"class.v8::internal::FixedArray" = type { %"class.v8::internal::TorqueGeneratedFixedArray" }
%"class.v8::internal::TorqueGeneratedFixedArray" = type { %"class.v8::internal::FixedArrayBase" }
%"class.v8::internal::FixedArrayBase" = type { %"class.v8::internal::TorqueGeneratedFixedArrayBase" }
%"class.v8::internal::TorqueGeneratedFixedArrayBase" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::RuntimeProfiler" = type opaque
%"class.v8::internal::CompilationCache" = type opaque
%"class.std::__1::shared_ptr.721" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::Counters" = type { %"class.std::__1::enable_shared_from_this", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::AggregatableHistogramTimer", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::RuntimeCallStats", %"class.v8::internal::WorkerThreadRuntimeCallStats", %"class.v8::internal::Isolate"*, %"class.v8::internal::StatsTable" }
%"class.std::__1::enable_shared_from_this" = type { %"class.std::__1::weak_ptr" }
%"class.std::__1::weak_ptr" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::HistogramTimer" = type { %"class.v8::internal::TimedHistogram.base", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::TimedHistogram.base" = type <{ %"class.v8::internal::Histogram", i32 }>
%"class.v8::base::ElapsedTimer" = type { %"class.v8::base::TimeTicks" }
%"class.v8::base::TimeTicks" = type { %"class.v8::base::time_internal::TimeBase" }
%"class.v8::base::time_internal::TimeBase" = type { i64 }
%"class.v8::internal::TimedHistogram" = type <{ %"class.v8::internal::Histogram", i32, [4 x i8] }>
%"class.v8::internal::AggregatableHistogramTimer" = type { %"class.v8::internal::Histogram", %"class.v8::base::TimeDelta" }
%"class.v8::base::TimeDelta" = type { i64 }
%"class.v8::internal::Histogram" = type { i8*, i32, i32, i32, i8*, %"class.v8::internal::Counters"* }
%"class.v8::internal::StatsCounterThreadSafe" = type { %"class.v8::internal::StatsCounterBase", %"class.v8::base::Mutex" }
%"class.v8::internal::StatsCounterBase" = type { %"class.v8::internal::Counters"*, i8*, i32* }
%"class.v8::internal::StatsCounter" = type <{ %"class.v8::internal::StatsCounterBase", i8, [7 x i8] }>
%"class.v8::internal::RuntimeCallStats" = type { %"class.v8::base::AtomicValue", %"class.v8::base::AtomicValue.722", i8, i32, %"class.v8::internal::ThreadId", [1370 x %"class.v8::internal::RuntimeCallCounter"] }
%"class.v8::base::AtomicValue" = type { i64 }
%"class.v8::base::AtomicValue.722" = type { i64 }
%"class.v8::internal::RuntimeCallCounter" = type { i8*, i64, i64 }
%"class.v8::internal::WorkerThreadRuntimeCallStats" = type <{ %"class.v8::base::Mutex", %"class.std::__1::vector.723", %"class.v8::base::Optional", %"class.v8::internal::ThreadId", [4 x i8] }>
%"class.std::__1::vector.723" = type { %"class.std::__1::__vector_base.724" }
%"class.std::__1::__vector_base.724" = type { %"class.std::__1::unique_ptr.725"*, %"class.std::__1::unique_ptr.725"*, %"class.std::__1::__compressed_pair.726" }
%"class.std::__1::unique_ptr.725" = type opaque
%"class.std::__1::__compressed_pair.726" = type { %"struct.std::__1::__compressed_pair_elem.727" }
%"struct.std::__1::__compressed_pair_elem.727" = type { %"class.std::__1::unique_ptr.725"* }
%"class.v8::base::Optional" = type { %"class.v8::base::internal::OptionalBase" }
%"class.v8::base::internal::OptionalBase" = type { %"struct.v8::base::internal::OptionalStorage" }
%"struct.v8::base::internal::OptionalStorage" = type { %"struct.v8::base::internal::OptionalStorageBase" }
%"struct.v8::base::internal::OptionalStorageBase" = type { i8, %union.anon.731 }
%union.anon.731 = type { i32 }
%"class.v8::internal::StatsTable" = type { i32* (i8*)*, i8* (i8*, i32, i32, i64)*, void (i8*, i32)* }
%"class.v8::base::RecursiveMutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.v8::internal::Logger" = type { %"class.v8::internal::CodeEventListener", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.732", %"class.std::__1::unique_ptr.738", %"struct.std::__1::atomic.112", %"class.std::__1::unique_ptr.744", %"class.std::__1::unique_ptr.750", %"class.std::__1::unique_ptr.756", %"class.std::__1::unique_ptr.762", %"class.std::__1::unique_ptr.768", %"class.std::__1::set.774", i32, i8, %"class.v8::internal::ExistingCodeLogger", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::CodeEventListener" = type { i32 (...)** }
%"class.std::__1::unique_ptr.732" = type { %"class.std::__1::__compressed_pair.733" }
%"class.std::__1::__compressed_pair.733" = type { %"struct.std::__1::__compressed_pair_elem.734" }
%"struct.std::__1::__compressed_pair_elem.734" = type { %"class.v8::internal::Ticker"* }
%"class.v8::internal::Ticker" = type opaque
%"class.std::__1::unique_ptr.738" = type { %"class.std::__1::__compressed_pair.739" }
%"class.std::__1::__compressed_pair.739" = type { %"struct.std::__1::__compressed_pair_elem.740" }
%"struct.std::__1::__compressed_pair_elem.740" = type { %"class.v8::internal::Profiler"* }
%"class.v8::internal::Profiler" = type opaque
%"class.std::__1::unique_ptr.744" = type { %"class.std::__1::__compressed_pair.745" }
%"class.std::__1::__compressed_pair.745" = type { %"struct.std::__1::__compressed_pair_elem.746" }
%"struct.std::__1::__compressed_pair_elem.746" = type { %"class.v8::internal::Log"* }
%"class.v8::internal::Log" = type opaque
%"class.std::__1::unique_ptr.750" = type { %"class.std::__1::__compressed_pair.751" }
%"class.std::__1::__compressed_pair.751" = type { %"struct.std::__1::__compressed_pair_elem.752" }
%"struct.std::__1::__compressed_pair_elem.752" = type { %"class.v8::internal::PerfBasicLogger"* }
%"class.v8::internal::PerfBasicLogger" = type opaque
%"class.std::__1::unique_ptr.756" = type { %"class.std::__1::__compressed_pair.757" }
%"class.std::__1::__compressed_pair.757" = type { %"struct.std::__1::__compressed_pair_elem.758" }
%"struct.std::__1::__compressed_pair_elem.758" = type { %"class.v8::internal::PerfJitLogger"* }
%"class.v8::internal::PerfJitLogger" = type opaque
%"class.std::__1::unique_ptr.762" = type { %"class.std::__1::__compressed_pair.763" }
%"class.std::__1::__compressed_pair.763" = type { %"struct.std::__1::__compressed_pair_elem.764" }
%"struct.std::__1::__compressed_pair_elem.764" = type { %"class.v8::internal::LowLevelLogger"* }
%"class.v8::internal::LowLevelLogger" = type opaque
%"class.std::__1::unique_ptr.768" = type { %"class.std::__1::__compressed_pair.769" }
%"class.std::__1::__compressed_pair.769" = type { %"struct.std::__1::__compressed_pair_elem.770" }
%"struct.std::__1::__compressed_pair_elem.770" = type { %"class.v8::internal::JitLogger"* }
%"class.v8::internal::JitLogger" = type opaque
%"class.std::__1::set.774" = type { %"class.std::__1::__tree.775" }
%"class.std::__1::__tree.775" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.776", %"class.std::__1::__compressed_pair.780" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.776" = type { %"struct.std::__1::__compressed_pair_elem.445" }
%"struct.std::__1::__compressed_pair_elem.445" = type { %"class.std::__1::__tree_end_node" }
%"class.std::__1::__compressed_pair.780" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::internal::ExistingCodeLogger" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::CodeEventListener"* }
%"class.v8::internal::StubCache" = type { [2048 x %"struct.v8::internal::StubCache::Entry"], [512 x %"struct.v8::internal::StubCache::Entry"], %"class.v8::internal::Isolate"* }
%"struct.v8::internal::StubCache::Entry" = type { %"class.v8::internal::StrongTaggedValue", %"class.v8::internal::TaggedValue", %"class.v8::internal::StrongTaggedValue" }
%"class.v8::internal::TaggedValue" = type { %"class.v8::internal::TaggedImpl.783" }
%"class.v8::internal::TaggedImpl.783" = type { i32 }
%"class.v8::internal::StrongTaggedValue" = type { %"class.v8::internal::TaggedImpl.782" }
%"class.v8::internal::TaggedImpl.782" = type { i32 }
%"class.v8::internal::Deoptimizer" = type opaque
%"class.v8::internal::MaterializedObjectStore" = type opaque
%"class.v8::internal::DescriptorLookupCache" = type { [64 x %"struct.v8::internal::DescriptorLookupCache::Key"], [64 x i32] }
%"struct.v8::internal::DescriptorLookupCache::Key" = type { %"class.v8::internal::Map", %"class.v8::internal::Name" }
%"class.v8::internal::Map" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Name" = type { %"class.v8::internal::TorqueGeneratedName" }
%"class.v8::internal::TorqueGeneratedName" = type { %"class.v8::internal::PrimitiveHeapObject" }
%"class.v8::internal::PrimitiveHeapObject" = type { %"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" }
%"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" = type { %"class.v8::internal::HeapObject" }
%"struct.v8::internal::HandleScopeData" = type { i64*, i64*, i32, i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::CanonicalHandleScope" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::Zone"*, %"class.v8::internal::RootIndexMap"*, %"class.std::__1::unique_ptr.649", i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::OptimizedCompilationInfo" = type opaque
%"class.v8::internal::RootIndexMap" = type opaque
%"class.std::__1::unique_ptr.649" = type { %"class.std::__1::__compressed_pair.650" }
%"class.std::__1::__compressed_pair.650" = type { %"struct.std::__1::__compressed_pair_elem.651" }
%"struct.std::__1::__compressed_pair_elem.651" = type { %"class.v8::internal::IdentityMap"* }
%"class.v8::internal::IdentityMap" = type opaque
%"class.v8::internal::HandleScopeImplementer" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::DetachableVector", %"class.v8::internal::DetachableVector.784", %"class.v8::internal::DetachableVector.785", %"class.v8::internal::DetachableVector.784", i64*, i64*, %"struct.v8::internal::HandleScopeData" }
%"class.v8::internal::DetachableVector" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVectorBase" = type { i8*, i64, i64 }
%"class.v8::internal::DetachableVector.785" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVector.784" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::UnicodeCache" = type opaque
%"class.v8::internal::AccountingAllocator" = type { i32 (...)**, %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.std::__1::unique_ptr.643", %"class.std::__1::unique_ptr.441" }
%"class.std::__1::unique_ptr.643" = type { %"class.std::__1::__compressed_pair.644" }
%"class.std::__1::__compressed_pair.644" = type { %"struct.std::__1::__compressed_pair_elem.645" }
%"struct.std::__1::__compressed_pair_elem.645" = type { %"class.v8::internal::VirtualMemory"* }
%"class.std::__1::unique_ptr.441" = type { %"class.std::__1::__compressed_pair.442" }
%"class.std::__1::__compressed_pair.442" = type { %"struct.std::__1::__compressed_pair_elem.443" }
%"struct.std::__1::__compressed_pair_elem.443" = type { %"class.v8::base::BoundedPageAllocator"* }
%"class.v8::base::BoundedPageAllocator" = type { %"class.v8::PageAllocator", %"class.v8::base::Mutex", i64, i64, %"class.v8::PageAllocator"*, %"class.v8::base::RegionAllocator" }
%"class.v8::base::RegionAllocator" = type { %"class.v8::base::RegionAllocator::Region", i64, i64, i64, i64, %"class.std::__1::set", %"class.std::__1::set.451" }
%"class.v8::base::RegionAllocator::Region" = type <{ %"class.v8::base::AddressRegion", i32, [4 x i8] }>
%"class.v8::base::AddressRegion" = type { i64, i64 }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.444", %"class.std::__1::__compressed_pair.449" }
%"class.std::__1::__compressed_pair.444" = type { %"struct.std::__1::__compressed_pair_elem.445" }
%"class.std::__1::__compressed_pair.449" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::set.451" = type { %"class.std::__1::__tree.452" }
%"class.std::__1::__tree.452" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.444", %"class.std::__1::__compressed_pair.453" }
%"class.std::__1::__compressed_pair.453" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::internal::InnerPointerToCodeCache" = type opaque
%"class.v8::internal::GlobalHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.786", %"class.std::__1::vector.792", %"class.std::__1::unique_ptr.799", %"class.std::__1::vector.806", %"class.std::__1::unique_ptr.813", i64, %"class.std::__1::vector.819", %"class.std::__1::vector.827", %"class.std::__1::vector.835", i8, i8, i32 }
%"class.std::__1::unique_ptr.786" = type { %"class.std::__1::__compressed_pair.787" }
%"class.std::__1::__compressed_pair.787" = type { %"struct.std::__1::__compressed_pair_elem.788" }
%"struct.std::__1::__compressed_pair_elem.788" = type { %"class.v8::internal::GlobalHandles::NodeSpace"* }
%"class.v8::internal::GlobalHandles::NodeSpace" = type opaque
%"class.std::__1::vector.792" = type { %"class.std::__1::__vector_base.793" }
%"class.std::__1::__vector_base.793" = type { %"class.v8::internal::GlobalHandles::Node"**, %"class.v8::internal::GlobalHandles::Node"**, %"class.std::__1::__compressed_pair.794" }
%"class.v8::internal::GlobalHandles::Node" = type opaque
%"class.std::__1::__compressed_pair.794" = type { %"struct.std::__1::__compressed_pair_elem.795" }
%"struct.std::__1::__compressed_pair_elem.795" = type { %"class.v8::internal::GlobalHandles::Node"** }
%"class.std::__1::unique_ptr.799" = type { %"class.std::__1::__compressed_pair.800" }
%"class.std::__1::__compressed_pair.800" = type { %"struct.std::__1::__compressed_pair_elem.801" }
%"struct.std::__1::__compressed_pair_elem.801" = type { %"class.v8::internal::GlobalHandles::NodeSpace.802"* }
%"class.v8::internal::GlobalHandles::NodeSpace.802" = type opaque
%"class.std::__1::vector.806" = type { %"class.std::__1::__vector_base.807" }
%"class.std::__1::__vector_base.807" = type { %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.std::__1::__compressed_pair.808" }
%"class.v8::internal::GlobalHandles::TracedNode" = type opaque
%"class.std::__1::__compressed_pair.808" = type { %"struct.std::__1::__compressed_pair_elem.809" }
%"struct.std::__1::__compressed_pair_elem.809" = type { %"class.v8::internal::GlobalHandles::TracedNode"** }
%"class.std::__1::unique_ptr.813" = type { %"class.std::__1::__compressed_pair.814" }
%"class.std::__1::__compressed_pair.814" = type { %"struct.std::__1::__compressed_pair_elem.815" }
%"struct.std::__1::__compressed_pair_elem.815" = type { %"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace"* }
%"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace" = type opaque
%"class.std::__1::vector.819" = type { %"class.std::__1::__vector_base.820" }
%"class.std::__1::__vector_base.820" = type { %"struct.std::__1::pair.821"*, %"struct.std::__1::pair.821"*, %"class.std::__1::__compressed_pair.822" }
%"struct.std::__1::pair.821" = type opaque
%"class.std::__1::__compressed_pair.822" = type { %"struct.std::__1::__compressed_pair_elem.823" }
%"struct.std::__1::__compressed_pair_elem.823" = type { %"struct.std::__1::pair.821"* }
%"class.std::__1::vector.827" = type { %"class.std::__1::__vector_base.828" }
%"class.std::__1::__vector_base.828" = type { %"struct.std::__1::pair.829"*, %"struct.std::__1::pair.829"*, %"class.std::__1::__compressed_pair.830" }
%"struct.std::__1::pair.829" = type opaque
%"class.std::__1::__compressed_pair.830" = type { %"struct.std::__1::__compressed_pair_elem.831" }
%"struct.std::__1::__compressed_pair_elem.831" = type { %"struct.std::__1::pair.829"* }
%"class.std::__1::vector.835" = type { %"class.std::__1::__vector_base.836" }
%"class.std::__1::__vector_base.836" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.std::__1::__compressed_pair.837" }
%"class.v8::internal::GlobalHandles::PendingPhantomCallback" = type { void (%"class.v8::WeakCallbackInfo"*)*, i8*, [2 x i8*] }
%"class.v8::WeakCallbackInfo" = type { %"class.v8::Isolate"*, i8*, {}**, [2 x i8*] }
%"class.v8::Isolate" = type { i8 }
%"class.std::__1::__compressed_pair.837" = type { %"struct.std::__1::__compressed_pair_elem.838" }
%"struct.std::__1::__compressed_pair_elem.838" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"* }
%"class.v8::internal::EternalHandles" = type { i32, %"class.std::__1::vector.655", %"class.std::__1::vector.842" }
%"class.std::__1::vector.655" = type { %"class.std::__1::__vector_base.656" }
%"class.std::__1::__vector_base.656" = type { i64**, i64**, %"class.std::__1::__compressed_pair.657" }
%"class.std::__1::__compressed_pair.657" = type { %"struct.std::__1::__compressed_pair_elem.658" }
%"struct.std::__1::__compressed_pair_elem.658" = type { i64** }
%"class.v8::internal::ThreadManager" = type opaque
%"class.v8::bigint::Processor" = type opaque
%"class.v8::internal::RuntimeState" = type { %"class.std::__1::unique_ptr.849" }
%"class.std::__1::unique_ptr.849" = type { %"class.std::__1::__compressed_pair.850" }
%"class.std::__1::__compressed_pair.850" = type { %"struct.std::__1::__compressed_pair_elem.851" }
%"struct.std::__1::__compressed_pair_elem.851" = type { %"struct.v8::internal::Runtime::Function"* }
%"struct.v8::internal::Runtime::Function" = type { i32, i32, i8*, i64, i8, i8 }
%"class.v8::internal::Builtins" = type { %"class.v8::internal::Isolate"*, i8, i32 }
%"class.v8::internal::SetupIsolateDelegate" = type opaque
%"class.v8::internal::RegExpStack" = type opaque
%"class.std::__1::vector.842" = type { %"class.std::__1::__vector_base.843" }
%"class.std::__1::__vector_base.843" = type { i32*, i32*, %"class.std::__1::__compressed_pair.844" }
%"class.std::__1::__compressed_pair.844" = type { %"struct.std::__1::__compressed_pair_elem.845" }
%"struct.std::__1::__compressed_pair_elem.845" = type { i32* }
%"class.v8::internal::DateCache" = type opaque
%"class.v8::base::RandomNumberGenerator" = type { i64, i64, i64 }
%"struct.std::__1::atomic.855" = type { %"struct.std::__1::__atomic_base.856" }
%"struct.std::__1::__atomic_base.856" = type { %"struct.std::__1::__cxx_atomic_impl.857" }
%"struct.std::__1::__cxx_atomic_impl.857" = type { %"struct.std::__1::__cxx_atomic_base_impl.858" }
%"struct.std::__1::__cxx_atomic_base_impl.858" = type { i32 }
%"class.v8::Promise" = type { i8 }
%"struct.std::__1::atomic.865" = type { %"struct.std::__1::__atomic_base.866" }
%"struct.std::__1::__atomic_base.866" = type { %"struct.std::__1::__cxx_atomic_impl.867" }
%"struct.std::__1::__cxx_atomic_impl.867" = type { %"struct.std::__1::__cxx_atomic_base_impl.868" }
%"struct.std::__1::__cxx_atomic_base_impl.868" = type { i32 }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair.870" }
%"class.std::__1::__compressed_pair.870" = type { %"struct.std::__1::__compressed_pair_elem.871" }
%"struct.std::__1::__compressed_pair_elem.871" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon.872 }
%union.anon.872 = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%"class.std::__1::unordered_map.877" = type { %"class.std::__1::__hash_table.878" }
%"class.std::__1::__hash_table.878" = type <{ %"class.std::__1::unique_ptr.879", %"class.std::__1::__compressed_pair.889", %"class.std::__1::__compressed_pair.894", %"class.std::__1::__compressed_pair.897", [4 x i8] }>
%"class.std::__1::unique_ptr.879" = type { %"class.std::__1::__compressed_pair.880" }
%"class.std::__1::__compressed_pair.880" = type { %"struct.std::__1::__compressed_pair_elem.881", %"struct.std::__1::__compressed_pair_elem.883" }
%"struct.std::__1::__compressed_pair_elem.881" = type { %"struct.std::__1::__hash_node_base.882"** }
%"struct.std::__1::__hash_node_base.882" = type { %"struct.std::__1::__hash_node_base.882"* }
%"struct.std::__1::__compressed_pair_elem.883" = type { %"class.std::__1::__bucket_list_deallocator.884" }
%"class.std::__1::__bucket_list_deallocator.884" = type { %"class.std::__1::__compressed_pair.885" }
%"class.std::__1::__compressed_pair.885" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.889" = type { %"struct.std::__1::__compressed_pair_elem.890" }
%"struct.std::__1::__compressed_pair_elem.890" = type { %"struct.std::__1::__hash_node_base.882" }
%"class.std::__1::__compressed_pair.894" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.897" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::atomic.112" = type { %"struct.std::__1::__atomic_base.113" }
%"struct.std::__1::__atomic_base.113" = type { %"struct.std::__1::__cxx_atomic_impl.114" }
%"struct.std::__1::__cxx_atomic_impl.114" = type { %"struct.std::__1::__cxx_atomic_base_impl.115" }
%"struct.std::__1::__cxx_atomic_base_impl.115" = type { i8 }
%"class.v8::internal::Debug" = type { %"class.v8::debug::DebugDelegate"*, i8, i8, i8, i8, i8, i8, i8, i8, i8, %"class.v8::internal::DebugInfoListNode"*, %"class.std::__1::unique_ptr.903", %"class.v8::internal::Handle.909", %"class.v8::internal::DebugFeatureTracker", %"class.v8::internal::Debug::ThreadLocal", %"class.v8::internal::Handle.910", %"class.v8::internal::Isolate"* }
%"class.v8::debug::DebugDelegate" = type { i32 (...)** }
%"class.v8::internal::DebugInfoListNode" = type { i64*, %"class.v8::internal::DebugInfoListNode"* }
%"class.std::__1::unique_ptr.903" = type { %"class.std::__1::__compressed_pair.904" }
%"class.std::__1::__compressed_pair.904" = type { %"struct.std::__1::__compressed_pair_elem.905" }
%"struct.std::__1::__compressed_pair_elem.905" = type { %"class.v8::internal::Debug::TemporaryObjectsTracker"* }
%"class.v8::internal::Debug::TemporaryObjectsTracker" = type opaque
%"class.v8::internal::Handle.909" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::DebugFeatureTracker" = type <{ %"class.v8::internal::Isolate"*, i32, [4 x i8] }>
%"class.v8::internal::Debug::ThreadLocal" = type <{ i64, i32, i8, [3 x i8], %"class.v8::internal::Object", i8, [3 x i8], i32, i32, i32, %"class.v8::internal::Object", %"class.v8::internal::Object", i32, i8, [3 x i8] }>
%"class.v8::internal::Handle.910" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HeapProfiler" = type { %"class.v8::internal::HeapObjectAllocationTracker", %"class.std::__1::unique_ptr.911", %"class.std::__1::vector.917", %"class.std::__1::unique_ptr.925", %"class.std::__1::unique_ptr.931", i8, i8, %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.937", %"class.std::__1::vector.943", %"struct.std::__1::pair.951" }
%"class.v8::internal::HeapObjectAllocationTracker" = type { i32 (...)** }
%"class.std::__1::unique_ptr.911" = type { %"class.std::__1::__compressed_pair.912" }
%"class.std::__1::__compressed_pair.912" = type { %"struct.std::__1::__compressed_pair_elem.913" }
%"struct.std::__1::__compressed_pair_elem.913" = type { %"class.v8::internal::HeapObjectsMap"* }
%"class.v8::internal::HeapObjectsMap" = type opaque
%"class.std::__1::vector.917" = type { %"class.std::__1::__vector_base.918" }
%"class.std::__1::__vector_base.918" = type { %"class.std::__1::unique_ptr.919"*, %"class.std::__1::unique_ptr.919"*, %"class.std::__1::__compressed_pair.920" }
%"class.std::__1::unique_ptr.919" = type opaque
%"class.std::__1::__compressed_pair.920" = type { %"struct.std::__1::__compressed_pair_elem.921" }
%"struct.std::__1::__compressed_pair_elem.921" = type { %"class.std::__1::unique_ptr.919"* }
%"class.std::__1::unique_ptr.925" = type { %"class.std::__1::__compressed_pair.926" }
%"class.std::__1::__compressed_pair.926" = type { %"struct.std::__1::__compressed_pair_elem.927" }
%"struct.std::__1::__compressed_pair_elem.927" = type { %"class.v8::internal::StringsStorage"* }
%"class.v8::internal::StringsStorage" = type opaque
%"class.std::__1::unique_ptr.931" = type { %"class.std::__1::__compressed_pair.932" }
%"class.std::__1::__compressed_pair.932" = type { %"struct.std::__1::__compressed_pair_elem.933" }
%"struct.std::__1::__compressed_pair_elem.933" = type { %"class.v8::internal::AllocationTracker"* }
%"class.v8::internal::AllocationTracker" = type opaque
%"class.std::__1::unique_ptr.937" = type { %"class.std::__1::__compressed_pair.938" }
%"class.std::__1::__compressed_pair.938" = type { %"struct.std::__1::__compressed_pair_elem.939" }
%"struct.std::__1::__compressed_pair_elem.939" = type { %"class.v8::internal::SamplingHeapProfiler"* }
%"class.v8::internal::SamplingHeapProfiler" = type opaque
%"class.std::__1::vector.943" = type { %"class.std::__1::__vector_base.944" }
%"class.std::__1::__vector_base.944" = type { %"struct.std::__1::pair.945"*, %"struct.std::__1::pair.945"*, %"class.std::__1::__compressed_pair.946" }
%"struct.std::__1::pair.945" = type opaque
%"class.std::__1::__compressed_pair.946" = type { %"struct.std::__1::__compressed_pair_elem.947" }
%"struct.std::__1::__compressed_pair_elem.947" = type { %"struct.std::__1::pair.945"* }
%"struct.std::__1::pair.951" = type { i8 (%"class.v8::Isolate"*, %"class.v8::Local.683"*, i16, i8*)*, i8* }
%"class.v8::Local.683" = type { %"class.v8::Value"* }
%"class.std::__1::unique_ptr.952" = type { %"class.std::__1::__compressed_pair.953" }
%"class.std::__1::__compressed_pair.953" = type { %"struct.std::__1::__compressed_pair_elem.954" }
%"struct.std::__1::__compressed_pair_elem.954" = type { %"class.v8::internal::CodeEventDispatcher"* }
%"class.v8::internal::CodeEventDispatcher" = type { %"class.v8::internal::CodeEventListener", %"class.std::__1::unordered_set.955", %"class.v8::base::Mutex" }
%"class.std::__1::unordered_set.955" = type { %"class.std::__1::__hash_table.956" }
%"class.std::__1::__hash_table.956" = type <{ %"class.std::__1::unique_ptr.957", %"class.std::__1::__compressed_pair.967", %"class.std::__1::__compressed_pair.972", %"class.std::__1::__compressed_pair.976", [4 x i8] }>
%"class.std::__1::unique_ptr.957" = type { %"class.std::__1::__compressed_pair.958" }
%"class.std::__1::__compressed_pair.958" = type { %"struct.std::__1::__compressed_pair_elem.959", %"struct.std::__1::__compressed_pair_elem.961" }
%"struct.std::__1::__compressed_pair_elem.959" = type { %"struct.std::__1::__hash_node_base.960"** }
%"struct.std::__1::__hash_node_base.960" = type { %"struct.std::__1::__hash_node_base.960"* }
%"struct.std::__1::__compressed_pair_elem.961" = type { %"class.std::__1::__bucket_list_deallocator.962" }
%"class.std::__1::__bucket_list_deallocator.962" = type { %"class.std::__1::__compressed_pair.963" }
%"class.std::__1::__compressed_pair.963" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.967" = type { %"struct.std::__1::__compressed_pair_elem.968" }
%"struct.std::__1::__compressed_pair_elem.968" = type { %"struct.std::__1::__hash_node_base.960" }
%"class.std::__1::__compressed_pair.972" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.976" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::AstStringConstants" = type opaque
%"class.v8::internal::interpreter::Interpreter" = type opaque
%"class.v8::internal::compiler::PerIsolateCompilerCache" = type opaque
%"class.v8::internal::Zone" = type <{ i64, i64, i64, i64, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::Segment"*, i8*, i8, i8, [6 x i8] }>
%"class.v8::internal::Segment" = type { %"class.v8::internal::Zone"*, %"class.v8::internal::Segment"*, i64 }
%"class.v8::internal::CompilerDispatcher" = type opaque
%"class.std::__1::queue" = type { %"class.std::__1::deque" }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.990" }
%"struct.std::__1::__split_buffer" = type { %"struct.std::__1::pair.984"**, %"struct.std::__1::pair.984"**, %"struct.std::__1::pair.984"**, %"class.std::__1::__compressed_pair.985" }
%"struct.std::__1::pair.984" = type opaque
%"class.std::__1::__compressed_pair.985" = type { %"struct.std::__1::__compressed_pair_elem.986" }
%"struct.std::__1::__compressed_pair_elem.986" = type { %"struct.std::__1::pair.984"** }
%"class.std::__1::__compressed_pair.990" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.v8::String" = type { i8 }
%"class.v8::Context" = type { i8 }
%"class.v8::FunctionCallbackInfo" = type <{ i64*, i64*, i32, [4 x i8] }>
%"class.v8::internal::Relocatable" = type { i32 (...)**, %"class.v8::internal::Isolate"*, %"class.v8::internal::Relocatable"* }
%"class.std::__1::vector.995" = type { %"class.std::__1::__vector_base.996" }
%"class.std::__1::__vector_base.996" = type { %"class.v8::internal::Handle.997"*, %"class.v8::internal::Handle.997"*, %"class.std::__1::__compressed_pair.998" }
%"class.v8::internal::Handle.997" = type { %"class.v8::internal::HandleBase" }
%"class.std::__1::__compressed_pair.998" = type { %"struct.std::__1::__compressed_pair_elem.999" }
%"struct.std::__1::__compressed_pair_elem.999" = type { %"class.v8::internal::Handle.997"* }
%"class.v8::internal::AddressToIndexHashMap" = type opaque
%"class.v8::internal::HeapObjectToIndexHashMap" = type opaque
%"class.v8::internal::MicrotaskQueue" = type opaque
%"class.v8::internal::CompilationStatistics" = type opaque
%"class.v8::internal::CodeTracer" = type <{ %"class.v8::internal::EmbeddedVector", %struct._IO_FILE*, i32, [4 x i8] }>
%"class.v8::internal::EmbeddedVector" = type { %"class.v8::internal::Vector", [128 x i8] }
%"class.v8::internal::Vector" = type { i8*, i64 }
%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%"class.v8::PromiseRejectMessage" = type { %"class.v8::Local.860", i32, %"class.v8::Local.683" }
%"class.v8::Local.860" = type { %"class.v8::Promise"* }
%"class.v8::StartupData" = type { i8*, i32 }
%"class.v8_inspector::V8Inspector" = type opaque
%"class.v8::internal::compiler::NodeObserver" = type opaque
%"class.v8::internal::OptimizingCompileDispatcher" = type opaque
%"class.std::__1::unique_ptr.1003" = type { %"class.std::__1::__compressed_pair.1004" }
%"class.std::__1::__compressed_pair.1004" = type { %"struct.std::__1::__compressed_pair_elem.1005" }
%"struct.std::__1::__compressed_pair_elem.1005" = type { %"class.v8::internal::PersistentHandlesList"* }
%"class.v8::internal::PersistentHandlesList" = type { %"class.v8::base::Mutex", %"class.v8::internal::PersistentHandles"* }
%"class.v8::internal::PersistentHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::vector.655", i64*, i64*, %"class.v8::internal::PersistentHandles"*, %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.1009" = type { %"class.std::__1::__vector_base.1010" }
%"class.std::__1::__vector_base.1010" = type { void (%"class.v8::Isolate"*)**, void (%"class.v8::Isolate"*)**, %"class.std::__1::__compressed_pair.1011" }
%"class.std::__1::__compressed_pair.1011" = type { %"struct.std::__1::__compressed_pair_elem.1012" }
%"struct.std::__1::__compressed_pair_elem.1012" = type { void (%"class.v8::Isolate"*)** }
%"class.std::__1::shared_ptr.1016" = type { %"class.v8::internal::metrics::Recorder"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::metrics::Recorder" = type opaque
%"class.std::__1::unordered_map.1017" = type { %"class.std::__1::__hash_table.1018" }
%"class.std::__1::__hash_table.1018" = type <{ %"class.std::__1::unique_ptr.1019", %"class.std::__1::__compressed_pair.1029", %"class.std::__1::__compressed_pair.1034", %"class.std::__1::__compressed_pair.1037", [4 x i8] }>
%"class.std::__1::unique_ptr.1019" = type { %"class.std::__1::__compressed_pair.1020" }
%"class.std::__1::__compressed_pair.1020" = type { %"struct.std::__1::__compressed_pair_elem.1021", %"struct.std::__1::__compressed_pair_elem.1023" }
%"struct.std::__1::__compressed_pair_elem.1021" = type { %"struct.std::__1::__hash_node_base.1022"** }
%"struct.std::__1::__hash_node_base.1022" = type { %"struct.std::__1::__hash_node_base.1022"* }
%"struct.std::__1::__compressed_pair_elem.1023" = type { %"class.std::__1::__bucket_list_deallocator.1024" }
%"class.std::__1::__bucket_list_deallocator.1024" = type { %"class.std::__1::__compressed_pair.1025" }
%"class.std::__1::__compressed_pair.1025" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1029" = type { %"struct.std::__1::__compressed_pair_elem.1030" }
%"struct.std::__1::__compressed_pair_elem.1030" = type { %"struct.std::__1::__hash_node_base.1022" }
%"class.std::__1::__compressed_pair.1034" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1037" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.v8::metrics::LongTaskStats" = type { i64, i64, i64 }
%"class.std::__1::vector.502" = type { %"class.std::__1::__vector_base.503" }
%"class.std::__1::__vector_base.503" = type { %"class.v8::internal::Object"*, %"class.v8::internal::Object"*, %"class.std::__1::__compressed_pair.504" }
%"class.std::__1::__compressed_pair.504" = type { %"struct.std::__1::__compressed_pair_elem.505" }
%"struct.std::__1::__compressed_pair_elem.505" = type { %"class.v8::internal::Object"* }
%"class.v8::internal::BuiltinsConstantsTableBuilder" = type opaque
%"class.v8::ArrayBuffer::Allocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.120" = type { %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::FutexWaitListNode" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::shared_ptr.1041", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::base::ConditionVariable", %"class.v8::internal::FutexWaitListNode"*, %"class.v8::internal::FutexWaitListNode"*, %"class.std::__1::weak_ptr.1066", i64, i8*, i8, i8, %"class.v8::Global", %"class.v8::Global.1067", %"class.v8::base::TimeTicks", i64 }
%"class.std::__1::shared_ptr.1041" = type { %"class.v8::TaskRunner"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::TaskRunner" = type { i32 (...)** }
%"class.v8::base::ConditionVariable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon, %union.anon.497, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon = type { i64 }
%union.anon.497 = type { i64 }
%"class.std::__1::weak_ptr.1066" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::BackingStore" = type <{ i8*, %"struct.std::__1::atomic", i64, %"union.v8::internal::BackingStore::TypeSpecificData", i16, [6 x i8] }>
%"union.v8::internal::BackingStore::TypeSpecificData" = type { %"class.std::__1::shared_ptr.120" }
%"class.v8::Global" = type { %"class.v8::PersistentBase" }
%"class.v8::PersistentBase" = type { %"class.v8::Promise"* }
%"class.v8::Global.1067" = type { %"class.v8::PersistentBase.1068" }
%"class.v8::PersistentBase.1068" = type { %"class.v8::Context"* }
%"class.v8::internal::CancelableTaskManager" = type <{ i64, %"class.std::__1::unordered_map.1042", %"class.v8::base::ConditionVariable", %"class.v8::base::Mutex", i8, [7 x i8] }>
%"class.std::__1::unordered_map.1042" = type { %"class.std::__1::__hash_table.1043" }
%"class.std::__1::__hash_table.1043" = type <{ %"class.std::__1::unique_ptr.1044", %"class.std::__1::__compressed_pair.1054", %"class.std::__1::__compressed_pair.1059", %"class.std::__1::__compressed_pair.1062", [4 x i8] }>
%"class.std::__1::unique_ptr.1044" = type { %"class.std::__1::__compressed_pair.1045" }
%"class.std::__1::__compressed_pair.1045" = type { %"struct.std::__1::__compressed_pair_elem.1046", %"struct.std::__1::__compressed_pair_elem.1048" }
%"struct.std::__1::__compressed_pair_elem.1046" = type { %"struct.std::__1::__hash_node_base.1047"** }
%"struct.std::__1::__hash_node_base.1047" = type { %"struct.std::__1::__hash_node_base.1047"* }
%"struct.std::__1::__compressed_pair_elem.1048" = type { %"class.std::__1::__bucket_list_deallocator.1049" }
%"class.std::__1::__bucket_list_deallocator.1049" = type { %"class.std::__1::__compressed_pair.1050" }
%"class.std::__1::__compressed_pair.1050" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1054" = type { %"struct.std::__1::__compressed_pair_elem.1055" }
%"struct.std::__1::__compressed_pair_elem.1055" = type { %"struct.std::__1::__hash_node_base.1047" }
%"class.std::__1::__compressed_pair.1059" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1062" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::debug::ConsoleDelegate" = type { i32 (...)** }
%"class.v8::debug::AsyncEventDelegate" = type { i32 (...)** }
%"class.std::__1::unique_ptr.1069" = type { %"class.std::__1::__compressed_pair.1070" }
%"class.std::__1::__compressed_pair.1070" = type { %"struct.std::__1::__compressed_pair_elem.1071" }
%"struct.std::__1::__compressed_pair_elem.1071" = type { %"class.v8::internal::LocalIsolate"* }
%"class.v8::internal::LocalIsolate" = type { %"class.v8::internal::HiddenLocalFactory", %"class.v8::internal::LocalHeap", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.1074", %"class.v8::internal::ThreadId", i64, %"class.v8::internal::RuntimeCallStats"* }
%"class.v8::internal::HiddenLocalFactory" = type { %"class.v8::internal::LocalFactory" }
%"class.v8::internal::LocalFactory" = type { %"class.v8::internal::ReadOnlyRoots" }
%"class.v8::internal::ReadOnlyRoots" = type { i64* }
%"class.v8::internal::LocalHeap" = type { %"class.v8::internal::Heap"*, i8, %"struct.std::__1::atomic.636", i8, i8, %"class.v8::internal::LocalHeap"*, %"class.v8::internal::LocalHeap"*, %"class.std::__1::unique_ptr.640", %"class.std::__1::unique_ptr.665", %"class.std::__1::unique_ptr.434", %"class.std::__1::vector.671", %"class.v8::internal::ConcurrentAllocator" }
%"struct.std::__1::atomic.636" = type { %"struct.std::__1::__atomic_base.637" }
%"struct.std::__1::__atomic_base.637" = type { %"struct.std::__1::__cxx_atomic_impl.638" }
%"struct.std::__1::__cxx_atomic_impl.638" = type { %"struct.std::__1::__cxx_atomic_base_impl.639" }
%"struct.std::__1::__cxx_atomic_base_impl.639" = type { i32 }
%"class.std::__1::unique_ptr.640" = type { %"class.std::__1::__compressed_pair.641" }
%"class.std::__1::__compressed_pair.641" = type { %"struct.std::__1::__compressed_pair_elem.642" }
%"struct.std::__1::__compressed_pair_elem.642" = type { %"class.v8::internal::LocalHandles"* }
%"class.v8::internal::LocalHandles" = type { %"struct.v8::internal::HandleScopeData", %"class.std::__1::vector.655" }
%"class.std::__1::unique_ptr.665" = type { %"class.std::__1::__compressed_pair.666" }
%"class.std::__1::__compressed_pair.666" = type { %"struct.std::__1::__compressed_pair_elem.667" }
%"struct.std::__1::__compressed_pair_elem.667" = type { %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.671" = type { %"class.std::__1::__vector_base.672" }
%"class.std::__1::__vector_base.672" = type { %"struct.std::__1::pair.673"*, %"struct.std::__1::pair.673"*, %"class.std::__1::__compressed_pair.674" }
%"struct.std::__1::pair.673" = type opaque
%"class.std::__1::__compressed_pair.674" = type { %"struct.std::__1::__compressed_pair_elem.675" }
%"struct.std::__1::__compressed_pair_elem.675" = type { %"struct.std::__1::pair.673"* }
%"class.v8::internal::ConcurrentAllocator" = type { %"class.v8::internal::LocalHeap"*, %"class.v8::internal::PagedSpace"*, %"class.v8::internal::LocalAllocationBuffer" }
%"class.v8::internal::PagedSpace" = type { %"class.v8::internal::SpaceWithLinearArea", i32, i32, i64, %"class.v8::internal::AllocationStats", %"class.v8::base::Mutex", i64, i64 }
%"class.v8::internal::SpaceWithLinearArea" = type { %"class.v8::internal::Space", %"class.v8::internal::LinearAllocationArea", [3 x i64] }
%"class.v8::internal::Space" = type { %"class.v8::internal::BaseSpace", %"class.v8::internal::AllocationCounter", %"class.v8::internal::heap::List", %"struct.std::__1::atomic"*, %"class.std::__1::unique_ptr.59" }
%"class.v8::internal::AllocationCounter" = type <{ %"class.std::__1::vector.29", %"class.std::__1::vector.29", %"class.std::__1::unordered_set", i8, [7 x i8], i64, i64, i8, [7 x i8] }>
%"class.std::__1::vector.29" = type { %"class.std::__1::__vector_base.30" }
%"class.std::__1::__vector_base.30" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"class.std::__1::__compressed_pair.31" }
%"struct.v8::internal::AllocationCounter::AllocationObserverCounter" = type { %"class.v8::internal::AllocationObserver"*, i64, i64 }
%"class.std::__1::__compressed_pair.31" = type { %"struct.std::__1::__compressed_pair_elem.32" }
%"struct.std::__1::__compressed_pair_elem.32" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.36" }
%"class.std::__1::__hash_table.36" = type <{ %"class.std::__1::unique_ptr.37", %"class.std::__1::__compressed_pair.47", %"class.std::__1::__compressed_pair.52", %"class.std::__1::__compressed_pair.54", [4 x i8] }>
%"class.std::__1::unique_ptr.37" = type { %"class.std::__1::__compressed_pair.38" }
%"class.std::__1::__compressed_pair.38" = type { %"struct.std::__1::__compressed_pair_elem.39", %"struct.std::__1::__compressed_pair_elem.41" }
%"struct.std::__1::__compressed_pair_elem.39" = type { %"struct.std::__1::__hash_node_base.40"** }
%"struct.std::__1::__hash_node_base.40" = type { %"struct.std::__1::__hash_node_base.40"* }
%"struct.std::__1::__compressed_pair_elem.41" = type { %"class.std::__1::__bucket_list_deallocator.42" }
%"class.std::__1::__bucket_list_deallocator.42" = type { %"class.std::__1::__compressed_pair.43" }
%"class.std::__1::__compressed_pair.43" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.47" = type { %"struct.std::__1::__compressed_pair_elem.48" }
%"struct.std::__1::__compressed_pair_elem.48" = type { %"struct.std::__1::__hash_node_base.40" }
%"class.std::__1::__compressed_pair.52" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.54" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::heap::List" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.std::__1::unique_ptr.59" = type { %"class.std::__1::__compressed_pair.60" }
%"class.std::__1::__compressed_pair.60" = type { %"struct.std::__1::__compressed_pair_elem.61" }
%"struct.std::__1::__compressed_pair_elem.61" = type { %"class.v8::internal::FreeList"* }
%"class.v8::internal::FreeList" = type { i32 (...)**, i32, i32, i64, %"struct.std::__1::atomic", %"class.v8::internal::FreeListCategory"**, i64 }
%"class.v8::internal::LinearAllocationArea" = type { i64, i64, i64 }
%"class.v8::internal::LocalAllocationBuffer" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::LinearAllocationArea" }
%"class.std::__1::unique_ptr.1074" = type { %"class.std::__1::__compressed_pair.1075" }
%"class.std::__1::__compressed_pair.1075" = type { %"struct.std::__1::__compressed_pair_elem.1076" }
%"struct.std::__1::__compressed_pair_elem.1076" = type { %"class.v8::internal::LocalLogger"* }
%"class.v8::internal::LocalLogger" = type opaque
%"struct.v8::internal::ManagedPtrDestructor" = type { i64, %"struct.v8::internal::ManagedPtrDestructor"*, %"struct.v8::internal::ManagedPtrDestructor"*, i8*, void (i8*)*, i64* }
%"class.v8::internal::wasm::WasmEngine" = type opaque
%"class.std::__1::unique_ptr.1083" = type { %"class.std::__1::__compressed_pair.1084" }
%"class.std::__1::__compressed_pair.1084" = type { %"struct.std::__1::__compressed_pair_elem.1085" }
%"struct.std::__1::__compressed_pair_elem.1085" = type { %"class.v8::internal::TracingCpuProfilerImpl"* }
%"class.v8::internal::TracingCpuProfilerImpl" = type opaque
%"class.v8::internal::EmbeddedFileWriterInterface" = type opaque
%"class.v8::Context::BackupIncumbentScope" = type { %"class.v8::Local.861", i64, %"class.v8::Context::BackupIncumbentScope"* }
%"class.v8::Local.861" = type { %"class.v8::Context"* }
%"class.v8::internal::Isolate::ThreadDataTable" = type { %"class.std::__1::unordered_map.1091" }
%"class.std::__1::unordered_map.1091" = type { %"class.std::__1::__hash_table.1092" }
%"class.std::__1::__hash_table.1092" = type <{ %"class.std::__1::unique_ptr.1093", %"class.std::__1::__compressed_pair.1103", %"class.std::__1::__compressed_pair.1108", %"class.std::__1::__compressed_pair.1111", [4 x i8] }>
%"class.std::__1::unique_ptr.1093" = type { %"class.std::__1::__compressed_pair.1094" }
%"class.std::__1::__compressed_pair.1094" = type { %"struct.std::__1::__compressed_pair_elem.1095", %"struct.std::__1::__compressed_pair_elem.1097" }
%"struct.std::__1::__compressed_pair_elem.1095" = type { %"struct.std::__1::__hash_node_base.1096"** }
%"struct.std::__1::__hash_node_base.1096" = type { %"struct.std::__1::__hash_node_base.1096"* }
%"struct.std::__1::__compressed_pair_elem.1097" = type { %"class.std::__1::__bucket_list_deallocator.1098" }
%"class.std::__1::__bucket_list_deallocator.1098" = type { %"class.std::__1::__compressed_pair.1099" }
%"class.std::__1::__compressed_pair.1099" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1103" = type { %"struct.std::__1::__compressed_pair_elem.1104" }
%"struct.std::__1::__compressed_pair_elem.1104" = type { %"struct.std::__1::__hash_node_base.1096" }
%"class.std::__1::__compressed_pair.1108" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.1111" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"struct.std::__1::atomic.1117" = type { %"struct.std::__1::__atomic_base.1118" }
%"struct.std::__1::__atomic_base.1118" = type { %"struct.std::__1::__cxx_atomic_impl.1119" }
%"struct.std::__1::__cxx_atomic_impl.1119" = type { %"struct.std::__1::__cxx_atomic_base_impl.1120" }
%"struct.std::__1::__cxx_atomic_base_impl.1120" = type { %"class.std::__1::vector.1121"* }
%"class.std::__1::vector.1121" = type { %"class.std::__1::__vector_base.1122" }
%"class.std::__1::__vector_base.1122" = type { %"struct.v8::MemoryRange"*, %"struct.v8::MemoryRange"*, %"class.std::__1::__compressed_pair.1123" }
%"struct.v8::MemoryRange" = type { i8*, i64 }
%"class.std::__1::__compressed_pair.1123" = type { %"struct.std::__1::__compressed_pair_elem.1124" }
%"struct.std::__1::__compressed_pair_elem.1124" = type { %"struct.v8::MemoryRange"* }
%"struct.std::__1::atomic.20" = type { %"struct.std::__1::__atomic_base.21" }
%"struct.std::__1::__atomic_base.21" = type { %"struct.std::__1::__cxx_atomic_impl.22" }
%"struct.std::__1::__cxx_atomic_impl.22" = type { %"struct.std::__1::__cxx_atomic_base_impl.23" }
%"struct.std::__1::__cxx_atomic_base_impl.23" = type { i32 }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"struct.std::__1::pair"*, %"struct.std::__1::pair"*, %"class.std::__1::__compressed_pair.24" }
%"struct.std::__1::pair" = type opaque
%"class.std::__1::__compressed_pair.24" = type { %"struct.std::__1::__compressed_pair_elem.25" }
%"struct.std::__1::__compressed_pair_elem.25" = type { %"struct.std::__1::pair"* }
%"class.v8::internal::NewSpace" = type { %"class.v8::internal::SpaceWithLinearArea", %"class.v8::base::Mutex", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace", %"class.v8::internal::VirtualMemory", %"class.std::__1::vector.63" }
%"class.v8::internal::SemiSpace" = type { %"class.v8::internal::Space", i64, i64, i64, i64, i64, i32, %"class.v8::internal::Page"* }
%"class.v8::internal::Page" = type { %"class.v8::internal::MemoryChunk" }
%"class.std::__1::vector.63" = type { %"class.std::__1::__vector_base.64" }
%"class.std::__1::__vector_base.64" = type { %"struct.std::__1::pair.65"*, %"struct.std::__1::pair.65"*, %"class.std::__1::__compressed_pair.66" }
%"struct.std::__1::pair.65" = type { i32, i64 }
%"class.std::__1::__compressed_pair.66" = type { %"struct.std::__1::__compressed_pair_elem.67" }
%"struct.std::__1::__compressed_pair_elem.67" = type { %"struct.std::__1::pair.65"* }
%"class.v8::internal::CodeSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::OldLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace" }
%"class.v8::internal::LargeObjectSpace" = type { %"class.v8::internal::Space", %"struct.std::__1::atomic", i32, %"struct.std::__1::atomic", %"class.v8::base::Mutex", %"struct.std::__1::atomic" }
%"class.v8::internal::CodeLargeObjectSpace" = type { %"class.v8::internal::OldLargeObjectSpace", %"class.std::__1::unordered_map.71" }
%"class.std::__1::unordered_map.71" = type { %"class.std::__1::__hash_table.72" }
%"class.std::__1::__hash_table.72" = type <{ %"class.std::__1::unique_ptr.73", %"class.std::__1::__compressed_pair.83", %"class.std::__1::__compressed_pair.88", %"class.std::__1::__compressed_pair.93", [4 x i8] }>
%"class.std::__1::unique_ptr.73" = type { %"class.std::__1::__compressed_pair.74" }
%"class.std::__1::__compressed_pair.74" = type { %"struct.std::__1::__compressed_pair_elem.75", %"struct.std::__1::__compressed_pair_elem.77" }
%"struct.std::__1::__compressed_pair_elem.75" = type { %"struct.std::__1::__hash_node_base.76"** }
%"struct.std::__1::__hash_node_base.76" = type { %"struct.std::__1::__hash_node_base.76"* }
%"struct.std::__1::__compressed_pair_elem.77" = type { %"class.std::__1::__bucket_list_deallocator.78" }
%"class.std::__1::__bucket_list_deallocator.78" = type { %"class.std::__1::__compressed_pair.79" }
%"class.std::__1::__compressed_pair.79" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.83" = type { %"struct.std::__1::__compressed_pair_elem.84" }
%"struct.std::__1::__compressed_pair_elem.84" = type { %"struct.std::__1::__hash_node_base.76" }
%"class.std::__1::__compressed_pair.88" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.93" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::NewLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace", i64 }
%"class.v8::internal::OldSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::MapSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.std::__1::unique_ptr.106" = type { %"class.std::__1::__compressed_pair.107" }
%"class.std::__1::__compressed_pair.107" = type { %"struct.std::__1::__compressed_pair_elem.108" }
%"struct.std::__1::__compressed_pair_elem.108" = type { %"class.v8::internal::ConcurrentAllocator"* }
%"class.v8::internal::ArrayBufferExtension" = type { %"struct.std::__1::atomic.112", %"struct.std::__1::atomic.116", %"class.std::__1::shared_ptr", %"class.v8::internal::ArrayBufferExtension"*, %"struct.std::__1::atomic" }
%"struct.std::__1::atomic.116" = type { %"struct.std::__1::__atomic_base.117" }
%"struct.std::__1::__atomic_base.117" = type { %"struct.std::__1::__cxx_atomic_impl.118" }
%"struct.std::__1::__cxx_atomic_impl.118" = type { %"struct.std::__1::__cxx_atomic_base_impl.119" }
%"struct.std::__1::__cxx_atomic_base_impl.119" = type { i8 }
%"class.std::__1::shared_ptr" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"struct.std::__1::atomic.121" = type { %"struct.std::__1::__atomic_base.122" }
%"struct.std::__1::__atomic_base.122" = type { %"struct.std::__1::__cxx_atomic_impl.123" }
%"struct.std::__1::__cxx_atomic_impl.123" = type { %"struct.std::__1::__cxx_atomic_base_impl.124" }
%"struct.std::__1::__cxx_atomic_base_impl.124" = type { i32 }
%"class.v8::internal::AllocationObserver" = type { i32 (...)**, i64 }
%"class.v8::internal::StressScavengeObserver" = type opaque
%"class.v8::internal::Object" = type { %"class.v8::internal::TaggedImpl" }
%"class.v8::internal::TaggedImpl" = type { i64 }
%"class.std::__1::vector.125" = type { %"class.std::__1::__vector_base.126" }
%"class.std::__1::__vector_base.126" = type { %"struct.v8::internal::Heap::GCCallbackTuple"*, %"struct.v8::internal::Heap::GCCallbackTuple"*, %"class.std::__1::__compressed_pair.127" }
%"struct.v8::internal::Heap::GCCallbackTuple" = type { void (%"class.v8::Isolate"*, i32, i32, i8*)*, i32, i8* }
%"class.std::__1::__compressed_pair.127" = type { %"struct.std::__1::__compressed_pair_elem.128" }
%"struct.std::__1::__compressed_pair_elem.128" = type { %"struct.v8::internal::Heap::GCCallbackTuple"* }
%"class.std::__1::unique_ptr.132" = type { %"class.std::__1::__compressed_pair.133" }
%"class.std::__1::__compressed_pair.133" = type { %"struct.std::__1::__compressed_pair_elem.134" }
%"struct.std::__1::__compressed_pair_elem.134" = type { %"class.v8::internal::GCTracer"* }
%"class.v8::internal::GCTracer" = type opaque
%"class.std::__1::unique_ptr.138" = type { %"class.std::__1::__compressed_pair.139" }
%"class.std::__1::__compressed_pair.139" = type { %"struct.std::__1::__compressed_pair_elem.140" }
%"struct.std::__1::__compressed_pair_elem.140" = type { %"class.v8::internal::MarkCompactCollector"* }
%"class.v8::internal::MarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::base::Mutex", %"class.v8::base::Semaphore", i8, i8, i8, i8, i8, i8, [2 x i8], %"class.v8::internal::MarkingWorklists", %"class.v8::internal::WeakObjects", %"struct.v8::internal::EphemeronMarking", %"class.std::__1::unique_ptr.180", %"class.std::__1::unique_ptr.186", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", %"class.std::__1::vector.240", %"class.std::__1::vector.240", %"class.std::__1::vector.240", %"class.std::__1::vector.247", %"class.v8::internal::Sweeper"*, %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", [2 x i8], i32, i32, [4 x i8] }>
%"class.v8::internal::MarkCompactCollectorBase" = type { i32 (...)**, %"class.v8::internal::Heap"* }
%"class.v8::base::Semaphore" = type { %union.sem_t }
%union.sem_t = type { i64, [24 x i8] }
%"class.v8::internal::MarkingWorklists" = type { %"class.heap::base::Worklist", %"class.heap::base::Worklist", %"class.heap::base::Worklist.141", %"class.std::__1::vector.142", %"class.std::__1::vector.149", %"class.heap::base::Worklist" }
%"class.heap::base::Worklist.141" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment"*, %"struct.std::__1::atomic" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment" = type opaque
%"class.std::__1::vector.142" = type { %"class.std::__1::__vector_base.143" }
%"class.std::__1::__vector_base.143" = type { %"struct.v8::internal::ContextWorklistPair"*, %"struct.v8::internal::ContextWorklistPair"*, %"class.std::__1::__compressed_pair.144" }
%"struct.v8::internal::ContextWorklistPair" = type { i64, %"class.heap::base::Worklist"* }
%"class.std::__1::__compressed_pair.144" = type { %"struct.std::__1::__compressed_pair_elem.145" }
%"struct.std::__1::__compressed_pair_elem.145" = type { %"struct.v8::internal::ContextWorklistPair"* }
%"class.std::__1::vector.149" = type { %"class.std::__1::__vector_base.150" }
%"class.std::__1::__vector_base.150" = type { %"class.std::__1::unique_ptr.151"*, %"class.std::__1::unique_ptr.151"*, %"class.std::__1::__compressed_pair.152" }
%"class.std::__1::unique_ptr.151" = type opaque
%"class.std::__1::__compressed_pair.152" = type { %"struct.std::__1::__compressed_pair_elem.153" }
%"struct.std::__1::__compressed_pair_elem.153" = type { %"class.std::__1::unique_ptr.151"* }
%"class.heap::base::Worklist" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment" = type opaque
%"class.v8::internal::WeakObjects" = type { %"class.v8::internal::Worklist", %"class.v8::internal::Worklist.157", %"class.v8::internal::Worklist.159", %"class.v8::internal::Worklist.159", %"class.v8::internal::Worklist.159", %"class.v8::internal::Worklist.161", %"class.v8::internal::Worklist.163", %"class.v8::internal::Worklist.165", %"class.v8::internal::Worklist.167", %"class.v8::internal::Worklist.169", %"class.v8::internal::Worklist.171" }
%"class.v8::internal::Worklist" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.157" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.159" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.161" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.163" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.165" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.167" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.169" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"struct.std::__1::atomic" }
%"class.v8::internal::Worklist.171" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"struct.std::__1::atomic" }
%"struct.v8::internal::EphemeronMarking" = type { %"class.std::__1::vector.173", i8, i64 }
%"class.std::__1::vector.173" = type { %"class.std::__1::__vector_base.174" }
%"class.std::__1::__vector_base.174" = type { %"class.v8::internal::HeapObject"*, %"class.v8::internal::HeapObject"*, %"class.std::__1::__compressed_pair.175" }
%"class.std::__1::__compressed_pair.175" = type { %"struct.std::__1::__compressed_pair_elem.176" }
%"struct.std::__1::__compressed_pair_elem.176" = type { %"class.v8::internal::HeapObject"* }
%"class.std::__1::unique_ptr.180" = type { %"class.std::__1::__compressed_pair.181" }
%"class.std::__1::__compressed_pair.181" = type { %"struct.std::__1::__compressed_pair_elem.182" }
%"struct.std::__1::__compressed_pair_elem.182" = type { %"class.v8::internal::MainMarkingVisitor"* }
%"class.v8::internal::MainMarkingVisitor" = type opaque
%"class.std::__1::unique_ptr.186" = type { %"class.std::__1::__compressed_pair.187" }
%"class.std::__1::__compressed_pair.187" = type { %"struct.std::__1::__compressed_pair_elem.188" }
%"struct.std::__1::__compressed_pair_elem.188" = type { %"class.v8::internal::MarkingWorklists::Local"* }
%"class.v8::internal::MarkingWorklists::Local" = type { %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", i64, %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local"*, i8, [7 x i8], %"class.std::__1::unordered_map.189" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local" = type { %"class.heap::base::Worklist.141"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.heap::base::internal::SegmentBase" = type { i16, i16 }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local" = type { %"class.heap::base::Worklist"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.std::__1::unordered_map.189" = type { %"class.std::__1::__hash_table.190" }
%"class.std::__1::__hash_table.190" = type <{ %"class.std::__1::unique_ptr.191", %"class.std::__1::__compressed_pair.201", %"class.std::__1::__compressed_pair.206", %"class.std::__1::__compressed_pair.209", [4 x i8] }>
%"class.std::__1::unique_ptr.191" = type { %"class.std::__1::__compressed_pair.192" }
%"class.std::__1::__compressed_pair.192" = type { %"struct.std::__1::__compressed_pair_elem.193", %"struct.std::__1::__compressed_pair_elem.195" }
%"struct.std::__1::__compressed_pair_elem.193" = type { %"struct.std::__1::__hash_node_base.194"** }
%"struct.std::__1::__hash_node_base.194" = type { %"struct.std::__1::__hash_node_base.194"* }
%"struct.std::__1::__compressed_pair_elem.195" = type { %"class.std::__1::__bucket_list_deallocator.196" }
%"class.std::__1::__bucket_list_deallocator.196" = type { %"class.std::__1::__compressed_pair.197" }
%"class.std::__1::__compressed_pair.197" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.201" = type { %"struct.std::__1::__compressed_pair_elem.202" }
%"struct.std::__1::__compressed_pair_elem.202" = type { %"struct.std::__1::__hash_node_base.194" }
%"class.std::__1::__compressed_pair.206" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.209" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.v8::internal::NativeContextInferrer" = type { i8 }
%"class.v8::internal::NativeContextStats" = type { %"class.std::__1::unordered_map.216" }
%"class.std::__1::unordered_map.216" = type { %"class.std::__1::__hash_table.217" }
%"class.std::__1::__hash_table.217" = type <{ %"class.std::__1::unique_ptr.218", %"class.std::__1::__compressed_pair.228", %"class.std::__1::__compressed_pair.233", %"class.std::__1::__compressed_pair.236", [4 x i8] }>
%"class.std::__1::unique_ptr.218" = type { %"class.std::__1::__compressed_pair.219" }
%"class.std::__1::__compressed_pair.219" = type { %"struct.std::__1::__compressed_pair_elem.220", %"struct.std::__1::__compressed_pair_elem.222" }
%"struct.std::__1::__compressed_pair_elem.220" = type { %"struct.std::__1::__hash_node_base.221"** }
%"struct.std::__1::__hash_node_base.221" = type { %"struct.std::__1::__hash_node_base.221"* }
%"struct.std::__1::__compressed_pair_elem.222" = type { %"class.std::__1::__bucket_list_deallocator.223" }
%"class.std::__1::__bucket_list_deallocator.223" = type { %"class.std::__1::__compressed_pair.224" }
%"class.std::__1::__compressed_pair.224" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.228" = type { %"struct.std::__1::__compressed_pair_elem.229" }
%"struct.std::__1::__compressed_pair_elem.229" = type { %"struct.std::__1::__hash_node_base.221" }
%"class.std::__1::__compressed_pair.233" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.236" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::vector.240" = type { %"class.std::__1::__vector_base.241" }
%"class.std::__1::__vector_base.241" = type { %"class.v8::internal::Page"**, %"class.v8::internal::Page"**, %"class.std::__1::__compressed_pair.242" }
%"class.std::__1::__compressed_pair.242" = type { %"struct.std::__1::__compressed_pair_elem.243" }
%"struct.std::__1::__compressed_pair_elem.243" = type { %"class.v8::internal::Page"** }
%"class.std::__1::vector.247" = type { %"class.std::__1::__vector_base.248" }
%"class.std::__1::__vector_base.248" = type { %"struct.std::__1::pair.249"*, %"struct.std::__1::pair.249"*, %"class.std::__1::__compressed_pair.250" }
%"struct.std::__1::pair.249" = type opaque
%"class.std::__1::__compressed_pair.250" = type { %"struct.std::__1::__compressed_pair_elem.251" }
%"struct.std::__1::__compressed_pair_elem.251" = type { %"struct.std::__1::pair.249"* }
%"class.v8::internal::Sweeper" = type <{ %"class.v8::internal::Heap"*, %"class.v8::internal::MajorNonAtomicMarkingState"*, %"class.std::__1::unique_ptr.255", %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.240"], [3 x %"class.std::__1::vector.240"], i8, %"struct.std::__1::atomic.112", [6 x i8], %"class.std::__1::vector.240", i64, %"class.v8::base::Semaphore", i8, i8, i8, [5 x i8] }>
%"class.std::__1::unique_ptr.255" = type { %"class.std::__1::__compressed_pair.256" }
%"class.std::__1::__compressed_pair.256" = type { %"struct.std::__1::__compressed_pair_elem.257" }
%"struct.std::__1::__compressed_pair_elem.257" = type { %"class.v8::JobHandle"* }
%"class.v8::JobHandle" = type { i32 (...)** }
%"class.v8::internal::MajorMarkingState" = type { i8 }
%"class.v8::internal::MajorNonAtomicMarkingState" = type { i8 }
%"class.v8::internal::MinorMarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::internal::Worklist.265"*, %"class.v8::internal::YoungGenerationMarkingVisitor"*, %"class.v8::base::Semaphore", %"class.std::__1::vector.240", %"class.std::__1::vector.240", %"class.v8::internal::MinorMarkingState", %"class.v8::internal::MinorNonAtomicMarkingState", [6 x i8] }>
%"class.v8::internal::Worklist.265" = type opaque
%"class.v8::internal::YoungGenerationMarkingVisitor" = type opaque
%"class.v8::internal::MinorMarkingState" = type { i8 }
%"class.v8::internal::MinorNonAtomicMarkingState" = type { i8 }
%"class.std::__1::unique_ptr.268" = type { %"class.std::__1::__compressed_pair.269" }
%"class.std::__1::__compressed_pair.269" = type { %"struct.std::__1::__compressed_pair_elem.270" }
%"struct.std::__1::__compressed_pair_elem.270" = type { %"class.v8::internal::ScavengerCollector"* }
%"class.v8::internal::ScavengerCollector" = type opaque
%"class.std::__1::unique_ptr.274" = type { %"class.std::__1::__compressed_pair.275" }
%"class.std::__1::__compressed_pair.275" = type { %"struct.std::__1::__compressed_pair_elem.276" }
%"struct.std::__1::__compressed_pair_elem.276" = type { %"class.v8::internal::ArrayBufferSweeper"* }
%"class.v8::internal::ArrayBufferSweeper" = type opaque
%"class.std::__1::unique_ptr.280" = type { %"class.std::__1::__compressed_pair.281" }
%"class.std::__1::__compressed_pair.281" = type { %"struct.std::__1::__compressed_pair_elem.282" }
%"struct.std::__1::__compressed_pair_elem.282" = type { %"class.v8::internal::MemoryAllocator"* }
%"class.v8::internal::MemoryAllocator" = type { %"class.v8::internal::Isolate"*, %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"*, i64, %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"struct.std::__1::atomic", %"class.v8::internal::VirtualMemory", %"class.v8::internal::MemoryAllocator::Unmapper", %"class.std::__1::unordered_set.290", %"class.v8::base::Mutex" }
%"class.v8::internal::MemoryAllocator::Unmapper" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MemoryAllocator"*, %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.283"], %"class.std::__1::unique_ptr.255" }
%"class.std::__1::vector.283" = type { %"class.std::__1::__vector_base.284" }
%"class.std::__1::__vector_base.284" = type { %"class.v8::internal::MemoryChunk"**, %"class.v8::internal::MemoryChunk"**, %"class.std::__1::__compressed_pair.285" }
%"class.std::__1::__compressed_pair.285" = type { %"struct.std::__1::__compressed_pair_elem.286" }
%"struct.std::__1::__compressed_pair_elem.286" = type { %"class.v8::internal::MemoryChunk"** }
%"class.std::__1::unique_ptr.319" = type { %"class.std::__1::__compressed_pair.320" }
%"class.std::__1::__compressed_pair.320" = type { %"struct.std::__1::__compressed_pair_elem.321" }
%"struct.std::__1::__compressed_pair_elem.321" = type { %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::IncrementalMarking" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MarkCompactCollector"*, %"class.v8::internal::WeakObjects"*, double, double, i64, i64, i64, i64, double, i64, %"struct.std::__1::atomic.322", i8, i8, i8, i8, [3 x i8], %"class.v8::internal::IncrementalMarkingJob", %"struct.std::__1::atomic.326", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorAtomicMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", %"class.v8::base::Mutex", %"class.std::__1::unordered_map.331" }
%"struct.std::__1::atomic.322" = type { %"struct.std::__1::__atomic_base.323" }
%"struct.std::__1::__atomic_base.323" = type { %"struct.std::__1::__cxx_atomic_impl.324" }
%"struct.std::__1::__cxx_atomic_impl.324" = type { %"struct.std::__1::__cxx_atomic_base_impl.325" }
%"struct.std::__1::__cxx_atomic_base_impl.325" = type { i8 }
%"class.v8::internal::IncrementalMarkingJob" = type <{ %"class.v8::base::Mutex", double, i8, i8, [6 x i8] }>
%"struct.std::__1::atomic.326" = type { %"struct.std::__1::__atomic_base.327" }
%"struct.std::__1::__atomic_base.327" = type { %"struct.std::__1::__cxx_atomic_impl.328" }
%"struct.std::__1::__cxx_atomic_impl.328" = type { %"struct.std::__1::__cxx_atomic_base_impl.329" }
%"struct.std::__1::__cxx_atomic_base_impl.329" = type { i32 }
%"class.v8::internal::IncrementalMarking::Observer" = type { %"class.v8::internal::AllocationObserver", %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::MajorAtomicMarkingState" = type { i8 }
%"class.std::__1::unordered_map.331" = type { %"class.std::__1::__hash_table.332" }
%"class.std::__1::__hash_table.332" = type <{ %"class.std::__1::unique_ptr.333", %"class.std::__1::__compressed_pair.343", %"class.std::__1::__compressed_pair.348", %"class.std::__1::__compressed_pair.351", [4 x i8] }>
%"class.std::__1::unique_ptr.333" = type { %"class.std::__1::__compressed_pair.334" }
%"class.std::__1::__compressed_pair.334" = type { %"struct.std::__1::__compressed_pair_elem.335", %"struct.std::__1::__compressed_pair_elem.337" }
%"struct.std::__1::__compressed_pair_elem.335" = type { %"struct.std::__1::__hash_node_base.336"** }
%"struct.std::__1::__hash_node_base.336" = type { %"struct.std::__1::__hash_node_base.336"* }
%"struct.std::__1::__compressed_pair_elem.337" = type { %"class.std::__1::__bucket_list_deallocator.338" }
%"class.std::__1::__bucket_list_deallocator.338" = type { %"class.std::__1::__compressed_pair.339" }
%"class.std::__1::__compressed_pair.339" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.343" = type { %"struct.std::__1::__compressed_pair_elem.344" }
%"struct.std::__1::__compressed_pair_elem.344" = type { %"struct.std::__1::__hash_node_base.336" }
%"class.std::__1::__compressed_pair.348" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.351" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.358" = type { %"class.std::__1::__compressed_pair.359" }
%"class.std::__1::__compressed_pair.359" = type { %"struct.std::__1::__compressed_pair_elem.360" }
%"struct.std::__1::__compressed_pair_elem.360" = type { %"class.v8::internal::ConcurrentMarking"* }
%"class.v8::internal::ConcurrentMarking" = type <{ %"class.std::__1::unique_ptr.255", %"class.v8::internal::Heap"*, %"class.v8::internal::MarkingWorklists"*, %"class.v8::internal::WeakObjects"*, [8 x %"struct.v8::internal::ConcurrentMarking::TaskState"], %"struct.std::__1::atomic", %"struct.std::__1::atomic.112", [7 x i8] }>
%"struct.v8::internal::ConcurrentMarking::TaskState" = type { i64, %"class.std::__1::unordered_map.361", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", [64 x i8] }
%"class.std::__1::unordered_map.361" = type { %"class.std::__1::__hash_table.362" }
%"class.std::__1::__hash_table.362" = type <{ %"class.std::__1::unique_ptr.363", %"class.std::__1::__compressed_pair.373", %"class.std::__1::__compressed_pair.378", %"class.std::__1::__compressed_pair.381", [4 x i8] }>
%"class.std::__1::unique_ptr.363" = type { %"class.std::__1::__compressed_pair.364" }
%"class.std::__1::__compressed_pair.364" = type { %"struct.std::__1::__compressed_pair_elem.365", %"struct.std::__1::__compressed_pair_elem.367" }
%"struct.std::__1::__compressed_pair_elem.365" = type { %"struct.std::__1::__hash_node_base.366"** }
%"struct.std::__1::__hash_node_base.366" = type { %"struct.std::__1::__hash_node_base.366"* }
%"struct.std::__1::__compressed_pair_elem.367" = type { %"class.std::__1::__bucket_list_deallocator.368" }
%"class.std::__1::__bucket_list_deallocator.368" = type { %"class.std::__1::__compressed_pair.369" }
%"class.std::__1::__compressed_pair.369" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.373" = type { %"struct.std::__1::__compressed_pair_elem.374" }
%"struct.std::__1::__compressed_pair_elem.374" = type { %"struct.std::__1::__hash_node_base.366" }
%"class.std::__1::__compressed_pair.378" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.381" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.388" = type { %"class.std::__1::__compressed_pair.389" }
%"class.std::__1::__compressed_pair.389" = type { %"struct.std::__1::__compressed_pair_elem.390" }
%"struct.std::__1::__compressed_pair_elem.390" = type { %"class.v8::internal::GCIdleTimeHandler"* }
%"class.v8::internal::GCIdleTimeHandler" = type opaque
%"class.std::__1::unique_ptr.394" = type { %"class.std::__1::__compressed_pair.395" }
%"class.std::__1::__compressed_pair.395" = type { %"struct.std::__1::__compressed_pair_elem.396" }
%"struct.std::__1::__compressed_pair_elem.396" = type { %"class.v8::internal::MemoryMeasurement"* }
%"class.v8::internal::MemoryMeasurement" = type { %"class.std::__1::list", %"class.std::__1::list", %"class.std::__1::list", %"class.v8::internal::Isolate"*, i8, i8, i8, %"class.v8::base::RandomNumberGenerator" }
%"class.std::__1::list" = type { %"class.std::__1::__list_imp" }
%"class.std::__1::__list_imp" = type { %"struct.std::__1::__list_node_base", %"class.std::__1::__compressed_pair.397" }
%"struct.std::__1::__list_node_base" = type { %"struct.std::__1::__list_node_base"*, %"struct.std::__1::__list_node_base"* }
%"class.std::__1::__compressed_pair.397" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::unique_ptr.404" = type { %"class.std::__1::__compressed_pair.405" }
%"class.std::__1::__compressed_pair.405" = type { %"struct.std::__1::__compressed_pair_elem.406" }
%"struct.std::__1::__compressed_pair_elem.406" = type { %"class.v8::internal::MemoryReducer"* }
%"class.v8::internal::MemoryReducer" = type opaque
%"class.std::__1::unique_ptr.410" = type { %"class.std::__1::__compressed_pair.411" }
%"class.std::__1::__compressed_pair.411" = type { %"struct.std::__1::__compressed_pair_elem.412" }
%"struct.std::__1::__compressed_pair_elem.412" = type { %"class.v8::internal::ObjectStats"* }
%"class.v8::internal::ObjectStats" = type opaque
%"class.std::__1::unique_ptr.416" = type { %"class.std::__1::__compressed_pair.417" }
%"class.std::__1::__compressed_pair.417" = type { %"struct.std::__1::__compressed_pair_elem.418" }
%"struct.std::__1::__compressed_pair_elem.418" = type { %"class.v8::internal::ScavengeJob"* }
%"class.v8::internal::ScavengeJob" = type opaque
%"class.std::__1::unique_ptr.422" = type { %"class.std::__1::__compressed_pair.423" }
%"class.std::__1::__compressed_pair.423" = type { %"struct.std::__1::__compressed_pair_elem.424" }
%"struct.std::__1::__compressed_pair_elem.424" = type { %"class.v8::internal::AllocationObserver"* }
%"class.std::__1::unique_ptr.428" = type { %"class.std::__1::__compressed_pair.429" }
%"class.std::__1::__compressed_pair.429" = type { %"struct.std::__1::__compressed_pair_elem.430" }
%"struct.std::__1::__compressed_pair_elem.430" = type { %"class.v8::internal::LocalEmbedderHeapTracer"* }
%"class.v8::internal::LocalEmbedderHeapTracer" = type opaque
%"class.std::__1::unique_ptr.434" = type { %"class.std::__1::__compressed_pair.435" }
%"class.std::__1::__compressed_pair.435" = type { %"struct.std::__1::__compressed_pair_elem.436" }
%"struct.std::__1::__compressed_pair_elem.436" = type { %"class.v8::internal::MarkingBarrier"* }
%"class.v8::internal::MarkingBarrier" = type opaque
%"class.std::__1::shared_ptr.440" = type { %"class.v8::internal::CodeRange"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::CodeRange" = type { %"class.v8::internal::VirtualMemoryCage", %"struct.std::__1::atomic.458", %"class.v8::base::Mutex" }
%"class.v8::internal::VirtualMemoryCage" = type { i32 (...)**, i64, %"class.std::__1::unique_ptr.441", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.458" = type { %"struct.std::__1::__atomic_base.459" }
%"struct.std::__1::__atomic_base.459" = type { %"struct.std::__1::__cxx_atomic_impl.460" }
%"struct.std::__1::__cxx_atomic_impl.460" = type { %"struct.std::__1::__cxx_atomic_base_impl.461" }
%"struct.std::__1::__cxx_atomic_base_impl.461" = type { i8* }
%"class.v8::CppHeap" = type opaque
%"class.v8::EmbedderRootsHandler" = type { i32 (...)** }
%"class.v8::internal::StrongRootsEntry" = type { %"class.v8::internal::FullObjectSlot", %"class.v8::internal::FullObjectSlot", %"class.v8::internal::StrongRootsEntry"*, %"class.v8::internal::StrongRootsEntry"* }
%"class.v8::internal::FullObjectSlot" = type { %"class.v8::internal::SlotBase" }
%"class.v8::internal::SlotBase" = type { i64 }
%"class.std::__1::unordered_map.462" = type { %"class.std::__1::__hash_table.463" }
%"class.std::__1::__hash_table.463" = type <{ %"class.std::__1::unique_ptr.464", %"class.std::__1::__compressed_pair.474", %"class.std::__1::__compressed_pair.479", %"class.std::__1::__compressed_pair.482", [4 x i8] }>
%"class.std::__1::unique_ptr.464" = type { %"class.std::__1::__compressed_pair.465" }
%"class.std::__1::__compressed_pair.465" = type { %"struct.std::__1::__compressed_pair_elem.466", %"struct.std::__1::__compressed_pair_elem.468" }
%"struct.std::__1::__compressed_pair_elem.466" = type { %"struct.std::__1::__hash_node_base.467"** }
%"struct.std::__1::__hash_node_base.467" = type { %"struct.std::__1::__hash_node_base.467"* }
%"struct.std::__1::__compressed_pair_elem.468" = type { %"class.std::__1::__bucket_list_deallocator.469" }
%"class.std::__1::__bucket_list_deallocator.469" = type { %"class.std::__1::__compressed_pair.470" }
%"class.std::__1::__compressed_pair.470" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.474" = type { %"struct.std::__1::__compressed_pair_elem.475" }
%"struct.std::__1::__compressed_pair_elem.475" = type { %"struct.std::__1::__hash_node_base.467" }
%"class.std::__1::__compressed_pair.479" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.482" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unique_ptr.488" = type { %"class.std::__1::__compressed_pair.489" }
%"class.std::__1::__compressed_pair.489" = type { %"struct.std::__1::__compressed_pair_elem.490" }
%"struct.std::__1::__compressed_pair_elem.490" = type { %"class.v8::internal::GlobalHandleVector"* }
%"class.v8::internal::GlobalHandleVector" = type opaque
%"class.std::__1::unique_ptr.494" = type { %"class.std::__1::__compressed_pair.495" }
%"class.std::__1::__compressed_pair.495" = type { %"struct.std::__1::__compressed_pair_elem.496" }
%"struct.std::__1::__compressed_pair_elem.496" = type { %"class.v8::internal::GlobalSafepoint"* }
%"class.v8::internal::GlobalSafepoint" = type <{ %"class.v8::internal::GlobalSafepoint::Barrier", %"class.v8::internal::Heap"*, %"class.v8::base::Mutex", %"class.v8::internal::LocalHeap"*, i32, [4 x i8] }>
%"class.v8::internal::GlobalSafepoint::Barrier" = type { %"class.v8::base::Mutex", %"class.v8::base::ConditionVariable", %"class.v8::base::ConditionVariable", i8, i32 }
%"class.v8::internal::Heap::ExternalStringTable" = type { %"class.v8::internal::Heap"*, %"class.std::__1::vector.502", %"class.std::__1::vector.502" }
%"class.std::__1::unique_ptr.509" = type { %"class.std::__1::__compressed_pair.510" }
%"class.std::__1::__compressed_pair.510" = type { %"struct.std::__1::__compressed_pair_elem.511" }
%"struct.std::__1::__compressed_pair_elem.511" = type { %"class.v8::internal::CollectionBarrier"* }
%"class.v8::internal::CollectionBarrier" = type opaque
%"class.v8::internal::HeapObject" = type { %"class.v8::internal::Object" }
%"class.v8::base::SharedMutex" = type { %union.pthread_rwlock_t }
%union.pthread_rwlock_t = type { %struct.__pthread_rwlock_arch_t }
%struct.__pthread_rwlock_arch_t = type { i32, i32, i32, i32, i32, i32, i32, i32, i8, [7 x i8], i64, i32 }
%"class.v8::base::Mutex" = type { %union.pthread_mutex_t }
%"class.std::__1::unordered_set.290" = type { %"class.std::__1::__hash_table.291" }
%"class.std::__1::__hash_table.291" = type <{ %"class.std::__1::unique_ptr.292", %"class.std::__1::__compressed_pair.302", %"class.std::__1::__compressed_pair.307", %"class.std::__1::__compressed_pair.311", [4 x i8] }>
%"class.std::__1::unique_ptr.292" = type { %"class.std::__1::__compressed_pair.293" }
%"class.std::__1::__compressed_pair.293" = type { %"struct.std::__1::__compressed_pair_elem.294", %"struct.std::__1::__compressed_pair_elem.296" }
%"struct.std::__1::__compressed_pair_elem.294" = type { %"struct.std::__1::__hash_node_base.295"** }
%"struct.std::__1::__hash_node_base.295" = type { %"struct.std::__1::__hash_node_base.295"* }
%"struct.std::__1::__compressed_pair_elem.296" = type { %"class.std::__1::__bucket_list_deallocator.297" }
%"class.std::__1::__bucket_list_deallocator.297" = type { %"class.std::__1::__compressed_pair.298" }
%"class.std::__1::__compressed_pair.298" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.302" = type { %"struct.std::__1::__compressed_pair_elem.303" }
%"struct.std::__1::__compressed_pair_elem.303" = type { %"struct.std::__1::__hash_node_base.295" }
%"class.std::__1::__compressed_pair.307" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.311" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.541" = type { %"class.std::__1::__hash_table.542" }
%"class.std::__1::__hash_table.542" = type <{ %"class.std::__1::unique_ptr.543", %"class.std::__1::__compressed_pair.553", %"class.std::__1::__compressed_pair.558", %"class.std::__1::__compressed_pair.561", [4 x i8] }>
%"class.std::__1::unique_ptr.543" = type { %"class.std::__1::__compressed_pair.544" }
%"class.std::__1::__compressed_pair.544" = type { %"struct.std::__1::__compressed_pair_elem.545", %"struct.std::__1::__compressed_pair_elem.547" }
%"struct.std::__1::__compressed_pair_elem.545" = type { %"struct.std::__1::__hash_node_base.546"** }
%"struct.std::__1::__hash_node_base.546" = type { %"struct.std::__1::__hash_node_base.546"* }
%"struct.std::__1::__compressed_pair_elem.547" = type { %"class.std::__1::__bucket_list_deallocator.548" }
%"class.std::__1::__bucket_list_deallocator.548" = type { %"class.std::__1::__compressed_pair.549" }
%"class.std::__1::__compressed_pair.549" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.553" = type { %"struct.std::__1::__compressed_pair_elem.554" }
%"struct.std::__1::__compressed_pair_elem.554" = type { %"struct.std::__1::__hash_node_base.546" }
%"class.std::__1::__compressed_pair.558" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.561" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.515" = type { %"class.std::__1::__hash_table.516" }
%"class.std::__1::__hash_table.516" = type <{ %"class.std::__1::unique_ptr.517", %"class.std::__1::__compressed_pair.527", %"class.std::__1::__compressed_pair.532", %"class.std::__1::__compressed_pair.535", [4 x i8] }>
%"class.std::__1::unique_ptr.517" = type { %"class.std::__1::__compressed_pair.518" }
%"class.std::__1::__compressed_pair.518" = type { %"struct.std::__1::__compressed_pair_elem.519", %"struct.std::__1::__compressed_pair_elem.521" }
%"struct.std::__1::__compressed_pair_elem.519" = type { %"struct.std::__1::__hash_node_base.520"** }
%"struct.std::__1::__hash_node_base.520" = type { %"struct.std::__1::__hash_node_base.520"* }
%"struct.std::__1::__compressed_pair_elem.521" = type { %"class.std::__1::__bucket_list_deallocator.522" }
%"class.std::__1::__bucket_list_deallocator.522" = type { %"class.std::__1::__compressed_pair.523" }
%"class.std::__1::__compressed_pair.523" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.527" = type { %"struct.std::__1::__compressed_pair_elem.528" }
%"struct.std::__1::__compressed_pair_elem.528" = type { %"struct.std::__1::__hash_node_base.520" }
%"class.std::__1::__compressed_pair.532" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.535" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::unordered_map.565" = type { %"class.std::__1::__hash_table.566" }
%"class.std::__1::__hash_table.566" = type <{ %"class.std::__1::unique_ptr.567", %"class.std::__1::__compressed_pair.577", %"class.std::__1::__compressed_pair.582", %"class.std::__1::__compressed_pair.587", [4 x i8] }>
%"class.std::__1::unique_ptr.567" = type { %"class.std::__1::__compressed_pair.568" }
%"class.std::__1::__compressed_pair.568" = type { %"struct.std::__1::__compressed_pair_elem.569", %"struct.std::__1::__compressed_pair_elem.571" }
%"struct.std::__1::__compressed_pair_elem.569" = type { %"struct.std::__1::__hash_node_base.570"** }
%"struct.std::__1::__hash_node_base.570" = type { %"struct.std::__1::__hash_node_base.570"* }
%"struct.std::__1::__compressed_pair_elem.571" = type { %"class.std::__1::__bucket_list_deallocator.572" }
%"class.std::__1::__bucket_list_deallocator.572" = type { %"class.std::__1::__compressed_pair.573" }
%"class.std::__1::__compressed_pair.573" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.577" = type { %"struct.std::__1::__compressed_pair_elem.578" }
%"struct.std::__1::__compressed_pair_elem.578" = type { %"struct.std::__1::__hash_node_base.570" }
%"class.std::__1::__compressed_pair.582" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"class.std::__1::__compressed_pair.587" = type { %"struct.std::__1::__compressed_pair_elem.12" }
%"class.std::__1::vector.593" = type { %"class.std::__1::__vector_base.594" }
%"class.std::__1::__vector_base.594" = type { %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.std::__1::__compressed_pair.595" }
%"class.std::__1::__compressed_pair.595" = type { %"struct.std::__1::__compressed_pair_elem.596" }
%"struct.std::__1::__compressed_pair_elem.596" = type { %"class.v8::internal::HeapObjectAllocationTracker"** }
%"class.std::__1::unique_ptr.600" = type { %"class.std::__1::__compressed_pair.601" }
%"class.std::__1::__compressed_pair.601" = type { %"struct.std::__1::__compressed_pair_elem.602" }
%"struct.std::__1::__compressed_pair_elem.602" = type { %"class.v8::internal::third_party_heap::Heap"* }
%"class.v8::internal::third_party_heap::Heap" = type { i8 }
%"struct.std::__1::atomic.606" = type { %"struct.std::__1::__atomic_base.607" }
%"struct.std::__1::__atomic_base.607" = type { %"struct.std::__1::__cxx_atomic_impl.608" }
%"struct.std::__1::__cxx_atomic_impl.608" = type { %"struct.std::__1::__cxx_atomic_base_impl.609" }
%"struct.std::__1::__cxx_atomic_base_impl.609" = type { %"class.v8::internal::BaseSpace"* }
%"class.v8::internal::VirtualMemory" = type { %"class.v8::PageAllocator"*, %"class.v8::base::AddressRegion" }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.14" }
%"struct.std::__1::__atomic_base.14" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i64 }
%"class.v8::internal::SlotSet" = type { i8 }
%"class.v8::internal::TypedSlotSet" = type { %"class.v8::internal::TypedSlots", i64 }
%"class.v8::internal::TypedSlots" = type { i32 (...)**, %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"* }
%"struct.v8::internal::TypedSlots::Chunk" = type { %"struct.v8::internal::TypedSlots::Chunk"*, %"class.std::__1::vector.610" }
%"class.std::__1::vector.610" = type { %"class.std::__1::__vector_base.611" }
%"class.std::__1::__vector_base.611" = type { %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"*, %"class.std::__1::__compressed_pair.612" }
%"struct.v8::internal::TypedSlots::TypedSlot" = type { i32 }
%"class.std::__1::__compressed_pair.612" = type { %"struct.std::__1::__compressed_pair_elem.613" }
%"struct.std::__1::__compressed_pair_elem.613" = type { %"struct.v8::internal::TypedSlots::TypedSlot"* }
%"class.std::__1::set.617" = type { %"class.std::__1::__tree.618" }
%"class.std::__1::__tree.618" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.619", %"class.std::__1::__compressed_pair.623" }
%"class.std::__1::__compressed_pair.619" = type { %"struct.std::__1::__compressed_pair_elem.445" }
%"class.std::__1::__compressed_pair.623" = type { %"struct.std::__1::__compressed_pair_elem.2" }
%"struct.std::__1::atomic.625" = type { %"struct.std::__1::__atomic_base.626" }
%"struct.std::__1::__atomic_base.626" = type { %"struct.std::__1::__cxx_atomic_impl.627" }
%"struct.std::__1::__cxx_atomic_impl.627" = type { %"struct.std::__1::__cxx_atomic_base_impl.628" }
%"struct.std::__1::__cxx_atomic_base_impl.628" = type { i64 }
%"class.v8::internal::heap::ListNode" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::FreeListCategory" = type { i32, i32, %"class.v8::internal::FreeSpace", %"class.v8::internal::FreeListCategory"*, %"class.v8::internal::FreeListCategory"* }
%"class.v8::internal::FreeSpace" = type { %"class.v8::internal::TorqueGeneratedFreeSpace" }
%"class.v8::internal::TorqueGeneratedFreeSpace" = type { %"class.v8::internal::HeapObject" }
%"struct.std::__1::atomic.15" = type { %"struct.std::__1::__atomic_base.16" }
%"struct.std::__1::__atomic_base.16" = type { %"struct.std::__1::__atomic_base.17" }
%"struct.std::__1::__atomic_base.17" = type { %"struct.std::__1::__cxx_atomic_impl.18" }
%"struct.std::__1::__cxx_atomic_impl.18" = type { %"struct.std::__1::__cxx_atomic_base_impl.19" }
%"struct.std::__1::__cxx_atomic_base_impl.19" = type { i64 }
%"class.v8::internal::Bitmap" = type { i8 }
%"class.v8::internal::CodeObjectRegistry" = type <{ %"class.std::__1::vector.629", i8, [7 x i8] }>
%"class.std::__1::vector.629" = type { %"class.std::__1::__vector_base.630" }
%"class.std::__1::__vector_base.630" = type { i64*, i64*, %"class.std::__1::__compressed_pair.631" }
%"class.std::__1::__compressed_pair.631" = type { %"struct.std::__1::__compressed_pair_elem.632" }
%"struct.std::__1::__compressed_pair_elem.632" = type { i64* }
%"class.v8::internal::PossiblyEmptyBuckets" = type { i64 }
%"class.v8::internal::SlotSet::Bucket" = type { [32 x i32] }
%"class.std::__1::tuple" = type { %"struct.std::__1::__tuple_impl" }
%"struct.std::__1::__tuple_impl" = type { %"class.std::__1::__tuple_leaf" }
%"class.std::__1::__tuple_leaf" = type { i64* }
%"class.std::__1::tuple.1150" = type { i8 }
%"class.std::__1::unique_ptr.1151" = type { %"class.std::__1::__compressed_pair.1152" }
%"class.std::__1::__compressed_pair.1152" = type { %"struct.std::__1::__compressed_pair_elem.1153", %"struct.std::__1::__compressed_pair_elem.1154" }
%"struct.std::__1::__compressed_pair_elem.1153" = type { %"struct.std::__1::__hash_node.1146"* }
%"struct.std::__1::__hash_node.1146" = type { %"struct.std::__1::__hash_node_base.76", i64, %"struct.std::__1::__hash_value_type" }
%"struct.std::__1::__hash_value_type" = type { %"struct.std::__1::pair.1128" }
%"struct.std::__1::pair.1128" = type { i64, %"class.v8::internal::LargePage"* }
%"struct.std::__1::__compressed_pair_elem.1154" = type { %"class.std::__1::__hash_node_destructor" }
%"class.std::__1::__hash_node_destructor" = type <{ %"class.std::__1::allocator.86"*, i8, [7 x i8] }>
%"class.std::__1::allocator.86" = type { i8 }
%"class.v8::internal::ConcurrentBitmap.1148" = type { i8 }
%"class.std::__1::function" = type { %"class.std::__1::__function::__policy_func" }
%"class.std::__1::__function::__policy_func" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker", %"struct.std::__1::__function::__policy"* }
%"union.std::__1::__function::__policy_storage" = type { i8*, [8 x i8] }
%"struct.std::__1::__function::__policy_invoker" = type { i1 (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::HeapObject"*)* }
%"struct.std::__1::__function::__policy" = type { i8* (i8*)*, void (i8*)*, i8, %"class.std::type_info"* }
%"class.std::type_info" = type { i32 (...)**, i8* }
%"class.v8::internal::NoFreeList" = type { %"class.v8::internal::FreeList" }

$_ZN2v88internal14ObjectIteratorD2Ev = comdat any

$_ZN2v88internal9BaseSpace15CommittedMemoryEv = comdat any

$_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv = comdat any

$_ZN2v88internal16LargeObjectSpace4SizeEv = comdat any

$_ZN2v88internal16LargeObjectSpaceD0Ev = comdat any

$_ZN2v88internal5Space29StartNextInlineAllocationStepEv = comdat any

$_ZN2v88internal16LargeObjectSpace13SizeOfObjectsEv = comdat any

$_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi = comdat any

$_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE = comdat any

$_ZNK2v88internal16LargeObjectSpace13is_off_threadEv = comdat any

$_ZN2v88internal30LargeObjectSpaceObjectIteratorD0Ev = comdat any

$_ZN2v88internal16LargeObjectSpaceD2Ev = comdat any

$_ZN2v88internal19NewLargeObjectSpaceD0Ev = comdat any

$_ZN2v88internal20CodeLargeObjectSpaceD2Ev = comdat any

$_ZN2v88internal20CodeLargeObjectSpaceD0Ev = comdat any

$_ZN2v88internal19OldLargeObjectSpaceD0Ev = comdat any

$_ZN2v88internal8FreeListD2Ev = comdat any

$_ZN2v88internal10NoFreeListD0Ev = comdat any

$_ZN2v88internal10NoFreeList21GuaranteedAllocatableEm = comdat any

$_ZN2v88internal10NoFreeList4FreeEmmNS0_8FreeModeE = comdat any

$_ZN2v88internal10NoFreeList8AllocateEmPmNS0_16AllocationOriginE = comdat any

$_ZN2v88internal10NoFreeList14GetPageForSizeEm = comdat any

$_ZN2v88internal10NoFreeList26SelectFreeListCategoryTypeEm = comdat any

$_ZN2v88internal7SlotSet11RemoveRangeEmmmNS1_15EmptyBucketModeE = comdat any

$_ZN2v88internal7SlotSet6Bucket7IsEmptyEv = comdat any

$_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE25__emplace_unique_key_argsImJRKNS_21piecewise_construct_tENS_5tupleIJRKmEEENSM_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeIS6_PvEEEEbEERKT_DpOT0_ = comdat any

$_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE6rehashEm = comdat any

$_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE8__rehashEm = comdat any

$_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE6removeENS_21__hash_const_iteratorIPNS_11__hash_nodeIS6_PvEEEE = comdat any

$_ZTVN2v88internal19OldLargeObjectSpaceE = comdat any

$_ZTVN2v88internal10NoFreeListE = comdat any

@.str = private unnamed_addr constant [24 x i8] c"Code page is too large.\00", align 1
@_ZTVN2v88internal30LargeObjectSpaceObjectIteratorE = hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::internal::ObjectIterator"*)* @_ZN2v88internal14ObjectIteratorD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpaceObjectIterator"*)* @_ZN2v88internal30LargeObjectSpaceObjectIteratorD0Ev to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpaceObjectIterator"*)* @_ZN2v88internal30LargeObjectSpaceObjectIterator4NextEv to i8*)] }, align 8
@_ZTVN2v88internal16LargeObjectSpaceE = hidden unnamed_addr constant { [22 x i8*] } { [22 x i8*] [i8* null, i8* null, i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace15CommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace23CommittedPhysicalMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace4SizeEv to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpaceD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpaceD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space21AddAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space24RemoveAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space24PauseAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space25ResumeAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space29StartNextInlineAllocationStepEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace13SizeOfObjectsEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace9AvailableEv to i8*), i8* bitcast (i32 (%"class.v8::internal::Space"*, i32)* @_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi to i8*), i8* bitcast (%"class.v8::internal::ObjectIterator"* (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal16LargeObjectSpace17GetObjectIteratorEPNS0_4HeapE to i8*), i8* bitcast (i64 (%"class.v8::internal::Space"*, i32)* @_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace19FreeUnmarkedObjectsEv to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)* @_ZN2v88internal16LargeObjectSpace7AddPageEPNS0_9LargePageEm to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)* @_ZN2v88internal16LargeObjectSpace10RemovePageEPNS0_9LargePageEm to i8*), i8* bitcast (i1 (%"class.v8::internal::LargeObjectSpace"*)* @_ZNK2v88internal16LargeObjectSpace13is_off_threadEv to i8*)] }, align 8
@_ZN2v88internal8FLAG_logE = external local_unnamed_addr global i8, align 1
@.str.1 = private unnamed_addr constant [17 x i8] c"LargeObjectChunk\00", align 1
@.str.2 = private unnamed_addr constant [18 x i8] c"Check failed: %s.\00", align 1
@.str.3 = private unnamed_addr constant [18 x i8] c"page->Contains(a)\00", align 1
@_ZTVN2v88internal19OldLargeObjectSpaceE = linkonce_odr hidden unnamed_addr constant { [22 x i8*] } { [22 x i8*] [i8* null, i8* null, i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace15CommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace23CommittedPhysicalMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace4SizeEv to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpaceD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::OldLargeObjectSpace"*)* @_ZN2v88internal19OldLargeObjectSpaceD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space21AddAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space24RemoveAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space24PauseAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space25ResumeAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space29StartNextInlineAllocationStepEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace13SizeOfObjectsEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace9AvailableEv to i8*), i8* bitcast (i32 (%"class.v8::internal::Space"*, i32)* @_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi to i8*), i8* bitcast (%"class.v8::internal::ObjectIterator"* (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal16LargeObjectSpace17GetObjectIteratorEPNS0_4HeapE to i8*), i8* bitcast (i64 (%"class.v8::internal::Space"*, i32)* @_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace19FreeUnmarkedObjectsEv to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)* @_ZN2v88internal16LargeObjectSpace7AddPageEPNS0_9LargePageEm to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)* @_ZN2v88internal16LargeObjectSpace10RemovePageEPNS0_9LargePageEm to i8*), i8* bitcast (i1 (%"class.v8::internal::LargeObjectSpace"*)* @_ZNK2v88internal16LargeObjectSpace13is_off_threadEv to i8*)] }, comdat, align 8
@_ZTVN2v88internal19NewLargeObjectSpaceE = hidden unnamed_addr constant { [22 x i8*] } { [22 x i8*] [i8* null, i8* null, i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace15CommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace23CommittedPhysicalMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace4SizeEv to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpaceD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::NewLargeObjectSpace"*)* @_ZN2v88internal19NewLargeObjectSpaceD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space21AddAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space24RemoveAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space24PauseAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space25ResumeAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space29StartNextInlineAllocationStepEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace13SizeOfObjectsEv to i8*), i8* bitcast (i64 (%"class.v8::internal::NewLargeObjectSpace"*)* @_ZN2v88internal19NewLargeObjectSpace9AvailableEv to i8*), i8* bitcast (i32 (%"class.v8::internal::Space"*, i32)* @_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi to i8*), i8* bitcast (%"class.v8::internal::ObjectIterator"* (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal16LargeObjectSpace17GetObjectIteratorEPNS0_4HeapE to i8*), i8* bitcast (i64 (%"class.v8::internal::Space"*, i32)* @_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace19FreeUnmarkedObjectsEv to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)* @_ZN2v88internal16LargeObjectSpace7AddPageEPNS0_9LargePageEm to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)* @_ZN2v88internal16LargeObjectSpace10RemovePageEPNS0_9LargePageEm to i8*), i8* bitcast (i1 (%"class.v8::internal::LargeObjectSpace"*)* @_ZNK2v88internal16LargeObjectSpace13is_off_threadEv to i8*)] }, align 8
@_ZN2v88internal13FLAG_minor_mcE = external local_unnamed_addr global i8, align 1
@_ZN2v88internal23FLAG_concurrent_markingE = external local_unnamed_addr global i8, align 1
@_ZTVN2v88internal20CodeLargeObjectSpaceE = hidden unnamed_addr constant { [22 x i8*] } { [22 x i8*] [i8* null, i8* null, i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace15CommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::BaseSpace"*)* @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace23CommittedPhysicalMemoryEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace4SizeEv to i8*), i8* bitcast (void (%"class.v8::internal::CodeLargeObjectSpace"*)* @_ZN2v88internal20CodeLargeObjectSpaceD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::CodeLargeObjectSpace"*)* @_ZN2v88internal20CodeLargeObjectSpaceD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space21AddAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*)* @_ZN2v88internal5Space24RemoveAllocationObserverEPNS0_18AllocationObserverE to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space24PauseAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space25ResumeAllocationObserversEv to i8*), i8* bitcast (void (%"class.v8::internal::Space"*)* @_ZN2v88internal5Space29StartNextInlineAllocationStepEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace13SizeOfObjectsEv to i8*), i8* bitcast (i64 (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace9AvailableEv to i8*), i8* bitcast (i32 (%"class.v8::internal::Space"*, i32)* @_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi to i8*), i8* bitcast (%"class.v8::internal::ObjectIterator"* (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal16LargeObjectSpace17GetObjectIteratorEPNS0_4HeapE to i8*), i8* bitcast (i64 (%"class.v8::internal::Space"*, i32)* @_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE to i8*), i8* bitcast (void (%"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal16LargeObjectSpace19FreeUnmarkedObjectsEv to i8*), i8* bitcast (void (%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)* @_ZN2v88internal20CodeLargeObjectSpace7AddPageEPNS0_9LargePageEm to i8*), i8* bitcast (void (%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)* @_ZN2v88internal20CodeLargeObjectSpace10RemovePageEPNS0_9LargePageEm to i8*), i8* bitcast (i1 (%"class.v8::internal::LargeObjectSpace"*)* @_ZNK2v88internal16LargeObjectSpace13is_off_threadEv to i8*)] }, align 8
@_ZTVN2v88internal10NoFreeListE = linkonce_odr hidden unnamed_addr constant { [12 x i8*] } { [12 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::internal::FreeList"*)* @_ZN2v88internal8FreeListD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::NoFreeList"*)* @_ZN2v88internal10NoFreeListD0Ev to i8*), i8* bitcast (i64 (%"class.v8::internal::NoFreeList"*, i64)* @_ZN2v88internal10NoFreeList21GuaranteedAllocatableEm to i8*), i8* bitcast (i64 (%"class.v8::internal::NoFreeList"*, i64, i64, i32)* @_ZN2v88internal10NoFreeList4FreeEmmNS0_8FreeModeE to i8*), i8* bitcast (i64 (%"class.v8::internal::NoFreeList"*, i64, i64*, i32)* @_ZN2v88internal10NoFreeList8AllocateEmPmNS0_16AllocationOriginE to i8*), i8* bitcast (%"class.v8::internal::Page"* (%"class.v8::internal::NoFreeList"*, i64)* @_ZN2v88internal10NoFreeList14GetPageForSizeEm to i8*), i8* bitcast (void (%"class.v8::internal::FreeList"*)* @_ZN2v88internal8FreeList5ResetEv to i8*), i8* bitcast (i1 (%"class.v8::internal::FreeList"*, %"class.v8::internal::FreeListCategory"*)* @_ZN2v88internal8FreeList11AddCategoryEPNS0_16FreeListCategoryE to i8*), i8* bitcast (void (%"class.v8::internal::FreeList"*, %"class.v8::internal::FreeListCategory"*)* @_ZN2v88internal8FreeList14RemoveCategoryEPNS0_16FreeListCategoryE to i8*), i8* bitcast (i32 (%"class.v8::internal::NoFreeList"*, i64)* @_ZN2v88internal10NoFreeList26SelectFreeListCategoryTypeEm to i8*)] }, comdat, align 8
@.str.4 = private unnamed_addr constant [50 x i8] c"NoFreeList can't be used as a standard FreeList. \00", align 1
@.str.5 = private unnamed_addr constant [49 x i8] c"NoFreeList can't be used as a standard FreeList.\00", align 1
@_ZTVN2v88internal5SpaceE = external unnamed_addr constant { [18 x i8*] }, align 8
@.str.6 = private unnamed_addr constant [16 x i8] c"!object.IsSmi()\00", align 1
@.str.7 = private unnamed_addr constant [53 x i8] c"end_offset <= buckets * kBitsPerBucket * kTaggedSize\00", align 1
@_ZNSt3__1L19piecewise_constructE = internal constant %"struct.std::__1::piecewise_construct_t" undef, align 1

@_ZN2v88internal30LargeObjectSpaceObjectIteratorC1EPNS0_16LargeObjectSpaceE = hidden unnamed_addr alias void (%"class.v8::internal::LargeObjectSpaceObjectIterator"*, %"class.v8::internal::LargeObjectSpace"*), void (%"class.v8::internal::LargeObjectSpaceObjectIterator"*, %"class.v8::internal::LargeObjectSpace"*)* @_ZN2v88internal30LargeObjectSpaceObjectIteratorC2EPNS0_16LargeObjectSpaceE
@_ZN2v88internal16LargeObjectSpaceC1EPNS0_4HeapENS0_15AllocationSpaceE = hidden unnamed_addr alias void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::Heap"*, i32), void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::Heap"*, i32)* @_ZN2v88internal16LargeObjectSpaceC2EPNS0_4HeapENS0_15AllocationSpaceE
@_ZN2v88internal19OldLargeObjectSpaceC1EPNS0_4HeapE = hidden unnamed_addr alias void (%"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::Heap"*), void (%"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal19OldLargeObjectSpaceC2EPNS0_4HeapE
@_ZN2v88internal19OldLargeObjectSpaceC1EPNS0_4HeapENS0_15AllocationSpaceE = hidden unnamed_addr alias void (%"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::Heap"*, i32), void (%"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::Heap"*, i32)* @_ZN2v88internal19OldLargeObjectSpaceC2EPNS0_4HeapENS0_15AllocationSpaceE
@_ZN2v88internal19NewLargeObjectSpaceC1EPNS0_4HeapEm = hidden unnamed_addr alias void (%"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::Heap"*, i64), void (%"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::Heap"*, i64)* @_ZN2v88internal19NewLargeObjectSpaceC2EPNS0_4HeapEm
@_ZN2v88internal20CodeLargeObjectSpaceC1EPNS0_4HeapE = hidden unnamed_addr alias void (%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::Heap"*), void (%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::Heap"*)* @_ZN2v88internal20CodeLargeObjectSpaceC2EPNS0_4HeapE

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::LargePage"* @_ZN2v88internal9LargePage10InitializeEPNS0_4HeapEPNS0_11MemoryChunkENS0_13ExecutabilityE(%"class.v8::internal::Heap"* nocapture readnone, %"class.v8::internal::MemoryChunk"*, i32) local_unnamed_addr #0 align 2 {
  %4 = icmp eq i32 %2, 0
  br i1 %4, label %10, label %5

5:                                                ; preds = %3
  %6 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %1, i64 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = icmp ugt i64 %7, 536870912
  br i1 %8, label %9, label %10

9:                                                ; preds = %5
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str, i64 0, i64 0)) #13
  unreachable

10:                                               ; preds = %3, %5
  %11 = bitcast %"class.v8::internal::MemoryChunk"* %1 to %"class.v8::internal::LargePage"*
  %12 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %1, i64 0, i32 0, i32 1
  %13 = load i64, i64* %12, align 8
  %14 = or i64 %13, 32
  store i64 %14, i64* %12, align 8
  %15 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %1, i64 0, i32 12
  %16 = bitcast %"class.v8::internal::heap::ListNode"* %15 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %16, i8 0, i64 16, i1 false) #14
  ret %"class.v8::internal::LargePage"* %11
}

; Function Attrs: noreturn
declare void @_Z8V8_FatalPKcz(i8*, ...) local_unnamed_addr #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden i64 @_ZN2v88internal16LargeObjectSpace9AvailableEv(%"class.v8::internal::LargeObjectSpace"* nocapture readnone) unnamed_addr #3 align 2 {
  ret i64 0
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal9LargePage18GetAddressToShrinkEmm(%"class.v8::internal::LargePage"*, i64, i64) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0, i32 0, i32 1
  %5 = load i64, i64* %4, align 8
  %6 = and i64 %5, 1
  %7 = icmp eq i64 %6, 0
  br i1 %7, label %8, label %22

8:                                                ; preds = %3
  %9 = ptrtoint %"class.v8::internal::LargePage"* %0 to i64
  %10 = tail call i64 @_ZN2v88internal15MemoryAllocator17GetCommitPageSizeEv() #14
  %11 = xor i64 %9, -1
  %12 = add i64 %11, %1
  %13 = add i64 %12, %2
  %14 = add i64 %13, %10
  %15 = sub nsw i64 0, %10
  %16 = and i64 %14, %15
  %17 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0
  %18 = tail call i64 @_ZN2v88internal11MemoryChunk23CommittedPhysicalMemoryEv(%"class.v8::internal::MemoryChunk"* %17) #14
  %19 = icmp ult i64 %16, %18
  %20 = add i64 %16, %9
  %21 = select i1 %19, i64 %20, i64 0
  ret i64 %21

22:                                               ; preds = %3
  ret i64 0
}

declare i64 @_ZN2v88internal15MemoryAllocator17GetCommitPageSizeEv() local_unnamed_addr #4

declare i64 @_ZN2v88internal11MemoryChunk23CommittedPhysicalMemoryEv(%"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal9LargePage24ClearOutOfLiveRangeSlotsEm(%"class.v8::internal::LargePage"*, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0, i32 0, i32 4
  %4 = load i64, i64* %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0, i32 1, i64 0
  %6 = bitcast %"class.v8::internal::SlotSet"** %5 to i64*
  %7 = load atomic i64, i64* %6 acquire, align 8
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %22, label %9

9:                                                ; preds = %2
  %10 = inttoptr i64 %7 to %"class.v8::internal::SlotSet"*
  %11 = ptrtoint %"class.v8::internal::LargePage"* %0 to i64
  %12 = sub i64 %1, %11
  %13 = sub i64 %4, %11
  %14 = shl i64 %12, 32
  %15 = ashr exact i64 %14, 32
  %16 = shl i64 %13, 32
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0, i32 0, i32 0
  %19 = load i64, i64* %18, align 8
  %20 = add i64 %19, 4095
  %21 = lshr i64 %20, 12
  tail call void @_ZN2v88internal7SlotSet11RemoveRangeEmmmNS1_15EmptyBucketModeE(%"class.v8::internal::SlotSet"* nonnull %10, i64 %15, i64 %17, i64 %21, i32 0) #14
  br label %22

22:                                               ; preds = %2, %9
  %23 = load i64, i64* %3, align 8
  %24 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0, i32 1, i64 1
  %25 = bitcast %"class.v8::internal::SlotSet"** %24 to i64*
  %26 = load atomic i64, i64* %25 acquire, align 8
  %27 = icmp eq i64 %26, 0
  br i1 %27, label %41, label %28

28:                                               ; preds = %22
  %29 = inttoptr i64 %26 to %"class.v8::internal::SlotSet"*
  %30 = ptrtoint %"class.v8::internal::LargePage"* %0 to i64
  %31 = sub i64 %1, %30
  %32 = sub i64 %23, %30
  %33 = shl i64 %31, 32
  %34 = ashr exact i64 %33, 32
  %35 = shl i64 %32, 32
  %36 = ashr exact i64 %35, 32
  %37 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0, i32 0, i32 0
  %38 = load i64, i64* %37, align 8
  %39 = add i64 %38, 4095
  %40 = lshr i64 %39, 12
  tail call void @_ZN2v88internal7SlotSet11RemoveRangeEmmmNS1_15EmptyBucketModeE(%"class.v8::internal::SlotSet"* nonnull %29, i64 %34, i64 %36, i64 %40, i32 0) #14
  br label %41

41:                                               ; preds = %22, %28
  %42 = load i64, i64* %3, align 8
  %43 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0, i32 5, i64 0
  %44 = bitcast %"class.v8::internal::TypedSlotSet"** %43 to i64*
  %45 = load atomic i64, i64* %44 acquire, align 8
  %46 = inttoptr i64 %45 to %"class.v8::internal::TypedSlotSet"*
  %47 = icmp eq i64 %45, 0
  br i1 %47, label %140, label %48

48:                                               ; preds = %41
  %49 = getelementptr inbounds %"class.v8::internal::TypedSlotSet", %"class.v8::internal::TypedSlotSet"* %46, i64 0, i32 0, i32 1
  %50 = load %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"** %49, align 8
  %51 = icmp eq %"struct.v8::internal::TypedSlots::Chunk"* %50, null
  br i1 %51, label %140, label %52

52:                                               ; preds = %48
  %53 = getelementptr inbounds %"class.v8::internal::TypedSlotSet", %"class.v8::internal::TypedSlotSet"* %46, i64 0, i32 1
  %54 = bitcast %"struct.v8::internal::TypedSlots::Chunk"** %49 to i64*
  br label %55

55:                                               ; preds = %136, %52
  %56 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %137, %136 ], [ %50, %52 ]
  %57 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %138, %136 ], [ null, %52 ]
  %58 = getelementptr inbounds %"struct.v8::internal::TypedSlots::Chunk", %"struct.v8::internal::TypedSlots::Chunk"* %56, i64 0, i32 1, i32 0, i32 0
  %59 = load %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"** %58, align 8
  %60 = getelementptr inbounds %"struct.v8::internal::TypedSlots::Chunk", %"struct.v8::internal::TypedSlots::Chunk"* %56, i64 0, i32 1, i32 0, i32 1
  %61 = load %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"** %60, align 8
  %62 = icmp eq %"struct.v8::internal::TypedSlots::TypedSlot"* %59, %61
  br i1 %62, label %74, label %63

63:                                               ; preds = %55
  %64 = ptrtoint %"struct.v8::internal::TypedSlots::TypedSlot"* %59 to i64
  %65 = getelementptr %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %61, i64 -1
  %66 = ptrtoint %"struct.v8::internal::TypedSlots::TypedSlot"* %65 to i64
  %67 = sub i64 %66, %64
  %68 = lshr i64 %67, 2
  %69 = add nuw nsw i64 %68, 1
  %70 = and i64 %69, 1
  %71 = icmp eq i64 %68, 0
  br i1 %71, label %77, label %72

72:                                               ; preds = %63
  %73 = sub nuw nsw i64 %69, %70
  br label %101

74:                                               ; preds = %55
  %75 = getelementptr inbounds %"struct.v8::internal::TypedSlots::Chunk", %"struct.v8::internal::TypedSlots::Chunk"* %56, i64 0, i32 0
  %76 = load %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"** %75, align 8
  br label %122

77:                                               ; preds = %263, %63
  %78 = phi i8 [ undef, %63 ], [ %264, %263 ]
  %79 = phi i8 [ 1, %63 ], [ %264, %263 ]
  %80 = phi %"struct.v8::internal::TypedSlots::TypedSlot"* [ %59, %63 ], [ %265, %263 ]
  %81 = icmp eq i64 %70, 0
  br i1 %81, label %95, label %82

82:                                               ; preds = %77
  %83 = getelementptr inbounds %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %80, i64 0, i32 0
  %84 = load i32, i32* %83, align 4
  %85 = icmp ugt i32 %84, -536870913
  br i1 %85, label %95, label %86

86:                                               ; preds = %82
  %87 = and i32 %84, 536870911
  %88 = load i64, i64* %53, align 8
  %89 = zext i32 %87 to i64
  %90 = add i64 %88, %89
  %91 = icmp uge i64 %90, %1
  %92 = icmp ult i64 %90, %42
  %93 = and i1 %91, %92
  br i1 %93, label %94, label %95

94:                                               ; preds = %86
  store i32 -536870912, i32* %83, align 4
  br label %95

95:                                               ; preds = %94, %86, %82, %77
  %96 = phi i8 [ %78, %77 ], [ %79, %82 ], [ %79, %94 ], [ 0, %86 ]
  %97 = getelementptr inbounds %"struct.v8::internal::TypedSlots::Chunk", %"struct.v8::internal::TypedSlots::Chunk"* %56, i64 0, i32 0
  %98 = load %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"** %97, align 8
  %99 = and i8 %96, 1
  %100 = icmp eq i8 %99, 0
  br i1 %100, label %136, label %122

101:                                              ; preds = %263, %72
  %102 = phi i8 [ 1, %72 ], [ %264, %263 ]
  %103 = phi %"struct.v8::internal::TypedSlots::TypedSlot"* [ %59, %72 ], [ %265, %263 ]
  %104 = phi i64 [ %73, %72 ], [ %266, %263 ]
  %105 = getelementptr inbounds %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %103, i64 0, i32 0
  %106 = load i32, i32* %105, align 4
  %107 = icmp ugt i32 %106, -536870913
  br i1 %107, label %117, label %108

108:                                              ; preds = %101
  %109 = and i32 %106, 536870911
  %110 = load i64, i64* %53, align 8
  %111 = zext i32 %109 to i64
  %112 = add i64 %110, %111
  %113 = icmp uge i64 %112, %1
  %114 = icmp ult i64 %112, %42
  %115 = and i1 %113, %114
  br i1 %115, label %116, label %117

116:                                              ; preds = %108
  store i32 -536870912, i32* %105, align 4
  br label %117

117:                                              ; preds = %116, %108, %101
  %118 = phi i8 [ %102, %101 ], [ %102, %116 ], [ 0, %108 ]
  %119 = getelementptr inbounds %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %103, i64 1, i32 0
  %120 = load i32, i32* %119, align 4
  %121 = icmp ugt i32 %120, -536870913
  br i1 %121, label %263, label %254

122:                                              ; preds = %95, %74
  %123 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %76, %74 ], [ %98, %95 ]
  %124 = icmp eq %"struct.v8::internal::TypedSlots::Chunk"* %57, null
  %125 = bitcast %"struct.v8::internal::TypedSlots::Chunk"* %57 to i64*
  %126 = select i1 %124, i64* %54, i64* %125
  %127 = ptrtoint %"struct.v8::internal::TypedSlots::Chunk"* %123 to i64
  store atomic volatile i64 %127, i64* %126 monotonic, align 8
  %128 = load %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"** %58, align 8
  %129 = icmp eq %"struct.v8::internal::TypedSlots::TypedSlot"* %128, null
  br i1 %129, label %134, label %130

130:                                              ; preds = %122
  %131 = ptrtoint %"struct.v8::internal::TypedSlots::TypedSlot"* %128 to i64
  %132 = bitcast %"struct.v8::internal::TypedSlots::TypedSlot"** %60 to i64*
  store i64 %131, i64* %132, align 8
  %133 = bitcast %"struct.v8::internal::TypedSlots::TypedSlot"* %128 to i8*
  tail call void @_ZdlPv(i8* %133) #15
  br label %134

134:                                              ; preds = %130, %122
  %135 = bitcast %"struct.v8::internal::TypedSlots::Chunk"* %56 to i8*
  tail call void @_ZdlPv(i8* %135) #15
  br label %136

136:                                              ; preds = %134, %95
  %137 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %123, %134 ], [ %98, %95 ]
  %138 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %57, %134 ], [ %56, %95 ]
  %139 = icmp eq %"struct.v8::internal::TypedSlots::Chunk"* %137, null
  br i1 %139, label %140, label %55

140:                                              ; preds = %136, %41, %48
  %141 = load i64, i64* %3, align 8
  %142 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %0, i64 0, i32 0, i32 5, i64 1
  %143 = bitcast %"class.v8::internal::TypedSlotSet"** %142 to i64*
  %144 = load atomic i64, i64* %143 acquire, align 8
  %145 = inttoptr i64 %144 to %"class.v8::internal::TypedSlotSet"*
  %146 = icmp eq i64 %144, 0
  br i1 %146, label %239, label %147

147:                                              ; preds = %140
  %148 = getelementptr inbounds %"class.v8::internal::TypedSlotSet", %"class.v8::internal::TypedSlotSet"* %145, i64 0, i32 0, i32 1
  %149 = load %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"** %148, align 8
  %150 = icmp eq %"struct.v8::internal::TypedSlots::Chunk"* %149, null
  br i1 %150, label %239, label %151

151:                                              ; preds = %147
  %152 = getelementptr inbounds %"class.v8::internal::TypedSlotSet", %"class.v8::internal::TypedSlotSet"* %145, i64 0, i32 1
  %153 = bitcast %"struct.v8::internal::TypedSlots::Chunk"** %148 to i64*
  br label %154

154:                                              ; preds = %235, %151
  %155 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %236, %235 ], [ %149, %151 ]
  %156 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %237, %235 ], [ null, %151 ]
  %157 = getelementptr inbounds %"struct.v8::internal::TypedSlots::Chunk", %"struct.v8::internal::TypedSlots::Chunk"* %155, i64 0, i32 1, i32 0, i32 0
  %158 = load %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"** %157, align 8
  %159 = getelementptr inbounds %"struct.v8::internal::TypedSlots::Chunk", %"struct.v8::internal::TypedSlots::Chunk"* %155, i64 0, i32 1, i32 0, i32 1
  %160 = load %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"** %159, align 8
  %161 = icmp eq %"struct.v8::internal::TypedSlots::TypedSlot"* %158, %160
  br i1 %161, label %173, label %162

162:                                              ; preds = %154
  %163 = ptrtoint %"struct.v8::internal::TypedSlots::TypedSlot"* %158 to i64
  %164 = getelementptr %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %160, i64 -1
  %165 = ptrtoint %"struct.v8::internal::TypedSlots::TypedSlot"* %164 to i64
  %166 = sub i64 %165, %163
  %167 = lshr i64 %166, 2
  %168 = add nuw nsw i64 %167, 1
  %169 = and i64 %168, 1
  %170 = icmp eq i64 %167, 0
  br i1 %170, label %176, label %171

171:                                              ; preds = %162
  %172 = sub nuw nsw i64 %168, %169
  br label %200

173:                                              ; preds = %154
  %174 = getelementptr inbounds %"struct.v8::internal::TypedSlots::Chunk", %"struct.v8::internal::TypedSlots::Chunk"* %155, i64 0, i32 0
  %175 = load %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"** %174, align 8
  br label %221

176:                                              ; preds = %249, %162
  %177 = phi i8 [ undef, %162 ], [ %250, %249 ]
  %178 = phi i8 [ 1, %162 ], [ %250, %249 ]
  %179 = phi %"struct.v8::internal::TypedSlots::TypedSlot"* [ %158, %162 ], [ %251, %249 ]
  %180 = icmp eq i64 %169, 0
  br i1 %180, label %194, label %181

181:                                              ; preds = %176
  %182 = getelementptr inbounds %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %179, i64 0, i32 0
  %183 = load i32, i32* %182, align 4
  %184 = icmp ugt i32 %183, -536870913
  br i1 %184, label %194, label %185

185:                                              ; preds = %181
  %186 = and i32 %183, 536870911
  %187 = load i64, i64* %152, align 8
  %188 = zext i32 %186 to i64
  %189 = add i64 %187, %188
  %190 = icmp uge i64 %189, %1
  %191 = icmp ult i64 %189, %141
  %192 = and i1 %190, %191
  br i1 %192, label %193, label %194

193:                                              ; preds = %185
  store i32 -536870912, i32* %182, align 4
  br label %194

194:                                              ; preds = %193, %185, %181, %176
  %195 = phi i8 [ %177, %176 ], [ %178, %181 ], [ %178, %193 ], [ 0, %185 ]
  %196 = getelementptr inbounds %"struct.v8::internal::TypedSlots::Chunk", %"struct.v8::internal::TypedSlots::Chunk"* %155, i64 0, i32 0
  %197 = load %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"** %196, align 8
  %198 = and i8 %195, 1
  %199 = icmp eq i8 %198, 0
  br i1 %199, label %235, label %221

200:                                              ; preds = %249, %171
  %201 = phi i8 [ 1, %171 ], [ %250, %249 ]
  %202 = phi %"struct.v8::internal::TypedSlots::TypedSlot"* [ %158, %171 ], [ %251, %249 ]
  %203 = phi i64 [ %172, %171 ], [ %252, %249 ]
  %204 = getelementptr inbounds %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %202, i64 0, i32 0
  %205 = load i32, i32* %204, align 4
  %206 = icmp ugt i32 %205, -536870913
  br i1 %206, label %216, label %207

207:                                              ; preds = %200
  %208 = and i32 %205, 536870911
  %209 = load i64, i64* %152, align 8
  %210 = zext i32 %208 to i64
  %211 = add i64 %209, %210
  %212 = icmp uge i64 %211, %1
  %213 = icmp ult i64 %211, %141
  %214 = and i1 %212, %213
  br i1 %214, label %215, label %216

215:                                              ; preds = %207
  store i32 -536870912, i32* %204, align 4
  br label %216

216:                                              ; preds = %215, %207, %200
  %217 = phi i8 [ %201, %200 ], [ %201, %215 ], [ 0, %207 ]
  %218 = getelementptr inbounds %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %202, i64 1, i32 0
  %219 = load i32, i32* %218, align 4
  %220 = icmp ugt i32 %219, -536870913
  br i1 %220, label %249, label %240

221:                                              ; preds = %194, %173
  %222 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %175, %173 ], [ %197, %194 ]
  %223 = icmp eq %"struct.v8::internal::TypedSlots::Chunk"* %156, null
  %224 = bitcast %"struct.v8::internal::TypedSlots::Chunk"* %156 to i64*
  %225 = select i1 %223, i64* %153, i64* %224
  %226 = ptrtoint %"struct.v8::internal::TypedSlots::Chunk"* %222 to i64
  store atomic volatile i64 %226, i64* %225 monotonic, align 8
  %227 = load %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"** %157, align 8
  %228 = icmp eq %"struct.v8::internal::TypedSlots::TypedSlot"* %227, null
  br i1 %228, label %233, label %229

229:                                              ; preds = %221
  %230 = ptrtoint %"struct.v8::internal::TypedSlots::TypedSlot"* %227 to i64
  %231 = bitcast %"struct.v8::internal::TypedSlots::TypedSlot"** %159 to i64*
  store i64 %230, i64* %231, align 8
  %232 = bitcast %"struct.v8::internal::TypedSlots::TypedSlot"* %227 to i8*
  tail call void @_ZdlPv(i8* %232) #15
  br label %233

233:                                              ; preds = %229, %221
  %234 = bitcast %"struct.v8::internal::TypedSlots::Chunk"* %155 to i8*
  tail call void @_ZdlPv(i8* %234) #15
  br label %235

235:                                              ; preds = %233, %194
  %236 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %222, %233 ], [ %197, %194 ]
  %237 = phi %"struct.v8::internal::TypedSlots::Chunk"* [ %156, %233 ], [ %155, %194 ]
  %238 = icmp eq %"struct.v8::internal::TypedSlots::Chunk"* %236, null
  br i1 %238, label %239, label %154

239:                                              ; preds = %235, %140, %147
  ret void

240:                                              ; preds = %216
  %241 = and i32 %219, 536870911
  %242 = load i64, i64* %152, align 8
  %243 = zext i32 %241 to i64
  %244 = add i64 %242, %243
  %245 = icmp uge i64 %244, %1
  %246 = icmp ult i64 %244, %141
  %247 = and i1 %245, %246
  br i1 %247, label %248, label %249

248:                                              ; preds = %240
  store i32 -536870912, i32* %218, align 4
  br label %249

249:                                              ; preds = %248, %240, %216
  %250 = phi i8 [ %217, %216 ], [ %217, %248 ], [ 0, %240 ]
  %251 = getelementptr inbounds %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %202, i64 2
  %252 = add i64 %203, -2
  %253 = icmp eq i64 %252, 0
  br i1 %253, label %176, label %200

254:                                              ; preds = %117
  %255 = and i32 %120, 536870911
  %256 = load i64, i64* %53, align 8
  %257 = zext i32 %255 to i64
  %258 = add i64 %256, %257
  %259 = icmp uge i64 %258, %1
  %260 = icmp ult i64 %258, %42
  %261 = and i1 %259, %260
  br i1 %261, label %262, label %263

262:                                              ; preds = %254
  store i32 -536870912, i32* %119, align 4
  br label %263

263:                                              ; preds = %262, %254, %117
  %264 = phi i8 [ %118, %117 ], [ %118, %262 ], [ 0, %254 ]
  %265 = getelementptr inbounds %"struct.v8::internal::TypedSlots::TypedSlot", %"struct.v8::internal::TypedSlots::TypedSlot"* %103, i64 2
  %266 = add i64 %104, -2
  %267 = icmp eq i64 %266, 0
  br i1 %267, label %77, label %101
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal30LargeObjectSpaceObjectIteratorC2EPNS0_16LargeObjectSpaceE(%"class.v8::internal::LargeObjectSpaceObjectIterator"* nocapture, %"class.v8::internal::LargeObjectSpace"* nocapture readonly) unnamed_addr #5 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::LargeObjectSpaceObjectIterator", %"class.v8::internal::LargeObjectSpaceObjectIterator"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2v88internal30LargeObjectSpaceObjectIteratorE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %3, align 8
  %4 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %1, i64 0, i32 0, i32 2, i32 0
  %5 = bitcast %"class.v8::internal::MemoryChunk"** %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::LargeObjectSpaceObjectIterator", %"class.v8::internal::LargeObjectSpaceObjectIterator"* %0, i64 0, i32 1
  %8 = bitcast %"class.v8::internal::LargePage"** %7 to i64*
  store i64 %6, i64* %8, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden i64 @_ZN2v88internal30LargeObjectSpaceObjectIterator4NextEv(%"class.v8::internal::LargeObjectSpaceObjectIterator"* nocapture) unnamed_addr #5 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::LargeObjectSpaceObjectIterator", %"class.v8::internal::LargeObjectSpaceObjectIterator"* %0, i64 0, i32 1
  %3 = load %"class.v8::internal::LargePage"*, %"class.v8::internal::LargePage"** %2, align 8
  %4 = icmp eq %"class.v8::internal::LargePage"* %3, null
  br i1 %4, label %13, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %3, i64 0, i32 0, i32 0, i32 3
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 1
  %9 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %3, i64 0, i32 0, i32 12, i32 0
  %10 = bitcast %"class.v8::internal::MemoryChunk"** %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = bitcast %"class.v8::internal::LargePage"** %2 to i64*
  store i64 %11, i64* %12, align 8
  br label %13

13:                                               ; preds = %1, %5
  %14 = phi i64 [ %8, %5 ], [ 0, %1 ]
  ret i64 %14
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal16LargeObjectSpaceC2EPNS0_4HeapENS0_15AllocationSpaceE(%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::Heap"*, i32) unnamed_addr #0 align 2 {
  %4 = tail call i8* @_Znwm(i64 48) #15
  %5 = bitcast i8* %4 to i32 (...)***
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 48, i1 false)
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [12 x i8*] }, { [12 x i8*] }* @_ZTVN2v88internal10NoFreeListE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0
  %7 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2
  store i32 %2, i32* %8, align 8
  %9 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %10 = bitcast i64* %9 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %10, i8 0, i64 16, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %11 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1
  %12 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 2, i32 0, i32 3
  %13 = bitcast %"class.std::__1::__compressed_pair.54"* %12 to i32*
  %14 = bitcast %"class.v8::internal::AllocationCounter"* %11 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %14, i8 0, i64 80, i1 false) #14
  store i32 1065353216, i32* %13, align 4
  %15 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 3
  store i8 0, i8* %15, align 8
  %16 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 5
  %17 = bitcast i64* %16 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %17, i8 0, i64 17, i1 false) #14
  %18 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2
  %19 = bitcast %"class.v8::internal::heap::List"* %18 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %19, i8 0, i64 16, i1 false) #14
  %20 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 4
  %21 = ptrtoint i8* %4 to i64
  %22 = bitcast %"class.std::__1::unique_ptr.59"* %20 to i64*
  store i64 %21, i64* %22, align 8
  %23 = tail call i8* @_Znam(i64 16) #15
  %24 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 3
  %25 = bitcast %"struct.std::__1::atomic"** %24 to i8**
  store i8* %23, i8** %25, align 8
  %26 = bitcast i8* %23 to i64*
  store atomic i64 0, i64* %26 seq_cst, align 8
  %27 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %24, align 8
  %28 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %27, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %28 seq_cst, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal16LargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %29 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %29, align 8
  %30 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 2
  store i32 0, i32* %30, align 8
  %31 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %31, align 8
  %32 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 4
  tail call void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"* %32) #14
  %33 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %33, align 8
  ret void
}

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #6

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #2

declare void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"*) unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal16LargeObjectSpace8TearDownEv(%"class.v8::internal::LargeObjectSpace"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %3 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2
  %4 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %3, i64 0, i32 0
  %5 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %6 = bitcast %"class.v8::internal::Heap"** %5 to i64*
  %7 = bitcast %"class.v8::internal::MemoryChunk"** %2 to i64*
  %8 = bitcast %"class.v8::internal::heap::List"* %3 to i64*
  br label %9

9:                                                ; preds = %51, %1
  %10 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %4, align 8
  %11 = icmp eq %"class.v8::internal::MemoryChunk"* %10, null
  br i1 %11, label %12, label %15

12:                                               ; preds = %9
  %13 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %2, align 8
  %14 = icmp eq %"class.v8::internal::MemoryChunk"* %13, null
  br i1 %14, label %56, label %15

15:                                               ; preds = %9, %12
  %16 = load i8, i8* @_ZN2v88internal8FLAG_logE, align 1, !range !2
  %17 = icmp eq i8 %16, 0
  br i1 %17, label %25, label %18

18:                                               ; preds = %15
  %19 = load i64, i64* %6, align 8
  %20 = add i64 %19, -41416
  %21 = inttoptr i64 %20 to %"class.v8::internal::Isolate"*
  %22 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %21, i64 0, i32 21
  %23 = load %"class.v8::internal::Logger"*, %"class.v8::internal::Logger"** %22, align 8
  %24 = bitcast %"class.v8::internal::MemoryChunk"* %10 to i8*
  tail call void @_ZN2v88internal6Logger11DeleteEventEPKcPv(%"class.v8::internal::Logger"* %23, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.1, i64 0, i64 0), i8* %24) #14
  br label %25

25:                                               ; preds = %15, %18
  %26 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %2, align 8
  %27 = icmp eq %"class.v8::internal::MemoryChunk"* %26, %10
  br i1 %27, label %28, label %32

28:                                               ; preds = %25
  %29 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %10, i64 0, i32 12, i32 1
  %30 = bitcast %"class.v8::internal::MemoryChunk"** %29 to i64*
  %31 = load i64, i64* %30, align 8
  store i64 %31, i64* %7, align 8
  br label %32

32:                                               ; preds = %28, %25
  %33 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %4, align 8
  %34 = icmp eq %"class.v8::internal::MemoryChunk"* %33, %10
  br i1 %34, label %35, label %39

35:                                               ; preds = %32
  %36 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %10, i64 0, i32 12, i32 0
  %37 = bitcast %"class.v8::internal::MemoryChunk"** %36 to i64*
  %38 = load i64, i64* %37, align 8
  store i64 %38, i64* %8, align 8
  br label %39

39:                                               ; preds = %35, %32
  %40 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %10, i64 0, i32 12, i32 0
  %41 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %40, align 8
  %42 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %10, i64 0, i32 12, i32 1
  %43 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %42, align 8
  %44 = icmp eq %"class.v8::internal::MemoryChunk"* %41, null
  br i1 %44, label %47, label %45

45:                                               ; preds = %39
  %46 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %41, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %43, %"class.v8::internal::MemoryChunk"** %46, align 8
  br label %47

47:                                               ; preds = %45, %39
  %48 = icmp eq %"class.v8::internal::MemoryChunk"* %43, null
  br i1 %48, label %51, label %49

49:                                               ; preds = %47
  %50 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %43, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %41, %"class.v8::internal::MemoryChunk"** %50, align 8
  br label %51

51:                                               ; preds = %47, %49
  %52 = bitcast %"class.v8::internal::MemoryChunk"** %40 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %52, i8 0, i64 16, i1 false) #14
  %53 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %54 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %53, i64 0, i32 85, i32 0, i32 0, i32 0
  %55 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %54, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE0EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %55, %"class.v8::internal::MemoryChunk"* %10) #14
  br label %9

56:                                               ; preds = %12
  ret void
}

declare void @_ZN2v88internal6Logger11DeleteEventEPKcPv(%"class.v8::internal::Logger"*, i8*, i8*) local_unnamed_addr #4

declare void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE0EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal16LargeObjectSpace35AdvanceAndInvokeAllocationObserversEmm(%"class.v8::internal::LargeObjectSpace"*, i64, i64) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1
  %5 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 3
  %6 = load i8, i8* %5, align 8, !range !2
  %7 = icmp eq i8 %6, 0
  br i1 %7, label %8, label %24

8:                                                ; preds = %3
  %9 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %10 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = bitcast %"class.v8::internal::AllocationCounter"* %4 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = icmp eq i64 %11, %13
  br i1 %14, label %24, label %15

15:                                               ; preds = %8
  %16 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 6
  %17 = load i64, i64* %16, align 8
  %18 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 5
  %19 = load i64, i64* %18, align 8
  %20 = sub i64 %17, %19
  %21 = icmp ugt i64 %20, %2
  br i1 %21, label %23, label %22

22:                                               ; preds = %15
  tail call void @_ZN2v88internal17AllocationCounter25InvokeAllocationObserversEmmm(%"class.v8::internal::AllocationCounter"* %4, i64 %1, i64 %2, i64 %2) #14
  br label %23

23:                                               ; preds = %15, %22
  tail call void @_ZN2v88internal17AllocationCounter26AdvanceAllocationObserversEm(%"class.v8::internal::AllocationCounter"* %4, i64 %2) #14
  br label %24

24:                                               ; preds = %8, %3, %23
  ret void
}

declare void @_ZN2v88internal17AllocationCounter25InvokeAllocationObserversEmmm(%"class.v8::internal::AllocationCounter"*, i64, i64, i64) local_unnamed_addr #4

declare void @_ZN2v88internal17AllocationCounter26AdvanceAllocationObserversEm(%"class.v8::internal::AllocationCounter"*, i64) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19OldLargeObjectSpace11AllocateRawEi(%"class.v8::internal::OldLargeObjectSpace"*, i32) local_unnamed_addr #0 align 2 {
  %3 = tail call i64 @_ZN2v88internal19OldLargeObjectSpace11AllocateRawEiNS0_13ExecutabilityE(%"class.v8::internal::OldLargeObjectSpace"* %0, i32 %1, i32 0)
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19OldLargeObjectSpace11AllocateRawEiNS0_13ExecutabilityE(%"class.v8::internal::OldLargeObjectSpace"*, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::HeapObject", align 8
  %5 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %6 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %7 = sext i32 %1 to i64
  %8 = tail call zeroext i1 @_ZN2v88internal4Heap22CanExpandOldGenerationEm(%"class.v8::internal::Heap"* %6, i64 %7) #14
  br i1 %8, label %9, label %144

9:                                                ; preds = %3
  %10 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %11 = tail call zeroext i1 @_ZN2v88internal4Heap41ShouldExpandOldGenerationOnSlowAllocationEPNS0_9LocalHeapE(%"class.v8::internal::Heap"* %10, %"class.v8::internal::LocalHeap"* null) #14
  br i1 %11, label %12, label %144

12:                                               ; preds = %9
  %13 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0
  %14 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %15 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %14, i64 0, i32 85, i32 0, i32 0, i32 0
  %16 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %15, align 8
  %17 = tail call %"class.v8::internal::LargePage"* @_ZN2v88internal15MemoryAllocator17AllocateLargePageEmPNS0_16LargeObjectSpaceENS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"* %16, i64 %7, %"class.v8::internal::LargeObjectSpace"* %13, i32 %2) #14
  %18 = icmp eq %"class.v8::internal::LargePage"* %17, null
  br i1 %18, label %144, label %19

19:                                               ; preds = %12
  %20 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 4
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %20) #14
  %21 = bitcast %"class.v8::internal::OldLargeObjectSpace"* %0 to void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)***
  %22 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %21, align 8
  %23 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %22, i64 17
  %24 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %23, align 8
  tail call void %24(%"class.v8::internal::LargeObjectSpace"* %13, %"class.v8::internal::LargePage"* nonnull %17, i64 %7) #14
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %20) #14
  %25 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %17, i64 0, i32 0, i32 0, i32 3
  %26 = load i64, i64* %25, align 8
  %27 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %28 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %27, i64 %26, i32 %1, i32 1) #14
  %29 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %17, i64 0, i32 0
  %30 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %31 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %30, i64 0, i32 86, i32 0, i32 0, i32 0
  %32 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %31, align 8
  %33 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %32, i64 0, i32 11, i32 0, i32 0, i32 0, i32 0
  %34 = load atomic i8, i8* %33 seq_cst, align 1
  %35 = icmp ne i8 %34, 0
  tail call void @_ZN2v88internal11MemoryChunk25SetOldGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"* %29, i1 zeroext %35) #14
  %36 = load i64, i64* %25, align 8
  %37 = add i64 %36, 1
  %38 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %39 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %38, i64 0, i32 129
  tail call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %39) #14
  %40 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %36, i64* %40 release, align 8
  tail call void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"* %39) #14
  %41 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %42 = tail call zeroext i1 @_ZN2v88internal4Heap28ShouldOptimizeForMemoryUsageEv(%"class.v8::internal::Heap"* %41) #14
  %43 = zext i1 %42 to i32
  tail call void @_ZN2v88internal4Heap49StartIncrementalMarkingIfAllocationLimitIsReachedEiNS_15GCCallbackFlagsE(%"class.v8::internal::Heap"* %41, i32 %43, i32 64) #14
  %44 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %45 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %44, i64 0, i32 86, i32 0, i32 0, i32 0
  %46 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %45, align 8
  %47 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %46, i64 0, i32 14
  %48 = load i8, i8* %47, align 1, !range !2
  %49 = icmp eq i8 %48, 0
  br i1 %49, label %116, label %50

50:                                               ; preds = %19
  %51 = and i64 %37, -262144
  %52 = or i64 %51, 272
  %53 = sub i64 %37, %51
  %54 = trunc i64 %53 to i32
  %55 = lshr i32 %54, 2
  %56 = and i32 %55, 31
  %57 = shl i32 1, %56
  %58 = inttoptr i64 %52 to i32*
  %59 = lshr i64 %53, 7
  %60 = and i64 %59, 33554431
  %61 = getelementptr inbounds i32, i32* %58, i64 %60
  %62 = load atomic i32, i32* %61 monotonic, align 4
  br label %63

63:                                               ; preds = %67, %50
  %64 = phi i32 [ %62, %50 ], [ %70, %67 ]
  %65 = and i32 %64, %57
  %66 = icmp eq i32 %65, %57
  br i1 %66, label %116, label %67

67:                                               ; preds = %63
  %68 = or i32 %64, %57
  %69 = cmpxchg volatile i32* %61, i32 %64, i32 %68 release monotonic
  %70 = extractvalue { i32, i1 } %69, 0
  %71 = extractvalue { i32, i1 } %69, 1
  br i1 %71, label %72, label %63

72:                                               ; preds = %67
  %73 = bitcast %"class.v8::internal::HeapObject"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %73) #14
  %74 = getelementptr inbounds %"class.v8::internal::HeapObject", %"class.v8::internal::HeapObject"* %4, i64 0, i32 0, i32 0, i32 0
  store i64 %37, i64* %74, align 8
  %75 = sub i64 %36, %51
  %76 = trunc i64 %75 to i32
  %77 = lshr i32 %76, 2
  %78 = and i32 %77, 31
  %79 = shl i32 1, %78
  %80 = lshr i64 %75, 7
  %81 = and i64 %80, 33554431
  %82 = getelementptr inbounds i32, i32* %58, i64 %81
  %83 = load atomic i32, i32* %82 acquire, align 4
  %84 = and i32 %83, %79
  %85 = icmp eq i32 %84, 0
  br i1 %85, label %115, label %86

86:                                               ; preds = %72
  %87 = shl i32 %79, 1
  %88 = icmp eq i32 %87, 0
  %89 = getelementptr inbounds i32, i32* %82, i64 1
  %90 = select i1 %88, i32 1, i32 %87
  %91 = select i1 %88, i32* %89, i32* %82
  %92 = load atomic i32, i32* %91 monotonic, align 4
  br label %93

93:                                               ; preds = %97, %86
  %94 = phi i32 [ %92, %86 ], [ %100, %97 ]
  %95 = and i32 %94, %90
  %96 = icmp eq i32 %95, %90
  br i1 %96, label %115, label %97

97:                                               ; preds = %93
  %98 = or i32 %94, %90
  %99 = cmpxchg volatile i32* %91, i32 %94, i32 %98 release monotonic
  %100 = extractvalue { i32, i1 } %99, 0
  %101 = extractvalue { i32, i1 } %99, 1
  br i1 %101, label %102, label %93

102:                                              ; preds = %97
  %103 = inttoptr i64 %51 to %"class.v8::internal::MemoryChunk"*
  %104 = load i64, i64* %74, align 8
  %105 = and i64 %104, -4294967296
  %106 = add i64 %104, -1
  %107 = inttoptr i64 %106 to i32*
  %108 = load atomic i32, i32* %107 monotonic, align 4
  %109 = zext i32 %108 to i64
  %110 = or i64 %105, %109
  %111 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %4, i64 %110) #14
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %103, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %114 = atomicrmw add i64* %113, i64 %112 monotonic
  br label %115

115:                                              ; preds = %93, %102, %72
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %73) #14
  br label %116

116:                                              ; preds = %63, %19, %115
  call void @_ZN2v88internal11MemoryChunk25InitializationMemoryFenceEv(%"class.v8::internal::MemoryChunk"* %29) #14
  %117 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %118 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %119 = load i32, i32* %118, align 8
  call void @_ZN2v88internal4Heap28NotifyOldGenerationExpansionENS0_15AllocationSpaceEPNS0_11MemoryChunkE(%"class.v8::internal::Heap"* %117, i32 %119, %"class.v8::internal::MemoryChunk"* %29) #14
  %120 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %121 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 3
  %122 = load i8, i8* %121, align 8, !range !2
  %123 = icmp eq i8 %122, 0
  br i1 %123, label %124, label %140

124:                                              ; preds = %116
  %125 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %126 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %125 to i64*
  %127 = load i64, i64* %126, align 8
  %128 = bitcast %"class.v8::internal::AllocationCounter"* %120 to i64*
  %129 = load i64, i64* %128, align 8
  %130 = icmp eq i64 %127, %129
  br i1 %130, label %140, label %131

131:                                              ; preds = %124
  %132 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 6
  %133 = load i64, i64* %132, align 8
  %134 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 5
  %135 = load i64, i64* %134, align 8
  %136 = sub i64 %133, %135
  %137 = icmp ugt i64 %136, %7
  br i1 %137, label %139, label %138

138:                                              ; preds = %131
  call void @_ZN2v88internal17AllocationCounter25InvokeAllocationObserversEmmm(%"class.v8::internal::AllocationCounter"* %120, i64 %36, i64 %7, i64 %7) #14
  br label %139

139:                                              ; preds = %138, %131
  call void @_ZN2v88internal17AllocationCounter26AdvanceAllocationObserversEm(%"class.v8::internal::AllocationCounter"* %120, i64 %7) #14
  br label %140

140:                                              ; preds = %116, %124, %139
  %141 = and i64 %37, 1
  %142 = icmp eq i64 %141, 0
  br i1 %142, label %143, label %149, !prof !3

143:                                              ; preds = %140
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.2, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.6, i64 0, i64 0)) #13
  unreachable

144:                                              ; preds = %12, %3, %9
  %145 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %146 = load i32, i32* %145, align 8
  %147 = sext i32 %146 to i64
  %148 = shl nsw i64 %147, 1
  br label %149

149:                                              ; preds = %144, %140
  %150 = phi i64 [ %37, %140 ], [ %148, %144 ]
  ret i64 %150
}

declare zeroext i1 @_ZN2v88internal4Heap22CanExpandOldGenerationEm(%"class.v8::internal::Heap"*, i64) local_unnamed_addr #4

declare zeroext i1 @_ZN2v88internal4Heap41ShouldExpandOldGenerationOnSlowAllocationEPNS0_9LocalHeapE(%"class.v8::internal::Heap"*, %"class.v8::internal::LocalHeap"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::LargePage"* @_ZN2v88internal16LargeObjectSpace17AllocateLargePageEiNS0_13ExecutabilityE(%"class.v8::internal::LargeObjectSpace"*, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %5 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %5, i64 0, i32 85, i32 0, i32 0, i32 0
  %7 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %6, align 8
  %8 = sext i32 %1 to i64
  %9 = tail call %"class.v8::internal::LargePage"* @_ZN2v88internal15MemoryAllocator17AllocateLargePageEmPNS0_16LargeObjectSpaceENS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"* %7, i64 %8, %"class.v8::internal::LargeObjectSpace"* %0, i32 %2) #14
  %10 = icmp eq %"class.v8::internal::LargePage"* %9, null
  br i1 %10, label %21, label %11

11:                                               ; preds = %3
  %12 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 4
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %12) #14
  %13 = bitcast %"class.v8::internal::LargeObjectSpace"* %0 to void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)***
  %14 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %13, align 8
  %15 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %14, i64 17
  %16 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %15, align 8
  tail call void %16(%"class.v8::internal::LargeObjectSpace"* %0, %"class.v8::internal::LargePage"* nonnull %9, i64 %8) #14
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %12) #14
  %17 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %9, i64 0, i32 0, i32 0, i32 3
  %18 = load i64, i64* %17, align 8
  %19 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %4, align 8
  %20 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %19, i64 %18, i32 %1, i32 1) #14
  br label %21

21:                                               ; preds = %3, %11
  ret %"class.v8::internal::LargePage"* %9
}

declare void @_ZN2v88internal11MemoryChunk25SetOldGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"*, i1 zeroext) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal16LargeObjectSpace19UpdatePendingObjectENS0_10HeapObjectE(%"class.v8::internal::LargeObjectSpace"* nocapture, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %4 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %4, i64 0, i32 129
  tail call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %5) #14
  %6 = add i64 %1, -1
  %7 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %6, i64* %7 release, align 8
  tail call void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"* %5) #14
  ret void
}

declare void @_ZN2v88internal4Heap49StartIncrementalMarkingIfAllocationLimitIsReachedEiNS_15GCCallbackFlagsE(%"class.v8::internal::Heap"*, i32, i32) local_unnamed_addr #4

declare void @_ZN2v88internal11MemoryChunk25InitializationMemoryFenceEv(%"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

declare void @_ZN2v88internal4Heap28NotifyOldGenerationExpansionENS0_15AllocationSpaceEPNS0_11MemoryChunkE(%"class.v8::internal::Heap"*, i32, %"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19OldLargeObjectSpace21AllocateRawBackgroundEPNS0_9LocalHeapEi(%"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::LocalHeap"*, i32) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::HeapObject", align 8
  %5 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %6 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %7 = sext i32 %2 to i64
  %8 = tail call zeroext i1 @_ZN2v88internal4Heap32CanExpandOldGenerationBackgroundEPNS0_9LocalHeapEm(%"class.v8::internal::Heap"* %6, %"class.v8::internal::LocalHeap"* %1, i64 %7) #14
  br i1 %8, label %9, label %115

9:                                                ; preds = %3
  %10 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %11 = tail call zeroext i1 @_ZN2v88internal4Heap41ShouldExpandOldGenerationOnSlowAllocationEPNS0_9LocalHeapE(%"class.v8::internal::Heap"* %10, %"class.v8::internal::LocalHeap"* %1) #14
  br i1 %11, label %12, label %115

12:                                               ; preds = %9
  %13 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0
  %14 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %15 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %14, i64 0, i32 85, i32 0, i32 0, i32 0
  %16 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %15, align 8
  %17 = tail call %"class.v8::internal::LargePage"* @_ZN2v88internal15MemoryAllocator17AllocateLargePageEmPNS0_16LargeObjectSpaceENS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"* %16, i64 %7, %"class.v8::internal::LargeObjectSpace"* %13, i32 0) #14
  %18 = icmp eq %"class.v8::internal::LargePage"* %17, null
  br i1 %18, label %115, label %19

19:                                               ; preds = %12
  %20 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 4
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %20) #14
  %21 = bitcast %"class.v8::internal::OldLargeObjectSpace"* %0 to void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)***
  %22 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %21, align 8
  %23 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %22, i64 17
  %24 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %23, align 8
  tail call void %24(%"class.v8::internal::LargeObjectSpace"* %13, %"class.v8::internal::LargePage"* nonnull %17, i64 %7) #14
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %20) #14
  %25 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %17, i64 0, i32 0, i32 0, i32 3
  %26 = load i64, i64* %25, align 8
  %27 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %28 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %27, i64 %26, i32 %2, i32 1) #14
  %29 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %17, i64 0, i32 0
  %30 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %31 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %30, i64 0, i32 86, i32 0, i32 0, i32 0
  %32 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %31, align 8
  %33 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %32, i64 0, i32 11, i32 0, i32 0, i32 0, i32 0
  %34 = load atomic i8, i8* %33 seq_cst, align 1
  %35 = icmp ne i8 %34, 0
  tail call void @_ZN2v88internal11MemoryChunk25SetOldGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"* %29, i1 zeroext %35) #14
  %36 = load i64, i64* %25, align 8
  %37 = add i64 %36, 1
  %38 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  tail call void @_ZN2v88internal4Heap59StartIncrementalMarkingIfAllocationLimitIsReachedBackgroundEv(%"class.v8::internal::Heap"* %38) #14
  %39 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %40 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %39, i64 0, i32 86, i32 0, i32 0, i32 0
  %41 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %40, align 8
  %42 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %41, i64 0, i32 14
  %43 = load i8, i8* %42, align 1, !range !2
  %44 = icmp eq i8 %43, 0
  br i1 %44, label %111, label %45

45:                                               ; preds = %19
  %46 = and i64 %37, -262144
  %47 = or i64 %46, 272
  %48 = sub i64 %37, %46
  %49 = trunc i64 %48 to i32
  %50 = lshr i32 %49, 2
  %51 = and i32 %50, 31
  %52 = shl i32 1, %51
  %53 = inttoptr i64 %47 to i32*
  %54 = lshr i64 %48, 7
  %55 = and i64 %54, 33554431
  %56 = getelementptr inbounds i32, i32* %53, i64 %55
  %57 = load atomic i32, i32* %56 monotonic, align 4
  br label %58

58:                                               ; preds = %62, %45
  %59 = phi i32 [ %57, %45 ], [ %65, %62 ]
  %60 = and i32 %59, %52
  %61 = icmp eq i32 %60, %52
  br i1 %61, label %111, label %62

62:                                               ; preds = %58
  %63 = or i32 %59, %52
  %64 = cmpxchg volatile i32* %56, i32 %59, i32 %63 release monotonic
  %65 = extractvalue { i32, i1 } %64, 0
  %66 = extractvalue { i32, i1 } %64, 1
  br i1 %66, label %67, label %58

67:                                               ; preds = %62
  %68 = bitcast %"class.v8::internal::HeapObject"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %68) #14
  %69 = getelementptr inbounds %"class.v8::internal::HeapObject", %"class.v8::internal::HeapObject"* %4, i64 0, i32 0, i32 0, i32 0
  store i64 %37, i64* %69, align 8
  %70 = sub i64 %36, %46
  %71 = trunc i64 %70 to i32
  %72 = lshr i32 %71, 2
  %73 = and i32 %72, 31
  %74 = shl i32 1, %73
  %75 = lshr i64 %70, 7
  %76 = and i64 %75, 33554431
  %77 = getelementptr inbounds i32, i32* %53, i64 %76
  %78 = load atomic i32, i32* %77 acquire, align 4
  %79 = and i32 %78, %74
  %80 = icmp eq i32 %79, 0
  br i1 %80, label %110, label %81

81:                                               ; preds = %67
  %82 = shl i32 %74, 1
  %83 = icmp eq i32 %82, 0
  %84 = getelementptr inbounds i32, i32* %77, i64 1
  %85 = select i1 %83, i32 1, i32 %82
  %86 = select i1 %83, i32* %84, i32* %77
  %87 = load atomic i32, i32* %86 monotonic, align 4
  br label %88

88:                                               ; preds = %92, %81
  %89 = phi i32 [ %87, %81 ], [ %95, %92 ]
  %90 = and i32 %89, %85
  %91 = icmp eq i32 %90, %85
  br i1 %91, label %110, label %92

92:                                               ; preds = %88
  %93 = or i32 %89, %85
  %94 = cmpxchg volatile i32* %86, i32 %89, i32 %93 release monotonic
  %95 = extractvalue { i32, i1 } %94, 0
  %96 = extractvalue { i32, i1 } %94, 1
  br i1 %96, label %97, label %88

97:                                               ; preds = %92
  %98 = inttoptr i64 %46 to %"class.v8::internal::MemoryChunk"*
  %99 = load i64, i64* %69, align 8
  %100 = and i64 %99, -4294967296
  %101 = add i64 %99, -1
  %102 = inttoptr i64 %101 to i32*
  %103 = load atomic i32, i32* %102 monotonic, align 4
  %104 = zext i32 %103 to i64
  %105 = or i64 %100, %104
  %106 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %4, i64 %105) #14
  %107 = sext i32 %106 to i64
  %108 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %98, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %109 = atomicrmw add i64* %108, i64 %107 monotonic
  br label %110

110:                                              ; preds = %88, %97, %67
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %68) #14
  br label %111

111:                                              ; preds = %58, %19, %110
  call void @_ZN2v88internal11MemoryChunk25InitializationMemoryFenceEv(%"class.v8::internal::MemoryChunk"* %29) #14
  %112 = and i64 %37, 1
  %113 = icmp eq i64 %112, 0
  br i1 %113, label %114, label %120, !prof !3

114:                                              ; preds = %111
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.2, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.6, i64 0, i64 0)) #13
  unreachable

115:                                              ; preds = %12, %3, %9
  %116 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %117 = load i32, i32* %116, align 8
  %118 = sext i32 %117 to i64
  %119 = shl nsw i64 %118, 1
  br label %120

120:                                              ; preds = %115, %111
  %121 = phi i64 [ %37, %111 ], [ %119, %115 ]
  ret i64 %121
}

declare zeroext i1 @_ZN2v88internal4Heap32CanExpandOldGenerationBackgroundEPNS0_9LocalHeapEm(%"class.v8::internal::Heap"*, %"class.v8::internal::LocalHeap"*, i64) local_unnamed_addr #4

declare void @_ZN2v88internal4Heap59StartIncrementalMarkingIfAllocationLimitIsReachedBackgroundEv(%"class.v8::internal::Heap"*) local_unnamed_addr #4

declare %"class.v8::internal::LargePage"* @_ZN2v88internal15MemoryAllocator17AllocateLargePageEmPNS0_16LargeObjectSpaceENS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"*, i64, %"class.v8::internal::LargeObjectSpace"*, i32) local_unnamed_addr #4

declare i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"*, i64, i32, i32) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal16LargeObjectSpace23CommittedPhysicalMemoryEv(%"class.v8::internal::LargeObjectSpace"*) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0
  %3 = bitcast %"class.v8::internal::LargeObjectSpace"* %0 to i64 (%"class.v8::internal::BaseSpace"*)***
  %4 = load i64 (%"class.v8::internal::BaseSpace"*)**, i64 (%"class.v8::internal::BaseSpace"*)*** %3, align 8
  %5 = load i64 (%"class.v8::internal::BaseSpace"*)*, i64 (%"class.v8::internal::BaseSpace"*)** %4, align 8
  %6 = tail call i64 %5(%"class.v8::internal::BaseSpace"* %2) #14
  ret i64 %6
}

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::LargePage"* @_ZN2v88internal20CodeLargeObjectSpace8FindPageEm(%"class.v8::internal::CodeLargeObjectSpace"* nocapture readonly, i64) local_unnamed_addr #0 align 2 {
  %3 = and i64 %1, -262144
  %4 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %83, label %7

7:                                                ; preds = %2
  %8 = tail call i64 @llvm.ctpop.i64(i64 %5) #14, !range !4
  %9 = icmp ugt i64 %8, 1
  br i1 %9, label %13, label %10

10:                                               ; preds = %7
  %11 = add i64 %5, -1
  %12 = and i64 %11, %3
  br label %17

13:                                               ; preds = %7
  %14 = icmp ult i64 %3, %5
  br i1 %14, label %17, label %15

15:                                               ; preds = %13
  %16 = urem i64 %3, %5
  br label %17

17:                                               ; preds = %15, %13, %10
  %18 = phi i64 [ %12, %10 ], [ %16, %15 ], [ %3, %13 ]
  %19 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %20 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %19, align 8
  %21 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %20, i64 %18
  %22 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %21, align 8
  %23 = icmp eq %"struct.std::__1::__hash_node_base.76"* %22, null
  br i1 %23, label %83, label %24

24:                                               ; preds = %17
  %25 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %22, i64 0, i32 0
  %26 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %25, align 8
  %27 = icmp eq %"struct.std::__1::__hash_node_base.76"* %26, null
  br i1 %27, label %83, label %28

28:                                               ; preds = %24
  %29 = add i64 %5, -1
  br i1 %9, label %30, label %52

30:                                               ; preds = %28, %48
  %31 = phi %"struct.std::__1::__hash_node_base.76"* [ %50, %48 ], [ %26, %28 ]
  %32 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %31, i64 1
  %33 = bitcast %"struct.std::__1::__hash_node_base.76"* %32 to i64*
  %34 = load i64, i64* %33, align 8
  %35 = icmp eq i64 %34, %3
  br i1 %35, label %43, label %36

36:                                               ; preds = %30
  %37 = icmp ult i64 %34, %5
  br i1 %37, label %40, label %38

38:                                               ; preds = %36
  %39 = urem i64 %34, %5
  br label %40

40:                                               ; preds = %38, %36
  %41 = phi i64 [ %39, %38 ], [ %34, %36 ]
  %42 = icmp eq i64 %41, %18
  br i1 %42, label %48, label %83

43:                                               ; preds = %30
  %44 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %31, i64 2
  %45 = bitcast %"struct.std::__1::__hash_node_base.76"* %44 to i64*
  %46 = load i64, i64* %45, align 8
  %47 = icmp eq i64 %46, %3
  br i1 %47, label %70, label %48

48:                                               ; preds = %43, %40
  %49 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %31, i64 0, i32 0
  %50 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %49, align 8
  %51 = icmp eq %"struct.std::__1::__hash_node_base.76"* %50, null
  br i1 %51, label %83, label %30

52:                                               ; preds = %28, %66
  %53 = phi %"struct.std::__1::__hash_node_base.76"* [ %68, %66 ], [ %26, %28 ]
  %54 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %53, i64 1
  %55 = bitcast %"struct.std::__1::__hash_node_base.76"* %54 to i64*
  %56 = load i64, i64* %55, align 8
  %57 = icmp eq i64 %56, %3
  br i1 %57, label %61, label %58

58:                                               ; preds = %52
  %59 = and i64 %56, %29
  %60 = icmp eq i64 %59, %18
  br i1 %60, label %66, label %83

61:                                               ; preds = %52
  %62 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %53, i64 2
  %63 = bitcast %"struct.std::__1::__hash_node_base.76"* %62 to i64*
  %64 = load i64, i64* %63, align 8
  %65 = icmp eq i64 %64, %3
  br i1 %65, label %70, label %66

66:                                               ; preds = %61, %58
  %67 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %53, i64 0, i32 0
  %68 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %67, align 8
  %69 = icmp eq %"struct.std::__1::__hash_node_base.76"* %68, null
  br i1 %69, label %83, label %52

70:                                               ; preds = %61, %43
  %71 = phi %"struct.std::__1::__hash_node_base.76"* [ %31, %43 ], [ %53, %61 ]
  %72 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %71, i64 3
  %73 = bitcast %"struct.std::__1::__hash_node_base.76"* %72 to %"class.v8::internal::LargePage"**
  %74 = load %"class.v8::internal::LargePage"*, %"class.v8::internal::LargePage"** %73, align 8
  %75 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %74, i64 0, i32 0, i32 0, i32 3
  %76 = load i64, i64* %75, align 8
  %77 = icmp ugt i64 %76, %1
  br i1 %77, label %82, label %78, !prof !5

78:                                               ; preds = %70
  %79 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %74, i64 0, i32 0, i32 0, i32 4
  %80 = load i64, i64* %79, align 8
  %81 = icmp ugt i64 %80, %1
  br i1 %81, label %83, label %82, !prof !6

82:                                               ; preds = %70, %78
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.2, i64 0, i64 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.3, i64 0, i64 0)) #13
  unreachable

83:                                               ; preds = %66, %58, %48, %40, %24, %2, %17, %78
  %84 = phi %"class.v8::internal::LargePage"* [ %74, %78 ], [ null, %17 ], [ null, %2 ], [ null, %24 ], [ null, %40 ], [ null, %48 ], [ null, %58 ], [ null, %66 ]
  ret %"class.v8::internal::LargePage"* %84
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19OldLargeObjectSpace30ClearMarkingStateOfLiveObjectsEv(%"class.v8::internal::OldLargeObjectSpace"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2, i32 0
  %3 = bitcast %"class.v8::internal::MemoryChunk"** %2 to i64*
  %4 = load i64, i64* %3, align 8
  %5 = inttoptr i64 %4 to %"class.v8::internal::LargePage"*
  %6 = icmp eq i64 %4, 0
  br i1 %6, label %13, label %7

7:                                                ; preds = %1
  %8 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %5, i64 0, i32 0, i32 0, i32 3
  %9 = load i64, i64* %8, align 8
  %10 = add i64 %9, 1
  %11 = trunc i64 %10 to i32
  %12 = icmp eq i32 %11, 0
  br i1 %12, label %13, label %14

13:                                               ; preds = %90, %93, %1, %7
  ret void

14:                                               ; preds = %7, %93
  %15 = phi i64 [ %96, %93 ], [ %10, %7 ]
  %16 = phi %"class.v8::internal::LargePage"* [ %91, %93 ], [ %5, %7 ]
  %17 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %16, i64 0, i32 0, i32 12, i32 0
  %18 = bitcast %"class.v8::internal::MemoryChunk"** %17 to i64*
  %19 = load i64, i64* %18, align 8
  %20 = and i64 %15, -262144
  %21 = or i64 %20, 272
  %22 = sub i64 %15, %20
  %23 = trunc i64 %22 to i32
  %24 = lshr i32 %23, 2
  %25 = and i32 %24, 31
  %26 = shl i32 1, %25
  %27 = inttoptr i64 %21 to i32*
  %28 = lshr i64 %22, 7
  %29 = and i64 %28, 33554431
  %30 = getelementptr inbounds i32, i32* %27, i64 %29
  %31 = load i32, i32* %30, align 4
  %32 = and i32 %31, %26
  %33 = icmp eq i32 %32, 0
  br i1 %33, label %90, label %34

34:                                               ; preds = %14
  %35 = xor i32 %26, -1
  %36 = and i32 %31, %35
  store i32 %36, i32* %30, align 4
  %37 = shl i32 %26, 1
  %38 = icmp eq i32 %37, 0
  %39 = getelementptr inbounds i32, i32* %30, i64 1
  %40 = select i1 %38, i32* %39, i32* %30
  %41 = load i32, i32* %40, align 4
  %42 = xor i32 %37, -1
  %43 = select i1 %38, i32 -2, i32 %42
  %44 = and i32 %41, %43
  store i32 %44, i32* %40, align 4
  %45 = inttoptr i64 %20 to %"class.v8::internal::MemoryChunk"*
  %46 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %45, i64 0, i32 1, i64 0
  %47 = bitcast %"class.v8::internal::SlotSet"** %46 to i64*
  %48 = load atomic i64, i64* %47 acquire, align 32
  %49 = icmp eq i64 %48, 0
  br i1 %49, label %81, label %50

50:                                               ; preds = %34
  %51 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %45, i64 0, i32 0, i32 0
  %52 = load i64, i64* %51, align 262144
  %53 = add i64 %52, 4095
  %54 = lshr i64 %53, 12
  %55 = icmp eq i64 %54, 0
  br i1 %55, label %80, label %56

56:                                               ; preds = %50
  %57 = inttoptr i64 %48 to %"class.v8::internal::SlotSet::Bucket"**
  br label %58

58:                                               ; preds = %73, %56
  %59 = phi i64 [ 0, %56 ], [ %75, %73 ]
  %60 = phi i8 [ 1, %56 ], [ %74, %73 ]
  %61 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket"*, %"class.v8::internal::SlotSet::Bucket"** %57, i64 %59
  %62 = bitcast %"class.v8::internal::SlotSet::Bucket"** %61 to i64*
  %63 = load atomic i64, i64* %62 acquire, align 8
  %64 = icmp eq i64 %63, 0
  br i1 %64, label %73, label %65

65:                                               ; preds = %58
  %66 = inttoptr i64 %63 to %"class.v8::internal::SlotSet::Bucket"*
  %67 = tail call zeroext i1 @_ZN2v88internal7SlotSet6Bucket7IsEmptyEv(%"class.v8::internal::SlotSet::Bucket"* nonnull %66) #14
  br i1 %67, label %68, label %73

68:                                               ; preds = %65
  %69 = load atomic i64, i64* %62 acquire, align 8
  store atomic volatile i64 0, i64* %62 release, align 8
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %73, label %71

71:                                               ; preds = %68
  %72 = inttoptr i64 %69 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* nonnull %72) #14
  br label %73

73:                                               ; preds = %71, %68, %65, %58
  %74 = phi i8 [ 0, %65 ], [ %60, %58 ], [ %60, %68 ], [ %60, %71 ]
  %75 = add nuw nsw i64 %59, 1
  %76 = icmp eq i64 %75, %54
  br i1 %76, label %77, label %58

77:                                               ; preds = %73
  %78 = and i8 %74, 1
  %79 = icmp eq i8 %78, 0
  br i1 %79, label %81, label %80

80:                                               ; preds = %77, %50
  tail call void @_ZN2v88internal11MemoryChunk14ReleaseSlotSetILNS0_17RememberedSetTypeE0EEEvv(%"class.v8::internal::MemoryChunk"* %45) #14
  br label %81

81:                                               ; preds = %34, %77, %80
  %82 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %45, i64 0, i32 0, i32 1
  %83 = load i64, i64* %82, align 8
  %84 = and i64 %83, 256
  %85 = icmp eq i64 %84, 0
  br i1 %85, label %88, label %86

86:                                               ; preds = %81
  %87 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %45, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %87 release, align 16
  br label %88

88:                                               ; preds = %81, %86
  %89 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %45, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %89 monotonic, align 8
  br label %90

90:                                               ; preds = %14, %88
  %91 = inttoptr i64 %19 to %"class.v8::internal::LargePage"*
  %92 = icmp eq i64 %19, 0
  br i1 %92, label %13, label %93

93:                                               ; preds = %90
  %94 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %91, i64 0, i32 0, i32 0, i32 3
  %95 = load i64, i64* %94, align 8
  %96 = add i64 %95, 1
  %97 = trunc i64 %96 to i32
  %98 = icmp eq i32 %97, 0
  br i1 %98, label %13, label %14
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal14ObjectIteratorD2Ev(%"class.v8::internal::ObjectIterator"*) unnamed_addr #0 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal20CodeLargeObjectSpace21InsertChunkMapEntriesEPNS0_9LargePageE(%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::LargePage"*) local_unnamed_addr #0 align 2 {
  %3 = alloca %"class.std::__1::tuple", align 8
  %4 = alloca %"class.std::__1::tuple.1150", align 1
  %5 = alloca i64, align 8
  %6 = bitcast i64* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %6) #14
  %7 = ptrtoint %"class.v8::internal::LargePage"* %1 to i64
  store i64 %7, i64* %5, align 8
  %8 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 0
  %9 = load i64, i64* %8, align 8
  %10 = add i64 %9, %7
  %11 = icmp ugt i64 %10, %7
  br i1 %11, label %12, label %17

12:                                               ; preds = %2
  %13 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0
  %14 = bitcast %"class.std::__1::tuple"* %3 to i8*
  %15 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %3, i64 0, i32 0, i32 0, i32 0
  %16 = getelementptr inbounds %"class.std::__1::tuple.1150", %"class.std::__1::tuple.1150"* %4, i64 0, i32 0
  br label %18

17:                                               ; preds = %18, %2
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %6) #14
  ret void

18:                                               ; preds = %12, %18
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %14) #14
  store i64* %5, i64** %15, align 8
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %16) #14
  %19 = call { %"struct.std::__1::__hash_node_base.76"*, i8 } @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE25__emplace_unique_key_argsImJRKNS_21piecewise_construct_tENS_5tupleIJRKmEEENSM_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeIS6_PvEEEEbEERKT_DpOT0_(%"class.std::__1::__hash_table.72"* %13, i64* nonnull dereferenceable(8) %5, %"struct.std::__1::piecewise_construct_t"* nonnull dereferenceable(1) @_ZNSt3__1L19piecewise_constructE, %"class.std::__1::tuple"* nonnull dereferenceable(8) %3, %"class.std::__1::tuple.1150"* nonnull dereferenceable(1) %4) #14
  %20 = extractvalue { %"struct.std::__1::__hash_node_base.76"*, i8 } %19, 0
  %21 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %20, i64 3
  %22 = bitcast %"struct.std::__1::__hash_node_base.76"* %21 to %"class.v8::internal::LargePage"**
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %16) #14
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %14) #14
  store %"class.v8::internal::LargePage"* %1, %"class.v8::internal::LargePage"** %22, align 8
  %23 = load i64, i64* %5, align 8
  %24 = add i64 %23, 262144
  store i64 %24, i64* %5, align 8
  %25 = load i64, i64* %8, align 8
  %26 = add i64 %25, %7
  %27 = icmp ult i64 %24, %26
  br i1 %27, label %18, label %17
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal20CodeLargeObjectSpace21RemoveChunkMapEntriesEPNS0_9LargePageE(%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::LargePage"*) local_unnamed_addr #0 align 2 {
  %3 = alloca %"class.std::__1::unique_ptr.1151", align 8
  %4 = ptrtoint %"class.v8::internal::LargePage"* %1 to i64
  %5 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, %4
  %8 = icmp ugt i64 %7, %4
  br i1 %8, label %9, label %15

9:                                                ; preds = %2
  %10 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0
  %11 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %12 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %10, i64 0, i32 0, i32 0, i32 0, i32 0
  %13 = bitcast %"class.std::__1::unique_ptr.1151"* %3 to i8*
  %14 = getelementptr inbounds %"class.std::__1::unique_ptr.1151", %"class.std::__1::unique_ptr.1151"* %3, i64 0, i32 0, i32 0, i32 0
  br label %16

15:                                               ; preds = %91, %2
  ret void

16:                                               ; preds = %9, %91
  %17 = phi i64 [ %6, %9 ], [ %92, %91 ]
  %18 = phi i64 [ %4, %9 ], [ %93, %91 ]
  %19 = load i64, i64* %11, align 8
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %91, label %21

21:                                               ; preds = %16
  %22 = call i64 @llvm.ctpop.i64(i64 %19) #14, !range !4
  %23 = icmp ugt i64 %22, 1
  br i1 %23, label %27, label %24

24:                                               ; preds = %21
  %25 = add i64 %19, -1
  %26 = and i64 %25, %18
  br label %31

27:                                               ; preds = %21
  %28 = icmp ult i64 %18, %19
  br i1 %28, label %31, label %29

29:                                               ; preds = %27
  %30 = urem i64 %18, %19
  br label %31

31:                                               ; preds = %29, %27, %24
  %32 = phi i64 [ %26, %24 ], [ %30, %29 ], [ %18, %27 ]
  %33 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %12, align 8
  %34 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %33, i64 %32
  %35 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %34, align 8
  %36 = icmp eq %"struct.std::__1::__hash_node_base.76"* %35, null
  br i1 %36, label %91, label %37

37:                                               ; preds = %31
  %38 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %35, i64 0, i32 0
  %39 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %38, align 8
  %40 = icmp eq %"struct.std::__1::__hash_node_base.76"* %39, null
  br i1 %40, label %91, label %41

41:                                               ; preds = %37
  %42 = add i64 %19, -1
  br i1 %23, label %43, label %65

43:                                               ; preds = %41, %61
  %44 = phi %"struct.std::__1::__hash_node_base.76"* [ %63, %61 ], [ %39, %41 ]
  %45 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %44, i64 1
  %46 = bitcast %"struct.std::__1::__hash_node_base.76"* %45 to i64*
  %47 = load i64, i64* %46, align 8
  %48 = icmp eq i64 %47, %18
  br i1 %48, label %56, label %49

49:                                               ; preds = %43
  %50 = icmp ult i64 %47, %19
  br i1 %50, label %53, label %51

51:                                               ; preds = %49
  %52 = urem i64 %47, %19
  br label %53

53:                                               ; preds = %51, %49
  %54 = phi i64 [ %52, %51 ], [ %47, %49 ]
  %55 = icmp eq i64 %54, %32
  br i1 %55, label %61, label %91

56:                                               ; preds = %43
  %57 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %44, i64 2
  %58 = bitcast %"struct.std::__1::__hash_node_base.76"* %57 to i64*
  %59 = load i64, i64* %58, align 8
  %60 = icmp eq i64 %59, %18
  br i1 %60, label %83, label %61

61:                                               ; preds = %56, %53
  %62 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %44, i64 0, i32 0
  %63 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %62, align 8
  %64 = icmp eq %"struct.std::__1::__hash_node_base.76"* %63, null
  br i1 %64, label %91, label %43

65:                                               ; preds = %41, %79
  %66 = phi %"struct.std::__1::__hash_node_base.76"* [ %81, %79 ], [ %39, %41 ]
  %67 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %66, i64 1
  %68 = bitcast %"struct.std::__1::__hash_node_base.76"* %67 to i64*
  %69 = load i64, i64* %68, align 8
  %70 = icmp eq i64 %69, %18
  br i1 %70, label %74, label %71

71:                                               ; preds = %65
  %72 = and i64 %69, %42
  %73 = icmp eq i64 %72, %32
  br i1 %73, label %79, label %91

74:                                               ; preds = %65
  %75 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %66, i64 2
  %76 = bitcast %"struct.std::__1::__hash_node_base.76"* %75 to i64*
  %77 = load i64, i64* %76, align 8
  %78 = icmp eq i64 %77, %18
  br i1 %78, label %83, label %79

79:                                               ; preds = %74, %71
  %80 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %66, i64 0, i32 0
  %81 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %80, align 8
  %82 = icmp eq %"struct.std::__1::__hash_node_base.76"* %81, null
  br i1 %82, label %91, label %65

83:                                               ; preds = %74, %56
  %84 = phi %"struct.std::__1::__hash_node_base.76"* [ %44, %56 ], [ %66, %74 ]
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %13) #14
  call void @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE6removeENS_21__hash_const_iteratorIPNS_11__hash_nodeIS6_PvEEEE(%"class.std::__1::unique_ptr.1151"* nonnull sret %3, %"class.std::__1::__hash_table.72"* %10, %"struct.std::__1::__hash_node_base.76"* nonnull %84) #14
  %85 = load %"struct.std::__1::__hash_node.1146"*, %"struct.std::__1::__hash_node.1146"** %14, align 8
  store %"struct.std::__1::__hash_node.1146"* null, %"struct.std::__1::__hash_node.1146"** %14, align 8
  %86 = icmp eq %"struct.std::__1::__hash_node.1146"* %85, null
  br i1 %86, label %89, label %87

87:                                               ; preds = %83
  %88 = bitcast %"struct.std::__1::__hash_node.1146"* %85 to i8*
  call void @_ZdlPv(i8* %88) #15
  br label %89

89:                                               ; preds = %87, %83
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %13) #14
  %90 = load i64, i64* %5, align 8
  br label %91

91:                                               ; preds = %71, %79, %53, %61, %37, %16, %31, %89
  %92 = phi i64 [ %17, %37 ], [ %17, %16 ], [ %17, %31 ], [ %90, %89 ], [ %17, %61 ], [ %17, %53 ], [ %17, %79 ], [ %17, %71 ]
  %93 = add i64 %18, 262144
  %94 = add i64 %92, %4
  %95 = icmp ult i64 %93, %94
  br i1 %95, label %16, label %15
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19OldLargeObjectSpace21PromoteNewLargeObjectEPNS0_9LargePageE(%"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::LargePage"*) local_unnamed_addr #0 align 2 {
  %3 = alloca %"class.v8::internal::HeapObject", align 8
  %4 = bitcast %"class.v8::internal::HeapObject"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %4) #14
  %5 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 3
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 1
  %8 = getelementptr inbounds %"class.v8::internal::HeapObject", %"class.v8::internal::HeapObject"* %3, i64 0, i32 0, i32 0, i32 0
  store i64 %7, i64* %8, align 8
  %9 = and i64 %7, -4294967296
  %10 = inttoptr i64 %6 to i32*
  %11 = load atomic i32, i32* %10 monotonic, align 4
  %12 = zext i32 %11 to i64
  %13 = or i64 %9, %12
  %14 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %3, i64 %13) #14
  %15 = sext i32 %14 to i64
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %4) #14
  %16 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 8, i32 0
  %17 = bitcast %"struct.std::__1::__atomic_base.607"* %16 to i64*
  %18 = load atomic i64, i64* %17 seq_cst, align 8
  %19 = inttoptr i64 %18 to %"class.v8::internal::LargeObjectSpace"*
  %20 = inttoptr i64 %18 to void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)***
  %21 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %20, align 8
  %22 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %21, i64 18
  %23 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %22, align 8
  call void %23(%"class.v8::internal::LargeObjectSpace"* %19, %"class.v8::internal::LargePage"* %1, i64 %15) #14
  %24 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 1
  %25 = load i64, i64* %24, align 8
  %26 = and i64 %25, -9
  store i64 %26, i64* %24, align 8
  %27 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0
  %28 = bitcast %"class.v8::internal::OldLargeObjectSpace"* %0 to void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)***
  %29 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %28, align 8
  %30 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %29, i64 17
  %31 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %30, align 8
  call void %31(%"class.v8::internal::LargeObjectSpace"* %27, %"class.v8::internal::LargePage"* %1, i64 %15) #14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal16LargeObjectSpace7AddPageEPNS0_9LargePageEm(%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = shl i64 %5, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %9 = atomicrmw add i64* %8, i64 %7 seq_cst
  %10 = load i64, i64* %4, align 8
  %11 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = atomicrmw add i64* %11, i64 %10 seq_cst
  %13 = load atomic i64, i64* %11 seq_cst, align 8
  %14 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 4
  %15 = load i64, i64* %14, align 8
  %16 = icmp ugt i64 %13, %15
  br i1 %16, label %17, label %19

17:                                               ; preds = %3
  %18 = load atomic i64, i64* %11 seq_cst, align 8
  store i64 %18, i64* %14, align 8
  br label %19

19:                                               ; preds = %3, %17
  %20 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %21 = atomicrmw add i64* %20, i64 %2 seq_cst
  %22 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 2
  %23 = load i32, i32* %22, align 8
  %24 = add nsw i32 %23, 1
  store i32 %24, i32* %22, align 8
  %25 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0
  %26 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %27 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %26, align 8
  %28 = icmp eq %"class.v8::internal::MemoryChunk"* %27, null
  br i1 %28, label %37, label %29

29:                                               ; preds = %19
  %30 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %27, i64 0, i32 12, i32 0
  %31 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %30, align 8
  %32 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %31, %"class.v8::internal::MemoryChunk"** %32, align 8
  %33 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %27, %"class.v8::internal::MemoryChunk"** %33, align 8
  store %"class.v8::internal::MemoryChunk"* %25, %"class.v8::internal::MemoryChunk"** %30, align 8
  %34 = icmp eq %"class.v8::internal::MemoryChunk"* %31, null
  %35 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %31, i64 0, i32 12, i32 1
  %36 = select i1 %34, %"class.v8::internal::MemoryChunk"** %26, %"class.v8::internal::MemoryChunk"** %35
  br label %41

37:                                               ; preds = %19
  %38 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 0
  %39 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %40 = bitcast %"class.v8::internal::MemoryChunk"** %38 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %40, i8 0, i64 16, i1 false) #14
  store %"class.v8::internal::MemoryChunk"* %25, %"class.v8::internal::MemoryChunk"** %39, align 8
  br label %41

41:                                               ; preds = %29, %37
  %42 = phi %"class.v8::internal::MemoryChunk"** [ %26, %37 ], [ %36, %29 ]
  store %"class.v8::internal::MemoryChunk"* %25, %"class.v8::internal::MemoryChunk"** %42, align 8
  %43 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 8
  %44 = ptrtoint %"class.v8::internal::LargeObjectSpace"* %0 to i64
  %45 = bitcast %"struct.std::__1::atomic.606"* %43 to i64*
  store atomic i64 %44, i64* %45 seq_cst, align 8
  %46 = bitcast %"class.v8::internal::LargeObjectSpace"* %0 to i1 (%"class.v8::internal::LargeObjectSpace"*)***
  %47 = load i1 (%"class.v8::internal::LargeObjectSpace"*)**, i1 (%"class.v8::internal::LargeObjectSpace"*)*** %46, align 8
  %48 = getelementptr inbounds i1 (%"class.v8::internal::LargeObjectSpace"*)*, i1 (%"class.v8::internal::LargeObjectSpace"*)** %47, i64 19
  %49 = load i1 (%"class.v8::internal::LargeObjectSpace"*)*, i1 (%"class.v8::internal::LargeObjectSpace"*)** %48, align 8
  %50 = tail call zeroext i1 %49(%"class.v8::internal::LargeObjectSpace"* %0) #14
  br i1 %50, label %59, label %51

51:                                               ; preds = %41
  %52 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %53 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %52, align 8
  %54 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %53, i64 0, i32 86, i32 0, i32 0, i32 0
  %55 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %54, align 8
  %56 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %55, i64 0, i32 11, i32 0, i32 0, i32 0, i32 0
  %57 = load atomic i8, i8* %56 seq_cst, align 1
  %58 = icmp ne i8 %57, 0
  br label %59

59:                                               ; preds = %51, %41
  %60 = phi i1 [ false, %41 ], [ %58, %51 ]
  tail call void @_ZN2v88internal11MemoryChunk25SetOldGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"* %25, i1 zeroext %60) #14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal16LargeObjectSpace10RemovePageEPNS0_9LargePageEm(%"class.v8::internal::LargeObjectSpace"* nocapture, %"class.v8::internal::LargePage"*, i64) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = shl i64 %5, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %9 = atomicrmw sub i64* %8, i64 %7 seq_cst
  %10 = load i64, i64* %4, align 8
  %11 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = atomicrmw sub i64* %11, i64 %10 seq_cst
  %13 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %14 = atomicrmw sub i64* %13, i64 %2 seq_cst
  %15 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 2
  %16 = load i32, i32* %15, align 8
  %17 = add nsw i32 %16, -1
  store i32 %17, i32* %15, align 8
  %18 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2
  %19 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0
  %20 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %21 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %20, align 8
  %22 = icmp eq %"class.v8::internal::MemoryChunk"* %21, %19
  br i1 %22, label %23, label %28

23:                                               ; preds = %3
  %24 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 1
  %25 = bitcast %"class.v8::internal::MemoryChunk"** %24 to i64*
  %26 = load i64, i64* %25, align 8
  %27 = bitcast %"class.v8::internal::MemoryChunk"** %20 to i64*
  store i64 %26, i64* %27, align 8
  br label %28

28:                                               ; preds = %23, %3
  %29 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %18, i64 0, i32 0
  %30 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %29, align 8
  %31 = icmp eq %"class.v8::internal::MemoryChunk"* %30, %19
  br i1 %31, label %32, label %37

32:                                               ; preds = %28
  %33 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 0
  %34 = bitcast %"class.v8::internal::MemoryChunk"** %33 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = bitcast %"class.v8::internal::heap::List"* %18 to i64*
  store i64 %35, i64* %36, align 8
  br label %37

37:                                               ; preds = %32, %28
  %38 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 0
  %39 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %38, align 8
  %40 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 1
  %41 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %40, align 8
  %42 = icmp eq %"class.v8::internal::MemoryChunk"* %39, null
  br i1 %42, label %45, label %43

43:                                               ; preds = %37
  %44 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %39, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %41, %"class.v8::internal::MemoryChunk"** %44, align 8
  br label %45

45:                                               ; preds = %43, %37
  %46 = icmp eq %"class.v8::internal::MemoryChunk"* %41, null
  br i1 %46, label %49, label %47

47:                                               ; preds = %45
  %48 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %41, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %39, %"class.v8::internal::MemoryChunk"** %48, align 8
  br label %49

49:                                               ; preds = %45, %47
  %50 = bitcast %"class.v8::internal::MemoryChunk"** %38 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %50, i8 0, i64 16, i1 false) #14
  %51 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 8
  %52 = bitcast %"struct.std::__1::atomic.606"* %51 to i64*
  store atomic i64 0, i64* %52 seq_cst, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal16LargeObjectSpace19FreeUnmarkedObjectsEv(%"class.v8::internal::LargeObjectSpace"*) unnamed_addr #0 align 2 {
  %2 = alloca %"class.v8::internal::HeapObject", align 8
  %3 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %4 = bitcast %"class.v8::internal::MemoryChunk"** %3 to %"class.v8::internal::LargePage"**
  %5 = load %"class.v8::internal::LargePage"*, %"class.v8::internal::LargePage"** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %7 = icmp eq %"class.v8::internal::LargePage"* %5, null
  br i1 %7, label %107, label %8

8:                                                ; preds = %1
  %9 = bitcast %"class.v8::internal::HeapObject"* %2 to i8*
  %10 = getelementptr inbounds %"class.v8::internal::HeapObject", %"class.v8::internal::HeapObject"* %2, i64 0, i32 0, i32 0, i32 0
  %11 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %12 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %13 = bitcast %"class.v8::internal::LargeObjectSpace"* %0 to void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)***
  br label %14

14:                                               ; preds = %8, %104
  %15 = phi %"class.v8::internal::LargePage"* [ %5, %8 ], [ %19, %104 ]
  %16 = phi i64 [ 0, %8 ], [ %105, %104 ]
  %17 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %15, i64 0, i32 0, i32 12, i32 0
  %18 = bitcast %"class.v8::internal::MemoryChunk"** %17 to %"class.v8::internal::LargePage"**
  %19 = load %"class.v8::internal::LargePage"*, %"class.v8::internal::LargePage"** %18, align 8
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %9) #14
  %20 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %15, i64 0, i32 0, i32 0, i32 3
  %21 = load i64, i64* %20, align 8
  %22 = add i64 %21, 1
  store i64 %22, i64* %10, align 8
  %23 = and i64 %22, -4294967296
  %24 = inttoptr i64 %21 to i32*
  %25 = load atomic i32, i32* %24 monotonic, align 4
  %26 = zext i32 %25 to i64
  %27 = or i64 %23, %26
  %28 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %2, i64 %27) #14
  %29 = sext i32 %28 to i64
  %30 = load i64, i64* %10, align 8
  %31 = and i64 %30, -262144
  %32 = or i64 %31, 272
  %33 = sub i64 %30, %31
  %34 = trunc i64 %33 to i32
  %35 = lshr i32 %34, 2
  %36 = and i32 %35, 31
  %37 = shl i32 1, %36
  %38 = inttoptr i64 %32 to i32*
  %39 = lshr i64 %33, 7
  %40 = and i64 %39, 33554431
  %41 = getelementptr inbounds i32, i32* %38, i64 %40
  %42 = load i32, i32* %41, align 4
  %43 = and i32 %37, %42
  %44 = icmp eq i32 %43, 0
  br i1 %44, label %96, label %45

45:                                               ; preds = %14
  %46 = shl i32 %37, 1
  %47 = icmp eq i32 %46, 0
  %48 = getelementptr inbounds i32, i32* %41, i64 1
  %49 = select i1 %47, i32 1, i32 %46
  %50 = select i1 %47, i32* %48, i32* %41
  %51 = load i32, i32* %50, align 4
  %52 = and i32 %51, %49
  %53 = icmp eq i32 %52, 0
  br i1 %53, label %96, label %54

54:                                               ; preds = %45
  %55 = add i64 %16, %29
  %56 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %15, i64 0, i32 0, i32 0, i32 1
  %57 = load i64, i64* %56, align 8
  %58 = and i64 %57, 1
  %59 = icmp eq i64 %58, 0
  br i1 %59, label %60, label %104

60:                                               ; preds = %54
  %61 = ptrtoint %"class.v8::internal::LargePage"* %15 to i64
  %62 = call i64 @_ZN2v88internal15MemoryAllocator17GetCommitPageSizeEv() #14
  %63 = sub i64 -2, %61
  %64 = add i64 %63, %30
  %65 = add i64 %64, %29
  %66 = add i64 %65, %62
  %67 = sub nsw i64 0, %62
  %68 = and i64 %66, %67
  %69 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %15, i64 0, i32 0
  %70 = call i64 @_ZN2v88internal11MemoryChunk23CommittedPhysicalMemoryEv(%"class.v8::internal::MemoryChunk"* %69) #14
  %71 = icmp uge i64 %68, %70
  %72 = add i64 %68, %61
  %73 = icmp eq i64 %72, 0
  %74 = or i1 %71, %73
  br i1 %74, label %104, label %75

75:                                               ; preds = %60
  call void @_ZN2v88internal9LargePage24ClearOutOfLiveRangeSlotsEm(%"class.v8::internal::LargePage"* nonnull %15, i64 %72)
  %76 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %15, i64 0, i32 0, i32 0
  %77 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %15, i64 0, i32 0, i32 0, i32 0
  %78 = load i64, i64* %77, align 8
  %79 = sub i64 %78, %68
  %80 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %6, align 8
  %81 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %80, i64 0, i32 85, i32 0, i32 0, i32 0
  %82 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %81, align 8
  %83 = load i64, i64* %20, align 8
  %84 = load i64, i64* %10, align 8
  %85 = and i64 %84, -4294967296
  %86 = add i64 %84, -1
  %87 = inttoptr i64 %86 to i32*
  %88 = load atomic i32, i32* %87 monotonic, align 4
  %89 = zext i32 %88 to i64
  %90 = or i64 %85, %89
  %91 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %2, i64 %90) #14
  %92 = sext i32 %91 to i64
  %93 = add i64 %83, %92
  call void @_ZN2v88internal15MemoryAllocator17PartialFreeMemoryEPNS0_16BasicMemoryChunkEmmm(%"class.v8::internal::MemoryAllocator"* %82, %"class.v8::internal::BasicMemoryChunk"* %76, i64 %72, i64 %79, i64 %93) #14
  %94 = atomicrmw sub i64* %11, i64 %79 seq_cst
  %95 = atomicrmw sub i64* %12, i64 %79 seq_cst
  br label %104

96:                                               ; preds = %45, %14
  %97 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %13, align 8
  %98 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %97, i64 18
  %99 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %98, align 8
  call void %99(%"class.v8::internal::LargeObjectSpace"* %0, %"class.v8::internal::LargePage"* nonnull %15, i64 %29) #14
  %100 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %6, align 8
  %101 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %100, i64 0, i32 85, i32 0, i32 0, i32 0
  %102 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %101, align 8
  %103 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %15, i64 0, i32 0
  call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE2EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %102, %"class.v8::internal::MemoryChunk"* %103) #14
  br label %104

104:                                              ; preds = %60, %54, %75, %96
  %105 = phi i64 [ %16, %96 ], [ %55, %75 ], [ %55, %60 ], [ %55, %54 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %9) #14
  %106 = icmp eq %"class.v8::internal::LargePage"* %19, null
  br i1 %106, label %107, label %14

107:                                              ; preds = %104, %1
  %108 = phi i64 [ 0, %1 ], [ %105, %104 ]
  %109 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %108, i64* %109 seq_cst, align 8
  ret void
}

declare void @_ZN2v88internal15MemoryAllocator17PartialFreeMemoryEPNS0_16BasicMemoryChunkEmmm(%"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::BasicMemoryChunk"*, i64, i64, i64) local_unnamed_addr #4

declare void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE2EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal16LargeObjectSpace8ContainsENS0_10HeapObjectE(%"class.v8::internal::LargeObjectSpace"* readnone, i64) local_unnamed_addr #5 align 2 {
  %3 = and i64 %1, -262144
  %4 = inttoptr i64 %3 to %"class.v8::internal::BasicMemoryChunk"*
  %5 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %4, i64 0, i32 8, i32 0
  %6 = bitcast %"struct.std::__1::__atomic_base.607"* %5 to i64*
  %7 = load atomic i64, i64* %6 seq_cst, align 64
  %8 = inttoptr i64 %7 to %"class.v8::internal::BaseSpace"*
  %9 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0
  %10 = icmp eq %"class.v8::internal::BaseSpace"* %9, %8
  ret i1 %10
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden zeroext i1 @_ZN2v88internal16LargeObjectSpace12ContainsSlowEm(%"class.v8::internal::LargeObjectSpace"* nocapture readonly, i64) local_unnamed_addr #7 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %4 = bitcast %"class.v8::internal::MemoryChunk"** %3 to %"class.v8::internal::LargePage"**
  %5 = load %"class.v8::internal::LargePage"*, %"class.v8::internal::LargePage"** %4, align 8
  %6 = icmp eq %"class.v8::internal::LargePage"* %5, null
  br i1 %6, label %21, label %7

7:                                                ; preds = %2, %16
  %8 = phi %"class.v8::internal::LargePage"* [ %19, %16 ], [ %5, %2 ]
  %9 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %8, i64 0, i32 0, i32 0, i32 3
  %10 = load i64, i64* %9, align 8
  %11 = icmp ugt i64 %10, %1
  br i1 %11, label %16, label %12

12:                                               ; preds = %7
  %13 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %8, i64 0, i32 0, i32 0, i32 4
  %14 = load i64, i64* %13, align 8
  %15 = icmp ugt i64 %14, %1
  br i1 %15, label %21, label %16

16:                                               ; preds = %7, %12
  %17 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %8, i64 0, i32 0, i32 12, i32 0
  %18 = bitcast %"class.v8::internal::MemoryChunk"** %17 to %"class.v8::internal::LargePage"**
  %19 = load %"class.v8::internal::LargePage"*, %"class.v8::internal::LargePage"** %18, align 8
  %20 = icmp eq %"class.v8::internal::LargePage"* %19, null
  br i1 %20, label %21, label %7

21:                                               ; preds = %12, %16, %2
  %22 = phi i1 [ false, %2 ], [ false, %16 ], [ true, %12 ]
  ret i1 %22
}

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::ObjectIterator"* @_ZN2v88internal16LargeObjectSpace17GetObjectIteratorEPNS0_4HeapE(%"class.v8::internal::LargeObjectSpace"* nocapture readonly, %"class.v8::internal::Heap"* nocapture readnone) unnamed_addr #0 align 2 {
  %3 = tail call i8* @_ZN2v88internal8MallocednwEm(i64 16) #14
  %4 = bitcast i8* %3 to i32 (...)***
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2v88internal30LargeObjectSpaceObjectIteratorE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %5 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2, i32 0
  %6 = bitcast %"class.v8::internal::MemoryChunk"** %5 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds i8, i8* %3, i64 8
  %9 = bitcast i8* %8 to i64*
  store i64 %7, i64* %9, align 8
  %10 = bitcast i8* %3 to %"class.v8::internal::ObjectIterator"*
  ret %"class.v8::internal::ObjectIterator"* %10
}

declare i8* @_ZN2v88internal8MallocednwEm(i64) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19OldLargeObjectSpaceC2EPNS0_4HeapE(%"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::Heap"*) unnamed_addr #0 align 2 {
  %3 = tail call i8* @_Znwm(i64 48) #15
  %4 = bitcast i8* %3 to i32 (...)***
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 48, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [12 x i8*] }, { [12 x i8*] }* @_ZTVN2v88internal10NoFreeListE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %5 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %6 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %6, align 8
  %7 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 4, i32* %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %9 = bitcast i64* %8 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %9, i8 0, i64 16, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %10 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %11 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 2, i32 0, i32 3
  %12 = bitcast %"class.std::__1::__compressed_pair.54"* %11 to i32*
  %13 = bitcast %"class.v8::internal::AllocationCounter"* %10 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %13, i8 0, i64 80, i1 false) #14
  store i32 1065353216, i32* %12, align 4
  %14 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 3
  store i8 0, i8* %14, align 8
  %15 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 5
  %16 = bitcast i64* %15 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %16, i8 0, i64 17, i1 false) #14
  %17 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2
  %18 = bitcast %"class.v8::internal::heap::List"* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %18, i8 0, i64 16, i1 false) #14
  %19 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 4
  %20 = ptrtoint i8* %3 to i64
  %21 = bitcast %"class.std::__1::unique_ptr.59"* %19 to i64*
  store i64 %20, i64* %21, align 8
  %22 = tail call i8* @_Znam(i64 16) #15
  %23 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3
  %24 = bitcast %"struct.std::__1::atomic"** %23 to i8**
  store i8* %22, i8** %24, align 8
  %25 = bitcast i8* %22 to i64*
  store atomic i64 0, i64* %25 seq_cst, align 8
  %26 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %23, align 8
  %27 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %26, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %27 seq_cst, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal16LargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %28 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %28, align 8
  %29 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 2
  store i32 0, i32* %29, align 8
  %30 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %30, align 8
  %31 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 4
  tail call void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"* %31) #14
  %32 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %32, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal19OldLargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19OldLargeObjectSpaceC2EPNS0_4HeapENS0_15AllocationSpaceE(%"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::Heap"*, i32) unnamed_addr #0 align 2 {
  %4 = tail call i8* @_Znwm(i64 48) #15
  %5 = bitcast i8* %4 to i32 (...)***
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 48, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [12 x i8*] }, { [12 x i8*] }* @_ZTVN2v88internal10NoFreeListE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %7 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %2, i32* %8, align 8
  %9 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %10 = bitcast i64* %9 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %10, i8 0, i64 16, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %11 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %12 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 2, i32 0, i32 3
  %13 = bitcast %"class.std::__1::__compressed_pair.54"* %12 to i32*
  %14 = bitcast %"class.v8::internal::AllocationCounter"* %11 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %14, i8 0, i64 80, i1 false) #14
  store i32 1065353216, i32* %13, align 4
  %15 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 3
  store i8 0, i8* %15, align 8
  %16 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 5
  %17 = bitcast i64* %16 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %17, i8 0, i64 17, i1 false) #14
  %18 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2
  %19 = bitcast %"class.v8::internal::heap::List"* %18 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %19, i8 0, i64 16, i1 false) #14
  %20 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 4
  %21 = ptrtoint i8* %4 to i64
  %22 = bitcast %"class.std::__1::unique_ptr.59"* %20 to i64*
  store i64 %21, i64* %22, align 8
  %23 = tail call i8* @_Znam(i64 16) #15
  %24 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3
  %25 = bitcast %"struct.std::__1::atomic"** %24 to i8**
  store i8* %23, i8** %25, align 8
  %26 = bitcast i8* %23 to i64*
  store atomic i64 0, i64* %26 seq_cst, align 8
  %27 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %24, align 8
  %28 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %27, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %28 seq_cst, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal16LargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %29 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %29, align 8
  %30 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 2
  store i32 0, i32* %30, align 8
  %31 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %31, align 8
  %32 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 4
  tail call void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"* %32) #14
  %33 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %33, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal19OldLargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19NewLargeObjectSpaceC2EPNS0_4HeapEm(%"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::Heap"*, i64) unnamed_addr #0 align 2 {
  %4 = tail call i8* @_Znwm(i64 48) #15
  %5 = bitcast i8* %4 to i32 (...)***
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 48, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [12 x i8*] }, { [12 x i8*] }* @_ZTVN2v88internal10NoFreeListE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %7 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 6, i32* %8, align 8
  %9 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %10 = bitcast i64* %9 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %10, i8 0, i64 16, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %11 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %12 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 2, i32 0, i32 3
  %13 = bitcast %"class.std::__1::__compressed_pair.54"* %12 to i32*
  %14 = bitcast %"class.v8::internal::AllocationCounter"* %11 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %14, i8 0, i64 80, i1 false) #14
  store i32 1065353216, i32* %13, align 4
  %15 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 3
  store i8 0, i8* %15, align 8
  %16 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 5
  %17 = bitcast i64* %16 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %17, i8 0, i64 17, i1 false) #14
  %18 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2
  %19 = bitcast %"class.v8::internal::heap::List"* %18 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %19, i8 0, i64 16, i1 false) #14
  %20 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 4
  %21 = ptrtoint i8* %4 to i64
  %22 = bitcast %"class.std::__1::unique_ptr.59"* %20 to i64*
  store i64 %21, i64* %22, align 8
  %23 = tail call i8* @_Znam(i64 16) #15
  %24 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3
  %25 = bitcast %"struct.std::__1::atomic"** %24 to i8**
  store i8* %23, i8** %25, align 8
  %26 = bitcast i8* %23 to i64*
  store atomic i64 0, i64* %26 seq_cst, align 8
  %27 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %24, align 8
  %28 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %27, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %28 seq_cst, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal16LargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %29 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %29, align 8
  %30 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 2
  store i32 0, i32* %30, align 8
  %31 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %31, align 8
  %32 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 4
  tail call void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"* %32) #14
  %33 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %33, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal19NewLargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %6, align 8
  %34 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 1
  store i64 %2, i64* %34, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19NewLargeObjectSpace11AllocateRawEi(%"class.v8::internal::NewLargeObjectSpace"*, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %4 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0
  %6 = bitcast %"class.v8::internal::NewLargeObjectSpace"* %0 to i64 (%"class.v8::internal::LargeObjectSpace"*)***
  %7 = load i64 (%"class.v8::internal::LargeObjectSpace"*)**, i64 (%"class.v8::internal::LargeObjectSpace"*)*** %6, align 8
  %8 = getelementptr inbounds i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %7, i64 11
  %9 = load i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %8, align 8
  %10 = tail call i64 %9(%"class.v8::internal::LargeObjectSpace"* %5) #14
  %11 = tail call zeroext i1 @_ZN2v88internal4Heap22CanExpandOldGenerationEm(%"class.v8::internal::Heap"* %4, i64 %10) #14
  br i1 %11, label %12, label %99

12:                                               ; preds = %2
  %13 = load i64 (%"class.v8::internal::LargeObjectSpace"*)**, i64 (%"class.v8::internal::LargeObjectSpace"*)*** %6, align 8
  %14 = getelementptr inbounds i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %13, i64 11
  %15 = load i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %14, align 8
  %16 = tail call i64 %15(%"class.v8::internal::LargeObjectSpace"* %5) #14
  %17 = icmp eq i64 %16, 0
  %18 = sext i32 %1 to i64
  br i1 %17, label %26, label %19

19:                                               ; preds = %12
  %20 = bitcast %"class.v8::internal::NewLargeObjectSpace"* %0 to i64 (%"class.v8::internal::NewLargeObjectSpace"*)***
  %21 = load i64 (%"class.v8::internal::NewLargeObjectSpace"*)**, i64 (%"class.v8::internal::NewLargeObjectSpace"*)*** %20, align 8
  %22 = getelementptr inbounds i64 (%"class.v8::internal::NewLargeObjectSpace"*)*, i64 (%"class.v8::internal::NewLargeObjectSpace"*)** %21, i64 12
  %23 = load i64 (%"class.v8::internal::NewLargeObjectSpace"*)*, i64 (%"class.v8::internal::NewLargeObjectSpace"*)** %22, align 8
  %24 = tail call i64 %23(%"class.v8::internal::NewLargeObjectSpace"* %0) #14
  %25 = icmp ult i64 %24, %18
  br i1 %25, label %99, label %26

26:                                               ; preds = %12, %19
  %27 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %3, align 8
  %28 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %27, i64 0, i32 85, i32 0, i32 0, i32 0
  %29 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %28, align 8
  %30 = tail call %"class.v8::internal::LargePage"* @_ZN2v88internal15MemoryAllocator17AllocateLargePageEmPNS0_16LargeObjectSpaceENS0_13ExecutabilityE(%"class.v8::internal::MemoryAllocator"* %29, i64 %18, %"class.v8::internal::LargeObjectSpace"* %5, i32 0) #14
  %31 = icmp eq %"class.v8::internal::LargePage"* %30, null
  br i1 %31, label %99, label %32

32:                                               ; preds = %26
  %33 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 4
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %33) #14
  %34 = bitcast %"class.v8::internal::NewLargeObjectSpace"* %0 to void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)***
  %35 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %34, align 8
  %36 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %35, i64 17
  %37 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %36, align 8
  tail call void %37(%"class.v8::internal::LargeObjectSpace"* %5, %"class.v8::internal::LargePage"* nonnull %30, i64 %18) #14
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %33) #14
  %38 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %30, i64 0, i32 0, i32 0, i32 3
  %39 = load i64, i64* %38, align 8
  %40 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %3, align 8
  %41 = tail call i64 @_ZN2v88internal4Heap20CreateFillerObjectAtEmiNS0_18ClearRecordedSlotsE(%"class.v8::internal::Heap"* %40, i64 %39, i32 %1, i32 1) #14
  %42 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 1
  %43 = load i64 (%"class.v8::internal::LargeObjectSpace"*)**, i64 (%"class.v8::internal::LargeObjectSpace"*)*** %6, align 8
  %44 = getelementptr inbounds i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %43, i64 11
  %45 = load i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %44, align 8
  %46 = tail call i64 %45(%"class.v8::internal::LargeObjectSpace"* %5) #14
  %47 = load i64, i64* %42, align 8
  %48 = icmp ult i64 %47, %46
  %49 = select i1 %48, i64 %46, i64 %47
  store i64 %49, i64* %42, align 8
  %50 = load i64, i64* %38, align 8
  %51 = add i64 %50, 1
  %52 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %30, i64 0, i32 0
  %53 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %3, align 8
  %54 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %53, i64 0, i32 86, i32 0, i32 0, i32 0
  %55 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %54, align 8
  %56 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %55, i64 0, i32 11, i32 0, i32 0, i32 0, i32 0
  %57 = load atomic i8, i8* %56 seq_cst, align 1
  %58 = icmp ne i8 %57, 0
  tail call void @_ZN2v88internal11MemoryChunk27SetYoungGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"* %52, i1 zeroext %58) #14
  %59 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %30, i64 0, i32 0, i32 0, i32 1
  %60 = load i64, i64* %59, align 8
  %61 = or i64 %60, 16
  store i64 %61, i64* %59, align 8
  %62 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %3, align 8
  %63 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %62, i64 0, i32 129
  tail call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %63) #14
  %64 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %50, i64* %64 release, align 8
  tail call void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"* %63) #14
  %65 = load i8, i8* @_ZN2v88internal13FLAG_minor_mcE, align 1, !range !2
  %66 = icmp eq i8 %65, 0
  br i1 %66, label %74, label %67

67:                                               ; preds = %32
  tail call void @_ZN2v88internal11MemoryChunk29AllocateYoungGenerationBitmapEv(%"class.v8::internal::MemoryChunk"* %52) #14
  %68 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %30, i64 0, i32 0, i32 0
  %69 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %68, i64 2, i32 7
  %70 = bitcast %"struct.std::__1::atomic.15"* %69 to %"class.v8::internal::ConcurrentBitmap.1148"**
  %71 = load %"class.v8::internal::ConcurrentBitmap.1148"*, %"class.v8::internal::ConcurrentBitmap.1148"** %70, align 8
  %72 = getelementptr inbounds %"class.v8::internal::ConcurrentBitmap.1148", %"class.v8::internal::ConcurrentBitmap.1148"* %71, i64 0, i32 0
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %72, i8 0, i64 8196, i1 false) #14
  %73 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %30, i64 0, i32 0, i32 14, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %73 monotonic, align 8
  br label %74

74:                                               ; preds = %32, %67
  tail call void @_ZN2v88internal11MemoryChunk25InitializationMemoryFenceEv(%"class.v8::internal::MemoryChunk"* %52) #14
  %75 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %76 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 3
  %77 = load i8, i8* %76, align 8, !range !2
  %78 = icmp eq i8 %77, 0
  br i1 %78, label %79, label %95

79:                                               ; preds = %74
  %80 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %81 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %80 to i64*
  %82 = load i64, i64* %81, align 8
  %83 = bitcast %"class.v8::internal::AllocationCounter"* %75 to i64*
  %84 = load i64, i64* %83, align 8
  %85 = icmp eq i64 %82, %84
  br i1 %85, label %95, label %86

86:                                               ; preds = %79
  %87 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 6
  %88 = load i64, i64* %87, align 8
  %89 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 5
  %90 = load i64, i64* %89, align 8
  %91 = sub i64 %88, %90
  %92 = icmp ugt i64 %91, %18
  br i1 %92, label %94, label %93

93:                                               ; preds = %86
  tail call void @_ZN2v88internal17AllocationCounter25InvokeAllocationObserversEmmm(%"class.v8::internal::AllocationCounter"* %75, i64 %50, i64 %18, i64 %18) #14
  br label %94

94:                                               ; preds = %93, %86
  tail call void @_ZN2v88internal17AllocationCounter26AdvanceAllocationObserversEm(%"class.v8::internal::AllocationCounter"* %75, i64 %18) #14
  br label %95

95:                                               ; preds = %74, %79, %94
  %96 = and i64 %51, 1
  %97 = icmp eq i64 %96, 0
  br i1 %97, label %98, label %104, !prof !3

98:                                               ; preds = %95
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.2, i64 0, i64 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.6, i64 0, i64 0)) #13
  unreachable

99:                                               ; preds = %26, %19, %2
  %100 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %101 = load i32, i32* %100, align 8
  %102 = sext i32 %101 to i64
  %103 = shl nsw i64 %102, 1
  br label %104

104:                                              ; preds = %99, %95
  %105 = phi i64 [ %51, %95 ], [ %103, %99 ]
  ret i64 %105
}

declare void @_ZN2v88internal11MemoryChunk27SetYoungGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"*, i1 zeroext) local_unnamed_addr #4

declare void @_ZN2v88internal11MemoryChunk29AllocateYoungGenerationBitmapEv(%"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19NewLargeObjectSpace9AvailableEv(%"class.v8::internal::NewLargeObjectSpace"*) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 1
  %3 = load i64, i64* %2, align 8
  %4 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0
  %5 = bitcast %"class.v8::internal::NewLargeObjectSpace"* %0 to i64 (%"class.v8::internal::LargeObjectSpace"*)***
  %6 = load i64 (%"class.v8::internal::LargeObjectSpace"*)**, i64 (%"class.v8::internal::LargeObjectSpace"*)*** %5, align 8
  %7 = getelementptr inbounds i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %6, i64 11
  %8 = load i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %7, align 8
  %9 = tail call i64 %8(%"class.v8::internal::LargeObjectSpace"* %4) #14
  %10 = sub i64 %3, %9
  ret i64 %10
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN2v88internal19NewLargeObjectSpace4FlipEv(%"class.v8::internal::NewLargeObjectSpace"* nocapture readonly) local_unnamed_addr #5 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2, i32 0
  %3 = bitcast %"class.v8::internal::MemoryChunk"** %2 to %"class.v8::internal::LargePage"**
  %4 = load %"class.v8::internal::LargePage"*, %"class.v8::internal::LargePage"** %3, align 8
  %5 = icmp eq %"class.v8::internal::LargePage"* %4, null
  br i1 %5, label %6, label %7

6:                                                ; preds = %7, %1
  ret void

7:                                                ; preds = %1, %7
  %8 = phi %"class.v8::internal::LargePage"* [ %15, %7 ], [ %4, %1 ]
  %9 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %8, i64 0, i32 0, i32 0, i32 1
  %10 = load i64, i64* %9, align 8
  %11 = and i64 %10, -25
  %12 = or i64 %11, 8
  store i64 %12, i64* %9, align 8
  %13 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %8, i64 0, i32 0, i32 12, i32 0
  %14 = bitcast %"class.v8::internal::MemoryChunk"** %13 to %"class.v8::internal::LargePage"**
  %15 = load %"class.v8::internal::LargePage"*, %"class.v8::internal::LargePage"** %14, align 8
  %16 = icmp eq %"class.v8::internal::LargePage"* %15, null
  br i1 %16, label %6, label %7
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19NewLargeObjectSpace15FreeDeadObjectsERKNSt3__18functionIFbNS0_10HeapObjectEEEE(%"class.v8::internal::NewLargeObjectSpace"*, %"class.std::__1::function"* dereferenceable(32)) local_unnamed_addr #0 align 2 {
  %3 = alloca %"class.v8::internal::HeapObject", align 8
  %4 = alloca %"class.v8::internal::HeapObject", align 8
  %5 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %6 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %6, i64 0, i32 86, i32 0, i32 0, i32 0
  %8 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %7, align 8
  %9 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %8, i64 0, i32 11, i32 0, i32 0, i32 0, i32 0
  %10 = load atomic i8, i8* %9 seq_cst, align 1
  %11 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0
  %12 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2, i32 0
  %13 = bitcast %"class.v8::internal::MemoryChunk"** %12 to i64*
  %14 = load i64, i64* %13, align 8, !noalias !7
  %15 = inttoptr i64 %14 to %"class.v8::internal::LargePage"*
  %16 = icmp eq i64 %14, 0
  br i1 %16, label %17, label %19

17:                                               ; preds = %2
  %18 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %18 seq_cst, align 8
  br label %115

19:                                               ; preds = %2
  %20 = icmp eq i8 %10, 0
  %21 = bitcast %"class.v8::internal::HeapObject"* %4 to i8*
  %22 = getelementptr inbounds %"class.v8::internal::HeapObject", %"class.v8::internal::HeapObject"* %4, i64 0, i32 0, i32 0, i32 0
  %23 = bitcast %"class.v8::internal::HeapObject"* %3 to i8*
  %24 = getelementptr inbounds %"class.v8::internal::HeapObject", %"class.v8::internal::HeapObject"* %3, i64 0, i32 0, i32 0, i32 0
  %25 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 1, i32 0
  %26 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 0
  %27 = bitcast %"class.v8::internal::NewLargeObjectSpace"* %0 to void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)***
  br i1 %20, label %28, label %69

28:                                               ; preds = %19, %58
  %29 = phi %"class.v8::internal::LargePage"* [ %61, %58 ], [ %15, %19 ]
  %30 = phi i64 [ %60, %58 ], [ 0, %19 ]
  %31 = phi i8 [ %59, %58 ], [ 0, %19 ]
  %32 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %29, i64 0, i32 0, i32 12, i32 0
  %33 = bitcast %"class.v8::internal::MemoryChunk"** %32 to i64*
  %34 = load i64, i64* %33, align 8, !noalias !10
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %21) #14
  %35 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %29, i64 0, i32 0, i32 0, i32 3
  %36 = load i64, i64* %35, align 8
  %37 = add i64 %36, 1
  store i64 %37, i64* %22, align 8
  %38 = and i64 %37, -4294967296
  %39 = inttoptr i64 %36 to i32*
  %40 = load atomic i32, i32* %39 monotonic, align 4
  %41 = zext i32 %40 to i64
  %42 = or i64 %38, %41
  %43 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %4, i64 %42) #14
  %44 = sext i32 %43 to i64
  %45 = load i64, i64* %22, align 8
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %23)
  store i64 %45, i64* %24, align 8
  %46 = load i1 (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::HeapObject"*)*, i1 (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::HeapObject"*)** %25, align 8
  %47 = call zeroext i1 %46(%"union.std::__1::__function::__policy_storage"* %26, %"class.v8::internal::HeapObject"* nonnull dereferenceable(8) %3) #14
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %23)
  br i1 %47, label %50, label %48

48:                                               ; preds = %28
  %49 = add i64 %30, %44
  br label %58

50:                                               ; preds = %28
  %51 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %27, align 8
  %52 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %51, i64 18
  %53 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %52, align 8
  call void %53(%"class.v8::internal::LargeObjectSpace"* %11, %"class.v8::internal::LargePage"* %29, i64 %44) #14
  %54 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %55 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %54, i64 0, i32 85, i32 0, i32 0, i32 0
  %56 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %55, align 8
  %57 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %29, i64 0, i32 0
  call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE2EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %56, %"class.v8::internal::MemoryChunk"* %57) #14
  br label %58

58:                                               ; preds = %50, %48
  %59 = phi i8 [ 1, %50 ], [ %31, %48 ]
  %60 = phi i64 [ %30, %50 ], [ %49, %48 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %21) #14
  %61 = inttoptr i64 %34 to %"class.v8::internal::LargePage"*
  %62 = icmp eq i64 %34, 0
  br i1 %62, label %63, label %28

63:                                               ; preds = %105, %58
  %64 = phi i8 [ %59, %58 ], [ %106, %105 ]
  %65 = phi i64 [ %60, %58 ], [ %107, %105 ]
  %66 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 %65, i64* %66 seq_cst, align 8
  %67 = and i8 %64, 1
  %68 = icmp eq i8 %67, 0
  br i1 %68, label %115, label %110

69:                                               ; preds = %19, %105
  %70 = phi %"class.v8::internal::LargePage"* [ %108, %105 ], [ %15, %19 ]
  %71 = phi i64 [ %107, %105 ], [ 0, %19 ]
  %72 = phi i8 [ %106, %105 ], [ 0, %19 ]
  %73 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %70, i64 0, i32 0, i32 12, i32 0
  %74 = bitcast %"class.v8::internal::MemoryChunk"** %73 to i64*
  %75 = load i64, i64* %74, align 8, !noalias !10
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %21) #14
  %76 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %70, i64 0, i32 0, i32 0, i32 3
  %77 = load i64, i64* %76, align 8
  %78 = add i64 %77, 1
  store i64 %78, i64* %22, align 8
  %79 = and i64 %78, -4294967296
  %80 = inttoptr i64 %77 to i32*
  %81 = load atomic i32, i32* %80 monotonic, align 4
  %82 = zext i32 %81 to i64
  %83 = or i64 %79, %82
  %84 = call i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"* nonnull %4, i64 %83) #14
  %85 = sext i32 %84 to i64
  %86 = load i64, i64* %22, align 8
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %23)
  store i64 %86, i64* %24, align 8
  %87 = load i1 (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::HeapObject"*)*, i1 (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::HeapObject"*)** %25, align 8
  %88 = call zeroext i1 %87(%"union.std::__1::__function::__policy_storage"* %26, %"class.v8::internal::HeapObject"* nonnull dereferenceable(8) %3) #14
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %23)
  br i1 %88, label %89, label %103

89:                                               ; preds = %69
  %90 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)**, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*** %27, align 8
  %91 = getelementptr inbounds void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %90, i64 18
  %92 = load void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)*, void (%"class.v8::internal::LargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64)** %91, align 8
  call void %92(%"class.v8::internal::LargeObjectSpace"* %11, %"class.v8::internal::LargePage"* %70, i64 %85) #14
  %93 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %94 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %93, i64 0, i32 85, i32 0, i32 0, i32 0
  %95 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %94, align 8
  %96 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %70, i64 0, i32 0
  call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE2EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %95, %"class.v8::internal::MemoryChunk"* %96) #14
  %97 = load i8, i8* @_ZN2v88internal23FLAG_concurrent_markingE, align 1, !range !2
  %98 = icmp eq i8 %97, 0
  br i1 %98, label %105, label %99

99:                                               ; preds = %89
  %100 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %101 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %100, i64 0, i32 87, i32 0, i32 0, i32 0
  %102 = load %"class.v8::internal::ConcurrentMarking"*, %"class.v8::internal::ConcurrentMarking"** %101, align 8
  call void @_ZN2v88internal17ConcurrentMarking20ClearMemoryChunkDataEPNS0_11MemoryChunkE(%"class.v8::internal::ConcurrentMarking"* %102, %"class.v8::internal::MemoryChunk"* %96) #14
  br label %105

103:                                              ; preds = %69
  %104 = add i64 %71, %85
  br label %105

105:                                              ; preds = %89, %99, %103
  %106 = phi i8 [ 1, %99 ], [ 1, %89 ], [ %72, %103 ]
  %107 = phi i64 [ %71, %99 ], [ %71, %89 ], [ %104, %103 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %21) #14
  %108 = inttoptr i64 %75 to %"class.v8::internal::LargePage"*
  %109 = icmp eq i64 %75, 0
  br i1 %109, label %63, label %69

110:                                              ; preds = %63
  %111 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %5, align 8
  %112 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %111, i64 0, i32 85, i32 0, i32 0, i32 0
  %113 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %112, align 8
  %114 = getelementptr inbounds %"class.v8::internal::MemoryAllocator", %"class.v8::internal::MemoryAllocator"* %113, i64 0, i32 9
  call void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"* %114) #14
  br label %115

115:                                              ; preds = %17, %63, %110
  ret void
}

declare void @_ZN2v88internal17ConcurrentMarking20ClearMemoryChunkDataEPNS0_11MemoryChunkE(%"class.v8::internal::ConcurrentMarking"*, %"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

declare void @_ZN2v88internal15MemoryAllocator8Unmapper16FreeQueuedChunksEv(%"class.v8::internal::MemoryAllocator::Unmapper"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19NewLargeObjectSpace11SetCapacityEm(%"class.v8::internal::NewLargeObjectSpace"*, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0
  %4 = bitcast %"class.v8::internal::NewLargeObjectSpace"* %0 to i64 (%"class.v8::internal::LargeObjectSpace"*)***
  %5 = load i64 (%"class.v8::internal::LargeObjectSpace"*)**, i64 (%"class.v8::internal::LargeObjectSpace"*)*** %4, align 8
  %6 = getelementptr inbounds i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %5, i64 11
  %7 = load i64 (%"class.v8::internal::LargeObjectSpace"*)*, i64 (%"class.v8::internal::LargeObjectSpace"*)** %6, align 8
  %8 = tail call i64 %7(%"class.v8::internal::LargeObjectSpace"* %3) #14
  %9 = icmp ugt i64 %8, %1
  %10 = select i1 %9, i64 %8, i64 %1
  %11 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 1
  store i64 %10, i64* %11, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal20CodeLargeObjectSpaceC2EPNS0_4HeapE(%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::Heap"*) unnamed_addr #0 align 2 {
  %3 = tail call i8* @_Znwm(i64 48) #15
  %4 = bitcast i8* %3 to i32 (...)***
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %3, i8 0, i64 48, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [12 x i8*] }, { [12 x i8*] }* @_ZTVN2v88internal10NoFreeListE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %5 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %6 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store %"class.v8::internal::Heap"* %1, %"class.v8::internal::Heap"** %6, align 8
  %7 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 2
  store i32 5, i32* %7, align 8
  %8 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %9 = bitcast i64* %8 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %9, i8 0, i64 16, i1 false) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %10 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %11 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1, i32 2, i32 0, i32 3
  %12 = bitcast %"class.std::__1::__compressed_pair.54"* %11 to i32*
  %13 = bitcast %"class.v8::internal::AllocationCounter"* %10 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %13, i8 0, i64 80, i1 false) #14
  store i32 1065353216, i32* %12, align 4
  %14 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1, i32 3
  store i8 0, i8* %14, align 8
  %15 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 1, i32 5
  %16 = bitcast i64* %15 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %16, i8 0, i64 17, i1 false) #14
  %17 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %18 = bitcast %"class.v8::internal::heap::List"* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %18, i8 0, i64 16, i1 false) #14
  %19 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 4
  %20 = ptrtoint i8* %3 to i64
  %21 = bitcast %"class.std::__1::unique_ptr.59"* %19 to i64*
  store i64 %20, i64* %21, align 8
  %22 = tail call i8* @_Znam(i64 16) #15
  %23 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 3
  %24 = bitcast %"struct.std::__1::atomic"** %23 to i8**
  store i8* %22, i8** %24, align 8
  %25 = bitcast i8* %22 to i64*
  store atomic i64 0, i64* %25 seq_cst, align 8
  %26 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %23, align 8
  %27 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %26, i64 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store atomic i64 0, i64* %27 seq_cst, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal16LargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %28 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %28, align 8
  %29 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2
  store i32 0, i32* %29, align 8
  %30 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %30, align 8
  %31 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 4
  tail call void @_ZN2v84base5MutexC1Ev(%"class.v8::base::Mutex"* %31) #14
  %32 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 0, i64* %32, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal20CodeLargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %33 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1
  %34 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 3
  %35 = bitcast %"class.std::__1::__compressed_pair.93"* %34 to i32*
  %36 = bitcast %"class.std::__1::unordered_map.71"* %33 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %36, i8 0, i64 32, i1 false) #14
  store i32 1065353216, i32* %35, align 4
  %37 = getelementptr inbounds %"class.std::__1::unordered_map.71", %"class.std::__1::unordered_map.71"* %33, i64 0, i32 0
  tail call void @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE8__rehashEm(%"class.std::__1::__hash_table.72"* %37, i64 1024) #14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal20CodeLargeObjectSpace11AllocateRawEi(%"class.v8::internal::CodeLargeObjectSpace"*, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0
  %4 = tail call i64 @_ZN2v88internal19OldLargeObjectSpace11AllocateRawEiNS0_13ExecutabilityE(%"class.v8::internal::OldLargeObjectSpace"* %3, i32 %1, i32 1)
  ret i64 %4
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal20CodeLargeObjectSpace7AddPageEPNS0_9LargePageEm(%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64) unnamed_addr #0 align 2 {
  %4 = alloca %"class.std::__1::tuple", align 8
  %5 = alloca %"class.std::__1::tuple.1150", align 1
  %6 = alloca i64, align 8
  %7 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0
  %8 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 0
  %9 = load i64, i64* %8, align 8
  %10 = shl i64 %9, 32
  %11 = ashr exact i64 %10, 32
  %12 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %13 = atomicrmw add i64* %12, i64 %11 seq_cst
  %14 = load i64, i64* %8, align 8
  %15 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %16 = atomicrmw add i64* %15, i64 %14 seq_cst
  %17 = load atomic i64, i64* %15 seq_cst, align 8
  %18 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 4
  %19 = load i64, i64* %18, align 8
  %20 = icmp ugt i64 %17, %19
  br i1 %20, label %21, label %23

21:                                               ; preds = %3
  %22 = load atomic i64, i64* %15 seq_cst, align 8
  store i64 %22, i64* %18, align 8
  br label %23

23:                                               ; preds = %21, %3
  %24 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %25 = atomicrmw add i64* %24, i64 %2 seq_cst
  %26 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2
  %27 = load i32, i32* %26, align 8
  %28 = add nsw i32 %27, 1
  store i32 %28, i32* %26, align 8
  %29 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0
  %30 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2, i32 1
  %31 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %30, align 8
  %32 = icmp eq %"class.v8::internal::MemoryChunk"* %31, null
  br i1 %32, label %41, label %33

33:                                               ; preds = %23
  %34 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %31, i64 0, i32 12, i32 0
  %35 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %34, align 8
  %36 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %35, %"class.v8::internal::MemoryChunk"** %36, align 8
  %37 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %31, %"class.v8::internal::MemoryChunk"** %37, align 8
  store %"class.v8::internal::MemoryChunk"* %29, %"class.v8::internal::MemoryChunk"** %34, align 8
  %38 = icmp eq %"class.v8::internal::MemoryChunk"* %35, null
  %39 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %35, i64 0, i32 12, i32 1
  %40 = select i1 %38, %"class.v8::internal::MemoryChunk"** %30, %"class.v8::internal::MemoryChunk"** %39
  br label %45

41:                                               ; preds = %23
  %42 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 0
  %43 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2, i32 0
  %44 = bitcast %"class.v8::internal::MemoryChunk"** %42 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %44, i8 0, i64 16, i1 false) #14
  store %"class.v8::internal::MemoryChunk"* %29, %"class.v8::internal::MemoryChunk"** %43, align 8
  br label %45

45:                                               ; preds = %33, %41
  %46 = phi %"class.v8::internal::MemoryChunk"** [ %30, %41 ], [ %40, %33 ]
  store %"class.v8::internal::MemoryChunk"* %29, %"class.v8::internal::MemoryChunk"** %46, align 8
  %47 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 8
  %48 = ptrtoint %"class.v8::internal::CodeLargeObjectSpace"* %0 to i64
  %49 = bitcast %"struct.std::__1::atomic.606"* %47 to i64*
  store atomic i64 %48, i64* %49 seq_cst, align 8
  %50 = bitcast %"class.v8::internal::CodeLargeObjectSpace"* %0 to i1 (%"class.v8::internal::LargeObjectSpace"*)***
  %51 = load i1 (%"class.v8::internal::LargeObjectSpace"*)**, i1 (%"class.v8::internal::LargeObjectSpace"*)*** %50, align 8
  %52 = getelementptr inbounds i1 (%"class.v8::internal::LargeObjectSpace"*)*, i1 (%"class.v8::internal::LargeObjectSpace"*)** %51, i64 19
  %53 = load i1 (%"class.v8::internal::LargeObjectSpace"*)*, i1 (%"class.v8::internal::LargeObjectSpace"*)** %52, align 8
  %54 = tail call zeroext i1 %53(%"class.v8::internal::LargeObjectSpace"* %7) #14
  br i1 %54, label %63, label %55

55:                                               ; preds = %45
  %56 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  %57 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %56, align 8
  %58 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %57, i64 0, i32 86, i32 0, i32 0, i32 0
  %59 = load %"class.v8::internal::IncrementalMarking"*, %"class.v8::internal::IncrementalMarking"** %58, align 8
  %60 = getelementptr inbounds %"class.v8::internal::IncrementalMarking", %"class.v8::internal::IncrementalMarking"* %59, i64 0, i32 11, i32 0, i32 0, i32 0, i32 0
  %61 = load atomic i8, i8* %60 seq_cst, align 1
  %62 = icmp ne i8 %61, 0
  br label %63

63:                                               ; preds = %45, %55
  %64 = phi i1 [ false, %45 ], [ %62, %55 ]
  tail call void @_ZN2v88internal11MemoryChunk25SetOldGenerationPageFlagsEb(%"class.v8::internal::MemoryChunk"* %29, i1 zeroext %64) #14
  %65 = bitcast i64* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %65) #14
  %66 = ptrtoint %"class.v8::internal::LargePage"* %1 to i64
  store i64 %66, i64* %6, align 8
  %67 = load i64, i64* %8, align 8
  %68 = add i64 %67, %66
  %69 = icmp ugt i64 %68, %66
  br i1 %69, label %70, label %85

70:                                               ; preds = %63
  %71 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0
  %72 = bitcast %"class.std::__1::tuple"* %4 to i8*
  %73 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %4, i64 0, i32 0, i32 0, i32 0
  %74 = getelementptr inbounds %"class.std::__1::tuple.1150", %"class.std::__1::tuple.1150"* %5, i64 0, i32 0
  br label %75

75:                                               ; preds = %75, %70
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %72) #14
  store i64* %6, i64** %73, align 8
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %74) #14
  %76 = call { %"struct.std::__1::__hash_node_base.76"*, i8 } @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE25__emplace_unique_key_argsImJRKNS_21piecewise_construct_tENS_5tupleIJRKmEEENSM_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeIS6_PvEEEEbEERKT_DpOT0_(%"class.std::__1::__hash_table.72"* %71, i64* nonnull dereferenceable(8) %6, %"struct.std::__1::piecewise_construct_t"* nonnull dereferenceable(1) @_ZNSt3__1L19piecewise_constructE, %"class.std::__1::tuple"* nonnull dereferenceable(8) %4, %"class.std::__1::tuple.1150"* nonnull dereferenceable(1) %5) #14
  %77 = extractvalue { %"struct.std::__1::__hash_node_base.76"*, i8 } %76, 0
  %78 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %77, i64 3
  %79 = bitcast %"struct.std::__1::__hash_node_base.76"* %78 to %"class.v8::internal::LargePage"**
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %74) #14
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %72) #14
  store %"class.v8::internal::LargePage"* %1, %"class.v8::internal::LargePage"** %79, align 8
  %80 = load i64, i64* %6, align 8
  %81 = add i64 %80, 262144
  store i64 %81, i64* %6, align 8
  %82 = load i64, i64* %8, align 8
  %83 = add i64 %82, %66
  %84 = icmp ult i64 %81, %83
  br i1 %84, label %75, label %85

85:                                               ; preds = %75, %63
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %65) #14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal20CodeLargeObjectSpace10RemovePageEPNS0_9LargePageEm(%"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::LargePage"*, i64) unnamed_addr #0 align 2 {
  tail call void @_ZN2v88internal20CodeLargeObjectSpace21RemoveChunkMapEntriesEPNS0_9LargePageE(%"class.v8::internal::CodeLargeObjectSpace"* %0, %"class.v8::internal::LargePage"* %1)
  %4 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  %5 = bitcast %"class.v8::internal::Heap"** %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, -41416
  %8 = inttoptr i64 %7 to %"class.v8::internal::Isolate"*
  %9 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0
  tail call void @_ZN2v88internal7Isolate21RemoveCodeMemoryChunkEPNS0_11MemoryChunkE(%"class.v8::internal::Isolate"* %8, %"class.v8::internal::MemoryChunk"* %9) #14
  %10 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 0
  %11 = load i64, i64* %10, align 8
  %12 = shl i64 %11, 32
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %15 = atomicrmw sub i64* %14, i64 %13 seq_cst
  %16 = load i64, i64* %10, align 8
  %17 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %18 = atomicrmw sub i64* %17, i64 %16 seq_cst
  %19 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %20 = atomicrmw sub i64* %19, i64 %2 seq_cst
  %21 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 2
  %22 = load i32, i32* %21, align 8
  %23 = add nsw i32 %22, -1
  store i32 %23, i32* %21, align 8
  %24 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %25 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 2, i32 1
  %26 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %25, align 8
  %27 = icmp eq %"class.v8::internal::MemoryChunk"* %26, %9
  br i1 %27, label %28, label %33

28:                                               ; preds = %3
  %29 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 1
  %30 = bitcast %"class.v8::internal::MemoryChunk"** %29 to i64*
  %31 = load i64, i64* %30, align 8
  %32 = bitcast %"class.v8::internal::MemoryChunk"** %25 to i64*
  store i64 %31, i64* %32, align 8
  br label %33

33:                                               ; preds = %28, %3
  %34 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %24, i64 0, i32 0
  %35 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %34, align 8
  %36 = icmp eq %"class.v8::internal::MemoryChunk"* %35, %9
  br i1 %36, label %37, label %42

37:                                               ; preds = %33
  %38 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 0
  %39 = bitcast %"class.v8::internal::MemoryChunk"** %38 to i64*
  %40 = load i64, i64* %39, align 8
  %41 = bitcast %"class.v8::internal::heap::List"* %24 to i64*
  store i64 %40, i64* %41, align 8
  br label %42

42:                                               ; preds = %37, %33
  %43 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 0
  %44 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %43, align 8
  %45 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 12, i32 1
  %46 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %45, align 8
  %47 = icmp eq %"class.v8::internal::MemoryChunk"* %44, null
  br i1 %47, label %50, label %48

48:                                               ; preds = %42
  %49 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %44, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %46, %"class.v8::internal::MemoryChunk"** %49, align 8
  br label %50

50:                                               ; preds = %48, %42
  %51 = icmp eq %"class.v8::internal::MemoryChunk"* %46, null
  br i1 %51, label %54, label %52

52:                                               ; preds = %50
  %53 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %46, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %44, %"class.v8::internal::MemoryChunk"** %53, align 8
  br label %54

54:                                               ; preds = %50, %52
  %55 = bitcast %"class.v8::internal::MemoryChunk"** %43 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %55, i8 0, i64 16, i1 false) #14
  %56 = getelementptr inbounds %"class.v8::internal::LargePage", %"class.v8::internal::LargePage"* %1, i64 0, i32 0, i32 0, i32 8
  %57 = bitcast %"struct.std::__1::atomic.606"* %56 to i64*
  store atomic i64 0, i64* %57 seq_cst, align 8
  ret void
}

declare void @_ZN2v88internal7Isolate21RemoveCodeMemoryChunkEPNS0_11MemoryChunkE(%"class.v8::internal::Isolate"*, %"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9BaseSpace15CommittedMemoryEv(%"class.v8::internal::BaseSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::BaseSpace", %"class.v8::internal::BaseSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i64, i64* %2 seq_cst, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal9BaseSpace22MaximumCommittedMemoryEv(%"class.v8::internal::BaseSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::BaseSpace", %"class.v8::internal::BaseSpace"* %0, i64 0, i32 4
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal16LargeObjectSpace4SizeEv(%"class.v8::internal::LargeObjectSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i64, i64* %2 seq_cst, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal16LargeObjectSpaceD0Ev(%"class.v8::internal::LargeObjectSpace"*) unnamed_addr #0 comdat align 2 {
  tail call void @_ZN2v88internal16LargeObjectSpaceD2Ev(%"class.v8::internal::LargeObjectSpace"* %0) #14
  %2 = bitcast %"class.v8::internal::LargeObjectSpace"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %2) #14
  ret void
}

declare void @_ZN2v88internal5Space21AddAllocationObserverEPNS0_18AllocationObserverE(%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*) unnamed_addr #4

declare void @_ZN2v88internal5Space24RemoveAllocationObserverEPNS0_18AllocationObserverE(%"class.v8::internal::Space"*, %"class.v8::internal::AllocationObserver"*) unnamed_addr #4

declare void @_ZN2v88internal5Space24PauseAllocationObserversEv(%"class.v8::internal::Space"*) unnamed_addr #4

declare void @_ZN2v88internal5Space25ResumeAllocationObserversEv(%"class.v8::internal::Space"*) unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal5Space29StartNextInlineAllocationStepEv(%"class.v8::internal::Space"*) unnamed_addr #0 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal16LargeObjectSpace13SizeOfObjectsEv(%"class.v8::internal::LargeObjectSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load atomic i64, i64* %2 seq_cst, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN2v88internal5Space30RoundSizeDownToObjectAlignmentEi(%"class.v8::internal::Space"*, i32) unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 0, i32 2
  %4 = load i32, i32* %3, align 8
  %5 = icmp eq i32 %4, 2
  %6 = select i1 %5, i32 -32, i32 -4
  %7 = and i32 %6, %1
  ret i32 %7
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZNK2v88internal5Space25ExternalBackingStoreBytesENS0_24ExternalBackingStoreTypeE(%"class.v8::internal::Space"*, i32) unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::Space", %"class.v8::internal::Space"* %0, i64 0, i32 3
  %4 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %3, align 8
  %5 = zext i32 %1 to i64
  %6 = getelementptr inbounds %"struct.std::__1::atomic", %"struct.std::__1::atomic"* %4, i64 %5, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load atomic i64, i64* %6 seq_cst, align 8
  ret i64 %7
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZNK2v88internal16LargeObjectSpace13is_off_threadEv(%"class.v8::internal::LargeObjectSpace"*) unnamed_addr #0 comdat align 2 {
  ret i1 false
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal30LargeObjectSpaceObjectIteratorD0Ev(%"class.v8::internal::LargeObjectSpaceObjectIterator"*) unnamed_addr #8 comdat align 2 {
  %2 = bitcast %"class.v8::internal::LargeObjectSpaceObjectIterator"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %2) #14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal16LargeObjectSpaceD2Ev(%"class.v8::internal::LargeObjectSpace"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal16LargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2, i32 1
  %4 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 2
  %5 = getelementptr inbounds %"class.v8::internal::heap::List", %"class.v8::internal::heap::List"* %4, i64 0, i32 0
  %6 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 1
  %7 = bitcast %"class.v8::internal::Heap"** %6 to i64*
  %8 = bitcast %"class.v8::internal::MemoryChunk"** %3 to i64*
  %9 = bitcast %"class.v8::internal::heap::List"* %4 to i64*
  br label %10

10:                                               ; preds = %52, %1
  %11 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %5, align 8
  %12 = icmp eq %"class.v8::internal::MemoryChunk"* %11, null
  br i1 %12, label %13, label %16

13:                                               ; preds = %10
  %14 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %3, align 8
  %15 = icmp eq %"class.v8::internal::MemoryChunk"* %14, null
  br i1 %15, label %57, label %16

16:                                               ; preds = %13, %10
  %17 = load i8, i8* @_ZN2v88internal8FLAG_logE, align 1, !range !2
  %18 = icmp eq i8 %17, 0
  br i1 %18, label %26, label %19

19:                                               ; preds = %16
  %20 = load i64, i64* %7, align 8
  %21 = add i64 %20, -41416
  %22 = inttoptr i64 %21 to %"class.v8::internal::Isolate"*
  %23 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %22, i64 0, i32 21
  %24 = load %"class.v8::internal::Logger"*, %"class.v8::internal::Logger"** %23, align 8
  %25 = bitcast %"class.v8::internal::MemoryChunk"* %11 to i8*
  tail call void @_ZN2v88internal6Logger11DeleteEventEPKcPv(%"class.v8::internal::Logger"* %24, i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.1, i64 0, i64 0), i8* %25) #14
  br label %26

26:                                               ; preds = %19, %16
  %27 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %3, align 8
  %28 = icmp eq %"class.v8::internal::MemoryChunk"* %27, %11
  br i1 %28, label %29, label %33

29:                                               ; preds = %26
  %30 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %11, i64 0, i32 12, i32 1
  %31 = bitcast %"class.v8::internal::MemoryChunk"** %30 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %8, align 8
  br label %33

33:                                               ; preds = %29, %26
  %34 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %5, align 8
  %35 = icmp eq %"class.v8::internal::MemoryChunk"* %34, %11
  br i1 %35, label %36, label %40

36:                                               ; preds = %33
  %37 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %11, i64 0, i32 12, i32 0
  %38 = bitcast %"class.v8::internal::MemoryChunk"** %37 to i64*
  %39 = load i64, i64* %38, align 8
  store i64 %39, i64* %9, align 8
  br label %40

40:                                               ; preds = %36, %33
  %41 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %11, i64 0, i32 12, i32 0
  %42 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %41, align 8
  %43 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %11, i64 0, i32 12, i32 1
  %44 = load %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"** %43, align 8
  %45 = icmp eq %"class.v8::internal::MemoryChunk"* %42, null
  br i1 %45, label %48, label %46

46:                                               ; preds = %40
  %47 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %42, i64 0, i32 12, i32 1
  store %"class.v8::internal::MemoryChunk"* %44, %"class.v8::internal::MemoryChunk"** %47, align 8
  br label %48

48:                                               ; preds = %46, %40
  %49 = icmp eq %"class.v8::internal::MemoryChunk"* %44, null
  br i1 %49, label %52, label %50

50:                                               ; preds = %48
  %51 = getelementptr inbounds %"class.v8::internal::MemoryChunk", %"class.v8::internal::MemoryChunk"* %44, i64 0, i32 12, i32 0
  store %"class.v8::internal::MemoryChunk"* %42, %"class.v8::internal::MemoryChunk"** %51, align 8
  br label %52

52:                                               ; preds = %50, %48
  %53 = bitcast %"class.v8::internal::MemoryChunk"** %41 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %53, i8 0, i64 16, i1 false) #14
  %54 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %6, align 8
  %55 = getelementptr inbounds %"class.v8::internal::Heap", %"class.v8::internal::Heap"* %54, i64 0, i32 85, i32 0, i32 0, i32 0
  %56 = load %"class.v8::internal::MemoryAllocator"*, %"class.v8::internal::MemoryAllocator"** %55, align 8
  tail call void @_ZN2v88internal15MemoryAllocator4FreeILNS1_8FreeModeE0EEEvPNS0_11MemoryChunkE(%"class.v8::internal::MemoryAllocator"* %56, %"class.v8::internal::MemoryChunk"* %11) #14
  br label %10

57:                                               ; preds = %13
  %58 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 4
  tail call void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"* %58) #14
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [18 x i8*] }, { [18 x i8*] }* @_ZTVN2v88internal5SpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %59 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 3
  %60 = load %"struct.std::__1::atomic"*, %"struct.std::__1::atomic"** %59, align 8
  %61 = icmp eq %"struct.std::__1::atomic"* %60, null
  br i1 %61, label %64, label %62

62:                                               ; preds = %57
  %63 = bitcast %"struct.std::__1::atomic"* %60 to i8*
  tail call void @_ZdaPv(i8* %63) #15
  br label %64

64:                                               ; preds = %62, %57
  store %"struct.std::__1::atomic"* null, %"struct.std::__1::atomic"** %59, align 8
  %65 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 4, i32 0, i32 0, i32 0
  %66 = load %"class.v8::internal::FreeList"*, %"class.v8::internal::FreeList"** %65, align 8
  store %"class.v8::internal::FreeList"* null, %"class.v8::internal::FreeList"** %65, align 8
  %67 = icmp eq %"class.v8::internal::FreeList"* %66, null
  br i1 %67, label %73, label %68

68:                                               ; preds = %64
  %69 = bitcast %"class.v8::internal::FreeList"* %66 to void (%"class.v8::internal::FreeList"*)***
  %70 = load void (%"class.v8::internal::FreeList"*)**, void (%"class.v8::internal::FreeList"*)*** %69, align 8
  %71 = getelementptr inbounds void (%"class.v8::internal::FreeList"*)*, void (%"class.v8::internal::FreeList"*)** %70, i64 1
  %72 = load void (%"class.v8::internal::FreeList"*)*, void (%"class.v8::internal::FreeList"*)** %71, align 8
  tail call void %72(%"class.v8::internal::FreeList"* nonnull %66) #14
  br label %73

73:                                               ; preds = %64, %68
  %74 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 2, i32 0, i32 1, i32 0, i32 0, i32 0
  %75 = load %"struct.std::__1::__hash_node_base.40"*, %"struct.std::__1::__hash_node_base.40"** %74, align 8
  %76 = icmp eq %"struct.std::__1::__hash_node_base.40"* %75, null
  br i1 %76, label %83, label %77

77:                                               ; preds = %73, %77
  %78 = phi %"struct.std::__1::__hash_node_base.40"* [ %80, %77 ], [ %75, %73 ]
  %79 = getelementptr inbounds %"struct.std::__1::__hash_node_base.40", %"struct.std::__1::__hash_node_base.40"* %78, i64 0, i32 0
  %80 = load %"struct.std::__1::__hash_node_base.40"*, %"struct.std::__1::__hash_node_base.40"** %79, align 8
  %81 = bitcast %"struct.std::__1::__hash_node_base.40"* %78 to i8*
  tail call void @_ZdlPv(i8* %81) #15
  %82 = icmp eq %"struct.std::__1::__hash_node_base.40"* %80, null
  br i1 %82, label %83, label %77

83:                                               ; preds = %77, %73
  %84 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
  %85 = load %"struct.std::__1::__hash_node_base.40"**, %"struct.std::__1::__hash_node_base.40"*** %84, align 8
  store %"struct.std::__1::__hash_node_base.40"** null, %"struct.std::__1::__hash_node_base.40"*** %84, align 8
  %86 = icmp eq %"struct.std::__1::__hash_node_base.40"** %85, null
  br i1 %86, label %89, label %87

87:                                               ; preds = %83
  %88 = bitcast %"struct.std::__1::__hash_node_base.40"** %85 to i8*
  tail call void @_ZdlPv(i8* %88) #15
  br label %89

89:                                               ; preds = %87, %83
  %90 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0
  %91 = load %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %90, align 8
  %92 = icmp eq %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %91, null
  br i1 %92, label %98, label %93

93:                                               ; preds = %89
  %94 = ptrtoint %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %91 to i64
  %95 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 1
  %96 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %95 to i64*
  store i64 %94, i64* %96, align 8
  %97 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %91 to i8*
  tail call void @_ZdlPv(i8* %97) #15
  br label %98

98:                                               ; preds = %93, %89
  %99 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %100 = load %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %99, align 8
  %101 = icmp eq %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %100, null
  br i1 %101, label %107, label %102

102:                                              ; preds = %98
  %103 = ptrtoint %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %100 to i64
  %104 = getelementptr inbounds %"class.v8::internal::LargeObjectSpace", %"class.v8::internal::LargeObjectSpace"* %0, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %105 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"** %104 to i64*
  store i64 %103, i64* %105, align 8
  %106 = bitcast %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* %100 to i8*
  tail call void @_ZdlPv(i8* %106) #15
  br label %107

107:                                              ; preds = %98, %102
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal19NewLargeObjectSpaceD0Ev(%"class.v8::internal::NewLargeObjectSpace"*) unnamed_addr #8 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::NewLargeObjectSpace", %"class.v8::internal::NewLargeObjectSpace"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal16LargeObjectSpaceD2Ev(%"class.v8::internal::LargeObjectSpace"* %2) #14
  %3 = bitcast %"class.v8::internal::NewLargeObjectSpace"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %3) #14
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal20CodeLargeObjectSpaceD2Ev(%"class.v8::internal::CodeLargeObjectSpace"*) unnamed_addr #8 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal20CodeLargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 1, i32 0, i32 0, i32 0
  %4 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %3, align 8
  %5 = icmp eq %"struct.std::__1::__hash_node_base.76"* %4, null
  br i1 %5, label %12, label %6

6:                                                ; preds = %1, %6
  %7 = phi %"struct.std::__1::__hash_node_base.76"* [ %9, %6 ], [ %4, %1 ]
  %8 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %7, i64 0, i32 0
  %9 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %8, align 8
  %10 = bitcast %"struct.std::__1::__hash_node_base.76"* %7 to i8*
  tail call void @_ZdlPv(i8* %10) #15
  %11 = icmp eq %"struct.std::__1::__hash_node_base.76"* %9, null
  br i1 %11, label %12, label %6

12:                                               ; preds = %6, %1
  %13 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %14 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %13, align 8
  store %"struct.std::__1::__hash_node_base.76"** null, %"struct.std::__1::__hash_node_base.76"*** %13, align 8
  %15 = icmp eq %"struct.std::__1::__hash_node_base.76"** %14, null
  br i1 %15, label %18, label %16

16:                                               ; preds = %12
  %17 = bitcast %"struct.std::__1::__hash_node_base.76"** %14 to i8*
  tail call void @_ZdlPv(i8* %17) #15
  br label %18

18:                                               ; preds = %12, %16
  %19 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0
  tail call void @_ZN2v88internal16LargeObjectSpaceD2Ev(%"class.v8::internal::LargeObjectSpace"* %19) #14
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal20CodeLargeObjectSpaceD0Ev(%"class.v8::internal::CodeLargeObjectSpace"*) unnamed_addr #8 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [22 x i8*] }, { [22 x i8*] }* @_ZTVN2v88internal20CodeLargeObjectSpaceE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 1, i32 0, i32 0, i32 0
  %4 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %3, align 8
  %5 = icmp eq %"struct.std::__1::__hash_node_base.76"* %4, null
  br i1 %5, label %12, label %6

6:                                                ; preds = %1, %6
  %7 = phi %"struct.std::__1::__hash_node_base.76"* [ %9, %6 ], [ %4, %1 ]
  %8 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %7, i64 0, i32 0
  %9 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %8, align 8
  %10 = bitcast %"struct.std::__1::__hash_node_base.76"* %7 to i8*
  tail call void @_ZdlPv(i8* %10) #15
  %11 = icmp eq %"struct.std::__1::__hash_node_base.76"* %9, null
  br i1 %11, label %12, label %6

12:                                               ; preds = %6, %1
  %13 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %14 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %13, align 8
  store %"struct.std::__1::__hash_node_base.76"** null, %"struct.std::__1::__hash_node_base.76"*** %13, align 8
  %15 = icmp eq %"struct.std::__1::__hash_node_base.76"** %14, null
  br i1 %15, label %18, label %16

16:                                               ; preds = %12
  %17 = bitcast %"struct.std::__1::__hash_node_base.76"** %14 to i8*
  tail call void @_ZdlPv(i8* %17) #15
  br label %18

18:                                               ; preds = %12, %16
  %19 = getelementptr inbounds %"class.v8::internal::CodeLargeObjectSpace", %"class.v8::internal::CodeLargeObjectSpace"* %0, i64 0, i32 0, i32 0
  tail call void @_ZN2v88internal16LargeObjectSpaceD2Ev(%"class.v8::internal::LargeObjectSpace"* %19) #14
  %20 = bitcast %"class.v8::internal::CodeLargeObjectSpace"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %20) #14
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal19OldLargeObjectSpaceD0Ev(%"class.v8::internal::OldLargeObjectSpace"*) unnamed_addr #8 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OldLargeObjectSpace", %"class.v8::internal::OldLargeObjectSpace"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal16LargeObjectSpaceD2Ev(%"class.v8::internal::LargeObjectSpace"* %2) #14
  %3 = bitcast %"class.v8::internal::OldLargeObjectSpace"* %0 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* %3) #14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal8FreeListD2Ev(%"class.v8::internal::FreeList"*) unnamed_addr #0 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal10NoFreeListD0Ev(%"class.v8::internal::NoFreeList"*) unnamed_addr #8 comdat align 2 {
  %2 = bitcast %"class.v8::internal::NoFreeList"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #15
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal10NoFreeList21GuaranteedAllocatableEm(%"class.v8::internal::NoFreeList"*, i64) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.4, i64 0, i64 0)) #13
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal10NoFreeList4FreeEmmNS0_8FreeModeE(%"class.v8::internal::NoFreeList"*, i64, i64, i32) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.5, i64 0, i64 0)) #13
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal10NoFreeList8AllocateEmPmNS0_16AllocationOriginE(%"class.v8::internal::NoFreeList"*, i64, i64*, i32) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.5, i64 0, i64 0)) #13
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden %"class.v8::internal::Page"* @_ZN2v88internal10NoFreeList14GetPageForSizeEm(%"class.v8::internal::NoFreeList"*, i64) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.5, i64 0, i64 0)) #13
  unreachable
}

declare void @_ZN2v88internal8FreeList5ResetEv(%"class.v8::internal::FreeList"*) unnamed_addr #4

declare zeroext i1 @_ZN2v88internal8FreeList11AddCategoryEPNS0_16FreeListCategoryE(%"class.v8::internal::FreeList"*, %"class.v8::internal::FreeListCategory"*) unnamed_addr #4

declare void @_ZN2v88internal8FreeList14RemoveCategoryEPNS0_16FreeListCategoryE(%"class.v8::internal::FreeList"*, %"class.v8::internal::FreeListCategory"*) unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN2v88internal10NoFreeList26SelectFreeListCategoryTypeEm(%"class.v8::internal::NoFreeList"*, i64) unnamed_addr #0 comdat align 2 {
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([49 x i8], [49 x i8]* @.str.5, i64 0, i64 0)) #13
  unreachable
}

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #9

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znam(i64) local_unnamed_addr #6

declare zeroext i1 @_ZN2v88internal4Heap28ShouldOptimizeForMemoryUsageEv(%"class.v8::internal::Heap"*) local_unnamed_addr #4

declare i32 @_ZNK2v88internal10HeapObject11SizeFromMapENS0_3MapE(%"class.v8::internal::HeapObject"*, i64) local_unnamed_addr #4

; Function Attrs: nounwind
declare void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"*) unnamed_addr #10

; Function Attrs: nobuiltin nounwind
declare void @_ZdaPv(i8*) local_unnamed_addr #9

; Function Attrs: nounwind
declare void @_ZN2v88internal8MalloceddlEPv(i8*) local_unnamed_addr #10

declare void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"*) local_unnamed_addr #4

declare void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"*) local_unnamed_addr #4

declare void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"*) local_unnamed_addr #4

declare void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal7SlotSet11RemoveRangeEmmmNS1_15EmptyBucketModeE(%"class.v8::internal::SlotSet"*, i64, i64, i64, i32) local_unnamed_addr #0 comdat align 2 {
  %6 = shl i64 %3, 12
  %7 = icmp ult i64 %6, %2
  br i1 %7, label %8, label %9, !prof !3

8:                                                ; preds = %5
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.2, i64 0, i64 0), i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.7, i64 0, i64 0)) #13
  unreachable

9:                                                ; preds = %5
  %10 = lshr i64 %1, 2
  %11 = lshr i64 %1, 12
  %12 = lshr i64 %1, 7
  %13 = trunc i64 %12 to i32
  %14 = and i32 %13, 31
  %15 = trunc i64 %10 to i32
  %16 = and i32 %15, 31
  %17 = lshr i64 %2, 2
  %18 = lshr i64 %2, 12
  %19 = lshr i64 %2, 7
  %20 = trunc i64 %19 to i32
  %21 = and i32 %20, 31
  %22 = trunc i64 %17 to i32
  %23 = and i32 %22, 31
  %24 = shl nsw i32 -1, %16
  %25 = shl nsw i32 -1, %23
  %26 = xor i32 %25, -1
  %27 = icmp eq i64 %11, %18
  %28 = icmp eq i32 %14, %21
  %29 = and i1 %27, %28
  %30 = bitcast %"class.v8::internal::SlotSet"* %0 to %"class.v8::internal::SlotSet::Bucket"**
  %31 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket"*, %"class.v8::internal::SlotSet::Bucket"** %30, i64 %11
  %32 = bitcast %"class.v8::internal::SlotSet::Bucket"** %31 to i64*
  %33 = load atomic i64, i64* %32 acquire, align 8
  %34 = inttoptr i64 %33 to %"class.v8::internal::SlotSet::Bucket"*
  br i1 %29, label %35, label %52

35:                                               ; preds = %9
  %36 = icmp eq i64 %33, 0
  br i1 %36, label %235, label %37

37:                                               ; preds = %35
  %38 = and i32 %24, %26
  %39 = zext i32 %14 to i64
  %40 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %39
  %41 = load atomic i32, i32* %40 monotonic, align 4
  %42 = xor i32 %38, -1
  br label %43

43:                                               ; preds = %47, %37
  %44 = phi i32 [ %41, %37 ], [ %50, %47 ]
  %45 = and i32 %44, %38
  %46 = icmp eq i32 %45, 0
  br i1 %46, label %235, label %47

47:                                               ; preds = %43
  %48 = and i32 %44, %42
  %49 = cmpxchg volatile i32* %40, i32 %44, i32 %48 release monotonic
  %50 = extractvalue { i32, i1 } %49, 0
  %51 = extractvalue { i32, i1 } %49, 1
  br i1 %51, label %235, label %43

52:                                               ; preds = %9
  %53 = icmp ne i64 %33, 0
  br i1 %53, label %54, label %68

54:                                               ; preds = %52
  %55 = zext i32 %14 to i64
  %56 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %55
  %57 = load atomic i32, i32* %56 monotonic, align 4
  %58 = xor i32 %24, -1
  br label %59

59:                                               ; preds = %63, %54
  %60 = phi i32 [ %57, %54 ], [ %66, %63 ]
  %61 = and i32 %60, %24
  %62 = icmp eq i32 %61, 0
  br i1 %62, label %68, label %63

63:                                               ; preds = %59
  %64 = and i32 %60, %58
  %65 = cmpxchg volatile i32* %56, i32 %60, i32 %64 release monotonic
  %66 = extractvalue { i32, i1 } %65, 0
  %67 = extractvalue { i32, i1 } %65, 1
  br i1 %67, label %68, label %59

68:                                               ; preds = %63, %59, %52
  %69 = add nuw nsw i32 %14, 1
  %70 = icmp ult i64 %11, %18
  br i1 %70, label %71, label %112

71:                                               ; preds = %68
  %72 = icmp ult i32 %69, 32
  %73 = and i1 %72, %53
  br i1 %73, label %74, label %110

74:                                               ; preds = %71
  %75 = zext i32 %69 to i64
  %76 = sub nsw i32 30, %14
  %77 = and i32 %13, 7
  %78 = xor i32 %77, 7
  %79 = icmp eq i32 %78, 0
  br i1 %79, label %87, label %80

80:                                               ; preds = %74, %80
  %81 = phi i64 [ %84, %80 ], [ %75, %74 ]
  %82 = phi i32 [ %85, %80 ], [ %78, %74 ]
  %83 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %81
  store atomic volatile i32 0, i32* %83 release, align 4
  %84 = add nuw nsw i64 %81, 1
  %85 = add i32 %82, -1
  %86 = icmp eq i32 %85, 0
  br i1 %86, label %87, label %80, !llvm.loop !13

87:                                               ; preds = %80, %74
  %88 = phi i64 [ %75, %74 ], [ %84, %80 ]
  %89 = icmp ult i32 %76, 7
  br i1 %89, label %110, label %90

90:                                               ; preds = %87, %90
  %91 = phi i64 [ %107, %90 ], [ %88, %87 ]
  %92 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %91
  store atomic volatile i32 0, i32* %92 release, align 4
  %93 = add nuw nsw i64 %91, 1
  %94 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %93
  store atomic volatile i32 0, i32* %94 release, align 4
  %95 = add nuw nsw i64 %91, 2
  %96 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %95
  store atomic volatile i32 0, i32* %96 release, align 4
  %97 = add nuw nsw i64 %91, 3
  %98 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %97
  store atomic volatile i32 0, i32* %98 release, align 4
  %99 = add nuw nsw i64 %91, 4
  %100 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %99
  store atomic volatile i32 0, i32* %100 release, align 4
  %101 = add nuw nsw i64 %91, 5
  %102 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %101
  store atomic volatile i32 0, i32* %102 release, align 4
  %103 = add nuw nsw i64 %91, 6
  %104 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %103
  store atomic volatile i32 0, i32* %104 release, align 4
  %105 = add nuw nsw i64 %91, 7
  %106 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %34, i64 0, i32 0, i64 %105
  store atomic volatile i32 0, i32* %106 release, align 4
  %107 = add nuw nsw i64 %91, 8
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 32
  br i1 %109, label %110, label %90

110:                                              ; preds = %87, %90, %71
  %111 = add nuw nsw i64 %11, 1
  br label %112

112:                                              ; preds = %110, %68
  %113 = phi i64 [ %111, %110 ], [ %11, %68 ]
  %114 = phi i32 [ 0, %110 ], [ %69, %68 ]
  %115 = icmp ult i64 %113, %18
  br i1 %115, label %116, label %172

116:                                              ; preds = %112
  %117 = icmp eq i32 %4, 0
  br i1 %117, label %118, label %129

118:                                              ; preds = %116, %126
  %119 = phi i64 [ %127, %126 ], [ %113, %116 ]
  %120 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket"*, %"class.v8::internal::SlotSet::Bucket"** %30, i64 %119
  %121 = bitcast %"class.v8::internal::SlotSet::Bucket"** %120 to i64*
  %122 = load atomic i64, i64* %121 acquire, align 8
  store atomic volatile i64 0, i64* %121 release, align 8
  %123 = icmp eq i64 %122, 0
  br i1 %123, label %126, label %124

124:                                              ; preds = %118
  %125 = inttoptr i64 %122 to i8*
  tail call void @_ZN2v88internal8MalloceddlEPv(i8* nonnull %125) #14
  br label %126

126:                                              ; preds = %124, %118
  %127 = add nuw nsw i64 %119, 1
  %128 = icmp eq i64 %127, %18
  br i1 %128, label %172, label %118

129:                                              ; preds = %116, %169
  %130 = phi i64 [ %170, %169 ], [ %113, %116 ]
  %131 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket"*, %"class.v8::internal::SlotSet::Bucket"** %30, i64 %130
  %132 = bitcast %"class.v8::internal::SlotSet::Bucket"** %131 to i64*
  %133 = load atomic i64, i64* %132 acquire, align 8
  %134 = inttoptr i64 %133 to %"class.v8::internal::SlotSet::Bucket"*
  %135 = icmp eq i64 %133, 0
  br i1 %135, label %169, label %136

136:                                              ; preds = %129
  %137 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 0
  store atomic volatile i32 0, i32* %137 release, align 4
  %138 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 1
  store atomic volatile i32 0, i32* %138 release, align 4
  %139 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 2
  store atomic volatile i32 0, i32* %139 release, align 4
  %140 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 3
  store atomic volatile i32 0, i32* %140 release, align 4
  %141 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 4
  store atomic volatile i32 0, i32* %141 release, align 4
  %142 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 5
  store atomic volatile i32 0, i32* %142 release, align 4
  %143 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 6
  store atomic volatile i32 0, i32* %143 release, align 4
  %144 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 7
  store atomic volatile i32 0, i32* %144 release, align 4
  %145 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 8
  store atomic volatile i32 0, i32* %145 release, align 4
  %146 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 9
  store atomic volatile i32 0, i32* %146 release, align 4
  %147 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 10
  store atomic volatile i32 0, i32* %147 release, align 4
  %148 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 11
  store atomic volatile i32 0, i32* %148 release, align 4
  %149 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 12
  store atomic volatile i32 0, i32* %149 release, align 4
  %150 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 13
  store atomic volatile i32 0, i32* %150 release, align 4
  %151 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 14
  store atomic volatile i32 0, i32* %151 release, align 4
  %152 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 15
  store atomic volatile i32 0, i32* %152 release, align 4
  %153 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 16
  store atomic volatile i32 0, i32* %153 release, align 4
  %154 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 17
  store atomic volatile i32 0, i32* %154 release, align 4
  %155 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 18
  store atomic volatile i32 0, i32* %155 release, align 4
  %156 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 19
  store atomic volatile i32 0, i32* %156 release, align 4
  %157 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 20
  store atomic volatile i32 0, i32* %157 release, align 4
  %158 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 21
  store atomic volatile i32 0, i32* %158 release, align 4
  %159 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 22
  store atomic volatile i32 0, i32* %159 release, align 4
  %160 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 23
  store atomic volatile i32 0, i32* %160 release, align 4
  %161 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 24
  store atomic volatile i32 0, i32* %161 release, align 4
  %162 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 25
  store atomic volatile i32 0, i32* %162 release, align 4
  %163 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 26
  store atomic volatile i32 0, i32* %163 release, align 4
  %164 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 27
  store atomic volatile i32 0, i32* %164 release, align 4
  %165 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 28
  store atomic volatile i32 0, i32* %165 release, align 4
  %166 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 29
  store atomic volatile i32 0, i32* %166 release, align 4
  %167 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 30
  store atomic volatile i32 0, i32* %167 release, align 4
  %168 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %134, i64 0, i32 0, i64 31
  store atomic volatile i32 0, i32* %168 release, align 4
  br label %169

169:                                              ; preds = %136, %129
  %170 = add nuw nsw i64 %130, 1
  %171 = icmp eq i64 %170, %18
  br i1 %171, label %172, label %129

172:                                              ; preds = %169, %126, %112
  %173 = phi i64 [ %113, %112 ], [ %18, %126 ], [ %18, %169 ]
  %174 = icmp eq i64 %173, %3
  br i1 %174, label %235, label %175

175:                                              ; preds = %172
  %176 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket"*, %"class.v8::internal::SlotSet::Bucket"** %30, i64 %173
  %177 = bitcast %"class.v8::internal::SlotSet::Bucket"** %176 to i64*
  %178 = load atomic i64, i64* %177 acquire, align 8
  %179 = inttoptr i64 %178 to %"class.v8::internal::SlotSet::Bucket"*
  %180 = icmp eq i64 %178, 0
  br i1 %180, label %235, label %181

181:                                              ; preds = %175
  %182 = icmp slt i32 %114, %21
  br i1 %182, label %185, label %183

183:                                              ; preds = %181
  %184 = zext i32 %21 to i64
  br label %222

185:                                              ; preds = %181
  %186 = zext i32 %114 to i64
  %187 = zext i32 %21 to i64
  %188 = sub nsw i64 %187, %186
  %189 = xor i64 %186, -1
  %190 = add nsw i64 %189, %187
  %191 = and i64 %188, 7
  %192 = icmp eq i64 %191, 0
  br i1 %192, label %200, label %193

193:                                              ; preds = %185, %193
  %194 = phi i64 [ %197, %193 ], [ %186, %185 ]
  %195 = phi i64 [ %198, %193 ], [ %191, %185 ]
  %196 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %194
  store atomic volatile i32 0, i32* %196 release, align 4
  %197 = add nuw nsw i64 %194, 1
  %198 = add i64 %195, -1
  %199 = icmp eq i64 %198, 0
  br i1 %199, label %200, label %193, !llvm.loop !15

200:                                              ; preds = %193, %185
  %201 = phi i64 [ %186, %185 ], [ %197, %193 ]
  %202 = icmp ult i64 %190, 7
  br i1 %202, label %222, label %203

203:                                              ; preds = %200, %203
  %204 = phi i64 [ %220, %203 ], [ %201, %200 ]
  %205 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %204
  store atomic volatile i32 0, i32* %205 release, align 4
  %206 = add nuw nsw i64 %204, 1
  %207 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %206
  store atomic volatile i32 0, i32* %207 release, align 4
  %208 = add nuw nsw i64 %204, 2
  %209 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %208
  store atomic volatile i32 0, i32* %209 release, align 4
  %210 = add nuw nsw i64 %204, 3
  %211 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %210
  store atomic volatile i32 0, i32* %211 release, align 4
  %212 = add nuw nsw i64 %204, 4
  %213 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %212
  store atomic volatile i32 0, i32* %213 release, align 4
  %214 = add nuw nsw i64 %204, 5
  %215 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %214
  store atomic volatile i32 0, i32* %215 release, align 4
  %216 = add nuw nsw i64 %204, 6
  %217 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %216
  store atomic volatile i32 0, i32* %217 release, align 4
  %218 = add nuw nsw i64 %204, 7
  %219 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %218
  store atomic volatile i32 0, i32* %219 release, align 4
  %220 = add nuw nsw i64 %204, 8
  %221 = icmp eq i64 %220, %187
  br i1 %221, label %222, label %203

222:                                              ; preds = %200, %203, %183
  %223 = phi i64 [ %184, %183 ], [ %187, %203 ], [ %187, %200 ]
  %224 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %179, i64 0, i32 0, i64 %223
  %225 = load atomic i32, i32* %224 monotonic, align 4
  br label %226

226:                                              ; preds = %230, %222
  %227 = phi i32 [ %225, %222 ], [ %233, %230 ]
  %228 = and i32 %227, %26
  %229 = icmp eq i32 %228, 0
  br i1 %229, label %235, label %230

230:                                              ; preds = %226
  %231 = and i32 %227, %25
  %232 = cmpxchg volatile i32* %224, i32 %227, i32 %231 release monotonic
  %233 = extractvalue { i32, i1 } %232, 0
  %234 = extractvalue { i32, i1 } %232, 1
  br i1 %234, label %235, label %226

235:                                              ; preds = %230, %226, %47, %43, %172, %175, %35
  ret void
}

declare void @_ZN2v88internal11MemoryChunk14ReleaseSlotSetILNS0_17RememberedSetTypeE0EEEvv(%"class.v8::internal::MemoryChunk"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN2v88internal7SlotSet6Bucket7IsEmptyEv(%"class.v8::internal::SlotSet::Bucket"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 0
  %3 = load i32, i32* %2, align 4
  %4 = icmp eq i32 %3, 0
  br i1 %4, label %5, label %9

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 1
  %7 = load i32, i32* %6, align 4
  %8 = icmp eq i32 %7, 0
  br i1 %8, label %10, label %9

9:                                                ; preds = %122, %118, %114, %110, %106, %102, %98, %94, %90, %86, %82, %78, %74, %70, %66, %62, %58, %54, %50, %46, %42, %38, %34, %30, %26, %22, %18, %14, %10, %5, %1
  ret i1 false

10:                                               ; preds = %5
  %11 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 2
  %12 = load i32, i32* %11, align 4
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %14, label %9

14:                                               ; preds = %10
  %15 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 3
  %16 = load i32, i32* %15, align 4
  %17 = icmp eq i32 %16, 0
  br i1 %17, label %18, label %9

18:                                               ; preds = %14
  %19 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 4
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %20, 0
  br i1 %21, label %22, label %9

22:                                               ; preds = %18
  %23 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 5
  %24 = load i32, i32* %23, align 4
  %25 = icmp eq i32 %24, 0
  br i1 %25, label %26, label %9

26:                                               ; preds = %22
  %27 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 6
  %28 = load i32, i32* %27, align 4
  %29 = icmp eq i32 %28, 0
  br i1 %29, label %30, label %9

30:                                               ; preds = %26
  %31 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 7
  %32 = load i32, i32* %31, align 4
  %33 = icmp eq i32 %32, 0
  br i1 %33, label %34, label %9

34:                                               ; preds = %30
  %35 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 8
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 0
  br i1 %37, label %38, label %9

38:                                               ; preds = %34
  %39 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 9
  %40 = load i32, i32* %39, align 4
  %41 = icmp eq i32 %40, 0
  br i1 %41, label %42, label %9

42:                                               ; preds = %38
  %43 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 10
  %44 = load i32, i32* %43, align 4
  %45 = icmp eq i32 %44, 0
  br i1 %45, label %46, label %9

46:                                               ; preds = %42
  %47 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 11
  %48 = load i32, i32* %47, align 4
  %49 = icmp eq i32 %48, 0
  br i1 %49, label %50, label %9

50:                                               ; preds = %46
  %51 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 12
  %52 = load i32, i32* %51, align 4
  %53 = icmp eq i32 %52, 0
  br i1 %53, label %54, label %9

54:                                               ; preds = %50
  %55 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 13
  %56 = load i32, i32* %55, align 4
  %57 = icmp eq i32 %56, 0
  br i1 %57, label %58, label %9

58:                                               ; preds = %54
  %59 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 14
  %60 = load i32, i32* %59, align 4
  %61 = icmp eq i32 %60, 0
  br i1 %61, label %62, label %9

62:                                               ; preds = %58
  %63 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 15
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 0
  br i1 %65, label %66, label %9

66:                                               ; preds = %62
  %67 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 16
  %68 = load i32, i32* %67, align 4
  %69 = icmp eq i32 %68, 0
  br i1 %69, label %70, label %9

70:                                               ; preds = %66
  %71 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 17
  %72 = load i32, i32* %71, align 4
  %73 = icmp eq i32 %72, 0
  br i1 %73, label %74, label %9

74:                                               ; preds = %70
  %75 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 18
  %76 = load i32, i32* %75, align 4
  %77 = icmp eq i32 %76, 0
  br i1 %77, label %78, label %9

78:                                               ; preds = %74
  %79 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 19
  %80 = load i32, i32* %79, align 4
  %81 = icmp eq i32 %80, 0
  br i1 %81, label %82, label %9

82:                                               ; preds = %78
  %83 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 20
  %84 = load i32, i32* %83, align 4
  %85 = icmp eq i32 %84, 0
  br i1 %85, label %86, label %9

86:                                               ; preds = %82
  %87 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 21
  %88 = load i32, i32* %87, align 4
  %89 = icmp eq i32 %88, 0
  br i1 %89, label %90, label %9

90:                                               ; preds = %86
  %91 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 22
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 0
  br i1 %93, label %94, label %9

94:                                               ; preds = %90
  %95 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 23
  %96 = load i32, i32* %95, align 4
  %97 = icmp eq i32 %96, 0
  br i1 %97, label %98, label %9

98:                                               ; preds = %94
  %99 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 24
  %100 = load i32, i32* %99, align 4
  %101 = icmp eq i32 %100, 0
  br i1 %101, label %102, label %9

102:                                              ; preds = %98
  %103 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 25
  %104 = load i32, i32* %103, align 4
  %105 = icmp eq i32 %104, 0
  br i1 %105, label %106, label %9

106:                                              ; preds = %102
  %107 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 26
  %108 = load i32, i32* %107, align 4
  %109 = icmp eq i32 %108, 0
  br i1 %109, label %110, label %9

110:                                              ; preds = %106
  %111 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 27
  %112 = load i32, i32* %111, align 4
  %113 = icmp eq i32 %112, 0
  br i1 %113, label %114, label %9

114:                                              ; preds = %110
  %115 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 28
  %116 = load i32, i32* %115, align 4
  %117 = icmp eq i32 %116, 0
  br i1 %117, label %118, label %9

118:                                              ; preds = %114
  %119 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 29
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 0
  br i1 %121, label %122, label %9

122:                                              ; preds = %118
  %123 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 30
  %124 = load i32, i32* %123, align 4
  %125 = icmp eq i32 %124, 0
  br i1 %125, label %126, label %9

126:                                              ; preds = %122
  %127 = getelementptr inbounds %"class.v8::internal::SlotSet::Bucket", %"class.v8::internal::SlotSet::Bucket"* %0, i64 0, i32 0, i64 31
  %128 = load i32, i32* %127, align 4
  %129 = icmp eq i32 %128, 0
  ret i1 %129
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { %"struct.std::__1::__hash_node_base.76"*, i8 } @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE25__emplace_unique_key_argsImJRKNS_21piecewise_construct_tENS_5tupleIJRKmEEENSM_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeIS6_PvEEEEbEERKT_DpOT0_(%"class.std::__1::__hash_table.72"*, i64* dereferenceable(8), %"struct.std::__1::piecewise_construct_t"* dereferenceable(1), %"class.std::__1::tuple"* dereferenceable(8), %"class.std::__1::tuple.1150"* dereferenceable(1)) local_unnamed_addr #0 comdat align 2 {
  %6 = load i64, i64* %1, align 8
  %7 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %8 = load i64, i64* %7, align 8
  %9 = icmp eq i64 %8, 0
  br i1 %9, label %69, label %10

10:                                               ; preds = %5
  %11 = tail call i64 @llvm.ctpop.i64(i64 %8) #14, !range !4
  %12 = icmp ugt i64 %11, 1
  br i1 %12, label %16, label %13

13:                                               ; preds = %10
  %14 = add i64 %8, -1
  %15 = and i64 %14, %6
  br label %20

16:                                               ; preds = %10
  %17 = icmp ult i64 %6, %8
  br i1 %17, label %20, label %18

18:                                               ; preds = %16
  %19 = urem i64 %6, %8
  br label %20

20:                                               ; preds = %13, %16, %18
  %21 = phi i64 [ %15, %13 ], [ %19, %18 ], [ %6, %16 ]
  %22 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %23 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %22, align 8
  %24 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %23, i64 %21
  %25 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %24, align 8
  %26 = icmp eq %"struct.std::__1::__hash_node_base.76"* %25, null
  br i1 %26, label %69, label %27

27:                                               ; preds = %20
  %28 = add i64 %8, -1
  br i1 %12, label %29, label %51

29:                                               ; preds = %27, %46
  %30 = phi %"struct.std::__1::__hash_node_base.76"* [ %32, %46 ], [ %25, %27 ]
  %31 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %30, i64 0, i32 0
  %32 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %31, align 8
  %33 = icmp eq %"struct.std::__1::__hash_node_base.76"* %32, null
  br i1 %33, label %69, label %34

34:                                               ; preds = %29
  %35 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %32, i64 1
  %36 = bitcast %"struct.std::__1::__hash_node_base.76"* %35 to i64*
  %37 = load i64, i64* %36, align 8
  %38 = icmp eq i64 %37, %6
  br i1 %38, label %46, label %39

39:                                               ; preds = %34
  %40 = icmp ult i64 %37, %8
  br i1 %40, label %43, label %41

41:                                               ; preds = %39
  %42 = urem i64 %37, %8
  br label %43

43:                                               ; preds = %41, %39
  %44 = phi i64 [ %42, %41 ], [ %37, %39 ]
  %45 = icmp eq i64 %44, %21
  br i1 %45, label %46, label %69

46:                                               ; preds = %43, %34
  %47 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %32, i64 2
  %48 = bitcast %"struct.std::__1::__hash_node_base.76"* %47 to i64*
  %49 = load i64, i64* %48, align 8
  %50 = icmp eq i64 %49, %6
  br i1 %50, label %160, label %29

51:                                               ; preds = %27, %64
  %52 = phi %"struct.std::__1::__hash_node_base.76"* [ %54, %64 ], [ %25, %27 ]
  %53 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %52, i64 0, i32 0
  %54 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %53, align 8
  %55 = icmp eq %"struct.std::__1::__hash_node_base.76"* %54, null
  br i1 %55, label %69, label %56

56:                                               ; preds = %51
  %57 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %54, i64 1
  %58 = bitcast %"struct.std::__1::__hash_node_base.76"* %57 to i64*
  %59 = load i64, i64* %58, align 8
  %60 = icmp eq i64 %59, %6
  %61 = and i64 %59, %28
  %62 = icmp eq i64 %61, %21
  %63 = or i1 %60, %62
  br i1 %63, label %64, label %69

64:                                               ; preds = %56
  %65 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %54, i64 2
  %66 = bitcast %"struct.std::__1::__hash_node_base.76"* %65 to i64*
  %67 = load i64, i64* %66, align 8
  %68 = icmp eq i64 %67, %6
  br i1 %68, label %160, label %51

69:                                               ; preds = %56, %51, %43, %29, %20, %5
  %70 = phi i64 [ %21, %20 ], [ undef, %5 ], [ %21, %29 ], [ %21, %43 ], [ %21, %51 ], [ %21, %56 ]
  %71 = tail call i8* @_Znwm(i64 32) #15, !noalias !16
  %72 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %3, i64 0, i32 0, i32 0, i32 0
  %73 = load i64*, i64** %72, align 8, !noalias !16
  %74 = getelementptr inbounds i8, i8* %71, i64 16
  %75 = bitcast i8* %74 to i64*
  %76 = load i64, i64* %73, align 8, !noalias !16
  store i64 %76, i64* %75, align 8, !noalias !16
  %77 = getelementptr inbounds i8, i8* %71, i64 24
  %78 = bitcast i8* %77 to %"class.v8::internal::LargePage"**
  store %"class.v8::internal::LargePage"* null, %"class.v8::internal::LargePage"** %78, align 8, !noalias !16
  %79 = getelementptr inbounds i8, i8* %71, i64 8
  %80 = bitcast i8* %79 to i64*
  store i64 %6, i64* %80, align 8, !noalias !16
  %81 = bitcast i8* %71 to %"struct.std::__1::__hash_node_base.76"**
  store %"struct.std::__1::__hash_node_base.76"* null, %"struct.std::__1::__hash_node_base.76"** %81, align 8, !noalias !16
  %82 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 2, i32 0, i32 0
  %83 = load i64, i64* %82, align 8
  %84 = add i64 %83, 1
  %85 = uitofp i64 %84 to float
  %86 = uitofp i64 %8 to float
  %87 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 3, i32 0, i32 0
  %88 = load float, float* %87, align 4
  %89 = fmul float %88, %86
  %90 = fcmp olt float %89, %85
  %91 = or i1 %9, %90
  br i1 %91, label %92, label %115

92:                                               ; preds = %69
  %93 = shl i64 %8, 1
  %94 = icmp ult i64 %8, 3
  %95 = tail call i64 @llvm.ctpop.i64(i64 %8) #14, !range !4
  %96 = icmp ugt i64 %95, 1
  %97 = or i1 %94, %96
  %98 = zext i1 %97 to i64
  %99 = or i64 %93, %98
  %100 = fdiv float %85, %88
  %101 = tail call float @llvm.ceil.f32(float %100) #14
  %102 = fptoui float %101 to i64
  %103 = icmp ult i64 %99, %102
  %104 = select i1 %103, i64 %102, i64 %99
  tail call void @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE6rehashEm(%"class.std::__1::__hash_table.72"* %0, i64 %104)
  %105 = load i64, i64* %7, align 8
  %106 = tail call i64 @llvm.ctpop.i64(i64 %105) #14, !range !4
  %107 = icmp ugt i64 %106, 1
  br i1 %107, label %111, label %108

108:                                              ; preds = %92
  %109 = add i64 %105, -1
  %110 = and i64 %109, %6
  br label %115

111:                                              ; preds = %92
  %112 = icmp ult i64 %6, %105
  br i1 %112, label %115, label %113

113:                                              ; preds = %111
  %114 = urem i64 %6, %105
  br label %115

115:                                              ; preds = %113, %111, %108, %69
  %116 = phi i64 [ %8, %69 ], [ %105, %108 ], [ %105, %111 ], [ %105, %113 ]
  %117 = phi i64 [ %70, %69 ], [ %110, %108 ], [ %6, %111 ], [ %114, %113 ]
  %118 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %119 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %118, align 8
  %120 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %119, i64 %117
  %121 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %120, align 8
  %122 = icmp eq %"struct.std::__1::__hash_node_base.76"* %121, null
  br i1 %122, label %123, label %149

123:                                              ; preds = %115
  %124 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 1, i32 0, i32 0
  %125 = bitcast %"struct.std::__1::__hash_node_base.76"* %124 to i64*
  %126 = load i64, i64* %125, align 8
  %127 = bitcast i8* %71 to i64*
  store i64 %126, i64* %127, align 8
  %128 = bitcast %"struct.std::__1::__hash_node_base.76"* %124 to i8**
  store i8* %71, i8** %128, align 8
  store %"struct.std::__1::__hash_node_base.76"* %124, %"struct.std::__1::__hash_node_base.76"** %120, align 8
  %129 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %81, align 8
  %130 = icmp eq %"struct.std::__1::__hash_node_base.76"* %129, null
  br i1 %130, label %156, label %131

131:                                              ; preds = %123
  %132 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %129, i64 1
  %133 = bitcast %"struct.std::__1::__hash_node_base.76"* %132 to i64*
  %134 = load i64, i64* %133, align 8
  %135 = tail call i64 @llvm.ctpop.i64(i64 %116) #14, !range !4
  %136 = icmp ugt i64 %135, 1
  br i1 %136, label %140, label %137

137:                                              ; preds = %131
  %138 = add i64 %116, -1
  %139 = and i64 %134, %138
  br label %144

140:                                              ; preds = %131
  %141 = icmp ult i64 %134, %116
  br i1 %141, label %144, label %142

142:                                              ; preds = %140
  %143 = urem i64 %134, %116
  br label %144

144:                                              ; preds = %137, %140, %142
  %145 = phi i64 [ %139, %137 ], [ %143, %142 ], [ %134, %140 ]
  %146 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %118, align 8
  %147 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %146, i64 %145
  %148 = bitcast %"struct.std::__1::__hash_node_base.76"** %147 to i8**
  br label %154

149:                                              ; preds = %115
  %150 = bitcast %"struct.std::__1::__hash_node_base.76"* %121 to i64*
  %151 = load i64, i64* %150, align 8
  %152 = bitcast i8* %71 to i64*
  store i64 %151, i64* %152, align 8
  %153 = bitcast %"struct.std::__1::__hash_node_base.76"* %121 to i8**
  br label %154

154:                                              ; preds = %144, %149
  %155 = phi i8** [ %153, %149 ], [ %148, %144 ]
  store i8* %71, i8** %155, align 8
  br label %156

156:                                              ; preds = %154, %123
  %157 = bitcast i8* %71 to %"struct.std::__1::__hash_node_base.76"*
  %158 = load i64, i64* %82, align 8
  %159 = add i64 %158, 1
  store i64 %159, i64* %82, align 8
  br label %160

160:                                              ; preds = %64, %46, %156
  %161 = phi i8 [ 1, %156 ], [ 0, %46 ], [ 0, %64 ]
  %162 = phi %"struct.std::__1::__hash_node_base.76"* [ %157, %156 ], [ %32, %46 ], [ %54, %64 ]
  %163 = insertvalue { %"struct.std::__1::__hash_node_base.76"*, i8 } undef, %"struct.std::__1::__hash_node_base.76"* %162, 0
  %164 = insertvalue { %"struct.std::__1::__hash_node_base.76"*, i8 } %163, i8 %161, 1
  ret { %"struct.std::__1::__hash_node_base.76"*, i8 } %164
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE6rehashEm(%"class.std::__1::__hash_table.72"*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = icmp eq i64 %1, 1
  br i1 %3, label %9, label %4

4:                                                ; preds = %2
  %5 = tail call i64 @llvm.ctpop.i64(i64 %1), !range !4
  %6 = icmp ugt i64 %5, 1
  br i1 %6, label %7, label %9

7:                                                ; preds = %4
  %8 = tail call i64 @_ZNSt3__112__next_primeEm(i64 %1) #14
  br label %9

9:                                                ; preds = %2, %4, %7
  %10 = phi i64 [ %8, %7 ], [ %1, %4 ], [ 2, %2 ]
  %11 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %12 = load i64, i64* %11, align 8
  %13 = icmp ugt i64 %10, %12
  br i1 %13, label %14, label %15

14:                                               ; preds = %9
  tail call void @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE8__rehashEm(%"class.std::__1::__hash_table.72"* %0, i64 %10)
  br label %45

15:                                               ; preds = %9
  %16 = icmp ult i64 %10, %12
  br i1 %16, label %17, label %45

17:                                               ; preds = %15
  %18 = icmp ugt i64 %12, 2
  %19 = tail call i64 @llvm.ctpop.i64(i64 %12) #14, !range !4
  %20 = icmp ult i64 %19, 2
  %21 = and i1 %18, %20
  %22 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 2, i32 0, i32 0
  %23 = load i64, i64* %22, align 8
  %24 = uitofp i64 %23 to float
  %25 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 3, i32 0, i32 0
  %26 = load float, float* %25, align 4
  %27 = fdiv float %24, %26
  %28 = tail call float @llvm.ceil.f32(float %27) #14
  %29 = fptoui float %28 to i64
  br i1 %21, label %30, label %37

30:                                               ; preds = %17
  %31 = icmp ult i64 %29, 2
  br i1 %31, label %39, label %32

32:                                               ; preds = %30
  %33 = add i64 %29, -1
  %34 = tail call i64 @llvm.ctlz.i64(i64 %33, i1 true) #14, !range !4
  %35 = sub nuw nsw i64 64, %34
  %36 = shl i64 1, %35
  br label %39

37:                                               ; preds = %17
  %38 = tail call i64 @_ZNSt3__112__next_primeEm(i64 %29) #14
  br label %39

39:                                               ; preds = %32, %30, %37
  %40 = phi i64 [ %38, %37 ], [ %36, %32 ], [ %29, %30 ]
  %41 = icmp ult i64 %10, %40
  %42 = select i1 %41, i64 %40, i64 %10
  %43 = icmp ult i64 %42, %12
  br i1 %43, label %44, label %45

44:                                               ; preds = %39
  tail call void @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE8__rehashEm(%"class.std::__1::__hash_table.72"* %0, i64 %42)
  br label %45

45:                                               ; preds = %15, %44, %39, %14
  ret void
}

; Function Attrs: noreturn nounwind
declare void @abort() local_unnamed_addr #11

declare i64 @_ZNSt3__112__next_primeEm(i64) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE8__rehashEm(%"class.std::__1::__hash_table.72"*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 0, i32 0, i32 1, i32 0
  %4 = icmp eq i64 %1, 0
  br i1 %4, label %179, label %5

5:                                                ; preds = %2
  %6 = icmp ugt i64 %1, 2305843009213693951
  br i1 %6, label %7, label %8

7:                                                ; preds = %5
  tail call void @abort() #13
  unreachable

8:                                                ; preds = %5
  %9 = shl i64 %1, 3
  %10 = tail call i8* @_Znwm(i64 %9) #15
  %11 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %12 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %13 = bitcast %"class.std::__1::__hash_table.72"* %0 to i8**
  store i8* %10, i8** %13, align 8
  %14 = icmp eq %"struct.std::__1::__hash_node_base.76"** %12, null
  br i1 %14, label %17, label %15

15:                                               ; preds = %8
  %16 = bitcast %"struct.std::__1::__hash_node_base.76"** %12 to i8*
  tail call void @_ZdlPv(i8* %16) #15
  br label %17

17:                                               ; preds = %15, %8
  %18 = getelementptr inbounds %"class.std::__1::__bucket_list_deallocator.78", %"class.std::__1::__bucket_list_deallocator.78"* %3, i64 0, i32 0, i32 0, i32 0
  store i64 %1, i64* %18, align 8
  %19 = add i64 %1, -1
  %20 = and i64 %1, 3
  %21 = icmp ult i64 %19, 3
  br i1 %21, label %24, label %22

22:                                               ; preds = %17
  %23 = sub i64 %1, %20
  br label %40

24:                                               ; preds = %40, %17
  %25 = phi i64 [ 0, %17 ], [ %54, %40 ]
  %26 = icmp eq i64 %20, 0
  br i1 %26, label %35, label %27

27:                                               ; preds = %24, %27
  %28 = phi i64 [ %32, %27 ], [ %25, %24 ]
  %29 = phi i64 [ %33, %27 ], [ %20, %24 ]
  %30 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %31 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %30, i64 %28
  store %"struct.std::__1::__hash_node_base.76"* null, %"struct.std::__1::__hash_node_base.76"** %31, align 8
  %32 = add nuw i64 %28, 1
  %33 = add i64 %29, -1
  %34 = icmp eq i64 %33, 0
  br i1 %34, label %35, label %27, !llvm.loop !19

35:                                               ; preds = %27, %24
  %36 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 1, i32 0, i32 0
  %37 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %36, i64 0, i32 0
  %38 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %37, align 8
  %39 = icmp eq %"struct.std::__1::__hash_node_base.76"* %38, null
  br i1 %39, label %187, label %57

40:                                               ; preds = %40, %22
  %41 = phi i64 [ 0, %22 ], [ %54, %40 ]
  %42 = phi i64 [ %23, %22 ], [ %55, %40 ]
  %43 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %44 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %43, i64 %41
  store %"struct.std::__1::__hash_node_base.76"* null, %"struct.std::__1::__hash_node_base.76"** %44, align 8
  %45 = or i64 %41, 1
  %46 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %47 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %46, i64 %45
  store %"struct.std::__1::__hash_node_base.76"* null, %"struct.std::__1::__hash_node_base.76"** %47, align 8
  %48 = or i64 %41, 2
  %49 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %50 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %49, i64 %48
  store %"struct.std::__1::__hash_node_base.76"* null, %"struct.std::__1::__hash_node_base.76"** %50, align 8
  %51 = or i64 %41, 3
  %52 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %53 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %52, i64 %51
  store %"struct.std::__1::__hash_node_base.76"* null, %"struct.std::__1::__hash_node_base.76"** %53, align 8
  %54 = add nuw i64 %41, 4
  %55 = add i64 %42, -4
  %56 = icmp eq i64 %55, 0
  br i1 %56, label %24, label %40

57:                                               ; preds = %35
  %58 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %38, i64 1
  %59 = bitcast %"struct.std::__1::__hash_node_base.76"* %58 to i64*
  %60 = load i64, i64* %59, align 8
  %61 = tail call i64 @llvm.ctpop.i64(i64 %1) #14, !range !4
  %62 = icmp ugt i64 %61, 1
  br i1 %62, label %66, label %63

63:                                               ; preds = %57
  %64 = add i64 %1, -1
  %65 = and i64 %60, %64
  br label %70

66:                                               ; preds = %57
  %67 = icmp ult i64 %60, %1
  br i1 %67, label %70, label %68

68:                                               ; preds = %66
  %69 = urem i64 %60, %1
  br label %70

70:                                               ; preds = %63, %66, %68
  %71 = phi i64 [ %65, %63 ], [ %69, %68 ], [ %60, %66 ]
  %72 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %73 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %72, i64 %71
  store %"struct.std::__1::__hash_node_base.76"* %36, %"struct.std::__1::__hash_node_base.76"** %73, align 8
  %74 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %38, i64 0, i32 0
  %75 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %74, align 8
  %76 = icmp eq %"struct.std::__1::__hash_node_base.76"* %75, null
  br i1 %76, label %187, label %77

77:                                               ; preds = %70
  %78 = add i64 %1, -1
  br i1 %62, label %79, label %131

79:                                               ; preds = %77, %122
  %80 = phi %"struct.std::__1::__hash_node_base.76"* [ %126, %122 ], [ %75, %77 ]
  %81 = phi i64 [ %124, %122 ], [ %71, %77 ]
  %82 = phi %"struct.std::__1::__hash_node_base.76"* [ %123, %122 ], [ %38, %77 ]
  %83 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %80, i64 1
  %84 = bitcast %"struct.std::__1::__hash_node_base.76"* %83 to i64*
  %85 = load i64, i64* %84, align 8
  %86 = icmp ult i64 %85, %1
  br i1 %86, label %89, label %87

87:                                               ; preds = %79
  %88 = urem i64 %85, %1
  br label %89

89:                                               ; preds = %87, %79
  %90 = phi i64 [ %88, %87 ], [ %85, %79 ]
  %91 = icmp eq i64 %90, %81
  br i1 %91, label %122, label %92

92:                                               ; preds = %89
  %93 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %94 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %93, i64 %90
  %95 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %94, align 8
  %96 = icmp eq %"struct.std::__1::__hash_node_base.76"* %95, null
  br i1 %96, label %121, label %128

97:                                               ; preds = %128, %102
  %98 = phi %"struct.std::__1::__hash_node_base.76"* [ %100, %102 ], [ %80, %128 ]
  %99 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %98, i64 0, i32 0
  %100 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %99, align 8
  %101 = icmp eq %"struct.std::__1::__hash_node_base.76"* %100, null
  br i1 %101, label %108, label %102

102:                                              ; preds = %97
  %103 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %100, i64 2
  %104 = bitcast %"struct.std::__1::__hash_node_base.76"* %103 to i64*
  %105 = load i64, i64* %130, align 8
  %106 = load i64, i64* %104, align 8
  %107 = icmp eq i64 %105, %106
  br i1 %107, label %97, label %108

108:                                              ; preds = %102, %97
  %109 = ptrtoint %"struct.std::__1::__hash_node_base.76"* %100 to i64
  %110 = bitcast %"struct.std::__1::__hash_node_base.76"* %98 to i64*
  %111 = bitcast %"struct.std::__1::__hash_node_base.76"* %82 to i64*
  store i64 %109, i64* %111, align 8
  %112 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %113 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %112, i64 %90
  %114 = bitcast %"struct.std::__1::__hash_node_base.76"** %113 to i64**
  %115 = load i64*, i64** %114, align 8
  %116 = load i64, i64* %115, align 8
  store i64 %116, i64* %110, align 8
  %117 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %118 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %117, i64 %90
  %119 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %118, align 8
  %120 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %119, i64 0, i32 0
  store %"struct.std::__1::__hash_node_base.76"* %80, %"struct.std::__1::__hash_node_base.76"** %120, align 8
  br label %122

121:                                              ; preds = %92
  store %"struct.std::__1::__hash_node_base.76"* %82, %"struct.std::__1::__hash_node_base.76"** %94, align 8
  br label %122

122:                                              ; preds = %121, %108, %89
  %123 = phi %"struct.std::__1::__hash_node_base.76"* [ %80, %121 ], [ %82, %108 ], [ %80, %89 ]
  %124 = phi i64 [ %90, %121 ], [ %81, %108 ], [ %81, %89 ]
  %125 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %123, i64 0, i32 0
  %126 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %125, align 8
  %127 = icmp eq %"struct.std::__1::__hash_node_base.76"* %126, null
  br i1 %127, label %187, label %79

128:                                              ; preds = %92
  %129 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %80, i64 2
  %130 = bitcast %"struct.std::__1::__hash_node_base.76"* %129 to i64*
  br label %97

131:                                              ; preds = %77, %173
  %132 = phi %"struct.std::__1::__hash_node_base.76"* [ %177, %173 ], [ %75, %77 ]
  %133 = phi i64 [ %175, %173 ], [ %71, %77 ]
  %134 = phi %"struct.std::__1::__hash_node_base.76"* [ %174, %173 ], [ %38, %77 ]
  %135 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %132, i64 1
  %136 = bitcast %"struct.std::__1::__hash_node_base.76"* %135 to i64*
  %137 = load i64, i64* %136, align 8
  %138 = and i64 %137, %78
  %139 = icmp eq i64 %138, %133
  br i1 %139, label %173, label %140

140:                                              ; preds = %131
  %141 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %142 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %141, i64 %138
  %143 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %142, align 8
  %144 = icmp eq %"struct.std::__1::__hash_node_base.76"* %143, null
  br i1 %144, label %148, label %145

145:                                              ; preds = %140
  %146 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %132, i64 2
  %147 = bitcast %"struct.std::__1::__hash_node_base.76"* %146 to i64*
  br label %149

148:                                              ; preds = %140
  store %"struct.std::__1::__hash_node_base.76"* %134, %"struct.std::__1::__hash_node_base.76"** %142, align 8
  br label %173

149:                                              ; preds = %145, %154
  %150 = phi %"struct.std::__1::__hash_node_base.76"* [ %152, %154 ], [ %132, %145 ]
  %151 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %150, i64 0, i32 0
  %152 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %151, align 8
  %153 = icmp eq %"struct.std::__1::__hash_node_base.76"* %152, null
  br i1 %153, label %160, label %154

154:                                              ; preds = %149
  %155 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %152, i64 2
  %156 = bitcast %"struct.std::__1::__hash_node_base.76"* %155 to i64*
  %157 = load i64, i64* %147, align 8
  %158 = load i64, i64* %156, align 8
  %159 = icmp eq i64 %157, %158
  br i1 %159, label %149, label %160

160:                                              ; preds = %149, %154
  %161 = ptrtoint %"struct.std::__1::__hash_node_base.76"* %152 to i64
  %162 = bitcast %"struct.std::__1::__hash_node_base.76"* %150 to i64*
  %163 = bitcast %"struct.std::__1::__hash_node_base.76"* %134 to i64*
  store i64 %161, i64* %163, align 8
  %164 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %165 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %164, i64 %138
  %166 = bitcast %"struct.std::__1::__hash_node_base.76"** %165 to i64**
  %167 = load i64*, i64** %166, align 8
  %168 = load i64, i64* %167, align 8
  store i64 %168, i64* %162, align 8
  %169 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %11, align 8
  %170 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %169, i64 %138
  %171 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %170, align 8
  %172 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %171, i64 0, i32 0
  store %"struct.std::__1::__hash_node_base.76"* %132, %"struct.std::__1::__hash_node_base.76"** %172, align 8
  br label %173

173:                                              ; preds = %131, %160, %148
  %174 = phi %"struct.std::__1::__hash_node_base.76"* [ %132, %148 ], [ %134, %160 ], [ %132, %131 ]
  %175 = phi i64 [ %138, %148 ], [ %133, %160 ], [ %133, %131 ]
  %176 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %174, i64 0, i32 0
  %177 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %176, align 8
  %178 = icmp eq %"struct.std::__1::__hash_node_base.76"* %177, null
  br i1 %178, label %187, label %131

179:                                              ; preds = %2
  %180 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %181 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %180, align 8
  store %"struct.std::__1::__hash_node_base.76"** null, %"struct.std::__1::__hash_node_base.76"*** %180, align 8
  %182 = icmp eq %"struct.std::__1::__hash_node_base.76"** %181, null
  br i1 %182, label %185, label %183

183:                                              ; preds = %179
  %184 = bitcast %"struct.std::__1::__hash_node_base.76"** %181 to i8*
  tail call void @_ZdlPv(i8* %184) #15
  br label %185

185:                                              ; preds = %179, %183
  %186 = getelementptr inbounds %"class.std::__1::__bucket_list_deallocator.78", %"class.std::__1::__bucket_list_deallocator.78"* %3, i64 0, i32 0, i32 0, i32 0
  store i64 0, i64* %186, align 8
  br label %187

187:                                              ; preds = %173, %122, %70, %35, %185
  ret void
}

; Function Attrs: nounwind readnone speculatable
declare i64 @llvm.ctlz.i64(i64, i1 immarg) #12

; Function Attrs: nounwind readnone speculatable
declare float @llvm.ceil.f32(float) #12

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE6removeENS_21__hash_const_iteratorIPNS_11__hash_nodeIS6_PvEEEE(%"class.std::__1::unique_ptr.1151"* noalias sret, %"class.std::__1::__hash_table.72"*, %"struct.std::__1::__hash_node_base.76"*) local_unnamed_addr #0 comdat align 2 {
  %4 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %1, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %2, i64 1
  %7 = bitcast %"struct.std::__1::__hash_node_base.76"* %6 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = tail call i64 @llvm.ctpop.i64(i64 %5) #14, !range !4
  %10 = icmp ugt i64 %9, 1
  br i1 %10, label %14, label %11

11:                                               ; preds = %3
  %12 = add i64 %5, -1
  %13 = and i64 %12, %8
  br label %18

14:                                               ; preds = %3
  %15 = icmp ult i64 %8, %5
  br i1 %15, label %18, label %16

16:                                               ; preds = %14
  %17 = urem i64 %8, %5
  br label %18

18:                                               ; preds = %11, %14, %16
  %19 = phi i64 [ %13, %11 ], [ %17, %16 ], [ %8, %14 ]
  %20 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %1, i64 0, i32 0, i32 0, i32 0, i32 0
  %21 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %20, align 8
  %22 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %21, i64 %19
  %23 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %22, align 8
  br label %24

24:                                               ; preds = %24, %18
  %25 = phi %"struct.std::__1::__hash_node_base.76"* [ %23, %18 ], [ %27, %24 ]
  %26 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %25, i64 0, i32 0
  %27 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %26, align 8
  %28 = icmp eq %"struct.std::__1::__hash_node_base.76"* %27, %2
  br i1 %28, label %29, label %24

29:                                               ; preds = %24
  %30 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %1, i64 0, i32 1
  %31 = getelementptr inbounds %"class.std::__1::__compressed_pair.83", %"class.std::__1::__compressed_pair.83"* %30, i64 0, i32 0, i32 0
  %32 = icmp eq %"struct.std::__1::__hash_node_base.76"* %25, %31
  br i1 %32, label %47, label %33

33:                                               ; preds = %29
  %34 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %25, i64 1
  %35 = bitcast %"struct.std::__1::__hash_node_base.76"* %34 to i64*
  %36 = load i64, i64* %35, align 8
  br i1 %10, label %40, label %37

37:                                               ; preds = %33
  %38 = add i64 %5, -1
  %39 = and i64 %36, %38
  br label %44

40:                                               ; preds = %33
  %41 = icmp ult i64 %36, %5
  br i1 %41, label %44, label %42

42:                                               ; preds = %40
  %43 = urem i64 %36, %5
  br label %44

44:                                               ; preds = %37, %40, %42
  %45 = phi i64 [ %39, %37 ], [ %43, %42 ], [ %36, %40 ]
  %46 = icmp eq i64 %45, %19
  br i1 %46, label %66, label %47

47:                                               ; preds = %44, %29
  %48 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %2, i64 0, i32 0
  %49 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %48, align 8
  %50 = icmp eq %"struct.std::__1::__hash_node_base.76"* %49, null
  br i1 %50, label %65, label %51

51:                                               ; preds = %47
  %52 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %49, i64 1
  %53 = bitcast %"struct.std::__1::__hash_node_base.76"* %52 to i64*
  %54 = load i64, i64* %53, align 8
  br i1 %10, label %58, label %55

55:                                               ; preds = %51
  %56 = add i64 %5, -1
  %57 = and i64 %54, %56
  br label %62

58:                                               ; preds = %51
  %59 = icmp ult i64 %54, %5
  br i1 %59, label %62, label %60

60:                                               ; preds = %58
  %61 = urem i64 %54, %5
  br label %62

62:                                               ; preds = %55, %58, %60
  %63 = phi i64 [ %57, %55 ], [ %61, %60 ], [ %54, %58 ]
  %64 = icmp eq i64 %63, %19
  br i1 %64, label %66, label %65

65:                                               ; preds = %62, %47
  store %"struct.std::__1::__hash_node_base.76"* null, %"struct.std::__1::__hash_node_base.76"** %22, align 8
  br label %66

66:                                               ; preds = %62, %44, %65
  %67 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %2, i64 0, i32 0
  %68 = load %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %67, align 8
  %69 = icmp eq %"struct.std::__1::__hash_node_base.76"* %68, null
  %70 = ptrtoint %"struct.std::__1::__hash_node_base.76"* %68 to i64
  br i1 %69, label %90, label %71

71:                                               ; preds = %66
  %72 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76", %"struct.std::__1::__hash_node_base.76"* %68, i64 1
  %73 = bitcast %"struct.std::__1::__hash_node_base.76"* %72 to i64*
  %74 = load i64, i64* %73, align 8
  br i1 %10, label %78, label %75

75:                                               ; preds = %71
  %76 = add i64 %5, -1
  %77 = and i64 %74, %76
  br label %82

78:                                               ; preds = %71
  %79 = icmp ult i64 %74, %5
  br i1 %79, label %82, label %80

80:                                               ; preds = %78
  %81 = urem i64 %74, %5
  br label %82

82:                                               ; preds = %75, %78, %80
  %83 = phi i64 [ %77, %75 ], [ %81, %80 ], [ %74, %78 ]
  %84 = icmp eq i64 %83, %19
  br i1 %84, label %90, label %85

85:                                               ; preds = %82
  %86 = load %"struct.std::__1::__hash_node_base.76"**, %"struct.std::__1::__hash_node_base.76"*** %20, align 8
  %87 = getelementptr inbounds %"struct.std::__1::__hash_node_base.76"*, %"struct.std::__1::__hash_node_base.76"** %86, i64 %83
  store %"struct.std::__1::__hash_node_base.76"* %25, %"struct.std::__1::__hash_node_base.76"** %87, align 8
  %88 = bitcast %"struct.std::__1::__hash_node_base.76"* %2 to i64*
  %89 = load i64, i64* %88, align 8
  br label %90

90:                                               ; preds = %85, %82, %66
  %91 = phi i64 [ %89, %85 ], [ %70, %82 ], [ %70, %66 ]
  %92 = bitcast %"struct.std::__1::__hash_node_base.76"* %25 to i64*
  store i64 %91, i64* %92, align 8
  store %"struct.std::__1::__hash_node_base.76"* null, %"struct.std::__1::__hash_node_base.76"** %67, align 8
  %93 = getelementptr inbounds %"class.std::__1::__hash_table.72", %"class.std::__1::__hash_table.72"* %1, i64 0, i32 2, i32 0, i32 0
  %94 = load i64, i64* %93, align 8
  %95 = add i64 %94, -1
  store i64 %95, i64* %93, align 8
  %96 = ptrtoint %"struct.std::__1::__hash_node_base.76"* %2 to i64
  %97 = bitcast %"class.std::__1::unique_ptr.1151"* %0 to i64*
  store i64 %96, i64* %97, align 8
  %98 = getelementptr inbounds %"class.std::__1::unique_ptr.1151", %"class.std::__1::unique_ptr.1151"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %99 = bitcast %"class.std::__1::allocator.86"** %98 to %"class.std::__1::__compressed_pair.83"**
  store %"class.std::__1::__compressed_pair.83"* %30, %"class.std::__1::__compressed_pair.83"** %99, align 8
  %100 = getelementptr inbounds %"class.std::__1::unique_ptr.1151", %"class.std::__1::unique_ptr.1151"* %0, i64 0, i32 0, i32 1, i32 0, i32 1
  store i8 1, i8* %100, align 8
  ret void
}

; Function Attrs: nounwind readnone speculatable
declare i64 @llvm.ctpop.i64(i64) #12

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { argmemonly nounwind }
attributes #3 = { norecurse nounwind readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nobuiltin nofree "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { noreturn nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { nounwind readnone speculatable }
attributes #13 = { noreturn nounwind }
attributes #14 = { nounwind }
attributes #15 = { builtin nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i8 0, i8 2}
!3 = !{!"branch_weights", i32 1, i32 2000}
!4 = !{i64 0, i64 65}
!5 = !{!"branch_weights", i32 1073205, i32 2146410443}
!6 = !{!"branch_weights", i32 2000, i32 1}
!7 = !{!8}
!8 = distinct !{!8, !9, !"_ZN2v88internal16LargeObjectSpace5beginEv: argument 0"}
!9 = distinct !{!9, !"_ZN2v88internal16LargeObjectSpace5beginEv"}
!10 = !{!11}
!11 = distinct !{!11, !12, !"_ZN2v88internal16PageIteratorImplINS0_9LargePageEEppEi: argument 0"}
!12 = distinct !{!12, !"_ZN2v88internal16PageIteratorImplINS0_9LargePageEEppEi"}
!13 = distinct !{!13, !14}
!14 = !{!"llvm.loop.unroll.disable"}
!15 = distinct !{!15, !14}
!16 = !{!17}
!17 = distinct !{!17, !18, !"_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE21__construct_node_hashIRKNS_21piecewise_construct_tEJNS_5tupleIJRKmEEENSM_IJEEEEEENS_10unique_ptrINS_11__hash_nodeIS6_PvEENS_22__hash_node_destructorINSF_ISU_EEEEEEmOT_DpOT0_: argument 0"}
!18 = distinct !{!18, !"_ZNSt3__112__hash_tableINS_17__hash_value_typeImPN2v88internal9LargePageEEENS_22__unordered_map_hasherImS6_NS_4hashImEENS_8equal_toImEELb1EEENS_21__unordered_map_equalImS6_SB_S9_Lb1EEENS_9allocatorIS6_EEE21__construct_node_hashIRKNS_21piecewise_construct_tEJNS_5tupleIJRKmEEENSM_IJEEEEEENS_10unique_ptrINS_11__hash_nodeIS6_PvEENS_22__hash_node_destructorINSF_ISU_EEEEEEmOT_DpOT0_"}
!19 = distinct !{!19, !14}
